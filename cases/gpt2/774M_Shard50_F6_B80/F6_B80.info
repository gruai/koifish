********************************************************************
*             Koifish-v0.1 (2025-09-18 by gcc 11.4.0)              *
*  SPDX-FileCopyrightText: 2023-2025 Yingshi Chen                  *
*  SPDX-License-Identifier: MIT                                    *
*  MAIL: gsp.cys@gmail.com                                         *
********************************************************************

{train::optimizatioin::method} = adamw
{train::batch} = 80
{train::epoch} = 1
{train::learning-rate} = 0.001
{train::decay} = 0.1
{train::optimizatioin::grad_accumulation} = 1
{train::dump-every} = 10
{train::gpt-every} = -10
{seed} = 42
{threads} = 20
{train::optimizatioin::lars_ratio} = 0
{train::optimizatioin::ZMUV_ratio} = 0
{model::parameter::Layer} = 36
{Head} = 20
{Ffn} = 5120
{Ctx} = 1024
{model::fuyou::branch} = 6
{model::fuyou::crossover} = 0.6
{model::fuyou::mutation} = 0.001
{model::fuyou::social} = 2
{model::fuyou::method} = pso_ga
{model::fuyou::switch} = 100
[ARCH] sizeof(token)=4,sizeof(floatX)=2 sizeof(Grad)=2(2)
seed=42
{name} = edu_fineweb1B
{most} = 50
[GlobTokenset] edu_fineweb1B find 5G tokens @"./Datasets/edu_fineweb1B/*train*.bin"(50 files)
{name} = edu_fineweb1B
{eval-every} = 200
{samp} = 0.04
{most} = 10
[GlobTokenset] edu_fineweb1B find 0.1G tokens @"./Datasets/edu_fineweb1B/*val*.bin"(1 files)
DictVAE latent_dim=1280 Dialect=OFF
[shard-1]@"./Datasets/edu_fineweb1B/edu_fineweb_train_000001.bin": tokens=100(M) nShardSamples=1220(97656) 
[shard-1]@"./Datasets/edu_fineweb1B/edu_fineweb_val_000000.bin": tokens=100(M) nShardSamples=1220(97656) 
====== NO WIKI !!! ======
cudaGetDevice: _CUDA_FORCE_MMQ:    no
cudaGetDevice: _CUDA_FORCE_CUBLAS: no
cudaGetDevice: found 1 CUDA devices:
  Device 0: NVIDIA GeForce RTX 4090(25262.1M), compute capability 8.9, VMM: no
+-----------------------+----------------------------------------------------+
	君子不器 - "NVIDIA GeForce RTX 4090" 
	CUDA driver version / runtime version: 12.8 / 12.4
	CUDA capability major/minor version number: 8.9. ECC=0
	
	128 multiprocessors, 128 CUDA cores/MP, 16384 CUDA cores
	GPU max clock rate: 2520 MHz (2.52 GHz)
	Peak bandwidth 1008.1 GByte/s.	Memory clock rate: 10501 MHz (10.50 GHz)
	Memory bus width: 384-bit
	Global memory: 24092 MBytes (25262096384 Bytes)
	Constant memory: 64 KBytes (65536 Bytes)
	Shared memory per block: 48 KBytes (49152 Bytes)
	Shared memory per multiprocessor: 100 KBytes (102400 Bytes)
	L2 cache size: 73728 KBytes (75497472 Bytes)
	Total number of registers available per block: 65536
	Warp size: 32, Max number of threads per block: 1024
	Max number of threads per multiprocessor: 1536
	Max dimension size of a thread block (x,y,z): (1024, 1024, 64)
	Max dimension size of a grid size (x,y,z): (2147483647, 65535, 65535)
+-----------------------+----------------------------------------------------+
GPT2_model::InitModel: init model

 Init model embed=1280 layer=36 ff=5120 tpFFN=5
	 type of FFN=Variation@last_layer
koifish::CLI_params: 
 n_ctx=1024 embd=1280 n_ff=5120 n_head=20 n_head_kv=20 n_layer=36(-1) f_norm_rms_eps=1e-05
 ROPE: type=0 freq_base=10000 freq_scale=1 n_rot=64
 SepQKV: type=1  
[Shuffle]: nSamp=97656 samp_0={69070848:1024} hash=0x553E93901E44DA9E
[RLS]	Init [model.inp_embd,...,model.out.cls][Scheduling] MEM_STRATEGY=PRE_ALLOC_GPU UpdateParam=V1
[RLS]	nGuoke=0(0) Memory of GPU=3833.99M(free=21428.1M)


[Save] path is empty! To save model, please set the key of "checkpoint-out" in json config file("./cases/gpt2/774M_Shard50_F6_B80/F6_B80.json").
[Save] @"./hy-tmp/checkpoint/Koifish_latest.ck" nParams=580 nReloads=504  save_every=-1
	 cudaMalloc=838.861M@tmpBT4c type=BF16(E8) shape=[80,1024,5120,1] sum=0.839188G
	 cudaMalloc=838.861M@tmpFF1 type=BF16(E8) shape=[80,1024,5120,1] sum=1.67805G
	 cudaMalloc=128.778M@tmpTernary type=BF16(E8) shape=[1280,50304,1,1] sum=1.80683G
	 cudaMalloc=209.715M@tmpOutL type=BF16(E8) shape=[80,1024,1280,1] sum=2.01654G
	 cudaMalloc=906.592M@tmpScratch/output type=BF16(E8) shape=[8,56662016,1,1] sum=2.92313G
	 cudaMalloc=209.715M@tmpDelta type=BF16(E8) shape=[80,1024,1280,1] sum=3.13285G
	 cudaMalloc=209.715M@tmpDelta2 type=BF16(E8) shape=[80,1024,1280,1] sum=3.34257G
>>>>>> ST_SERIALIZE save @"./hy-tmp/checkpoint/Koifish_latest.ck" nInit=0 ......
>>>>>> ST_SERIALIZE save @"./hy-tmp/checkpoint/Koifish_latest.ck" nInit=0 sz=0M flag=256 T=4.729s

>>>>>> ST_SERIALIZE load@"./hy-tmp/checkpoint/Koifish_latest.ck" f=0......

>>>>>> ST_SERIALIZE load@"./hy-tmp/checkpoint/Koifish_latest.ck" nSerialT=580 iter=0
[RLS_branch] branches=6(36/6)  15@{L0:L6}	 fuyou_0 nParam=96 nReload=84(model.blk.0.attn.wq.weight model.blk.0.attn.wq.bias model.blk.0.attn.wk.weight model.blk.0.attn.wk.bias model.blk.0.attn.wv.weight model.blk.0.attn.wv.bias model.blk.0.attn.wo.weight model.blk.0.attn.wo.bias model.blk.0.ffn_up.weight model.blk.0.ffn_up.bias model.blk.0.ffn_down.weight model.blk.0.ffn_down.bias model.blk.0.ffn_norm.weight model.blk.0.ffn_norm.bias model.blk.1.attn.wq.weight model.blk.1.attn.wq.bias model.blk.1.attn.wk.weight model.blk.1.attn.wk.bias model.blk.1.attn.wv.weight model.blk.1.attn.wv.bias model.blk.1.attn.wo.weight model.blk.1.attn.wo.bias model.blk.1.ffn_up.weight model.blk.1.ffn_up.bias model.blk.1.ffn_down.weight model.blk.1.ffn_down.bias model.blk.1.ffn_norm.weight model.blk.1.ffn_norm.bias model.blk.2.attn.wq.weight model.blk.2.attn.wq.bias model.blk.2.attn.wk.weight model.blk.2.attn.wk.bias model.blk.2.attn.wv.weight model.blk.2.attn.wv.bias model.blk.2.attn.wo.weight model.blk.2.attn.wo.bias model.blk.2.ffn_up.weight model.blk.2.ffn_up.bias model.blk.2.ffn_down.weight model.blk.2.ffn_down.bias model.blk.2.ffn_norm.weight model.blk.2.ffn_norm.bias model.blk.3.attn.wq.weight model.blk.3.attn.wq.bias model.blk.3.attn.wk.weight model.blk.3.attn.wk.bias model.blk.3.attn.wv.weight model.blk.3.attn.wv.bias model.blk.3.attn.wo.weight model.blk.3.attn.wo.bias model.blk.3.ffn_up.weight model.blk.3.ffn_up.bias model.blk.3.ffn_down.weight model.blk.3.ffn_down.bias model.blk.3.ffn_norm.weight model.blk.3.ffn_norm.bias model.blk.4.attn.wq.weight model.blk.4.attn.wq.bias model.blk.4.attn.wk.weight model.blk.4.attn.wk.bias model.blk.4.attn.wv.weight model.blk.4.attn.wv.bias model.blk.4.attn.wo.weight model.blk.4.attn.wo.bias model.blk.4.ffn_up.weight model.blk.4.ffn_up.bias model.blk.4.ffn_down.weight model.blk.4.ffn_down.bias model.blk.4.ffn_norm.weight model.blk.4.ffn_norm.bias model.blk.5.attn.wq.weight model.blk.5.attn.wq.bias model.blk.5.attn.wk.weight model.blk.5.attn.wk.bias model.blk.5.attn.wv.weight model.blk.5.attn.wv.bias model.blk.5.attn.wo.weight model.blk.5.attn.wo.bias model.blk.5.ffn_up.weight model.blk.5.ffn_up.bias model.blk.5.ffn_down.weight model.blk.5.ffn_down.bias model.blk.5.ffn_norm.weight model.blk.5.ffn_norm.bias )
 15@{L6:L12}	 fuyou_1 nParam=96 nReload=84(model.blk.6.attn.wq.weight model.blk.6.attn.wq.bias model.blk.6.attn.wk.weight model.blk.6.attn.wk.bias model.blk.6.attn.wv.weight model.blk.6.attn.wv.bias model.blk.6.attn.wo.weight model.blk.6.attn.wo.bias model.blk.6.ffn_up.weight model.blk.6.ffn_up.bias model.blk.6.ffn_down.weight model.blk.6.ffn_down.bias model.blk.6.ffn_norm.weight model.blk.6.ffn_norm.bias model.blk.7.attn.wq.weight model.blk.7.attn.wq.bias model.blk.7.attn.wk.weight model.blk.7.attn.wk.bias model.blk.7.attn.wv.weight model.blk.7.attn.wv.bias model.blk.7.attn.wo.weight model.blk.7.attn.wo.bias model.blk.7.ffn_up.weight model.blk.7.ffn_up.bias model.blk.7.ffn_down.weight model.blk.7.ffn_down.bias model.blk.7.ffn_norm.weight model.blk.7.ffn_norm.bias model.blk.8.attn.wq.weight model.blk.8.attn.wq.bias model.blk.8.attn.wk.weight model.blk.8.attn.wk.bias model.blk.8.attn.wv.weight model.blk.8.attn.wv.bias model.blk.8.attn.wo.weight model.blk.8.attn.wo.bias model.blk.8.ffn_up.weight model.blk.8.ffn_up.bias model.blk.8.ffn_down.weight model.blk.8.ffn_down.bias model.blk.8.ffn_norm.weight model.blk.8.ffn_norm.bias model.blk.9.attn.wq.weight model.blk.9.attn.wq.bias model.blk.9.attn.wk.weight model.blk.9.attn.wk.bias model.blk.9.attn.wv.weight model.blk.9.attn.wv.bias model.blk.9.attn.wo.weight model.blk.9.attn.wo.bias model.blk.9.ffn_up.weight model.blk.9.ffn_up.bias model.blk.9.ffn_down.weight model.blk.9.ffn_down.bias model.blk.9.ffn_norm.weight model.blk.9.ffn_norm.bias model.blk.10.attn.wq.weight model.blk.10.attn.wq.bias model.blk.10.attn.wk.weight model.blk.10.attn.wk.bias model.blk.10.attn.wv.weight model.blk.10.attn.wv.bias model.blk.10.attn.wo.weight model.blk.10.attn.wo.bias model.blk.10.ffn_up.weight model.blk.10.ffn_up.bias model.blk.10.ffn_down.weight model.blk.10.ffn_down.bias model.blk.10.ffn_norm.weight model.blk.10.ffn_norm.bias model.blk.11.attn.wq.weight model.blk.11.attn.wq.bias model.blk.11.attn.wk.weight model.blk.11.attn.wk.bias model.blk.11.attn.wv.weight model.blk.11.attn.wv.bias model.blk.11.attn.wo.weight model.blk.11.attn.wo.bias model.blk.11.ffn_up.weight model.blk.11.ffn_up.bias model.blk.11.ffn_down.weight model.blk.11.ffn_down.bias model.blk.11.ffn_norm.weight model.blk.11.ffn_norm.bias )
 15@{L12:L18}	 fuyou_2 nParam=96 nReload=84(model.blk.12.attn.wq.weight model.blk.12.attn.wq.bias model.blk.12.attn.wk.weight model.blk.12.attn.wk.bias model.blk.12.attn.wv.weight model.blk.12.attn.wv.bias model.blk.12.attn.wo.weight model.blk.12.attn.wo.bias model.blk.12.ffn_up.weight model.blk.12.ffn_up.bias model.blk.12.ffn_down.weight model.blk.12.ffn_down.bias model.blk.12.ffn_norm.weight model.blk.12.ffn_norm.bias model.blk.13.attn.wq.weight model.blk.13.attn.wq.bias model.blk.13.attn.wk.weight model.blk.13.attn.wk.bias model.blk.13.attn.wv.weight model.blk.13.attn.wv.bias model.blk.13.attn.wo.weight model.blk.13.attn.wo.bias model.blk.13.ffn_up.weight model.blk.13.ffn_up.bias model.blk.13.ffn_down.weight model.blk.13.ffn_down.bias model.blk.13.ffn_norm.weight model.blk.13.ffn_norm.bias model.blk.14.attn.wq.weight model.blk.14.attn.wq.bias model.blk.14.attn.wk.weight model.blk.14.attn.wk.bias model.blk.14.attn.wv.weight model.blk.14.attn.wv.bias model.blk.14.attn.wo.weight model.blk.14.attn.wo.bias model.blk.14.ffn_up.weight model.blk.14.ffn_up.bias model.blk.14.ffn_down.weight model.blk.14.ffn_down.bias model.blk.14.ffn_norm.weight model.blk.14.ffn_norm.bias model.blk.15.attn.wq.weight model.blk.15.attn.wq.bias model.blk.15.attn.wk.weight model.blk.15.attn.wk.bias model.blk.15.attn.wv.weight model.blk.15.attn.wv.bias model.blk.15.attn.wo.weight model.blk.15.attn.wo.bias model.blk.15.ffn_up.weight model.blk.15.ffn_up.bias model.blk.15.ffn_down.weight model.blk.15.ffn_down.bias model.blk.15.ffn_norm.weight model.blk.15.ffn_norm.bias model.blk.16.attn.wq.weight model.blk.16.attn.wq.bias model.blk.16.attn.wk.weight model.blk.16.attn.wk.bias model.blk.16.attn.wv.weight model.blk.16.attn.wv.bias model.blk.16.attn.wo.weight model.blk.16.attn.wo.bias model.blk.16.ffn_up.weight model.blk.16.ffn_up.bias model.blk.16.ffn_down.weight model.blk.16.ffn_down.bias model.blk.16.ffn_norm.weight model.blk.16.ffn_norm.bias model.blk.17.attn.wq.weight model.blk.17.attn.wq.bias model.blk.17.attn.wk.weight model.blk.17.attn.wk.bias model.blk.17.attn.wv.weight model.blk.17.attn.wv.bias model.blk.17.attn.wo.weight model.blk.17.attn.wo.bias model.blk.17.ffn_up.weight model.blk.17.ffn_up.bias model.blk.17.ffn_down.weight model.blk.17.ffn_down.bias model.blk.17.ffn_norm.weight model.blk.17.ffn_norm.bias )
 15@{L18:L24}	 fuyou_3 nParam=96 nReload=84(model.blk.18.attn.wq.weight model.blk.18.attn.wq.bias model.blk.18.attn.wk.weight model.blk.18.attn.wk.bias model.blk.18.attn.wv.weight model.blk.18.attn.wv.bias model.blk.18.attn.wo.weight model.blk.18.attn.wo.bias model.blk.18.ffn_up.weight model.blk.18.ffn_up.bias model.blk.18.ffn_down.weight model.blk.18.ffn_down.bias model.blk.18.ffn_norm.weight model.blk.18.ffn_norm.bias model.blk.19.attn.wq.weight model.blk.19.attn.wq.bias model.blk.19.attn.wk.weight model.blk.19.attn.wk.bias model.blk.19.attn.wv.weight model.blk.19.attn.wv.bias model.blk.19.attn.wo.weight model.blk.19.attn.wo.bias model.blk.19.ffn_up.weight model.blk.19.ffn_up.bias model.blk.19.ffn_down.weight model.blk.19.ffn_down.bias model.blk.19.ffn_norm.weight model.blk.19.ffn_norm.bias model.blk.20.attn.wq.weight model.blk.20.attn.wq.bias model.blk.20.attn.wk.weight model.blk.20.attn.wk.bias model.blk.20.attn.wv.weight model.blk.20.attn.wv.bias model.blk.20.attn.wo.weight model.blk.20.attn.wo.bias model.blk.20.ffn_up.weight model.blk.20.ffn_up.bias model.blk.20.ffn_down.weight model.blk.20.ffn_down.bias model.blk.20.ffn_norm.weight model.blk.20.ffn_norm.bias model.blk.21.attn.wq.weight model.blk.21.attn.wq.bias model.blk.21.attn.wk.weight model.blk.21.attn.wk.bias model.blk.21.attn.wv.weight model.blk.21.attn.wv.bias model.blk.21.attn.wo.weight model.blk.21.attn.wo.bias model.blk.21.ffn_up.weight model.blk.21.ffn_up.bias model.blk.21.ffn_down.weight model.blk.21.ffn_down.bias model.blk.21.ffn_norm.weight model.blk.21.ffn_norm.bias model.blk.22.attn.wq.weight model.blk.22.attn.wq.bias model.blk.22.attn.wk.weight model.blk.22.attn.wk.bias model.blk.22.attn.wv.weight model.blk.22.attn.wv.bias model.blk.22.attn.wo.weight model.blk.22.attn.wo.bias model.blk.22.ffn_up.weight model.blk.22.ffn_up.bias model.blk.22.ffn_down.weight model.blk.22.ffn_down.bias model.blk.22.ffn_norm.weight model.blk.22.ffn_norm.bias model.blk.23.attn.wq.weight model.blk.23.attn.wq.bias model.blk.23.attn.wk.weight model.blk.23.attn.wk.bias model.blk.23.attn.wv.weight model.blk.23.attn.wv.bias model.blk.23.attn.wo.weight model.blk.23.attn.wo.bias model.blk.23.ffn_up.weight model.blk.23.ffn_up.bias model.blk.23.ffn_down.weight model.blk.23.ffn_down.bias model.blk.23.ffn_norm.weight model.blk.23.ffn_norm.bias )
 15@{L24:L30}	 fuyou_4 nParam=96 nReload=84(model.blk.24.attn.wq.weight model.blk.24.attn.wq.bias model.blk.24.attn.wk.weight model.blk.24.attn.wk.bias model.blk.24.attn.wv.weight model.blk.24.attn.wv.bias model.blk.24.attn.wo.weight model.blk.24.attn.wo.bias model.blk.24.ffn_up.weight model.blk.24.ffn_up.bias model.blk.24.ffn_down.weight model.blk.24.ffn_down.bias model.blk.24.ffn_norm.weight model.blk.24.ffn_norm.bias model.blk.25.attn.wq.weight model.blk.25.attn.wq.bias model.blk.25.attn.wk.weight model.blk.25.attn.wk.bias model.blk.25.attn.wv.weight model.blk.25.attn.wv.bias model.blk.25.attn.wo.weight model.blk.25.attn.wo.bias model.blk.25.ffn_up.weight model.blk.25.ffn_up.bias model.blk.25.ffn_down.weight model.blk.25.ffn_down.bias model.blk.25.ffn_norm.weight model.blk.25.ffn_norm.bias model.blk.26.attn.wq.weight model.blk.26.attn.wq.bias model.blk.26.attn.wk.weight model.blk.26.attn.wk.bias model.blk.26.attn.wv.weight model.blk.26.attn.wv.bias model.blk.26.attn.wo.weight model.blk.26.attn.wo.bias model.blk.26.ffn_up.weight model.blk.26.ffn_up.bias model.blk.26.ffn_down.weight model.blk.26.ffn_down.bias model.blk.26.ffn_norm.weight model.blk.26.ffn_norm.bias model.blk.27.attn.wq.weight model.blk.27.attn.wq.bias model.blk.27.attn.wk.weight model.blk.27.attn.wk.bias model.blk.27.attn.wv.weight model.blk.27.attn.wv.bias model.blk.27.attn.wo.weight model.blk.27.attn.wo.bias model.blk.27.ffn_up.weight model.blk.27.ffn_up.bias model.blk.27.ffn_down.weight model.blk.27.ffn_down.bias model.blk.27.ffn_norm.weight model.blk.27.ffn_norm.bias model.blk.28.attn.wq.weight model.blk.28.attn.wq.bias model.blk.28.attn.wk.weight model.blk.28.attn.wk.bias model.blk.28.attn.wv.weight model.blk.28.attn.wv.bias model.blk.28.attn.wo.weight model.blk.28.attn.wo.bias model.blk.28.ffn_up.weight model.blk.28.ffn_up.bias model.blk.28.ffn_down.weight model.blk.28.ffn_down.bias model.blk.28.ffn_norm.weight model.blk.28.ffn_norm.bias model.blk.29.attn.wq.weight model.blk.29.attn.wq.bias model.blk.29.attn.wk.weight model.blk.29.attn.wk.bias model.blk.29.attn.wv.weight model.blk.29.attn.wv.bias model.blk.29.attn.wo.weight model.blk.29.attn.wo.bias model.blk.29.ffn_up.weight model.blk.29.ffn_up.bias model.blk.29.ffn_down.weight model.blk.29.ffn_down.bias model.blk.29.ffn_norm.weight model.blk.29.ffn_norm.bias )
 15@{L30:L36}	 fuyou_5 nParam=96 nReload=84(model.blk.30.attn.wq.weight model.blk.30.attn.wq.bias model.blk.30.attn.wk.weight model.blk.30.attn.wk.bias model.blk.30.attn.wv.weight model.blk.30.attn.wv.bias model.blk.30.attn.wo.weight model.blk.30.attn.wo.bias model.blk.30.ffn_up.weight model.blk.30.ffn_up.bias model.blk.30.ffn_down.weight model.blk.30.ffn_down.bias model.blk.30.ffn_norm.weight model.blk.30.ffn_norm.bias model.blk.31.attn.wq.weight model.blk.31.attn.wq.bias model.blk.31.attn.wk.weight model.blk.31.attn.wk.bias model.blk.31.attn.wv.weight model.blk.31.attn.wv.bias model.blk.31.attn.wo.weight model.blk.31.attn.wo.bias model.blk.31.ffn_up.weight model.blk.31.ffn_up.bias model.blk.31.ffn_down.weight model.blk.31.ffn_down.bias model.blk.31.ffn_norm.weight model.blk.31.ffn_norm.bias model.blk.32.attn.wq.weight model.blk.32.attn.wq.bias model.blk.32.attn.wk.weight model.blk.32.attn.wk.bias model.blk.32.attn.wv.weight model.blk.32.attn.wv.bias model.blk.32.attn.wo.weight model.blk.32.attn.wo.bias model.blk.32.ffn_up.weight model.blk.32.ffn_up.bias model.blk.32.ffn_down.weight model.blk.32.ffn_down.bias model.blk.32.ffn_norm.weight model.blk.32.ffn_norm.bias model.blk.33.attn.wq.weight model.blk.33.attn.wq.bias model.blk.33.attn.wk.weight model.blk.33.attn.wk.bias model.blk.33.attn.wv.weight model.blk.33.attn.wv.bias model.blk.33.attn.wo.weight model.blk.33.attn.wo.bias model.blk.33.ffn_up.weight model.blk.33.ffn_up.bias model.blk.33.ffn_down.weight model.blk.33.ffn_down.bias model.blk.33.ffn_norm.weight model.blk.33.ffn_norm.bias model.blk.34.attn.wq.weight model.blk.34.attn.wq.bias model.blk.34.attn.wk.weight model.blk.34.attn.wk.bias model.blk.34.attn.wv.weight model.blk.34.attn.wv.bias model.blk.34.attn.wo.weight model.blk.34.attn.wo.bias model.blk.34.ffn_up.weight model.blk.34.ffn_up.bias model.blk.34.ffn_down.weight model.blk.34.ffn_down.bias model.blk.34.ffn_norm.weight model.blk.34.ffn_norm.bias model.blk.35.attn.wq.weight model.blk.35.attn.wq.bias model.blk.35.attn.wk.weight model.blk.35.attn.wk.bias model.blk.35.attn.wv.weight model.blk.35.attn.wv.bias model.blk.35.attn.wo.weight model.blk.35.attn.wo.bias model.blk.35.ffn_up.weight model.blk.35.ffn_up.bias model.blk.35.ffn_down.weight model.blk.35.ffn_down.bias model.blk.35.ffn_norm.weight model.blk.35.ffn_norm.bias )

[RLS_branch] 	Guoke=900(990) nSection=6 isRefParam=1	
[Scheduling] MEM_STRATEGY=PRE_ALLOC_GPU UpdateParam=V1
[RLS]	nGuoke=900(0) Memory of GPU=13044.7M(free=12217.4M)
[Fuyou] n=6 Explorer=[pso_ga] ensembler="BEST" nSwitch=100 "Only cur fuyou's params in GPU-memor!"

[Section@-1] layer[0-6] tasks=15(nPassBack=0) last_loss=3.40282e+38(0) N=(580,504,84 0)
[RLS] resident={model.inp_embd, model.blk.0.attn, model.blk.0.ffn, model.blk.1.attn, model.blk.1.ffn, model.blk.2.attn, model.blk.2.ffn, model.blk.3.attn, model.blk.3.ffn, model.blk.4.attn, model.blk.4.ffn, model.blk.5.attn, model.blk.5.ffn, model.output_norm, model.out.cls, }
[MEMORY] mGPU=13044.7M(free=12217.4M)
	 cudaMalloc=209.715M@model.inp_embd type=BF16(E8) shape=[80,1024,1280,1] sum=3.55261G
	 cudaMalloc=515.113M@model.inp_embd.weight type=BF16(E8) shape=[50304,1280,1,1]x2 sum=4.06772G
	 cudaMalloc=209.715M@model.blk.0.attn type=BF16(E8) shape=[80,1024,1280,1] sum=4.28792G
	 cudaMalloc=209.715M@model.blk.0.attn_norm.out type=BF16(E8) shape=[80,1024,1280,1] sum=4.49764G
	 cudaMalloc=209.715M@model.blk.0.attn.attn type=BF16(E8) shape=[80,1024,1280,1] sum=4.71391G
	 cudaMalloc=209.715M@model.blk.0.ffn type=BF16(E8) shape=[80,1024,1280,1] sum=4.97677G
	 cudaMalloc=209.715M@model.blk.0.ffn_norm.out type=BF16(E8) shape=[80,1024,1280,1] sum=5.18648G
	 cudaMalloc=209.715M@model.blk.1.attn type=BF16(E8) shape=[80,1024,1280,1] sum=5.50178G
	 cudaMalloc=209.715M@model.blk.1.attn_norm.out type=BF16(E8) shape=[80,1024,1280,1] sum=5.7115G
	 cudaMalloc=209.715M@model.blk.1.attn.attn type=BF16(E8) shape=[80,1024,1280,1] sum=5.92777G
	 cudaMalloc=209.715M@model.blk.1.ffn type=BF16(E8) shape=[80,1024,1280,1] sum=6.19063G
	 cudaMalloc=209.715M@model.blk.1.ffn_norm.out type=BF16(E8) shape=[80,1024,1280,1] sum=6.40034G
	 cudaMalloc=209.715M@model.blk.2.attn type=BF16(E8) shape=[80,1024,1280,1] sum=6.71564G
	 cudaMalloc=209.715M@model.blk.2.attn_norm.out type=BF16(E8) shape=[80,1024,1280,1] sum=6.92536G
	 cudaMalloc=209.715M@model.blk.2.attn.attn type=BF16(E8) shape=[80,1024,1280,1] sum=7.14163G
	 cudaMalloc=209.715M@model.blk.2.ffn type=BF16(E8) shape=[80,1024,1280,1] sum=7.40449G
	 cudaMalloc=209.715M@model.blk.2.ffn_norm.out type=BF16(E8) shape=[80,1024,1280,1] sum=7.6142G
	 cudaMalloc=209.715M@model.blk.3.attn type=BF16(E8) shape=[80,1024,1280,1] sum=7.9295G
	 cudaMalloc=209.715M@model.blk.3.attn_norm.out type=BF16(E8) shape=[80,1024,1280,1] sum=8.13922G
	 cudaMalloc=209.715M@model.blk.3.attn.attn type=BF16(E8) shape=[80,1024,1280,1] sum=8.35549G
	 cudaMalloc=209.715M@model.blk.3.ffn type=BF16(E8) shape=[80,1024,1280,1] sum=8.61835G
	 cudaMalloc=209.715M@model.blk.3.ffn_norm.out type=BF16(E8) shape=[80,1024,1280,1] sum=8.82806G
	 cudaMalloc=209.715M@model.blk.4.attn type=BF16(E8) shape=[80,1024,1280,1] sum=9.14336G
	 cudaMalloc=209.715M@model.blk.4.attn_norm.out type=BF16(E8) shape=[80,1024,1280,1] sum=9.35308G
	 cudaMalloc=209.715M@model.blk.4.attn.attn type=BF16(E8) shape=[80,1024,1280,1] sum=9.56935G
	 cudaMalloc=209.715M@model.blk.4.ffn type=BF16(E8) shape=[80,1024,1280,1] sum=9.83221G
	 cudaMalloc=209.715M@model.blk.4.ffn_norm.out type=BF16(E8) shape=[80,1024,1280,1] sum=10.0419G
	 cudaMalloc=209.715M@model.blk.5.attn type=BF16(E8) shape=[80,1024,1280,1] sum=10.3572G
	 cudaMalloc=209.715M@model.blk.5.attn_norm.out type=BF16(E8) shape=[80,1024,1280,1] sum=10.5669G
	 cudaMalloc=209.715M@model.blk.5.attn.attn type=BF16(E8) shape=[80,1024,1280,1] sum=10.7832G
	 cudaMalloc=209.715M@model.blk.5.ffn type=BF16(E8) shape=[80,1024,1280,1] sum=11.0461G
	 cudaMalloc=209.715M@model.blk.5.ffn_norm.out type=BF16(E8) shape=[80,1024,1280,1] sum=11.2558G
	 cudaMalloc=209.715M@model.output_norm type=BF16(E8) shape=[80,1024,1280,1] sum=12.7522G
	 cudaMalloc=824.181M@preLogits type=BF16(E8) shape=[8,1024,50304,1] sum=13.5774G
[TGraph::Prepare4Train] AdamTensor=(146,0.0223%) filter={"output" "norm" }

	[DictVAE]:resi=1 tpNorm=2 opOut="RND_GRAD" nLevel=0

	 {EMBED n=50257 +POS} SYM
{		 QKV E1280 H20 x=1 trans=0 }
		 model.blk.0.ffn {hidden=5120}  
{		 QKV E1280 H20 x=1 trans=0 }
		 model.blk.1.ffn {hidden=5120}  
{		 QKV E1280 H20 x=1 trans=0 }
		 model.blk.2.ffn {hidden=5120}  
{		 QKV E1280 H20 x=1 trans=0 }
		 model.blk.3.ffn {hidden=5120}  
{		 QKV E1280 H20 x=1 trans=0 }
		 model.blk.4.ffn {hidden=5120}  
{		 QKV E1280 H20 x=1 trans=0 }
		 model.blk.5.ffn {hidden=5120}  
{		 QKV E1280 H20 x=1 trans=0 }
		 model.blk.6.ffn {hidden=5120}  
{		 QKV E1280 H20 x=1 trans=0 }
		 model.blk.7.ffn {hidden=5120}  
{		 QKV E1280 H20 x=1 trans=0 }
		 model.blk.8.ffn {hidden=5120}  
{		 QKV E1280 H20 x=1 trans=0 }
		 model.blk.9.ffn {hidden=5120}  
{		 QKV E1280 H20 x=1 trans=0 }
		 model.blk.10.ffn {hidden=5120}  
{		 QKV E1280 H20 x=1 trans=0 }
		 model.blk.11.ffn {hidden=5120}  
{		 QKV E1280 H20 x=1 trans=0 }
		 model.blk.12.ffn {hidden=5120}  
{		 QKV E1280 H20 x=1 trans=0 }
		 model.blk.13.ffn {hidden=5120}  
{		 QKV E1280 H20 x=1 trans=0 }
		 model.blk.14.ffn {hidden=5120}  
{		 QKV E1280 H20 x=1 trans=0 }
		 model.blk.15.ffn {hidden=5120}  
{		 QKV E1280 H20 x=1 trans=0 }
		 model.blk.16.ffn {hidden=5120}  
{		 QKV E1280 H20 x=1 trans=0 }
		 model.blk.17.ffn {hidden=5120}  
{		 QKV E1280 H20 x=1 trans=0 }
		 model.blk.18.ffn {hidden=5120}  
{		 QKV E1280 H20 x=1 trans=0 }
		 model.blk.19.ffn {hidden=5120}  
{		 QKV E1280 H20 x=1 trans=0 }
		 model.blk.20.ffn {hidden=5120}  
{		 QKV E1280 H20 x=1 trans=0 }
		 model.blk.21.ffn {hidden=5120}  
{		 QKV E1280 H20 x=1 trans=0 }
		 model.blk.22.ffn {hidden=5120}  
{		 QKV E1280 H20 x=1 trans=0 }
		 model.blk.23.ffn {hidden=5120}  
{		 QKV E1280 H20 x=1 trans=0 }
		 model.blk.24.ffn {hidden=5120}  
{		 QKV E1280 H20 x=1 trans=0 }
		 model.blk.25.ffn {hidden=5120}  
{		 QKV E1280 H20 x=1 trans=0 }
		 model.blk.26.ffn {hidden=5120}  
{		 QKV E1280 H20 x=1 trans=0 }
		 model.blk.27.ffn {hidden=5120}  
{		 QKV E1280 H20 x=1 trans=0 }
		 model.blk.28.ffn {hidden=5120}  
{		 QKV E1280 H20 x=1 trans=0 }
		 model.blk.29.ffn {hidden=5120}  
{		 QKV E1280 H20 x=1 trans=0 }
		 model.blk.30.ffn {hidden=5120}  
{		 QKV E1280 H20 x=1 trans=0 }
		 model.blk.31.ffn {hidden=5120}  
{		 QKV E1280 H20 x=1 trans=0 }
		 model.blk.32.ffn {hidden=5120}  
{		 QKV E1280 H20 x=1 trans=0 }
		 model.blk.33.ffn {hidden=5120}  
{		 QKV E1280 H20 x=1 trans=0 }
		 model.blk.34.ffn {hidden=5120}  
{		 QKV E1280 H20 x=1 trans=0 }
		 model.blk.35.ffn {hidden=5120}  
	 LayerNormal(+b+mean+rstd) out=model.output_norm
	 OutCLS{dB=8 x=50304} Tyring
  target(ID)=I32 'target' 0.0819M	[ 80  1024  1  1 I32] 
  loss=float 'model.out.cls' 0.0819M	[ 80  1024  1  1 float] 
	LAY=38	
========
 GPT2:    Bias=(normal=1,slp=1) AttOnBC=0
========
koifish::CLI_params: 
 n_ctx=1024 embd=1280 n_ff=5120 n_head=20 n_head_kv=20 n_layer=36(-1) f_norm_rms_eps=1e-05
 ROPE: type=0 freq_base=10000 freq_scale=1 n_rot=64
 SepQKV: type=1  
====== nParams = 774090240(774.09M nT=580) ======
Dump: nParams=774090240 model_size = 0 bytes (0.0 MB)
Dump: n_vocab=50257 t_vocab=50257,n_batch=80,n_ctx=1024,n_embd=1280,n_head=20,n_rot=64,n_ff=5120
Dump: loader=
	 model.inp_embd.weight                P    szAlloc=515.113M	[ 50304  1280  1  1 BF16(E8)] 
	 position_embd.weight                 P    szAlloc=10.4858M	[ 1280  1024  1  1 BF16(E8)] 
	 model.blk.0.attn_norm.bias           P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.0.attn_norm.weight         P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.0.attn.wq.weight           P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.0.attn.wq.bias             P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.0.attn.wk.weight           P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.0.attn.wk.bias             P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.0.attn.wv.weight           P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.0.attn.wv.bias             P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.0.attn.wo.weight           P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.0.attn.wo.bias             P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.0.ffn_norm.weight          P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.0.ffn_norm.bias            P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.0.ffn_down.weight          P    szAlloc=52.4288M	[ 5120  1280  1  1 BF16(E8)] 
	 model.blk.0.ffn_down.bias            P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.0.ffn_up.weight            P    szAlloc=52.4288M	[ 1280  5120  1  1 BF16(E8)] 
	 model.blk.0.ffn_up.bias              P    szAlloc=0.04096M	[ 5120  1  1  1 BF16(E8)] 
	 model.blk.1.attn_norm.weight         P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.1.attn_norm.bias           P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.1.attn.wq.weight           P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.1.attn.wq.bias             P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.1.attn.wk.weight           P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.1.attn.wk.bias             P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.1.attn.wv.weight           P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.1.attn.wv.bias             P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.1.attn.wo.weight           P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.1.attn.wo.bias             P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.1.ffn_norm.weight          P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.1.ffn_norm.bias            P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.1.ffn_down.weight          P    szAlloc=52.4288M	[ 5120  1280  1  1 BF16(E8)] 
	 model.blk.1.ffn_down.bias            P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.1.ffn_up.weight            P    szAlloc=52.4288M	[ 1280  5120  1  1 BF16(E8)] 
	 model.blk.1.ffn_up.bias              P    szAlloc=0.04096M	[ 5120  1  1  1 BF16(E8)] 
	 model.blk.2.attn_norm.weight         P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.2.attn_norm.bias           P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.2.attn.wq.weight           P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.2.attn.wq.bias             P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.2.attn.wk.weight           P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.2.attn.wk.bias             P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.2.attn.wv.weight           P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.2.attn.wv.bias             P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.2.attn.wo.weight           P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.2.attn.wo.bias             P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.2.ffn_norm.weight          P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.2.ffn_norm.bias            P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.2.ffn_down.weight          P    szAlloc=52.4288M	[ 5120  1280  1  1 BF16(E8)] 
	 model.blk.2.ffn_down.bias            P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.2.ffn_up.weight            P    szAlloc=52.4288M	[ 1280  5120  1  1 BF16(E8)] 
	 model.blk.2.ffn_up.bias              P    szAlloc=0.04096M	[ 5120  1  1  1 BF16(E8)] 
	 model.blk.3.attn_norm.weight         P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.3.attn_norm.bias           P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.3.attn.wq.weight           P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.3.attn.wq.bias             P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.3.attn.wk.weight           P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.3.attn.wk.bias             P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.3.attn.wv.weight           P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.3.attn.wv.bias             P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.3.attn.wo.weight           P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.3.attn.wo.bias             P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.3.ffn_norm.weight          P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.3.ffn_norm.bias            P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.3.ffn_down.weight          P    szAlloc=52.4288M	[ 5120  1280  1  1 BF16(E8)] 
	 model.blk.3.ffn_down.bias            P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.3.ffn_up.weight            P    szAlloc=52.4288M	[ 1280  5120  1  1 BF16(E8)] 
	 model.blk.3.ffn_up.bias              P    szAlloc=0.04096M	[ 5120  1  1  1 BF16(E8)] 
	 model.blk.4.attn_norm.weight         P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.4.attn_norm.bias           P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.4.attn.wq.weight           P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.4.attn.wq.bias             P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.4.attn.wk.weight           P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.4.attn.wk.bias             P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.4.attn.wv.weight           P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.4.attn.wv.bias             P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.4.attn.wo.weight           P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.4.attn.wo.bias             P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.4.ffn_norm.weight          P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.4.ffn_norm.bias            P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.4.ffn_down.weight          P    szAlloc=52.4288M	[ 5120  1280  1  1 BF16(E8)] 
	 model.blk.4.ffn_down.bias            P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.4.ffn_up.weight            P    szAlloc=52.4288M	[ 1280  5120  1  1 BF16(E8)] 
	 model.blk.4.ffn_up.bias              P    szAlloc=0.04096M	[ 5120  1  1  1 BF16(E8)] 
	 model.blk.5.attn_norm.weight         P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.5.attn_norm.bias           P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.5.attn.wq.weight           P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.5.attn.wq.bias             P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.5.attn.wk.weight           P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.5.attn.wk.bias             P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.5.attn.wv.weight           P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.5.attn.wv.bias             P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.5.attn.wo.weight           P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.5.attn.wo.bias             P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.5.ffn_norm.weight          P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.5.ffn_norm.bias            P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.5.ffn_down.weight          P    szAlloc=52.4288M	[ 5120  1280  1  1 BF16(E8)] 
	 model.blk.5.ffn_down.bias            P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.5.ffn_up.weight            P    szAlloc=52.4288M	[ 1280  5120  1  1 BF16(E8)] 
	 model.blk.5.ffn_up.bias              P    szAlloc=0.04096M	[ 5120  1  1  1 BF16(E8)] 
	 model.blk.6.attn_norm.weight         P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.6.attn_norm.bias           P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.6.attn.wq.weight           P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.6.attn.wq.bias             P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.6.attn.wk.weight           P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.6.attn.wk.bias             P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.6.attn.wv.weight           P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.6.attn.wv.bias             P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.6.attn.wo.weight           P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.6.attn.wo.bias             P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.6.ffn_norm.weight          P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.6.ffn_norm.bias            P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.6.ffn_down.weight          P    szAlloc=52.4288M	[ 5120  1280  1  1 BF16(E8)] 
	 model.blk.6.ffn_down.bias            P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.6.ffn_up.weight            P    szAlloc=52.4288M	[ 1280  5120  1  1 BF16(E8)] 
	 model.blk.6.ffn_up.bias              P    szAlloc=0.04096M	[ 5120  1  1  1 BF16(E8)] 
	 model.blk.7.attn_norm.weight         P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.7.attn_norm.bias           P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.7.attn.wq.weight           P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.7.attn.wq.bias             P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.7.attn.wk.weight           P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.7.attn.wk.bias             P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.7.attn.wv.weight           P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.7.attn.wv.bias             P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.7.attn.wo.weight           P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.7.attn.wo.bias             P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.7.ffn_norm.weight          P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.7.ffn_norm.bias            P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.7.ffn_down.weight          P    szAlloc=52.4288M	[ 5120  1280  1  1 BF16(E8)] 
	 model.blk.7.ffn_down.bias            P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.7.ffn_up.weight            P    szAlloc=52.4288M	[ 1280  5120  1  1 BF16(E8)] 
	 model.blk.7.ffn_up.bias              P    szAlloc=0.04096M	[ 5120  1  1  1 BF16(E8)] 
	 model.blk.16.attn_norm.weight        P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.16.attn_norm.bias          P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.8.attn_norm.weight         P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.8.attn_norm.bias           P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.8.attn.wq.weight           P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.8.attn.wq.bias             P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.8.attn.wk.weight           P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.8.attn.wk.bias             P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.8.attn.wv.weight           P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.8.attn.wv.bias             P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.8.attn.wo.weight           P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.8.attn.wo.bias             P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.8.ffn_norm.weight          P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.8.ffn_norm.bias            P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.8.ffn_down.weight          P    szAlloc=52.4288M	[ 5120  1280  1  1 BF16(E8)] 
	 model.blk.8.ffn_down.bias            P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.8.ffn_up.weight            P    szAlloc=52.4288M	[ 1280  5120  1  1 BF16(E8)] 
	 model.blk.8.ffn_up.bias              P    szAlloc=0.04096M	[ 5120  1  1  1 BF16(E8)] 
	 model.blk.9.attn_norm.weight         P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.9.attn_norm.bias           P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.9.attn.wq.weight           P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.9.attn.wq.bias             P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.9.attn.wk.weight           P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.9.attn.wk.bias             P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.9.attn.wv.weight           P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.9.attn.wv.bias             P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.9.attn.wo.weight           P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.9.attn.wo.bias             P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.9.ffn_norm.weight          P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.9.ffn_norm.bias            P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.9.ffn_down.weight          P    szAlloc=52.4288M	[ 5120  1280  1  1 BF16(E8)] 
	 model.blk.9.ffn_down.bias            P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.9.ffn_up.weight            P    szAlloc=52.4288M	[ 1280  5120  1  1 BF16(E8)] 
	 model.blk.9.ffn_up.bias              P    szAlloc=0.04096M	[ 5120  1  1  1 BF16(E8)] 
	 model.blk.10.attn_norm.weight        P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.10.attn_norm.bias          P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.10.attn.wq.weight          P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.10.attn.wq.bias            P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.10.attn.wk.weight          P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.10.attn.wk.bias            P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.10.attn.wv.weight          P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.10.attn.wv.bias            P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.10.attn.wo.weight          P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.10.attn.wo.bias            P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.10.ffn_norm.weight         P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.10.ffn_norm.bias           P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.10.ffn_down.weight         P    szAlloc=52.4288M	[ 5120  1280  1  1 BF16(E8)] 
	 model.blk.10.ffn_down.bias           P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.10.ffn_up.weight           P    szAlloc=52.4288M	[ 1280  5120  1  1 BF16(E8)] 
	 model.blk.10.ffn_up.bias             P    szAlloc=0.04096M	[ 5120  1  1  1 BF16(E8)] 
	 model.blk.11.attn_norm.weight        P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.11.attn_norm.bias          P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.11.attn.wq.weight          P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.11.attn.wq.bias            P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.11.attn.wk.weight          P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.11.attn.wk.bias            P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.11.attn.wv.weight          P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.11.attn.wv.bias            P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.11.attn.wo.weight          P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.11.attn.wo.bias            P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.11.ffn_norm.weight         P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.11.ffn_norm.bias           P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.11.ffn_down.weight         P    szAlloc=52.4288M	[ 5120  1280  1  1 BF16(E8)] 
	 model.blk.11.ffn_down.bias           P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.11.ffn_up.weight           P    szAlloc=52.4288M	[ 1280  5120  1  1 BF16(E8)] 
	 model.blk.11.ffn_up.bias             P    szAlloc=0.04096M	[ 5120  1  1  1 BF16(E8)] 
	 model.blk.12.attn_norm.weight        P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.12.attn_norm.bias          P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.12.attn.wq.weight          P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.12.attn.wq.bias            P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.12.attn.wk.weight          P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.12.attn.wk.bias            P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.12.attn.wv.weight          P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.12.attn.wv.bias            P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.12.attn.wo.weight          P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.12.attn.wo.bias            P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.12.ffn_norm.weight         P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.12.ffn_norm.bias           P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.12.ffn_down.weight         P    szAlloc=52.4288M	[ 5120  1280  1  1 BF16(E8)] 
	 model.blk.12.ffn_down.bias           P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.12.ffn_up.weight           P    szAlloc=52.4288M	[ 1280  5120  1  1 BF16(E8)] 
	 model.blk.12.ffn_up.bias             P    szAlloc=0.04096M	[ 5120  1  1  1 BF16(E8)] 
	 model.blk.13.attn_norm.weight        P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.13.attn_norm.bias          P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.13.attn.wq.weight          P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.13.attn.wq.bias            P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.13.attn.wk.weight          P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.13.attn.wk.bias            P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.13.attn.wv.weight          P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.13.attn.wv.bias            P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.13.attn.wo.weight          P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.13.attn.wo.bias            P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.13.ffn_norm.weight         P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.13.ffn_norm.bias           P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.13.ffn_down.weight         P    szAlloc=52.4288M	[ 5120  1280  1  1 BF16(E8)] 
	 model.blk.13.ffn_down.bias           P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.13.ffn_up.weight           P    szAlloc=52.4288M	[ 1280  5120  1  1 BF16(E8)] 
	 model.blk.13.ffn_up.bias             P    szAlloc=0.04096M	[ 5120  1  1  1 BF16(E8)] 
	 model.blk.14.attn_norm.weight        P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.14.attn_norm.bias          P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.14.attn.wq.weight          P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.14.attn.wq.bias            P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.14.attn.wk.weight          P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.14.attn.wk.bias            P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.14.attn.wv.weight          P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.14.attn.wv.bias            P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.14.attn.wo.weight          P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.14.attn.wo.bias            P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.14.ffn_norm.weight         P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.14.ffn_norm.bias           P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.14.ffn_down.weight         P    szAlloc=52.4288M	[ 5120  1280  1  1 BF16(E8)] 
	 model.blk.14.ffn_down.bias           P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.14.ffn_up.weight           P    szAlloc=52.4288M	[ 1280  5120  1  1 BF16(E8)] 
	 model.blk.14.ffn_up.bias             P    szAlloc=0.04096M	[ 5120  1  1  1 BF16(E8)] 
	 model.blk.15.attn_norm.weight        P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.15.attn_norm.bias          P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.15.attn.wq.weight          P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.15.attn.wq.bias            P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.15.attn.wk.weight          P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.15.attn.wk.bias            P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.15.attn.wv.weight          P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.15.attn.wv.bias            P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.15.attn.wo.weight          P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.15.attn.wo.bias            P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.15.ffn_norm.weight         P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.15.ffn_norm.bias           P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.15.ffn_down.weight         P    szAlloc=52.4288M	[ 5120  1280  1  1 BF16(E8)] 
	 model.blk.15.ffn_down.bias           P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.15.ffn_up.weight           P    szAlloc=52.4288M	[ 1280  5120  1  1 BF16(E8)] 
	 model.blk.15.ffn_up.bias             P    szAlloc=0.04096M	[ 5120  1  1  1 BF16(E8)] 
	 model.blk.32.attn_norm.weight        P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.16.attn.wq.weight          P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.16.attn.wq.bias            P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.16.attn.wk.weight          P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.16.attn.wk.bias            P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.16.attn.wv.weight          P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.16.attn.wv.bias            P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.16.attn.wo.weight          P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.16.attn.wo.bias            P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.16.ffn_norm.weight         P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.16.ffn_norm.bias           P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.16.ffn_down.weight         P    szAlloc=52.4288M	[ 5120  1280  1  1 BF16(E8)] 
	 model.blk.16.ffn_down.bias           P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.16.ffn_up.weight           P    szAlloc=52.4288M	[ 1280  5120  1  1 BF16(E8)] 
	 model.blk.16.ffn_up.bias             P    szAlloc=0.04096M	[ 5120  1  1  1 BF16(E8)] 
	 model.blk.17.attn_norm.weight        P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.17.attn_norm.bias          P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.17.attn.wq.weight          P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.17.attn.wq.bias            P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.17.attn.wk.weight          P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.17.attn.wk.bias            P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.17.attn.wv.weight          P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.17.attn.wv.bias            P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.17.attn.wo.weight          P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.17.attn.wo.bias            P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.17.ffn_norm.weight         P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.17.ffn_norm.bias           P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.17.ffn_down.weight         P    szAlloc=52.4288M	[ 5120  1280  1  1 BF16(E8)] 
	 model.blk.17.ffn_down.bias           P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.17.ffn_up.weight           P    szAlloc=52.4288M	[ 1280  5120  1  1 BF16(E8)] 
	 model.blk.17.ffn_up.bias             P    szAlloc=0.04096M	[ 5120  1  1  1 BF16(E8)] 
	 model.blk.18.attn_norm.weight        P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.18.attn_norm.bias          P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.18.attn.wq.weight          P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.18.attn.wq.bias            P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.18.attn.wk.weight          P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.18.attn.wk.bias            P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.18.attn.wv.weight          P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.18.attn.wv.bias            P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.18.attn.wo.weight          P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.18.attn.wo.bias            P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.18.ffn_norm.weight         P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.18.ffn_norm.bias           P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.18.ffn_down.weight         P    szAlloc=52.4288M	[ 5120  1280  1  1 BF16(E8)] 
	 model.blk.18.ffn_down.bias           P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.18.ffn_up.weight           P    szAlloc=52.4288M	[ 1280  5120  1  1 BF16(E8)] 
	 model.blk.18.ffn_up.bias             P    szAlloc=0.04096M	[ 5120  1  1  1 BF16(E8)] 
	 model.blk.19.attn_norm.weight        P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.19.attn_norm.bias          P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.19.attn.wq.weight          P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.19.attn.wq.bias            P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.19.attn.wk.weight          P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.19.attn.wk.bias            P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.19.attn.wv.weight          P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.19.attn.wv.bias            P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.19.attn.wo.weight          P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.19.attn.wo.bias            P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.19.ffn_norm.weight         P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.19.ffn_norm.bias           P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.19.ffn_down.weight         P    szAlloc=52.4288M	[ 5120  1280  1  1 BF16(E8)] 
	 model.blk.19.ffn_down.bias           P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.19.ffn_up.weight           P    szAlloc=52.4288M	[ 1280  5120  1  1 BF16(E8)] 
	 model.blk.19.ffn_up.bias             P    szAlloc=0.04096M	[ 5120  1  1  1 BF16(E8)] 
	 model.blk.20.attn_norm.weight        P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.20.attn_norm.bias          P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.20.attn.wq.weight          P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.20.attn.wq.bias            P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.20.attn.wk.weight          P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.20.attn.wk.bias            P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.20.attn.wv.weight          P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.20.attn.wv.bias            P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.20.attn.wo.weight          P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.20.attn.wo.bias            P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.20.ffn_norm.weight         P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.20.ffn_norm.bias           P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.20.ffn_down.weight         P    szAlloc=52.4288M	[ 5120  1280  1  1 BF16(E8)] 
	 model.blk.20.ffn_down.bias           P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.20.ffn_up.weight           P    szAlloc=52.4288M	[ 1280  5120  1  1 BF16(E8)] 
	 model.blk.20.ffn_up.bias             P    szAlloc=0.04096M	[ 5120  1  1  1 BF16(E8)] 
	 model.blk.21.attn_norm.weight        P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.21.attn_norm.bias          P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.21.attn.wq.weight          P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.21.attn.wq.bias            P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.21.attn.wk.weight          P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.21.attn.wk.bias            P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.21.attn.wv.weight          P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.21.attn.wv.bias            P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.21.attn.wo.weight          P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.21.attn.wo.bias            P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.21.ffn_norm.weight         P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.21.ffn_norm.bias           P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.21.ffn_down.weight         P    szAlloc=52.4288M	[ 5120  1280  1  1 BF16(E8)] 
	 model.blk.21.ffn_down.bias           P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.21.ffn_up.weight           P    szAlloc=52.4288M	[ 1280  5120  1  1 BF16(E8)] 
	 model.blk.21.ffn_up.bias             P    szAlloc=0.04096M	[ 5120  1  1  1 BF16(E8)] 
	 model.blk.22.attn_norm.weight        P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.22.attn_norm.bias          P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.22.attn.wq.weight          P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.22.attn.wq.bias            P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.22.attn.wk.weight          P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.22.attn.wk.bias            P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.22.attn.wv.weight          P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.22.attn.wv.bias            P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.22.attn.wo.weight          P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.22.attn.wo.bias            P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.22.ffn_norm.weight         P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.22.ffn_norm.bias           P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.22.ffn_down.weight         P    szAlloc=52.4288M	[ 5120  1280  1  1 BF16(E8)] 
	 model.blk.22.ffn_down.bias           P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.22.ffn_up.weight           P    szAlloc=52.4288M	[ 1280  5120  1  1 BF16(E8)] 
	 model.blk.22.ffn_up.bias             P    szAlloc=0.04096M	[ 5120  1  1  1 BF16(E8)] 
	 model.blk.23.attn_norm.weight        P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.23.attn_norm.bias          P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.23.attn.wq.weight          P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.23.attn.wq.bias            P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.23.attn.wk.weight          P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.23.attn.wk.bias            P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.23.attn.wv.weight          P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.23.attn.wv.bias            P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.23.attn.wo.weight          P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.23.attn.wo.bias            P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.23.ffn_norm.weight         P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.23.ffn_norm.bias           P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.23.ffn_down.weight         P    szAlloc=52.4288M	[ 5120  1280  1  1 BF16(E8)] 
	 model.blk.23.ffn_down.bias           P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.23.ffn_up.weight           P    szAlloc=52.4288M	[ 1280  5120  1  1 BF16(E8)] 
	 model.blk.23.ffn_up.bias             P    szAlloc=0.04096M	[ 5120  1  1  1 BF16(E8)] 
	 model.blk.24.attn_norm.weight        P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.24.attn_norm.bias          P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.24.attn.wq.weight          P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.24.attn.wq.bias            P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.24.attn.wk.weight          P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.24.attn.wk.bias            P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.24.attn.wv.weight          P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.24.attn.wv.bias            P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.24.attn.wo.weight          P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.24.attn.wo.bias            P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.24.ffn_norm.weight         P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.24.ffn_norm.bias           P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.24.ffn_down.weight         P    szAlloc=52.4288M	[ 5120  1280  1  1 BF16(E8)] 
	 model.blk.24.ffn_down.bias           P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.24.ffn_up.weight           P    szAlloc=52.4288M	[ 1280  5120  1  1 BF16(E8)] 
	 model.blk.24.ffn_up.bias             P    szAlloc=0.04096M	[ 5120  1  1  1 BF16(E8)] 
	 model.blk.25.attn_norm.weight        P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.25.attn_norm.bias          P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.25.attn.wq.weight          P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.25.attn.wq.bias            P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.25.attn.wk.weight          P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.25.attn.wk.bias            P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.25.attn.wv.weight          P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.25.attn.wv.bias            P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.25.attn.wo.weight          P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.25.attn.wo.bias            P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.25.ffn_norm.weight         P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.25.ffn_norm.bias           P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.25.ffn_down.weight         P    szAlloc=52.4288M	[ 5120  1280  1  1 BF16(E8)] 
	 model.blk.25.ffn_down.bias           P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.25.ffn_up.weight           P    szAlloc=52.4288M	[ 1280  5120  1  1 BF16(E8)] 
	 model.blk.25.ffn_up.bias             P    szAlloc=0.04096M	[ 5120  1  1  1 BF16(E8)] 
	 model.blk.26.attn_norm.weight        P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.26.attn_norm.bias          P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.26.attn.wq.weight          P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.26.attn.wq.bias            P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.26.attn.wk.weight          P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.26.attn.wk.bias            P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.26.attn.wv.weight          P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.26.attn.wv.bias            P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.26.attn.wo.weight          P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.26.attn.wo.bias            P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.26.ffn_norm.weight         P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.26.ffn_norm.bias           P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.26.ffn_down.weight         P    szAlloc=52.4288M	[ 5120  1280  1  1 BF16(E8)] 
	 model.blk.26.ffn_down.bias           P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.26.ffn_up.weight           P    szAlloc=52.4288M	[ 1280  5120  1  1 BF16(E8)] 
	 model.blk.26.ffn_up.bias             P    szAlloc=0.04096M	[ 5120  1  1  1 BF16(E8)] 
	 model.blk.27.attn_norm.weight        P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.27.attn_norm.bias          P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.27.attn.wq.weight          P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.27.attn.wq.bias            P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.27.attn.wk.weight          P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.27.attn.wk.bias            P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.27.attn.wv.weight          P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.27.attn.wv.bias            P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.27.attn.wo.weight          P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.27.attn.wo.bias            P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.27.ffn_norm.weight         P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.27.ffn_norm.bias           P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.27.ffn_down.weight         P    szAlloc=52.4288M	[ 5120  1280  1  1 BF16(E8)] 
	 model.blk.27.ffn_down.bias           P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.27.ffn_up.weight           P    szAlloc=52.4288M	[ 1280  5120  1  1 BF16(E8)] 
	 model.blk.27.ffn_up.bias             P    szAlloc=0.04096M	[ 5120  1  1  1 BF16(E8)] 
	 model.blk.28.attn_norm.weight        P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.28.attn_norm.bias          P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.28.attn.wq.weight          P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.28.attn.wq.bias            P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.28.attn.wk.weight          P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.28.attn.wk.bias            P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.28.attn.wv.weight          P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.28.attn.wv.bias            P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.28.attn.wo.weight          P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.28.attn.wo.bias            P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.28.ffn_norm.weight         P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.28.ffn_norm.bias           P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.28.ffn_down.weight         P    szAlloc=52.4288M	[ 5120  1280  1  1 BF16(E8)] 
	 model.blk.28.ffn_down.bias           P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.28.ffn_up.weight           P    szAlloc=52.4288M	[ 1280  5120  1  1 BF16(E8)] 
	 model.blk.28.ffn_up.bias             P    szAlloc=0.04096M	[ 5120  1  1  1 BF16(E8)] 
	 model.blk.29.attn_norm.weight        P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.29.attn_norm.bias          P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.29.attn.wq.weight          P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.29.attn.wq.bias            P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.29.attn.wk.weight          P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.29.attn.wk.bias            P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.29.attn.wv.weight          P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.29.attn.wv.bias            P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.29.attn.wo.weight          P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.29.attn.wo.bias            P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.29.ffn_norm.weight         P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.29.ffn_norm.bias           P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.29.ffn_down.weight         P    szAlloc=52.4288M	[ 5120  1280  1  1 BF16(E8)] 
	 model.blk.29.ffn_down.bias           P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.29.ffn_up.weight           P    szAlloc=52.4288M	[ 1280  5120  1  1 BF16(E8)] 
	 model.blk.29.ffn_up.bias             P    szAlloc=0.04096M	[ 5120  1  1  1 BF16(E8)] 
	 model.blk.30.attn_norm.weight        P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.30.attn_norm.bias          P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.30.attn.wq.weight          P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.30.attn.wq.bias            P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.30.attn.wk.weight          P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.30.attn.wk.bias            P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.30.attn.wv.weight          P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.30.attn.wv.bias            P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.30.attn.wo.weight          P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.30.attn.wo.bias            P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.30.ffn_norm.weight         P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.30.ffn_norm.bias           P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.30.ffn_down.weight         P    szAlloc=52.4288M	[ 5120  1280  1  1 BF16(E8)] 
	 model.blk.30.ffn_down.bias           P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.30.ffn_up.weight           P    szAlloc=52.4288M	[ 1280  5120  1  1 BF16(E8)] 
	 model.blk.30.ffn_up.bias             P    szAlloc=0.04096M	[ 5120  1  1  1 BF16(E8)] 
	 model.blk.31.attn_norm.weight        P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.31.attn_norm.bias          P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.31.attn.wq.weight          P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.31.attn.wq.bias            P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.31.attn.wk.weight          P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.31.attn.wk.bias            P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.31.attn.wv.weight          P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.31.attn.wv.bias            P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.31.attn.wo.weight          P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.31.attn.wo.bias            P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.31.ffn_norm.weight         P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.31.ffn_norm.bias           P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.31.ffn_down.weight         P    szAlloc=52.4288M	[ 5120  1280  1  1 BF16(E8)] 
	 model.blk.31.ffn_down.bias           P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.31.ffn_up.weight           P    szAlloc=52.4288M	[ 1280  5120  1  1 BF16(E8)] 
	 model.blk.31.ffn_up.bias             P    szAlloc=0.04096M	[ 5120  1  1  1 BF16(E8)] 
	 model.blk.32.attn_norm.bias          P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.32.attn.wq.weight          P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.32.attn.wq.bias            P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.32.attn.wk.weight          P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.32.attn.wk.bias            P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.32.attn.wv.weight          P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.32.attn.wv.bias            P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.32.attn.wo.weight          P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.32.attn.wo.bias            P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.32.ffn_norm.weight         P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.32.ffn_norm.bias           P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.32.ffn_down.weight         P    szAlloc=52.4288M	[ 5120  1280  1  1 BF16(E8)] 
	 model.blk.32.ffn_down.bias           P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.32.ffn_up.weight           P    szAlloc=52.4288M	[ 1280  5120  1  1 BF16(E8)] 
	 model.blk.32.ffn_up.bias             P    szAlloc=0.04096M	[ 5120  1  1  1 BF16(E8)] 
	 model.blk.33.attn_norm.weight        P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.33.attn_norm.bias          P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.33.attn.wq.weight          P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.33.attn.wq.bias            P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.33.attn.wk.weight          P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.33.attn.wk.bias            P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.33.attn.wv.weight          P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.33.attn.wv.bias            P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.33.attn.wo.weight          P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.33.attn.wo.bias            P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.33.ffn_norm.weight         P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.33.ffn_norm.bias           P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.33.ffn_down.weight         P    szAlloc=52.4288M	[ 5120  1280  1  1 BF16(E8)] 
	 model.blk.33.ffn_down.bias           P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.33.ffn_up.weight           P    szAlloc=52.4288M	[ 1280  5120  1  1 BF16(E8)] 
	 model.blk.33.ffn_up.bias             P    szAlloc=0.04096M	[ 5120  1  1  1 BF16(E8)] 
	 model.blk.34.attn_norm.weight        P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.34.attn_norm.bias          P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.34.attn.wq.weight          P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.34.attn.wq.bias            P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.34.attn.wk.weight          P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.34.attn.wk.bias            P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.34.attn.wv.weight          P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.34.attn.wv.bias            P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.34.attn.wo.weight          P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.34.attn.wo.bias            P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.34.ffn_norm.weight         P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.34.ffn_norm.bias           P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.34.ffn_down.weight         P    szAlloc=52.4288M	[ 5120  1280  1  1 BF16(E8)] 
	 model.blk.34.ffn_down.bias           P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.34.ffn_up.weight           P    szAlloc=52.4288M	[ 1280  5120  1  1 BF16(E8)] 
	 model.blk.34.ffn_up.bias             P    szAlloc=0.04096M	[ 5120  1  1  1 BF16(E8)] 
	 model.blk.35.attn_norm.weight        P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.35.attn_norm.bias          P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.35.attn.wq.weight          P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.35.attn.wq.bias            P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.35.attn.wk.weight          P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.35.attn.wk.bias            P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.35.attn.wv.weight          P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.35.attn.wv.bias            P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.35.attn.wo.weight          P    szAlloc=13.1072M	[ 1280  1280  1  1 BF16(E8)] 
	 model.blk.35.attn.wo.bias            P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.35.ffn_norm.weight         P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.35.ffn_norm.bias           P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.35.ffn_down.weight         P    szAlloc=52.4288M	[ 5120  1280  1  1 BF16(E8)] 
	 model.blk.35.ffn_down.bias           P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.blk.35.ffn_up.weight           P    szAlloc=52.4288M	[ 1280  5120  1  1 BF16(E8)] 
	 model.blk.35.ffn_up.bias             P    szAlloc=0.04096M	[ 5120  1  1  1 BF16(E8)] 
	 model.output_norm.weight             P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 
	 model.output_norm.bias               P    szAlloc=0.01024M	[ 1280  1  1  1 BF16(E8)] 

[NO_QUANT] bit_per_parameter=16 szGama=2 TILEQ=(8,8) pQuant=W_SCALE tensor=0(0%) 
[MEMORY] Current usage statistics:  555 mem-blocks sum=12.4G(4.72G) 
	activation=7583.9M weight=1548.2M grad=1548.2M moments=3096.4M temp=3342.2M other=0M
======== nEopch=1 most_iter=61035
[Scheduling] MEM_STRATEGY=PRE_ALLOC_GPU UpdateParam=V1
[RLS]	nGuoke=900(0) Memory of GPU=13044.7M(free=12217.4M)
[Fuyou] n=6 Explorer=[pso_ga] ensembler="BEST" nSwitch=100 "Only cur fuyou's params in GPU-memor!"

	Type weight=BF16(E8) activation=BF16(E8)OPT: iter = 0
[Dataset]_"Train" nShard=50(T=5000M) samping=1(1220) EachShard(nSamp=97656,nBatch=1220)
[Dataset]_"Eval" nShard=1(T=100M) samping=0.04(48) EachShard(nSamp=97656,nBatch=1220)
	LR policy=Cosine warmup=600@61035
	nParams = 774090240(774.09M, nT=580 nG0=0)
	ADAM lr=0.001,beta=[0.9,0.95] decay=0.1(dim>=2) clip=0.0277778(alg=1)
[OPT_Adam]	sRESI=1 s_rounding=0 alloc_w=0 remater[ffn=1 ]
	Search@<J_model.Backward>  device=[] 
	 Accumulation=1 AdaptiveSched=0 GRAP=0x7fffb0130070 rZMUV=0 rLARS=0 
	DECENT=0(ADAMw) SIGN=0 tpFuseCu=1 filter=5

[DEBUG]: gemm=-1 classifier=1
[MEMORY] mGPU=13044.7M(free=12217.4M)
[epoch_0]_1      loss=11.011145 |g|=6.36	lr=3.33e-06 | 0.1%@S1  T=1.96s eta=1d 09:12:56 | 41.8K token/s | 
[MEMORY] mGPU=16414.8M(free=8847.29M)
[epoch_0]_11     loss=9.504320 |g|=2.41	lr=2.00e-05 | 0.9%@S1  T=922.1ms eta=15:37:49 | 44.2K token/s | 
[epoch_0]_21     loss=8.901451 |g|=1.62	lr=3.67e-05 | 1.7%@S1  T=926.9ms eta=15:42:35 | 46.4K token/s | 
[epoch_0]_31     loss=8.405726 |g|=1.24	lr=5.33e-05 | 2.5%@S1  T=928.6ms eta=15:44:05 | 48.5K token/s | 
[epoch_0]_41     loss=7.873939 |g|=1.36	lr=7.00e-05 | 3.4%@S1  T=937.8ms eta=15:53:18 | 50.4K token/s | 
[epoch_0]_51     loss=7.547352 |g|=0.743	lr=8.67e-05 | 4.2%@S1  T=939.7ms eta=15:55:06 | 52.3K token/s | 
[epoch_0]_61     loss=7.258046 |g|=0.675	lr=1.03e-04 | 5.0%@S1  T=937.7ms eta=15:52:54 | 54.0K token/s | 
[epoch_0]_71     loss=7.128428 |g|=0.843	lr=1.20e-04 | 5.8%@S1  T=940.1ms eta=15:55:11 | 55.7K token/s | 
[epoch_0]_81     loss=7.023672 |g|=1.22	lr=1.37e-04 | 6.6%@S1  T=943.3ms eta=15:58:19 | 57.2K token/s | 
[epoch_0]_91     loss=6.941983 |g|=0.872	lr=1.53e-04 | 7.5%@S1  T=946.9ms eta=16:01:48 | 58.7K token/s | 
[Section@100] layer[6-12] tasks=15(nPassBack=0) last_loss=6.82419(3.40282e+38) N=(580,588,168 9900)
[epoch_0]_101    loss=8.140527 |g|=4.48	lr=1.70e-04 | 8.3%@S1  T=1.10s eta=18:32:20 | 59.5K token/s | 
[epoch_0]_111    loss=7.668805 |g|=0.994	lr=1.87e-04 | 9.1%@S1  T=946.6ms eta=16:01:08 | 60.8K token/s | 
[epoch_0]_121    loss=7.208415 |g|=0.728	lr=2.03e-04 | 9.9%@S1  T=944.1ms eta=15:58:28 | 62.1K token/s | 
[epoch_0]_131    loss=6.936585 |g|=0.759	lr=2.20e-04 | 10.7%@S1  T=942.0ms eta=15:56:11 | 63.4K token/s | 
[epoch_0]_141    loss=6.858841 |g|=0.564	lr=2.37e-04 | 11.6%@S1  T=947.6ms eta=16:01:41 | 64.5K token/s | 
[epoch_0]_151    loss=6.708813 |g|=0.628	lr=2.53e-04 | 12.4%@S1  T=936.8ms eta=15:50:35 | 65.7K token/s | 
[epoch_0]_161    loss=6.654139 |g|=0.872	lr=2.70e-04 | 13.2%@S1  T=941.3ms eta=15:55:01 | 66.7K token/s | 
[epoch_0]_171    loss=6.570291 |g|=0.803	lr=2.87e-04 | 14.0%@S1  T=941.1ms eta=15:54:38 | 67.8K token/s | 
[epoch_0]_181    loss=6.492238 |g|=0.519	lr=3.03e-04 | 14.8%@S1  T=942.9ms eta=15:56:19 | 68.7K token/s | 
[epoch_0]_191    loss=6.388744 |g|=0.379	lr=3.20e-04 | 15.6%@S1  T=941.3ms eta=15:54:33 | 69.6K token/s | 
[eval] 
	 Loss@"edu_fineweb1B"=6.519 nFuyou=1 	#6.51911±0.0740 tps=297K(4.01408M) a=[6.31846,6.79477] T=13.4959(sec)
[Section@200] layer[12-18] tasks=15(nPassBack=0) last_loss=6.35523(3.40282e+38) N=(580,672,252 19900)
[epoch_0]_201    loss=7.917932 |g|=2.99	lr=3.37e-04 | 16.5%@S1  T=3.93s eta=2d 18:28:02 | 67.2K token/s | 
[epoch_0]_211    loss=7.599853 |g|=0.996	lr=3.53e-04 | 17.3%@S1  T=949.9ms eta=16:02:56 | 68.1K token/s | 
[epoch_0]_221    loss=7.055778 |g|=0.934	lr=3.70e-04 | 18.1%@S1  T=939.9ms eta=15:52:39 | 69.1K token/s | 
[epoch_0]_231    loss=6.727719 |g|=0.805	lr=3.87e-04 | 18.9%@S1  T=941.2ms eta=15:53:46 | 70.0K token/s | 
[epoch_0]_241    loss=6.610739 |g|=0.555	lr=4.03e-04 | 19.7%@S1  T=945.1ms eta=15:57:37 | 70.8K token/s | 
[epoch_0]_251    loss=6.534111 |g|=0.518	lr=4.20e-04 | 20.6%@S1  T=944.9ms eta=15:57:16 | 71.6K token/s | 
[epoch_0]_261    loss=6.430016 |g|=0.471	lr=4.37e-04 | 21.4%@S1  T=943.5ms eta=15:55:42 | 72.4K token/s | 
[epoch_0]_271    loss=6.410214 |g|=0.718	lr=4.53e-04 | 22.2%@S1  T=943.9ms eta=15:55:55 | 73.1K token/s | 
[epoch_0]_281    loss=6.419286 |g|=0.592	lr=4.70e-04 | 23.0%@S1  T=945.4ms eta=15:57:16 | 73.8K token/s | 
[epoch_0]_291    loss=6.319509 |g|=0.452	lr=4.87e-04 | 23.8%@S1  T=948.0ms eta=15:59:43 | 74.4K token/s | 
[Section@300] layer[18-24] tasks=15(nPassBack=0) last_loss=6.37271(3.40282e+38) N=(580,756,336 29900)
[epoch_0]_301    loss=8.154145 |g|=4.89	lr=5.03e-04 | 24.7%@S1  T=1.09s eta=18:20:27 | 74.5K token/s | 
[epoch_0]_311    loss=7.319685 |g|=0.802	lr=5.20e-04 | 25.5%@S1  T=936.9ms eta=15:48:13 | 75.1K token/s | 
[epoch_0]_321    loss=6.956706 |g|=0.758	lr=5.37e-04 | 26.3%@S1  T=947.3ms eta=15:58:35 | 75.7K token/s | 
[epoch_0]_331    loss=6.637536 |g|=0.454	lr=5.53e-04 | 27.1%@S1  T=947.3ms eta=15:58:26 | 76.2K token/s | 
[epoch_0]_341    loss=6.577891 |g|=0.615	lr=5.70e-04 | 27.9%@S1  T=948.8ms eta=15:59:47 | 76.7K token/s | 
[epoch_0]_351    loss=6.461284 |g|=0.547	lr=5.87e-04 | 28.8%@S1  T=946.3ms eta=15:57:03 | 77.2K token/s | 
[epoch_0]_361    loss=6.387731 |g|=0.587	lr=6.03e-04 | 29.6%@S1  T=946.3ms eta=15:56:54 | 77.7K token/s | 
[epoch_0]_371    loss=6.458180 |g|=0.429	lr=6.20e-04 | 30.4%@S1  T=944.0ms eta=15:54:29 | 78.1K token/s | 
[epoch_0]_381    loss=6.296132 |g|=0.382	lr=6.37e-04 | 31.2%@S1  T=942.3ms eta=15:52:33 | 78.6K token/s | 
[epoch_0]_391    loss=6.267705 |g|=0.484	lr=6.53e-04 | 32.0%@S1  T=941.7ms eta=15:51:46 | 79.0K token/s | 
[eval] 
	 Loss@"edu_fineweb1B"=6.350(0.17) nBranch=1 nToken=4.01M best=6.5191(0) E2T=0.12 T=13.5115(0)s x=0
	#6.34991±0.0716 tps=297K(4.01408M) a=[6.16804,6.60801] T=13.5115(sec)
[Section@400] layer[24-30] tasks=15(nPassBack=0) last_loss=6.22967(3.40282e+38) N=(580,840,420 39900)
[epoch_0]_401    loss=8.763003 |g|=10.3	lr=6.70e-04 | 32.9%@S1  T=3.93s eta=2d 18:14:42 | 76.1K token/s | 
[epoch_0]_411    loss=7.322185 |g|=1.69	lr=6.87e-04 | 33.7%@S1  T=946.5ms eta=15:56:18 | 76.6K token/s | 
[epoch_0]_421    loss=6.840598 |g|=1.27	lr=7.03e-04 | 34.5%@S1  T=939.5ms eta=15:49:05 | 77.1K token/s | 
[epoch_0]_431    loss=6.663228 |g|=0.621	lr=7.20e-04 | 35.3%@S1  T=948.1ms eta=15:57:40 | 77.6K token/s | 
[epoch_0]_441    loss=6.462145 |g|=0.448	lr=7.37e-04 | 36.1%@S1  T=947.0ms eta=15:56:21 | 78.0K token/s | 
[epoch_0]_451    loss=6.442928 |g|=0.538	lr=7.53e-04 | 36.9%@S1  T=943.5ms eta=15:52:41 | 78.5K token/s | 
[epoch_0]_461    loss=6.398159 |g|=0.729	lr=7.70e-04 | 37.8%@S1  T=940.5ms eta=15:49:27 | 78.9K token/s | 
[epoch_0]_471    loss=6.321877 |g|=0.485	lr=7.87e-04 | 38.6%@S1  T=948.2ms eta=15:57:04 | 79.3K token/s | 
[epoch_0]_481    loss=6.244359 |g|=0.696	lr=8.03e-04 | 39.4%@S1  T=945.1ms eta=15:53:48 | 79.7K token/s | 
[epoch_0]_491    loss=6.244311 |g|=0.538	lr=8.20e-04 | 40.2%@S1  T=945.0ms eta=15:53:32 | 80.0K token/s | 
[Section@500] layer[30-36] tasks=15(nPassBack=0) last_loss=6.23497(3.40282e+38) N=(580,924,504 49900)
[epoch_0]_501    loss=9.175475 |g|=10.2	lr=8.37e-04 | 41.0%@S1  T=1.10s eta=18:34:17 | 79.7K token/s | 
[epoch_0]_511    loss=7.363953 |g|=1.46	lr=8.53e-04 | 41.9%@S1  T=941.7ms eta=15:49:54 | 80.1K token/s | 
[epoch_0]_521    loss=6.852727 |g|=0.826	lr=8.70e-04 | 42.7%@S1  T=944.4ms eta=15:52:28 | 80.4K token/s | 
[epoch_0]_531    loss=6.748456 |g|=0.538	lr=8.87e-04 | 43.5%@S1  T=946.6ms eta=15:54:30 | 80.7K token/s | 
[epoch_0]_541    loss=6.630352 |g|=0.474	lr=9.03e-04 | 44.3%@S1  T=941.6ms eta=15:49:21 | 81.0K token/s | 
[epoch_0]_551    loss=6.475586 |g|=0.505	lr=9.20e-04 | 45.1%@S1  T=948.5ms eta=15:56:07 | 81.3K token/s | 
[epoch_0]_561    loss=6.436956 |g|=0.544	lr=9.37e-04 | 46.0%@S1  T=945.4ms eta=15:52:49 | 81.6K token/s | 
[epoch_0]_571    loss=6.307289 |g|=0.555	lr=9.53e-04 | 46.8%@S1  T=948.5ms eta=15:55:51 | 81.8K token/s | 
[epoch_0]_581    loss=6.246981 |g|=0.451	lr=9.70e-04 | 47.6%@S1  T=948.2ms eta=15:55:23 | 82.0K token/s | 
[epoch_0]_591    loss=6.309940 |g|=0.405	lr=9.87e-04 | 48.4%@S1  T=951.6ms eta=15:58:38 | 82.2K token/s | 
[Fuyou] head="5" update algorithm=4 t=2.03s
[eval] 
	 Loss@"edu_fineweb1B"=6.311(0.039) nBranch=1 nToken=4.01M best=6.3499(1) E2T=0.0939 T=13.5179(0)s x=0
	#6.31094±0.0730 tps=297K(4.01408M) a=[6.13626,6.57303] T=13.5179(sec)
[Section@600] layer[0-6] tasks=15(nPassBack=0) last_loss=6.21701(3.40282e+38) N=(580,1008,588 59900)
[epoch_0]_601    loss=6.287845 |g|=0.827	lr=1.00e-03 | 49.2%@S1  T=4.05s eta=2d 20:02:24 | 79.1K token/s | 
[epoch_0]_611    loss=6.240643 |g|=0.424	lr=1.00e-03 | 50.1%@S1  T=942.8ms eta=15:49:30 | 79.5K token/s | 
[epoch_0]_621    loss=6.141491 |g|=0.394	lr=1.00e-03 | 50.9%@S1  T=946.3ms eta=15:52:47 | 79.9K token/s | 
[epoch_0]_631    loss=6.155504 |g|=0.529	lr=1.00e-03 | 51.7%@S1  T=942.5ms eta=15:48:51 | 80.2K token/s | 
[epoch_0]_641    loss=6.066131 |g|=0.377	lr=1.00e-03 | 52.5%@S1  T=945.0ms eta=15:51:13 | 80.6K token/s | 
[epoch_0]_651    loss=6.140749 |g|=0.395	lr=1.00e-03 | 53.3%@S1  T=949.8ms eta=15:55:53 | 80.8K token/s | 
[epoch_0]_661    loss=6.075768 |g|=0.581	lr=1.00e-03 | 54.2%@S1  T=968.1ms eta=16:14:07 | 81.0K token/s | 
[epoch_0]_671    loss=6.007214 |g|=0.336	lr=1.00e-03 | 55.0%@S1  T=951.4ms eta=15:57:11 | 81.3K token/s | 
[epoch_0]_681    loss=5.996290 |g|=0.392	lr=1.00e-03 | 55.8%@S1  T=949.6ms eta=15:55:09 | 81.5K token/s | 
[epoch_0]_691    loss=5.933817 |g|=0.384	lr=1.00e-03 | 56.6%@S1  T=942.1ms eta=15:47:32 | 81.8K token/s | 
[Fuyou] head="0" update algorithm=4 t=2.05s
[Section@700] layer[6-12] tasks=15(nPassBack=0) last_loss=5.95224(0.871944) N=(580,1092,672 69900)
[epoch_0]_701    loss=5.946332 |g|=0.54	lr=1.00e-03 | 57.4%@S1  T=1.22s eta=20:24:21 | 81.1K token/s | 
[epoch_0]_711    loss=5.891073 |g|=0.342	lr=1.00e-03 | 58.2%@S1  T=944.4ms eta=15:49:32 | 81.4K token/s | 
[epoch_0]_721    loss=5.916510 |g|=0.308	lr=1.00e-03 | 59.1%@S1  T=947.5ms eta=15:52:29 | 81.6K token/s | 
[epoch_0]_731    loss=5.880805 |g|=0.467	lr=1.00e-03 | 59.9%@S1  T=950.2ms eta=15:55:03 | 81.8K token/s | 
[epoch_0]_741    loss=5.884269 |g|=0.418	lr=1.00e-03 | 60.7%@S1  T=953.4ms eta=15:58:05 | 82.0K token/s | 
[epoch_0]_751    loss=5.824683 |g|=0.354	lr=1.00e-03 | 61.5%@S1  T=955.6ms eta=16:00:10 | 82.2K token/s | 
[epoch_0]_761    loss=5.695004 |g|=0.317	lr=1.00e-03 | 62.3%@S1  T=959.1ms eta=16:03:31 | 82.4K token/s | 
[epoch_0]_771    loss=5.779579 |g|=0.481	lr=1.00e-03 | 63.2%@S1  T=941.3ms eta=15:45:27 | 82.6K token/s | 
[epoch_0]_781    loss=5.687696 |g|=0.391	lr=1.00e-03 | 64.0%@S1  T=956.3ms eta=16:00:19 | 82.8K token/s | 
[epoch_0]_791    loss=5.710817 |g|=0.448	lr=1.00e-03 | 64.8%@S1  T=953.4ms eta=15:57:16 | 82.9K token/s | 
[Fuyou] head="1" update algorithm=4 t=2.02s
[eval] 
	 Loss@"edu_fineweb1B"=5.785(0.53) nBranch=1 nToken=4.01M best=6.3109(2) E2T=0.0549 T=13.5147(0)s x=0
	#5.78541±0.0775 tps=297K(4.01408M) a=[5.62444,6.07124] T=13.5147(sec)
[Section@800] layer[12-18] tasks=15(nPassBack=0) last_loss=5.73047(0.624754) N=(580,1176,756 79900)
[epoch_0]_801    loss=5.732969 |g|=0.587	lr=1.00e-03 | 65.6%@S1  T=4.07s eta=2d 20:07:07 | 79.8K token/s | 
[epoch_0]_811    loss=5.554972 |g|=0.396	lr=1.00e-03 | 66.4%@S1  T=956.3ms eta=15:59:55 | 80.1K token/s | 
[epoch_0]_821    loss=5.640032 |g|=0.452	lr=1.00e-03 | 67.3%@S1  T=946.1ms eta=15:49:31 | 80.4K token/s | 
[epoch_0]_831    loss=5.635212 |g|=0.372	lr=1.00e-03 | 68.1%@S1  T=942.8ms eta=15:45:57 | 80.7K token/s | 
[epoch_0]_841    loss=5.642826 |g|=0.464	lr=1.00e-03 | 68.9%@S1  T=945.5ms eta=15:48:32 | 81.0K token/s | 
[epoch_0]_851    loss=5.642644 |g|=0.464	lr=1.00e-03 | 69.7%@S1  T=945.6ms eta=15:48:30 | 81.3K token/s | 
[epoch_0]_861    loss=5.525512 |g|=0.333	lr=1.00e-03 | 70.5%@S1  T=945.9ms eta=15:48:38 | 81.6K token/s | 
[epoch_0]_871    loss=5.577929 |g|=0.432	lr=1.00e-03 | 71.4%@S1  T=945.9ms eta=15:48:31 | 81.8K token/s | 
[epoch_0]_881    loss=5.466929 |g|=0.436	lr=1.00e-03 | 72.2%@S1  T=943.9ms eta=15:46:18 | 82.1K token/s | 
[epoch_0]_891    loss=5.541980 |g|=0.361	lr=1.00e-03 | 73.0%@S1  T=951.1ms eta=15:53:20 | 82.3K token/s | 
[Fuyou] head="2" update algorithm=4 t=2.06s
[Section@900] layer[18-24] tasks=15(nPassBack=0) last_loss=5.46188(0.910823) N=(580,1260,840 89900)
[epoch_0]_901    loss=5.551322 |g|=0.834	lr=1.00e-03 | 73.8%@S1  T=1.23s eta=20:37:08 | 81.5K token/s | 
[epoch_0]_911    loss=5.513136 |g|=0.373	lr=1.00e-03 | 74.6%@S1  T=944.6ms eta=15:46:31 | 81.7K token/s | 
[epoch_0]_921    loss=5.495142 |g|=0.426	lr=1.00e-03 | 75.4%@S1  T=942.7ms eta=15:44:28 | 82.0K token/s | 
[epoch_0]_931    loss=5.453734 |g|=0.407	lr=1.00e-03 | 76.3%@S1  T=943.8ms eta=15:45:23 | 82.2K token/s | 
[epoch_0]_941    loss=5.346894 |g|=0.384	lr=1.00e-03 | 77.1%@S1  T=947.4ms eta=15:48:51 | 82.5K token/s | 
[epoch_0]_951    loss=5.362429 |g|=0.401	lr=1.00e-03 | 77.9%@S1  T=942.4ms eta=15:43:40 | 82.7K token/s | 
[epoch_0]_961    loss=5.300939 |g|=0.334	lr=1.00e-03 | 78.7%@S1  T=949.0ms eta=15:50:11 | 82.9K token/s | 
[epoch_0]_971    loss=5.330248 |g|=0.447	lr=1.00e-03 | 79.5%@S1  T=943.5ms eta=15:44:29 | 83.1K token/s | 
[epoch_0]_981    loss=5.279879 |g|=0.468	lr=1.00e-03 | 80.4%@S1  T=944.5ms eta=15:45:19 | 83.2K token/s | 
[epoch_0]_991    loss=5.304549 |g|=0.396	lr=1.00e-03 | 81.2%@S1  T=941.7ms eta=15:42:25 | 83.4K token/s | 
[Fuyou] head="3" update algorithm=4 t=1.99s
[eval] 
	 Loss@"edu_fineweb1B"=5.358(0.43) nBranch=1 nToken=4.01M best=5.7854(3) E2T=0.0532 T=13.5102(0)s x=0
	#5.35757±0.0846 tps=297K(4.01408M) a=[5.18685,5.62809] T=13.5102(sec)
[Section@1000] layer[24-30] tasks=15(nPassBack=0) last_loss=5.30434(0.925332) N=(580,1344,924 99900)
[epoch_0]_1001   loss=5.429855 |g|=1.23	lr=1.00e-03 | 82.0%@S1  T=4.06s eta=2d 19:42:39 | 80.3K token/s | 
[epoch_0]_1011   loss=5.364962 |g|=0.514	lr=1.00e-03 | 82.8%@S1  T=947.1ms eta=15:47:31 | 80.6K token/s | 
[epoch_0]_1021   loss=5.271489 |g|=0.419	lr=1.00e-03 | 83.6%@S1  T=953.6ms eta=15:53:49 | 80.8K token/s | 
[epoch_0]_1031   loss=5.173151 |g|=0.421	lr=1.00e-03 | 84.5%@S1  T=946.8ms eta=15:46:54 | 81.1K token/s | 
[epoch_0]_1041   loss=5.253988 |g|=0.457	lr=1.00e-03 | 85.3%@S1  T=973.1ms eta=16:12:57 | 81.3K token/s | 
[epoch_0]_1051   loss=5.214482 |g|=0.385	lr=1.00e-03 | 86.1%@S1  T=949.9ms eta=15:49:40 | 81.5K token/s | 
[epoch_0]_1061   loss=5.152994 |g|=0.371	lr=1.00e-03 | 86.9%@S1  T=946.2ms eta=15:45:45 | 81.8K token/s | 
[epoch_0]_1071   loss=5.064143 |g|=0.403	lr=1.00e-03 | 87.7%@S1  T=946.6ms eta=15:46:01 | 82.0K token/s | 
[epoch_0]_1081   loss=5.098103 |g|=0.411	lr=1.00e-03 | 88.6%@S1  T=957.7ms eta=15:57:00 | 82.2K token/s | 
[epoch_0]_1091   loss=5.180395 |g|=0.42	lr=1.00e-03 | 89.4%@S1  T=957.7ms eta=15:56:49 | 82.4K token/s | 
[Fuyou] head="4" update algorithm=4 t=2.09s
[Section@1100] layer[30-36] tasks=15(nPassBack=0) last_loss=5.12647(1.1085) N=(580,1428,1008 109900)
[epoch_0]_1101   loss=5.229829 |g|=1.15	lr=1.00e-03 | 90.2%@S1  T=1.29s eta=21:33:02 | 81.4K token/s | 
[epoch_0]_1111   loss=5.146704 |g|=0.549	lr=1.00e-03 | 91.0%@S1  T=951.7ms eta=15:50:27 | 81.6K token/s | 
[epoch_0]_1121   loss=5.123018 |g|=0.425	lr=1.00e-03 | 91.8%@S1  T=951.9ms eta=15:50:33 | 81.9K token/s | 
[epoch_0]_1131   loss=5.009286 |g|=0.424	lr=1.00e-03 | 92.7%@S1  T=959.9ms eta=15:58:20 | 82.0K token/s | 
[epoch_0]_1141   loss=4.980640 |g|=0.411	lr=1.00e-03 | 93.5%@S1  T=947.7ms eta=15:45:59 | 82.3K token/s | 
[epoch_0]_1151   loss=4.967927 |g|=0.425	lr=1.00e-03 | 94.3%@S1  T=951.0ms eta=15:49:08 | 82.5K token/s | 
[epoch_0]_1161   loss=5.020669 |g|=0.415	lr=1.00e-03 | 95.1%@S1  T=956.3ms eta=15:54:17 | 82.6K token/s | 
[epoch_0]_1171   loss=4.998092 |g|=0.404	lr=1.00e-03 | 95.9%@S1  T=952.9ms eta=15:50:43 | 82.8K token/s | 
[epoch_0]_1181   loss=4.950295 |g|=0.535	lr=1.00e-03 | 96.7%@S1  T=962.4ms eta=16:00:03 | 82.9K token/s | 
[epoch_0]_1191   loss=4.981194 |g|=0.419	lr=1.00e-03 | 97.6%@S1  T=951.5ms eta=15:49:02 | 83.1K token/s | 
[Fuyou] head="5" update algorithm=4 t=2.07s
[eval] 
	 Loss@"edu_fineweb1B"=5.000(0.36) nBranch=1 nToken=4.01M best=5.3576(4) E2T=0.0866 T=13.5391(0)s x=0
	#5.00026±0.0889 tps=296K(4.01408M) a=[4.82218,5.24015] T=13.5391(sec)
[Section@1200] layer[0-6] tasks=15(nPassBack=0) last_loss=4.91364(1.30338) N=(580,1512,1092 119900)
[epoch_0]_1201   loss=4.946102 |g|=1.02	lr=1.00e-03 | 98.4%@S1  T=4.08s eta=2d 19:47:59 | 79.9K token/s | 
[epoch_0]_1211   loss=4.911891 |g|=0.464	lr=1.00e-03 | 99.2%@S1  T=947.7ms eta=15:44:53 | 80.2K token/s | 
[epoch_0]_1220   loss=4.916496 |g|=0.453	lr=1.00e-03 | 99.9%@S1  T=954.4ms eta=15:51:25 | 80.5K token/s | 
-------- End of shard_1@"./Datasets/edu_fineweb1B/edu_fineweb_train_000001.bin"-------- 
[shard-2]@"./Datasets/edu_fineweb1B/edu_fineweb_train_000002.bin": tokens=100(M) nShardSamples=1220(195312) 
[epoch_0]_1221   loss=4.925930 |g|=0.548	lr=1.00e-03 | 0.0%@S2  T=1.18s eta=19:35:21 | 80.0K token/s | 
[epoch_0]_1231   loss=4.920757 |g|=0.403	lr=1.00e-03 | 0.8%@S2  T=952.4ms eta=15:49:14 | 80.3K token/s | 
[epoch_0]_1241   loss=4.872053 |g|=0.422	lr=1.00e-03 | 1.7%@S2  T=945.1ms eta=15:41:50 | 80.6K token/s | 
[epoch_0]_1251   loss=4.864203 |g|=0.43	lr=1.00e-03 | 2.5%@S2  T=951.2ms eta=15:47:47 | 80.9K token/s | 
[epoch_0]_1261   loss=4.787653 |g|=0.521	lr=1.00e-03 | 3.3%@S2  T=950.4ms eta=15:46:48 | 81.1K token/s | 
[epoch_0]_1271   loss=4.831530 |g|=0.464	lr=1.00e-03 | 4.1%@S2  T=954.3ms eta=15:50:34 | 81.4K token/s | 
[epoch_0]_1281   loss=4.774546 |g|=0.497	lr=1.00e-03 | 4.9%@S2  T=954.2ms eta=15:50:15 | 81.6K token/s | 
[epoch_0]_1291   loss=4.756189 |g|=0.452	lr=1.00e-03 | 5.8%@S2  T=948.1ms eta=15:44:04 | 81.8K token/s | 
[Fuyou] head="0" update algorithm=4 t=2.08s
[Section@1300] layer[6-12] tasks=15(nPassBack=0) last_loss=4.82682(1.12543) N=(580,1596,1176 129900)
[epoch_0]_1301   loss=4.855648 |g|=1.05	lr=1.00e-03 | 6.6%@S2  T=1.26s eta=20:53:17 | 81.0K token/s | 
[epoch_0]_1311   loss=4.777620 |g|=0.496	lr=1.00e-03 | 7.4%@S2  T=946.6ms eta=15:42:15 | 81.3K token/s | 
[epoch_0]_1321   loss=4.803255 |g|=0.459	lr=1.00e-03 | 8.2%@S2  T=949.0ms eta=15:44:30 | 81.5K token/s | 
[epoch_0]_1331   loss=4.636506 |g|=0.423	lr=1.00e-03 | 9.0%@S2  T=952.3ms eta=15:47:33 | 81.7K token/s | 
[epoch_0]_1341   loss=4.680510 |g|=0.525	lr=1.00e-03 | 9.9%@S2  T=952.9ms eta=15:48:00 | 82.0K token/s | 
[epoch_0]_1351   loss=4.665607 |g|=0.493	lr=1.00e-03 | 10.7%@S2  T=958.5ms eta=15:53:28 | 82.1K token/s | 
[epoch_0]_1361   loss=4.638129 |g|=0.541	lr=1.00e-03 | 11.5%@S2  T=954.4ms eta=15:49:14 | 82.3K token/s | 
[epoch_0]_1371   loss=4.613332 |g|=0.501	lr=1.00e-03 | 12.3%@S2  T=950.4ms eta=15:45:06 | 82.5K token/s | 
[epoch_0]_1381   loss=4.712918 |g|=0.497	lr=1.00e-03 | 13.1%@S2  T=952.4ms eta=15:46:57 | 82.7K token/s | 
[epoch_0]_1391   loss=4.607583 |g|=0.496	lr=1.00e-03 | 14.0%@S2  T=952.2ms eta=15:46:32 | 82.9K token/s | 
[Fuyou] head="1" update algorithm=4 t=2.04s
[eval] 
	 Loss@"edu_fineweb1B"=4.694(0.31) nBranch=1 nToken=4.01M best=5.0003(5) E2T=0.0752 T=13.5188(0)s x=0
	#4.6942±0.0944 tps=297K(4.01408M) a=[4.48749,4.94488] T=13.5188(sec)
[Section@1400] layer[12-18] tasks=15(nPassBack=0) last_loss=4.61896(1.11152) N=(580,1680,1260 139900)
[epoch_0]_1401   loss=4.675709 |g|=0.973	lr=1.00e-03 | 14.8%@S2  T=4.08s eta=2d 19:32:14 | 79.7K token/s | 
[epoch_0]_1411   loss=4.538989 |g|=0.517	lr=1.00e-03 | 15.6%@S2  T=951.7ms eta=15:45:46 | 80.0K token/s | 
[epoch_0]_1421   loss=4.590992 |g|=0.504	lr=1.00e-03 | 16.4%@S2  T=969.7ms eta=16:03:28 | 80.3K token/s | 
[epoch_0]_1431   loss=4.640056 |g|=0.586	lr=1.00e-03 | 17.2%@S2  T=946.8ms eta=15:40:30 | 80.6K token/s | 
[epoch_0]_1441   loss=4.624330 |g|=0.463	lr=1.00e-03 | 18.0%@S2  T=958.3ms eta=15:51:51 | 80.8K token/s | 
[epoch_0]_1451   loss=4.581547 |g|=0.466	lr=1.00e-03 | 18.9%@S2  T=948.6ms eta=15:42:01 | 81.1K token/s | 
[epoch_0]_1461   loss=4.631342 |g|=0.523	lr=1.00e-03 | 19.7%@S2  T=968.2ms eta=16:01:19 | 81.3K token/s | 
[epoch_0]_1471   loss=4.551421 |g|=0.555	lr=9.99e-04 | 20.5%@S2  T=952.4ms eta=15:45:27 | 81.5K token/s | 
[epoch_0]_1481   loss=4.601976 |g|=0.416	lr=9.99e-04 | 21.3%@S2  T=953.9ms eta=15:46:48 | 81.7K token/s | 
[epoch_0]_1491   loss=4.553751 |g|=0.501	lr=9.99e-04 | 22.1%@S2  T=954.7ms eta=15:47:26 | 81.9K token/s | 
[Fuyou] head="2" update algorithm=4 t=2.07s
[Section@1500] layer[18-24] tasks=15(nPassBack=0) last_loss=4.54506(0.91682) N=(580,1764,1344 149900)
[epoch_0]_1501   loss=4.556509 |g|=0.911	lr=9.99e-04 | 23.0%@S2  T=1.27s eta=20:56:35 | 81.1K token/s | 
[epoch_0]_1511   loss=4.481810 |g|=0.493	lr=9.99e-04 | 23.8%@S2  T=950.4ms eta=15:42:51 | 81.3K token/s | 
[epoch_0]_1521   loss=4.512358 |g|=0.497	lr=9.99e-04 | 24.6%@S2  T=954.5ms eta=15:46:43 | 81.5K token/s | 
[epoch_0]_1531   loss=4.508969 |g|=0.482	lr=9.99e-04 | 25.4%@S2  T=955.4ms eta=15:47:29 | 81.8K token/s | 
[epoch_0]_1541   loss=4.487383 |g|=0.473	lr=9.99e-04 | 26.2%@S2  T=951.0ms eta=15:43:01 | 82.0K token/s | 
[epoch_0]_1551   loss=4.366901 |g|=0.462	lr=9.99e-04 | 27.1%@S2  T=951.7ms eta=15:43:30 | 82.2K token/s | 
[epoch_0]_1561   loss=4.449289 |g|=0.58	lr=9.99e-04 | 27.9%@S2  T=950.5ms eta=15:42:12 | 82.4K token/s | 
[epoch_0]_1571   loss=4.481377 |g|=0.516	lr=9.99e-04 | 28.7%@S2  T=955.6ms eta=15:47:04 | 82.5K token/s | 
[epoch_0]_1581   loss=4.450845 |g|=0.665	lr=9.99e-04 | 29.5%@S2  T=953.0ms eta=15:44:20 | 82.7K token/s | 
[epoch_0]_1591   loss=4.311563 |g|=0.518	lr=9.99e-04 | 30.3%@S2  T=954.4ms eta=15:45:36 | 82.9K token/s | 
[Fuyou] head="3" update algorithm=4 t=2.03s
[eval] 
	 Loss@"edu_fineweb1B"=4.536(0.16) nBranch=1 nToken=4.01M best=4.6942(6) E2T=0.146 T=13.5332(0)s x=0
	#4.53649±0.0990 tps=297K(4.01408M) a=[4.32595,4.78027] T=13.5332(sec)
[Section@1600] layer[24-30] tasks=15(nPassBack=0) last_loss=4.39019(0.914153) N=(580,1848,1428 159900)
[epoch_0]_1601   loss=4.493085 |g|=0.927	lr=9.99e-04 | 31.2%@S2  T=4.10s eta=2d 19:39:09 | 79.7K token/s | 
[epoch_0]_1611   loss=4.469102 |g|=0.476	lr=9.99e-04 | 32.0%@S2  T=959.7ms eta=15:50:30 | 80.0K token/s | 
[epoch_0]_1621   loss=4.453300 |g|=0.476	lr=9.99e-04 | 32.8%@S2  T=958.5ms eta=15:49:07 | 80.3K token/s | 
[epoch_0]_1631   loss=4.446650 |g|=0.44	lr=9.99e-04 | 33.6%@S2  T=953.2ms eta=15:43:42 | 80.6K token/s | 
[epoch_0]_1641   loss=4.456620 |g|=0.533	lr=9.99e-04 | 34.4%@S2  T=954.9ms eta=15:45:15 | 80.8K token/s | 
[epoch_0]_1651   loss=4.428809 |g|=0.484	lr=9.99e-04 | 35.3%@S2  T=951.8ms eta=15:42:03 | 81.1K token/s | 
[epoch_0]_1661   loss=4.407945 |g|=0.508	lr=9.99e-04 | 36.1%@S2  T=949.9ms eta=15:39:56 | 81.3K token/s | 
[epoch_0]_1671   loss=4.420959 |g|=0.5	lr=9.99e-04 | 36.9%@S2  T=953.1ms eta=15:43:00 | 81.6K token/s | 
[epoch_0]_1681   loss=4.364450 |g|=0.492	lr=9.99e-04 | 37.7%@S2  T=960.4ms eta=15:50:05 | 81.8K token/s | 
[epoch_0]_1691   loss=4.420469 |g|=0.506	lr=9.99e-04 | 38.5%@S2  T=955.5ms eta=15:45:04 | 82.0K token/s | 
[Fuyou] head="4" update algorithm=4 t=2.08s
[Section@1700] layer[30-36] tasks=15(nPassBack=0) last_loss=4.33305(0.793421) N=(580,1932,1512 169900)
[epoch_0]_1701   loss=4.345480 |g|=0.848	lr=9.99e-04 | 39.3%@S2  T=1.29s eta=21:11:09 | 81.1K token/s | 
[epoch_0]_1711   loss=4.382489 |g|=0.501	lr=9.99e-04 | 40.2%@S2  T=955.7ms eta=15:44:56 | 81.3K token/s | 
[epoch_0]_1721   loss=4.320060 |g|=0.523	lr=9.99e-04 | 41.0%@S2  T=951.0ms eta=15:40:07 | 81.5K token/s | 
[epoch_0]_1731   loss=4.356485 |g|=0.531	lr=9.99e-04 | 41.8%@S2  T=954.3ms eta=15:43:13 | 81.7K token/s | 
[epoch_0]_1741   loss=4.349744 |g|=0.462	lr=9.99e-04 | 42.6%@S2  T=951.0ms eta=15:39:48 | 82.0K token/s | 
[epoch_0]_1751   loss=4.373279 |g|=0.456	lr=9.99e-04 | 43.4%@S2  T=954.3ms eta=15:42:54 | 82.2K token/s | 
[epoch_0]_1761   loss=4.329640 |g|=0.563	lr=9.99e-04 | 44.3%@S2  T=951.1ms eta=15:39:36 | 82.4K token/s | 
[epoch_0]_1771   loss=4.353867 |g|=0.438	lr=9.99e-04 | 45.1%@S2  T=956.2ms eta=15:44:30 | 82.5K token/s | 
[epoch_0]_1781   loss=4.342940 |g|=0.565	lr=9.99e-04 | 45.9%@S2  T=977.3ms eta=16:05:07 | 82.6K token/s | 
[epoch_0]_1791   loss=4.314284 |g|=0.441	lr=9.99e-04 | 46.7%@S2  T=953.2ms eta=15:41:13 | 82.8K token/s | 
[Fuyou] head="5" update algorithm=4 t=2.07s
[eval] 
	 Loss@"edu_fineweb1B"=4.412(0.12) nBranch=1 nToken=4.01M best=4.5365(7) E2T=0.0965 T=13.5144(0)s x=0
	#4.4118±0.1004 tps=297K(4.01408M) a=[4.19869,4.64642] T=13.5144(sec)
[Section@1800] layer[0-6] tasks=15(nPassBack=0) last_loss=4.3153(0.598336) N=(580,2016,1596 179900)
[epoch_0]_1801   loss=4.392060 |g|=0.782	lr=9.99e-04 | 47.5%@S2  T=4.08s eta=2d 19:04:10 | 79.6K token/s | 
[epoch_0]_1811   loss=4.287345 |g|=0.5	lr=9.99e-04 | 48.4%@S2  T=952.6ms eta=15:40:16 | 79.9K token/s | 
[epoch_0]_1821   loss=4.384014 |g|=0.533	lr=9.99e-04 | 49.2%@S2  T=962.3ms eta=15:49:40 | 80.2K token/s | 
[epoch_0]_1831   loss=4.293153 |g|=0.459	lr=9.99e-04 | 50.0%@S2  T=955.7ms eta=15:42:59 | 80.5K token/s | 
[epoch_0]_1841   loss=4.308218 |g|=0.471	lr=9.99e-04 | 50.8%@S2  T=950.1ms eta=15:37:17 | 80.8K token/s | 
[epoch_0]_1851   loss=4.340784 |g|=0.483	lr=9.99e-04 | 51.6%@S2  T=960.4ms eta=15:47:20 | 81.0K token/s | 
[epoch_0]_1861   loss=4.322762 |g|=0.456	lr=9.99e-04 | 52.5%@S2  T=955.8ms eta=15:42:40 | 81.2K token/s | 
[epoch_0]_1871   loss=4.275332 |g|=0.418	lr=9.99e-04 | 53.3%@S2  T=955.7ms eta=15:42:22 | 81.5K token/s | 
[epoch_0]_1881   loss=4.344625 |g|=0.458	lr=9.99e-04 | 54.1%@S2  T=951.2ms eta=15:37:48 | 81.7K token/s | 
[epoch_0]_1891   loss=4.319207 |g|=0.563	lr=9.99e-04 | 54.9%@S2  T=948.3ms eta=15:34:48 | 81.9K token/s | 
[Fuyou] head="0" update algorithm=4 t=2.18s
[Section@1900] layer[6-12] tasks=15(nPassBack=0) last_loss=4.25366(0.573153) N=(580,2100,1680 189900)
[epoch_0]_1901   loss=4.318254 |g|=0.693	lr=9.99e-04 | 55.7%@S2  T=1.35s eta=22:09:04 | 80.9K token/s | 
[epoch_0]_1911   loss=4.300277 |g|=0.436	lr=9.99e-04 | 56.6%@S2  T=958.5ms eta=15:44:33 | 81.1K token/s | 
[epoch_0]_1921   loss=4.292185 |g|=0.423	lr=9.99e-04 | 57.4%@S2  T=962.2ms eta=15:47:57 | 81.3K token/s | 
[epoch_0]_1931   loss=4.274458 |g|=0.548	lr=9.99e-04 | 58.2%@S2  T=954.4ms eta=15:40:06 | 81.5K token/s | 
[epoch_0]_1941   loss=4.268871 |g|=0.451	lr=9.99e-04 | 59.0%@S2  T=950.9ms eta=15:36:31 | 81.8K token/s | 
[epoch_0]_1951   loss=4.331115 |g|=0.463	lr=9.99e-04 | 59.8%@S2  T=951.2ms eta=15:36:39 | 82.0K token/s | 
[epoch_0]_1961   loss=4.227863 |g|=0.492	lr=9.99e-04 | 60.6%@S2  T=948.2ms eta=15:33:32 | 82.2K token/s | 
[epoch_0]_1971   loss=4.234400 |g|=0.522	lr=9.99e-04 | 61.5%@S2  T=965.3ms eta=15:50:15 | 82.3K token/s | 
[epoch_0]_1981   loss=4.253819 |g|=0.489	lr=9.99e-04 | 62.3%@S2  T=950.2ms eta=15:35:15 | 82.5K token/s | 
[epoch_0]_1991   loss=4.238930 |g|=0.5	lr=9.99e-04 | 63.1%@S2  T=950.3ms eta=15:35:07 | 82.7K token/s | 
[Fuyou] head="1" update algorithm=4 t=2.06s
[eval] 
	 Loss@"edu_fineweb1B"=4.319(0.093) nBranch=1 nToken=4.01M best=4.4118(8) E2T=0.0107 T=13.5198(0)s x=0
	#4.31857±0.1016 tps=297K(4.01408M) a=[4.10281,4.55502] T=13.5198(sec)
[Section@2000] layer[12-18] tasks=15(nPassBack=0) last_loss=4.30783(0.311131) N=(580,2184,1764 199900)
[epoch_0]_2001   loss=4.314988 |g|=0.812	lr=9.99e-04 | 63.9%@S2  T=4.09s eta=2d 19:00:25 | 79.6K token/s | 
[epoch_0]_2011   loss=4.202273 |g|=0.507	lr=9.99e-04 | 64.7%@S2  T=952.6ms eta=15:37:07 | 79.9K token/s | 
[epoch_0]_2021   loss=4.200800 |g|=0.46	lr=9.99e-04 | 65.6%@S2  T=951.2ms eta=15:35:33 | 80.2K token/s | 
[epoch_0]_2031   loss=4.242046 |g|=0.458	lr=9.99e-04 | 66.4%@S2  T=950.1ms eta=15:34:21 | 80.5K token/s | 
[epoch_0]_2041   loss=4.283092 |g|=0.482	lr=9.99e-04 | 67.2%@S2  T=963.0ms eta=15:46:49 | 80.7K token/s | 
[epoch_0]_2051   loss=4.246298 |g|=0.512	lr=9.99e-04 | 68.0%@S2  T=955.4ms eta=15:39:14 | 81.0K token/s | 
[epoch_0]_2061   loss=4.206445 |g|=0.46	lr=9.99e-04 | 68.8%@S2  T=950.7ms eta=15:34:28 | 81.2K token/s | 
[epoch_0]_2071   loss=4.244316 |g|=0.595	lr=9.99e-04 | 69.7%@S2  T=956.4ms eta=15:39:53 | 81.5K token/s | 
[epoch_0]_2081   loss=4.276204 |g|=0.485	lr=9.99e-04 | 70.5%@S2  T=957.4ms eta=15:40:41 | 81.7K token/s | 
[epoch_0]_2091   loss=4.171860 |g|=0.518	lr=9.99e-04 | 71.3%@S2  T=961.2ms eta=15:44:16 | 81.8K token/s | 
[Fuyou] head="2" update algorithm=4 t=2.07s
[Section@2100] layer[18-24] tasks=15(nPassBack=0) last_loss=4.23027(0.31479) N=(580,2268,1848 209900)
[epoch_0]_2101   loss=4.283648 |g|=0.822	lr=9.98e-04 | 72.1%@S2  T=1.23s eta=20:05:47 | 81.1K token/s | 
[epoch_0]_2111   loss=4.290108 |g|=0.519	lr=9.98e-04 | 72.9%@S2  T=952.1ms eta=15:35:03 | 81.3K token/s | 
[epoch_0]_2121   loss=4.241678 |g|=0.454	lr=9.98e-04 | 73.8%@S2  T=962.9ms eta=15:45:27 | 81.5K token/s | 
[epoch_0]_2131   loss=4.109276 |g|=0.474	lr=9.98e-04 | 74.6%@S2  T=952.3ms eta=15:34:52 | 81.8K token/s | 
[epoch_0]_2141   loss=4.203327 |g|=0.488	lr=9.98e-04 | 75.4%@S2  T=959.7ms eta=15:41:58 | 81.9K token/s | 
[epoch_0]_2151   loss=4.134830 |g|=0.463	lr=9.98e-04 | 76.2%@S2  T=955.7ms eta=15:37:57 | 82.1K token/s | 
[epoch_0]_2161   loss=4.242964 |g|=0.505	lr=9.98e-04 | 77.0%@S2  T=956.4ms eta=15:38:25 | 82.3K token/s | 
[epoch_0]_2171   loss=4.197609 |g|=0.492	lr=9.98e-04 | 77.8%@S2  T=956.9ms eta=15:38:48 | 82.5K token/s | 
[epoch_0]_2181   loss=4.195662 |g|=0.445	lr=9.98e-04 | 78.7%@S2  T=950.2ms eta=15:32:05 | 82.6K token/s | 
[epoch_0]_2191   loss=4.124746 |g|=0.52	lr=9.98e-04 | 79.5%@S2  T=952.4ms eta=15:34:05 | 82.8K token/s | 
[Fuyou] head="3" update algorithm=4 t=2.06s
[eval] 
	 Loss@"edu_fineweb1B"=4.251(0.068) nBranch=1 nToken=4.01M best=4.3186(9) E2T=0.0605 T=13.5198(0)s x=0
	#4.25099±0.1006 tps=297K(4.01408M) a=[4.04085,4.48348] T=13.5198(sec)
[Section@2200] layer[24-30] tasks=15(nPassBack=0) last_loss=4.19053(0.199654) N=(580,2352,1932 219900)
[epoch_0]_2201   loss=4.152235 |g|=0.711	lr=9.98e-04 | 80.3%@S2  T=4.11s eta=2d 19:08:46 | 79.7K token/s | 
[epoch_0]_2211   loss=4.194200 |g|=0.531	lr=9.98e-04 | 81.1%@S2  T=954.0ms eta=15:35:16 | 80.0K token/s | 
[epoch_0]_2221   loss=4.134744 |g|=0.464	lr=9.98e-04 | 81.9%@S2  T=959.9ms eta=15:40:56 | 80.3K token/s | 
[epoch_0]_2231   loss=4.150601 |g|=0.437	lr=9.98e-04 | 82.8%@S2  T=955.3ms eta=15:36:15 | 80.5K token/s | 
[epoch_0]_2241   loss=4.185795 |g|=0.456	lr=9.98e-04 | 83.6%@S2  T=952.3ms eta=15:33:10 | 80.8K token/s | 
[epoch_0]_2251   loss=4.150743 |g|=0.466	lr=9.98e-04 | 84.4%@S2  T=949.2ms eta=15:29:59 | 81.1K token/s | 
[epoch_0]_2261   loss=4.191809 |g|=0.563	lr=9.98e-04 | 85.2%@S2  T=951.9ms eta=15:32:25 | 81.3K token/s | 
[epoch_0]_2271   loss=4.135527 |g|=0.47	lr=9.98e-04 | 86.0%@S2  T=959.7ms eta=15:39:57 | 81.5K token/s | 
[epoch_0]_2281   loss=4.128548 |g|=0.537	lr=9.98e-04 | 86.9%@S2  T=954.8ms eta=15:34:55 | 81.7K token/s | 
[epoch_0]_2291   loss=4.150017 |g|=0.506	lr=9.98e-04 | 87.7%@S2  T=946.7ms eta=15:26:53 | 82.0K token/s | 
[Fuyou] head="4" update algorithm=4 t=2.05s
[Section@2300] layer[30-36] tasks=15(nPassBack=0) last_loss=4.19043(0.142615) N=(580,2436,2016 229900)
[epoch_0]_2301   loss=4.128788 |g|=0.64	lr=9.98e-04 | 88.5%@S2  T=1.22s eta=19:58:41 | 81.2K token/s | 
[epoch_0]_2311   loss=4.215346 |g|=0.438	lr=9.98e-04 | 89.3%@S2  T=953.6ms eta=15:33:17 | 81.5K token/s | 
[epoch_0]_2321   loss=4.136772 |g|=0.435	lr=9.98e-04 | 90.1%@S2  T=951.2ms eta=15:30:47 | 81.7K token/s | 
[epoch_0]_2331   loss=4.153023 |g|=0.509	lr=9.98e-04 | 91.0%@S2  T=945.4ms eta=15:24:56 | 81.9K token/s | 
[epoch_0]_2341   loss=4.191547 |g|=0.49	lr=9.98e-04 | 91.8%@S2  T=949.5ms eta=15:28:48 | 82.2K token/s | 
[epoch_0]_2351   loss=4.178286 |g|=0.506	lr=9.98e-04 | 92.6%@S2  T=964.3ms eta=15:43:07 | 82.3K token/s | 
[epoch_0]_2361   loss=4.107475 |g|=0.42	lr=9.98e-04 | 93.4%@S2  T=955.6ms eta=15:34:27 | 82.5K token/s | 
[epoch_0]_2371   loss=4.097345 |g|=0.449	lr=9.98e-04 | 94.2%@S2  T=949.4ms eta=15:28:16 | 82.7K token/s | 
[epoch_0]_2381   loss=4.119100 |g|=0.447	lr=9.98e-04 | 95.1%@S2  T=951.7ms eta=15:30:20 | 82.8K token/s | 
[epoch_0]_2391   loss=4.202711 |g|=0.452	lr=9.98e-04 | 95.9%@S2  T=954.5ms eta=15:32:53 | 83.0K token/s | 
[Fuyou] head="5" update algorithm=4 t=2.08s
[eval] 
	 Loss@"edu_fineweb1B"=4.190(0.061) nBranch=1 nToken=4.01M best=4.2510(10) E2T=0.0521 T=13.4543(0)s x=0
	#4.19013±0.1018 tps=298K(4.01408M) a=[3.97284,4.42636] T=13.4543(sec)
[Section@2400] layer[0-6] tasks=15(nPassBack=0) last_loss=4.13805(0.177251) N=(580,2520,2100 239900)
[epoch_0]_2401   loss=4.169858 |g|=0.612	lr=9.98e-04 | 96.7%@S2  T=4.06s eta=2d 18:04:51 | 79.8K token/s | 
[epoch_0]_2411   loss=4.071496 |g|=0.487	lr=9.98e-04 | 97.5%@S2  T=951.3ms eta=15:29:31 | 80.2K token/s | 
[epoch_0]_2421   loss=4.106299 |g|=0.427	lr=9.98e-04 | 98.3%@S2  T=949.3ms eta=15:27:20 | 80.5K token/s | 
[epoch_0]_2431   loss=4.128015 |g|=0.512	lr=9.98e-04 | 99.1%@S2  T=955.2ms eta=15:32:56 | 80.7K token/s | 
[epoch_0]_2441   loss=4.046181 |g|=0.504	lr=9.98e-04 | 100.0%@S2  T=949.3ms eta=15:27:00 | 81.0K token/s | 
-------- End of shard_2@"./Datasets/edu_fineweb1B/edu_fineweb_train_000002.bin"-------- 
[shard-3]@"./Datasets/edu_fineweb1B/edu_fineweb_train_000003.bin": tokens=100(M) nShardSamples=1220(292968) 
[epoch_0]_2451   loss=4.198246 |g|=0.546	lr=9.98e-04 | 0.8%@S3  T=950.2ms eta=15:27:46 | 81.3K token/s | 
[epoch_0]_2461   loss=4.243085 |g|=0.472	lr=9.98e-04 | 1.6%@S3  T=953.0ms eta=15:30:19 | 81.5K token/s | 
[epoch_0]_2471   loss=4.107122 |g|=0.48	lr=9.98e-04 | 2.4%@S3  T=951.4ms eta=15:28:37 | 81.7K token/s | 
[epoch_0]_2481   loss=4.139720 |g|=0.421	lr=9.98e-04 | 3.2%@S3  T=949.8ms eta=15:26:57 | 82.0K token/s | 
[epoch_0]_2491   loss=4.185444 |g|=0.46	lr=9.98e-04 | 4.1%@S3  T=949.2ms eta=15:26:12 | 82.2K token/s | 
[Fuyou] head="0" update algorithm=4 t=2.18s
[Section@2500] layer[6-12] tasks=15(nPassBack=0) last_loss=4.16381(0.0898514) N=(580,2604,2184 249900)
[epoch_0]_2501   loss=4.189446 |g|=0.636	lr=9.98e-04 | 4.9%@S3  T=1.23s eta=20:02:02 | 81.4K token/s | 
[epoch_0]_2511   loss=4.180916 |g|=0.438	lr=9.98e-04 | 5.7%@S3  T=942.3ms eta=15:19:06 | 81.7K token/s | 
[epoch_0]_2521   loss=4.148018 |g|=0.536	lr=9.98e-04 | 6.5%@S3  T=943.0ms eta=15:19:36 | 81.9K token/s | 
[epoch_0]_2531   loss=4.175041 |g|=0.428	lr=9.98e-04 | 7.3%@S3  T=945.4ms eta=15:21:48 | 82.2K token/s | 
[epoch_0]_2541   loss=4.164645 |g|=0.432	lr=9.97e-04 | 8.2%@S3  T=947.1ms eta=15:23:16 | 82.4K token/s | 
[epoch_0]_2551   loss=4.104159 |g|=0.422	lr=9.97e-04 | 9.0%@S3  T=950.1ms eta=15:26:06 | 82.6K token/s | 
[epoch_0]_2561   loss=4.115002 |g|=0.549	lr=9.97e-04 | 9.8%@S3  T=950.9ms eta=15:26:44 | 82.8K token/s | 
[epoch_0]_2571   loss=4.183552 |g|=0.548	lr=9.97e-04 | 10.6%@S3  T=963.6ms eta=15:38:56 | 82.9K token/s | 
[epoch_0]_2581   loss=4.118204 |g|=0.484	lr=9.97e-04 | 11.4%@S3  T=947.2ms eta=15:22:49 | 83.0K token/s | 
[epoch_0]_2591   loss=4.071671 |g|=0.474	lr=9.97e-04 | 12.3%@S3  T=950.9ms eta=15:26:15 | 83.2K token/s | 
[Fuyou] head="1" update algorithm=4 t=2.04s
[eval] 
	 Loss@"edu_fineweb1B"=4.140(0.051) nBranch=1 nToken=4.01M best=4.1901(11) E2T=0.0504 T=13.4686(0)s x=0
	#4.13952±0.1014 tps=298K(4.01408M) a=[3.92178,4.38193] T=13.4686(sec)
[Section@2600] layer[12-18] tasks=15(nPassBack=0) last_loss=4.0891(0.218725) N=(580,2688,2268 259900)
[epoch_0]_2601   loss=4.107992 |g|=0.588	lr=9.97e-04 | 13.1%@S3  T=4.06s eta=2d 17:56:36 | 80.0K token/s | 
[epoch_0]_2611   loss=4.104125 |g|=0.464	lr=9.97e-04 | 13.9%@S3  T=957.5ms eta=15:32:19 | 80.3K token/s | 
[epoch_0]_2621   loss=4.236599 |g|=0.461	lr=9.97e-04 | 14.7%@S3  T=947.6ms eta=15:22:31 | 80.6K token/s | 
[epoch_0]_2631   loss=4.145483 |g|=0.399	lr=9.97e-04 | 15.5%@S3  T=947.1ms eta=15:21:53 | 80.9K token/s | 
[epoch_0]_2641   loss=4.081631 |g|=0.433	lr=9.97e-04 | 16.4%@S3  T=953.9ms eta=15:28:21 | 81.2K token/s | 
[epoch_0]_2651   loss=4.115764 |g|=0.486	lr=9.97e-04 | 17.2%@S3  T=949.6ms eta=15:24:02 | 81.4K token/s | 
[epoch_0]_2661   loss=4.052519 |g|=0.458	lr=9.97e-04 | 18.0%@S3  T=951.0ms eta=15:25:12 | 81.7K token/s | 
[epoch_0]_2671   loss=4.089158 |g|=0.411	lr=9.97e-04 | 18.8%@S3  T=968.0ms eta=15:41:34 | 81.8K token/s | 
[epoch_0]_2681   loss=4.056461 |g|=0.477	lr=9.97e-04 | 19.6%@S3  T=953.3ms eta=15:27:08 | 82.0K token/s | 
[epoch_0]_2691   loss=4.108475 |g|=0.471	lr=9.97e-04 | 20.4%@S3  T=957.1ms eta=15:30:42 | 82.2K token/s | 
[Fuyou] head="2" update algorithm=4 t=2.07s
[Section@2700] layer[18-24] tasks=15(nPassBack=0) last_loss=4.07322(0.157053) N=(580,2772,2352 269900)
[epoch_0]_2701   loss=4.139393 |g|=0.861	lr=9.97e-04 | 21.3%@S3  T=1.22s eta=19:44:45 | 81.4K token/s | 
[epoch_0]_2711   loss=4.092021 |g|=0.508	lr=9.97e-04 | 22.1%@S3  T=944.3ms eta=15:17:57 | 81.7K token/s | 
[epoch_0]_2721   loss=4.149065 |g|=0.506	lr=9.97e-04 | 22.9%@S3  T=950.9ms eta=15:24:12 | 81.9K token/s | 
[epoch_0]_2731   loss=4.069090 |g|=0.547	lr=9.97e-04 | 23.7%@S3  T=948.4ms eta=15:21:33 | 82.2K token/s | 
[epoch_0]_2741   loss=4.071680 |g|=0.443	lr=9.97e-04 | 24.5%@S3  T=949.7ms eta=15:22:44 | 82.4K token/s | 
[epoch_0]_2751   loss=4.115049 |g|=0.548	lr=9.97e-04 | 25.4%@S3  T=957.5ms eta=15:30:04 | 82.5K token/s | 
[epoch_0]_2761   loss=4.077086 |g|=0.449	lr=9.97e-04 | 26.2%@S3  T=955.4ms eta=15:27:57 | 82.7K token/s | 
[epoch_0]_2771   loss=4.083091 |g|=0.477	lr=9.97e-04 | 27.0%@S3  T=947.2ms eta=15:19:46 | 82.9K token/s | 
[epoch_0]_2781   loss=4.036896 |g|=0.49	lr=9.97e-04 | 27.8%@S3  T=944.2ms eta=15:16:42 | 83.1K token/s | 
[epoch_0]_2791   loss=4.096756 |g|=0.481	lr=9.97e-04 | 28.6%@S3  T=943.7ms eta=15:16:07 | 83.3K token/s | 
[Fuyou] head="3" update algorithm=4 t=2.20s
[eval] 
	 Loss@"edu_fineweb1B"=4.093(0.046) nBranch=1 nToken=4.01M best=4.1395(12) E2T=0.0486 T=13.4341(0)s x=0
	#4.09312±0.1029 tps=299K(4.01408M) a=[3.88207,4.32732] T=13.4341(sec)
[Section@2800] layer[24-30] tasks=15(nPassBack=0) last_loss=4.04453(0.146001) N=(580,2856,2436 279900)
[epoch_0]_2801   loss=4.039663 |g|=0.649	lr=9.97e-04 | 29.5%@S3  T=4.06s eta=2d 17:44:24 | 80.1K token/s | 
[epoch_0]_2811   loss=4.009317 |g|=0.545	lr=9.97e-04 | 30.3%@S3  T=956.8ms eta=15:28:26 | 80.4K token/s | 
[epoch_0]_2821   loss=4.075193 |g|=0.422	lr=9.97e-04 | 31.1%@S3  T=958.6ms eta=15:30:01 | 80.6K token/s | 
[epoch_0]_2831   loss=4.044584 |g|=0.476	lr=9.97e-04 | 31.9%@S3  T=952.1ms eta=15:23:35 | 80.9K token/s | 
[epoch_0]_2841   loss=4.111593 |g|=0.428	lr=9.97e-04 | 32.7%@S3  T=955.2ms eta=15:26:26 | 81.1K token/s | 
[epoch_0]_2851   loss=4.115444 |g|=0.455	lr=9.97e-04 | 33.6%@S3  T=953.1ms eta=15:24:14 | 81.4K token/s | 
[epoch_0]_2861   loss=4.082432 |g|=0.469	lr=9.97e-04 | 34.4%@S3  T=951.2ms eta=15:22:14 | 81.6K token/s | 
[epoch_0]_2871   loss=4.056233 |g|=0.463	lr=9.97e-04 | 35.2%@S3  T=969.1ms eta=15:39:29 | 81.8K token/s | 
[epoch_0]_2881   loss=4.058376 |g|=0.454	lr=9.97e-04 | 36.0%@S3  T=954.0ms eta=15:24:39 | 82.0K token/s | 
[epoch_0]_2891   loss=4.023475 |g|=0.551	lr=9.96e-04 | 36.8%@S3  T=955.3ms eta=15:25:45 | 82.2K token/s | 
[Fuyou] head="4" update algorithm=4 t=2.04s
[Section@2900] layer[30-36] tasks=15(nPassBack=0) last_loss=4.04101(0.14942) N=(580,2940,2520 289900)
[epoch_0]_2901   loss=4.014706 |g|=0.717	lr=9.96e-04 | 37.7%@S3  T=1.26s eta=20:16:37 | 81.3K token/s | 
[epoch_0]_2911   loss=3.971173 |g|=0.436	lr=9.96e-04 | 38.5%@S3  T=950.0ms eta=15:20:16 | 81.6K token/s | 
[epoch_0]_2921   loss=4.060246 |g|=0.471	lr=9.96e-04 | 39.3%@S3  T=961.8ms eta=15:31:36 | 81.7K token/s | 
[epoch_0]_2931   loss=4.037664 |g|=0.495	lr=9.96e-04 | 40.1%@S3  T=949.7ms eta=15:19:42 | 82.0K token/s | 
[epoch_0]_2941   loss=3.995676 |g|=0.444	lr=9.96e-04 | 40.9%@S3  T=958.0ms eta=15:27:34 | 82.1K token/s | 
[epoch_0]_2951   loss=4.113289 |g|=0.494	lr=9.96e-04 | 41.7%@S3  T=959.7ms eta=15:29:00 | 82.3K token/s | 
[epoch_0]_2961   loss=4.101019 |g|=0.398	lr=9.96e-04 | 42.6%@S3  T=956.9ms eta=15:26:09 | 82.5K token/s | 
[epoch_0]_2971   loss=4.004947 |g|=0.48	lr=9.96e-04 | 43.4%@S3  T=959.7ms eta=15:28:46 | 82.6K token/s | 
[epoch_0]_2981   loss=4.056184 |g|=0.462	lr=9.96e-04 | 44.2%@S3  T=957.7ms eta=15:26:39 | 82.8K token/s | 
[epoch_0]_2991   loss=4.094461 |g|=0.467	lr=9.96e-04 | 45.0%@S3  T=954.0ms eta=15:22:54 | 82.9K token/s | 
[Fuyou] head="5" update algorithm=4 t=2.06s
[eval] 
	 Loss@"edu_fineweb1B"=4.057(0.036) nBranch=1 nToken=4.01M best=4.0931(13) E2T=0.0637 T=13.4956(0)s x=0
	#4.05697±0.1034 tps=297K(4.01408M) a=[3.83958,4.29881] T=13.4956(sec)
[Section@3000] layer[0-6] tasks=15(nPassBack=0) last_loss=3.99327(0.144778) N=(580,3024,2604 299900)
[epoch_0]_3001   loss=4.093454 |g|=0.497	lr=9.96e-04 | 45.8%@S3  T=4.07s eta=2d 17:37:02 | 79.8K token/s | 
[epoch_0]_3011   loss=3.999584 |g|=0.499	lr=9.96e-04 | 46.7%@S3  T=956.8ms eta=15:25:18 | 80.1K token/s | 
[epoch_0]_3021   loss=4.032965 |g|=0.444	lr=9.96e-04 | 47.5%@S3  T=965.3ms eta=15:33:20 | 80.3K token/s | 
[epoch_0]_3031   loss=4.042300 |g|=0.412	lr=9.96e-04 | 48.3%@S3  T=956.6ms eta=15:24:48 | 80.6K token/s | 
[epoch_0]_3041   loss=4.027511 |g|=0.453	lr=9.96e-04 | 49.1%@S3  T=955.3ms eta=15:23:22 | 80.8K token/s | 
[epoch_0]_3051   loss=3.999086 |g|=0.455	lr=9.96e-04 | 49.9%@S3  T=959.9ms eta=15:27:37 | 81.1K token/s | 
[epoch_0]_3061   loss=4.029402 |g|=0.484	lr=9.96e-04 | 50.8%@S3  T=957.5ms eta=15:25:08 | 81.3K token/s | 
[epoch_0]_3071   loss=4.037206 |g|=0.442	lr=9.96e-04 | 51.6%@S3  T=961.5ms eta=15:28:53 | 81.5K token/s | 
[epoch_0]_3081   loss=3.987216 |g|=0.465	lr=9.96e-04 | 52.4%@S3  T=950.1ms eta=15:17:43 | 81.7K token/s | 
[epoch_0]_3091   loss=3.995839 |g|=0.431	lr=9.96e-04 | 53.2%@S3  T=970.8ms eta=15:37:31 | 81.9K token/s | 
[Fuyou] head="0" update algorithm=4 t=2.25s
[Section@3100] layer[6-12] tasks=15(nPassBack=0) last_loss=4.0147(0.149116) N=(580,3108,2688 309900)
[epoch_0]_3101   loss=3.955497 |g|=0.48	lr=9.96e-04 | 54.0%@S3  T=1.25s eta=20:07:10 | 81.0K token/s | 
[epoch_0]_3111   loss=4.001082 |g|=0.435	lr=9.96e-04 | 54.9%@S3  T=949.2ms eta=15:16:22 | 81.3K token/s | 
[epoch_0]_3121   loss=4.064181 |g|=0.516	lr=9.96e-04 | 55.7%@S3  T=955.7ms eta=15:22:26 | 81.5K token/s | 
[epoch_0]_3131   loss=4.009765 |g|=0.451	lr=9.96e-04 | 56.5%@S3  T=949.3ms eta=15:16:05 | 81.8K token/s | 
[epoch_0]_3141   loss=4.044899 |g|=0.46	lr=9.96e-04 | 57.3%@S3  T=953.3ms eta=15:19:51 | 82.0K token/s | 
[epoch_0]_3151   loss=4.041147 |g|=0.393	lr=9.96e-04 | 58.1%@S3  T=946.1ms eta=15:12:42 | 82.2K token/s | 
[epoch_0]_3161   loss=3.995533 |g|=0.419	lr=9.96e-04 | 59.0%@S3  T=948.9ms eta=15:15:18 | 82.4K token/s | 
[epoch_0]_3171   loss=4.012453 |g|=0.426	lr=9.96e-04 | 59.8%@S3  T=948.0ms eta=15:14:12 | 82.6K token/s | 
[epoch_0]_3181   loss=3.995443 |g|=0.458	lr=9.96e-04 | 60.6%@S3  T=965.2ms eta=15:30:41 | 82.7K token/s | 
[epoch_0]_3191   loss=3.998364 |g|=0.411	lr=9.96e-04 | 61.4%@S3  T=957.2ms eta=15:22:46 | 82.9K token/s | 
[Fuyou] head="1" update algorithm=4 t=2.05s
[eval] 
	 Loss@"edu_fineweb1B"=4.023(0.034) nBranch=1 nToken=4.01M best=4.0570(14) E2T=-0.0466 T=13.4038(0)s x=0
	#4.02326±0.1038 tps=299K(4.01408M) a=[3.81436,4.27207] T=13.4038(sec)
[Section@3200] layer[12-18] tasks=15(nPassBack=0) last_loss=4.06984(0.0192599) N=(580,3192,2772 319900)
[epoch_0]_3201   loss=4.055439 |g|=0.74	lr=9.95e-04 | 62.2%@S3  T=4.16s eta=2d 18:52:14 | 79.7K token/s | 
[epoch_0]_3211   loss=4.054926 |g|=0.437	lr=9.95e-04 | 63.0%@S3  T=946.6ms eta=15:12:13 | 80.0K token/s | 
[epoch_0]_3221   loss=3.950418 |g|=0.504	lr=9.95e-04 | 63.9%@S3  T=944.6ms eta=15:10:12 | 80.4K token/s | 
[epoch_0]_3231   loss=4.083899 |g|=0.437	lr=9.95e-04 | 64.7%@S3  T=950.2ms eta=15:15:25 | 80.7K token/s | 
[epoch_0]_3241   loss=3.988586 |g|=0.491	lr=9.95e-04 | 65.5%@S3  T=959.7ms eta=15:24:23 | 80.9K token/s | 
[epoch_0]_3251   loss=3.994632 |g|=0.427	lr=9.95e-04 | 66.3%@S3  T=951.9ms eta=15:16:46 | 81.2K token/s | 
[epoch_0]_3261   loss=3.927558 |g|=0.427	lr=9.95e-04 | 67.1%@S3  T=951.9ms eta=15:16:35 | 81.4K token/s | 
[epoch_0]_3271   loss=3.988196 |g|=0.424	lr=9.95e-04 | 68.0%@S3  T=951.4ms eta=15:15:56 | 81.6K token/s | 
[epoch_0]_3281   loss=4.003203 |g|=0.507	lr=9.95e-04 | 68.8%@S3  T=970.4ms eta=15:34:01 | 81.8K token/s | 
[epoch_0]_3291   loss=3.995055 |g|=0.464	lr=9.95e-04 | 69.6%@S3  T=962.2ms eta=15:26:03 | 81.9K token/s | 
[Fuyou] head="2" update algorithm=4 t=2.00s
[Section@3300] layer[18-24] tasks=15(nPassBack=0) last_loss=3.97889(0.0943315) N=(580,3276,2856 329900)
[epoch_0]_3301   loss=4.005695 |g|=0.655	lr=9.95e-04 | 70.4%@S3  T=1.21s eta=19:26:23 | 81.2K token/s | 
[epoch_0]_3311   loss=3.953427 |g|=0.496	lr=9.95e-04 | 71.2%@S3  T=955.9ms eta=15:19:35 | 81.5K token/s | 
[epoch_0]_3321   loss=3.986418 |g|=0.469	lr=9.95e-04 | 72.1%@S3  T=954.6ms eta=15:18:14 | 81.7K token/s | 
[epoch_0]_3331   loss=3.934468 |g|=0.472	lr=9.95e-04 | 72.9%@S3  T=953.5ms eta=15:16:58 | 81.9K token/s | 
[epoch_0]_3341   loss=3.928447 |g|=0.386	lr=9.95e-04 | 73.7%@S3  T=949.1ms eta=15:12:39 | 82.1K token/s | 
[epoch_0]_3351   loss=3.968319 |g|=0.43	lr=9.95e-04 | 74.5%@S3  T=957.6ms eta=15:20:40 | 82.3K token/s | 
[epoch_0]_3361   loss=3.960178 |g|=0.46	lr=9.95e-04 | 75.3%@S3  T=960.2ms eta=15:22:56 | 82.4K token/s | 
[epoch_0]_3371   loss=3.988559 |g|=0.476	lr=9.95e-04 | 76.2%@S3  T=952.9ms eta=15:15:50 | 82.6K token/s | 
[epoch_0]_3381   loss=3.998271 |g|=0.462	lr=9.95e-04 | 77.0%@S3  T=948.7ms eta=15:11:34 | 82.8K token/s | 
[epoch_0]_3391   loss=3.969865 |g|=0.5	lr=9.95e-04 | 77.8%@S3  T=949.7ms eta=15:12:25 | 83.0K token/s | 
[Fuyou] head="3" update algorithm=4 t=2.07s
[eval] 
	 Loss@"edu_fineweb1B"=3.995(0.028) nBranch=1 nToken=4.01M best=4.0233(15) E2T=-0.00222 T=13.4427(0)s x=0
	#3.99478±0.1041 tps=299K(4.01408M) a=[3.79247,4.24044] T=13.4427(sec)
[Section@3400] layer[24-30] tasks=15(nPassBack=0) last_loss=3.997(0.047528) N=(580,3360,2940 339900)
[epoch_0]_3401   loss=4.028950 |g|=0.614	lr=9.95e-04 | 78.6%@S3  T=4.06s eta=2d 17:03:50 | 79.8K token/s | 
[epoch_0]_3411   loss=3.989931 |g|=0.427	lr=9.95e-04 | 79.4%@S3  T=956.4ms eta=15:18:31 | 80.1K token/s | 
[epoch_0]_3421   loss=3.967964 |g|=0.43	lr=9.95e-04 | 80.3%@S3  T=963.4ms eta=15:25:07 | 80.4K token/s | 
[epoch_0]_3431   loss=3.934397 |g|=0.421	lr=9.95e-04 | 81.1%@S3  T=951.0ms eta=15:12:58 | 80.7K token/s | 
[epoch_0]_3441   loss=4.032826 |g|=0.561	lr=9.95e-04 | 81.9%@S3  T=953.9ms eta=15:15:40 | 80.9K token/s | 
[epoch_0]_3451   loss=3.931987 |g|=0.457	lr=9.95e-04 | 82.7%@S3  T=959.7ms eta=15:21:05 | 81.1K token/s | 
[epoch_0]_3461   loss=3.891279 |g|=0.541	lr=9.95e-04 | 83.5%@S3  T=957.8ms eta=15:19:02 | 81.4K token/s | 
[epoch_0]_3471   loss=3.975323 |g|=0.485	lr=9.94e-04 | 84.3%@S3  T=958.4ms eta=15:19:26 | 81.6K token/s | 
[epoch_0]_3481   loss=3.911537 |g|=0.433	lr=9.94e-04 | 85.2%@S3  T=966.1ms eta=15:26:43 | 81.7K token/s | 
[epoch_0]_3491   loss=3.995758 |g|=0.473	lr=9.94e-04 | 86.0%@S3  T=953.1ms eta=15:14:06 | 81.9K token/s | 
[Fuyou] head="4" update algorithm=4 t=2.05s
[Section@3500] layer[30-36] tasks=15(nPassBack=0) last_loss=3.91737(0.123639) N=(580,3444,3024 349900)
[epoch_0]_3501   loss=3.970164 |g|=0.622	lr=9.94e-04 | 86.8%@S3  T=1.23s eta=19:37:11 | 81.2K token/s | 
[epoch_0]_3511   loss=3.929400 |g|=0.437	lr=9.94e-04 | 87.6%@S3  T=972.6ms eta=15:32:25 | 81.3K token/s | 
[epoch_0]_3521   loss=3.910015 |g|=0.452	lr=9.94e-04 | 88.4%@S3  T=953.7ms eta=15:14:09 | 81.6K token/s | 
[epoch_0]_3531   loss=3.920860 |g|=0.472	lr=9.94e-04 | 89.3%@S3  T=958.9ms eta=15:19:03 | 81.7K token/s | 
[epoch_0]_3541   loss=3.990181 |g|=0.487	lr=9.94e-04 | 90.1%@S3  T=967.1ms eta=15:26:44 | 81.9K token/s | 
[epoch_0]_3551   loss=3.993241 |g|=0.475	lr=9.94e-04 | 90.9%@S3  T=960.4ms eta=15:20:07 | 82.1K token/s | 
[epoch_0]_3561   loss=3.882202 |g|=0.478	lr=9.94e-04 | 91.7%@S3  T=956.1ms eta=15:15:50 | 82.2K token/s | 
[epoch_0]_3571   loss=4.054548 |g|=0.511	lr=9.94e-04 | 92.5%@S3  T=960.4ms eta=15:19:49 | 82.4K token/s | 
[epoch_0]_3581   loss=3.863089 |g|=0.576	lr=9.94e-04 | 93.4%@S3  T=968.0ms eta=15:26:56 | 82.5K token/s | 
[epoch_0]_3591   loss=3.955505 |g|=0.49	lr=9.94e-04 | 94.2%@S3  T=961.8ms eta=15:20:48 | 82.6K token/s | 
[Fuyou] head="5" update algorithm=4 t=1.99s
[eval] 
	 Loss@"edu_fineweb1B"=3.966(0.029) nBranch=1 nToken=4.01M best=3.9948(16) E2T=0.0254 T=13.4822(0)s x=0
	#3.96574±0.1046 tps=298K(4.01408M) a=[3.75822,4.21656] T=13.4822(sec)
[Section@3600] layer[0-6] tasks=15(nPassBack=0) last_loss=3.9403(0.0529673) N=(580,3528,3108 359900)
[epoch_0]_3601   loss=3.915681 |g|=0.472	lr=9.94e-04 | 95.0%@S3  T=4.07s eta=2d 16:57:38 | 79.5K token/s | 
[epoch_0]_3611   loss=3.919341 |g|=0.476	lr=9.94e-04 | 95.8%@S3  T=959.6ms eta=15:18:25 | 79.8K token/s | 
[epoch_0]_3621   loss=3.914423 |g|=0.469	lr=9.94e-04 | 96.6%@S3  T=955.7ms eta=15:14:27 | 80.1K token/s | 
[epoch_0]_3631   loss=3.940417 |g|=0.511	lr=9.94e-04 | 97.5%@S3  T=964.1ms eta=15:22:21 | 80.3K token/s | 
[epoch_0]_3641   loss=3.900432 |g|=0.389	lr=9.94e-04 | 98.3%@S3  T=956.5ms eta=15:14:54 | 80.6K token/s | 
[epoch_0]_3651   loss=3.935213 |g|=0.486	lr=9.94e-04 | 99.1%@S3  T=955.3ms eta=15:13:37 | 80.9K token/s | 
[epoch_0]_3661   loss=3.895667 |g|=0.598	lr=9.94e-04 | 99.9%@S3  T=960.6ms eta=15:18:33 | 81.1K token/s | 
[epoch_0]_3662   loss=3.932211 |g|=0.435	lr=9.94e-04 | 100.0%@S3  T=963.3ms eta=15:21:05 | 81.3K token/s | 
-------- End of shard_3@"./Datasets/edu_fineweb1B/edu_fineweb_train_000003.bin"-------- 
[shard-4]@"./Datasets/edu_fineweb1B/edu_fineweb_train_000004.bin": tokens=100(M) nShardSamples=1220(390624) 
[epoch_0]_3671   loss=3.856176 |g|=0.439	lr=9.94e-04 | 0.7%@S4  T=950.7ms eta=15:08:56 | 81.5K token/s | 
[epoch_0]_3681   loss=3.854560 |g|=0.466	lr=9.94e-04 | 1.5%@S4  T=966.1ms eta=15:23:32 | 81.7K token/s | 
[epoch_0]_3691   loss=3.835090 |g|=0.506	lr=9.94e-04 | 2.4%@S4  T=971.9ms eta=15:28:52 | 81.8K token/s | 
[Fuyou] head="0" update algorithm=4 t=2.05s
[Section@3700] layer[6-12] tasks=15(nPassBack=0) last_loss=3.80871(0.205982) N=(580,3612,3192 369900)
[epoch_0]_3701   loss=3.821703 |g|=0.508	lr=9.94e-04 | 3.2%@S4  T=1.23s eta=19:34:43 | 81.1K token/s | 
[epoch_0]_3711   loss=3.821100 |g|=0.423	lr=9.94e-04 | 4.0%@S4  T=952.6ms eta=15:10:06 | 81.3K token/s | 
[epoch_0]_3721   loss=3.955643 |g|=0.467	lr=9.93e-04 | 4.8%@S4  T=956.0ms eta=15:13:13 | 81.5K token/s | 
[epoch_0]_3731   loss=3.852682 |g|=0.536	lr=9.93e-04 | 5.6%@S4  T=950.4ms eta=15:07:42 | 81.8K token/s | 
[epoch_0]_3741   loss=3.807956 |g|=0.432	lr=9.93e-04 | 6.5%@S4  T=957.4ms eta=15:14:13 | 82.0K token/s | 
[epoch_0]_3751   loss=3.844257 |g|=0.495	lr=9.93e-04 | 7.3%@S4  T=952.9ms eta=15:09:43 | 82.2K token/s | 
[epoch_0]_3761   loss=3.856559 |g|=0.453	lr=9.93e-04 | 8.1%@S4  T=969.2ms eta=15:25:11 | 82.3K token/s | 
[epoch_0]_3771   loss=3.852584 |g|=0.597	lr=9.93e-04 | 8.9%@S4  T=951.9ms eta=15:08:30 | 82.5K token/s | 
[epoch_0]_3781   loss=3.890877 |g|=0.455	lr=9.93e-04 | 9.7%@S4  T=956.5ms eta=15:12:45 | 82.6K token/s | 
[epoch_0]_3791   loss=3.872591 |g|=0.485	lr=9.93e-04 | 10.6%@S4  T=958.6ms eta=15:14:33 | 82.8K token/s | 
[Fuyou] head="1" update algorithm=4 t=2.05s
[eval] 
	 Loss@"edu_fineweb1B"=3.959(0.0065) nBranch=1 nToken=4.01M best=3.9657(17) E2T=0.116 T=13.4977(0)s x=0
	#3.95929±0.1071 tps=297K(4.01408M) a=[3.74383,4.21963] T=13.4977(sec)
[Section@3800] layer[12-18] tasks=15(nPassBack=0) last_loss=3.84344(0.226402) N=(580,3696,3276 379900)
[epoch_0]_3801   loss=3.898661 |g|=0.633	lr=9.93e-04 | 11.4%@S4  T=4.09s eta=2d 17:01:00 | 79.6K token/s | 
[epoch_0]_3811   loss=3.862500 |g|=0.455	lr=9.93e-04 | 12.2%@S4  T=961.6ms eta=15:17:04 | 79.9K token/s | 
[epoch_0]_3821   loss=3.898434 |g|=0.471	lr=9.93e-04 | 13.0%@S4  T=952.6ms eta=15:08:20 | 80.2K token/s | 
[epoch_0]_3831   loss=3.806731 |g|=0.432	lr=9.93e-04 | 13.8%@S4  T=956.6ms eta=15:12:00 | 80.5K token/s | 
[epoch_0]_3841   loss=3.829768 |g|=0.459	lr=9.93e-04 | 14.7%@S4  T=960.8ms eta=15:15:51 | 80.7K token/s | 
[epoch_0]_3851   loss=3.777881 |g|=0.471	lr=9.93e-04 | 15.5%@S4  T=964.1ms eta=15:18:48 | 80.9K token/s | 
[epoch_0]_3861   loss=3.786095 |g|=0.441	lr=9.93e-04 | 16.3%@S4  T=953.1ms eta=15:08:14 | 81.2K token/s | 
[epoch_0]_3871   loss=3.799562 |g|=0.517	lr=9.93e-04 | 17.1%@S4  T=959.4ms eta=15:14:04 | 81.4K token/s | 
[epoch_0]_3881   loss=3.869459 |g|=0.521	lr=9.93e-04 | 17.9%@S4  T=960.7ms eta=15:15:07 | 81.6K token/s | 
[epoch_0]_3891   loss=3.841584 |g|=0.473	lr=9.93e-04 | 18.8%@S4  T=952.9ms eta=15:07:32 | 81.8K token/s | 
[Fuyou] head="2" update algorithm=4 t=2.00s
[Section@3900] layer[18-24] tasks=15(nPassBack=0) last_loss=3.88105(0.0978382) N=(580,3780,3360 389900)
[epoch_0]_3901   loss=3.910788 |g|=0.535	lr=9.93e-04 | 19.6%@S4  T=1.32s eta=20:57:26 | 80.8K token/s | 
[epoch_0]_3911   loss=3.870706 |g|=0.456	lr=9.93e-04 | 20.4%@S4  T=956.7ms eta=15:10:51 | 81.1K token/s | 
[epoch_0]_3921   loss=3.804025 |g|=0.387	lr=9.93e-04 | 21.2%@S4  T=964.0ms eta=15:17:39 | 81.3K token/s | 
[epoch_0]_3931   loss=3.849112 |g|=0.425	lr=9.93e-04 | 22.0%@S4  T=959.1ms eta=15:12:46 | 81.5K token/s | 
[epoch_0]_3941   loss=3.858001 |g|=0.432	lr=9.93e-04 | 22.8%@S4  T=962.9ms eta=15:16:16 | 81.6K token/s | 
[epoch_0]_3951   loss=3.902765 |g|=0.556	lr=9.93e-04 | 23.7%@S4  T=963.1ms eta=15:16:19 | 81.8K token/s | 
[epoch_0]_3961   loss=3.825838 |g|=0.505	lr=9.92e-04 | 24.5%@S4  T=960.1ms eta=15:13:18 | 82.0K token/s | 
[epoch_0]_3971   loss=3.843891 |g|=0.46	lr=9.92e-04 | 25.3%@S4  T=962.0ms eta=15:14:55 | 82.1K token/s | 
[epoch_0]_3981   loss=3.794053 |g|=0.587	lr=9.92e-04 | 26.1%@S4  T=968.1ms eta=15:20:35 | 82.3K token/s | 
[epoch_0]_3991   loss=3.886812 |g|=0.462	lr=9.92e-04 | 26.9%@S4  T=959.8ms eta=15:12:31 | 82.4K token/s | 
[Fuyou] head="3" update algorithm=4 t=2.07s
[eval] 
	 Loss@"edu_fineweb1B"=3.941(0.019) nBranch=1 nToken=4.01M best=3.9593(18) E2T=0.0818 T=13.4952(0)s x=0
	#3.94059±0.1093 tps=297K(4.01408M) a=[3.72354,4.2034] T=13.4952(sec)
[Section@4000] layer[24-30] tasks=15(nPassBack=0) last_loss=3.85881(0.138197) N=(580,3864,3444 399900)
[epoch_0]_4001   loss=3.840401 |g|=0.578	lr=9.92e-04 | 27.8%@S4  T=4.09s eta=2d 16:50:35 | 79.3K token/s | 
[epoch_0]_4011   loss=3.873653 |g|=0.5	lr=9.92e-04 | 28.6%@S4  T=959.6ms eta=15:11:58 | 79.6K token/s | 
[epoch_0]_4021   loss=3.801154 |g|=0.42	lr=9.92e-04 | 29.4%@S4  T=971.3ms eta=15:22:58 | 79.8K token/s | 
[epoch_0]_4031   loss=3.890366 |g|=0.439	lr=9.92e-04 | 30.2%@S4  T=965.9ms eta=15:17:42 | 80.1K token/s | 
[epoch_0]_4041   loss=3.829688 |g|=0.504	lr=9.92e-04 | 31.0%@S4  T=969.7ms eta=15:21:07 | 80.3K token/s | 
[epoch_0]_4051   loss=3.846985 |g|=0.435	lr=9.92e-04 | 31.9%@S4  T=958.4ms eta=15:10:11 | 80.6K token/s | 
[epoch_0]_4061   loss=3.769311 |g|=0.417	lr=9.92e-04 | 32.7%@S4  T=962.2ms eta=15:13:39 | 80.8K token/s | 
[epoch_0]_4071   loss=3.842172 |g|=0.452	lr=9.92e-04 | 33.5%@S4  T=960.3ms eta=15:11:43 | 81.0K token/s | 
[epoch_0]_4081   loss=3.716935 |g|=0.52	lr=9.92e-04 | 34.3%@S4  T=962.5ms eta=15:13:36 | 81.2K token/s | 
[epoch_0]_4091   loss=3.742805 |g|=0.456	lr=9.92e-04 | 35.1%@S4  T=968.2ms eta=15:18:51 | 81.4K token/s | 
[Fuyou] head="4" update algorithm=4 t=2.07s
[Section@4100] layer[30-36] tasks=15(nPassBack=0) last_loss=3.84066(0.0767174) N=(580,3948,3528 409900)
[epoch_0]_4101   loss=3.818491 |g|=0.514	lr=9.92e-04 | 36.0%@S4  T=1.25s eta=19:49:51 | 80.6K token/s | 
[epoch_0]_4111   loss=3.847457 |g|=0.383	lr=9.92e-04 | 36.8%@S4  T=969.9ms eta=15:20:09 | 80.8K token/s | 
[epoch_0]_4121   loss=3.785418 |g|=0.433	lr=9.92e-04 | 37.6%@S4  T=958.0ms eta=15:08:42 | 81.0K token/s | 
[epoch_0]_4131   loss=3.798272 |g|=0.444	lr=9.92e-04 | 38.4%@S4  T=965.1ms eta=15:15:19 | 81.2K token/s | 
[epoch_0]_4141   loss=3.836453 |g|=0.439	lr=9.92e-04 | 39.2%@S4  T=962.3ms eta=15:12:26 | 81.4K token/s | 
[epoch_0]_4151   loss=3.798691 |g|=0.448	lr=9.92e-04 | 40.1%@S4  T=961.8ms eta=15:11:49 | 81.6K token/s | 
[epoch_0]_4161   loss=3.872800 |g|=0.445	lr=9.92e-04 | 40.9%@S4  T=968.6ms eta=15:18:08 | 81.7K token/s | 
[epoch_0]_4171   loss=3.780810 |g|=0.429	lr=9.91e-04 | 41.7%@S4  T=970.8ms eta=15:20:03 | 81.9K token/s | 
[epoch_0]_4181   loss=3.829098 |g|=0.418	lr=9.91e-04 | 42.5%@S4  T=964.3ms eta=15:13:46 | 82.0K token/s | 
[epoch_0]_4191   loss=3.831314 |g|=0.447	lr=9.91e-04 | 43.3%@S4  T=963.9ms eta=15:13:12 | 82.2K token/s | 
[Fuyou] head="5" update algorithm=4 t=2.02s
[eval] 
	 Loss@"edu_fineweb1B"=3.925(0.015) nBranch=1 nToken=4.01M best=3.9406(19) E2T=0.105 T=13.5038(0)s x=0
	#3.92513±0.1089 tps=297K(4.01408M) a=[3.70468,4.18584] T=13.5038(sec)
[Section@4200] layer[0-6] tasks=15(nPassBack=0) last_loss=3.82042(0.11988) N=(580,4032,3612 419900)
[epoch_0]_4201   loss=3.764561 |g|=0.582	lr=9.91e-04 | 44.1%@S4  T=4.09s eta=2d 16:30:16 | 79.1K token/s | 
[epoch_0]_4211   loss=3.815803 |g|=0.39	lr=9.91e-04 | 45.0%@S4  T=966.5ms eta=15:15:22 | 79.4K token/s | 
[epoch_0]_4221   loss=3.773010 |g|=0.445	lr=9.91e-04 | 45.8%@S4  T=969.0ms eta=15:17:33 | 79.6K token/s | 
[epoch_0]_4231   loss=3.750362 |g|=0.421	lr=9.91e-04 | 46.6%@S4  T=968.0ms eta=15:16:27 | 79.9K token/s | 
[epoch_0]_4241   loss=3.802830 |g|=0.431	lr=9.91e-04 | 47.4%@S4  T=972.1ms eta=15:20:07 | 80.1K token/s | 
[epoch_0]_4251   loss=3.829356 |g|=0.414	lr=9.91e-04 | 48.2%@S4  T=960.8ms eta=15:09:19 | 80.3K token/s | 
[epoch_0]_4261   loss=3.841581 |g|=0.45	lr=9.91e-04 | 49.1%@S4  T=969.4ms eta=15:17:19 | 80.6K token/s | 
[epoch_0]_4271   loss=3.780658 |g|=0.499	lr=9.91e-04 | 49.9%@S4  T=962.6ms eta=15:10:43 | 80.8K token/s | 
[epoch_0]_4281   loss=3.814722 |g|=0.398	lr=9.91e-04 | 50.7%@S4  T=975.6ms eta=15:22:49 | 80.9K token/s | 
[epoch_0]_4291   loss=3.787205 |g|=0.443	lr=9.91e-04 | 51.5%@S4  T=967.6ms eta=15:15:03 | 81.1K token/s | 
[Fuyou] head="0" update algorithm=4 t=2.08s
[Section@4300] layer[6-12] tasks=15(nPassBack=0) last_loss=3.81002(-0.0013063) N=(580,4116,3696 429900)
[epoch_0]_4301   loss=3.794327 |g|=0.516	lr=9.91e-04 | 52.3%@S4  T=1.38s eta=21:42:38 | 80.0K token/s | 
[epoch_0]_4311   loss=3.725849 |g|=0.423	lr=9.91e-04 | 53.2%@S4  T=961.5ms eta=15:08:57 | 80.3K token/s | 
[epoch_0]_4321   loss=3.749936 |g|=0.454	lr=9.91e-04 | 54.0%@S4  T=973.6ms eta=15:20:17 | 80.5K token/s | 
[epoch_0]_4331   loss=3.732648 |g|=0.432	lr=9.91e-04 | 54.8%@S4  T=962.3ms eta=15:09:27 | 80.7K token/s | 
[epoch_0]_4341   loss=3.802836 |g|=0.469	lr=9.91e-04 | 55.6%@S4  T=962.8ms eta=15:09:47 | 80.9K token/s | 
[epoch_0]_4351   loss=3.852134 |g|=0.558	lr=9.91e-04 | 56.4%@S4  T=967.3ms eta=15:13:53 | 81.1K token/s | 
[epoch_0]_4361   loss=3.762765 |g|=0.411	lr=9.91e-04 | 57.3%@S4  T=965.9ms eta=15:12:21 | 81.3K token/s | 
[epoch_0]_4371   loss=3.769922 |g|=0.374	lr=9.91e-04 | 58.1%@S4  T=976.0ms eta=15:21:46 | 81.4K token/s | 
[epoch_0]_4381   loss=3.798145 |g|=0.552	lr=9.90e-04 | 58.9%@S4  T=971.0ms eta=15:16:51 | 81.6K token/s | 
[epoch_0]_4391   loss=3.807205 |g|=0.462	lr=9.90e-04 | 59.7%@S4  T=968.0ms eta=15:13:49 | 81.7K token/s | 
[Fuyou] head="1" update algorithm=4 t=2.15s
[eval] 
	 Loss@"edu_fineweb1B"=3.914(0.011) nBranch=1 nToken=4.01M best=3.9251(20) E2T=0.121 T=13.5035(0)s x=0
	#3.91371±0.1092 tps=297K(4.01408M) a=[3.69465,4.17574] T=13.5035(sec)
[Section@4400] layer[12-18] tasks=15(nPassBack=0) last_loss=3.7927(0.0507402) N=(580,4200,3780 439900)
[epoch_0]_4401   loss=3.767361 |g|=0.491	lr=9.90e-04 | 60.5%@S4  T=4.09s eta=2d 16:22:27 | 78.7K token/s | 
[epoch_0]_4411   loss=3.870453 |g|=0.48	lr=9.90e-04 | 61.4%@S4  T=960.8ms eta=15:06:46 | 79.0K token/s | 
[epoch_0]_4421   loss=3.806577 |g|=0.407	lr=9.90e-04 | 62.2%@S4  T=980.8ms eta=15:25:29 | 79.2K token/s | 
[epoch_0]_4431   loss=3.739714 |g|=0.462	lr=9.90e-04 | 63.0%@S4  T=959.8ms eta=15:05:28 | 79.5K token/s | 
[epoch_0]_4441   loss=3.715631 |g|=0.409	lr=9.90e-04 | 63.8%@S4  T=960.2ms eta=15:05:39 | 79.8K token/s | 
[epoch_0]_4451   loss=3.800103 |g|=0.414	lr=9.90e-04 | 64.6%@S4  T=968.8ms eta=15:13:36 | 80.0K token/s | 
[epoch_0]_4461   loss=3.763608 |g|=0.45	lr=9.90e-04 | 65.4%@S4  T=962.0ms eta=15:07:05 | 80.3K token/s | 
[epoch_0]_4471   loss=3.850533 |g|=0.434	lr=9.90e-04 | 66.3%@S4  T=971.6ms eta=15:15:58 | 80.5K token/s | 
[epoch_0]_4481   loss=3.696434 |g|=0.483	lr=9.90e-04 | 67.1%@S4  T=973.6ms eta=15:17:43 | 80.7K token/s | 
[epoch_0]_4491   loss=3.721616 |g|=0.437	lr=9.90e-04 | 67.9%@S4  T=962.2ms eta=15:06:48 | 80.9K token/s | 
[Fuyou] head="2" update algorithm=4 t=2.08s
[Section@4500] layer[18-24] tasks=15(nPassBack=0) last_loss=3.73263(0.148421) N=(580,4284,3864 449900)
[epoch_0]_4501   loss=3.818076 |g|=0.579	lr=9.90e-04 | 68.7%@S4  T=1.24s eta=19:30:13 | 80.2K token/s | 
[epoch_0]_4511   loss=3.765576 |g|=0.467	lr=9.90e-04 | 69.5%@S4  T=966.7ms eta=15:10:44 | 80.4K token/s | 
[epoch_0]_4521   loss=3.740517 |g|=0.411	lr=9.90e-04 | 70.4%@S4  T=972.0ms eta=15:15:33 | 80.6K token/s | 
[epoch_0]_4531   loss=3.796808 |g|=0.432	lr=9.90e-04 | 71.2%@S4  T=973.4ms eta=15:16:41 | 80.8K token/s | 
[epoch_0]_4541   loss=3.778655 |g|=0.427	lr=9.90e-04 | 72.0%@S4  T=963.1ms eta=15:06:47 | 81.0K token/s | 
[epoch_0]_4551   loss=3.771539 |g|=0.421	lr=9.90e-04 | 72.8%@S4  T=986.8ms eta=15:28:59 | 81.1K token/s | 
[epoch_0]_4561   loss=3.789937 |g|=0.417	lr=9.90e-04 | 73.6%@S4  T=964.5ms eta=15:07:51 | 81.3K token/s | 
[epoch_0]_4571   loss=3.738641 |g|=0.432	lr=9.89e-04 | 74.5%@S4  T=964.5ms eta=15:07:36 | 81.5K token/s | 
[epoch_0]_4581   loss=3.803855 |g|=0.531	lr=9.89e-04 | 75.3%@S4  T=984.9ms eta=15:26:40 | 81.5K token/s | 
[epoch_0]_4591   loss=3.808851 |g|=0.433	lr=9.89e-04 | 76.1%@S4  T=966.3ms eta=15:09:00 | 81.7K token/s | 
[Fuyou] head="3" update algorithm=4 t=2.07s
[eval] 
	 Loss@"edu_fineweb1B"=3.892(0.022) nBranch=1 nToken=4.01M best=3.9137(21) E2T=0.202 T=13.4865(0)s x=0
	#3.89214±0.1092 tps=298K(4.01408M) a=[3.6738,4.155] T=13.4865(sec)
[Section@4600] layer[24-30] tasks=15(nPassBack=0) last_loss=3.68973(0.169076) N=(580,4368,3948 459900)
[epoch_0]_4601   loss=3.771371 |g|=0.561	lr=9.89e-04 | 76.9%@S4  T=4.09s eta=2d 16:02:21 | 78.6K token/s | 
[epoch_0]_4611   loss=3.772115 |g|=0.506	lr=9.89e-04 | 77.7%@S4  T=966.1ms eta=15:08:33 | 78.9K token/s | 
[epoch_0]_4621   loss=3.674109 |g|=0.459	lr=9.89e-04 | 78.6%@S4  T=965.6ms eta=15:07:50 | 79.2K token/s | 
[epoch_0]_4631   loss=3.687608 |g|=0.413	lr=9.89e-04 | 79.4%@S4  T=973.8ms eta=15:15:24 | 79.5K token/s | 
[epoch_0]_4641   loss=3.802064 |g|=0.413	lr=9.89e-04 | 80.2%@S4  T=964.2ms eta=15:06:12 | 79.7K token/s | 
[epoch_0]_4651   loss=3.760614 |g|=0.415	lr=9.89e-04 | 81.0%@S4  T=964.5ms eta=15:06:21 | 80.0K token/s | 
[epoch_0]_4661   loss=3.758014 |g|=0.437	lr=9.89e-04 | 81.8%@S4  T=965.9ms eta=15:07:32 | 80.2K token/s | 
[epoch_0]_4671   loss=3.784060 |g|=0.547	lr=9.89e-04 | 82.7%@S4  T=967.6ms eta=15:08:56 | 80.5K token/s | 
[epoch_0]_4681   loss=3.775111 |g|=0.484	lr=9.89e-04 | 83.5%@S4  T=972.3ms eta=15:13:14 | 80.7K token/s | 
[epoch_0]_4691   loss=3.722722 |g|=0.424	lr=9.89e-04 | 84.3%@S4  T=977.7ms eta=15:18:09 | 80.8K token/s | 
[Fuyou] head="4" update algorithm=4 t=2.06s
[Section@4700] layer[30-36] tasks=15(nPassBack=0) last_loss=3.78469(0.0559633) N=(580,4452,4032 469900)
[epoch_0]_4701   loss=3.776764 |g|=0.584	lr=9.89e-04 | 85.1%@S4  T=1.32s eta=20:41:15 | 79.9K token/s | 
[epoch_0]_4711   loss=3.670613 |g|=0.416	lr=9.89e-04 | 85.9%@S4  T=957.2ms eta=14:58:33 | 80.2K token/s | 
[epoch_0]_4721   loss=3.718365 |g|=0.409	lr=9.89e-04 | 86.7%@S4  T=966.5ms eta=15:07:05 | 80.4K token/s | 
[epoch_0]_4731   loss=3.794014 |g|=0.417	lr=9.89e-04 | 87.6%@S4  T=973.0ms eta=15:13:05 | 80.6K token/s | 
[epoch_0]_4741   loss=3.738303 |g|=0.372	lr=9.89e-04 | 88.4%@S4  T=966.9ms eta=15:07:11 | 80.8K token/s | 
[epoch_0]_4751   loss=3.748251 |g|=0.387	lr=9.89e-04 | 89.2%@S4  T=969.8ms eta=15:09:45 | 81.0K token/s | 
[epoch_0]_4761   loss=3.678218 |g|=0.421	lr=9.88e-04 | 90.0%@S4  T=968.9ms eta=15:08:42 | 81.1K token/s | 
[epoch_0]_4771   loss=3.745686 |g|=0.441	lr=9.88e-04 | 90.8%@S4  T=966.6ms eta=15:06:23 | 81.3K token/s | 
[epoch_0]_4781   loss=3.694707 |g|=0.44	lr=9.88e-04 | 91.7%@S4  T=962.8ms eta=15:02:43 | 81.5K token/s | 
[epoch_0]_4791   loss=3.758010 |g|=0.4	lr=9.88e-04 | 92.5%@S4  T=973.4ms eta=15:12:28 | 81.6K token/s | 
[Fuyou] head="5" update algorithm=4 t=2.08s
[eval] 
	 Loss@"edu_fineweb1B"=3.880(0.012) nBranch=1 nToken=4.01M best=3.8921(22) E2T=0.128 T=13.5032(0)s x=0
	#3.87987±0.1113 tps=297K(4.01408M) a=[3.65508,4.14709] T=13.5032(sec)
[Section@4800] layer[0-6] tasks=15(nPassBack=0) last_loss=3.75224(0.068187) N=(580,4536,4116 479900)
[epoch_0]_4801   loss=3.789236 |g|=0.413	lr=9.88e-04 | 93.3%@S4  T=4.11s eta=2d 16:07:39 | 78.6K token/s | 
[epoch_0]_4811   loss=3.805215 |g|=0.42	lr=9.88e-04 | 94.1%@S4  T=965.9ms eta=15:05:05 | 78.9K token/s | 
[epoch_0]_4821   loss=3.794851 |g|=0.439	lr=9.88e-04 | 94.9%@S4  T=973.5ms eta=15:12:07 | 79.1K token/s | 
[epoch_0]_4831   loss=3.741954 |g|=0.462	lr=9.88e-04 | 95.8%@S4  T=977.8ms eta=15:15:58 | 79.4K token/s | 
[epoch_0]_4841   loss=3.748096 |g|=0.428	lr=9.88e-04 | 96.6%@S4  T=969.6ms eta=15:08:04 | 79.6K token/s | 
[epoch_0]_4851   loss=3.740813 |g|=0.448	lr=9.88e-04 | 97.4%@S4  T=961.3ms eta=15:00:11 | 79.9K token/s | 
[epoch_0]_4861   loss=3.753013 |g|=0.406	lr=9.88e-04 | 98.2%@S4  T=964.5ms eta=15:02:58 | 80.2K token/s | 
[epoch_0]_4871   loss=3.649608 |g|=0.403	lr=9.88e-04 | 99.0%@S4  T=987.3ms eta=15:24:08 | 80.3K token/s | 
[epoch_0]_4881   loss=3.742973 |g|=0.406	lr=9.88e-04 | 99.9%@S4  T=972.1ms eta=15:09:49 | 80.5K token/s | 
[epoch_0]_4882   loss=3.741235 |g|=0.402	lr=9.88e-04 | 99.9%@S4  T=975.0ms eta=15:12:29 | 80.7K token/s | 
-------- End of shard_4@"./Datasets/edu_fineweb1B/edu_fineweb_train_000004.bin"-------- 
[shard-5]@"./Datasets/edu_fineweb1B/edu_fineweb_train_000005.bin": tokens=100(M) nShardSamples=1220(488280) 
[epoch_0]_4891   loss=3.811050 |g|=0.394	lr=9.88e-04 | 0.7%@S5  T=977.0ms eta=15:14:10 | 80.8K token/s | 
[Fuyou] head="0" update algorithm=4 t=2.09s
[Section@4900] layer[6-12] tasks=15(nPassBack=0) last_loss=3.83991(-0.0298841) N=(580,4620,4200 489900)
[epoch_0]_4901   loss=3.877677 |g|=0.46	lr=9.88e-04 | 1.5%@S5  T=1.25s eta=19:30:35 | 80.1K token/s | 
[epoch_0]_4911   loss=3.841093 |g|=0.416	lr=9.88e-04 | 2.3%@S5  T=966.4ms eta=15:03:55 | 80.3K token/s | 
[epoch_0]_4921   loss=3.979882 |g|=0.485	lr=9.88e-04 | 3.1%@S5  T=967.0ms eta=15:04:22 | 80.5K token/s | 
[epoch_0]_4931   loss=3.907877 |g|=0.507	lr=9.88e-04 | 3.9%@S5  T=963.5ms eta=15:00:57 | 80.7K token/s | 
[epoch_0]_4941   loss=3.853918 |g|=0.492	lr=9.87e-04 | 4.8%@S5  T=963.6ms eta=15:00:53 | 81.0K token/s | 
[epoch_0]_4951   loss=3.908924 |g|=0.439	lr=9.87e-04 | 5.6%@S5  T=971.3ms eta=15:07:54 | 81.1K token/s | 
[epoch_0]_4961   loss=3.860951 |g|=0.464	lr=9.87e-04 | 6.4%@S5  T=966.6ms eta=15:03:22 | 81.3K token/s | 
[epoch_0]_4971   loss=3.858469 |g|=0.439	lr=9.87e-04 | 7.2%@S5  T=976.5ms eta=15:12:26 | 81.4K token/s | 
[epoch_0]_4981   loss=3.857132 |g|=0.449	lr=9.87e-04 | 8.0%@S5  T=976.5ms eta=15:12:14 | 81.6K token/s | 
[epoch_0]_4991   loss=3.869880 |g|=0.46	lr=9.87e-04 | 8.9%@S5  T=966.5ms eta=15:02:49 | 81.7K token/s | 
[Fuyou] head="1" update algorithm=4 t=2.11s
[eval] 
	 Loss@"edu_fineweb1B"=3.839(0.041) nBranch=1 nToken=4.01M best=3.8799(23) E2T=-0.0676 T=13.4965(0)s x=0
	#3.83914±0.1086 tps=297K(4.01408M) a=[3.62486,4.09594] T=13.4965(sec)
[Section@5000] layer[12-18] tasks=15(nPassBack=0) last_loss=3.90672(-0.114017) N=(580,4704,4284 499900)
[epoch_0]_5001   loss=3.855005 |g|=0.515	lr=9.87e-04 | 9.7%@S5  T=4.08s eta=2d 15:34:02 | 78.6K token/s | 
[epoch_0]_5011   loss=3.837441 |g|=0.45	lr=9.87e-04 | 10.5%@S5  T=965.2ms eta=15:01:16 | 78.9K token/s | 
[epoch_0]_5021   loss=3.882686 |g|=0.39	lr=9.87e-04 | 11.3%@S5  T=971.8ms eta=15:07:11 | 79.2K token/s | 
[epoch_0]_5031   loss=3.844689 |g|=0.482	lr=9.87e-04 | 12.1%@S5  T=987.5ms eta=15:21:43 | 79.4K token/s | 
[epoch_0]_5041   loss=3.836924 |g|=0.437	lr=9.87e-04 | 13.0%@S5  T=964.4ms eta=14:59:58 | 79.7K token/s | 
[epoch_0]_5051   loss=3.846039 |g|=0.479	lr=9.87e-04 | 13.8%@S5  T=970.5ms eta=15:05:30 | 79.9K token/s | 
[epoch_0]_5061   loss=3.913267 |g|=0.423	lr=9.87e-04 | 14.6%@S5  T=971.8ms eta=15:06:33 | 80.1K token/s | 
[epoch_0]_5071   loss=3.843544 |g|=0.428	lr=9.87e-04 | 15.4%@S5  T=972.9ms eta=15:07:25 | 80.3K token/s | 
[epoch_0]_5081   loss=3.881740 |g|=0.422	lr=9.87e-04 | 16.2%@S5  T=965.2ms eta=15:00:08 | 80.6K token/s | 
[epoch_0]_5091   loss=3.828640 |g|=0.469	lr=9.87e-04 | 17.1%@S5  T=983.2ms eta=15:16:43 | 80.7K token/s | 
[Fuyou] head="2" update algorithm=4 t=2.09s
[Section@5100] layer[18-24] tasks=15(nPassBack=0) last_loss=3.84084(-0.108207) N=(580,4788,4368 509900)
[epoch_0]_5101   loss=3.802310 |g|=0.398	lr=9.87e-04 | 17.9%@S5  T=1.24s eta=19:20:10 | 80.0K token/s | 
[epoch_0]_5111   loss=3.918514 |g|=0.475	lr=9.86e-04 | 18.7%@S5  T=989.0ms eta=15:21:50 | 80.1K token/s | 
[epoch_0]_5121   loss=3.879061 |g|=0.495	lr=9.86e-04 | 19.5%@S5  T=979.5ms eta=15:12:50 | 80.3K token/s | 
[epoch_0]_5131   loss=3.857234 |g|=0.455	lr=9.86e-04 | 20.3%@S5  T=968.0ms eta=15:01:57 | 80.5K token/s | 
[epoch_0]_5141   loss=3.850061 |g|=0.422	lr=9.86e-04 | 21.2%@S5  T=971.9ms eta=15:05:20 | 80.7K token/s | 
[epoch_0]_5151   loss=3.871180 |g|=0.41	lr=9.86e-04 | 22.0%@S5  T=963.8ms eta=14:57:41 | 80.9K token/s | 
[epoch_0]_5161   loss=3.846091 |g|=0.443	lr=9.86e-04 | 22.8%@S5  T=968.2ms eta=15:01:36 | 81.1K token/s | 
[epoch_0]_5171   loss=3.915074 |g|=0.384	lr=9.86e-04 | 23.6%@S5  T=968.9ms eta=15:02:03 | 81.3K token/s | 
[epoch_0]_5181   loss=3.801582 |g|=0.446	lr=9.86e-04 | 24.4%@S5  T=975.6ms eta=15:08:09 | 81.4K token/s | 
[epoch_0]_5191   loss=3.850028 |g|=0.435	lr=9.86e-04 | 25.2%@S5  T=971.2ms eta=15:03:53 | 81.5K token/s | 
[Fuyou] head="3" update algorithm=4 t=2.07s
[eval] 
	 Loss@"edu_fineweb1B"=3.817(0.022) nBranch=1 nToken=4.01M best=3.8391(24) E2T=-0.0223 T=13.4899(0)s x=0
	#3.81721±0.1064 tps=298K(4.01408M) a=[3.60858,4.07402] T=13.4899(sec)
[Section@5200] layer[24-30] tasks=15(nPassBack=0) last_loss=3.83948(-0.149754) N=(580,4872,4452 519900)
[epoch_0]_5201   loss=3.837711 |g|=0.491	lr=9.86e-04 | 26.1%@S5  T=4.09s eta=2d 15:26:49 | 78.5K token/s | 
[epoch_0]_5211   loss=3.895483 |g|=0.458	lr=9.86e-04 | 26.9%@S5  T=998.3ms eta=15:28:48 | 78.6K token/s | 
[epoch_0]_5221   loss=3.817106 |g|=0.426	lr=9.86e-04 | 27.7%@S5  T=969.1ms eta=15:01:29 | 78.9K token/s | 
[epoch_0]_5231   loss=3.870900 |g|=0.455	lr=9.86e-04 | 28.5%@S5  T=967.2ms eta=14:59:33 | 79.2K token/s | 
[epoch_0]_5241   loss=3.879959 |g|=0.42	lr=9.86e-04 | 29.3%@S5  T=974.3ms eta=15:05:58 | 79.5K token/s | 
[epoch_0]_5251   loss=3.852377 |g|=0.482	lr=9.86e-04 | 30.2%@S5  T=990.6ms eta=15:20:59 | 79.6K token/s | 
[epoch_0]_5261   loss=3.821132 |g|=0.438	lr=9.86e-04 | 31.0%@S5  T=977.5ms eta=15:08:41 | 79.8K token/s | 
[epoch_0]_5271   loss=3.784865 |g|=0.452	lr=9.85e-04 | 31.8%@S5  T=966.7ms eta=14:58:27 | 80.1K token/s | 
[epoch_0]_5281   loss=3.853264 |g|=0.454	lr=9.85e-04 | 32.6%@S5  T=977.9ms eta=15:08:43 | 80.3K token/s | 
[epoch_0]_5291   loss=3.811351 |g|=0.437	lr=9.85e-04 | 33.4%@S5  T=973.2ms eta=15:04:09 | 80.5K token/s | 
[Fuyou] head="4" update algorithm=4 t=2.04s
[Section@5300] layer[30-36] tasks=15(nPassBack=0) last_loss=3.86778(-0.0830882) N=(580,4956,4536 529900)
[epoch_0]_5301   loss=3.814655 |g|=0.502	lr=9.85e-04 | 34.3%@S5  T=1.23s eta=19:03:36 | 79.8K token/s | 
[epoch_0]_5311   loss=3.885958 |g|=0.476	lr=9.85e-04 | 35.1%@S5  T=970.2ms eta=15:01:02 | 80.0K token/s | 
[epoch_0]_5321   loss=3.849698 |g|=0.484	lr=9.85e-04 | 35.9%@S5  T=987.4ms eta=15:16:54 | 80.2K token/s | 
[epoch_0]_5331   loss=3.855604 |g|=0.413	lr=9.85e-04 | 36.7%@S5  T=978.1ms eta=15:08:03 | 80.3K token/s | 
[epoch_0]_5341   loss=3.821241 |g|=0.439	lr=9.85e-04 | 37.5%@S5  T=978.4ms eta=15:08:12 | 80.5K token/s | 
[epoch_0]_5351   loss=3.873651 |g|=0.491	lr=9.85e-04 | 38.4%@S5  T=968.9ms eta=14:59:14 | 80.7K token/s | 
[epoch_0]_5361   loss=3.839046 |g|=0.448	lr=9.85e-04 | 39.2%@S5  T=967.6ms eta=14:57:48 | 80.9K token/s | 
[epoch_0]_5371   loss=3.815804 |g|=0.412	lr=9.85e-04 | 40.0%@S5  T=969.6ms eta=14:59:30 | 81.1K token/s | 
[epoch_0]_5381   loss=3.764701 |g|=0.387	lr=9.85e-04 | 40.8%@S5  T=963.5ms eta=14:53:43 | 81.3K token/s | 
[epoch_0]_5391   loss=3.827914 |g|=0.41	lr=9.85e-04 | 41.6%@S5  T=974.8ms eta=15:04:04 | 81.4K token/s | 
[Fuyou] head="5" update algorithm=4 t=2.08s
[eval] 
	 Loss@"edu_fineweb1B"=3.805(0.013) nBranch=1 nToken=4.01M best=3.8172(25) E2T=-0.0351 T=13.4937(0)s x=0
	#3.80465±0.1053 tps=297K(4.01408M) a=[3.60808,4.05386] T=13.4937(sec)
[Section@5400] layer[0-6] tasks=15(nPassBack=0) last_loss=3.8398(-0.0875595) N=(580,5040,4620 539900)
[epoch_0]_5401   loss=3.796976 |g|=0.478	lr=9.85e-04 | 42.5%@S5  T=4.10s eta=2d 15:20:58 | 78.3K token/s | 
[epoch_0]_5411   loss=3.865913 |g|=0.47	lr=9.85e-04 | 43.3%@S5  T=1.00s eta=15:29:38 | 78.5K token/s | 
[epoch_0]_5421   loss=3.877044 |g|=0.432	lr=9.85e-04 | 44.1%@S5  T=970.7ms eta=14:59:45 | 78.8K token/s | 
[epoch_0]_5431   loss=3.871912 |g|=0.409	lr=9.84e-04 | 44.9%@S5  T=966.9ms eta=14:56:04 | 79.1K token/s | 
[epoch_0]_5441   loss=3.804144 |g|=0.482	lr=9.84e-04 | 45.7%@S5  T=970.4ms eta=14:59:08 | 79.4K token/s | 
[epoch_0]_5451   loss=3.703837 |g|=0.419	lr=9.84e-04 | 46.5%@S5  T=992.1ms eta=15:19:07 | 79.5K token/s | 
[epoch_0]_5461   loss=3.774759 |g|=0.443	lr=9.84e-04 | 47.4%@S5  T=970.7ms eta=14:59:07 | 79.8K token/s | 
[epoch_0]_5471   loss=3.815953 |g|=0.361	lr=9.84e-04 | 48.2%@S5  T=968.8ms eta=14:57:10 | 80.0K token/s | 
[epoch_0]_5481   loss=3.832187 |g|=0.479	lr=9.84e-04 | 49.0%@S5  T=988.3ms eta=15:15:02 | 80.2K token/s | 
[epoch_0]_5491   loss=3.774920 |g|=0.395	lr=9.84e-04 | 49.8%@S5  T=973.6ms eta=15:01:17 | 80.4K token/s | 
[Fuyou] head="0" update algorithm=4 t=2.09s
[Section@5500] layer[6-12] tasks=15(nPassBack=0) last_loss=3.74909(0.0908132) N=(580,5124,4704 549900)
[epoch_0]_5501   loss=3.818127 |g|=0.492	lr=9.84e-04 | 50.6%@S5  T=1.30s eta=20:07:03 | 79.5K token/s | 
[epoch_0]_5511   loss=3.819594 |g|=0.449	lr=9.84e-04 | 51.5%@S5  T=966.2ms eta=14:54:05 | 79.7K token/s | 
[epoch_0]_5521   loss=3.794697 |g|=0.416	lr=9.84e-04 | 52.3%@S5  T=968.2ms eta=14:55:47 | 80.0K token/s | 
[epoch_0]_5531   loss=3.824270 |g|=0.416	lr=9.84e-04 | 53.1%@S5  T=976.2ms eta=15:03:04 | 80.2K token/s | 
[epoch_0]_5541   loss=3.787130 |g|=0.449	lr=9.84e-04 | 53.9%@S5  T=969.6ms eta=14:56:48 | 80.4K token/s | 
[epoch_0]_5551   loss=3.793108 |g|=0.445	lr=9.84e-04 | 54.7%@S5  T=974.1ms eta=15:00:48 | 80.6K token/s | 
[epoch_0]_5561   loss=3.819635 |g|=0.461	lr=9.84e-04 | 55.6%@S5  T=988.7ms eta=15:14:08 | 80.7K token/s | 
[epoch_0]_5571   loss=3.805865 |g|=0.45	lr=9.84e-04 | 56.4%@S5  T=988.7ms eta=15:13:57 | 80.8K token/s | 
[epoch_0]_5581   loss=3.802550 |g|=0.39	lr=9.83e-04 | 57.2%@S5  T=968.4ms eta=14:55:03 | 81.0K token/s | 
[epoch_0]_5591   loss=3.796829 |g|=0.43	lr=9.83e-04 | 58.0%@S5  T=975.5ms eta=15:01:24 | 81.1K token/s | 
[Fuyou] head="1" update algorithm=4 t=2.04s
[eval] 
	 Loss@"edu_fineweb1B"=3.785(0.02) nBranch=1 nToken=4.01M best=3.8047(26) E2T=-0.000446 T=13.4907(0)s x=0
	#3.78488±0.1057 tps=298K(4.01408M) a=[3.57997,4.03589] T=13.4907(sec)
[Section@5600] layer[12-18] tasks=15(nPassBack=0) last_loss=3.78533(0.121387) N=(580,5208,4788 559900)
[epoch_0]_5601   loss=3.793616 |g|=0.592	lr=9.83e-04 | 58.8%@S5  T=4.10s eta=2d 15:08:28 | 78.1K token/s | 
[epoch_0]_5611   loss=3.720666 |g|=0.464	lr=9.83e-04 | 59.7%@S5  T=972.6ms eta=14:58:22 | 78.4K token/s | 
[epoch_0]_5621   loss=3.771917 |g|=0.463	lr=9.83e-04 | 60.5%@S5  T=977.5ms eta=15:02:49 | 78.7K token/s | 
[epoch_0]_5631   loss=3.805463 |g|=0.465	lr=9.83e-04 | 61.3%@S5  T=984.7ms eta=15:09:13 | 78.9K token/s | 
[epoch_0]_5641   loss=3.760062 |g|=0.491	lr=9.83e-04 | 62.1%@S5  T=975.6ms eta=15:00:42 | 79.1K token/s | 
[epoch_0]_5651   loss=3.819300 |g|=0.468	lr=9.83e-04 | 62.9%@S5  T=977.2ms eta=15:02:03 | 79.4K token/s | 
[epoch_0]_5661   loss=3.777702 |g|=0.406	lr=9.83e-04 | 63.8%@S5  T=970.0ms eta=14:55:11 | 79.6K token/s | 
[epoch_0]_5671   loss=3.843044 |g|=0.446	lr=9.83e-04 | 64.6%@S5  T=970.2ms eta=14:55:16 | 79.9K token/s | 
[epoch_0]_5681   loss=3.850118 |g|=0.376	lr=9.83e-04 | 65.4%@S5  T=979.2ms eta=15:03:24 | 80.1K token/s | 
[epoch_0]_5691   loss=3.786507 |g|=0.417	lr=9.83e-04 | 66.2%@S5  T=989.3ms eta=15:12:32 | 80.2K token/s | 
[Fuyou] head="2" update algorithm=4 t=2.09s
[Section@5700] layer[18-24] tasks=15(nPassBack=0) last_loss=3.7881(0.0527363) N=(580,5292,4872 569900)
[epoch_0]_5701   loss=3.805338 |g|=0.479	lr=9.83e-04 | 67.0%@S5  T=1.32s eta=20:16:47 | 79.3K token/s | 
[epoch_0]_5711   loss=3.818759 |g|=0.443	lr=9.83e-04 | 67.8%@S5  T=971.5ms eta=14:55:48 | 79.5K token/s | 
[epoch_0]_5721   loss=3.674273 |g|=0.455	lr=9.83e-04 | 68.7%@S5  T=968.5ms eta=14:52:53 | 79.8K token/s | 
[epoch_0]_5731   loss=3.751985 |g|=0.389	lr=9.82e-04 | 69.5%@S5  T=986.0ms eta=15:08:52 | 80.0K token/s | 
[epoch_0]_5741   loss=3.757066 |g|=0.463	lr=9.82e-04 | 70.3%@S5  T=981.1ms eta=15:04:08 | 80.1K token/s | 
[epoch_0]_5751   loss=3.803105 |g|=0.376	lr=9.82e-04 | 71.1%@S5  T=968.5ms eta=14:52:20 | 80.4K token/s | 
[epoch_0]_5761   loss=3.755371 |g|=0.388	lr=9.82e-04 | 71.9%@S5  T=981.4ms eta=15:04:08 | 80.5K token/s | 
[epoch_0]_5771   loss=3.780767 |g|=0.435	lr=9.82e-04 | 72.8%@S5  T=973.3ms eta=14:56:28 | 80.7K token/s | 
[epoch_0]_5781   loss=3.791692 |g|=0.452	lr=9.82e-04 | 73.6%@S5  T=975.3ms eta=14:58:10 | 80.9K token/s | 
[epoch_0]_5791   loss=3.764836 |g|=0.4	lr=9.82e-04 | 74.4%@S5  T=981.4ms eta=15:03:34 | 81.0K token/s | 
[Fuyou] head="3" update algorithm=4 t=2.08s
[eval] 
	 Loss@"edu_fineweb1B"=3.770(0.015) nBranch=1 nToken=4.01M best=3.7849(27) E2T=-0.0232 T=13.4901(0)s x=0
	#3.77036±0.1051 tps=298K(4.01408M) a=[3.56494,4.02215] T=13.4901(sec)
[Section@5800] layer[24-30] tasks=15(nPassBack=0) last_loss=3.79356(0.0459216) N=(580,5376,4956 579900)
[epoch_0]_5801   loss=3.878748 |g|=0.571	lr=9.82e-04 | 75.2%@S5  T=4.09s eta=2d 14:44:16 | 77.9K token/s | 
[epoch_0]_5811   loss=3.760740 |g|=0.415	lr=9.82e-04 | 76.0%@S5  T=967.6ms eta=14:50:36 | 78.3K token/s | 
[epoch_0]_5821   loss=3.835141 |g|=0.435	lr=9.82e-04 | 76.9%@S5  T=968.3ms eta=14:51:04 | 78.6K token/s | 
[epoch_0]_5831   loss=3.668633 |g|=0.44	lr=9.82e-04 | 77.7%@S5  T=967.4ms eta=14:50:06 | 78.9K token/s | 
[epoch_0]_5841   loss=3.776858 |g|=0.447	lr=9.82e-04 | 78.5%@S5  T=973.4ms eta=14:55:24 | 79.2K token/s | 
[epoch_0]_5851   loss=3.762241 |g|=0.456	lr=9.82e-04 | 79.3%@S5  T=978.3ms eta=14:59:48 | 79.4K token/s | 
[epoch_0]_5861   loss=3.785625 |g|=0.403	lr=9.82e-04 | 80.1%@S5  T=981.8ms eta=15:02:48 | 79.6K token/s | 
[epoch_0]_5871   loss=3.699983 |g|=0.391	lr=9.82e-04 | 81.0%@S5  T=971.9ms eta=14:53:36 | 79.8K token/s | 
[epoch_0]_5881   loss=3.793221 |g|=0.403	lr=9.81e-04 | 81.8%@S5  T=967.9ms eta=14:49:42 | 80.1K token/s | 
[epoch_0]_5891   loss=3.778942 |g|=0.419	lr=9.81e-04 | 82.6%@S5  T=967.0ms eta=14:48:46 | 80.3K token/s | 
[Fuyou] head="4" update algorithm=4 t=2.07s
[Section@5900] layer[30-36] tasks=15(nPassBack=0) last_loss=3.85527(0.0125091) N=(580,5460,5040 589900)
[epoch_0]_5901   loss=3.747094 |g|=0.515	lr=9.81e-04 | 83.4%@S5  T=1.42s eta=21:40:55 | 79.2K token/s | 
[epoch_0]_5911   loss=3.815580 |g|=0.382	lr=9.81e-04 | 84.2%@S5  T=974.4ms eta=14:55:15 | 79.4K token/s | 
[epoch_0]_5921   loss=3.766083 |g|=0.419	lr=9.81e-04 | 85.1%@S5  T=972.0ms eta=14:52:49 | 79.7K token/s | 
[epoch_0]_5931   loss=3.807083 |g|=0.4	lr=9.81e-04 | 85.9%@S5  T=976.2ms eta=14:56:34 | 79.9K token/s | 
[epoch_0]_5941   loss=3.791355 |g|=0.468	lr=9.81e-04 | 86.7%@S5  T=966.3ms eta=14:47:17 | 80.1K token/s | 
[epoch_0]_5951   loss=3.728175 |g|=0.382	lr=9.81e-04 | 87.5%@S5  T=971.8ms eta=14:52:11 | 80.3K token/s | 
[epoch_0]_5961   loss=3.790645 |g|=0.441	lr=9.81e-04 | 88.3%@S5  T=978.4ms eta=14:58:07 | 80.5K token/s | 
[epoch_0]_5971   loss=3.807845 |g|=0.373	lr=9.81e-04 | 89.1%@S5  T=968.9ms eta=14:49:10 | 80.7K token/s | 
[epoch_0]_5981   loss=3.725993 |g|=0.401	lr=9.81e-04 | 90.0%@S5  T=968.0ms eta=14:48:09 | 80.9K token/s | 
[epoch_0]_5991   loss=3.769407 |g|=0.361	lr=9.81e-04 | 90.8%@S5  T=974.8ms eta=14:54:16 | 81.1K token/s | 
[Fuyou] head="5" update algorithm=4 t=2.11s
[eval] 
	 Loss@"edu_fineweb1B"=3.759(0.012) nBranch=1 nToken=4.01M best=3.7704(28) E2T=0.0686 T=13.4939(0)s x=0
	#3.7587±0.1054 tps=297K(4.01408M) a=[3.56381,4.00879] T=13.4939(sec)
[Section@6000] layer[0-6] tasks=15(nPassBack=0) last_loss=3.69005(0.149744) N=(580,5544,5124 599900)
[epoch_0]_6001   loss=3.766767 |g|=0.376	lr=9.81e-04 | 91.6%@S5  T=4.10s eta=2d 14:36:38 | 78.0K token/s | 
[epoch_0]_6011   loss=3.787864 |g|=0.423	lr=9.81e-04 | 92.4%@S5  T=984.1ms eta=15:02:30 | 78.3K token/s | 
[epoch_0]_6021   loss=3.778209 |g|=0.395	lr=9.80e-04 | 93.2%@S5  T=968.8ms eta=14:48:15 | 78.6K token/s | 
[epoch_0]_6031   loss=3.757750 |g|=0.431	lr=9.80e-04 | 94.1%@S5  T=970.8ms eta=14:49:58 | 78.9K token/s | 
[epoch_0]_6041   loss=3.751437 |g|=0.428	lr=9.80e-04 | 94.9%@S5  T=990.4ms eta=15:07:43 | 79.1K token/s | 
[epoch_0]_6051   loss=3.815750 |g|=0.404	lr=9.80e-04 | 95.7%@S5  T=982.2ms eta=15:00:03 | 79.3K token/s | 
[epoch_0]_6061   loss=3.805958 |g|=0.449	lr=9.80e-04 | 96.5%@S5  T=973.1ms eta=14:51:36 | 79.5K token/s | 
[epoch_0]_6071   loss=3.781152 |g|=0.497	lr=9.80e-04 | 97.3%@S5  T=976.0ms eta=14:54:03 | 79.7K token/s | 
[epoch_0]_6081   loss=3.728493 |g|=0.425	lr=9.80e-04 | 98.2%@S5  T=970.0ms eta=14:48:25 | 80.0K token/s | 
[epoch_0]_6091   loss=3.795601 |g|=0.385	lr=9.80e-04 | 99.0%@S5  T=980.7ms eta=14:58:03 | 80.2K token/s | 
[Fuyou] head="0" update algorithm=4 t=2.09s
[Section@6100] layer[6-12] tasks=15(nPassBack=0) last_loss=3.75008(-0.000988483) N=(580,5628,5208 609900)
[epoch_0]_6101   loss=3.746348 |g|=0.444	lr=9.80e-04 | 99.8%@S5  T=1.39s eta=21:10:25 | 79.1K token/s | 
[epoch_0]_6103   loss=3.835208 |g|=0.472	lr=9.80e-04 | 100.0%@S5  T=1.02s eta=15:30:02 | 79.2K token/s | 
-------- End of shard_5@"./Datasets/edu_fineweb1B/edu_fineweb_train_000005.bin"-------- 
[shard-6]@"./Datasets/edu_fineweb1B/edu_fineweb_train_000006.bin": tokens=100(M) nShardSamples=1220(585936) 
[epoch_0]_6111   loss=3.767540 |g|=0.421	lr=9.80e-04 | 0.6%@S6  T=959.6ms eta=14:38:22 | 79.5K token/s | 
[epoch_0]_6121   loss=3.781002 |g|=0.485	lr=9.80e-04 | 1.4%@S6  T=969.7ms eta=14:47:29 | 79.7K token/s | 
[epoch_0]_6131   loss=3.793039 |g|=0.435	lr=9.80e-04 | 2.3%@S6  T=968.4ms eta=14:46:11 | 80.0K token/s | 
[epoch_0]_6141   loss=3.784120 |g|=0.403	lr=9.80e-04 | 3.1%@S6  T=969.6ms eta=14:47:04 | 80.2K token/s | 
[epoch_0]_6151   loss=3.815314 |g|=0.419	lr=9.80e-04 | 3.9%@S6  T=966.4ms eta=14:43:57 | 80.4K token/s | 
[epoch_0]_6161   loss=3.747668 |g|=0.398	lr=9.79e-04 | 4.7%@S6  T=970.3ms eta=14:47:26 | 80.6K token/s | 
[epoch_0]_6171   loss=3.720368 |g|=0.377	lr=9.79e-04 | 5.5%@S6  T=980.8ms eta=14:56:49 | 80.8K token/s | 
[epoch_0]_6181   loss=3.751185 |g|=0.433	lr=9.79e-04 | 6.3%@S6  T=962.0ms eta=14:39:27 | 81.0K token/s | 
[epoch_0]_6191   loss=3.763603 |g|=0.465	lr=9.79e-04 | 7.2%@S6  T=965.4ms eta=14:42:28 | 81.2K token/s | 
[Fuyou] head="1" update algorithm=4 t=2.08s
[eval] 
	 Loss@"edu_fineweb1B"=3.759(-0.00023) nBranch=1 nToken=4.01M best=3.7587(29) E2T=0.0248 T=13.4943(0)s x=0
	#3.75893±0.1058 tps=297K(4.01408M) a=[3.55219,4.0175] T=13.4943(sec)
[Section@6200] layer[12-18] tasks=15(nPassBack=0) last_loss=3.73412(0.0512049) N=(580,5712,5292 619900)
[epoch_0]_6201   loss=3.679757 |g|=0.611	lr=9.79e-04 | 8.0%@S6  T=4.10s eta=2d 14:23:42 | 78.1K token/s | 
[epoch_0]_6211   loss=3.667784 |g|=0.403	lr=9.79e-04 | 8.8%@S6  T=973.1ms eta=14:49:08 | 78.4K token/s | 
[epoch_0]_6221   loss=3.669151 |g|=0.417	lr=9.79e-04 | 9.6%@S6  T=976.9ms eta=14:52:30 | 78.7K token/s | 
[epoch_0]_6231   loss=3.792080 |g|=0.428	lr=9.79e-04 | 10.4%@S6  T=976.5ms eta=14:51:57 | 79.0K token/s | 
[epoch_0]_6241   loss=3.736652 |g|=0.393	lr=9.79e-04 | 11.3%@S6  T=979.7ms eta=14:54:43 | 79.2K token/s | 
[epoch_0]_6251   loss=3.730393 |g|=0.396	lr=9.79e-04 | 12.1%@S6  T=964.2ms eta=14:40:20 | 79.5K token/s | 
[epoch_0]_6261   loss=3.728267 |g|=0.396	lr=9.79e-04 | 12.9%@S6  T=969.1ms eta=14:44:42 | 79.7K token/s | 
[epoch_0]_6271   loss=3.738220 |g|=0.386	lr=9.79e-04 | 13.7%@S6  T=971.2ms eta=14:46:25 | 80.0K token/s | 
[epoch_0]_6281   loss=3.759922 |g|=0.418	lr=9.79e-04 | 14.5%@S6  T=964.3ms eta=14:39:56 | 80.2K token/s | 
[epoch_0]_6291   loss=3.791462 |g|=0.446	lr=9.78e-04 | 15.4%@S6  T=972.5ms eta=14:47:18 | 80.4K token/s | 
[Fuyou] head="2" update algorithm=4 t=2.10s
[Section@6300] layer[18-24] tasks=15(nPassBack=0) last_loss=3.66701(0.121087) N=(580,5796,5376 629900)
[epoch_0]_6301   loss=3.726168 |g|=0.449	lr=9.78e-04 | 16.2%@S6  T=1.25s eta=18:56:04 | 79.7K token/s | 
[epoch_0]_6311   loss=3.720398 |g|=0.436	lr=9.78e-04 | 17.0%@S6  T=966.5ms eta=14:41:32 | 79.9K token/s | 
[epoch_0]_6321   loss=3.762089 |g|=0.446	lr=9.78e-04 | 17.8%@S6  T=968.0ms eta=14:42:42 | 80.2K token/s | 
[epoch_0]_6331   loss=3.717405 |g|=0.419	lr=9.78e-04 | 18.6%@S6  T=980.9ms eta=14:54:21 | 80.3K token/s | 
[epoch_0]_6341   loss=3.778968 |g|=0.464	lr=9.78e-04 | 19.5%@S6  T=985.5ms eta=14:58:20 | 80.5K token/s | 
[epoch_0]_6351   loss=3.742666 |g|=0.385	lr=9.78e-04 | 20.3%@S6  T=975.6ms eta=14:49:11 | 80.7K token/s | 
[epoch_0]_6361   loss=3.725663 |g|=0.472	lr=9.78e-04 | 21.1%@S6  T=976.9ms eta=14:50:13 | 80.8K token/s | 
[epoch_0]_6371   loss=3.679762 |g|=0.441	lr=9.78e-04 | 21.9%@S6  T=984.9ms eta=14:57:18 | 80.9K token/s | 
[epoch_0]_6381   loss=3.703273 |g|=0.395	lr=9.78e-04 | 22.7%@S6  T=999.5ms eta=15:10:27 | 81.0K token/s | 
[epoch_0]_6391   loss=3.744650 |g|=0.398	lr=9.78e-04 | 23.6%@S6  T=980.4ms eta=14:52:53 | 81.1K token/s | 
[Fuyou] head="3" update algorithm=4 t=2.03s
[eval] 
	 Loss@"edu_fineweb1B"=3.755(0.0039) nBranch=1 nToken=4.01M best=3.7589(30) E2T=-0.00343 T=13.4787(0)s x=0
	#3.75498±0.1068 tps=298K(4.01408M) a=[3.5508,4.02143] T=13.4787(sec)
[Section@6400] layer[24-30] tasks=15(nPassBack=0) last_loss=3.75841(0.0351496) N=(580,5880,5460 639900)
[epoch_0]_6401   loss=3.697593 |g|=0.44	lr=9.78e-04 | 24.4%@S6  T=4.10s eta=2d 14:15:40 | 78.1K token/s | 
[epoch_0]_6411   loss=3.606367 |g|=0.395	lr=9.78e-04 | 25.2%@S6  T=994.1ms eta=15:05:03 | 78.3K token/s | 
[epoch_0]_6421   loss=3.687599 |g|=0.52	lr=9.78e-04 | 26.0%@S6  T=979.9ms eta=14:51:57 | 78.5K token/s | 
[epoch_0]_6431   loss=3.758413 |g|=0.42	lr=9.77e-04 | 26.8%@S6  T=978.6ms eta=14:50:37 | 78.8K token/s | 
[epoch_0]_6441   loss=3.722260 |g|=0.423	lr=9.77e-04 | 27.6%@S6  T=1.00s eta=15:10:04 | 79.0K token/s | 
[epoch_0]_6451   loss=3.685888 |g|=0.418	lr=9.77e-04 | 28.5%@S6  T=990.3ms eta=15:00:56 | 79.1K token/s | 
[epoch_0]_6461   loss=3.685790 |g|=0.421	lr=9.77e-04 | 29.3%@S6  T=988.4ms eta=14:58:58 | 79.3K token/s | 
[epoch_0]_6471   loss=3.703853 |g|=0.371	lr=9.77e-04 | 30.1%@S6  T=988.8ms eta=14:59:12 | 79.5K token/s | 
[epoch_0]_6481   loss=3.698826 |g|=0.389	lr=9.77e-04 | 30.9%@S6  T=980.0ms eta=14:51:03 | 79.7K token/s | 
[epoch_0]_6491   loss=3.676619 |g|=0.414	lr=9.77e-04 | 31.7%@S6  T=974.3ms eta=14:45:41 | 79.9K token/s | 
[Fuyou] head="4" update algorithm=4 t=2.11s
[Section@6500] layer[30-36] tasks=15(nPassBack=0) last_loss=3.68296(0.172308) N=(580,5964,5544 649900)
[epoch_0]_6501   loss=3.751661 |g|=0.462	lr=9.77e-04 | 32.6%@S6  T=1.49s eta=22:34:52 | 78.7K token/s | 
[epoch_0]_6511   loss=3.690733 |g|=0.43	lr=9.77e-04 | 33.4%@S6  T=981.6ms eta=14:51:59 | 78.9K token/s | 
[epoch_0]_6521   loss=3.692295 |g|=0.387	lr=9.77e-04 | 34.2%@S6  T=987.8ms eta=14:57:27 | 79.1K token/s | 
[epoch_0]_6531   loss=3.762977 |g|=0.412	lr=9.77e-04 | 35.0%@S6  T=996.9ms eta=15:05:34 | 79.3K token/s | 
[epoch_0]_6541   loss=3.766509 |g|=0.404	lr=9.77e-04 | 35.8%@S6  T=984.8ms eta=14:54:26 | 79.5K token/s | 
[epoch_0]_6551   loss=3.707805 |g|=0.434	lr=9.77e-04 | 36.7%@S6  T=980.4ms eta=14:50:18 | 79.7K token/s | 
[epoch_0]_6561   loss=3.688795 |g|=0.404	lr=9.76e-04 | 37.5%@S6  T=975.4ms eta=14:45:33 | 79.9K token/s | 
[epoch_0]_6571   loss=3.679388 |g|=0.401	lr=9.76e-04 | 38.3%@S6  T=981.2ms eta=14:50:37 | 80.1K token/s | 
[epoch_0]_6581   loss=3.735868 |g|=0.441	lr=9.76e-04 | 39.1%@S6  T=978.8ms eta=14:48:17 | 80.2K token/s | 
[epoch_0]_6591   loss=3.706549 |g|=0.416	lr=9.76e-04 | 39.9%@S6  T=978.8ms eta=14:48:07 | 80.4K token/s | 
[Fuyou] head="5" update algorithm=4 t=2.12s
[eval] 
	 Loss@"edu_fineweb1B"=3.748(0.0073) nBranch=1 nToken=4.01M best=3.7550(31) E2T=0.088 T=13.4807(0)s x=0
	#3.74768±0.1085 tps=298K(4.01408M) a=[3.54652,4.00975] T=13.4807(sec)
[Section@6600] layer[0-6] tasks=15(nPassBack=0) last_loss=3.65968(0.030375) N=(580,6048,5628 659900)
[epoch_0]_6601   loss=3.663236 |g|=0.462	lr=9.76e-04 | 40.8%@S6  T=4.09s eta=2d 13:52:21 | 77.4K token/s | 
[epoch_0]_6611   loss=3.743504 |g|=0.389	lr=9.76e-04 | 41.6%@S6  T=978.3ms eta=14:47:23 | 77.7K token/s | 
[epoch_0]_6621   loss=3.608828 |g|=0.401	lr=9.76e-04 | 42.4%@S6  T=977.4ms eta=14:46:23 | 78.0K token/s | 
[epoch_0]_6631   loss=3.724666 |g|=0.394	lr=9.76e-04 | 43.2%@S6  T=973.8ms eta=14:42:59 | 78.3K token/s | 
[epoch_0]_6641   loss=3.753905 |g|=0.391	lr=9.76e-04 | 44.0%@S6  T=979.9ms eta=14:48:18 | 78.6K token/s | 
[epoch_0]_6651   loss=3.619807 |g|=0.391	lr=9.76e-04 | 44.9%@S6  T=979.2ms eta=14:47:35 | 78.8K token/s | 
[epoch_0]_6661   loss=3.644502 |g|=0.473	lr=9.76e-04 | 45.7%@S6  T=970.7ms eta=14:39:40 | 79.1K token/s | 
[epoch_0]_6671   loss=3.729077 |g|=0.413	lr=9.76e-04 | 46.5%@S6  T=973.2ms eta=14:41:49 | 79.4K token/s | 
[epoch_0]_6681   loss=3.648062 |g|=0.416	lr=9.75e-04 | 47.3%@S6  T=961.9ms eta=14:31:20 | 79.7K token/s | 
[epoch_0]_6691   loss=3.654162 |g|=0.409	lr=9.75e-04 | 48.1%@S6  T=967.4ms eta=14:36:13 | 79.9K token/s | 
[Fuyou] head="0" update algorithm=4 t=2.15s
[Section@6700] layer[6-12] tasks=15(nPassBack=0) last_loss=3.66786(0.0822163) N=(580,6132,5712 669900)
[epoch_0]_6701   loss=3.619533 |g|=0.502	lr=9.75e-04 | 48.9%@S6  T=1.45s eta=21:49:49 | 78.8K token/s | 
[epoch_0]_6711   loss=3.691700 |g|=0.419	lr=9.75e-04 | 49.8%@S6  T=972.6ms eta=14:40:36 | 79.0K token/s | 
[epoch_0]_6721   loss=3.769441 |g|=0.397	lr=9.75e-04 | 50.6%@S6  T=969.9ms eta=14:37:56 | 79.3K token/s | 
[epoch_0]_6731   loss=3.691407 |g|=0.411	lr=9.75e-04 | 51.4%@S6  T=978.7ms eta=14:45:46 | 79.5K token/s | 
[epoch_0]_6741   loss=3.699505 |g|=0.451	lr=9.75e-04 | 52.2%@S6  T=974.7ms eta=14:41:57 | 79.7K token/s | 
[epoch_0]_6751   loss=3.726308 |g|=0.428	lr=9.75e-04 | 53.0%@S6  T=969.9ms eta=14:37:28 | 80.0K token/s | 
[epoch_0]_6761   loss=3.722122 |g|=0.428	lr=9.75e-04 | 53.9%@S6  T=971.5ms eta=14:38:49 | 80.2K token/s | 
[epoch_0]_6771   loss=3.720614 |g|=0.404	lr=9.75e-04 | 54.7%@S6  T=982.9ms eta=14:48:55 | 80.4K token/s | 
[epoch_0]_6781   loss=3.652034 |g|=0.414	lr=9.75e-04 | 55.5%@S6  T=987.5ms eta=14:52:55 | 80.5K token/s | 
[epoch_0]_6791   loss=3.676166 |g|=0.411	lr=9.75e-04 | 56.3%@S6  T=969.1ms eta=14:36:06 | 80.7K token/s | 
[Fuyou] head="1" update algorithm=4 t=2.07s
[eval] 
	 Loss@"edu_fineweb1B"=3.740(0.0075) nBranch=1 nToken=4.01M best=3.7477(32) E2T=0.0382 T=13.4877(0)s x=0
	#3.74021±0.1086 tps=298K(4.01408M) a=[3.53216,4.00591] T=13.4877(sec)
[Section@6800] layer[12-18] tasks=15(nPassBack=0) last_loss=3.70199(0.0321336) N=(580,6216,5796 679900)
[epoch_0]_6801   loss=3.725300 |g|=0.523	lr=9.75e-04 | 57.1%@S6  T=4.10s eta=2d 13:46:42 | 77.7K token/s | 
[epoch_0]_6811   loss=3.712844 |g|=0.456	lr=9.74e-04 | 58.0%@S6  T=969.3ms eta=14:35:56 | 78.0K token/s | 
[epoch_0]_6821   loss=3.620631 |g|=0.379	lr=9.74e-04 | 58.8%@S6  T=969.2ms eta=14:35:41 | 78.3K token/s | 
[epoch_0]_6831   loss=3.722405 |g|=0.456	lr=9.74e-04 | 59.6%@S6  T=974.6ms eta=14:40:24 | 78.6K token/s | 
[epoch_0]_6841   loss=3.721893 |g|=0.447	lr=9.74e-04 | 60.4%@S6  T=988.9ms eta=14:53:13 | 78.8K token/s | 
[epoch_0]_6851   loss=3.717243 |g|=0.393	lr=9.74e-04 | 61.2%@S6  T=975.6ms eta=14:41:00 | 79.1K token/s | 
[epoch_0]_6861   loss=3.729589 |g|=0.415	lr=9.74e-04 | 62.1%@S6  T=976.1ms eta=14:41:17 | 79.3K token/s | 
[epoch_0]_6871   loss=3.662061 |g|=0.411	lr=9.74e-04 | 62.9%@S6  T=970.4ms eta=14:36:01 | 79.6K token/s | 
[epoch_0]_6881   loss=3.638323 |g|=0.411	lr=9.74e-04 | 63.7%@S6  T=973.0ms eta=14:38:09 | 79.8K token/s | 
[epoch_0]_6891   loss=3.733908 |g|=0.433	lr=9.74e-04 | 64.5%@S6  T=976.9ms eta=14:41:35 | 80.0K token/s | 
[Fuyou] head="2" update algorithm=4 t=2.03s
[Section@6900] layer[18-24] tasks=15(nPassBack=0) last_loss=3.6959(-0.0288849) N=(580,6300,5880 689900)
[epoch_0]_6901   loss=3.673373 |g|=0.431	lr=9.74e-04 | 65.3%@S6  T=1.39s eta=20:53:12 | 79.0K token/s | 
[epoch_0]_6911   loss=3.714897 |g|=0.419	lr=9.74e-04 | 66.2%@S6  T=968.0ms eta=14:33:12 | 79.2K token/s | 
[epoch_0]_6921   loss=3.727239 |g|=0.482	lr=9.74e-04 | 67.0%@S6  T=977.8ms eta=14:41:52 | 79.5K token/s | 
[epoch_0]_6931   loss=3.677108 |g|=0.428	lr=9.73e-04 | 67.8%@S6  T=979.3ms eta=14:43:06 | 79.7K token/s | 
[epoch_0]_6941   loss=3.627556 |g|=0.456	lr=9.73e-04 | 68.6%@S6  T=974.6ms eta=14:38:39 | 79.9K token/s | 
[epoch_0]_6951   loss=3.665263 |g|=0.432	lr=9.73e-04 | 69.4%@S6  T=977.0ms eta=14:40:42 | 80.1K token/s | 
[epoch_0]_6961   loss=3.645336 |g|=0.437	lr=9.73e-04 | 70.2%@S6  T=976.2ms eta=14:39:47 | 80.3K token/s | 
[epoch_0]_6971   loss=3.663382 |g|=0.392	lr=9.73e-04 | 71.1%@S6  T=983.9ms eta=14:46:32 | 80.4K token/s | 
[epoch_0]_6981   loss=3.704684 |g|=0.378	lr=9.73e-04 | 71.9%@S6  T=984.9ms eta=14:47:17 | 80.6K token/s | 
[epoch_0]_6991   loss=3.663125 |g|=0.358	lr=9.73e-04 | 72.7%@S6  T=977.5ms eta=14:40:29 | 80.7K token/s | 
[Fuyou] head="3" update algorithm=4 t=2.07s
[eval] 
	 Loss@"edu_fineweb1B"=3.734(0.0058) nBranch=1 nToken=4.01M best=3.7402(33) E2T=0.0238 T=13.4819(0)s x=0
	#3.73437±0.1080 tps=298K(4.01408M) a=[3.53377,4.00119] T=13.4819(sec)
[Section@7000] layer[24-30] tasks=15(nPassBack=0) last_loss=3.71053(0.0478876) N=(580,6384,5964 699900)
[epoch_0]_7001   loss=3.692760 |g|=0.353	lr=9.73e-04 | 73.5%@S6  T=4.10s eta=2d 13:31:25 | 77.7K token/s | 
[epoch_0]_7011   loss=3.669600 |g|=0.425	lr=9.73e-04 | 74.3%@S6  T=992.2ms eta=14:53:21 | 77.9K token/s | 
[epoch_0]_7021   loss=3.683352 |g|=0.379	lr=9.73e-04 | 75.2%@S6  T=976.7ms eta=14:39:16 | 78.2K token/s | 
[epoch_0]_7031   loss=3.752345 |g|=0.392	lr=9.73e-04 | 76.0%@S6  T=974.7ms eta=14:37:18 | 78.5K token/s | 
[epoch_0]_7041   loss=3.713108 |g|=0.448	lr=9.73e-04 | 76.8%@S6  T=975.0ms eta=14:37:22 | 78.8K token/s | 
[epoch_0]_7051   loss=3.689216 |g|=0.379	lr=9.72e-04 | 77.6%@S6  T=990.9ms eta=14:51:30 | 79.0K token/s | 
[epoch_0]_7061   loss=3.638796 |g|=0.389	lr=9.72e-04 | 78.4%@S6  T=975.3ms eta=14:37:20 | 79.2K token/s | 
[epoch_0]_7071   loss=3.792912 |g|=0.455	lr=9.72e-04 | 79.3%@S6  T=979.1ms eta=14:40:34 | 79.5K token/s | 
[epoch_0]_7081   loss=3.781956 |g|=0.399	lr=9.72e-04 | 80.1%@S6  T=972.6ms eta=14:34:35 | 79.7K token/s | 
[epoch_0]_7091   loss=3.685705 |g|=0.404	lr=9.72e-04 | 80.9%@S6  T=975.3ms eta=14:36:52 | 79.9K token/s | 
[Fuyou] head="4" update algorithm=4 t=2.09s
[Section@7100] layer[30-36] tasks=15(nPassBack=0) last_loss=3.66439(0.0185704) N=(580,6468,6048 709900)
[epoch_0]_7101   loss=3.624254 |g|=0.491	lr=9.72e-04 | 81.7%@S6  T=1.40s eta=20:56:02 | 78.9K token/s | 
[epoch_0]_7111   loss=3.676927 |g|=0.419	lr=9.72e-04 | 82.5%@S6  T=967.9ms eta=14:29:53 | 79.1K token/s | 
[epoch_0]_7121   loss=3.673241 |g|=0.386	lr=9.72e-04 | 83.4%@S6  T=985.4ms eta=14:45:27 | 79.3K token/s | 
[epoch_0]_7131   loss=3.656363 |g|=0.396	lr=9.72e-04 | 84.2%@S6  T=968.7ms eta=14:30:19 | 79.6K token/s | 
[epoch_0]_7141   loss=3.652125 |g|=0.402	lr=9.72e-04 | 85.0%@S6  T=967.4ms eta=14:28:54 | 79.9K token/s | 
[epoch_0]_7151   loss=3.595970 |g|=0.395	lr=9.72e-04 | 85.8%@S6  T=968.2ms eta=14:29:29 | 80.1K token/s | 
[epoch_0]_7161   loss=3.646411 |g|=0.408	lr=9.71e-04 | 86.6%@S6  T=975.7ms eta=14:36:02 | 80.3K token/s | 
[epoch_0]_7171   loss=3.722028 |g|=0.38	lr=9.71e-04 | 87.5%@S6  T=981.7ms eta=14:41:16 | 80.4K token/s | 
[epoch_0]_7181   loss=3.650446 |g|=0.394	lr=9.71e-04 | 88.3%@S6  T=998.2ms eta=14:55:55 | 80.5K token/s | 
[epoch_0]_7191   loss=3.699715 |g|=0.386	lr=9.71e-04 | 89.1%@S6  T=964.4ms eta=14:25:25 | 80.7K token/s | 
[Fuyou] head="5" update algorithm=4 t=2.06s
[eval] 
	 Loss@"edu_fineweb1B"=3.728(0.0061) nBranch=1 nToken=4.01M best=3.7344(34) E2T=0.00316 T=13.4844(0)s x=0
	#3.72826±0.1097 tps=298K(4.01408M) a=[3.51938,3.99711] T=13.4844(sec)
[Section@7200] layer[0-6] tasks=15(nPassBack=0) last_loss=3.7251(-0.0654211) N=(580,6552,6132 719900)
[epoch_0]_7201   loss=3.641457 |g|=0.411	lr=9.71e-04 | 89.9%@S6  T=4.09s eta=2d 13:10:05 | 77.7K token/s | 
[epoch_0]_7211   loss=3.621719 |g|=0.406	lr=9.71e-04 | 90.7%@S6  T=966.5ms eta=14:27:00 | 78.1K token/s | 
[epoch_0]_7221   loss=3.663543 |g|=0.412	lr=9.71e-04 | 91.5%@S6  T=970.2ms eta=14:30:11 | 78.4K token/s | 
[epoch_0]_7231   loss=3.640420 |g|=0.429	lr=9.71e-04 | 92.4%@S6  T=989.5ms eta=14:47:20 | 78.6K token/s | 
[epoch_0]_7241   loss=3.652696 |g|=0.384	lr=9.71e-04 | 93.2%@S6  T=967.5ms eta=14:27:24 | 78.9K token/s | 
[epoch_0]_7251   loss=3.697487 |g|=0.373	lr=9.71e-04 | 94.0%@S6  T=964.2ms eta=14:24:17 | 79.2K token/s | 
[epoch_0]_7261   loss=3.740291 |g|=0.411	lr=9.71e-04 | 94.8%@S6  T=970.7ms eta=14:29:58 | 79.5K token/s | 
[epoch_0]_7271   loss=3.628953 |g|=0.353	lr=9.71e-04 | 95.6%@S6  T=970.9ms eta=14:30:01 | 79.7K token/s | 
[epoch_0]_7281   loss=3.688663 |g|=0.462	lr=9.70e-04 | 96.5%@S6  T=966.7ms eta=14:26:02 | 80.0K token/s | 
[epoch_0]_7291   loss=3.593492 |g|=0.401	lr=9.70e-04 | 97.3%@S6  T=976.0ms eta=14:34:12 | 80.2K token/s | 
[Fuyou] head="0" update algorithm=4 t=2.07s
[Section@7300] layer[6-12] tasks=15(nPassBack=0) last_loss=3.628(0.0398643) N=(580,6636,6216 729900)
[epoch_0]_7301   loss=3.709325 |g|=0.441	lr=9.70e-04 | 98.1%@S6  T=1.25s eta=18:43:01 | 79.4K token/s | 
[epoch_0]_7311   loss=3.653870 |g|=0.421	lr=9.70e-04 | 98.9%@S6  T=965.9ms eta=14:24:49 | 79.7K token/s | 
[epoch_0]_7321   loss=3.684847 |g|=0.47	lr=9.70e-04 | 99.7%@S6  T=964.2ms eta=14:23:10 | 80.0K token/s | 
[epoch_0]_7324   loss=3.680063 |g|=0.395	lr=9.70e-04 | 100.0%@S6  T=964.5ms eta=14:23:26 | 80.2K token/s | 
-------- End of shard_6@"./Datasets/edu_fineweb1B/edu_fineweb_train_000006.bin"-------- 
[shard-7]@"./Datasets/edu_fineweb1B/edu_fineweb_train_000007.bin": tokens=100(M) nShardSamples=1220(683592) 
[epoch_0]_7331   loss=3.645732 |g|=0.393	lr=9.70e-04 | 0.6%@S7  T=960.3ms eta=14:19:34 | 80.5K token/s | 
[epoch_0]_7341   loss=3.685480 |g|=0.403	lr=9.70e-04 | 1.4%@S7  T=967.0ms eta=14:25:23 | 80.7K token/s | 
[epoch_0]_7351   loss=3.704678 |g|=0.382	lr=9.70e-04 | 2.2%@S7  T=971.0ms eta=14:28:47 | 80.9K token/s | 
[epoch_0]_7361   loss=3.699373 |g|=0.389	lr=9.70e-04 | 3.0%@S7  T=976.9ms eta=14:33:55 | 81.0K token/s | 
[epoch_0]_7371   loss=3.589904 |g|=0.39	lr=9.70e-04 | 3.8%@S7  T=959.1ms eta=14:17:49 | 81.2K token/s | 
[epoch_0]_7381   loss=3.750344 |g|=0.417	lr=9.70e-04 | 4.7%@S7  T=970.2ms eta=14:27:37 | 81.4K token/s | 
[epoch_0]_7391   loss=3.670117 |g|=0.407	lr=9.69e-04 | 5.5%@S7  T=962.0ms eta=14:20:05 | 81.6K token/s | 
[Fuyou] head="1" update algorithm=4 t=2.06s
[eval] 
	 Loss@"edu_fineweb1B"=3.707(0.021) nBranch=1 nToken=4.01M best=3.7283(35) E2T=-0.026 T=13.4766(0)s x=0
	#3.70702±0.1088 tps=298K(4.01408M) a=[3.50343,3.9754] T=13.4766(sec)
[Section@7400] layer[12-18] tasks=15(nPassBack=0) last_loss=3.73301(-0.0310161) N=(580,6720,6300 739900)
[epoch_0]_7401   loss=3.678421 |g|=0.374	lr=9.69e-04 | 6.3%@S7  T=4.09s eta=2d 12:53:20 | 78.5K token/s | 
[epoch_0]_7411   loss=3.658209 |g|=0.391	lr=9.69e-04 | 7.1%@S7  T=983.8ms eta=14:39:17 | 78.7K token/s | 
[epoch_0]_7421   loss=3.682121 |g|=0.407	lr=9.69e-04 | 7.9%@S7  T=969.7ms eta=14:26:31 | 79.0K token/s | 
[epoch_0]_7431   loss=3.666655 |g|=0.42	lr=9.69e-04 | 8.8%@S7  T=966.1ms eta=14:23:06 | 79.3K token/s | 
[epoch_0]_7441   loss=3.610685 |g|=0.407	lr=9.69e-04 | 9.6%@S7  T=972.4ms eta=14:28:34 | 79.6K token/s | 
[epoch_0]_7451   loss=3.632577 |g|=0.481	lr=9.69e-04 | 10.4%@S7  T=968.5ms eta=14:24:53 | 79.8K token/s | 
[epoch_0]_7461   loss=3.597176 |g|=0.413	lr=9.69e-04 | 11.2%@S7  T=981.0ms eta=14:35:57 | 80.0K token/s | 
[epoch_0]_7471   loss=3.593192 |g|=0.385	lr=9.69e-04 | 12.0%@S7  T=962.7ms eta=14:19:28 | 80.3K token/s | 
[epoch_0]_7481   loss=3.649042 |g|=0.395	lr=9.69e-04 | 12.8%@S7  T=963.2ms eta=14:19:43 | 80.5K token/s | 
[epoch_0]_7491   loss=3.629300 |g|=0.385	lr=9.69e-04 | 13.7%@S7  T=965.6ms eta=14:21:41 | 80.7K token/s | 
[Fuyou] head="2" update algorithm=4 t=2.06s
[Section@7500] layer[18-24] tasks=15(nPassBack=0) last_loss=3.65111(0.0447903) N=(580,6804,6384 749900)
[epoch_0]_7501   loss=3.706530 |g|=0.404	lr=9.68e-04 | 14.5%@S7  T=1.26s eta=18:42:32 | 79.9K token/s | 
[epoch_0]_7511   loss=3.714754 |g|=0.43	lr=9.68e-04 | 15.3%@S7  T=967.5ms eta=14:23:06 | 80.2K token/s | 
[epoch_0]_7521   loss=3.682050 |g|=0.4	lr=9.68e-04 | 16.1%@S7  T=985.6ms eta=14:39:05 | 80.3K token/s | 
[epoch_0]_7531   loss=3.717861 |g|=0.525	lr=9.68e-04 | 16.9%@S7  T=981.9ms eta=14:35:36 | 80.5K token/s | 
[epoch_0]_7541   loss=3.670150 |g|=0.365	lr=9.68e-04 | 17.8%@S7  T=969.5ms eta=14:24:24 | 80.7K token/s | 
[epoch_0]_7551   loss=3.717766 |g|=0.485	lr=9.68e-04 | 18.6%@S7  T=963.4ms eta=14:18:47 | 80.9K token/s | 
[epoch_0]_7561   loss=3.667968 |g|=0.339	lr=9.68e-04 | 19.4%@S7  T=969.4ms eta=14:23:55 | 81.1K token/s | 
[epoch_0]_7571   loss=3.699146 |g|=0.43	lr=9.68e-04 | 20.2%@S7  T=974.5ms eta=14:28:22 | 81.2K token/s | 
[epoch_0]_7581   loss=3.642869 |g|=0.35	lr=9.68e-04 | 21.0%@S7  T=970.2ms eta=14:24:18 | 81.4K token/s | 
[epoch_0]_7591   loss=3.601779 |g|=0.373	lr=9.68e-04 | 21.9%@S7  T=981.4ms eta=14:34:09 | 81.5K token/s | 
[Fuyou] head="3" update algorithm=4 t=2.04s
[eval] 
	 Loss@"edu_fineweb1B"=3.690(0.018) nBranch=1 nToken=4.01M best=3.7070(36) E2T=0.0922 T=13.4888(0)s x=0
	#3.68952±0.1078 tps=298K(4.01408M) a=[3.49337,3.96232] T=13.4888(sec)
[Section@7600] layer[24-30] tasks=15(nPassBack=0) last_loss=3.59729(0.113238) N=(580,6888,6468 759900)
[epoch_0]_7601   loss=3.657700 |g|=0.399	lr=9.68e-04 | 22.7%@S7  T=4.09s eta=2d 12:45:58 | 78.4K token/s | 
[epoch_0]_7611   loss=3.686192 |g|=0.391	lr=9.67e-04 | 23.5%@S7  T=980.2ms eta=14:32:44 | 78.7K token/s | 
[epoch_0]_7621   loss=3.696753 |g|=0.4	lr=9.67e-04 | 24.3%@S7  T=989.5ms eta=14:40:54 | 78.9K token/s | 
[epoch_0]_7631   loss=3.609437 |g|=0.386	lr=9.67e-04 | 25.1%@S7  T=975.6ms eta=14:28:22 | 79.1K token/s | 
[epoch_0]_7641   loss=3.766180 |g|=0.461	lr=9.67e-04 | 26.0%@S7  T=968.0ms eta=14:21:24 | 79.4K token/s | 
[epoch_0]_7651   loss=3.653368 |g|=0.408	lr=9.67e-04 | 26.8%@S7  T=967.5ms eta=14:20:50 | 79.7K token/s | 
[epoch_0]_7661   loss=3.728203 |g|=0.362	lr=9.67e-04 | 27.6%@S7  T=983.0ms eta=14:34:26 | 79.9K token/s | 
[epoch_0]_7671   loss=3.696818 |g|=0.362	lr=9.67e-04 | 28.4%@S7  T=964.7ms eta=14:18:02 | 80.1K token/s | 
[epoch_0]_7681   loss=3.607528 |g|=0.396	lr=9.67e-04 | 29.2%@S7  T=964.8ms eta=14:17:56 | 80.3K token/s | 
[epoch_0]_7691   loss=3.686145 |g|=0.414	lr=9.67e-04 | 30.0%@S7  T=965.7ms eta=14:18:33 | 80.6K token/s | 
[Fuyou] head="4" update algorithm=4 t=2.03s
[Section@7700] layer[30-36] tasks=15(nPassBack=0) last_loss=3.68481(-0.0204208) N=(580,6972,6552 769900)
[epoch_0]_7701   loss=3.687259 |g|=0.419	lr=9.67e-04 | 30.9%@S7  T=1.24s eta=18:21:06 | 79.8K token/s | 
[epoch_0]_7711   loss=3.680541 |g|=0.433	lr=9.67e-04 | 31.7%@S7  T=963.6ms eta=14:16:25 | 80.1K token/s | 
[epoch_0]_7721   loss=3.662636 |g|=0.387	lr=9.66e-04 | 32.5%@S7  T=966.6ms eta=14:18:51 | 80.3K token/s | 
[epoch_0]_7731   loss=3.614628 |g|=0.453	lr=9.66e-04 | 33.3%@S7  T=971.5ms eta=14:23:05 | 80.5K token/s | 
[epoch_0]_7741   loss=3.686223 |g|=0.426	lr=9.66e-04 | 34.1%@S7  T=967.9ms eta=14:19:44 | 80.7K token/s | 
[epoch_0]_7751   loss=3.683860 |g|=0.411	lr=9.66e-04 | 35.0%@S7  T=971.7ms eta=14:22:56 | 80.9K token/s | 
[epoch_0]_7761   loss=3.607502 |g|=0.403	lr=9.66e-04 | 35.8%@S7  T=970.8ms eta=14:22:01 | 81.1K token/s | 
[epoch_0]_7771   loss=3.675210 |g|=0.401	lr=9.66e-04 | 36.6%@S7  T=976.1ms eta=14:26:29 | 81.2K token/s | 
[epoch_0]_7781   loss=3.657263 |g|=0.387	lr=9.66e-04 | 37.4%@S7  T=970.9ms eta=14:21:43 | 81.4K token/s | 
[epoch_0]_7791   loss=3.695853 |g|=0.449	lr=9.66e-04 | 38.2%@S7  T=977.0ms eta=14:26:59 | 81.5K token/s | 
[Fuyou] head="5" update algorithm=4 t=2.04s
[eval] 
	 Loss@"edu_fineweb1B"=3.678(0.011) nBranch=1 nToken=4.01M best=3.6895(37) E2T=0.0216 T=13.4908(0)s x=0
	#3.67827±0.1095 tps=298K(4.01408M) a=[3.47958,3.95294] T=13.4908(sec)
[Section@7800] layer[0-6] tasks=15(nPassBack=0) last_loss=3.6567(0.0684021) N=(580,7056,6636 779900)
[epoch_0]_7801   loss=3.610467 |g|=0.41	lr=9.66e-04 | 39.1%@S7  T=4.09s eta=2d 12:29:20 | 78.4K token/s | 
[epoch_0]_7811   loss=3.570324 |g|=0.406	lr=9.66e-04 | 39.9%@S7  T=972.4ms eta=14:22:32 | 78.7K token/s | 
[epoch_0]_7821   loss=3.809817 |g|=0.386	lr=9.66e-04 | 40.7%@S7  T=973.8ms eta=14:23:38 | 79.0K token/s | 
[epoch_0]_7831   loss=3.690953 |g|=0.405	lr=9.65e-04 | 41.5%@S7  T=969.7ms eta=14:19:51 | 79.3K token/s | 
[epoch_0]_7841   loss=3.708236 |g|=0.403	lr=9.65e-04 | 42.3%@S7  T=967.7ms eta=14:17:56 | 79.5K token/s | 
[epoch_0]_7851   loss=3.691925 |g|=0.41	lr=9.65e-04 | 43.2%@S7  T=962.3ms eta=14:13:01 | 79.8K token/s | 
[epoch_0]_7861   loss=3.668720 |g|=0.343	lr=9.65e-04 | 44.0%@S7  T=972.2ms eta=14:21:37 | 80.0K token/s | 
[epoch_0]_7871   loss=3.608032 |g|=0.404	lr=9.65e-04 | 44.8%@S7  T=974.2ms eta=14:23:13 | 80.2K token/s | 
[epoch_0]_7881   loss=3.586369 |g|=0.466	lr=9.65e-04 | 45.6%@S7  T=969.6ms eta=14:19:00 | 80.5K token/s | 
[epoch_0]_7891   loss=3.652854 |g|=0.402	lr=9.65e-04 | 46.4%@S7  T=979.0ms eta=14:27:05 | 80.6K token/s | 
[Fuyou] head="0" update algorithm=4 t=2.04s
[Section@7900] layer[6-12] tasks=15(nPassBack=0) last_loss=3.66026(-0.0322607) N=(580,7140,6720 789900)
[epoch_0]_7901   loss=3.612244 |g|=0.506	lr=9.65e-04 | 47.3%@S7  T=1.37s eta=20:11:13 | 79.6K token/s | 
[epoch_0]_7911   loss=3.637708 |g|=0.368	lr=9.65e-04 | 48.1%@S7  T=970.9ms eta=14:19:38 | 79.8K token/s | 
[epoch_0]_7921   loss=3.617866 |g|=0.411	lr=9.65e-04 | 48.9%@S7  T=979.5ms eta=14:27:05 | 80.0K token/s | 
[epoch_0]_7931   loss=3.597400 |g|=0.374	lr=9.64e-04 | 49.7%@S7  T=964.5ms eta=14:13:39 | 80.3K token/s | 
[epoch_0]_7941   loss=3.704702 |g|=0.478	lr=9.64e-04 | 50.5%@S7  T=981.4ms eta=14:28:28 | 80.4K token/s | 
[epoch_0]_7951   loss=3.614612 |g|=0.436	lr=9.64e-04 | 51.3%@S7  T=970.8ms eta=14:18:52 | 80.6K token/s | 
[epoch_0]_7961   loss=3.712094 |g|=0.464	lr=9.64e-04 | 52.2%@S7  T=971.2ms eta=14:19:05 | 80.8K token/s | 
[epoch_0]_7971   loss=3.737613 |g|=0.42	lr=9.64e-04 | 53.0%@S7  T=987.6ms eta=14:33:23 | 80.9K token/s | 
[epoch_0]_7981   loss=3.615679 |g|=0.384	lr=9.64e-04 | 53.8%@S7  T=976.8ms eta=14:23:44 | 81.1K token/s | 
[epoch_0]_7991   loss=3.586213 |g|=0.405	lr=9.64e-04 | 54.6%@S7  T=971.9ms eta=14:19:11 | 81.2K token/s | 
[Fuyou] head="1" update algorithm=4 t=2.02s
[eval] 
	 Loss@"edu_fineweb1B"=3.672(0.0066) nBranch=1 nToken=4.01M best=3.6783(38) E2T=0.0517 T=13.4858(0)s x=0
	#3.67169±0.1099 tps=298K(4.01408M) a=[3.47181,3.94173] T=13.4858(sec)
[Section@8000] layer[12-18] tasks=15(nPassBack=0) last_loss=3.61998(0.113027) N=(580,7224,6804 799900)
[epoch_0]_8001   loss=3.644185 |g|=0.459	lr=9.64e-04 | 55.4%@S7  T=4.09s eta=2d 12:15:18 | 78.2K token/s | 
[epoch_0]_8011   loss=3.592601 |g|=0.403	lr=9.64e-04 | 56.3%@S7  T=981.5ms eta=14:27:24 | 78.4K token/s | 
[epoch_0]_8021   loss=3.573365 |g|=0.356	lr=9.64e-04 | 57.1%@S7  T=973.2ms eta=14:19:51 | 78.7K token/s | 
[epoch_0]_8031   loss=3.682203 |g|=0.402	lr=9.64e-04 | 57.9%@S7  T=967.7ms eta=14:14:52 | 79.0K token/s | 
[epoch_0]_8041   loss=3.675050 |g|=0.403	lr=9.63e-04 | 58.7%@S7  T=972.4ms eta=14:18:48 | 79.3K token/s | 
[epoch_0]_8051   loss=3.701008 |g|=0.465	lr=9.63e-04 | 59.5%@S7  T=985.4ms eta=14:30:09 | 79.5K token/s | 
[epoch_0]_8061   loss=3.628714 |g|=0.391	lr=9.63e-04 | 60.4%@S7  T=984.4ms eta=14:29:09 | 79.7K token/s | 
[epoch_0]_8071   loss=3.607687 |g|=0.395	lr=9.63e-04 | 61.2%@S7  T=960.4ms eta=14:07:44 | 79.9K token/s | 
[epoch_0]_8081   loss=3.610940 |g|=0.443	lr=9.63e-04 | 62.0%@S7  T=969.4ms eta=14:15:33 | 80.2K token/s | 
[epoch_0]_8091   loss=3.634179 |g|=0.388	lr=9.63e-04 | 62.8%@S7  T=968.5ms eta=14:14:35 | 80.4K token/s | 
[Fuyou] head="2" update algorithm=4 t=2.06s
[Section@8100] layer[18-24] tasks=15(nPassBack=0) last_loss=3.65161(-0.000504732) N=(580,7308,6888 809900)
[epoch_0]_8101   loss=3.590051 |g|=0.413	lr=9.63e-04 | 63.6%@S7  T=1.24s eta=18:14:18 | 79.7K token/s | 
[epoch_0]_8111   loss=3.646145 |g|=0.412	lr=9.63e-04 | 64.5%@S7  T=965.4ms eta=14:11:32 | 79.9K token/s | 
[epoch_0]_8121   loss=3.667150 |g|=0.442	lr=9.63e-04 | 65.3%@S7  T=967.8ms eta=14:13:31 | 80.2K token/s | 
[epoch_0]_8131   loss=3.687837 |g|=0.434	lr=9.63e-04 | 66.1%@S7  T=983.4ms eta=14:27:06 | 80.3K token/s | 
[epoch_0]_8141   loss=3.519251 |g|=0.356	lr=9.62e-04 | 66.9%@S7  T=964.1ms eta=14:09:56 | 80.6K token/s | 
[epoch_0]_8151   loss=3.642499 |g|=0.402	lr=9.62e-04 | 67.7%@S7  T=968.3ms eta=14:13:27 | 80.8K token/s | 
[epoch_0]_8161   loss=3.629386 |g|=0.414	lr=9.62e-04 | 68.6%@S7  T=972.2ms eta=14:16:44 | 80.9K token/s | 
[epoch_0]_8171   loss=3.717430 |g|=0.405	lr=9.62e-04 | 69.4%@S7  T=985.4ms eta=14:28:12 | 81.0K token/s | 
[epoch_0]_8181   loss=3.638294 |g|=0.467	lr=9.62e-04 | 70.2%@S7  T=985.8ms eta=14:28:21 | 81.1K token/s | 
[epoch_0]_8191   loss=3.621274 |g|=0.395	lr=9.62e-04 | 71.0%@S7  T=968.8ms eta=14:13:16 | 81.3K token/s | 
[Fuyou] head="3" update algorithm=4 t=2.07s
[eval] 
	 Loss@"edu_fineweb1B"=3.663(0.009) nBranch=1 nToken=4.01M best=3.6717(39) E2T=-0.00992 T=13.4842(0)s x=0
	#3.66268±0.1097 tps=298K(4.01408M) a=[3.45927,3.9343] T=13.4842(sec)
[Section@8200] layer[24-30] tasks=15(nPassBack=0) last_loss=3.6726(-0.0753121) N=(580,7392,6972 819900)
[epoch_0]_8201   loss=3.646231 |g|=0.373	lr=9.62e-04 | 71.8%@S7  T=4.09s eta=2d 12:05:38 | 78.2K token/s | 
[epoch_0]_8211   loss=3.677952 |g|=0.381	lr=9.62e-04 | 72.6%@S7  T=965.0ms eta=14:09:37 | 78.6K token/s | 
[epoch_0]_8221   loss=3.628502 |g|=0.358	lr=9.62e-04 | 73.5%@S7  T=976.1ms eta=14:19:10 | 78.8K token/s | 
[epoch_0]_8231   loss=3.688836 |g|=0.406	lr=9.62e-04 | 74.3%@S7  T=985.0ms eta=14:26:52 | 79.1K token/s | 
[epoch_0]_8241   loss=3.678713 |g|=0.407	lr=9.61e-04 | 75.1%@S7  T=990.3ms eta=14:31:19 | 79.2K token/s | 
[epoch_0]_8251   loss=3.603838 |g|=0.48	lr=9.61e-04 | 75.9%@S7  T=970.8ms eta=14:14:04 | 79.5K token/s | 
[epoch_0]_8261   loss=3.604690 |g|=0.424	lr=9.61e-04 | 76.7%@S7  T=965.2ms eta=14:09:00 | 79.8K token/s | 
[epoch_0]_8271   loss=3.578698 |g|=0.371	lr=9.61e-04 | 77.6%@S7  T=969.9ms eta=14:12:53 | 80.0K token/s | 
[epoch_0]_8281   loss=3.688904 |g|=0.407	lr=9.61e-04 | 78.4%@S7  T=969.7ms eta=14:12:36 | 80.2K token/s | 
[epoch_0]_8291   loss=3.672748 |g|=0.434	lr=9.61e-04 | 79.2%@S7  T=967.6ms eta=14:10:33 | 80.5K token/s | 
[Fuyou] head="4" update algorithm=4 t=2.09s
[Section@8300] layer[30-36] tasks=15(nPassBack=0) last_loss=3.59662(0.0881965) N=(580,7476,7056 829900)
[epoch_0]_8301   loss=3.639443 |g|=0.39	lr=9.61e-04 | 80.0%@S7  T=1.25s eta=18:20:49 | 79.7K token/s | 
[epoch_0]_8311   loss=3.658679 |g|=0.369	lr=9.61e-04 | 80.8%@S7  T=972.3ms eta=14:14:23 | 79.9K token/s | 
[epoch_0]_8321   loss=3.609596 |g|=0.448	lr=9.61e-04 | 81.7%@S7  T=978.1ms eta=14:19:21 | 80.1K token/s | 
[epoch_0]_8331   loss=3.631082 |g|=0.382	lr=9.61e-04 | 82.5%@S7  T=983.7ms eta=14:24:03 | 80.3K token/s | 
[epoch_0]_8341   loss=3.577168 |g|=0.371	lr=9.60e-04 | 83.3%@S7  T=984.1ms eta=14:24:14 | 80.4K token/s | 
[epoch_0]_8351   loss=3.562653 |g|=0.395	lr=9.60e-04 | 84.1%@S7  T=977.6ms eta=14:18:25 | 80.6K token/s | 
[epoch_0]_8361   loss=3.589248 |g|=0.335	lr=9.60e-04 | 84.9%@S7  T=966.0ms eta=14:08:02 | 80.8K token/s | 
[epoch_0]_8371   loss=3.602691 |g|=0.383	lr=9.60e-04 | 85.8%@S7  T=973.1ms eta=14:14:05 | 81.0K token/s | 
[epoch_0]_8381   loss=3.567138 |g|=0.37	lr=9.60e-04 | 86.6%@S7  T=970.9ms eta=14:12:00 | 81.1K token/s | 
[epoch_0]_8391   loss=3.555964 |g|=0.402	lr=9.60e-04 | 87.4%@S7  T=976.6ms eta=14:16:50 | 81.3K token/s | 
[Fuyou] head="5" update algorithm=4 t=2.06s
[eval] 
	 Loss@"edu_fineweb1B"=3.655(0.0075) nBranch=1 nToken=4.01M best=3.6627(40) E2T=0.0212 T=13.4788(0)s x=0
	#3.65516±0.1103 tps=298K(4.01408M) a=[3.4573,3.92675] T=13.4788(sec)
[Section@8400] layer[0-6] tasks=15(nPassBack=0) last_loss=3.63392(0.0227802) N=(580,7560,7140 839900)
[epoch_0]_8401   loss=3.623966 |g|=0.402	lr=9.60e-04 | 88.2%@S7  T=4.09s eta=2d 11:51:06 | 78.2K token/s | 
[epoch_0]_8411   loss=3.667641 |g|=0.451	lr=9.60e-04 | 89.0%@S7  T=974.1ms eta=14:14:19 | 78.5K token/s | 
[epoch_0]_8421   loss=3.576751 |g|=0.371	lr=9.60e-04 | 89.9%@S7  T=970.7ms eta=14:11:10 | 78.8K token/s | 
[epoch_0]_8431   loss=3.726813 |g|=0.572	lr=9.60e-04 | 90.7%@S7  T=968.6ms eta=14:09:13 | 79.1K token/s | 
[epoch_0]_8441   loss=3.599817 |g|=0.376	lr=9.59e-04 | 91.5%@S7  T=988.4ms eta=14:26:22 | 79.3K token/s | 
[epoch_0]_8451   loss=3.633528 |g|=0.402	lr=9.59e-04 | 92.3%@S7  T=988.7ms eta=14:26:30 | 79.5K token/s | 
[epoch_0]_8461   loss=3.603980 |g|=0.453	lr=9.59e-04 | 93.1%@S7  T=972.5ms eta=14:12:06 | 79.7K token/s | 
[epoch_0]_8471   loss=3.624049 |g|=0.418	lr=9.59e-04 | 93.9%@S7  T=972.1ms eta=14:11:38 | 79.9K token/s | 
[epoch_0]_8481   loss=3.640920 |g|=0.397	lr=9.59e-04 | 94.8%@S7  T=968.1ms eta=14:07:58 | 80.2K token/s | 
[epoch_0]_8491   loss=3.625654 |g|=0.375	lr=9.59e-04 | 95.6%@S7  T=974.6ms eta=14:13:28 | 80.4K token/s | 
[Fuyou] head="0" update algorithm=4 t=2.04s
[Section@8500] layer[6-12] tasks=15(nPassBack=0) last_loss=3.56243(0.0978298) N=(580,7644,7224 849900)
[epoch_0]_8501   loss=3.644262 |g|=0.368	lr=9.59e-04 | 96.4%@S7  T=1.23s eta=18:00:48 | 79.7K token/s | 
[epoch_0]_8511   loss=3.608771 |g|=0.377	lr=9.59e-04 | 97.2%@S7  T=969.7ms eta=14:08:51 | 79.9K token/s | 
[epoch_0]_8521   loss=3.622293 |g|=0.453	lr=9.59e-04 | 98.0%@S7  T=970.7ms eta=14:09:32 | 80.1K token/s | 
[epoch_0]_8531   loss=3.664081 |g|=0.487	lr=9.59e-04 | 98.9%@S7  T=970.7ms eta=14:09:24 | 80.3K token/s | 
[epoch_0]_8541   loss=3.710754 |g|=0.392	lr=9.58e-04 | 99.7%@S7  T=969.3ms eta=14:08:03 | 80.5K token/s | 
[epoch_0]_8544   loss=3.587815 |g|=0.416	lr=9.58e-04 | 99.9%@S7  T=987.7ms eta=14:24:07 | 80.7K token/s | 
-------- End of shard_7@"./Datasets/edu_fineweb1B/edu_fineweb_train_000007.bin"-------- 
[shard-8]@"./Datasets/edu_fineweb1B/edu_fineweb_train_000008.bin": tokens=100(M) nShardSamples=1220(781248) 
[epoch_0]_8551   loss=3.668149 |g|=0.371	lr=9.58e-04 | 0.5%@S8  T=972.8ms eta=14:10:58 | 80.8K token/s | 
[epoch_0]_8561   loss=3.724668 |g|=0.373	lr=9.58e-04 | 1.3%@S8  T=987.7ms eta=14:23:49 | 80.9K token/s | 
[epoch_0]_8571   loss=3.624223 |g|=0.4	lr=9.58e-04 | 2.1%@S8  T=984.9ms eta=14:21:14 | 81.1K token/s | 
[epoch_0]_8581   loss=3.665178 |g|=0.388	lr=9.58e-04 | 3.0%@S8  T=962.8ms eta=14:01:40 | 81.3K token/s | 
[epoch_0]_8591   loss=3.631505 |g|=0.401	lr=9.58e-04 | 3.8%@S8  T=968.0ms eta=14:06:06 | 81.4K token/s | 
[Fuyou] head="1" update algorithm=4 t=2.38s
[eval] 
	 Loss@"edu_fineweb1B"=3.649(0.0065) nBranch=1 nToken=4.01M best=3.6552(41) E2T=-0.0103 T=13.4777(0)s x=0
	#3.64868±0.1099 tps=298K(4.01408M) a=[3.45347,3.92613] T=13.4777(sec)
[Section@8600] layer[12-18] tasks=15(nPassBack=0) last_loss=3.65898(-0.0389988) N=(580,7728,7308 859900)
[epoch_0]_8601   loss=3.721793 |g|=0.44	lr=9.58e-04 | 4.6%@S8  T=4.11s eta=2d 11:52:34 | 78.4K token/s | 
[epoch_0]_8611   loss=3.607549 |g|=0.373	lr=9.58e-04 | 5.4%@S8  T=972.5ms eta=14:09:43 | 78.6K token/s | 
[epoch_0]_8621   loss=3.640703 |g|=0.447	lr=9.58e-04 | 6.2%@S8  T=984.0ms eta=14:19:36 | 78.9K token/s | 
[epoch_0]_8631   loss=3.677108 |g|=0.393	lr=9.57e-04 | 7.1%@S8  T=966.7ms eta=14:04:16 | 79.2K token/s | 
[epoch_0]_8641   loss=3.696771 |g|=0.386	lr=9.57e-04 | 7.9%@S8  T=959.4ms eta=13:57:45 | 79.5K token/s | 
[epoch_0]_8651   loss=3.684089 |g|=0.365	lr=9.57e-04 | 8.7%@S8  T=964.7ms eta=14:02:15 | 79.8K token/s | 
[epoch_0]_8661   loss=3.628410 |g|=0.422	lr=9.57e-04 | 9.5%@S8  T=988.3ms eta=14:22:41 | 79.9K token/s | 
[epoch_0]_8671   loss=3.747510 |g|=0.423	lr=9.57e-04 | 10.3%@S8  T=976.7ms eta=14:12:24 | 80.1K token/s | 
[epoch_0]_8681   loss=3.699366 |g|=0.381	lr=9.57e-04 | 11.2%@S8  T=975.9ms eta=14:11:33 | 80.3K token/s | 
[epoch_0]_8691   loss=3.739435 |g|=0.448	lr=9.57e-04 | 12.0%@S8  T=985.1ms eta=14:19:25 | 80.4K token/s | 
[Fuyou] head="2" update algorithm=4 t=2.07s
[Section@8700] layer[18-24] tasks=15(nPassBack=0) last_loss=3.68063(-0.0290191) N=(580,7812,7392 869900)
[epoch_0]_8701   loss=3.663327 |g|=0.382	lr=9.57e-04 | 12.8%@S8  T=1.25s eta=18:12:52 | 79.7K token/s | 
[epoch_0]_8711   loss=3.683893 |g|=0.401	lr=9.57e-04 | 13.6%@S8  T=971.4ms eta=14:07:09 | 79.9K token/s | 
[epoch_0]_8721   loss=3.718259 |g|=0.432	lr=9.57e-04 | 14.4%@S8  T=978.1ms eta=14:12:48 | 80.1K token/s | 
[epoch_0]_8731   loss=3.714891 |g|=0.382	lr=9.56e-04 | 15.2%@S8  T=989.4ms eta=14:22:28 | 80.2K token/s | 
[epoch_0]_8741   loss=3.636853 |g|=0.424	lr=9.56e-04 | 16.1%@S8  T=989.1ms eta=14:22:02 | 80.4K token/s | 
[epoch_0]_8751   loss=3.693654 |g|=0.421	lr=9.56e-04 | 16.9%@S8  T=969.0ms eta=14:04:25 | 80.6K token/s | 
[epoch_0]_8761   loss=3.605615 |g|=0.412	lr=9.56e-04 | 17.7%@S8  T=970.1ms eta=14:05:11 | 80.8K token/s | 
[epoch_0]_8771   loss=3.655940 |g|=0.423	lr=9.56e-04 | 18.5%@S8  T=973.0ms eta=14:07:33 | 80.9K token/s | 
[epoch_0]_8781   loss=3.642539 |g|=0.413	lr=9.56e-04 | 19.3%@S8  T=973.7ms eta=14:07:59 | 81.1K token/s | 
[epoch_0]_8791   loss=3.608864 |g|=0.458	lr=9.56e-04 | 20.2%@S8  T=977.1ms eta=14:10:48 | 81.2K token/s | 
[Fuyou] head="3" update algorithm=4 t=2.00s
[eval] 
	 Loss@"edu_fineweb1B"=3.644(0.0047) nBranch=1 nToken=4.01M best=3.6487(42) E2T=-0.0397 T=13.4744(0)s x=0
	#3.644±0.1096 tps=298K(4.01408M) a=[3.44883,3.92883] T=13.4744(sec)
[Section@8800] layer[24-30] tasks=15(nPassBack=0) last_loss=3.68368(-0.011081) N=(580,7896,7476 879900)
[epoch_0]_8801   loss=3.635512 |g|=0.361	lr=9.56e-04 | 21.0%@S8  T=4.09s eta=2d 11:16:40 | 78.2K token/s | 
[epoch_0]_8811   loss=3.649714 |g|=0.402	lr=9.56e-04 | 21.8%@S8  T=984.4ms eta=14:16:47 | 78.4K token/s | 
[epoch_0]_8821   loss=3.650722 |g|=0.395	lr=9.55e-04 | 22.6%@S8  T=967.8ms eta=14:02:12 | 78.7K token/s | 
[epoch_0]_8831   loss=3.683484 |g|=0.386	lr=9.55e-04 | 23.4%@S8  T=972.2ms eta=14:05:52 | 79.0K token/s | 
[epoch_0]_8841   loss=3.631976 |g|=0.343	lr=9.55e-04 | 24.3%@S8  T=971.3ms eta=14:04:54 | 79.3K token/s | 
[epoch_0]_8851   loss=3.704433 |g|=0.405	lr=9.55e-04 | 25.1%@S8  T=975.2ms eta=14:08:08 | 79.5K token/s | 
[epoch_0]_8861   loss=3.704485 |g|=0.364	lr=9.55e-04 | 25.9%@S8  T=979.1ms eta=14:11:23 | 79.7K token/s | 
[epoch_0]_8871   loss=3.619734 |g|=0.35	lr=9.55e-04 | 26.7%@S8  T=973.9ms eta=14:06:44 | 80.0K token/s | 
[epoch_0]_8881   loss=3.647214 |g|=0.428	lr=9.55e-04 | 27.5%@S8  T=968.1ms eta=14:01:28 | 80.2K token/s | 
[epoch_0]_8891   loss=3.642571 |g|=0.444	lr=9.55e-04 | 28.4%@S8  T=968.7ms eta=14:01:54 | 80.4K token/s | 
[Fuyou] head="4" update algorithm=4 t=2.04s
[Section@8900] layer[30-36] tasks=15(nPassBack=0) last_loss=3.65871(-0.0620906) N=(580,7980,7560 889900)
[epoch_0]_8901   loss=3.674486 |g|=0.404	lr=9.55e-04 | 29.2%@S8  T=1.30s eta=18:45:58 | 79.5K token/s | 
[epoch_0]_8911   loss=3.632266 |g|=0.389	lr=9.55e-04 | 30.0%@S8  T=966.6ms eta=13:59:42 | 79.8K token/s | 
[epoch_0]_8921   loss=3.676558 |g|=0.436	lr=9.54e-04 | 30.8%@S8  T=991.6ms eta=14:21:13 | 79.9K token/s | 
[epoch_0]_8931   loss=3.669032 |g|=0.453	lr=9.54e-04 | 31.6%@S8  T=969.0ms eta=14:01:29 | 80.2K token/s | 
[epoch_0]_8941   loss=3.571657 |g|=0.343	lr=9.54e-04 | 32.4%@S8  T=964.5ms eta=13:57:27 | 80.4K token/s | 
[epoch_0]_8951   loss=3.599633 |g|=0.382	lr=9.54e-04 | 33.3%@S8  T=970.1ms eta=14:02:09 | 80.6K token/s | 
[epoch_0]_8961   loss=3.698085 |g|=0.452	lr=9.54e-04 | 34.1%@S8  T=974.0ms eta=14:05:19 | 80.8K token/s | 
[epoch_0]_8971   loss=3.637613 |g|=0.405	lr=9.54e-04 | 34.9%@S8  T=973.2ms eta=14:04:30 | 81.0K token/s | 
[epoch_0]_8981   loss=3.678828 |g|=0.395	lr=9.54e-04 | 35.7%@S8  T=977.4ms eta=14:07:58 | 81.1K token/s | 
[epoch_0]_8991   loss=3.680561 |g|=0.388	lr=9.54e-04 | 36.5%@S8  T=988.8ms eta=14:17:39 | 81.2K token/s | 
[Fuyou] head="5" update algorithm=4 t=2.04s
[eval] 
	 Loss@"edu_fineweb1B"=3.643(0.00059) nBranch=1 nToken=4.01M best=3.6440(43) E2T=0.0374 T=13.4821(0)s x=0
	#3.64341±0.1094 tps=298K(4.01408M) a=[3.45359,3.92861] T=13.4821(sec)
[Section@9000] layer[0-6] tasks=15(nPassBack=0) last_loss=3.60598(0.0279405) N=(580,8064,7644 899900)
[epoch_0]_9001   loss=3.666204 |g|=0.426	lr=9.54e-04 | 37.4%@S8  T=4.08s eta=2d 10:59:31 | 78.1K token/s | 
[epoch_0]_9011   loss=3.653643 |g|=0.399	lr=9.53e-04 | 38.2%@S8  T=971.0ms eta=14:01:55 | 78.4K token/s | 
[epoch_0]_9021   loss=3.538114 |g|=0.391	lr=9.53e-04 | 39.0%@S8  T=967.6ms eta=13:58:50 | 78.8K token/s | 
[epoch_0]_9031   loss=3.716377 |g|=0.397	lr=9.53e-04 | 39.8%@S8  T=976.3ms eta=14:06:12 | 79.0K token/s | 
[epoch_0]_9041   loss=3.688450 |g|=0.429	lr=9.53e-04 | 40.6%@S8  T=983.8ms eta=14:12:32 | 79.2K token/s | 
[epoch_0]_9051   loss=3.716334 |g|=0.39	lr=9.53e-04 | 41.5%@S8  T=989.9ms eta=14:17:36 | 79.4K token/s | 
[epoch_0]_9061   loss=3.645467 |g|=0.392	lr=9.53e-04 | 42.3%@S8  T=963.9ms eta=13:54:55 | 79.7K token/s | 
[epoch_0]_9071   loss=3.679132 |g|=0.355	lr=9.53e-04 | 43.1%@S8  T=966.9ms eta=13:57:25 | 79.9K token/s | 
[epoch_0]_9081   loss=3.693723 |g|=0.361	lr=9.53e-04 | 43.9%@S8  T=967.0ms eta=13:57:20 | 80.2K token/s | 
[epoch_0]_9091   loss=3.622534 |g|=0.398	lr=9.53e-04 | 44.7%@S8  T=969.2ms eta=13:59:03 | 80.4K token/s | 
[Fuyou] head="0" update algorithm=4 t=2.05s
[Section@9100] layer[6-12] tasks=15(nPassBack=0) last_loss=3.64361(-0.0811834) N=(580,8148,7728 909900)
[epoch_0]_9101   loss=3.662691 |g|=0.413	lr=9.52e-04 | 45.6%@S8  T=1.36s eta=19:37:44 | 79.4K token/s | 
[epoch_0]_9111   loss=3.668754 |g|=0.426	lr=9.52e-04 | 46.4%@S8  T=974.7ms eta=14:03:30 | 79.6K token/s | 
[epoch_0]_9121   loss=3.625468 |g|=0.367	lr=9.52e-04 | 47.2%@S8  T=968.2ms eta=13:57:44 | 79.9K token/s | 
[epoch_0]_9131   loss=3.619230 |g|=0.382	lr=9.52e-04 | 48.0%@S8  T=969.7ms eta=13:58:50 | 80.1K token/s | 
[epoch_0]_9141   loss=3.653374 |g|=0.472	lr=9.52e-04 | 48.8%@S8  T=972.8ms eta=14:01:22 | 80.3K token/s | 
[epoch_0]_9151   loss=3.601853 |g|=0.401	lr=9.52e-04 | 49.7%@S8  T=972.3ms eta=14:00:48 | 80.5K token/s | 
[epoch_0]_9161   loss=3.659395 |g|=0.395	lr=9.52e-04 | 50.5%@S8  T=973.1ms eta=14:01:17 | 80.7K token/s | 
[epoch_0]_9171   loss=3.612854 |g|=0.382	lr=9.52e-04 | 51.3%@S8  T=977.1ms eta=14:04:37 | 80.8K token/s | 
[epoch_0]_9181   loss=3.605779 |g|=0.371	lr=9.52e-04 | 52.1%@S8  T=985.9ms eta=14:12:04 | 81.0K token/s | 
[epoch_0]_9191   loss=3.650301 |g|=0.42	lr=9.51e-04 | 52.9%@S8  T=977.1ms eta=14:04:14 | 81.1K token/s | 
[Fuyou] head="1" update algorithm=4 t=2.04s
[eval] 
	 Loss@"edu_fineweb1B"=3.635(0.0085) nBranch=1 nToken=4.01M best=3.6434(44) E2T=0.00363 T=13.4775(0)s x=0
	#3.63493±0.1097 tps=298K(4.01408M) a=[3.43954,3.92241] T=13.4775(sec)
[Section@9200] layer[12-18] tasks=15(nPassBack=0) last_loss=3.6313(0.027674) N=(580,8232,7812 919900)
[epoch_0]_9201   loss=3.658036 |g|=0.422	lr=9.51e-04 | 53.7%@S8  T=4.09s eta=2d 10:54:51 | 78.0K token/s | 
[epoch_0]_9211   loss=3.605888 |g|=0.399	lr=9.51e-04 | 54.6%@S8  T=976.5ms eta=14:03:25 | 78.3K token/s | 
[epoch_0]_9221   loss=3.684341 |g|=0.461	lr=9.51e-04 | 55.4%@S8  T=964.0ms eta=13:52:29 | 78.7K token/s | 
[epoch_0]_9231   loss=3.585251 |g|=0.428	lr=9.51e-04 | 56.2%@S8  T=973.4ms eta=14:00:28 | 78.9K token/s | 
[epoch_0]_9241   loss=3.645503 |g|=0.394	lr=9.51e-04 | 57.0%@S8  T=989.8ms eta=14:14:26 | 79.1K token/s | 
[epoch_0]_9251   loss=3.658096 |g|=0.362	lr=9.51e-04 | 57.8%@S8  T=988.2ms eta=14:12:50 | 79.3K token/s | 
[epoch_0]_9261   loss=3.594270 |g|=0.392	lr=9.51e-04 | 58.7%@S8  T=968.9ms eta=13:56:02 | 79.6K token/s | 
[epoch_0]_9271   loss=3.594952 |g|=0.364	lr=9.51e-04 | 59.5%@S8  T=970.7ms eta=13:57:28 | 79.8K token/s | 
[epoch_0]_9281   loss=3.693690 |g|=0.433	lr=9.50e-04 | 60.3%@S8  T=971.1ms eta=13:57:39 | 80.1K token/s | 
[epoch_0]_9291   loss=3.685866 |g|=0.425	lr=9.50e-04 | 61.1%@S8  T=970.7ms eta=13:57:08 | 80.3K token/s | 
[Fuyou] head="2" update algorithm=4 t=1.99s
[Section@9300] layer[18-24] tasks=15(nPassBack=0) last_loss=3.6025(0.0781324) N=(580,8316,7896 929900)
[epoch_0]_9301   loss=3.566688 |g|=0.453	lr=9.50e-04 | 61.9%@S8  T=1.24s eta=17:48:19 | 79.6K token/s | 
[epoch_0]_9311   loss=3.675347 |g|=0.413	lr=9.50e-04 | 62.8%@S8  T=969.5ms eta=13:55:45 | 79.8K token/s | 
[epoch_0]_9321   loss=3.628326 |g|=0.391	lr=9.50e-04 | 63.6%@S8  T=966.3ms eta=13:52:51 | 80.1K token/s | 
[epoch_0]_9331   loss=3.649613 |g|=0.426	lr=9.50e-04 | 64.4%@S8  T=968.5ms eta=13:54:37 | 80.3K token/s | 
[epoch_0]_9341   loss=3.658018 |g|=0.357	lr=9.50e-04 | 65.2%@S8  T=970.6ms eta=13:56:12 | 80.5K token/s | 
[epoch_0]_9351   loss=3.702764 |g|=0.351	lr=9.50e-04 | 66.0%@S8  T=977.0ms eta=14:01:35 | 80.7K token/s | 
[epoch_0]_9361   loss=3.652487 |g|=0.345	lr=9.50e-04 | 66.9%@S8  T=966.8ms eta=13:52:38 | 80.9K token/s | 
[epoch_0]_9371   loss=3.593445 |g|=0.375	lr=9.49e-04 | 67.7%@S8  T=980.6ms eta=14:04:19 | 81.0K token/s | 
[epoch_0]_9381   loss=3.650650 |g|=0.381	lr=9.49e-04 | 68.5%@S8  T=964.4ms eta=13:50:17 | 81.2K token/s | 
[epoch_0]_9391   loss=3.630379 |g|=0.389	lr=9.49e-04 | 69.3%@S8  T=958.8ms eta=13:45:16 | 81.4K token/s | 
[Fuyou] head="3" update algorithm=4 t=2.03s
[eval] 
	 Loss@"edu_fineweb1B"=3.628(0.0065) nBranch=1 nToken=4.01M best=3.6349(45) E2T=-0.0405 T=13.4149(0)s x=0
	#3.62846±0.1094 tps=299K(4.01408M) a=[3.4394,3.91332] T=13.4149(sec)
[Section@9400] layer[24-30] tasks=15(nPassBack=0) last_loss=3.669(0.014677) N=(580,8400,7980 939900)
[epoch_0]_9401   loss=3.556603 |g|=0.35	lr=9.49e-04 | 70.1%@S8  T=4.07s eta=2d 10:20:55 | 78.3K token/s | 
[epoch_0]_9411   loss=3.659941 |g|=0.441	lr=9.49e-04 | 71.0%@S8  T=962.4ms eta=13:48:04 | 78.7K token/s | 
[epoch_0]_9421   loss=3.662949 |g|=0.396	lr=9.49e-04 | 71.8%@S8  T=983.0ms eta=14:05:34 | 78.9K token/s | 
[epoch_0]_9431   loss=3.621399 |g|=0.423	lr=9.49e-04 | 72.6%@S8  T=979.5ms eta=14:02:26 | 79.1K token/s | 
[epoch_0]_9441   loss=3.610210 |g|=0.423	lr=9.49e-04 | 73.4%@S8  T=962.6ms eta=13:47:44 | 79.4K token/s | 
[epoch_0]_9451   loss=3.686194 |g|=0.408	lr=9.49e-04 | 74.2%@S8  T=960.4ms eta=13:45:41 | 79.7K token/s | 
[epoch_0]_9461   loss=3.687610 |g|=0.362	lr=9.48e-04 | 75.0%@S8  T=966.5ms eta=13:50:47 | 80.0K token/s | 
[epoch_0]_9471   loss=3.594942 |g|=0.369	lr=9.48e-04 | 75.9%@S8  T=968.2ms eta=13:52:03 | 80.2K token/s | 
[epoch_0]_9481   loss=3.554760 |g|=0.388	lr=9.48e-04 | 76.7%@S8  T=966.7ms eta=13:50:39 | 80.4K token/s | 
[epoch_0]_9491   loss=3.669209 |g|=0.408	lr=9.48e-04 | 77.5%@S8  T=969.0ms eta=13:52:27 | 80.7K token/s | 
[Fuyou] head="4" update algorithm=4 t=2.04s
[Section@9500] layer[30-36] tasks=15(nPassBack=0) last_loss=3.59533(0.0633814) N=(580,8484,8064 949900)
[epoch_0]_9501   loss=3.684257 |g|=0.442	lr=9.48e-04 | 78.3%@S8  T=1.25s eta=17:50:29 | 79.9K token/s | 
[epoch_0]_9511   loss=3.596364 |g|=0.403	lr=9.48e-04 | 79.1%@S8  T=960.6ms eta=13:44:56 | 80.2K token/s | 
[epoch_0]_9521   loss=3.669394 |g|=0.415	lr=9.48e-04 | 80.0%@S8  T=976.9ms eta=13:58:43 | 80.4K token/s | 
[epoch_0]_9531   loss=3.609477 |g|=0.396	lr=9.48e-04 | 80.8%@S8  T=960.2ms eta=13:44:12 | 80.6K token/s | 
[epoch_0]_9541   loss=3.648886 |g|=0.452	lr=9.47e-04 | 81.6%@S8  T=963.2ms eta=13:46:40 | 80.8K token/s | 
[epoch_0]_9551   loss=3.635018 |g|=0.369	lr=9.47e-04 | 82.4%@S8  T=968.0ms eta=13:50:34 | 81.0K token/s | 
[epoch_0]_9561   loss=3.610700 |g|=0.388	lr=9.47e-04 | 83.2%@S8  T=965.3ms eta=13:48:09 | 81.2K token/s | 
[epoch_0]_9571   loss=3.650708 |g|=0.374	lr=9.47e-04 | 84.1%@S8  T=972.5ms eta=13:54:06 | 81.4K token/s | 
[epoch_0]_9581   loss=3.631509 |g|=0.379	lr=9.47e-04 | 84.9%@S8  T=980.2ms eta=14:00:35 | 81.5K token/s | 
[epoch_0]_9591   loss=3.647050 |g|=0.39	lr=9.47e-04 | 85.7%@S8  T=987.7ms eta=14:06:49 | 81.5K token/s | 
[Fuyou] head="5" update algorithm=4 t=2.06s
[eval] 
	 Loss@"edu_fineweb1B"=3.624(0.004) nBranch=1 nToken=4.01M best=3.6285(46) E2T=-0.0605 T=13.4116(0)s x=0
	#3.62446±0.1085 tps=299K(4.01408M) a=[3.43472,3.90329] T=13.4116(sec)
[Section@9600] layer[0-6] tasks=15(nPassBack=0) last_loss=3.68496(-0.0789857) N=(580,8568,8148 959900)
[epoch_0]_9601   loss=3.737620 |g|=0.504	lr=9.47e-04 | 86.5%@S8  T=4.07s eta=2d 10:09:15 | 78.5K token/s | 
[epoch_0]_9611   loss=3.516601 |g|=0.37	lr=9.47e-04 | 87.3%@S8  T=963.4ms eta=13:45:40 | 78.8K token/s | 
[epoch_0]_9621   loss=3.529198 |g|=0.382	lr=9.47e-04 | 88.2%@S8  T=971.3ms eta=13:52:16 | 79.1K token/s | 
[epoch_0]_9631   loss=3.600014 |g|=0.354	lr=9.46e-04 | 89.0%@S8  T=971.2ms eta=13:52:03 | 79.3K token/s | 
[epoch_0]_9641   loss=3.621035 |g|=0.39	lr=9.46e-04 | 89.8%@S8  T=989.1ms eta=14:07:15 | 79.5K token/s | 
[epoch_0]_9651   loss=3.528696 |g|=0.372	lr=9.46e-04 | 90.6%@S8  T=964.9ms eta=13:46:19 | 79.8K token/s | 
[epoch_0]_9661   loss=3.632470 |g|=0.346	lr=9.46e-04 | 91.4%@S8  T=970.5ms eta=13:50:59 | 80.0K token/s | 
[epoch_0]_9671   loss=3.629988 |g|=0.417	lr=9.46e-04 | 92.3%@S8  T=962.6ms eta=13:44:03 | 80.3K token/s | 
[epoch_0]_9681   loss=3.612081 |g|=0.38	lr=9.46e-04 | 93.1%@S8  T=963.0ms eta=13:44:12 | 80.5K token/s | 
[epoch_0]_9691   loss=3.667422 |g|=0.417	lr=9.46e-04 | 93.9%@S8  T=972.2ms eta=13:51:54 | 80.7K token/s | 
[Fuyou] head="0" update algorithm=4 t=2.05s
[Section@9700] layer[6-12] tasks=15(nPassBack=0) last_loss=3.62225(0.0213606) N=(580,8652,8232 969900)
[epoch_0]_9701   loss=3.552390 |g|=0.385	lr=9.46e-04 | 94.7%@S8  T=1.30s eta=18:33:40 | 79.8K token/s | 
[epoch_0]_9711   loss=3.608567 |g|=0.362	lr=9.46e-04 | 95.5%@S8  T=967.4ms eta=13:47:30 | 80.1K token/s | 
[epoch_0]_9721   loss=3.566089 |g|=0.381	lr=9.45e-04 | 96.3%@S8  T=966.7ms eta=13:46:43 | 80.3K token/s | 
[epoch_0]_9731   loss=3.604848 |g|=0.397	lr=9.45e-04 | 97.2%@S8  T=970.6ms eta=13:49:54 | 80.5K token/s | 
[epoch_0]_9741   loss=3.600548 |g|=0.406	lr=9.45e-04 | 98.0%@S8  T=974.4ms eta=13:53:00 | 80.7K token/s | 
[epoch_0]_9751   loss=3.559644 |g|=0.394	lr=9.45e-04 | 98.8%@S8  T=971.5ms eta=13:50:21 | 80.9K token/s | 
[epoch_0]_9761   loss=3.550971 |g|=0.373	lr=9.45e-04 | 99.6%@S8  T=981.6ms eta=13:58:50 | 81.0K token/s | 
[epoch_0]_9765   loss=3.555976 |g|=0.374	lr=9.45e-04 | 100.0%@S8  T=974.3ms eta=13:52:32 | 81.1K token/s | 
-------- End of shard_8@"./Datasets/edu_fineweb1B/edu_fineweb_train_000008.bin"-------- 
[shard-9]@"./Datasets/edu_fineweb1B/edu_fineweb_train_000009.bin": tokens=100(M) nShardSamples=1220(878904) 
[epoch_0]_9771   loss=3.588558 |g|=0.41	lr=9.45e-04 | 0.4%@S9  T=979.9ms eta=13:57:15 | 81.3K token/s | 
[epoch_0]_9781   loss=3.551804 |g|=0.368	lr=9.45e-04 | 1.3%@S9  T=962.6ms eta=13:42:18 | 81.5K token/s | 
[epoch_0]_9791   loss=3.521213 |g|=0.388	lr=9.45e-04 | 2.1%@S9  T=959.2ms eta=13:39:12 | 81.7K token/s | 
[Fuyou] head="1" update algorithm=4 t=2.06s
[eval] 
	 Loss@"edu_fineweb1B"=3.628(-0.0036) nBranch=1 nToken=4.01M best=3.6245(47) E2T=0.0605 T=13.4202(0)s x=0
	#3.62803±0.1089 tps=299K(4.01408M) a=[3.43718,3.90922] T=13.4202(sec)
[Section@9800] layer[12-18] tasks=15(nPassBack=0) last_loss=3.56756(0.0637434) N=(580,8736,8316 979900)
[epoch_0]_9801   loss=3.520568 |g|=0.409	lr=9.44e-04 | 2.9%@S9  T=4.08s eta=2d 10:04:03 | 78.6K token/s | 
[epoch_0]_9811   loss=3.573826 |g|=0.387	lr=9.44e-04 | 3.7%@S9  T=963.3ms eta=13:42:24 | 78.9K token/s | 
[epoch_0]_9821   loss=3.500446 |g|=0.426	lr=9.44e-04 | 4.5%@S9  T=966.8ms eta=13:45:15 | 79.2K token/s | 
[epoch_0]_9831   loss=3.571818 |g|=0.42	lr=9.44e-04 | 5.4%@S9  T=986.1ms eta=14:01:32 | 79.4K token/s | 
[epoch_0]_9841   loss=3.542172 |g|=0.383	lr=9.44e-04 | 6.2%@S9  T=965.5ms eta=13:43:46 | 79.7K token/s | 
[epoch_0]_9851   loss=3.545128 |g|=0.345	lr=9.44e-04 | 7.0%@S9  T=972.4ms eta=13:49:33 | 79.9K token/s | 
[epoch_0]_9861   loss=3.520771 |g|=0.371	lr=9.44e-04 | 7.8%@S9  T=966.7ms eta=13:44:29 | 80.1K token/s | 
[epoch_0]_9871   loss=3.473349 |g|=0.371	lr=9.44e-04 | 8.6%@S9  T=965.2ms eta=13:43:05 | 80.4K token/s | 
[epoch_0]_9881   loss=3.564861 |g|=0.389	lr=9.44e-04 | 9.5%@S9  T=971.3ms eta=13:48:03 | 80.6K token/s | 
[epoch_0]_9891   loss=3.573780 |g|=0.375	lr=9.43e-04 | 10.3%@S9  T=974.8ms eta=13:50:55 | 80.7K token/s | 
[Fuyou] head="2" update algorithm=4 t=1.99s
[Section@9900] layer[18-24] tasks=15(nPassBack=0) last_loss=3.50799(0.0945044) N=(580,8820,8400 989900)
[epoch_0]_9901   loss=3.558216 |g|=0.418	lr=9.43e-04 | 11.1%@S9  T=1.23s eta=17:26:28 | 80.0K token/s | 
[epoch_0]_9911   loss=3.513674 |g|=0.421	lr=9.43e-04 | 11.9%@S9  T=965.1ms eta=13:42:17 | 80.3K token/s | 
[epoch_0]_9921   loss=3.655209 |g|=0.418	lr=9.43e-04 | 12.7%@S9  T=983.4ms eta=13:57:43 | 80.4K token/s | 
[epoch_0]_9931   loss=3.586640 |g|=0.389	lr=9.43e-04 | 13.6%@S9  T=962.7ms eta=13:39:55 | 80.7K token/s | 
[epoch_0]_9941   loss=3.543345 |g|=0.438	lr=9.43e-04 | 14.4%@S9  T=965.5ms eta=13:42:10 | 80.9K token/s | 
[epoch_0]_9951   loss=3.531826 |g|=0.386	lr=9.43e-04 | 15.2%@S9  T=968.1ms eta=13:44:13 | 81.1K token/s | 
[epoch_0]_9961   loss=3.583782 |g|=0.444	lr=9.43e-04 | 16.0%@S9  T=982.6ms eta=13:56:25 | 81.2K token/s | 
[epoch_0]_9971   loss=3.546562 |g|=0.357	lr=9.42e-04 | 16.8%@S9  T=966.7ms eta=13:42:41 | 81.4K token/s | 
[epoch_0]_9981   loss=3.484643 |g|=0.412	lr=9.42e-04 | 17.6%@S9  T=977.4ms eta=13:51:37 | 81.5K token/s | 
[epoch_0]_9991   loss=3.516185 |g|=0.372	lr=9.42e-04 | 18.5%@S9  T=983.0ms eta=13:56:14 | 81.6K token/s | 
[Fuyou] head="3" update algorithm=4 t=2.05s
[eval] 
	 Loss@"edu_fineweb1B"=3.634(-0.0059) nBranch=1 nToken=4.01M best=3.6245(47) E2T=0.0995 T=13.4162(0)s x=0
	#3.63393±0.1105 tps=299K(4.01408M) a=[3.44525,3.91843] T=13.4162(sec)
[Section@10000] layer[24-30] tasks=15(nPassBack=0) last_loss=3.53446(0.134544) N=(580,8904,8484 999900)
[epoch_0]_10001  loss=3.608450 |g|=0.363	lr=9.42e-04 | 19.3%@S9  T=4.07s eta=2d 09:42:16 | 78.5K token/s | 
[epoch_0]_10011  loss=3.532857 |g|=0.379	lr=9.42e-04 | 20.1%@S9  T=982.6ms eta=13:55:35 | 78.7K token/s | 
[epoch_0]_10021  loss=3.624684 |g|=0.419	lr=9.42e-04 | 20.9%@S9  T=964.6ms eta=13:40:08 | 79.1K token/s | 
[epoch_0]_10031  loss=3.571841 |g|=0.378	lr=9.42e-04 | 21.7%@S9  T=965.5ms eta=13:40:45 | 79.3K token/s | 
[epoch_0]_10041  loss=3.533052 |g|=0.418	lr=9.42e-04 | 22.6%@S9  T=976.6ms eta=13:50:00 | 79.6K token/s | 
[epoch_0]_10051  loss=3.496767 |g|=0.403	lr=9.41e-04 | 23.4%@S9  T=962.3ms eta=13:37:42 | 79.8K token/s | 
[epoch_0]_10061  loss=3.592272 |g|=0.422	lr=9.41e-04 | 24.2%@S9  T=967.4ms eta=13:41:53 | 80.1K token/s | 
[epoch_0]_10071  loss=3.544360 |g|=0.359	lr=9.41e-04 | 25.0%@S9  T=997.7ms eta=14:07:28 | 80.2K token/s | 
[epoch_0]_10081  loss=3.521911 |g|=0.376	lr=9.41e-04 | 25.8%@S9  T=967.3ms eta=13:41:27 | 80.4K token/s | 
[epoch_0]_10091  loss=3.600379 |g|=0.357	lr=9.41e-04 | 26.7%@S9  T=967.8ms eta=13:41:45 | 80.6K token/s | 
[Fuyou] head="4" update algorithm=4 t=2.06s
[Section@10100] layer[30-36] tasks=15(nPassBack=0) last_loss=3.50359(0.0917399) N=(580,8988,8568 1009900)
[epoch_0]_10101  loss=3.543076 |g|=0.364	lr=9.41e-04 | 27.5%@S9  T=1.25s eta=17:41:32 | 79.9K token/s | 
[epoch_0]_10111  loss=3.568339 |g|=0.385	lr=9.41e-04 | 28.3%@S9  T=968.0ms eta=13:41:35 | 80.1K token/s | 
[epoch_0]_10121  loss=3.543893 |g|=0.43	lr=9.41e-04 | 29.1%@S9  T=975.6ms eta=13:47:50 | 80.3K token/s | 
[epoch_0]_10131  loss=3.558363 |g|=0.379	lr=9.40e-04 | 29.9%@S9  T=969.4ms eta=13:42:25 | 80.5K token/s | 
[epoch_0]_10141  loss=3.594492 |g|=0.417	lr=9.40e-04 | 30.8%@S9  T=969.5ms eta=13:42:23 | 80.7K token/s | 
[epoch_0]_10151  loss=3.513276 |g|=0.378	lr=9.40e-04 | 31.6%@S9  T=965.6ms eta=13:38:52 | 80.9K token/s | 
[epoch_0]_10161  loss=3.561784 |g|=0.381	lr=9.40e-04 | 32.4%@S9  T=972.5ms eta=13:44:37 | 81.1K token/s | 
[epoch_0]_10171  loss=3.477838 |g|=0.387	lr=9.40e-04 | 33.2%@S9  T=969.7ms eta=13:42:03 | 81.3K token/s | 
[epoch_0]_10181  loss=3.500442 |g|=0.445	lr=9.40e-04 | 34.0%@S9  T=984.5ms eta=13:54:24 | 81.4K token/s | 
[epoch_0]_10191  loss=3.578508 |g|=0.373	lr=9.40e-04 | 34.8%@S9  T=967.8ms eta=13:40:05 | 81.5K token/s | 
[Fuyou] head="5" update algorithm=4 t=2.00s
[eval] 
	 Loss@"edu_fineweb1B"=3.631(0.0028) nBranch=1 nToken=4.01M best=3.6245(47) E2T=0.0776 T=13.4088(0)s x=0
	#3.63115±0.1107 tps=299K(4.01408M) a=[3.43252,3.91857] T=13.4088(sec)
[Section@10200] layer[0-6] tasks=15(nPassBack=0) last_loss=3.55353(0.131435) N=(580,9072,8652 1019900)
[epoch_0]_10201  loss=3.535420 |g|=0.388	lr=9.40e-04 | 35.7%@S9  T=4.08s eta=2d 09:33:07 | 78.4K token/s | 
[epoch_0]_10211  loss=3.626065 |g|=0.368	lr=9.39e-04 | 36.5%@S9  T=972.6ms eta=13:43:49 | 78.7K token/s | 
[epoch_0]_10221  loss=3.573406 |g|=0.362	lr=9.39e-04 | 37.3%@S9  T=972.8ms eta=13:43:54 | 79.0K token/s | 
[epoch_0]_10231  loss=3.515661 |g|=0.384	lr=9.39e-04 | 38.1%@S9  T=983.5ms eta=13:52:47 | 79.2K token/s | 
[epoch_0]_10241  loss=3.466494 |g|=0.362	lr=9.39e-04 | 38.9%@S9  T=986.9ms eta=13:55:27 | 79.4K token/s | 
[epoch_0]_10251  loss=3.568438 |g|=0.354	lr=9.39e-04 | 39.8%@S9  T=970.0ms eta=13:40:58 | 79.7K token/s | 
[epoch_0]_10261  loss=3.557474 |g|=0.371	lr=9.39e-04 | 40.6%@S9  T=967.6ms eta=13:38:49 | 79.9K token/s | 
[epoch_0]_10271  loss=3.533523 |g|=0.364	lr=9.39e-04 | 41.4%@S9  T=962.9ms eta=13:34:39 | 80.2K token/s | 
[epoch_0]_10281  loss=3.474664 |g|=0.382	lr=9.39e-04 | 42.2%@S9  T=973.4ms eta=13:43:26 | 80.4K token/s | 
[epoch_0]_10291  loss=3.480974 |g|=0.348	lr=9.39e-04 | 43.0%@S9  T=972.5ms eta=13:42:27 | 80.6K token/s | 
[Fuyou] head="0" update algorithm=4 t=2.05s
[Section@10300] layer[6-12] tasks=15(nPassBack=0) last_loss=3.52478(0.0974779) N=(580,9156,8736 1029900)
[epoch_0]_10301  loss=3.545388 |g|=0.413	lr=9.38e-04 | 43.9%@S9  T=1.30s eta=18:20:53 | 79.7K token/s | 
[epoch_0]_10311  loss=3.539621 |g|=0.392	lr=9.38e-04 | 44.7%@S9  T=968.2ms eta=13:38:31 | 79.9K token/s | 
[epoch_0]_10321  loss=3.552863 |g|=0.358	lr=9.38e-04 | 45.5%@S9  T=966.7ms eta=13:37:06 | 80.2K token/s | 
[epoch_0]_10331  loss=3.510312 |g|=0.401	lr=9.38e-04 | 46.3%@S9  T=965.0ms eta=13:35:29 | 80.4K token/s | 
[epoch_0]_10341  loss=3.532819 |g|=0.407	lr=9.38e-04 | 47.1%@S9  T=964.8ms eta=13:35:08 | 80.6K token/s | 
[epoch_0]_10351  loss=3.546357 |g|=0.427	lr=9.38e-04 | 48.0%@S9  T=964.9ms eta=13:35:02 | 80.8K token/s | 
[epoch_0]_10361  loss=3.558039 |g|=0.404	lr=9.38e-04 | 48.8%@S9  T=979.9ms eta=13:47:33 | 81.0K token/s | 
[epoch_0]_10371  loss=3.518661 |g|=0.369	lr=9.38e-04 | 49.6%@S9  T=966.3ms eta=13:35:57 | 81.2K token/s | 
[epoch_0]_10381  loss=3.578077 |g|=0.404	lr=9.37e-04 | 50.4%@S9  T=966.2ms eta=13:35:39 | 81.4K token/s | 
[epoch_0]_10391  loss=3.517121 |g|=0.408	lr=9.37e-04 | 51.2%@S9  T=967.3ms eta=13:36:29 | 81.5K token/s | 
[Fuyou] head="1" update algorithm=4 t=2.06s
[eval] 
	 Loss@"edu_fineweb1B"=3.631(-0.00031) nBranch=1 nToken=4.01M best=3.6245(47) E2T=0.0731 T=13.4468(0)s x=0
	#3.63146±0.1113 tps=299K(4.01408M) a=[3.43739,3.92101] T=13.4468(sec)
[Section@10400] layer[12-18] tasks=15(nPassBack=0) last_loss=3.5584(0.00916243) N=(580,9240,8820 1039900)
[epoch_0]_10401  loss=3.497065 |g|=0.376	lr=9.37e-04 | 52.1%@S9  T=4.08s eta=2d 09:27:05 | 78.4K token/s | 
[epoch_0]_10411  loss=3.522848 |g|=0.377	lr=9.37e-04 | 52.9%@S9  T=987.3ms eta=13:53:03 | 78.7K token/s | 
[epoch_0]_10421  loss=3.466115 |g|=0.352	lr=9.37e-04 | 53.7%@S9  T=974.6ms eta=13:42:07 | 78.9K token/s | 
[epoch_0]_10431  loss=3.471534 |g|=0.358	lr=9.37e-04 | 54.5%@S9  T=973.0ms eta=13:40:35 | 79.2K token/s | 
[epoch_0]_10441  loss=3.541012 |g|=0.473	lr=9.37e-04 | 55.3%@S9  T=977.5ms eta=13:44:17 | 79.4K token/s | 
[epoch_0]_10451  loss=3.526135 |g|=0.376	lr=9.37e-04 | 56.1%@S9  T=985.8ms eta=13:51:03 | 79.6K token/s | 
[epoch_0]_10461  loss=3.577525 |g|=0.359	lr=9.36e-04 | 57.0%@S9  T=986.6ms eta=13:51:36 | 79.8K token/s | 
[epoch_0]_10471  loss=3.553774 |g|=0.337	lr=9.36e-04 | 57.8%@S9  T=975.6ms eta=13:42:11 | 80.0K token/s | 
[epoch_0]_10481  loss=3.589001 |g|=0.379	lr=9.36e-04 | 58.6%@S9  T=970.1ms eta=13:37:23 | 80.2K token/s | 
[epoch_0]_10491  loss=3.562113 |g|=0.494	lr=9.36e-04 | 59.4%@S9  T=966.6ms eta=13:34:15 | 80.4K token/s | 
[Fuyou] head="2" update algorithm=4 t=2.04s
[Section@10500] layer[18-24] tasks=15(nPassBack=0) last_loss=3.49798(0.0100126) N=(580,9324,8904 1049900)
[epoch_0]_10501  loss=3.495989 |g|=0.346	lr=9.36e-04 | 60.2%@S9  T=1.39s eta=19:30:59 | 79.4K token/s | 
[epoch_0]_10511  loss=3.513877 |g|=0.388	lr=9.36e-04 | 61.1%@S9  T=975.6ms eta=13:41:31 | 79.6K token/s | 
[epoch_0]_10521  loss=3.568238 |g|=0.401	lr=9.36e-04 | 61.9%@S9  T=969.4ms eta=13:36:06 | 79.8K token/s | 
[epoch_0]_10531  loss=3.451634 |g|=0.376	lr=9.35e-04 | 62.7%@S9  T=971.1ms eta=13:37:23 | 80.1K token/s | 
[epoch_0]_10541  loss=3.584121 |g|=0.367	lr=9.35e-04 | 63.5%@S9  T=978.9ms eta=13:43:48 | 80.3K token/s | 
[epoch_0]_10551  loss=3.544934 |g|=0.384	lr=9.35e-04 | 64.3%@S9  T=979.0ms eta=13:43:44 | 80.4K token/s | 
[epoch_0]_10561  loss=3.512106 |g|=0.448	lr=9.35e-04 | 65.2%@S9  T=973.0ms eta=13:38:29 | 80.6K token/s | 
[epoch_0]_10571  loss=3.521304 |g|=0.421	lr=9.35e-04 | 66.0%@S9  T=979.1ms eta=13:43:29 | 80.8K token/s | 
[epoch_0]_10581  loss=3.515777 |g|=0.419	lr=9.35e-04 | 66.8%@S9  T=991.1ms eta=13:53:23 | 80.9K token/s | 
[epoch_0]_10591  loss=3.470151 |g|=0.384	lr=9.35e-04 | 67.6%@S9  T=989.3ms eta=13:51:43 | 81.0K token/s | 
[Fuyou] head="3" update algorithm=4 t=2.07s
[eval] 
	 Loss@"edu_fineweb1B"=3.628(0.003) nBranch=1 nToken=4.01M best=3.6245(47) E2T=0.208 T=13.4742(0)s x=0
	#3.62841±0.1107 tps=298K(4.01408M) a=[3.43301,3.9113] T=13.4742(sec)
[Section@10600] layer[24-30] tasks=15(nPassBack=0) last_loss=3.42045(0.114012) N=(580,9408,8988 1059900)
[epoch_0]_10601  loss=3.433228 |g|=0.394	lr=9.35e-04 | 68.4%@S9  T=4.09s eta=2d 09:15:02 | 77.9K token/s | 
[epoch_0]_10611  loss=3.532055 |g|=0.373	lr=9.34e-04 | 69.3%@S9  T=991.1ms eta=13:52:56 | 78.1K token/s | 
[epoch_0]_10621  loss=3.563511 |g|=0.386	lr=9.34e-04 | 70.1%@S9  T=976.9ms eta=13:40:47 | 78.4K token/s | 
[epoch_0]_10631  loss=3.505484 |g|=0.486	lr=9.34e-04 | 70.9%@S9  T=969.8ms eta=13:34:41 | 78.7K token/s | 
[epoch_0]_10641  loss=3.554956 |g|=0.374	lr=9.34e-04 | 71.7%@S9  T=973.1ms eta=13:37:20 | 79.0K token/s | 
[epoch_0]_10651  loss=3.533459 |g|=0.353	lr=9.34e-04 | 72.5%@S9  T=991.7ms eta=13:52:48 | 79.2K token/s | 
[epoch_0]_10661  loss=3.514664 |g|=0.383	lr=9.34e-04 | 73.4%@S9  T=988.2ms eta=13:49:41 | 79.4K token/s | 
[epoch_0]_10671  loss=3.538907 |g|=0.386	lr=9.34e-04 | 74.2%@S9  T=975.1ms eta=13:38:31 | 79.6K token/s | 
[epoch_0]_10681  loss=3.521451 |g|=0.343	lr=9.34e-04 | 75.0%@S9  T=976.9ms eta=13:39:49 | 79.8K token/s | 
[epoch_0]_10691  loss=3.565696 |g|=0.367	lr=9.33e-04 | 75.8%@S9  T=976.9ms eta=13:39:38 | 80.0K token/s | 
[Fuyou] head="4" update algorithm=4 t=2.04s
[Section@10700] layer[30-36] tasks=15(nPassBack=0) last_loss=3.53699(-0.0334053) N=(580,9492,9072 1069900)
[epoch_0]_10701  loss=3.452878 |g|=0.36	lr=9.33e-04 | 76.6%@S9  T=1.38s eta=19:14:16 | 79.0K token/s | 
[epoch_0]_10711  loss=3.527610 |g|=0.41	lr=9.33e-04 | 77.4%@S9  T=968.7ms eta=13:32:29 | 79.3K token/s | 
[epoch_0]_10721  loss=3.497563 |g|=0.377	lr=9.33e-04 | 78.3%@S9  T=985.2ms eta=13:46:10 | 79.5K token/s | 
[epoch_0]_10731  loss=3.490973 |g|=0.372	lr=9.33e-04 | 79.1%@S9  T=968.3ms eta=13:31:50 | 79.7K token/s | 
[epoch_0]_10741  loss=3.533126 |g|=0.445	lr=9.33e-04 | 79.9%@S9  T=973.5ms eta=13:36:03 | 79.9K token/s | 
[epoch_0]_10751  loss=3.559717 |g|=0.354	lr=9.33e-04 | 80.7%@S9  T=978.2ms eta=13:39:48 | 80.1K token/s | 
[epoch_0]_10761  loss=3.441049 |g|=0.347	lr=9.33e-04 | 81.5%@S9  T=977.9ms eta=13:39:21 | 80.3K token/s | 
[epoch_0]_10771  loss=3.459135 |g|=0.377	lr=9.32e-04 | 82.4%@S9  T=986.0ms eta=13:46:02 | 80.5K token/s | 
[epoch_0]_10781  loss=3.479493 |g|=0.372	lr=9.32e-04 | 83.2%@S9  T=987.9ms eta=13:47:24 | 80.6K token/s | 
[epoch_0]_10791  loss=3.489994 |g|=0.404	lr=9.32e-04 | 84.0%@S9  T=968.8ms eta=13:31:15 | 80.8K token/s | 
[Fuyou] head="5" update algorithm=4 t=2.05s
[eval] 
	 Loss@"edu_fineweb1B"=3.627(0.0011) nBranch=1 nToken=4.01M best=3.6245(47) E2T=0.135 T=13.4861(0)s x=0
	#3.62728±0.1114 tps=298K(4.01408M) a=[3.42204,3.91456] T=13.4861(sec)
[Section@10800] layer[0-6] tasks=15(nPassBack=0) last_loss=3.49265(0.0608799) N=(580,9576,9156 1079900)
[epoch_0]_10801  loss=3.490647 |g|=0.354	lr=9.32e-04 | 84.8%@S9  T=4.10s eta=2d 09:13:44 | 77.7K token/s | 
[epoch_0]_10811  loss=3.569787 |g|=0.391	lr=9.32e-04 | 85.6%@S9  T=974.5ms eta=13:35:42 | 78.1K token/s | 
[epoch_0]_10821  loss=3.554672 |g|=0.369	lr=9.32e-04 | 86.5%@S9  T=981.6ms eta=13:41:29 | 78.3K token/s | 
[epoch_0]_10831  loss=3.502863 |g|=0.377	lr=9.32e-04 | 87.3%@S9  T=979.9ms eta=13:39:57 | 78.6K token/s | 
[epoch_0]_10841  loss=3.540190 |g|=0.365	lr=9.31e-04 | 88.1%@S9  T=992.7ms eta=13:50:25 | 78.8K token/s | 
[epoch_0]_10851  loss=3.484963 |g|=0.331	lr=9.31e-04 | 88.9%@S9  T=969.2ms eta=13:30:38 | 79.1K token/s | 
[epoch_0]_10861  loss=3.570493 |g|=0.407	lr=9.31e-04 | 89.7%@S9  T=971.6ms eta=13:32:27 | 79.3K token/s | 
[epoch_0]_10871  loss=3.584445 |g|=0.384	lr=9.31e-04 | 90.6%@S9  T=978.7ms eta=13:38:14 | 79.6K token/s | 
[epoch_0]_10881  loss=3.489511 |g|=0.405	lr=9.31e-04 | 91.4%@S9  T=981.7ms eta=13:40:36 | 79.7K token/s | 
[epoch_0]_10891  loss=3.547566 |g|=0.429	lr=9.31e-04 | 92.2%@S9  T=978.8ms eta=13:38:01 | 79.9K token/s | 
[Fuyou] head="0" update algorithm=4 t=2.06s
[Section@10900] layer[6-12] tasks=15(nPassBack=0) last_loss=3.54322(-0.0184474) N=(580,9660,9240 1089900)
[epoch_0]_10901  loss=3.517136 |g|=0.458	lr=9.31e-04 | 93.0%@S9  T=1.35s eta=18:46:16 | 79.0K token/s | 
[epoch_0]_10911  loss=3.565843 |g|=0.409	lr=9.31e-04 | 93.8%@S9  T=973.9ms eta=13:33:37 | 79.2K token/s | 
[epoch_0]_10921  loss=3.502002 |g|=0.378	lr=9.30e-04 | 94.7%@S9  T=976.4ms eta=13:35:31 | 79.5K token/s | 
[epoch_0]_10931  loss=3.541549 |g|=0.377	lr=9.30e-04 | 95.5%@S9  T=969.8ms eta=13:29:50 | 79.7K token/s | 
[epoch_0]_10941  loss=3.500145 |g|=0.428	lr=9.30e-04 | 96.3%@S9  T=987.8ms eta=13:44:44 | 79.9K token/s | 
[epoch_0]_10951  loss=3.481789 |g|=0.356	lr=9.30e-04 | 97.1%@S9  T=981.3ms eta=13:39:09 | 80.1K token/s | 
[epoch_0]_10961  loss=3.516930 |g|=0.432	lr=9.30e-04 | 97.9%@S9  T=989.5ms eta=13:45:49 | 80.2K token/s | 
[epoch_0]_10971  loss=3.566426 |g|=0.387	lr=9.30e-04 | 98.7%@S9  T=980.5ms eta=13:38:05 | 80.4K token/s | 
[epoch_0]_10981  loss=3.493208 |g|=0.37	lr=9.30e-04 | 99.6%@S9  T=1.00s eta=13:57:26 | 80.4K token/s | 
[epoch_0]_10986  loss=3.423592 |g|=0.345	lr=9.30e-04 | 100.0%@S9  T=979.8ms eta=13:37:16 | 80.6K token/s | 
-------- End of shard_9@"./Datasets/edu_fineweb1B/edu_fineweb_train_000009.bin"-------- 
[shard-10]@"./Datasets/edu_fineweb1B/edu_fineweb_train_000010.bin": tokens=100(M) nShardSamples=1220(976560) 
[epoch_0]_10991  loss=3.648233 |g|=0.363	lr=9.30e-04 | 0.4%@S10  T=987.9ms eta=13:43:58 | 80.7K token/s | 
[Fuyou] head="1" update algorithm=4 t=2.08s
[eval] 
	 Loss@"edu_fineweb1B"=3.617(0.01) nBranch=1 nToken=4.01M best=3.6273(53) E2T=-0.0686 T=13.4717(0)s x=0
	#3.61709±0.1099 tps=298K(4.01408M) a=[3.40983,3.89852] T=13.4717(sec)
[Section@11000] layer[12-18] tasks=15(nPassBack=0) last_loss=3.68565(-0.127255) N=(580,9744,9324 1099900)
[epoch_0]_11001  loss=3.719861 |g|=0.37	lr=9.29e-04 | 1.2%@S10  T=4.09s eta=2d 08:52:39 | 77.7K token/s | 
[epoch_0]_11011  loss=3.644088 |g|=0.413	lr=9.29e-04 | 2.0%@S10  T=1.01s eta=14:02:53 | 77.8K token/s | 
[epoch_0]_11021  loss=3.627877 |g|=0.435	lr=9.29e-04 | 2.8%@S10  T=974.7ms eta=13:32:28 | 78.2K token/s | 
[epoch_0]_11031  loss=3.690417 |g|=0.362	lr=9.29e-04 | 3.7%@S10  T=977.3ms eta=13:34:31 | 78.4K token/s | 
[epoch_0]_11041  loss=3.591037 |g|=0.402	lr=9.29e-04 | 4.5%@S10  T=987.1ms eta=13:42:29 | 78.7K token/s | 
[epoch_0]_11051  loss=3.733094 |g|=0.383	lr=9.29e-04 | 5.3%@S10  T=984.2ms eta=13:39:54 | 78.9K token/s | 
[epoch_0]_11061  loss=3.627411 |g|=0.346	lr=9.29e-04 | 6.1%@S10  T=997.1ms eta=13:50:28 | 79.1K token/s | 
[epoch_0]_11071  loss=3.622292 |g|=0.433	lr=9.28e-04 | 6.9%@S10  T=988.8ms eta=13:43:25 | 79.2K token/s | 
[epoch_0]_11081  loss=3.570090 |g|=0.398	lr=9.28e-04 | 7.8%@S10  T=976.6ms eta=13:33:06 | 79.5K token/s | 
[epoch_0]_11091  loss=3.619948 |g|=0.405	lr=9.28e-04 | 8.6%@S10  T=974.8ms eta=13:31:24 | 79.7K token/s | 
[Fuyou] head="2" update algorithm=4 t=2.02s
[Section@11100] layer[18-24] tasks=15(nPassBack=0) last_loss=3.61638(-0.118394) N=(580,9828,9408 1109900)
[epoch_0]_11101  loss=3.608654 |g|=0.413	lr=9.28e-04 | 9.4%@S10  T=1.26s eta=17:24:43 | 79.0K token/s | 
[epoch_0]_11111  loss=3.677529 |g|=0.413	lr=9.28e-04 | 10.2%@S10  T=976.9ms eta=13:32:53 | 79.2K token/s | 
[epoch_0]_11121  loss=3.639988 |g|=0.403	lr=9.28e-04 | 11.0%@S10  T=995.6ms eta=13:48:15 | 79.4K token/s | 
[epoch_0]_11131  loss=3.618879 |g|=0.384	lr=9.28e-04 | 11.9%@S10  T=994.6ms eta=13:47:13 | 79.5K token/s | 
[epoch_0]_11141  loss=3.559383 |g|=0.376	lr=9.28e-04 | 12.7%@S10  T=975.1ms eta=13:30:49 | 79.8K token/s | 
[epoch_0]_11151  loss=3.627202 |g|=0.368	lr=9.27e-04 | 13.5%@S10  T=972.3ms eta=13:28:21 | 80.0K token/s | 
[epoch_0]_11161  loss=3.631902 |g|=0.414	lr=9.27e-04 | 14.3%@S10  T=975.6ms eta=13:30:55 | 80.2K token/s | 
[epoch_0]_11171  loss=3.661425 |g|=0.429	lr=9.27e-04 | 15.1%@S10  T=978.7ms eta=13:33:22 | 80.4K token/s | 
[epoch_0]_11181  loss=3.606300 |g|=0.393	lr=9.27e-04 | 16.0%@S10  T=975.5ms eta=13:30:30 | 80.5K token/s | 
[epoch_0]_11191  loss=3.684001 |g|=0.37	lr=9.27e-04 | 16.8%@S10  T=987.7ms eta=13:40:28 | 80.7K token/s | 
[Fuyou] head="3" update algorithm=4 t=2.03s
[eval] 
	 Loss@"edu_fineweb1B"=3.593(0.024) nBranch=1 nToken=4.01M best=3.6171(54) E2T=0.0111 T=13.4989(0)s x=0
	#3.59321±0.1079 tps=297K(4.01408M) a=[3.40302,3.87455] T=13.4989(sec)
[Section@11200] layer[24-30] tasks=15(nPassBack=0) last_loss=3.58207(-0.161627) N=(580,9912,9492 1119900)
[epoch_0]_11201  loss=3.570755 |g|=0.385	lr=9.27e-04 | 17.6%@S10  T=4.12s eta=2d 08:59:19 | 77.6K token/s | 
[epoch_0]_11211  loss=3.641288 |g|=0.341	lr=9.27e-04 | 18.4%@S10  T=982.0ms eta=13:35:29 | 77.9K token/s | 
[epoch_0]_11221  loss=3.615571 |g|=0.416	lr=9.26e-04 | 19.2%@S10  T=975.4ms eta=13:29:48 | 78.2K token/s | 
[epoch_0]_11231  loss=3.681727 |g|=0.371	lr=9.26e-04 | 20.0%@S10  T=978.2ms eta=13:31:55 | 78.5K token/s | 
[epoch_0]_11241  loss=3.645328 |g|=0.368	lr=9.26e-04 | 20.9%@S10  T=993.5ms eta=13:44:28 | 78.7K token/s | 
[epoch_0]_11251  loss=3.640370 |g|=0.366	lr=9.26e-04 | 21.7%@S10  T=976.0ms eta=13:29:48 | 78.9K token/s | 
[epoch_0]_11261  loss=3.563434 |g|=0.37	lr=9.26e-04 | 22.5%@S10  T=976.0ms eta=13:29:37 | 79.2K token/s | 
[epoch_0]_11271  loss=3.575891 |g|=0.37	lr=9.26e-04 | 23.3%@S10  T=978.3ms eta=13:31:25 | 79.4K token/s | 
[epoch_0]_11281  loss=3.546763 |g|=0.401	lr=9.26e-04 | 24.1%@S10  T=983.9ms eta=13:35:54 | 79.6K token/s | 
[epoch_0]_11291  loss=3.562847 |g|=0.376	lr=9.26e-04 | 25.0%@S10  T=987.2ms eta=13:38:28 | 79.8K token/s | 
[Fuyou] head="4" update algorithm=4 t=2.03s
[Section@11300] layer[30-36] tasks=15(nPassBack=0) last_loss=3.62942(-0.0924265) N=(580,9996,9576 1129900)
[epoch_0]_11301  loss=3.564712 |g|=0.374	lr=9.25e-04 | 25.8%@S10  T=1.30s eta=17:57:21 | 78.9K token/s | 
[epoch_0]_11311  loss=3.577363 |g|=0.353	lr=9.25e-04 | 26.6%@S10  T=997.3ms eta=13:46:32 | 79.1K token/s | 
[epoch_0]_11321  loss=3.643877 |g|=0.405	lr=9.25e-04 | 27.4%@S10  T=981.4ms eta=13:33:09 | 79.3K token/s | 
[epoch_0]_11331  loss=3.655044 |g|=0.397	lr=9.25e-04 | 28.2%@S10  T=976.6ms eta=13:29:02 | 79.6K token/s | 
[epoch_0]_11341  loss=3.624911 |g|=0.362	lr=9.25e-04 | 29.1%@S10  T=986.1ms eta=13:36:40 | 79.7K token/s | 
[epoch_0]_11351  loss=3.620379 |g|=0.401	lr=9.25e-04 | 29.9%@S10  T=1.00s eta=13:48:14 | 79.8K token/s | 
[epoch_0]_11361  loss=3.611098 |g|=0.406	lr=9.25e-04 | 30.7%@S10  T=996.2ms eta=13:44:47 | 80.0K token/s | 
[epoch_0]_11371  loss=3.590764 |g|=0.391	lr=9.24e-04 | 31.5%@S10  T=974.7ms eta=13:26:46 | 80.2K token/s | 
[epoch_0]_11381  loss=3.616331 |g|=0.418	lr=9.24e-04 | 32.3%@S10  T=975.4ms eta=13:27:11 | 80.4K token/s | 
[epoch_0]_11391  loss=3.668583 |g|=0.36	lr=9.24e-04 | 33.2%@S10  T=976.9ms eta=13:28:18 | 80.5K token/s | 
[Fuyou] head="5" update algorithm=4 t=2.07s
[eval] 
	 Loss@"edu_fineweb1B"=3.586(0.0073) nBranch=1 nToken=4.01M best=3.5932(55) E2T=-0.0797 T=13.4837(0)s x=0
	#3.58593±0.1079 tps=298K(4.01408M) a=[3.39877,3.86309] T=13.4837(sec)
[Section@11400] layer[0-6] tasks=15(nPassBack=0) last_loss=3.66562(-0.172977) N=(580,10080,9660 1139900)
[epoch_0]_11401  loss=3.653928 |g|=0.385	lr=9.24e-04 | 34.0%@S10  T=4.09s eta=2d 08:27:30 | 77.5K token/s | 
[epoch_0]_11411  loss=3.575105 |g|=0.355	lr=9.24e-04 | 34.8%@S10  T=977.5ms eta=13:28:26 | 77.8K token/s | 
[epoch_0]_11421  loss=3.634516 |g|=0.376	lr=9.24e-04 | 35.6%@S10  T=979.8ms eta=13:30:12 | 78.1K token/s | 
[epoch_0]_11431  loss=3.626443 |g|=0.361	lr=9.24e-04 | 36.4%@S10  T=975.4ms eta=13:26:22 | 78.4K token/s | 
[epoch_0]_11441  loss=3.617766 |g|=0.449	lr=9.23e-04 | 37.3%@S10  T=1.01s eta=13:56:08 | 78.5K token/s | 
[epoch_0]_11451  loss=3.639213 |g|=0.384	lr=9.23e-04 | 38.1%@S10  T=997.3ms eta=13:44:07 | 78.7K token/s | 
[epoch_0]_11461  loss=3.669153 |g|=0.364	lr=9.23e-04 | 38.9%@S10  T=991.5ms eta=13:39:10 | 78.9K token/s | 
[epoch_0]_11471  loss=3.522489 |g|=0.357	lr=9.23e-04 | 39.7%@S10  T=984.3ms eta=13:33:07 | 79.1K token/s | 
[epoch_0]_11481  loss=3.595287 |g|=0.408	lr=9.23e-04 | 40.5%@S10  T=983.9ms eta=13:32:38 | 79.3K token/s | 
[epoch_0]_11491  loss=3.610704 |g|=0.374	lr=9.23e-04 | 41.3%@S10  T=981.4ms eta=13:30:22 | 79.5K token/s | 
[Fuyou] head="0" update algorithm=4 t=2.08s
[Section@11500] layer[6-12] tasks=15(nPassBack=0) last_loss=3.54592(-0.0026958) N=(580,10164,9744 1149900)
[epoch_0]_11501  loss=3.560907 |g|=0.388	lr=9.23e-04 | 42.2%@S10  T=1.25s eta=17:13:01 | 78.8K token/s | 
[epoch_0]_11511  loss=3.622690 |g|=0.388	lr=9.22e-04 | 43.0%@S10  T=967.6ms eta=13:18:41 | 79.1K token/s | 
[epoch_0]_11521  loss=3.621127 |g|=0.387	lr=9.22e-04 | 43.8%@S10  T=972.0ms eta=13:22:08 | 79.4K token/s | 
[epoch_0]_11531  loss=3.560277 |g|=0.383	lr=9.22e-04 | 44.6%@S10  T=971.7ms eta=13:21:41 | 79.6K token/s | 
[epoch_0]_11541  loss=3.650324 |g|=0.448	lr=9.22e-04 | 45.4%@S10  T=979.3ms eta=13:27:47 | 79.8K token/s | 
[epoch_0]_11551  loss=3.692276 |g|=0.404	lr=9.22e-04 | 46.3%@S10  T=983.8ms eta=13:31:21 | 80.0K token/s | 
[epoch_0]_11561  loss=3.673818 |g|=0.363	lr=9.22e-04 | 47.1%@S10  T=983.2ms eta=13:30:40 | 80.2K token/s | 
[epoch_0]_11571  loss=3.578080 |g|=0.364	lr=9.22e-04 | 47.9%@S10  T=976.7ms eta=13:25:09 | 80.4K token/s | 
[epoch_0]_11581  loss=3.590029 |g|=0.363	lr=9.22e-04 | 48.7%@S10  T=1.00s eta=13:44:33 | 80.4K token/s | 
[epoch_0]_11591  loss=3.629574 |g|=0.416	lr=9.21e-04 | 49.5%@S10  T=973.2ms eta=13:22:00 | 80.6K token/s | 
[Fuyou] head="1" update algorithm=4 t=2.03s
[eval] 
	 Loss@"edu_fineweb1B"=3.578(0.0079) nBranch=1 nToken=4.01M best=3.5859(56) E2T=-0.0439 T=13.478(0)s x=0
	#3.57806±0.1082 tps=298K(4.01408M) a=[3.38577,3.86078] T=13.478(sec)
[Section@11600] layer[12-18] tasks=15(nPassBack=0) last_loss=3.62197(0.0636811) N=(580,10248,9828 1159900)
[epoch_0]_11601  loss=3.573810 |g|=0.384	lr=9.21e-04 | 50.4%@S10  T=4.10s eta=2d 08:14:38 | 77.6K token/s | 
[epoch_0]_11611  loss=3.585203 |g|=0.345	lr=9.21e-04 | 51.2%@S10  T=982.7ms eta=13:29:27 | 77.9K token/s | 
[epoch_0]_11621  loss=3.575510 |g|=0.38	lr=9.21e-04 | 52.0%@S10  T=987.2ms eta=13:33:02 | 78.1K token/s | 
[epoch_0]_11631  loss=3.552203 |g|=0.398	lr=9.21e-04 | 52.8%@S10  T=1.00s eta=13:44:50 | 78.3K token/s | 
[epoch_0]_11641  loss=3.665287 |g|=0.453	lr=9.21e-04 | 53.6%@S10  T=983.1ms eta=13:29:18 | 78.6K token/s | 
[epoch_0]_11651  loss=3.586884 |g|=0.358	lr=9.21e-04 | 54.5%@S10  T=970.0ms eta=13:18:20 | 78.9K token/s | 
[epoch_0]_11661  loss=3.583996 |g|=0.405	lr=9.20e-04 | 55.3%@S10  T=983.3ms eta=13:29:08 | 79.1K token/s | 
[epoch_0]_11671  loss=3.676660 |g|=0.377	lr=9.20e-04 | 56.1%@S10  T=989.9ms eta=13:34:26 | 79.3K token/s | 
[epoch_0]_11681  loss=3.627280 |g|=0.38	lr=9.20e-04 | 56.9%@S10  T=1.00s eta=13:42:47 | 79.4K token/s | 
[epoch_0]_11691  loss=3.665778 |g|=0.459	lr=9.20e-04 | 57.7%@S10  T=979.8ms eta=13:25:49 | 79.6K token/s | 
[Fuyou] head="2" update algorithm=4 t=2.04s
[Section@11700] layer[18-24] tasks=15(nPassBack=0) last_loss=3.6185(-0.00211954) N=(580,10332,9912 1169900)
[epoch_0]_11701  loss=3.578098 |g|=0.348	lr=9.20e-04 | 58.5%@S10  T=1.26s eta=17:14:38 | 78.9K token/s | 
[epoch_0]_11711  loss=3.632438 |g|=0.368	lr=9.20e-04 | 59.4%@S10  T=984.7ms eta=13:29:30 | 79.1K token/s | 
[epoch_0]_11721  loss=3.563675 |g|=0.39	lr=9.20e-04 | 60.2%@S10  T=972.9ms eta=13:19:39 | 79.4K token/s | 
[epoch_0]_11731  loss=3.646566 |g|=0.389	lr=9.19e-04 | 61.0%@S10  T=973.1ms eta=13:19:38 | 79.6K token/s | 
[epoch_0]_11741  loss=3.625400 |g|=0.376	lr=9.19e-04 | 61.8%@S10  T=978.2ms eta=13:23:40 | 79.8K token/s | 
[epoch_0]_11751  loss=3.588603 |g|=0.437	lr=9.19e-04 | 62.6%@S10  T=979.5ms eta=13:24:35 | 80.0K token/s | 
[epoch_0]_11761  loss=3.643862 |g|=0.353	lr=9.19e-04 | 63.5%@S10  T=978.7ms eta=13:23:42 | 80.2K token/s | 
[epoch_0]_11771  loss=3.635006 |g|=0.408	lr=9.19e-04 | 64.3%@S10  T=977.8ms eta=13:22:50 | 80.4K token/s | 
[epoch_0]_11781  loss=3.635690 |g|=0.377	lr=9.19e-04 | 65.1%@S10  T=982.1ms eta=13:26:10 | 80.5K token/s | 
[epoch_0]_11791  loss=3.652201 |g|=0.362	lr=9.19e-04 | 65.9%@S10  T=999.8ms eta=13:40:34 | 80.6K token/s | 
[Fuyou] head="3" update algorithm=4 t=2.03s
[eval] 
	 Loss@"edu_fineweb1B"=3.570(0.008) nBranch=1 nToken=4.01M best=3.5781(57) E2T=-0.0403 T=13.4918(0)s x=0
	#3.57009±0.1079 tps=298K(4.01408M) a=[3.37981,3.84926] T=13.4918(sec)
[Section@11800] layer[24-30] tasks=15(nPassBack=0) last_loss=3.6104(-0.0283225) N=(580,10416,9996 1179900)
[epoch_0]_11801  loss=3.594933 |g|=0.334	lr=9.18e-04 | 66.7%@S10  T=4.09s eta=2d 07:59:45 | 77.6K token/s | 
[epoch_0]_11811  loss=3.619757 |g|=0.377	lr=9.18e-04 | 67.6%@S10  T=983.2ms eta=13:26:37 | 77.8K token/s | 
[epoch_0]_11821  loss=3.531259 |g|=0.362	lr=9.18e-04 | 68.4%@S10  T=998.1ms eta=13:38:38 | 78.1K token/s | 
[epoch_0]_11831  loss=3.606970 |g|=0.422	lr=9.18e-04 | 69.2%@S10  T=984.3ms eta=13:27:13 | 78.3K token/s | 
[epoch_0]_11841  loss=3.576177 |g|=0.354	lr=9.18e-04 | 70.0%@S10  T=981.4ms eta=13:24:37 | 78.6K token/s | 
[epoch_0]_11851  loss=3.562244 |g|=0.386	lr=9.18e-04 | 70.8%@S10  T=985.6ms eta=13:27:56 | 78.8K token/s | 
[epoch_0]_11861  loss=3.649258 |g|=0.382	lr=9.18e-04 | 71.7%@S10  T=999.1ms eta=13:38:49 | 79.0K token/s | 
[epoch_0]_11871  loss=3.667590 |g|=0.399	lr=9.17e-04 | 72.5%@S10  T=988.9ms eta=13:30:19 | 79.2K token/s | 
[epoch_0]_11881  loss=3.584794 |g|=0.383	lr=9.17e-04 | 73.3%@S10  T=972.3ms eta=13:16:32 | 79.4K token/s | 
[epoch_0]_11891  loss=3.651036 |g|=0.357	lr=9.17e-04 | 74.1%@S10  T=988.7ms eta=13:29:50 | 79.6K token/s | 
[Fuyou] head="4" update algorithm=4 t=2.07s
[Section@11900] layer[30-36] tasks=15(nPassBack=0) last_loss=3.48404(0.145374) N=(580,10500,10080 1189900)
[epoch_0]_11901  loss=3.583356 |g|=0.371	lr=9.17e-04 | 74.9%@S10  T=1.41s eta=19:12:26 | 78.5K token/s | 
[epoch_0]_11911  loss=3.612440 |g|=0.398	lr=9.17e-04 | 75.8%@S10  T=981.8ms eta=13:23:49 | 78.8K token/s | 
[epoch_0]_11921  loss=3.626809 |g|=0.365	lr=9.17e-04 | 76.6%@S10  T=987.7ms eta=13:28:31 | 79.0K token/s | 
[epoch_0]_11931  loss=3.591692 |g|=0.403	lr=9.17e-04 | 77.4%@S10  T=999.2ms eta=13:37:46 | 79.1K token/s | 
[epoch_0]_11941  loss=3.608936 |g|=0.396	lr=9.16e-04 | 78.2%@S10  T=1.00s eta=13:39:57 | 79.2K token/s | 
[epoch_0]_11951  loss=3.691892 |g|=0.391	lr=9.16e-04 | 79.0%@S10  T=975.5ms eta=13:18:01 | 79.5K token/s | 
[epoch_0]_11961  loss=3.607643 |g|=0.457	lr=9.16e-04 | 79.8%@S10  T=973.3ms eta=13:16:03 | 79.7K token/s | 
[epoch_0]_11971  loss=3.650832 |g|=0.381	lr=9.16e-04 | 80.7%@S10  T=984.0ms eta=13:24:39 | 79.9K token/s | 
[epoch_0]_11981  loss=3.617798 |g|=0.371	lr=9.16e-04 | 81.5%@S10  T=979.0ms eta=13:20:24 | 80.1K token/s | 
[epoch_0]_11991  loss=3.556044 |g|=0.363	lr=9.16e-04 | 82.3%@S10  T=982.0ms eta=13:22:39 | 80.3K token/s | 
[Fuyou] head="5" update algorithm=4 t=2.08s
[eval] 
	 Loss@"edu_fineweb1B"=3.567(0.0026) nBranch=1 nToken=4.01M best=3.5701(58) E2T=-0.102 T=13.4806(0)s x=0
	#3.56745±0.1072 tps=298K(4.01408M) a=[3.38065,3.8447] T=13.4806(sec)
[Section@12000] layer[0-6] tasks=15(nPassBack=0) last_loss=3.66962(-0.00399566) N=(580,10584,10164 1199900)
[epoch_0]_12001  loss=3.560770 |g|=0.395	lr=9.16e-04 | 83.1%@S10  T=4.10s eta=2d 07:51:45 | 77.2K token/s | 
[epoch_0]_12011  loss=3.553293 |g|=0.349	lr=9.15e-04 | 83.9%@S10  T=998.0ms eta=13:35:24 | 77.5K token/s | 
[epoch_0]_12021  loss=3.560144 |g|=0.406	lr=9.15e-04 | 84.8%@S10  T=978.4ms eta=13:19:14 | 77.8K token/s | 
[epoch_0]_12031  loss=3.593125 |g|=0.407	lr=9.15e-04 | 85.6%@S10  T=980.9ms eta=13:21:06 | 78.1K token/s | 
[epoch_0]_12041  loss=3.663006 |g|=0.37	lr=9.15e-04 | 86.4%@S10  T=989.9ms eta=13:28:18 | 78.3K token/s | 
[epoch_0]_12051  loss=3.564742 |g|=0.415	lr=9.15e-04 | 87.2%@S10  T=986.8ms eta=13:25:36 | 78.5K token/s | 
[epoch_0]_12061  loss=3.623198 |g|=0.4	lr=9.15e-04 | 88.0%@S10  T=1.00s eta=13:36:35 | 78.7K token/s | 
[epoch_0]_12071  loss=3.648865 |g|=0.386	lr=9.15e-04 | 88.9%@S10  T=986.5ms eta=13:25:02 | 78.9K token/s | 
[epoch_0]_12081  loss=3.562988 |g|=0.408	lr=9.14e-04 | 89.7%@S10  T=982.0ms eta=13:21:12 | 79.2K token/s | 
[epoch_0]_12091  loss=3.553535 |g|=0.342	lr=9.14e-04 | 90.5%@S10  T=977.8ms eta=13:17:37 | 79.4K token/s | 
[Fuyou] head="0" update algorithm=4 t=2.04s
[Section@12100] layer[6-12] tasks=15(nPassBack=0) last_loss=3.56878(-0.0228603) N=(580,10668,10248 1209900)
[epoch_0]_12101  loss=3.609211 |g|=0.441	lr=9.14e-04 | 91.3%@S10  T=1.33s eta=18:02:49 | 78.5K token/s | 
[epoch_0]_12111  loss=3.619590 |g|=0.397	lr=9.14e-04 | 92.1%@S10  T=981.0ms eta=13:19:53 | 78.8K token/s | 
[epoch_0]_12121  loss=3.556135 |g|=0.367	lr=9.14e-04 | 93.0%@S10  T=998.9ms eta=13:34:22 | 78.9K token/s | 
[epoch_0]_12131  loss=3.555041 |g|=0.406	lr=9.14e-04 | 93.8%@S10  T=1.00s eta=13:37:34 | 79.1K token/s | 
[epoch_0]_12141  loss=3.645979 |g|=0.44	lr=9.14e-04 | 94.6%@S10  T=981.7ms eta=13:19:57 | 79.3K token/s | 
[epoch_0]_12151  loss=3.576714 |g|=0.383	lr=9.13e-04 | 95.4%@S10  T=977.7ms eta=13:16:32 | 79.5K token/s | 
[epoch_0]_12161  loss=3.628228 |g|=0.396	lr=9.13e-04 | 96.2%@S10  T=980.1ms eta=13:18:22 | 79.7K token/s | 
[epoch_0]_12171  loss=3.631393 |g|=0.363	lr=9.13e-04 | 97.1%@S10  T=976.8ms eta=13:15:27 | 79.9K token/s | 
[epoch_0]_12181  loss=3.561090 |g|=0.392	lr=9.13e-04 | 97.9%@S10  T=975.7ms eta=13:14:26 | 80.1K token/s | 
[epoch_0]_12191  loss=3.591928 |g|=0.384	lr=9.13e-04 | 98.7%@S10  T=983.0ms eta=13:20:13 | 80.3K token/s | 
[Fuyou] head="1" update algorithm=4 t=2.12s
[eval] 
	 Loss@"edu_fineweb1B"=3.563(0.0046) nBranch=1 nToken=4.01M best=3.5675(59) E2T=-0.0622 T=13.4897(0)s x=0
	#3.56283±0.1070 tps=298K(4.01408M) a=[3.37412,3.84219] T=13.4897(sec)
[Section@12200] layer[12-18] tasks=15(nPassBack=0) last_loss=3.62501(-0.00304008) N=(580,10752,10332 1219900)
[epoch_0]_12201  loss=3.559228 |g|=0.362	lr=9.13e-04 | 99.5%@S10  T=4.11s eta=2d 07:43:34 | 77.3K token/s | 
[epoch_0]_12206  loss=3.546907 |g|=0.387	lr=9.13e-04 | 99.9%@S10  T=1.03s eta=14:01:08 | 77.4K token/s | 
[epoch_0]_12207  loss=3.618181 |g|=0.429	lr=9.13e-04 | 100.0%@S10  T=1.02s eta=13:50:44 | 77.5K token/s | 
-------- End of shard_10@"./Datasets/edu_fineweb1B/edu_fineweb_train_000010.bin"-------- 
[shard-11]@"./Datasets/edu_fineweb1B/edu_fineweb_train_000011.bin": tokens=100(M) nShardSamples=1220(1074216) 
[epoch_0]_12211  loss=3.465963 |g|=0.363	lr=9.13e-04 | 0.3%@S11  T=990.5ms eta=13:26:00 | 77.8K token/s | 
[epoch_0]_12221  loss=3.549965 |g|=0.402	lr=9.12e-04 | 1.1%@S11  T=976.4ms eta=13:14:21 | 78.1K token/s | 
[epoch_0]_12231  loss=3.538788 |g|=0.374	lr=9.12e-04 | 2.0%@S11  T=975.1ms eta=13:13:08 | 78.4K token/s | 
[epoch_0]_12241  loss=3.578611 |g|=0.383	lr=9.12e-04 | 2.8%@S11  T=971.4ms eta=13:10:00 | 78.7K token/s | 
[epoch_0]_12251  loss=3.555676 |g|=0.467	lr=9.12e-04 | 3.6%@S11  T=981.4ms eta=13:17:56 | 78.9K token/s | 
[epoch_0]_12261  loss=3.567194 |g|=0.367	lr=9.12e-04 | 4.4%@S11  T=984.2ms eta=13:20:04 | 79.1K token/s | 
[epoch_0]_12271  loss=3.527492 |g|=0.392	lr=9.12e-04 | 5.2%@S11  T=981.1ms eta=13:17:19 | 79.3K token/s | 
[epoch_0]_12281  loss=3.571672 |g|=0.386	lr=9.12e-04 | 6.1%@S11  T=998.7ms eta=13:31:32 | 79.5K token/s | 
[epoch_0]_12291  loss=3.523230 |g|=0.391	lr=9.11e-04 | 6.9%@S11  T=974.7ms eta=13:11:52 | 79.7K token/s | 
[Fuyou] head="2" update algorithm=4 t=2.04s
[Section@12300] layer[18-24] tasks=15(nPassBack=0) last_loss=3.54242(0.0760741) N=(580,10836,10416 1229900)
[epoch_0]_12301  loss=3.531741 |g|=0.389	lr=9.11e-04 | 7.7%@S11  T=1.25s eta=16:57:40 | 79.0K token/s | 
[epoch_0]_12311  loss=3.546158 |g|=0.391	lr=9.11e-04 | 8.5%@S11  T=976.0ms eta=13:12:36 | 79.2K token/s | 
[epoch_0]_12321  loss=3.515196 |g|=0.397	lr=9.11e-04 | 9.3%@S11  T=988.3ms eta=13:22:26 | 79.4K token/s | 
[epoch_0]_12331  loss=3.594872 |g|=0.434	lr=9.11e-04 | 10.2%@S11  T=978.3ms eta=13:14:05 | 79.6K token/s | 
[epoch_0]_12341  loss=3.526373 |g|=0.376	lr=9.11e-04 | 11.0%@S11  T=977.4ms eta=13:13:11 | 79.8K token/s | 
[epoch_0]_12351  loss=3.517053 |g|=0.388	lr=9.10e-04 | 11.8%@S11  T=975.9ms eta=13:11:53 | 80.0K token/s | 
[epoch_0]_12361  loss=3.536395 |g|=0.381	lr=9.10e-04 | 12.6%@S11  T=986.4ms eta=13:20:12 | 80.2K token/s | 
[epoch_0]_12371  loss=3.542601 |g|=0.409	lr=9.10e-04 | 13.4%@S11  T=979.0ms eta=13:14:02 | 80.4K token/s | 
[epoch_0]_12381  loss=3.526541 |g|=0.379	lr=9.10e-04 | 14.3%@S11  T=987.8ms eta=13:21:00 | 80.5K token/s | 
[epoch_0]_12391  loss=3.544549 |g|=0.348	lr=9.10e-04 | 15.1%@S11  T=980.0ms eta=13:14:31 | 80.7K token/s | 
[Fuyou] head="3" update algorithm=4 t=1.98s
[eval] 
	 Loss@"edu_fineweb1B"=3.570(-0.0067) nBranch=1 nToken=4.01M best=3.5675(59) E2T=0.0257 T=13.4786(0)s x=0
	#3.56951±0.1083 tps=298K(4.01408M) a=[3.3769,3.84927] T=13.4786(sec)
[Section@12400] layer[24-30] tasks=15(nPassBack=0) last_loss=3.54378(0.0666184) N=(580,10920,10500 1239900)
[epoch_0]_12401  loss=3.603012 |g|=0.36	lr=9.10e-04 | 15.9%@S11  T=4.10s eta=2d 07:21:54 | 77.6K token/s | 
[epoch_0]_12411  loss=3.549643 |g|=0.399	lr=9.10e-04 | 16.7%@S11  T=999.0ms eta=13:29:36 | 77.8K token/s | 
[epoch_0]_12421  loss=3.555935 |g|=0.366	lr=9.09e-04 | 17.5%@S11  T=974.3ms eta=13:09:26 | 78.2K token/s | 
[epoch_0]_12431  loss=3.598012 |g|=0.377	lr=9.09e-04 | 18.4%@S11  T=979.9ms eta=13:13:48 | 78.4K token/s | 
[epoch_0]_12441  loss=3.567884 |g|=0.373	lr=9.09e-04 | 19.2%@S11  T=982.8ms eta=13:15:59 | 78.7K token/s | 
[epoch_0]_12451  loss=3.455784 |g|=0.359	lr=9.09e-04 | 20.0%@S11  T=982.1ms eta=13:15:13 | 78.9K token/s | 
[epoch_0]_12461  loss=3.558208 |g|=0.403	lr=9.09e-04 | 20.8%@S11  T=991.5ms eta=13:22:39 | 79.1K token/s | 
[epoch_0]_12471  loss=3.484848 |g|=0.366	lr=9.09e-04 | 21.6%@S11  T=998.9ms eta=13:28:32 | 79.2K token/s | 
[epoch_0]_12481  loss=3.558888 |g|=0.387	lr=9.09e-04 | 22.4%@S11  T=979.6ms eta=13:12:42 | 79.5K token/s | 
[epoch_0]_12491  loss=3.495305 |g|=0.462	lr=9.08e-04 | 23.3%@S11  T=979.4ms eta=13:12:25 | 79.7K token/s | 
[Fuyou] head="4" update algorithm=4 t=2.07s
[Section@12500] layer[30-36] tasks=15(nPassBack=0) last_loss=3.53248(-0.0484324) N=(580,11004,10584 1249900)
[epoch_0]_12501  loss=3.524465 |g|=0.341	lr=9.08e-04 | 24.1%@S11  T=1.26s eta=16:58:40 | 78.9K token/s | 
[epoch_0]_12511  loss=3.597809 |g|=0.335	lr=9.08e-04 | 24.9%@S11  T=985.5ms eta=13:17:02 | 79.1K token/s | 
[epoch_0]_12521  loss=3.490925 |g|=0.35	lr=9.08e-04 | 25.7%@S11  T=976.9ms eta=13:09:53 | 79.4K token/s | 
[epoch_0]_12531  loss=3.568715 |g|=0.395	lr=9.08e-04 | 26.5%@S11  T=978.7ms eta=13:11:09 | 79.6K token/s | 
[epoch_0]_12541  loss=3.495600 |g|=0.382	lr=9.08e-04 | 27.4%@S11  T=971.1ms eta=13:04:54 | 79.8K token/s | 
[epoch_0]_12551  loss=3.562514 |g|=0.418	lr=9.08e-04 | 28.2%@S11  T=978.8ms eta=13:10:57 | 80.0K token/s | 
[epoch_0]_12561  loss=3.550000 |g|=0.406	lr=9.07e-04 | 29.0%@S11  T=995.3ms eta=13:24:04 | 80.1K token/s | 
[epoch_0]_12571  loss=3.609115 |g|=0.347	lr=9.07e-04 | 29.8%@S11  T=997.5ms eta=13:25:43 | 80.2K token/s | 
[epoch_0]_12581  loss=3.552223 |g|=0.391	lr=9.07e-04 | 30.6%@S11  T=1.00s eta=13:28:58 | 80.3K token/s | 
[epoch_0]_12591  loss=3.514129 |g|=0.379	lr=9.07e-04 | 31.5%@S11  T=982.2ms eta=13:13:01 | 80.5K token/s | 
[Fuyou] head="5" update algorithm=4 t=2.06s
[eval] 
	 Loss@"edu_fineweb1B"=3.573(-0.0036) nBranch=1 nToken=4.01M best=3.5675(59) E2T=-0.0282 T=13.483(0)s x=0
	#3.57315±0.1089 tps=298K(4.01408M) a=[3.37973,3.86289] T=13.483(sec)
[Section@12600] layer[0-6] tasks=15(nPassBack=0) last_loss=3.60131(0.0683095) N=(580,11088,10668 1259900)
[epoch_0]_12601  loss=3.550394 |g|=0.333	lr=9.07e-04 | 32.3%@S11  T=4.09s eta=2d 07:05:20 | 77.4K token/s | 
[epoch_0]_12611  loss=3.530022 |g|=0.341	lr=9.07e-04 | 33.1%@S11  T=979.0ms eta=13:10:06 | 77.8K token/s | 
[epoch_0]_12621  loss=3.431486 |g|=0.342	lr=9.06e-04 | 33.9%@S11  T=986.7ms eta=13:16:09 | 78.0K token/s | 
[epoch_0]_12631  loss=3.526597 |g|=0.372	lr=9.06e-04 | 34.7%@S11  T=984.6ms eta=13:14:19 | 78.3K token/s | 
[epoch_0]_12641  loss=3.510855 |g|=0.361	lr=9.06e-04 | 35.6%@S11  T=997.9ms eta=13:24:52 | 78.5K token/s | 
[epoch_0]_12651  loss=3.521130 |g|=0.347	lr=9.06e-04 | 36.4%@S11  T=1.01s eta=13:31:44 | 78.6K token/s | 
[epoch_0]_12661  loss=3.512332 |g|=0.389	lr=9.06e-04 | 37.2%@S11  T=979.6ms eta=13:09:47 | 78.9K token/s | 
[epoch_0]_12671  loss=3.612331 |g|=0.376	lr=9.06e-04 | 38.0%@S11  T=980.9ms eta=13:10:39 | 79.1K token/s | 
[epoch_0]_12681  loss=3.524282 |g|=0.399	lr=9.06e-04 | 38.8%@S11  T=970.8ms eta=13:02:23 | 79.4K token/s | 
[epoch_0]_12691  loss=3.547749 |g|=0.371	lr=9.05e-04 | 39.7%@S11  T=974.4ms eta=13:05:08 | 79.6K token/s | 
[Fuyou] head="0" update algorithm=4 t=2.07s
[Section@12700] layer[6-12] tasks=15(nPassBack=0) last_loss=3.59587(-0.027086) N=(580,11172,10752 1269900)
[epoch_0]_12701  loss=3.499795 |g|=0.359	lr=9.05e-04 | 40.5%@S11  T=1.36s eta=18:15:23 | 78.6K token/s | 
[epoch_0]_12711  loss=3.621540 |g|=0.36	lr=9.05e-04 | 41.3%@S11  T=975.2ms eta=13:05:24 | 78.9K token/s | 
[epoch_0]_12721  loss=3.527001 |g|=0.381	lr=9.05e-04 | 42.1%@S11  T=976.4ms eta=13:06:12 | 79.2K token/s | 
[epoch_0]_12731  loss=3.542289 |g|=0.43	lr=9.05e-04 | 42.9%@S11  T=981.0ms eta=13:09:44 | 79.4K token/s | 
[epoch_0]_12741  loss=3.611837 |g|=0.386	lr=9.05e-04 | 43.7%@S11  T=977.7ms eta=13:06:58 | 79.6K token/s | 
[epoch_0]_12751  loss=3.566511 |g|=0.363	lr=9.04e-04 | 44.6%@S11  T=978.1ms eta=13:07:04 | 79.8K token/s | 
[epoch_0]_12761  loss=3.576908 |g|=0.411	lr=9.04e-04 | 45.4%@S11  T=974.6ms eta=13:04:06 | 80.0K token/s | 
[epoch_0]_12771  loss=3.509500 |g|=0.41	lr=9.04e-04 | 46.2%@S11  T=984.6ms eta=13:11:58 | 80.2K token/s | 
[epoch_0]_12781  loss=3.553909 |g|=0.382	lr=9.04e-04 | 47.0%@S11  T=997.0ms eta=13:21:48 | 80.3K token/s | 
[epoch_0]_12791  loss=3.485432 |g|=0.324	lr=9.04e-04 | 47.8%@S11  T=1.00s eta=13:25:02 | 80.3K token/s | 
[Fuyou] head="1" update algorithm=4 t=2.05s
[eval] 
	 Loss@"edu_fineweb1B"=3.571(0.0018) nBranch=1 nToken=4.01M best=3.5675(59) E2T=0.0761 T=13.4974(0)s x=0
	#3.57136±0.1093 tps=297K(4.01408M) a=[3.37746,3.85849] T=13.4974(sec)
[Section@12800] layer[12-18] tasks=15(nPassBack=0) last_loss=3.49529(0.129723) N=(580,11256,10836 1279900)
[epoch_0]_12801  loss=3.559201 |g|=0.395	lr=9.04e-04 | 48.7%@S11  T=4.11s eta=2d 07:00:05 | 77.3K token/s | 
[epoch_0]_12811  loss=3.564772 |g|=0.38	lr=9.04e-04 | 49.5%@S11  T=978.5ms eta=13:06:26 | 77.6K token/s | 
[epoch_0]_12821  loss=3.471083 |g|=0.363	lr=9.03e-04 | 50.3%@S11  T=973.6ms eta=13:02:20 | 78.0K token/s | 
[epoch_0]_12831  loss=3.561178 |g|=0.394	lr=9.03e-04 | 51.1%@S11  T=978.7ms eta=13:06:16 | 78.3K token/s | 
[epoch_0]_12841  loss=3.462583 |g|=0.396	lr=9.03e-04 | 51.9%@S11  T=983.0ms eta=13:09:37 | 78.5K token/s | 
[epoch_0]_12851  loss=3.548583 |g|=0.408	lr=9.03e-04 | 52.8%@S11  T=1.00s eta=13:24:20 | 78.7K token/s | 
[epoch_0]_12861  loss=3.532835 |g|=0.35	lr=9.03e-04 | 53.6%@S11  T=1.00s eta=13:24:58 | 78.8K token/s | 
[epoch_0]_12871  loss=3.520720 |g|=0.39	lr=9.03e-04 | 54.4%@S11  T=982.8ms eta=13:08:55 | 79.1K token/s | 
[epoch_0]_12881  loss=3.512667 |g|=0.389	lr=9.03e-04 | 55.2%@S11  T=980.1ms eta=13:06:34 | 79.3K token/s | 
[epoch_0]_12891  loss=3.496952 |g|=0.351	lr=9.02e-04 | 56.0%@S11  T=980.8ms eta=13:07:01 | 79.5K token/s | 
[Fuyou] head="2" update algorithm=4 t=1.99s
[Section@12900] layer[18-24] tasks=15(nPassBack=0) last_loss=3.53915(0.00327015) N=(580,11340,10920 1289900)
[epoch_0]_12901  loss=3.485774 |g|=0.342	lr=9.02e-04 | 56.9%@S11  T=1.29s eta=17:13:00 | 78.7K token/s | 
[epoch_0]_12911  loss=3.525625 |g|=0.379	lr=9.02e-04 | 57.7%@S11  T=979.4ms eta=13:05:33 | 78.9K token/s | 
[epoch_0]_12921  loss=3.560211 |g|=0.349	lr=9.02e-04 | 58.5%@S11  T=979.4ms eta=13:05:24 | 79.2K token/s | 
[epoch_0]_12931  loss=3.543471 |g|=0.381	lr=9.02e-04 | 59.3%@S11  T=982.4ms eta=13:07:39 | 79.4K token/s | 
[epoch_0]_12941  loss=3.486283 |g|=0.391	lr=9.02e-04 | 60.1%@S11  T=973.3ms eta=13:00:08 | 79.6K token/s | 
[epoch_0]_12951  loss=3.543388 |g|=0.378	lr=9.01e-04 | 60.9%@S11  T=978.3ms eta=13:04:02 | 79.8K token/s | 
[epoch_0]_12961  loss=3.555584 |g|=0.401	lr=9.01e-04 | 61.8%@S11  T=985.9ms eta=13:09:56 | 80.0K token/s | 
[epoch_0]_12971  loss=3.483457 |g|=0.385	lr=9.01e-04 | 62.6%@S11  T=985.7ms eta=13:09:35 | 80.2K token/s | 
[epoch_0]_12981  loss=3.458497 |g|=0.348	lr=9.01e-04 | 63.4%@S11  T=988.7ms eta=13:11:48 | 80.3K token/s | 
[epoch_0]_12991  loss=3.583433 |g|=0.409	lr=9.01e-04 | 64.2%@S11  T=981.2ms eta=13:05:41 | 80.4K token/s | 
[Fuyou] head="3" update algorithm=4 t=2.03s
[eval] 
	 Loss@"edu_fineweb1B"=3.572(-0.001) nBranch=1 nToken=4.01M best=3.5675(59) E2T=0.0581 T=13.4828(0)s x=0
	#3.57238±0.1097 tps=298K(4.01408M) a=[3.38923,3.85988] T=13.4828(sec)
[Section@13000] layer[24-30] tasks=15(nPassBack=0) last_loss=3.51425(0.029526) N=(580,11424,11004 1299900)
[epoch_0]_13001  loss=3.586713 |g|=0.381	lr=9.01e-04 | 65.0%@S11  T=4.12s eta=2d 06:55:35 | 77.4K token/s | 
[epoch_0]_13011  loss=3.523138 |g|=0.386	lr=9.01e-04 | 65.9%@S11  T=1.00s eta=13:21:22 | 77.6K token/s | 
[epoch_0]_13021  loss=3.475165 |g|=0.397	lr=9.00e-04 | 66.7%@S11  T=986.2ms eta=13:09:10 | 77.9K token/s | 
[epoch_0]_13031  loss=3.528023 |g|=0.373	lr=9.00e-04 | 67.5%@S11  T=985.9ms eta=13:08:46 | 78.2K token/s | 
[epoch_0]_13041  loss=3.504287 |g|=0.377	lr=9.00e-04 | 68.3%@S11  T=981.0ms eta=13:04:39 | 78.4K token/s | 
[epoch_0]_13051  loss=3.486754 |g|=0.339	lr=9.00e-04 | 69.1%@S11  T=981.7ms eta=13:05:04 | 78.7K token/s | 
[epoch_0]_13061  loss=3.501328 |g|=0.369	lr=9.00e-04 | 70.0%@S11  T=999.8ms eta=13:19:22 | 78.9K token/s | 
[epoch_0]_13071  loss=3.478709 |g|=0.372	lr=9.00e-04 | 70.8%@S11  T=1.00s eta=13:21:25 | 79.0K token/s | 
[epoch_0]_13081  loss=3.502469 |g|=0.35	lr=8.99e-04 | 71.6%@S11  T=984.8ms eta=13:07:03 | 79.2K token/s | 
[epoch_0]_13091  loss=3.521561 |g|=0.356	lr=8.99e-04 | 72.4%@S11  T=1.01s eta=13:23:14 | 79.3K token/s | 
[Fuyou] head="4" update algorithm=4 t=2.07s
[Section@13100] layer[30-36] tasks=15(nPassBack=0) last_loss=3.53187(0.000605345) N=(580,11508,11088 1309900)
[epoch_0]_13101  loss=3.512623 |g|=0.375	lr=8.99e-04 | 73.2%@S11  T=1.28s eta=17:03:35 | 78.6K token/s | 
[epoch_0]_13111  loss=3.431452 |g|=0.353	lr=8.99e-04 | 74.1%@S11  T=979.2ms eta=13:02:06 | 78.8K token/s | 
[epoch_0]_13121  loss=3.498390 |g|=0.365	lr=8.99e-04 | 74.9%@S11  T=976.7ms eta=12:59:59 | 79.1K token/s | 
[epoch_0]_13131  loss=3.500392 |g|=0.364	lr=8.99e-04 | 75.7%@S11  T=979.0ms eta=13:01:39 | 79.3K token/s | 
[epoch_0]_13141  loss=3.534513 |g|=0.39	lr=8.98e-04 | 76.5%@S11  T=986.6ms eta=13:07:31 | 79.5K token/s | 
[epoch_0]_13151  loss=3.458418 |g|=0.358	lr=8.98e-04 | 77.3%@S11  T=991.1ms eta=13:10:59 | 79.6K token/s | 
[epoch_0]_13161  loss=3.576137 |g|=0.356	lr=8.98e-04 | 78.2%@S11  T=985.1ms eta=13:06:00 | 79.8K token/s | 
[epoch_0]_13171  loss=3.523597 |g|=0.401	lr=8.98e-04 | 79.0%@S11  T=1.01s eta=13:25:29 | 79.9K token/s | 
[epoch_0]_13181  loss=3.556129 |g|=0.381	lr=8.98e-04 | 79.8%@S11  T=1.00s eta=13:20:04 | 80.0K token/s | 
[epoch_0]_13191  loss=3.614401 |g|=0.361	lr=8.98e-04 | 80.6%@S11  T=984.5ms eta=13:05:00 | 80.1K token/s | 
[Fuyou] head="5" update algorithm=4 t=1.99s
[eval] 
	 Loss@"edu_fineweb1B"=3.571(0.0013) nBranch=1 nToken=4.01M best=3.5675(59) E2T=0.0091 T=13.4792(0)s x=0
	#3.57108±0.1096 tps=298K(4.01408M) a=[3.37937,3.85571] T=13.4792(sec)
[Section@13200] layer[0-6] tasks=15(nPassBack=0) last_loss=3.56198(0.0393281) N=(580,11592,11172 1319900)
[epoch_0]_13201  loss=3.496224 |g|=0.375	lr=8.98e-04 | 81.4%@S11  T=4.10s eta=2d 06:26:59 | 77.1K token/s | 
[epoch_0]_13211  loss=3.469853 |g|=0.367	lr=8.97e-04 | 82.2%@S11  T=979.2ms eta=13:00:26 | 77.4K token/s | 
[epoch_0]_13221  loss=3.466420 |g|=0.431	lr=8.97e-04 | 83.1%@S11  T=984.4ms eta=13:04:27 | 77.7K token/s | 
[epoch_0]_13231  loss=3.495562 |g|=0.43	lr=8.97e-04 | 83.9%@S11  T=986.9ms eta=13:06:15 | 78.0K token/s | 
[epoch_0]_13241  loss=3.545313 |g|=0.42	lr=8.97e-04 | 84.7%@S11  T=1.03s eta=13:40:09 | 78.1K token/s | 
[epoch_0]_13251  loss=3.540485 |g|=0.377	lr=8.97e-04 | 85.5%@S11  T=1.03s eta=13:36:32 | 78.2K token/s | 
[epoch_0]_13261  loss=3.557248 |g|=0.362	lr=8.97e-04 | 86.3%@S11  T=974.8ms eta=12:56:10 | 78.5K token/s | 
[epoch_0]_13271  loss=3.477283 |g|=0.378	lr=8.96e-04 | 87.2%@S11  T=972.9ms eta=12:54:29 | 78.8K token/s | 
[epoch_0]_13281  loss=3.601503 |g|=0.371	lr=8.96e-04 | 88.0%@S11  T=983.9ms eta=13:03:06 | 79.0K token/s | 
[epoch_0]_13291  loss=3.497567 |g|=0.354	lr=8.96e-04 | 88.8%@S11  T=982.1ms eta=13:01:28 | 79.2K token/s | 
[Fuyou] head="0" update algorithm=4 t=2.06s
[Section@13300] layer[6-12] tasks=15(nPassBack=0) last_loss=3.50193(0.0939372) N=(580,11676,11256 1329900)
[epoch_0]_13301  loss=3.560455 |g|=0.37	lr=8.96e-04 | 89.6%@S11  T=1.25s eta=16:35:12 | 78.5K token/s | 
[epoch_0]_13311  loss=3.546353 |g|=0.4	lr=8.96e-04 | 90.4%@S11  T=979.8ms eta=12:59:22 | 78.8K token/s | 
[epoch_0]_13321  loss=3.479745 |g|=0.404	lr=8.96e-04 | 91.3%@S11  T=978.0ms eta=12:57:44 | 79.0K token/s | 
[epoch_0]_13331  loss=3.471557 |g|=0.418	lr=8.96e-04 | 92.1%@S11  T=983.0ms eta=13:01:31 | 79.2K token/s | 
[epoch_0]_13341  loss=3.471127 |g|=0.361	lr=8.95e-04 | 92.9%@S11  T=971.1ms eta=12:51:55 | 79.5K token/s | 
[epoch_0]_13351  loss=3.565682 |g|=0.356	lr=8.95e-04 | 93.7%@S11  T=977.0ms eta=12:56:28 | 79.7K token/s | 
[epoch_0]_13361  loss=3.519191 |g|=0.474	lr=8.95e-04 | 94.5%@S11  T=984.6ms eta=13:02:21 | 79.9K token/s | 
[epoch_0]_13371  loss=3.471562 |g|=0.367	lr=8.95e-04 | 95.4%@S11  T=989.4ms eta=13:06:01 | 80.0K token/s | 
[epoch_0]_13381  loss=3.486482 |g|=0.375	lr=8.95e-04 | 96.2%@S11  T=1.00s eta=13:16:58 | 80.1K token/s | 
[epoch_0]_13391  loss=3.540543 |g|=0.388	lr=8.95e-04 | 97.0%@S11  T=1.00s eta=13:16:38 | 80.2K token/s | 
[Fuyou] head="1" update algorithm=4 t=2.05s
[eval] 
	 Loss@"edu_fineweb1B"=3.567(0.0044) nBranch=1 nToken=4.01M best=3.5711(65) E2T=0.0293 T=13.4842(0)s x=0
	#3.56672±0.1104 tps=298K(4.01408M) a=[3.37222,3.8524] T=13.4842(sec)
[Section@13400] layer[12-18] tasks=15(nPassBack=0) last_loss=3.5374(-0.0421081) N=(580,11760,11340 1339900)
[epoch_0]_13401  loss=3.471877 |g|=0.347	lr=8.94e-04 | 97.8%@S11  T=4.10s eta=2d 06:11:34 | 77.2K token/s | 
[epoch_0]_13411  loss=3.520159 |g|=0.433	lr=8.94e-04 | 98.6%@S11  T=973.8ms eta=12:52:57 | 77.5K token/s | 
[epoch_0]_13421  loss=3.528002 |g|=0.347	lr=8.94e-04 | 99.5%@S11  T=977.7ms eta=12:55:52 | 77.8K token/s | 
[epoch_0]_13427  loss=3.535079 |g|=0.356	lr=8.94e-04 | 99.9%@S11  T=979.9ms eta=12:57:31 | 78.1K token/s | 
-------- End of shard_11@"./Datasets/edu_fineweb1B/edu_fineweb_train_000011.bin"-------- 
[shard-12]@"./Datasets/edu_fineweb1B/edu_fineweb_train_000465.bin": tokens=100(M) nShardSamples=1220(1171872) 
[epoch_0]_13431  loss=3.527412 |g|=0.38	lr=8.94e-04 | 0.3%@S12  T=989.8ms eta=13:05:17 | 78.4K token/s | 
[epoch_0]_13441  loss=3.554511 |g|=0.42	lr=8.94e-04 | 1.1%@S12  T=987.7ms eta=13:03:30 | 78.6K token/s | 
[epoch_0]_13451  loss=3.468806 |g|=0.393	lr=8.94e-04 | 1.9%@S12  T=999.5ms eta=13:12:38 | 78.8K token/s | 
[epoch_0]_13461  loss=3.534955 |g|=0.367	lr=8.93e-04 | 2.7%@S12  T=1.00s eta=13:14:27 | 78.9K token/s | 
[epoch_0]_13471  loss=3.549297 |g|=0.372	lr=8.93e-04 | 3.5%@S12  T=990.1ms eta=13:04:51 | 79.1K token/s | 
[epoch_0]_13481  loss=3.527567 |g|=0.335	lr=8.93e-04 | 4.4%@S12  T=968.1ms eta=12:47:16 | 79.4K token/s | 
[epoch_0]_13491  loss=3.561302 |g|=0.363	lr=8.93e-04 | 5.2%@S12  T=974.0ms eta=12:51:47 | 79.6K token/s | 
[Fuyou] head="2" update algorithm=4 t=2.02s
[Section@13500] layer[18-24] tasks=15(nPassBack=0) last_loss=3.55765(-0.0184948) N=(580,11844,11424 1349900)
[epoch_0]_13501  loss=3.482601 |g|=0.348	lr=8.93e-04 | 6.0%@S12  T=1.37s eta=18:09:16 | 78.6K token/s | 
[epoch_0]_13511  loss=3.592731 |g|=0.374	lr=8.93e-04 | 6.8%@S12  T=980.1ms eta=12:56:19 | 78.9K token/s | 
[epoch_0]_13521  loss=3.528102 |g|=0.362	lr=8.92e-04 | 7.6%@S12  T=985.2ms eta=13:00:12 | 79.1K token/s | 
[epoch_0]_13531  loss=3.511687 |g|=0.365	lr=8.92e-04 | 8.5%@S12  T=978.1ms eta=12:54:21 | 79.3K token/s | 
[epoch_0]_13541  loss=3.570835 |g|=0.356	lr=8.92e-04 | 9.3%@S12  T=976.9ms eta=12:53:16 | 79.5K token/s | 
[epoch_0]_13551  loss=3.594189 |g|=0.368	lr=8.92e-04 | 10.1%@S12  T=978.3ms eta=12:54:11 | 79.7K token/s | 
[epoch_0]_13561  loss=3.578970 |g|=0.426	lr=8.92e-04 | 10.9%@S12  T=976.0ms eta=12:52:16 | 80.0K token/s | 
[epoch_0]_13571  loss=3.540012 |g|=0.376	lr=8.92e-04 | 11.7%@S12  T=997.9ms eta=13:09:22 | 80.1K token/s | 
[epoch_0]_13581  loss=3.578489 |g|=0.376	lr=8.92e-04 | 12.6%@S12  T=1.00s eta=13:14:22 | 80.1K token/s | 
[epoch_0]_13591  loss=3.503014 |g|=0.396	lr=8.91e-04 | 13.4%@S12  T=986.7ms eta=13:00:14 | 80.3K token/s | 
[Fuyou] head="3" update algorithm=4 t=2.04s
[eval] 
	 Loss@"edu_fineweb1B"=3.562(0.0043) nBranch=1 nToken=4.01M best=3.5667(66) E2T=-0.0723 T=13.4793(0)s x=0
	#3.56243±0.1095 tps=298K(4.01408M) a=[3.3641,3.84458] T=13.4793(sec)
[Section@13600] layer[24-30] tasks=15(nPassBack=0) last_loss=3.6347(-0.12045) N=(580,11928,11508 1359900)
[epoch_0]_13601  loss=3.603405 |g|=0.486	lr=8.91e-04 | 14.2%@S12  T=4.10s eta=2d 06:02:59 | 77.3K token/s | 
[epoch_0]_13611  loss=3.537196 |g|=0.374	lr=8.91e-04 | 15.0%@S12  T=1.00s eta=13:12:15 | 77.5K token/s | 
[epoch_0]_13621  loss=3.561522 |g|=0.353	lr=8.91e-04 | 15.8%@S12  T=972.5ms eta=12:48:32 | 77.8K token/s | 
[epoch_0]_13631  loss=3.518173 |g|=0.39	lr=8.91e-04 | 16.7%@S12  T=990.7ms eta=13:02:42 | 78.1K token/s | 
[epoch_0]_13641  loss=3.584793 |g|=0.375	lr=8.91e-04 | 17.5%@S12  T=992.6ms eta=13:04:03 | 78.3K token/s | 
[epoch_0]_13651  loss=3.570147 |g|=0.38	lr=8.90e-04 | 18.3%@S12  T=989.1ms eta=13:01:05 | 78.5K token/s | 
[epoch_0]_13661  loss=3.547270 |g|=0.367	lr=8.90e-04 | 19.1%@S12  T=1.01s eta=13:14:02 | 78.7K token/s | 
[epoch_0]_13671  loss=3.587696 |g|=0.391	lr=8.90e-04 | 19.9%@S12  T=982.7ms eta=12:55:45 | 78.9K token/s | 
[epoch_0]_13681  loss=3.492467 |g|=0.394	lr=8.90e-04 | 20.8%@S12  T=983.8ms eta=12:56:28 | 79.1K token/s | 
[epoch_0]_13691  loss=3.589677 |g|=0.392	lr=8.90e-04 | 21.6%@S12  T=980.3ms eta=12:53:33 | 79.3K token/s | 
[Fuyou] head="4" update algorithm=4 t=1.98s
[Section@13700] layer[30-36] tasks=15(nPassBack=0) last_loss=3.46031(0.0715601) N=(580,12012,11592 1369900)
[epoch_0]_13701  loss=3.588785 |g|=0.365	lr=8.90e-04 | 22.4%@S12  T=1.26s eta=16:32:04 | 78.6K token/s | 
[epoch_0]_13711  loss=3.471914 |g|=0.347	lr=8.89e-04 | 23.2%@S12  T=982.5ms eta=12:54:56 | 78.9K token/s | 
[epoch_0]_13721  loss=3.543077 |g|=0.333	lr=8.89e-04 | 24.0%@S12  T=1.00s eta=13:10:16 | 79.0K token/s | 
[epoch_0]_13731  loss=3.508718 |g|=0.405	lr=8.89e-04 | 24.8%@S12  T=1.01s eta=13:19:58 | 79.1K token/s | 
[epoch_0]_13741  loss=3.567088 |g|=0.373	lr=8.89e-04 | 25.7%@S12  T=983.2ms eta=12:54:58 | 79.3K token/s | 
[epoch_0]_13751  loss=3.470604 |g|=0.384	lr=8.89e-04 | 26.5%@S12  T=987.8ms eta=12:58:29 | 79.5K token/s | 
[epoch_0]_13761  loss=3.624780 |g|=0.369	lr=8.89e-04 | 27.3%@S12  T=983.9ms eta=12:55:14 | 79.7K token/s | 
[epoch_0]_13771  loss=3.477301 |g|=0.354	lr=8.88e-04 | 28.1%@S12  T=972.7ms eta=12:46:15 | 79.9K token/s | 
[epoch_0]_13781  loss=3.521116 |g|=0.368	lr=8.88e-04 | 28.9%@S12  T=973.4ms eta=12:46:36 | 80.1K token/s | 
[epoch_0]_13791  loss=3.553106 |g|=0.379	lr=8.88e-04 | 29.8%@S12  T=981.7ms eta=12:52:59 | 80.3K token/s | 
[Fuyou] head="5" update algorithm=4 t=2.02s
[eval] 
	 Loss@"edu_fineweb1B"=3.562(0.0002) nBranch=1 nToken=4.01M best=3.5624(67) E2T=0.0274 T=13.4763(0)s x=0
	#3.56223±0.1101 tps=298K(4.01408M) a=[3.36624,3.84729] T=13.4763(sec)
[Section@13800] layer[0-6] tasks=15(nPassBack=0) last_loss=3.53483(0.0271468) N=(580,12096,11676 1379900)
[epoch_0]_13801  loss=3.511459 |g|=0.317	lr=8.88e-04 | 30.6%@S12  T=4.09s eta=2d 05:41:59 | 77.3K token/s | 
[epoch_0]_13811  loss=3.582082 |g|=0.377	lr=8.88e-04 | 31.4%@S12  T=1.00s eta=13:10:56 | 77.5K token/s | 
[epoch_0]_13821  loss=3.499325 |g|=0.379	lr=8.88e-04 | 32.2%@S12  T=980.2ms eta=12:51:18 | 77.8K token/s | 
[epoch_0]_13831  loss=3.567954 |g|=0.354	lr=8.87e-04 | 33.0%@S12  T=983.8ms eta=12:53:59 | 78.1K token/s | 
[epoch_0]_13841  loss=3.510186 |g|=0.416	lr=8.87e-04 | 33.9%@S12  T=979.3ms eta=12:50:18 | 78.3K token/s | 
[epoch_0]_13851  loss=3.564993 |g|=0.416	lr=8.87e-04 | 34.7%@S12  T=984.2ms eta=12:53:57 | 78.6K token/s | 
[epoch_0]_13861  loss=3.566015 |g|=0.348	lr=8.87e-04 | 35.5%@S12  T=1.01s eta=13:13:54 | 78.7K token/s | 
[epoch_0]_13871  loss=3.625485 |g|=0.374	lr=8.87e-04 | 36.3%@S12  T=982.0ms eta=12:51:53 | 78.9K token/s | 
[epoch_0]_13881  loss=3.514216 |g|=0.354	lr=8.87e-04 | 37.1%@S12  T=980.4ms eta=12:50:28 | 79.2K token/s | 
[epoch_0]_13891  loss=3.543633 |g|=0.386	lr=8.86e-04 | 38.0%@S12  T=997.0ms eta=13:03:22 | 79.3K token/s | 
[Fuyou] head="0" update algorithm=4 t=2.03s
[Section@13900] layer[6-12] tasks=15(nPassBack=0) last_loss=3.48939(0.0125408) N=(580,12180,11760 1389900)
[epoch_0]_13901  loss=3.526229 |g|=0.342	lr=8.86e-04 | 38.8%@S12  T=1.28s eta=16:44:35 | 78.6K token/s | 
[epoch_0]_13911  loss=3.538355 |g|=0.408	lr=8.86e-04 | 39.6%@S12  T=972.9ms eta=12:44:07 | 78.8K token/s | 
[epoch_0]_13921  loss=3.541157 |g|=0.362	lr=8.86e-04 | 40.4%@S12  T=980.0ms eta=12:49:33 | 79.1K token/s | 
[epoch_0]_13931  loss=3.566051 |g|=0.354	lr=8.86e-04 | 41.2%@S12  T=983.0ms eta=12:51:42 | 79.3K token/s | 
[epoch_0]_13941  loss=3.619647 |g|=0.388	lr=8.86e-04 | 42.1%@S12  T=981.9ms eta=12:50:41 | 79.5K token/s | 
[epoch_0]_13951  loss=3.460895 |g|=0.345	lr=8.85e-04 | 42.9%@S12  T=981.3ms eta=12:50:03 | 79.7K token/s | 
[epoch_0]_13961  loss=3.642152 |g|=0.407	lr=8.85e-04 | 43.7%@S12  T=986.1ms eta=12:53:38 | 79.9K token/s | 
[epoch_0]_13971  loss=3.469631 |g|=0.376	lr=8.85e-04 | 44.5%@S12  T=986.9ms eta=12:54:06 | 80.0K token/s | 
[epoch_0]_13981  loss=3.558630 |g|=0.363	lr=8.85e-04 | 45.3%@S12  T=992.2ms eta=12:58:05 | 80.2K token/s | 
[epoch_0]_13991  loss=3.556067 |g|=0.399	lr=8.85e-04 | 46.1%@S12  T=979.8ms eta=12:48:11 | 80.3K token/s | 
[Fuyou] head="1" update algorithm=4 t=2.03s
[eval] 
	 Loss@"edu_fineweb1B"=3.558(0.0039) nBranch=1 nToken=4.01M best=3.5622(68) E2T=0.0264 T=13.4865(0)s x=0
	#3.55834±0.1095 tps=298K(4.01408M) a=[3.36171,3.84299] T=13.4865(sec)
[Section@14000] layer[12-18] tasks=15(nPassBack=0) last_loss=3.53195(0.00544453) N=(580,12264,11844 1399900)
[epoch_0]_14001  loss=3.493859 |g|=0.384	lr=8.85e-04 | 47.0%@S12  T=4.11s eta=2d 05:41:36 | 77.3K token/s | 
[epoch_0]_14011  loss=3.465539 |g|=0.347	lr=8.85e-04 | 47.8%@S12  T=1.01s eta=13:11:02 | 77.5K token/s | 
[epoch_0]_14021  loss=3.482422 |g|=0.351	lr=8.84e-04 | 48.6%@S12  T=990.0ms eta=12:55:45 | 77.8K token/s | 
[epoch_0]_14031  loss=3.503422 |g|=0.378	lr=8.84e-04 | 49.4%@S12  T=990.1ms eta=12:55:37 | 78.0K token/s | 
[epoch_0]_14041  loss=3.495924 |g|=0.384	lr=8.84e-04 | 50.2%@S12  T=991.0ms eta=12:56:10 | 78.2K token/s | 
[epoch_0]_14051  loss=3.552307 |g|=0.444	lr=8.84e-04 | 51.1%@S12  T=999.8ms eta=13:02:53 | 78.4K token/s | 
[epoch_0]_14061  loss=3.560673 |g|=0.354	lr=8.84e-04 | 51.9%@S12  T=1.01s eta=13:11:01 | 78.6K token/s | 
[epoch_0]_14071  loss=3.509406 |g|=0.349	lr=8.84e-04 | 52.7%@S12  T=1.00s eta=13:04:48 | 78.7K token/s | 
[epoch_0]_14081  loss=3.435982 |g|=0.34	lr=8.83e-04 | 53.5%@S12  T=983.5ms eta=12:49:41 | 78.9K token/s | 
[epoch_0]_14091  loss=3.536083 |g|=0.389	lr=8.83e-04 | 54.3%@S12  T=991.9ms eta=12:56:02 | 79.1K token/s | 
[Fuyou] head="2" update algorithm=4 t=2.04s
[Section@14100] layer[18-24] tasks=15(nPassBack=0) last_loss=3.48743(0.07022) N=(580,12348,11928 1409900)
[epoch_0]_14101  loss=3.519009 |g|=0.333	lr=8.83e-04 | 55.2%@S12  T=1.33s eta=17:20:36 | 78.3K token/s | 
[epoch_0]_14111  loss=3.603751 |g|=0.395	lr=8.83e-04 | 56.0%@S12  T=989.2ms eta=12:53:37 | 78.5K token/s | 
[epoch_0]_14121  loss=3.539373 |g|=0.406	lr=8.83e-04 | 56.8%@S12  T=993.1ms eta=12:56:29 | 78.7K token/s | 
[epoch_0]_14131  loss=3.512406 |g|=0.397	lr=8.83e-04 | 57.6%@S12  T=1.00s eta=13:01:56 | 78.8K token/s | 
[epoch_0]_14141  loss=3.476794 |g|=0.358	lr=8.82e-04 | 58.4%@S12  T=987.4ms eta=12:51:45 | 79.0K token/s | 
[epoch_0]_14151  loss=3.539588 |g|=0.363	lr=8.82e-04 | 59.3%@S12  T=996.4ms eta=12:58:37 | 79.2K token/s | 
[epoch_0]_14161  loss=3.508673 |g|=0.364	lr=8.82e-04 | 60.1%@S12  T=984.6ms eta=12:49:10 | 79.4K token/s | 
[epoch_0]_14171  loss=3.587477 |g|=0.421	lr=8.82e-04 | 60.9%@S12  T=995.4ms eta=12:57:28 | 79.6K token/s | 
[epoch_0]_14181  loss=3.435767 |g|=0.418	lr=8.82e-04 | 61.7%@S12  T=980.9ms eta=12:45:59 | 79.7K token/s | 
[epoch_0]_14191  loss=3.616489 |g|=0.383	lr=8.82e-04 | 62.5%@S12  T=991.8ms eta=12:54:19 | 79.9K token/s | 
[Fuyou] head="3" update algorithm=4 t=2.04s
[eval] 
	 Loss@"edu_fineweb1B"=3.553(0.0054) nBranch=1 nToken=4.01M best=3.5583(69) E2T=0.0403 T=13.4723(0)s x=0
	#3.55296±0.1096 tps=298K(4.01408M) a=[3.35947,3.83884] T=13.4723(sec)
[Section@14200] layer[24-30] tasks=15(nPassBack=0) last_loss=3.51267(0.122029) N=(580,12432,12012 1419900)
[epoch_0]_14201  loss=3.485762 |g|=0.346	lr=8.81e-04 | 63.3%@S12  T=4.10s eta=2d 05:21:01 | 76.9K token/s | 
[epoch_0]_14211  loss=3.444331 |g|=0.405	lr=8.81e-04 | 64.2%@S12  T=994.3ms eta=12:55:54 | 77.2K token/s | 
[epoch_0]_14221  loss=3.564326 |g|=0.365	lr=8.81e-04 | 65.0%@S12  T=992.1ms eta=12:54:04 | 77.4K token/s | 
[epoch_0]_14231  loss=3.511534 |g|=0.376	lr=8.81e-04 | 65.8%@S12  T=990.5ms eta=12:52:39 | 77.7K token/s | 
[epoch_0]_14241  loss=3.500970 |g|=0.339	lr=8.81e-04 | 66.6%@S12  T=989.7ms eta=12:51:49 | 78.0K token/s | 
[epoch_0]_14251  loss=3.550770 |g|=0.371	lr=8.81e-04 | 67.4%@S12  T=991.0ms eta=12:52:43 | 78.2K token/s | 
[epoch_0]_14261  loss=3.385237 |g|=0.352	lr=8.80e-04 | 68.3%@S12  T=995.9ms eta=12:56:24 | 78.4K token/s | 
[epoch_0]_14271  loss=3.472311 |g|=0.391	lr=8.80e-04 | 69.1%@S12  T=1.01s eta=13:03:20 | 78.6K token/s | 
[epoch_0]_14281  loss=3.597989 |g|=0.372	lr=8.80e-04 | 69.9%@S12  T=1.01s eta=13:08:02 | 78.7K token/s | 
[epoch_0]_14291  loss=3.532696 |g|=0.392	lr=8.80e-04 | 70.7%@S12  T=989.0ms eta=12:50:27 | 78.9K token/s | 
[Fuyou] head="4" update algorithm=4 t=2.03s
[Section@14300] layer[30-36] tasks=15(nPassBack=0) last_loss=3.48031(-0.0200007) N=(580,12516,12096 1429900)
[epoch_0]_14301  loss=3.569512 |g|=0.401	lr=8.80e-04 | 71.5%@S12  T=1.27s eta=16:29:29 | 78.2K token/s | 
[epoch_0]_14311  loss=3.497124 |g|=0.352	lr=8.80e-04 | 72.4%@S12  T=988.1ms eta=12:49:27 | 78.4K token/s | 
[epoch_0]_14321  loss=3.502457 |g|=0.356	lr=8.79e-04 | 73.2%@S12  T=1.01s eta=13:05:39 | 78.5K token/s | 
[epoch_0]_14331  loss=3.505565 |g|=0.417	lr=8.79e-04 | 74.0%@S12  T=985.0ms eta=12:46:45 | 78.8K token/s | 
[epoch_0]_14341  loss=3.496527 |g|=0.383	lr=8.79e-04 | 74.8%@S12  T=993.0ms eta=12:52:46 | 79.0K token/s | 
[epoch_0]_14351  loss=3.388761 |g|=0.352	lr=8.79e-04 | 75.6%@S12  T=985.0ms eta=12:46:22 | 79.2K token/s | 
[epoch_0]_14361  loss=3.521561 |g|=0.352	lr=8.79e-04 | 76.5%@S12  T=989.2ms eta=12:49:29 | 79.3K token/s | 
[epoch_0]_14371  loss=3.486938 |g|=0.349	lr=8.78e-04 | 77.3%@S12  T=986.5ms eta=12:47:12 | 79.5K token/s | 
[epoch_0]_14381  loss=3.553858 |g|=0.358	lr=8.78e-04 | 78.1%@S12  T=989.2ms eta=12:49:08 | 79.7K token/s | 
[epoch_0]_14391  loss=3.537755 |g|=0.374	lr=8.78e-04 | 78.9%@S12  T=996.7ms eta=12:54:52 | 79.8K token/s | 
[Fuyou] head="5" update algorithm=4 t=2.05s
[eval] 
	 Loss@"edu_fineweb1B"=3.552(0.00055) nBranch=1 nToken=4.01M best=3.5530(70) E2T=0.0548 T=13.4892(0)s x=0
	#3.55241±0.1092 tps=298K(4.01408M) a=[3.35849,3.83716] T=13.4892(sec)
[Section@14400] layer[0-6] tasks=15(nPassBack=0) last_loss=3.49759(0.0372441) N=(580,12600,12180 1439900)
[epoch_0]_14401  loss=3.580893 |g|=0.348	lr=8.78e-04 | 79.7%@S12  T=4.11s eta=2d 05:12:21 | 76.8K token/s | 
[epoch_0]_14411  loss=3.599761 |g|=0.388	lr=8.78e-04 | 80.6%@S12  T=1.00s eta=12:59:43 | 77.1K token/s | 
[epoch_0]_14421  loss=3.477791 |g|=0.409	lr=8.78e-04 | 81.4%@S12  T=985.7ms eta=12:45:47 | 77.4K token/s | 
[epoch_0]_14431  loss=3.523072 |g|=0.413	lr=8.77e-04 | 82.2%@S12  T=1.00s eta=12:58:37 | 77.6K token/s | 
[epoch_0]_14441  loss=3.566224 |g|=0.374	lr=8.77e-04 | 83.0%@S12  T=993.5ms eta=12:51:30 | 77.8K token/s | 
[epoch_0]_14451  loss=3.572743 |g|=0.352	lr=8.77e-04 | 83.8%@S12  T=992.9ms eta=12:50:55 | 78.1K token/s | 
[epoch_0]_14461  loss=3.579297 |g|=0.363	lr=8.77e-04 | 84.6%@S12  T=993.8ms eta=12:51:23 | 78.3K token/s | 
[epoch_0]_14471  loss=3.553681 |g|=0.37	lr=8.77e-04 | 85.5%@S12  T=1.00s eta=12:56:41 | 78.5K token/s | 
[epoch_0]_14481  loss=3.506879 |g|=0.371	lr=8.77e-04 | 86.3%@S12  T=1.02s eta=13:10:17 | 78.6K token/s | 
[epoch_0]_14491  loss=3.554536 |g|=0.352	lr=8.76e-04 | 87.1%@S12  T=1.00s eta=12:59:29 | 78.7K token/s | 
[Fuyou] head="0" update algorithm=4 t=2.06s
[Section@14500] layer[6-12] tasks=15(nPassBack=0) last_loss=3.52859(-0.0392005) N=(580,12684,12264 1449900)
[epoch_0]_14501  loss=3.504287 |g|=0.435	lr=8.76e-04 | 87.9%@S12  T=1.29s eta=16:38:06 | 78.0K token/s | 
[epoch_0]_14511  loss=3.534206 |g|=0.345	lr=8.76e-04 | 88.7%@S12  T=995.3ms eta=12:51:45 | 78.2K token/s | 
[epoch_0]_14521  loss=3.574326 |g|=0.374	lr=8.76e-04 | 89.6%@S12  T=1.01s eta=13:04:10 | 78.3K token/s | 
[epoch_0]_14531  loss=3.526252 |g|=0.367	lr=8.76e-04 | 90.4%@S12  T=1.02s eta=13:08:29 | 78.4K token/s | 
[epoch_0]_14541  loss=3.533536 |g|=0.366	lr=8.76e-04 | 91.2%@S12  T=988.8ms eta=12:46:15 | 78.6K token/s | 
[epoch_0]_14551  loss=3.477412 |g|=0.364	lr=8.75e-04 | 92.0%@S12  T=1.00s eta=12:57:16 | 78.8K token/s | 
[epoch_0]_14561  loss=3.572896 |g|=0.354	lr=8.75e-04 | 92.8%@S12  T=985.1ms eta=12:43:03 | 79.0K token/s | 
[epoch_0]_14571  loss=3.533277 |g|=0.345	lr=8.75e-04 | 93.7%@S12  T=983.7ms eta=12:41:46 | 79.2K token/s | 
[epoch_0]_14581  loss=3.564362 |g|=0.384	lr=8.75e-04 | 94.5%@S12  T=989.0ms eta=12:45:42 | 79.4K token/s | 
[epoch_0]_14591  loss=3.538076 |g|=0.362	lr=8.75e-04 | 95.3%@S12  T=989.6ms eta=12:46:00 | 79.6K token/s | 
[Fuyou] head="1" update algorithm=4 t=2.04s
[eval] 
	 Loss@"edu_fineweb1B"=3.548(0.0044) nBranch=1 nToken=4.01M best=3.5524(71) E2T=0.0114 T=13.4889(0)s x=0
	#3.54803±0.1088 tps=298K(4.01408M) a=[3.36233,3.83492] T=13.4889(sec)
[Section@14600] layer[12-18] tasks=15(nPassBack=0) last_loss=3.53667(-0.00471568) N=(580,12768,12348 1459900)
[epoch_0]_14601  loss=3.546005 |g|=0.374	lr=8.75e-04 | 96.1%@S12  T=4.12s eta=2d 05:06:26 | 76.6K token/s | 
[epoch_0]_14611  loss=3.549176 |g|=0.341	lr=8.74e-04 | 96.9%@S12  T=1.01s eta=13:01:36 | 76.8K token/s | 
[epoch_0]_14621  loss=3.467682 |g|=0.388	lr=8.74e-04 | 97.8%@S12  T=993.0ms eta=12:48:10 | 77.1K token/s | 
[epoch_0]_14631  loss=3.527515 |g|=0.363	lr=8.74e-04 | 98.6%@S12  T=987.1ms eta=12:43:23 | 77.4K token/s | 
[epoch_0]_14641  loss=3.481734 |g|=0.375	lr=8.74e-04 | 99.4%@S12  T=987.9ms eta=12:43:52 | 77.7K token/s | 
[epoch_0]_14648  loss=3.535561 |g|=0.381	lr=8.74e-04 | 100.0%@S12  T=989.1ms eta=12:44:40 | 77.9K token/s | 
-------- End of shard_12@"./Datasets/edu_fineweb1B/edu_fineweb_train_000465.bin"-------- 
[shard-13]@"./Datasets/edu_fineweb1B/edu_fineweb_train_000466.bin": tokens=100(M) nShardSamples=1220(1269528) 
[epoch_0]_14651  loss=3.639495 |g|=0.381	lr=8.74e-04 | 0.2%@S13  T=1.02s eta=13:04:50 | 78.1K token/s | 
[epoch_0]_14661  loss=3.598907 |g|=0.372	lr=8.74e-04 | 1.0%@S13  T=1.02s eta=13:05:33 | 78.2K token/s | 
[epoch_0]_14671  loss=3.616435 |g|=0.37	lr=8.73e-04 | 1.9%@S13  T=992.4ms eta=12:46:52 | 78.4K token/s | 
[epoch_0]_14681  loss=3.629601 |g|=0.39	lr=8.73e-04 | 2.7%@S13  T=1.01s eta=12:59:58 | 78.5K token/s | 
[epoch_0]_14691  loss=3.630727 |g|=0.439	lr=8.73e-04 | 3.5%@S13  T=1.02s eta=13:06:09 | 78.6K token/s | 
[Fuyou] head="2" update algorithm=4 t=2.03s
[Section@14700] layer[18-24] tasks=15(nPassBack=0) last_loss=3.56189(-0.0744636) N=(580,12852,12432 1469900)
[epoch_0]_14701  loss=3.541919 |g|=0.452	lr=8.73e-04 | 4.3%@S13  T=1.26s eta=16:09:15 | 78.0K token/s | 
[epoch_0]_14711  loss=3.579298 |g|=0.403	lr=8.73e-04 | 5.1%@S13  T=986.0ms eta=12:41:14 | 78.2K token/s | 
[epoch_0]_14721  loss=3.565716 |g|=0.382	lr=8.73e-04 | 5.9%@S13  T=993.8ms eta=12:47:05 | 78.4K token/s | 
[epoch_0]_14731  loss=3.543919 |g|=0.367	lr=8.72e-04 | 6.8%@S13  T=1.01s eta=13:00:29 | 78.6K token/s | 
[epoch_0]_14741  loss=3.578536 |g|=0.361	lr=8.72e-04 | 7.6%@S13  T=984.0ms eta=12:39:15 | 78.8K token/s | 
[epoch_0]_14751  loss=3.499423 |g|=0.427	lr=8.72e-04 | 8.4%@S13  T=1.03s eta=13:13:47 | 78.8K token/s | 
[epoch_0]_14761  loss=3.598057 |g|=0.371	lr=8.72e-04 | 9.2%@S13  T=991.8ms eta=12:44:55 | 79.0K token/s | 
[epoch_0]_14771  loss=3.558945 |g|=0.375	lr=8.72e-04 | 10.0%@S13  T=986.8ms eta=12:40:54 | 79.2K token/s | 
[epoch_0]_14781  loss=3.569020 |g|=0.378	lr=8.71e-04 | 10.9%@S13  T=987.8ms eta=12:41:30 | 79.4K token/s | 
[epoch_0]_14791  loss=3.593167 |g|=0.401	lr=8.71e-04 | 11.7%@S13  T=988.7ms eta=12:42:03 | 79.6K token/s | 
[Fuyou] head="3" update algorithm=4 t=2.04s
[eval] 
	 Loss@"edu_fineweb1B"=3.538(0.01) nBranch=1 nToken=4.01M best=3.5480(72) E2T=-0.0207 T=13.4879(0)s x=0
	#3.53767±0.1080 tps=298K(4.01408M) a=[3.35053,3.81418] T=13.4879(sec)
[Section@14800] layer[24-30] tasks=15(nPassBack=0) last_loss=3.55833(-0.0456579) N=(580,12936,12516 1479900)
[epoch_0]_14801  loss=3.604589 |g|=0.357	lr=8.71e-04 | 12.5%@S13  T=4.12s eta=2d 04:54:18 | 76.6K token/s | 
[epoch_0]_14811  loss=3.628768 |g|=0.375	lr=8.71e-04 | 13.3%@S13  T=997.2ms eta=12:48:15 | 76.9K token/s | 
[epoch_0]_14821  loss=3.568755 |g|=0.358	lr=8.71e-04 | 14.1%@S13  T=999.3ms eta=12:49:39 | 77.1K token/s | 
[epoch_0]_14831  loss=3.542405 |g|=0.386	lr=8.71e-04 | 15.0%@S13  T=987.6ms eta=12:40:31 | 77.4K token/s | 
[epoch_0]_14841  loss=3.597370 |g|=0.373	lr=8.70e-04 | 15.8%@S13  T=993.5ms eta=12:44:52 | 77.7K token/s | 
[epoch_0]_14851  loss=3.550122 |g|=0.411	lr=8.70e-04 | 16.6%@S13  T=990.0ms eta=12:42:03 | 77.9K token/s | 
[epoch_0]_14861  loss=3.591299 |g|=0.403	lr=8.70e-04 | 17.4%@S13  T=990.6ms eta=12:42:19 | 78.2K token/s | 
[epoch_0]_14871  loss=3.549634 |g|=0.362	lr=8.70e-04 | 18.2%@S13  T=996.9ms eta=12:46:58 | 78.4K token/s | 
[epoch_0]_14881  loss=3.523382 |g|=0.372	lr=8.70e-04 | 19.1%@S13  T=1000.0ms eta=12:49:11 | 78.5K token/s | 
[epoch_0]_14891  loss=3.564771 |g|=0.387	lr=8.70e-04 | 19.9%@S13  T=1.02s eta=13:02:24 | 78.6K token/s | 
[Fuyou] head="4" update algorithm=4 t=2.06s
[Section@14900] layer[30-36] tasks=15(nPassBack=0) last_loss=3.52999(-0.0496809) N=(580,13020,12600 1489900)
[epoch_0]_14901  loss=3.592745 |g|=0.355	lr=8.69e-04 | 20.7%@S13  T=1.36s eta=17:26:43 | 77.7K token/s | 
[epoch_0]_14911  loss=3.581784 |g|=0.406	lr=8.69e-04 | 21.5%@S13  T=992.9ms eta=12:43:17 | 78.0K token/s | 
[epoch_0]_14921  loss=3.557199 |g|=0.364	lr=8.69e-04 | 22.3%@S13  T=987.1ms eta=12:38:37 | 78.2K token/s | 
[epoch_0]_14931  loss=3.612050 |g|=0.36	lr=8.69e-04 | 23.2%@S13  T=990.1ms eta=12:40:45 | 78.4K token/s | 
[epoch_0]_14941  loss=3.539278 |g|=0.4	lr=8.69e-04 | 24.0%@S13  T=997.0ms eta=12:45:54 | 78.6K token/s | 
[epoch_0]_14951  loss=3.588043 |g|=0.358	lr=8.69e-04 | 24.8%@S13  T=1.02s eta=12:59:44 | 78.7K token/s | 
[epoch_0]_14961  loss=3.451741 |g|=0.345	lr=8.68e-04 | 25.6%@S13  T=1.02s eta=13:01:18 | 78.8K token/s | 
[epoch_0]_14971  loss=3.472311 |g|=0.388	lr=8.68e-04 | 26.4%@S13  T=996.1ms eta=12:44:46 | 79.0K token/s | 
[epoch_0]_14981  loss=3.587314 |g|=0.421	lr=8.68e-04 | 27.2%@S13  T=991.7ms eta=12:41:10 | 79.2K token/s | 
[epoch_0]_14991  loss=3.567723 |g|=0.375	lr=8.68e-04 | 28.1%@S13  T=991.7ms eta=12:40:59 | 79.3K token/s | 
[Fuyou] head="5" update algorithm=4 t=2.02s
[eval] 
	 Loss@"edu_fineweb1B"=3.532(0.0061) nBranch=1 nToken=4.01M best=3.5377(73) E2T=-0.00794 T=13.4848(0)s x=0
	#3.5316±0.1078 tps=298K(4.01408M) a=[3.34646,3.80473] T=13.4848(sec)
[Section@15000] layer[0-6] tasks=15(nPassBack=0) last_loss=3.53954(-0.0419474) N=(580,13104,12684 1499900)
[epoch_0]_15001  loss=3.479277 |g|=0.332	lr=8.68e-04 | 28.9%@S13  T=4.12s eta=2d 04:38:55 | 76.4K token/s | 
[epoch_0]_15011  loss=3.553707 |g|=0.368	lr=8.67e-04 | 29.7%@S13  T=994.7ms eta=12:43:01 | 76.7K token/s | 
[epoch_0]_15021  loss=3.513281 |g|=0.354	lr=8.67e-04 | 30.5%@S13  T=1.01s eta=12:54:32 | 76.9K token/s | 
[epoch_0]_15031  loss=3.509404 |g|=0.334	lr=8.67e-04 | 31.3%@S13  T=1.00s eta=12:47:24 | 77.1K token/s | 
[epoch_0]_15041  loss=3.567621 |g|=0.355	lr=8.67e-04 | 32.2%@S13  T=1.02s eta=13:02:01 | 77.3K token/s | 
[epoch_0]_15051  loss=3.508238 |g|=0.359	lr=8.67e-04 | 33.0%@S13  T=1.02s eta=13:00:22 | 77.5K token/s | 
[epoch_0]_15061  loss=3.567658 |g|=0.382	lr=8.67e-04 | 33.8%@S13  T=989.3ms eta=12:38:02 | 77.7K token/s | 
[epoch_0]_15071  loss=3.539399 |g|=0.362	lr=8.66e-04 | 34.6%@S13  T=986.7ms eta=12:35:53 | 78.0K token/s | 
[epoch_0]_15081  loss=3.556985 |g|=0.385	lr=8.66e-04 | 35.4%@S13  T=991.2ms eta=12:39:09 | 78.2K token/s | 
[epoch_0]_15091  loss=3.512280 |g|=0.351	lr=8.66e-04 | 36.3%@S13  T=1.01s eta=12:53:59 | 78.4K token/s | 
[Fuyou] head="0" update algorithm=4 t=2.09s
[Section@15100] layer[6-12] tasks=15(nPassBack=0) last_loss=3.57959(-0.0510051) N=(580,13188,12768 1509900)
[epoch_0]_15101  loss=3.472984 |g|=0.367	lr=8.66e-04 | 37.1%@S13  T=1.43s eta=18:12:40 | 77.3K token/s | 
[epoch_0]_15111  loss=3.471448 |g|=0.385	lr=8.66e-04 | 37.9%@S13  T=992.2ms eta=12:39:26 | 77.6K token/s | 
[epoch_0]_15121  loss=3.533385 |g|=0.442	lr=8.66e-04 | 38.7%@S13  T=1.01s eta=12:55:34 | 77.7K token/s | 
[epoch_0]_15131  loss=3.567631 |g|=0.378	lr=8.65e-04 | 39.5%@S13  T=1.24s eta=15:47:37 | 77.2K token/s | 
[epoch_0]_15141  loss=3.453166 |g|=0.351	lr=8.65e-04 | 40.4%@S13  T=1.30s eta=16:31:56 | 76.5K token/s | 
[epoch_0]_15151  loss=3.514288 |g|=0.412	lr=8.65e-04 | 41.2%@S13  T=1.26s eta=16:05:48 | 75.9K token/s | 
[epoch_0]_15161  loss=3.578405 |g|=0.376	lr=8.65e-04 | 42.0%@S13  T=1.28s eta=16:21:39 | 75.3K token/s | 
[epoch_0]_15171  loss=3.594516 |g|=0.395	lr=8.65e-04 | 42.8%@S13  T=1.31s eta=16:37:45 | 74.6K token/s | 
[epoch_0]_15181  loss=3.513435 |g|=0.398	lr=8.64e-04 | 43.6%@S13  T=1.02s eta=12:57:42 | 74.9K token/s | 
[epoch_0]_15191  loss=3.610091 |g|=0.377	lr=8.64e-04 | 44.5%@S13  T=1.01s eta=12:54:07 | 75.2K token/s | 
[Fuyou] head="1" update algorithm=4 t=2.09s
[eval] 
	 Loss@"edu_fineweb1B"=3.526(0.0058) nBranch=1 nToken=4.01M best=3.5316(74) E2T=-0.00919 T=13.5316(0)s x=0
	#3.52579±0.1084 tps=297K(4.01408M) a=[3.33224,3.792] T=13.5316(sec)
[Section@15200] layer[12-18] tasks=15(nPassBack=0) last_loss=3.53498(0.00168586) N=(580,13272,12852 1519900)
[epoch_0]_15201  loss=3.516639 |g|=0.38	lr=8.64e-04 | 45.3%@S13  T=4.54s eta=2d 09:51:42 | 72.4K token/s | 
[epoch_0]_15211  loss=3.537866 |g|=0.424	lr=8.64e-04 | 46.1%@S13  T=1.30s eta=16:36:34 | 71.9K token/s | 
[epoch_0]_15221  loss=3.585736 |g|=0.389	lr=8.64e-04 | 46.9%@S13  T=1.23s eta=15:40:24 | 71.6K token/s | 
[epoch_0]_15231  loss=3.517993 |g|=0.412	lr=8.64e-04 | 47.7%@S13  T=1.30s eta=16:33:31 | 71.2K token/s | 
[epoch_0]_15241  loss=3.558228 |g|=0.394	lr=8.63e-04 | 48.5%@S13  T=1.39s eta=17:40:32 | 70.6K token/s | 
[epoch_0]_15251  loss=3.516224 |g|=0.402	lr=8.63e-04 | 49.4%@S13  T=1.35s eta=17:08:54 | 70.1K token/s | 
[epoch_0]_15261  loss=3.610100 |g|=0.372	lr=8.63e-04 | 50.2%@S13  T=1.34s eta=17:02:31 | 69.6K token/s | 
[epoch_0]_15271  loss=3.519397 |g|=0.363	lr=8.63e-04 | 51.0%@S13  T=1.28s eta=16:13:25 | 69.4K token/s | 
[epoch_0]_15281  loss=3.579807 |g|=0.376	lr=8.63e-04 | 51.8%@S13  T=1.00s eta=12:42:53 | 70.0K token/s | 
[epoch_0]_15291  loss=3.572359 |g|=0.382	lr=8.63e-04 | 52.6%@S13  T=1.01s eta=12:48:56 | 70.6K token/s | 
[Fuyou] head="2" update algorithm=4 t=3.26s
[Section@15300] layer[18-24] tasks=15(nPassBack=0) last_loss=3.5632(-0.00131488) N=(580,13356,12936 1529900)
[epoch_0]_15301  loss=3.573634 |g|=0.394	lr=8.62e-04 | 53.5%@S13  T=1.77s eta=22:32:57 | 69.3K token/s | 
[epoch_0]_15311  loss=3.465309 |g|=0.386	lr=8.62e-04 | 54.3%@S13  T=1.35s eta=17:08:49 | 68.9K token/s | 
[epoch_0]_15321  loss=3.512461 |g|=0.351	lr=8.62e-04 | 55.1%@S13  T=1.35s eta=17:07:51 | 68.5K token/s | 
[epoch_0]_15331  loss=3.512031 |g|=0.346	lr=8.62e-04 | 55.9%@S13  T=1.22s eta=15:28:14 | 68.4K token/s | 
[epoch_0]_15341  loss=3.458704 |g|=0.388	lr=8.62e-04 | 56.7%@S13  T=1.23s eta=15:35:37 | 68.3K token/s | 
[epoch_0]_15351  loss=3.520956 |g|=0.366	lr=8.61e-04 | 57.6%@S13  T=1.08s eta=13:39:55 | 68.7K token/s | 
[epoch_0]_15361  loss=3.553102 |g|=0.39	lr=8.61e-04 | 58.4%@S13  T=989.2ms eta=12:33:01 | 69.4K token/s | 
[epoch_0]_15371  loss=3.532444 |g|=0.386	lr=8.61e-04 | 59.2%@S13  T=997.7ms eta=12:39:18 | 70.1K token/s | 
[epoch_0]_15381  loss=3.475721 |g|=0.387	lr=8.61e-04 | 60.0%@S13  T=998.4ms eta=12:39:40 | 70.7K token/s | 
[epoch_0]_15391  loss=3.582690 |g|=0.381	lr=8.61e-04 | 60.8%@S13  T=1.01s eta=12:48:24 | 71.2K token/s | 
[Fuyou] head="3" update algorithm=4 t=2.06s
[eval] 
	 Loss@"edu_fineweb1B"=3.523(0.0027) nBranch=1 nToken=4.01M best=3.5258(75) E2T=0.0137 T=13.4973(0)s x=0
	#3.52305±0.1079 tps=297K(4.01408M) a=[3.33697,3.79225] T=13.4973(sec)
[Section@15400] layer[24-30] tasks=15(nPassBack=0) last_loss=3.50934(0.0489953) N=(580,13440,13020 1539900)
[epoch_0]_15401  loss=3.516101 |g|=0.331	lr=8.61e-04 | 61.7%@S13  T=4.12s eta=2d 04:16:06 | 68.6K token/s | 
[epoch_0]_15411  loss=3.541689 |g|=0.367	lr=8.60e-04 | 62.5%@S13  T=1.03s eta=12:59:46 | 69.2K token/s | 
[epoch_0]_15421  loss=3.534310 |g|=0.372	lr=8.60e-04 | 63.3%@S13  T=996.1ms eta=12:37:17 | 69.8K token/s | 
[epoch_0]_15431  loss=3.516055 |g|=0.381	lr=8.60e-04 | 64.1%@S13  T=1.00s eta=12:40:32 | 70.4K token/s | 
[epoch_0]_15441  loss=3.531355 |g|=0.37	lr=8.60e-04 | 64.9%@S13  T=991.8ms eta=12:33:42 | 71.0K token/s | 
[epoch_0]_15451  loss=3.576327 |g|=0.36	lr=8.60e-04 | 65.8%@S13  T=989.7ms eta=12:31:52 | 71.6K token/s | 
[epoch_0]_15461  loss=3.597770 |g|=0.345	lr=8.59e-04 | 66.6%@S13  T=998.2ms eta=12:38:13 | 72.2K token/s | 
[epoch_0]_15471  loss=3.606874 |g|=0.426	lr=8.59e-04 | 67.4%@S13  T=1.03s eta=12:58:54 | 72.5K token/s | 
[epoch_0]_15481  loss=3.504551 |g|=0.4	lr=8.59e-04 | 68.2%@S13  T=1.04s eta=13:10:21 | 72.8K token/s | 
[epoch_0]_15491  loss=3.569238 |g|=0.382	lr=8.59e-04 | 69.0%@S13  T=1.05s eta=13:14:36 | 73.1K token/s | 
[Fuyou] head="4" update algorithm=4 t=2.12s
[Section@15500] layer[30-36] tasks=15(nPassBack=0) last_loss=3.4992(0.0307925) N=(580,13524,13104 1549900)
[epoch_0]_15501  loss=3.560238 |g|=0.378	lr=8.59e-04 | 69.8%@S13  T=1.57s eta=19:50:21 | 72.1K token/s | 
[epoch_0]_15511  loss=3.544564 |g|=0.335	lr=8.59e-04 | 70.7%@S13  T=1.01s eta=12:46:02 | 72.5K token/s | 
[epoch_0]_15521  loss=3.561522 |g|=0.395	lr=8.58e-04 | 71.5%@S13  T=1.01s eta=12:45:37 | 73.0K token/s | 
[epoch_0]_15531  loss=3.588933 |g|=0.359	lr=8.58e-04 | 72.3%@S13  T=1.00s eta=12:41:57 | 73.4K token/s | 
[epoch_0]_15541  loss=3.550292 |g|=0.387	lr=8.58e-04 | 73.1%@S13  T=1.06s eta=13:20:16 | 73.6K token/s | 
[epoch_0]_15551  loss=3.526154 |g|=0.397	lr=8.58e-04 | 73.9%@S13  T=1.03s eta=12:58:15 | 73.9K token/s | 
[epoch_0]_15561  loss=3.486834 |g|=0.357	lr=8.58e-04 | 74.8%@S13  T=1.03s eta=13:03:02 | 74.2K token/s | 
[epoch_0]_15571  loss=3.489309 |g|=0.335	lr=8.58e-04 | 75.6%@S13  T=1.02s eta=12:52:29 | 74.5K token/s | 
[epoch_0]_15581  loss=3.530650 |g|=0.391	lr=8.57e-04 | 76.4%@S13  T=1.02s eta=12:52:59 | 74.8K token/s | 
[epoch_0]_15591  loss=3.621472 |g|=0.354	lr=8.57e-04 | 77.2%@S13  T=1.02s eta=12:52:53 | 75.1K token/s | 
[Fuyou] head="5" update algorithm=4 t=2.06s
[eval] 
	 Loss@"edu_fineweb1B"=3.518(0.0047) nBranch=1 nToken=4.01M best=3.5231(76) E2T=0.0401 T=13.5057(0)s x=0
	#3.51833±0.1082 tps=297K(4.01408M) a=[3.33155,3.78792] T=13.5057(sec)
[Section@15600] layer[0-6] tasks=15(nPassBack=0) last_loss=3.47826(0.0612738) N=(580,13608,13188 1559900)
[epoch_0]_15601  loss=3.439642 |g|=0.354	lr=8.57e-04 | 78.0%@S13  T=4.19s eta=2d 04:51:40 | 72.3K token/s | 
[epoch_0]_15611  loss=3.514877 |g|=0.359	lr=8.57e-04 | 78.9%@S13  T=1.03s eta=12:56:37 | 72.7K token/s | 
[epoch_0]_15621  loss=3.515558 |g|=0.36	lr=8.57e-04 | 79.7%@S13  T=1.00s eta=12:39:33 | 73.1K token/s | 
[epoch_0]_15631  loss=3.498146 |g|=0.352	lr=8.56e-04 | 80.5%@S13  T=1.03s eta=12:57:51 | 73.4K token/s | 
[epoch_0]_15641  loss=3.586124 |g|=0.448	lr=8.56e-04 | 81.3%@S13  T=1.02s eta=12:50:33 | 73.8K token/s | 
[epoch_0]_15651  loss=3.493987 |g|=0.351	lr=8.56e-04 | 82.1%@S13  T=1.27s eta=16:04:16 | 73.3K token/s | 
[epoch_0]_15661  loss=3.564187 |g|=0.368	lr=8.56e-04 | 83.0%@S13  T=1.31s eta=16:32:43 | 72.8K token/s | 
[epoch_0]_15671  loss=3.512150 |g|=0.387	lr=8.56e-04 | 83.8%@S13  T=1.34s eta=16:51:30 | 72.2K token/s | 
[epoch_0]_15681  loss=3.516158 |g|=0.35	lr=8.56e-04 | 84.6%@S13  T=1.34s eta=16:51:12 | 71.6K token/s | 
[epoch_0]_15691  loss=3.526426 |g|=0.379	lr=8.55e-04 | 85.4%@S13  T=1.24s eta=15:38:59 | 71.4K token/s | 
[Fuyou] head="0" update algorithm=4 t=2.18s
[Section@15700] layer[6-12] tasks=15(nPassBack=0) last_loss=3.55829(0.021302) N=(580,13692,13272 1569900)
[epoch_0]_15701  loss=3.537287 |g|=0.342	lr=8.55e-04 | 86.2%@S13  T=1.32s eta=16:40:09 | 70.9K token/s | 
[epoch_0]_15711  loss=3.510747 |g|=0.401	lr=8.55e-04 | 87.0%@S13  T=1.03s eta=12:57:18 | 71.3K token/s | 
[epoch_0]_15721  loss=3.459758 |g|=0.383	lr=8.55e-04 | 87.9%@S13  T=1.07s eta=13:27:47 | 71.6K token/s | 
[epoch_0]_15731  loss=3.485313 |g|=0.347	lr=8.55e-04 | 88.7%@S13  T=1.38s eta=17:19:31 | 71.0K token/s | 
[epoch_0]_15741  loss=3.469228 |g|=0.372	lr=8.54e-04 | 89.5%@S13  T=1.38s eta=17:20:06 | 70.4K token/s | 
[epoch_0]_15751  loss=3.485406 |g|=0.375	lr=8.54e-04 | 90.3%@S13  T=1.34s eta=16:52:07 | 69.9K token/s | 
[epoch_0]_15761  loss=3.597028 |g|=0.384	lr=8.54e-04 | 91.1%@S13  T=1.38s eta=17:21:40 | 69.4K token/s | 
[epoch_0]_15771  loss=3.487585 |g|=0.392	lr=8.54e-04 | 92.0%@S13  T=1.36s eta=17:09:19 | 68.9K token/s | 
[epoch_0]_15781  loss=3.507334 |g|=0.442	lr=8.54e-04 | 92.8%@S13  T=1.36s eta=17:09:05 | 68.5K token/s | 
[epoch_0]_15791  loss=3.575158 |g|=0.354	lr=8.54e-04 | 93.6%@S13  T=1.32s eta=16:37:26 | 68.2K token/s | 
[Fuyou] head="1" update algorithm=4 t=3.56s
[eval] 
	 Loss@"edu_fineweb1B"=3.515(0.0033) nBranch=1 nToken=4.01M best=3.5183(77) E2T=-0.0828 T=13.6551(0)s x=0
	#3.51501±0.1071 tps=294K(4.01408M) a=[3.3276,3.77565] T=13.6551(sec)
[Section@15800] layer[12-18] tasks=15(nPassBack=0) last_loss=3.59782(-0.0628374) N=(580,13776,13356 1579900)
[epoch_0]_15801  loss=3.526989 |g|=0.343	lr=8.53e-04 | 94.4%@S13  T=4.86s eta=2d 13:06:52 | 65.6K token/s | 
[epoch_0]_15811  loss=3.507604 |g|=0.355	lr=8.53e-04 | 95.2%@S13  T=1.33s eta=16:42:31 | 65.4K token/s | 
[epoch_0]_15821  loss=3.566172 |g|=0.361	lr=8.53e-04 | 96.1%@S13  T=1.40s eta=17:34:10 | 65.1K token/s | 
[epoch_0]_15831  loss=3.483261 |g|=0.369	lr=8.53e-04 | 96.9%@S13  T=1.04s eta=13:02:39 | 65.7K token/s | 
[epoch_0]_15841  loss=3.523154 |g|=0.372	lr=8.53e-04 | 97.7%@S13  T=1.03s eta=12:56:58 | 66.4K token/s | 
[epoch_0]_15851  loss=3.618268 |g|=0.391	lr=8.52e-04 | 98.5%@S13  T=1.06s eta=13:18:28 | 67.0K token/s | 
[epoch_0]_15861  loss=3.565601 |g|=0.338	lr=8.52e-04 | 99.3%@S13  T=1.36s eta=17:00:27 | 66.6K token/s | 
[epoch_0]_15869  loss=3.498071 |g|=0.349	lr=8.52e-04 | 100.0%@S13  T=1.42s eta=17:50:08 | 66.2K token/s | 
-------- End of shard_13@"./Datasets/edu_fineweb1B/edu_fineweb_train_000466.bin"-------- 
[shard-14]@"./Datasets/edu_fineweb1B/edu_fineweb_train_000467.bin": tokens=100(M) nShardSamples=1220(1367184) 
[epoch_0]_15871  loss=3.515065 |g|=0.367	lr=8.52e-04 | 0.2%@S14  T=1.50s eta=18:45:24 | 65.6K token/s | 
[epoch_0]_15881  loss=3.545007 |g|=0.36	lr=8.52e-04 | 1.0%@S14  T=1.30s eta=16:21:58 | 65.5K token/s | 
[epoch_0]_15891  loss=3.632789 |g|=0.35	lr=8.52e-04 | 1.8%@S14  T=1.26s eta=15:46:26 | 65.5K token/s | 
[Fuyou] head="2" update algorithm=4 t=2.06s
[Section@15900] layer[18-24] tasks=15(nPassBack=0) last_loss=3.50263(0.0605767) N=(580,13860,13440 1589900)
[epoch_0]_15901  loss=3.555397 |g|=0.394	lr=8.52e-04 | 2.6%@S14  T=1.28s eta=16:04:13 | 65.4K token/s | 
[epoch_0]_15911  loss=3.525616 |g|=0.361	lr=8.51e-04 | 3.4%@S14  T=1.01s eta=12:43:05 | 66.2K token/s | 
[epoch_0]_15921  loss=3.475061 |g|=0.343	lr=8.51e-04 | 4.3%@S14  T=1.04s eta=13:00:19 | 66.8K token/s | 
[epoch_0]_15931  loss=3.603922 |g|=0.368	lr=8.51e-04 | 5.1%@S14  T=1.29s eta=16:12:15 | 66.6K token/s | 
[epoch_0]_15941  loss=3.548338 |g|=0.403	lr=8.51e-04 | 5.9%@S14  T=1.38s eta=17:19:15 | 66.3K token/s | 
[epoch_0]_15951  loss=3.545618 |g|=0.368	lr=8.51e-04 | 6.7%@S14  T=1.29s eta=16:11:27 | 66.1K token/s | 
[epoch_0]_15961  loss=3.524939 |g|=0.366	lr=8.50e-04 | 7.5%@S14  T=1.35s eta=16:56:27 | 65.8K token/s | 
[epoch_0]_15971  loss=3.552998 |g|=0.387	lr=8.50e-04 | 8.3%@S14  T=1.01s eta=12:37:37 | 66.6K token/s | 
[epoch_0]_15981  loss=3.615048 |g|=0.381	lr=8.50e-04 | 9.2%@S14  T=1.03s eta=12:53:11 | 67.2K token/s | 
[epoch_0]_15991  loss=3.460784 |g|=0.379	lr=8.50e-04 | 10.0%@S14  T=1.01s eta=12:41:50 | 67.9K token/s | 
[Fuyou] head="3" update algorithm=4 t=3.50s
[eval] 
	 Loss@"edu_fineweb1B"=3.519(-0.0041) nBranch=1 nToken=4.01M best=3.5183(77) E2T=0.0126 T=13.7171(0)s x=0
	#3.51913±0.1075 tps=293K(4.01408M) a=[3.32726,3.79325] T=13.7171(sec)
[Section@16000] layer[24-30] tasks=15(nPassBack=0) last_loss=3.50651(0.00282359) N=(580,13944,13524 1599900)
[epoch_0]_16001  loss=3.596462 |g|=0.365	lr=8.50e-04 | 10.8%@S14  T=4.84s eta=2d 12:30:30 | 65.4K token/s | 
[epoch_0]_16011  loss=3.514775 |g|=0.345	lr=8.49e-04 | 11.6%@S14  T=1.40s eta=17:29:48 | 65.0K token/s | 
[epoch_0]_16021  loss=3.570502 |g|=0.357	lr=8.49e-04 | 12.4%@S14  T=1.05s eta=13:09:10 | 65.7K token/s | 
[epoch_0]_16031  loss=3.488499 |g|=0.342	lr=8.49e-04 | 13.3%@S14  T=1.02s eta=12:48:06 | 66.4K token/s | 
[epoch_0]_16041  loss=3.472437 |g|=0.378	lr=8.49e-04 | 14.1%@S14  T=1.02s eta=12:47:43 | 67.1K token/s | 
[epoch_0]_16051  loss=3.568343 |g|=0.367	lr=8.49e-04 | 14.9%@S14  T=1.41s eta=17:37:27 | 66.6K token/s | 
[epoch_0]_16061  loss=3.630901 |g|=0.331	lr=8.49e-04 | 15.7%@S14  T=1.39s eta=17:20:21 | 66.2K token/s | 
[epoch_0]_16071  loss=3.525248 |g|=0.422	lr=8.48e-04 | 16.5%@S14  T=1.41s eta=17:34:42 | 65.8K token/s | 
[epoch_0]_16081  loss=3.543244 |g|=0.387	lr=8.48e-04 | 17.4%@S14  T=1.35s eta=16:49:00 | 65.6K token/s | 
[epoch_0]_16091  loss=3.453423 |g|=0.375	lr=8.48e-04 | 18.2%@S14  T=1.34s eta=16:42:21 | 65.4K token/s | 
[Fuyou] head="4" update algorithm=4 t=3.40s
[Section@16100] layer[30-36] tasks=15(nPassBack=0) last_loss=3.55975(-0.0605512) N=(580,14028,13608 1609900)
[epoch_0]_16101  loss=3.535557 |g|=0.341	lr=8.48e-04 | 19.0%@S14  T=1.89s eta=23:36:09 | 64.3K token/s | 
[epoch_0]_16111  loss=3.446247 |g|=0.397	lr=8.48e-04 | 19.8%@S14  T=1.30s eta=16:14:41 | 64.2K token/s | 
[epoch_0]_16121  loss=3.551425 |g|=0.357	lr=8.47e-04 | 20.6%@S14  T=1.23s eta=15:22:44 | 64.3K token/s | 
[epoch_0]_16131  loss=3.510375 |g|=0.396	lr=8.47e-04 | 21.5%@S14  T=1.01s eta=12:34:09 | 65.2K token/s | 
[epoch_0]_16141  loss=3.528887 |g|=0.343	lr=8.47e-04 | 22.3%@S14  T=1.03s eta=12:50:14 | 65.9K token/s | 
[epoch_0]_16151  loss=3.561665 |g|=0.387	lr=8.47e-04 | 23.1%@S14  T=1.03s eta=12:53:04 | 66.6K token/s | 
[epoch_0]_16161  loss=3.595408 |g|=0.372	lr=8.47e-04 | 23.9%@S14  T=1.36s eta=16:57:27 | 66.2K token/s | 
[epoch_0]_16171  loss=3.524671 |g|=0.368	lr=8.47e-04 | 24.7%@S14  T=1.39s eta=17:16:56 | 65.9K token/s | 
[epoch_0]_16181  loss=3.426692 |g|=0.357	lr=8.46e-04 | 25.6%@S14  T=1.39s eta=17:19:52 | 65.5K token/s | 
[epoch_0]_16191  loss=3.530288 |g|=0.364	lr=8.46e-04 | 26.4%@S14  T=1.13s eta=14:04:46 | 65.9K token/s | 
[Fuyou] head="5" update algorithm=4 t=2.05s
[eval] 
	 Loss@"edu_fineweb1B"=3.516(0.0028) nBranch=1 nToken=4.01M best=3.5191(79) E2T=-0.00866 T=13.4579(0)s x=0
	#3.51633±0.1076 tps=298K(4.01408M) a=[3.32934,3.79146] T=13.4579(sec)
[Section@16200] layer[0-6] tasks=15(nPassBack=0) last_loss=3.52498(-0.0467198) N=(580,14112,13692 1619900)
[epoch_0]_16201  loss=3.532535 |g|=0.321	lr=8.46e-04 | 27.2%@S14  T=4.15s eta=2d 03:40:42 | 63.6K token/s | 
[epoch_0]_16211  loss=3.484632 |g|=0.357	lr=8.46e-04 | 28.0%@S14  T=1.36s eta=16:55:18 | 63.4K token/s | 
[epoch_0]_16221  loss=3.479218 |g|=0.352	lr=8.46e-04 | 28.8%@S14  T=1.34s eta=16:41:33 | 63.3K token/s | 
[epoch_0]_16231  loss=3.574522 |g|=0.376	lr=8.45e-04 | 29.6%@S14  T=1.34s eta=16:40:03 | 63.2K token/s | 
[epoch_0]_16241  loss=3.439070 |g|=0.352	lr=8.45e-04 | 30.5%@S14  T=1.36s eta=16:57:42 | 63.0K token/s | 
[epoch_0]_16251  loss=3.577940 |g|=0.396	lr=8.45e-04 | 31.3%@S14  T=1.02s eta=12:44:03 | 63.9K token/s | 
[epoch_0]_16261  loss=3.548821 |g|=0.414	lr=8.45e-04 | 32.1%@S14  T=1.04s eta=12:53:12 | 64.6K token/s | 
[epoch_0]_16271  loss=3.535644 |g|=0.348	lr=8.45e-04 | 32.9%@S14  T=1.03s eta=12:47:03 | 65.4K token/s | 
[epoch_0]_16281  loss=3.504100 |g|=0.4	lr=8.44e-04 | 33.7%@S14  T=1.44s eta=17:57:23 | 65.0K token/s | 
[epoch_0]_16291  loss=3.558142 |g|=0.398	lr=8.44e-04 | 34.6%@S14  T=1.40s eta=17:23:07 | 64.6K token/s | 
[Fuyou] head="0" update algorithm=4 t=3.30s
[Section@16300] layer[6-12] tasks=15(nPassBack=0) last_loss=3.47561(0.0826831) N=(580,14196,13776 1629900)
[epoch_0]_16301  loss=3.497983 |g|=0.349	lr=8.44e-04 | 35.4%@S14  T=2.12s eta=1d 02:21:11 | 63.3K token/s | 
[epoch_0]_16311  loss=3.519788 |g|=0.388	lr=8.44e-04 | 36.2%@S14  T=1.31s eta=16:13:26 | 63.3K token/s | 
[epoch_0]_16321  loss=3.512794 |g|=0.428	lr=8.44e-04 | 37.0%@S14  T=1.38s eta=17:09:59 | 63.1K token/s | 
[epoch_0]_16331  loss=3.526923 |g|=0.402	lr=8.44e-04 | 37.8%@S14  T=1.37s eta=17:00:42 | 62.9K token/s | 
[epoch_0]_16341  loss=3.459302 |g|=0.386	lr=8.43e-04 | 38.7%@S14  T=1.43s eta=17:43:42 | 62.7K token/s | 
[epoch_0]_16351  loss=3.493888 |g|=0.38	lr=8.43e-04 | 39.5%@S14  T=1.41s eta=17:27:42 | 62.4K token/s | 
[epoch_0]_16361  loss=3.543586 |g|=0.379	lr=8.43e-04 | 40.3%@S14  T=1.05s eta=12:59:56 | 63.2K token/s | 
[epoch_0]_16371  loss=3.503094 |g|=0.378	lr=8.43e-04 | 41.1%@S14  T=1.02s eta=12:40:31 | 64.1K token/s | 
[epoch_0]_16381  loss=3.567808 |g|=0.347	lr=8.43e-04 | 41.9%@S14  T=1.02s eta=12:41:14 | 64.9K token/s | 
[epoch_0]_16391  loss=3.478551 |g|=0.371	lr=8.42e-04 | 42.8%@S14  T=1.39s eta=17:10:34 | 64.6K token/s | 
[Fuyou] head="1" update algorithm=4 t=3.77s
[eval] 
	 Loss@"edu_fineweb1B"=3.519(-0.0026) nBranch=1 nToken=4.01M best=3.5163(80) E2T=0.065 T=13.6748(0)s x=0
	#3.51889±0.1083 tps=294K(4.01408M) a=[3.3311,3.79754] T=13.6748(sec)
[Section@16400] layer[12-18] tasks=15(nPassBack=0) last_loss=3.45384(0.143983) N=(580,14280,13860 1639900)
[epoch_0]_16401  loss=3.576932 |g|=0.383	lr=8.42e-04 | 43.6%@S14  T=4.95s eta=2d 13:22:02 | 62.2K token/s | 
[epoch_0]_16411  loss=3.493902 |g|=0.379	lr=8.42e-04 | 44.4%@S14  T=1.31s eta=16:17:35 | 62.2K token/s | 
[epoch_0]_16421  loss=3.520839 |g|=0.383	lr=8.42e-04 | 45.2%@S14  T=1.38s eta=17:07:40 | 62.0K token/s | 
[epoch_0]_16431  loss=3.548041 |g|=0.379	lr=8.42e-04 | 46.0%@S14  T=1.29s eta=15:56:48 | 62.1K token/s | 
[epoch_0]_16441  loss=3.473933 |g|=0.373	lr=8.41e-04 | 46.9%@S14  T=1.45s eta=17:59:56 | 61.8K token/s | 
[epoch_0]_16451  loss=3.659835 |g|=0.354	lr=8.41e-04 | 47.7%@S14  T=1.05s eta=12:59:28 | 62.7K token/s | 
[epoch_0]_16461  loss=3.543654 |g|=0.379	lr=8.41e-04 | 48.5%@S14  T=1.03s eta=12:46:41 | 63.5K token/s | 
[epoch_0]_16471  loss=3.442735 |g|=0.386	lr=8.41e-04 | 49.3%@S14  T=1.03s eta=12:44:38 | 64.3K token/s | 
[epoch_0]_16481  loss=3.484261 |g|=0.354	lr=8.41e-04 | 50.1%@S14  T=1.02s eta=12:36:40 | 65.1K token/s | 
[epoch_0]_16491  loss=3.508107 |g|=0.354	lr=8.40e-04 | 50.9%@S14  T=1.40s eta=17:21:10 | 64.8K token/s | 
[Fuyou] head="2" update algorithm=4 t=3.79s
[Section@16500] layer[18-24] tasks=15(nPassBack=0) last_loss=3.51175(-0.00912499) N=(580,14364,13944 1649900)
[epoch_0]_16501  loss=3.465527 |g|=0.362	lr=8.40e-04 | 51.8%@S14  T=1.98s eta=1d 00:27:57 | 63.6K token/s | 
[epoch_0]_16511  loss=3.522118 |g|=0.387	lr=8.40e-04 | 52.6%@S14  T=1.37s eta=16:53:21 | 63.4K token/s | 
[epoch_0]_16521  loss=3.508788 |g|=0.362	lr=8.40e-04 | 53.4%@S14  T=1.02s eta=12:33:41 | 64.3K token/s | 
[epoch_0]_16531  loss=3.566525 |g|=0.37	lr=8.40e-04 | 54.2%@S14  T=1.05s eta=12:56:16 | 65.0K token/s | 
[epoch_0]_16541  loss=3.538446 |g|=0.379	lr=8.40e-04 | 55.0%@S14  T=1.04s eta=12:54:25 | 65.7K token/s | 
[epoch_0]_16551  loss=3.492091 |g|=0.358	lr=8.39e-04 | 55.9%@S14  T=1.38s eta=17:03:07 | 65.3K token/s | 
[epoch_0]_16561  loss=3.490676 |g|=0.399	lr=8.39e-04 | 56.7%@S14  T=1.36s eta=16:46:39 | 65.1K token/s | 
[epoch_0]_16571  loss=3.480771 |g|=0.37	lr=8.39e-04 | 57.5%@S14  T=1.38s eta=17:01:59 | 64.8K token/s | 
[epoch_0]_16581  loss=3.486000 |g|=0.355	lr=8.39e-04 | 58.3%@S14  T=1.47s eta=18:08:39 | 64.3K token/s | 
[epoch_0]_16591  loss=3.424683 |g|=0.387	lr=8.39e-04 | 59.1%@S14  T=1.05s eta=12:54:11 | 65.1K token/s | 
[Fuyou] head="3" update algorithm=4 t=2.18s
[eval] 
	 Loss@"edu_fineweb1B"=3.514(0.0046) nBranch=1 nToken=4.01M best=3.5189(81) E2T=-0.0214 T=13.457(0)s x=0
	#3.51431±0.1084 tps=298K(4.01408M) a=[3.3285,3.79231] T=13.457(sec)
[Section@16600] layer[24-30] tasks=15(nPassBack=0) last_loss=3.53571(-0.0292001) N=(580,14448,14028 1659900)
[epoch_0]_16601  loss=3.494033 |g|=0.351	lr=8.38e-04 | 60.0%@S14  T=4.15s eta=2d 03:14:24 | 62.8K token/s | 
[epoch_0]_16611  loss=3.486318 |g|=0.347	lr=8.38e-04 | 60.8%@S14  T=1.43s eta=17:36:37 | 62.5K token/s | 
[epoch_0]_16621  loss=3.487361 |g|=0.366	lr=8.38e-04 | 61.6%@S14  T=1.35s eta=16:38:50 | 62.4K token/s | 
[epoch_0]_16631  loss=3.504809 |g|=0.368	lr=8.38e-04 | 62.4%@S14  T=1.39s eta=17:08:20 | 62.3K token/s | 
[epoch_0]_16641  loss=3.529362 |g|=0.383	lr=8.38e-04 | 63.2%@S14  T=1.11s eta=13:41:04 | 62.8K token/s | 
[epoch_0]_16651  loss=3.491648 |g|=0.365	lr=8.37e-04 | 64.1%@S14  T=1.05s eta=12:59:38 | 63.6K token/s | 
[epoch_0]_16661  loss=3.518291 |g|=0.379	lr=8.37e-04 | 64.9%@S14  T=1.03s eta=12:44:40 | 64.4K token/s | 
[epoch_0]_16671  loss=3.486990 |g|=0.356	lr=8.37e-04 | 65.7%@S14  T=1.02s eta=12:37:27 | 65.1K token/s | 
[epoch_0]_16681  loss=3.533928 |g|=0.393	lr=8.37e-04 | 66.5%@S14  T=1.41s eta=17:22:54 | 64.8K token/s | 
[epoch_0]_16691  loss=3.535497 |g|=0.364	lr=8.37e-04 | 67.3%@S14  T=1.42s eta=17:25:47 | 64.4K token/s | 
[Fuyou] head="4" update algorithm=4 t=3.50s
[Section@16700] layer[30-36] tasks=15(nPassBack=0) last_loss=3.50559(0.0541656) N=(580,14532,14112 1669900)
[epoch_0]_16701  loss=3.493566 |g|=0.35	lr=8.37e-04 | 68.2%@S14  T=1.95s eta=23:58:46 | 63.3K token/s | 
[epoch_0]_16711  loss=3.534056 |g|=0.355	lr=8.36e-04 | 69.0%@S14  T=1.02s eta=12:30:41 | 64.2K token/s | 
[epoch_0]_16721  loss=3.495980 |g|=0.347	lr=8.36e-04 | 69.8%@S14  T=1.04s eta=12:44:47 | 64.9K token/s | 
[epoch_0]_16731  loss=3.508510 |g|=0.35	lr=8.36e-04 | 70.6%@S14  T=1.01s eta=12:25:51 | 65.7K token/s | 
[epoch_0]_16741  loss=3.478262 |g|=0.377	lr=8.36e-04 | 71.4%@S14  T=1.32s eta=16:12:08 | 65.6K token/s | 
[epoch_0]_16751  loss=3.535867 |g|=0.387	lr=8.36e-04 | 72.2%@S14  T=1.36s eta=16:43:52 | 65.3K token/s | 
[epoch_0]_16761  loss=3.423503 |g|=0.35	lr=8.35e-04 | 73.1%@S14  T=1.35s eta=16:37:17 | 65.1K token/s | 
[epoch_0]_16771  loss=3.521190 |g|=0.351	lr=8.35e-04 | 73.9%@S14  T=1.20s eta=14:48:36 | 65.2K token/s | 
[epoch_0]_16781  loss=3.571973 |g|=0.376	lr=8.35e-04 | 74.7%@S14  T=1.41s eta=17:20:07 | 64.9K token/s | 
[epoch_0]_16791  loss=3.508438 |g|=0.336	lr=8.35e-04 | 75.5%@S14  T=1.35s eta=16:36:55 | 64.6K token/s | 
[Fuyou] head="5" update algorithm=4 t=3.49s
[eval] 
	 Loss@"edu_fineweb1B"=3.516(-0.0015) nBranch=1 nToken=4.01M best=3.5143(82) E2T=-0.0195 T=13.7363(0)s x=0
	#3.51582±0.1084 tps=292K(4.01408M) a=[3.32952,3.79444] T=13.7363(sec)
[Section@16800] layer[0-6] tasks=15(nPassBack=0) last_loss=3.53529(-0.0103078) N=(580,14616,14196 1679900)
[epoch_0]_16801  loss=3.455286 |g|=0.334	lr=8.35e-04 | 76.3%@S14  T=4.86s eta=2d 11:43:10 | 62.3K token/s | 
[epoch_0]_16811  loss=3.460059 |g|=0.394	lr=8.34e-04 | 77.2%@S14  T=1.47s eta=18:01:57 | 61.9K token/s | 
[epoch_0]_16821  loss=3.503060 |g|=0.338	lr=8.34e-04 | 78.0%@S14  T=1.37s eta=16:46:44 | 61.8K token/s | 
[epoch_0]_16831  loss=3.523376 |g|=0.371	lr=8.34e-04 | 78.8%@S14  T=1.02s eta=12:30:11 | 62.8K token/s | 
[epoch_0]_16841  loss=3.568346 |g|=0.435	lr=8.34e-04 | 79.6%@S14  T=1.03s eta=12:40:04 | 63.6K token/s | 
[epoch_0]_16851  loss=3.525180 |g|=0.368	lr=8.34e-04 | 80.4%@S14  T=1.04s eta=12:42:42 | 64.4K token/s | 
[epoch_0]_16861  loss=3.533009 |g|=0.387	lr=8.33e-04 | 81.3%@S14  T=1.22s eta=14:59:05 | 64.5K token/s | 
[epoch_0]_16871  loss=3.477670 |g|=0.328	lr=8.33e-04 | 82.1%@S14  T=1.41s eta=17:17:56 | 64.2K token/s | 
[epoch_0]_16881  loss=3.524989 |g|=0.381	lr=8.33e-04 | 82.9%@S14  T=1.34s eta=16:24:55 | 64.0K token/s | 
[epoch_0]_16891  loss=3.528681 |g|=0.37	lr=8.33e-04 | 83.7%@S14  T=1.34s eta=16:26:40 | 63.9K token/s | 
[Fuyou] head="0" update algorithm=4 t=2.21s
[Section@16900] layer[6-12] tasks=15(nPassBack=0) last_loss=3.47864(-0.00302935) N=(580,14700,14280 1689900)
[epoch_0]_16901  loss=3.538259 |g|=0.364	lr=8.33e-04 | 84.5%@S14  T=1.31s eta=16:05:55 | 63.8K token/s | 
[epoch_0]_16911  loss=3.490559 |g|=0.336	lr=8.32e-04 | 85.4%@S14  T=1.03s eta=12:40:13 | 64.6K token/s | 
[epoch_0]_16921  loss=3.463126 |g|=0.361	lr=8.32e-04 | 86.2%@S14  T=1.03s eta=12:40:24 | 65.3K token/s | 
[epoch_0]_16931  loss=3.506728 |g|=0.372	lr=8.32e-04 | 87.0%@S14  T=1.42s eta=17:26:41 | 64.9K token/s | 
[epoch_0]_16941  loss=3.492190 |g|=0.37	lr=8.32e-04 | 87.8%@S14  T=1.43s eta=17:34:27 | 64.5K token/s | 
[epoch_0]_16951  loss=3.480269 |g|=0.367	lr=8.32e-04 | 88.6%@S14  T=1.31s eta=16:04:06 | 64.4K token/s | 
[epoch_0]_16961  loss=3.543023 |g|=0.37	lr=8.32e-04 | 89.4%@S14  T=1.33s eta=16:17:25 | 64.3K token/s | 
[epoch_0]_16971  loss=3.554640 |g|=0.368	lr=8.31e-04 | 90.3%@S14  T=1.06s eta=13:00:17 | 64.9K token/s | 
[epoch_0]_16981  loss=3.541170 |g|=0.368	lr=8.31e-04 | 91.1%@S14  T=1.06s eta=12:59:22 | 65.5K token/s | 
[epoch_0]_16991  loss=3.451669 |g|=0.356	lr=8.31e-04 | 91.9%@S14  T=1.06s eta=12:59:24 | 66.1K token/s | 
[Fuyou] head="1" update algorithm=4 t=3.34s
[eval] 
	 Loss@"edu_fineweb1B"=3.514(0.0014) nBranch=1 nToken=4.01M best=3.5143(82) E2T=0.0632 T=13.7506(0)s x=0
	#3.51439±0.1085 tps=292K(4.01408M) a=[3.3316,3.79784] T=13.7506(sec)
[Section@17000] layer[12-18] tasks=15(nPassBack=0) last_loss=3.45118(0.00265408) N=(580,14784,14364 1699900)
[epoch_0]_17001  loss=3.439267 |g|=0.367	lr=8.31e-04 | 92.7%@S14  T=4.81s eta=2d 10:50:41 | 63.7K token/s | 
[epoch_0]_17011  loss=3.445252 |g|=0.383	lr=8.31e-04 | 93.5%@S14  T=1.39s eta=17:00:24 | 63.4K token/s | 
[epoch_0]_17021  loss=3.496308 |g|=0.371	lr=8.30e-04 | 94.4%@S14  T=1.03s eta=12:36:06 | 64.2K token/s | 
[epoch_0]_17031  loss=3.498288 |g|=0.386	lr=8.30e-04 | 95.2%@S14  T=1.03s eta=12:36:29 | 65.0K token/s | 
[epoch_0]_17041  loss=3.486716 |g|=0.363	lr=8.30e-04 | 96.0%@S14  T=1.02s eta=12:30:58 | 65.7K token/s | 
[epoch_0]_17051  loss=3.437302 |g|=0.36	lr=8.30e-04 | 96.8%@S14  T=1.31s eta=16:01:39 | 65.6K token/s | 
[epoch_0]_17061  loss=3.540504 |g|=0.367	lr=8.30e-04 | 97.6%@S14  T=1.40s eta=17:07:42 | 65.2K token/s | 
[epoch_0]_17071  loss=3.448040 |g|=0.346	lr=8.29e-04 | 98.5%@S14  T=1.37s eta=16:42:27 | 64.9K token/s | 
[epoch_0]_17081  loss=3.460967 |g|=0.371	lr=8.29e-04 | 99.3%@S14  T=1.38s eta=16:51:49 | 64.7K token/s | 
[epoch_0]_17089  loss=3.441468 |g|=0.364	lr=8.29e-04 | 99.9%@S14  T=1.07s eta=13:05:37 | 65.3K token/s | 
-------- End of shard_14@"./Datasets/edu_fineweb1B/edu_fineweb_train_000467.bin"-------- 
[shard-15]@"./Datasets/edu_fineweb1B/edu_fineweb_train_000468.bin": tokens=100(M) nShardSamples=1220(1464840) 
[epoch_0]_17091  loss=3.502960 |g|=0.364	lr=8.29e-04 | 0.1%@S15  T=1.12s eta=13:37:38 | 65.7K token/s | 
[Fuyou] head="2" update algorithm=4 t=2.14s
[Section@17100] layer[18-24] tasks=15(nPassBack=0) last_loss=3.54116(-0.0294089) N=(580,14868,14448 1709900)
[epoch_0]_17101  loss=3.584640 |g|=0.354	lr=8.29e-04 | 0.9%@S15  T=1.56s eta=18:59:59 | 65.0K token/s | 
[epoch_0]_17111  loss=3.533762 |g|=0.36	lr=8.29e-04 | 1.7%@S15  T=1.23s eta=15:00:00 | 65.1K token/s | 
[epoch_0]_17121  loss=3.562583 |g|=0.339	lr=8.28e-04 | 2.6%@S15  T=1.39s eta=16:57:14 | 64.8K token/s | 
[epoch_0]_17131  loss=3.620477 |g|=0.369	lr=8.28e-04 | 3.4%@S15  T=1.38s eta=16:47:52 | 64.5K token/s | 
[epoch_0]_17141  loss=3.462223 |g|=0.398	lr=8.28e-04 | 4.2%@S15  T=1.35s eta=16:24:22 | 64.3K token/s | 
[epoch_0]_17151  loss=3.581749 |g|=0.361	lr=8.28e-04 | 5.0%@S15  T=1.04s eta=12:42:47 | 65.0K token/s | 
[epoch_0]_17161  loss=3.536699 |g|=0.37	lr=8.28e-04 | 5.8%@S15  T=1.05s eta=12:46:29 | 65.7K token/s | 
[epoch_0]_17171  loss=3.583733 |g|=0.384	lr=8.27e-04 | 6.7%@S15  T=1.06s eta=12:53:29 | 66.3K token/s | 
[epoch_0]_17181  loss=3.490092 |g|=0.376	lr=8.27e-04 | 7.5%@S15  T=1.34s eta=16:22:55 | 66.0K token/s | 
[epoch_0]_17191  loss=3.554654 |g|=0.371	lr=8.27e-04 | 8.3%@S15  T=1.37s eta=16:39:01 | 65.7K token/s | 
[Fuyou] head="3" update algorithm=4 t=3.21s
[eval] 
	 Loss@"edu_fineweb1B"=3.502(0.012) nBranch=1 nToken=4.01M best=3.5144(84) E2T=-0.0195 T=13.6867(0)s x=0
	#3.50226±0.1073 tps=293K(4.01408M) a=[3.31397,3.78349] T=13.6867(sec)
[Section@17200] layer[24-30] tasks=15(nPassBack=0) last_loss=3.52175(0.0139642) N=(580,14952,14532 1719900)
[epoch_0]_17201  loss=3.481441 |g|=0.335	lr=8.27e-04 | 9.1%@S15  T=4.47s eta=2d 06:26:30 | 63.3K token/s | 
[epoch_0]_17211  loss=3.509161 |g|=0.374	lr=8.27e-04 | 9.9%@S15  T=1.05s eta=12:43:49 | 64.1K token/s | 
[epoch_0]_17221  loss=3.610621 |g|=0.333	lr=8.26e-04 | 10.7%@S15  T=1.04s eta=12:38:13 | 64.8K token/s | 
[epoch_0]_17231  loss=3.493077 |g|=0.389	lr=8.26e-04 | 11.6%@S15  T=1.06s eta=12:52:21 | 65.5K token/s | 
[epoch_0]_17241  loss=3.530148 |g|=0.365	lr=8.26e-04 | 12.4%@S15  T=1.36s eta=16:36:15 | 65.2K token/s | 
[epoch_0]_17251  loss=3.429834 |g|=0.362	lr=8.26e-04 | 13.2%@S15  T=1.39s eta=16:51:25 | 64.9K token/s | 
[epoch_0]_17261  loss=3.575236 |g|=0.374	lr=8.26e-04 | 14.0%@S15  T=1.42s eta=17:14:40 | 64.5K token/s | 
[epoch_0]_17271  loss=3.541412 |g|=0.393	lr=8.25e-04 | 14.8%@S15  T=1.07s eta=12:56:52 | 65.1K token/s | 
[epoch_0]_17281  loss=3.576449 |g|=0.355	lr=8.25e-04 | 15.7%@S15  T=1.04s eta=12:37:09 | 65.8K token/s | 
[epoch_0]_17291  loss=3.540958 |g|=0.351	lr=8.25e-04 | 16.5%@S15  T=1.08s eta=13:07:49 | 66.3K token/s | 
[Fuyou] head="4" update algorithm=4 t=3.20s
[Section@17300] layer[30-36] tasks=15(nPassBack=0) last_loss=3.57888(-0.0732899) N=(580,15036,14616 1729900)
[epoch_0]_17301  loss=3.487939 |g|=0.349	lr=8.25e-04 | 17.3%@S15  T=2.08s eta=1d 01:17:47 | 65.0K token/s | 
[epoch_0]_17311  loss=3.521441 |g|=0.384	lr=8.25e-04 | 18.1%@S15  T=1.35s eta=16:21:09 | 64.8K token/s | 
[epoch_0]_17321  loss=3.534954 |g|=0.381	lr=8.24e-04 | 18.9%@S15  T=1.40s eta=17:00:33 | 64.5K token/s | 
[epoch_0]_17331  loss=3.479084 |g|=0.377	lr=8.24e-04 | 19.8%@S15  T=1.11s eta=13:31:58 | 64.9K token/s | 
[epoch_0]_17341  loss=3.536658 |g|=0.39	lr=8.24e-04 | 20.6%@S15  T=1.04s eta=12:34:30 | 65.6K token/s | 
[epoch_0]_17351  loss=3.553134 |g|=0.352	lr=8.24e-04 | 21.4%@S15  T=1.04s eta=12:34:27 | 66.3K token/s | 
[epoch_0]_17361  loss=3.508152 |g|=0.362	lr=8.24e-04 | 22.2%@S15  T=1.02s eta=12:19:37 | 67.0K token/s | 
[epoch_0]_17371  loss=3.533339 |g|=0.351	lr=8.24e-04 | 23.0%@S15  T=1.39s eta=16:52:59 | 66.6K token/s | 
[epoch_0]_17381  loss=3.502791 |g|=0.379	lr=8.23e-04 | 23.9%@S15  T=1.34s eta=16:12:18 | 66.3K token/s | 
[epoch_0]_17391  loss=3.496931 |g|=0.377	lr=8.23e-04 | 24.7%@S15  T=1.40s eta=16:55:28 | 66.0K token/s | 
[Fuyou] head="5" update algorithm=4 t=2.23s
[eval] 
	 Loss@"edu_fineweb1B"=3.498(0.0039) nBranch=1 nToken=4.01M best=3.5023(85) E2T=0.065 T=13.4613(0)s x=0
	#3.4984±0.1071 tps=298K(4.01408M) a=[3.31031,3.77515] T=13.4613(sec)
[Section@17400] layer[0-6] tasks=15(nPassBack=0) last_loss=3.43335(0.101939) N=(580,15120,14700 1739900)
[epoch_0]_17401  loss=3.612190 |g|=0.375	lr=8.23e-04 | 25.5%@S15  T=4.21s eta=2d 02:58:09 | 63.6K token/s | 
[epoch_0]_17411  loss=3.519864 |g|=0.375	lr=8.23e-04 | 26.3%@S15  T=1.10s eta=13:18:31 | 64.2K token/s | 
[epoch_0]_17421  loss=3.534743 |g|=0.383	lr=8.23e-04 | 27.1%@S15  T=1.44s eta=17:24:52 | 63.8K token/s | 
[epoch_0]_17431  loss=3.559779 |g|=0.408	lr=8.22e-04 | 28.0%@S15  T=1.35s eta=16:20:43 | 63.7K token/s | 
[epoch_0]_17441  loss=3.554706 |g|=0.366	lr=8.22e-04 | 28.8%@S15  T=1.38s eta=16:42:29 | 63.4K token/s | 
[epoch_0]_17451  loss=3.552274 |g|=0.354	lr=8.22e-04 | 29.6%@S15  T=1.04s eta=12:34:09 | 64.2K token/s | 
[epoch_0]_17461  loss=3.471665 |g|=0.465	lr=8.22e-04 | 30.4%@S15  T=1.03s eta=12:24:23 | 65.0K token/s | 
[epoch_0]_17471  loss=3.441364 |g|=0.344	lr=8.22e-04 | 31.2%@S15  T=1.02s eta=12:19:30 | 65.8K token/s | 
[epoch_0]_17481  loss=3.504801 |g|=0.338	lr=8.21e-04 | 32.0%@S15  T=1.29s eta=15:32:55 | 65.7K token/s | 
[epoch_0]_17491  loss=3.512027 |g|=0.342	lr=8.21e-04 | 32.9%@S15  T=1.41s eta=17:02:34 | 65.3K token/s | 
[Fuyou] head="0" update algorithm=4 t=3.59s
[Section@17500] layer[6-12] tasks=15(nPassBack=0) last_loss=3.47627(0.00236201) N=(580,15204,14784 1749900)
[epoch_0]_17501  loss=3.449465 |g|=0.304	lr=8.21e-04 | 33.7%@S15  T=1.88s eta=22:42:36 | 64.2K token/s | 
[epoch_0]_17511  loss=3.558563 |g|=0.355	lr=8.21e-04 | 34.5%@S15  T=1.04s eta=12:34:07 | 64.9K token/s | 
[epoch_0]_17521  loss=3.554773 |g|=0.366	lr=8.21e-04 | 35.3%@S15  T=1.04s eta=12:35:21 | 65.6K token/s | 
[epoch_0]_17531  loss=3.542592 |g|=0.368	lr=8.20e-04 | 36.1%@S15  T=1.06s eta=12:50:32 | 66.2K token/s | 
[epoch_0]_17541  loss=3.473038 |g|=0.36	lr=8.20e-04 | 37.0%@S15  T=1.06s eta=12:48:18 | 66.8K token/s | 
[epoch_0]_17551  loss=3.503961 |g|=0.369	lr=8.20e-04 | 37.8%@S15  T=1.35s eta=16:15:30 | 66.5K token/s | 
[epoch_0]_17561  loss=3.521614 |g|=0.354	lr=8.20e-04 | 38.6%@S15  T=1.38s eta=16:41:38 | 66.1K token/s | 
[epoch_0]_17571  loss=3.553556 |g|=0.39	lr=8.20e-04 | 39.4%@S15  T=1.39s eta=16:46:24 | 65.7K token/s | 
[epoch_0]_17581  loss=3.507437 |g|=0.4	lr=8.19e-04 | 40.2%@S15  T=1.04s eta=12:31:36 | 66.4K token/s | 
[epoch_0]_17591  loss=3.608508 |g|=0.346	lr=8.19e-04 | 41.1%@S15  T=1.07s eta=12:51:20 | 66.9K token/s | 
[Fuyou] head="1" update algorithm=4 t=2.10s
[eval] 
	 Loss@"edu_fineweb1B"=3.497(0.00094) nBranch=1 nToken=4.01M best=3.4984(86) E2T=-0.049 T=13.5865(0)s x=0
	#3.49746±0.1071 tps=295K(4.01408M) a=[3.31193,3.77948] T=13.5865(sec)
[Section@17600] layer[12-18] tasks=15(nPassBack=0) last_loss=3.5465(-0.0953193) N=(580,15288,14868 1759900)
[epoch_0]_17601  loss=3.522834 |g|=0.346	lr=8.19e-04 | 41.9%@S15  T=4.65s eta=2d 08:04:31 | 64.5K token/s | 
[epoch_0]_17611  loss=3.503374 |g|=0.392	lr=8.19e-04 | 42.7%@S15  T=1.37s eta=16:31:58 | 64.2K token/s | 
[epoch_0]_17621  loss=3.543678 |g|=0.358	lr=8.19e-04 | 43.5%@S15  T=1.40s eta=16:51:46 | 63.9K token/s | 
[epoch_0]_17631  loss=3.483916 |g|=0.382	lr=8.18e-04 | 44.3%@S15  T=1.04s eta=12:30:16 | 64.7K token/s | 
[epoch_0]_17641  loss=3.491278 |g|=0.371	lr=8.18e-04 | 45.2%@S15  T=1.03s eta=12:26:17 | 65.4K token/s | 
[epoch_0]_17651  loss=3.518341 |g|=0.368	lr=8.18e-04 | 46.0%@S15  T=1.04s eta=12:33:09 | 66.1K token/s | 
[epoch_0]_17661  loss=3.509048 |g|=0.362	lr=8.18e-04 | 46.8%@S15  T=1.42s eta=17:07:01 | 65.7K token/s | 
[epoch_0]_17671  loss=3.507317 |g|=0.375	lr=8.18e-04 | 47.6%@S15  T=1.39s eta=16:44:49 | 65.3K token/s | 
[epoch_0]_17681  loss=3.482055 |g|=0.371	lr=8.17e-04 | 48.4%@S15  T=1.36s eta=16:25:03 | 65.1K token/s | 
[epoch_0]_17691  loss=3.529758 |g|=0.398	lr=8.17e-04 | 49.3%@S15  T=1.06s eta=12:45:13 | 65.7K token/s | 
[Fuyou] head="2" update algorithm=4 t=2.19s
[Section@17700] layer[18-24] tasks=15(nPassBack=0) last_loss=3.48089(0.0602729) N=(580,15372,14952 1769900)
[epoch_0]_17701  loss=3.531410 |g|=0.389	lr=8.17e-04 | 50.1%@S15  T=1.47s eta=17:40:17 | 65.2K token/s | 
[epoch_0]_17711  loss=3.513130 |g|=0.371	lr=8.17e-04 | 50.9%@S15  T=1.04s eta=12:29:24 | 65.9K token/s | 
[epoch_0]_17721  loss=3.603713 |g|=0.345	lr=8.17e-04 | 51.7%@S15  T=1.36s eta=16:23:36 | 65.6K token/s | 
[epoch_0]_17731  loss=3.536452 |g|=0.36	lr=8.16e-04 | 52.5%@S15  T=1.36s eta=16:21:06 | 65.3K token/s | 
[epoch_0]_17741  loss=3.509259 |g|=0.352	lr=8.16e-04 | 53.3%@S15  T=1.44s eta=17:22:17 | 64.9K token/s | 
[epoch_0]_17751  loss=3.493385 |g|=0.451	lr=8.16e-04 | 54.2%@S15  T=1.34s eta=16:09:24 | 64.7K token/s | 
[epoch_0]_17761  loss=3.468023 |g|=0.379	lr=8.16e-04 | 55.0%@S15  T=1.03s eta=12:25:46 | 65.4K token/s | 
[epoch_0]_17771  loss=3.590197 |g|=0.377	lr=8.16e-04 | 55.8%@S15  T=1.04s eta=12:30:37 | 66.1K token/s | 
[epoch_0]_17781  loss=3.523911 |g|=0.382	lr=8.15e-04 | 56.6%@S15  T=1.03s eta=12:22:13 | 66.8K token/s | 
[epoch_0]_17791  loss=3.526770 |g|=0.379	lr=8.15e-04 | 57.4%@S15  T=1.41s eta=16:53:45 | 66.3K token/s | 
[Fuyou] head="3" update algorithm=4 t=3.45s
[eval] 
	 Loss@"edu_fineweb1B"=3.496(0.0016) nBranch=1 nToken=4.01M best=3.4975(87) E2T=-0.00746 T=13.6069(0)s x=0
	#3.49585±0.1059 tps=295K(4.01408M) a=[3.3151,3.77387] T=13.6069(sec)
[Section@17800] layer[24-30] tasks=15(nPassBack=0) last_loss=3.50331(0.0184393) N=(580,15456,15036 1779900)
[epoch_0]_17801  loss=3.574988 |g|=0.342	lr=8.15e-04 | 58.3%@S15  T=4.84s eta=2d 10:04:33 | 63.9K token/s | 
[epoch_0]_17811  loss=3.536037 |g|=0.371	lr=8.15e-04 | 59.1%@S15  T=1.27s eta=15:16:06 | 63.9K token/s | 
[epoch_0]_17821  loss=3.477538 |g|=0.377	lr=8.15e-04 | 59.9%@S15  T=1.36s eta=16:19:04 | 63.7K token/s | 
[epoch_0]_17831  loss=3.560891 |g|=0.39	lr=8.14e-04 | 60.7%@S15  T=1.40s eta=16:45:13 | 63.5K token/s | 
[epoch_0]_17841  loss=3.453037 |g|=0.381	lr=8.14e-04 | 61.5%@S15  T=1.37s eta=16:24:49 | 63.3K token/s | 
[epoch_0]_17851  loss=3.560328 |g|=0.369	lr=8.14e-04 | 62.4%@S15  T=1.27s eta=15:12:18 | 63.3K token/s | 
[epoch_0]_17861  loss=3.447847 |g|=0.374	lr=8.14e-04 | 63.2%@S15  T=1.02s eta=12:15:07 | 64.2K token/s | 
[epoch_0]_17871  loss=3.553480 |g|=0.359	lr=8.14e-04 | 64.0%@S15  T=1.05s eta=12:33:51 | 64.9K token/s | 
[epoch_0]_17881  loss=3.484697 |g|=0.344	lr=8.13e-04 | 64.8%@S15  T=1.04s eta=12:30:39 | 65.6K token/s | 
[epoch_0]_17891  loss=3.428182 |g|=0.364	lr=8.13e-04 | 65.6%@S15  T=1.34s eta=16:04:16 | 65.3K token/s | 
[Fuyou] head="4" update algorithm=4 t=3.57s
[Section@17900] layer[30-36] tasks=15(nPassBack=0) last_loss=3.4979(0.0809717) N=(580,15540,15120 1789900)
[epoch_0]_17901  loss=3.604218 |g|=0.388	lr=8.13e-04 | 66.5%@S15  T=1.90s eta=22:46:39 | 64.2K token/s | 
[epoch_0]_17911  loss=3.461993 |g|=0.352	lr=8.13e-04 | 67.3%@S15  T=1.36s eta=16:18:05 | 64.0K token/s | 
[epoch_0]_17921  loss=3.512449 |g|=0.359	lr=8.13e-04 | 68.1%@S15  T=1.02s eta=12:16:12 | 64.8K token/s | 
[epoch_0]_17931  loss=3.479164 |g|=0.364	lr=8.12e-04 | 68.9%@S15  T=1.04s eta=12:25:14 | 65.5K token/s | 
[epoch_0]_17941  loss=3.503908 |g|=0.382	lr=8.12e-04 | 69.7%@S15  T=1.03s eta=12:20:30 | 66.2K token/s | 
[epoch_0]_17951  loss=3.479697 |g|=0.366	lr=8.12e-04 | 70.6%@S15  T=1.35s eta=16:09:03 | 66.0K token/s | 
[epoch_0]_17961  loss=3.503788 |g|=0.403	lr=8.12e-04 | 71.4%@S15  T=1.41s eta=16:50:28 | 65.6K token/s | 
[epoch_0]_17971  loss=3.510138 |g|=0.374	lr=8.12e-04 | 72.2%@S15  T=1.35s eta=16:12:01 | 65.3K token/s | 
[epoch_0]_17981  loss=3.473745 |g|=0.398	lr=8.11e-04 | 73.0%@S15  T=1.42s eta=17:02:28 | 64.9K token/s | 
[epoch_0]_17991  loss=3.519335 |g|=0.331	lr=8.11e-04 | 73.8%@S15  T=1.05s eta=12:30:28 | 65.6K token/s | 
[Fuyou] head="5" update algorithm=4 t=2.14s
[eval] 
	 Loss@"edu_fineweb1B"=3.494(0.0023) nBranch=1 nToken=4.01M best=3.4958(88) E2T=-0.0655 T=13.4678(0)s x=0
	#3.49352±0.1069 tps=298K(4.01408M) a=[3.30955,3.77497] T=13.4678(sec)
[Section@18000] layer[0-6] tasks=15(nPassBack=0) last_loss=3.55901(-0.125653) N=(580,15624,15204 1799900)
[epoch_0]_18001  loss=3.550867 |g|=0.344	lr=8.11e-04 | 74.6%@S15  T=4.61s eta=2d 07:04:03 | 63.2K token/s | 
[epoch_0]_18011  loss=3.484089 |g|=0.333	lr=8.11e-04 | 75.5%@S15  T=1.37s eta=16:20:17 | 63.0K token/s | 
[epoch_0]_18021  loss=3.515611 |g|=0.351	lr=8.11e-04 | 76.3%@S15  T=1.33s eta=15:52:11 | 63.0K token/s | 
[epoch_0]_18031  loss=3.482592 |g|=0.357	lr=8.10e-04 | 77.1%@S15  T=1.42s eta=16:55:50 | 62.7K token/s | 
[epoch_0]_18041  loss=3.590190 |g|=0.387	lr=8.10e-04 | 77.9%@S15  T=1.04s eta=12:25:37 | 63.5K token/s | 
[epoch_0]_18051  loss=3.490853 |g|=0.382	lr=8.10e-04 | 78.7%@S15  T=1.06s eta=12:36:56 | 64.2K token/s | 
[epoch_0]_18061  loss=3.448282 |g|=0.39	lr=8.10e-04 | 79.6%@S15  T=1.06s eta=12:38:28 | 64.9K token/s | 
[epoch_0]_18071  loss=3.511678 |g|=0.37	lr=8.10e-04 | 80.4%@S15  T=1.50s eta=17:51:30 | 64.4K token/s | 
[epoch_0]_18081  loss=3.499838 |g|=0.349	lr=8.09e-04 | 81.2%@S15  T=1.46s eta=17:27:58 | 63.9K token/s | 
[epoch_0]_18091  loss=3.498983 |g|=0.358	lr=8.09e-04 | 82.0%@S15  T=1.42s eta=16:58:12 | 63.6K token/s | 
[Fuyou] head="0" update algorithm=4 t=2.17s
[Section@18100] layer[6-12] tasks=15(nPassBack=0) last_loss=3.52445(-0.0481796) N=(580,15708,15288 1809900)
[epoch_0]_18101  loss=3.551686 |g|=0.36	lr=8.09e-04 | 82.8%@S15  T=1.47s eta=17:29:06 | 63.2K token/s | 
[epoch_0]_18111  loss=3.523521 |g|=0.349	lr=8.09e-04 | 83.7%@S15  T=1.04s eta=12:24:32 | 64.0K token/s | 
[epoch_0]_18121  loss=3.498044 |g|=0.363	lr=8.08e-04 | 84.5%@S15  T=1.06s eta=12:35:29 | 64.7K token/s | 
[epoch_0]_18131  loss=3.499607 |g|=0.344	lr=8.08e-04 | 85.3%@S15  T=1.35s eta=16:06:54 | 64.5K token/s | 
[epoch_0]_18141  loss=3.529860 |g|=0.372	lr=8.08e-04 | 86.1%@S15  T=1.36s eta=16:11:44 | 64.3K token/s | 
[epoch_0]_18151  loss=3.533815 |g|=0.399	lr=8.08e-04 | 86.9%@S15  T=1.39s eta=16:34:39 | 64.0K token/s | 
[epoch_0]_18161  loss=3.448555 |g|=0.368	lr=8.08e-04 | 87.8%@S15  T=1.35s eta=16:01:24 | 63.8K token/s | 
[epoch_0]_18171  loss=3.484418 |g|=0.342	lr=8.07e-04 | 88.6%@S15  T=1.06s eta=12:36:06 | 64.5K token/s | 
[epoch_0]_18181  loss=3.460941 |g|=0.367	lr=8.07e-04 | 89.4%@S15  T=1.07s eta=12:41:53 | 65.1K token/s | 
[epoch_0]_18191  loss=3.547452 |g|=0.371	lr=8.07e-04 | 90.2%@S15  T=1.06s eta=12:35:55 | 65.8K token/s | 
[Fuyou] head="1" update algorithm=4 t=3.56s
[eval] 
	 Loss@"edu_fineweb1B"=3.490(0.0037) nBranch=1 nToken=4.01M best=3.4935(89) E2T=-0.0899 T=13.7154(0)s x=0
	#3.48985±0.1060 tps=293K(4.01408M) a=[3.31446,3.77375] T=13.7154(sec)
[Section@18200] layer[12-18] tasks=15(nPassBack=0) last_loss=3.57974(-0.0332401) N=(580,15792,15372 1819900)
[epoch_0]_18201  loss=3.480926 |g|=0.347	lr=8.07e-04 | 91.0%@S15  T=4.88s eta=2d 10:01:35 | 63.3K token/s | 
[epoch_0]_18211  loss=3.503544 |g|=0.365	lr=8.07e-04 | 91.8%@S15  T=1.48s eta=17:35:30 | 62.9K token/s | 
[epoch_0]_18221  loss=3.509721 |g|=0.346	lr=8.06e-04 | 92.7%@S15  T=1.07s eta=12:44:25 | 63.6K token/s | 
[epoch_0]_18231  loss=3.504874 |g|=0.35	lr=8.06e-04 | 93.5%@S15  T=1.08s eta=12:50:17 | 64.2K token/s | 
[epoch_0]_18241  loss=3.556904 |g|=0.365	lr=8.06e-04 | 94.3%@S15  T=1.07s eta=12:44:13 | 64.8K token/s | 
[epoch_0]_18251  loss=3.468615 |g|=0.354	lr=8.06e-04 | 95.1%@S15  T=1.35s eta=16:01:08 | 64.6K token/s | 
[epoch_0]_18261  loss=3.454110 |g|=0.357	lr=8.06e-04 | 95.9%@S15  T=1.41s eta=16:44:56 | 64.3K token/s | 
[epoch_0]_18271  loss=3.548301 |g|=0.388	lr=8.05e-04 | 96.8%@S15  T=1.46s eta=17:18:16 | 63.9K token/s | 
[epoch_0]_18281  loss=3.553701 |g|=0.324	lr=8.05e-04 | 97.6%@S15  T=1.52s eta=18:00:42 | 63.4K token/s | 
[epoch_0]_18291  loss=3.509685 |g|=0.367	lr=8.05e-04 | 98.4%@S15  T=1.05s eta=12:30:08 | 64.1K token/s | 
[Fuyou] head="2" update algorithm=4 t=2.23s
[Section@18300] layer[18-24] tasks=15(nPassBack=0) last_loss=3.48946(-0.00857496) N=(580,15876,15456 1829900)
[epoch_0]_18301  loss=3.475388 |g|=0.422	lr=8.05e-04 | 99.2%@S15  T=1.57s eta=18:36:40 | 63.5K token/s | 
[epoch_0]_18310  loss=3.530997 |g|=0.392	lr=8.05e-04 | 100.0%@S15  T=1.02s eta=12:05:00 | 64.4K token/s | 
-------- End of shard_15@"./Datasets/edu_fineweb1B/edu_fineweb_train_000468.bin"-------- 
[shard-16]@"./Datasets/edu_fineweb1B/edu_fineweb_train_000469.bin": tokens=100(M) nShardSamples=1220(1562496) 
[epoch_0]_18311  loss=3.551727 |g|=0.346	lr=8.05e-04 | 0.0%@S16  T=1.26s eta=14:55:42 | 64.4K token/s | 
[epoch_0]_18321  loss=3.502059 |g|=0.387	lr=8.04e-04 | 0.9%@S16  T=1.13s eta=13:27:52 | 64.8K token/s | 
[epoch_0]_18331  loss=3.498378 |g|=0.351	lr=8.04e-04 | 1.7%@S16  T=1.35s eta=16:01:56 | 64.6K token/s | 
[epoch_0]_18341  loss=3.495803 |g|=0.365	lr=8.04e-04 | 2.5%@S16  T=1.34s eta=15:55:31 | 64.4K token/s | 
[epoch_0]_18351  loss=3.460707 |g|=0.368	lr=8.04e-04 | 3.3%@S16  T=1.43s eta=16:53:56 | 64.1K token/s | 
[epoch_0]_18361  loss=3.396444 |g|=0.338	lr=8.04e-04 | 4.1%@S16  T=1.36s eta=16:05:01 | 63.9K token/s | 
[epoch_0]_18371  loss=3.515086 |g|=0.394	lr=8.03e-04 | 5.0%@S16  T=1.39s eta=16:29:59 | 63.6K token/s | 
[epoch_0]_18381  loss=3.450288 |g|=0.343	lr=8.03e-04 | 5.8%@S16  T=1.04s eta=12:20:36 | 64.4K token/s | 
[epoch_0]_18391  loss=3.517842 |g|=0.341	lr=8.03e-04 | 6.6%@S16  T=1.04s eta=12:21:34 | 65.1K token/s | 
[Fuyou] head="3" update algorithm=4 t=2.11s
[eval] 
	 Loss@"edu_fineweb1B"=3.488(0.0021) nBranch=1 nToken=4.01M best=3.4899(90) E2T=0.022 T=13.5943(0)s x=0
	#3.4878±0.1062 tps=295K(4.01408M) a=[3.31082,3.76383] T=13.5943(sec)
[Section@18400] layer[24-30] tasks=15(nPassBack=0) last_loss=3.46585(0.0374577) N=(580,15960,15540 1839900)
[epoch_0]_18401  loss=3.424122 |g|=0.369	lr=8.03e-04 | 7.4%@S16  T=4.69s eta=2d 07:32:49 | 62.7K token/s | 
[epoch_0]_18411  loss=3.490291 |g|=0.374	lr=8.03e-04 | 8.2%@S16  T=1.50s eta=17:42:24 | 62.3K token/s | 
[epoch_0]_18421  loss=3.430889 |g|=0.424	lr=8.02e-04 | 9.1%@S16  T=1.46s eta=17:17:44 | 62.0K token/s | 
[epoch_0]_18431  loss=3.484977 |g|=0.362	lr=8.02e-04 | 9.9%@S16  T=1.10s eta=13:04:27 | 62.6K token/s | 
[epoch_0]_18441  loss=3.498206 |g|=0.357	lr=8.02e-04 | 10.7%@S16  T=1.03s eta=12:14:18 | 63.4K token/s | 
[epoch_0]_18451  loss=3.462522 |g|=0.341	lr=8.02e-04 | 11.5%@S16  T=1.01s eta=12:00:05 | 64.3K token/s | 
[epoch_0]_18461  loss=3.487635 |g|=0.402	lr=8.02e-04 | 12.3%@S16  T=1.03s eta=12:10:27 | 65.1K token/s | 
[epoch_0]_18471  loss=3.506991 |g|=0.351	lr=8.01e-04 | 13.1%@S16  T=1.41s eta=16:42:20 | 64.7K token/s | 
[epoch_0]_18481  loss=3.471951 |g|=0.358	lr=8.01e-04 | 14.0%@S16  T=1.34s eta=15:53:14 | 64.5K token/s | 
[epoch_0]_18491  loss=3.507812 |g|=0.34	lr=8.01e-04 | 14.8%@S16  T=1.35s eta=15:57:07 | 64.3K token/s | 
[Fuyou] head="4" update algorithm=4 t=2.27s
[Section@18500] layer[30-36] tasks=15(nPassBack=0) last_loss=3.45476(0.0431406) N=(580,16044,15624 1849900)
[epoch_0]_18501  loss=3.488424 |g|=0.356	lr=8.01e-04 | 15.6%@S16  T=1.34s eta=15:53:01 | 64.2K token/s | 
[epoch_0]_18511  loss=3.496946 |g|=0.364	lr=8.01e-04 | 16.4%@S16  T=1.02s eta=12:05:59 | 64.9K token/s | 
[epoch_0]_18521  loss=3.523304 |g|=0.364	lr=8.00e-04 | 17.2%@S16  T=1.04s eta=12:15:39 | 65.6K token/s | 
[epoch_0]_18531  loss=3.495256 |g|=0.398	lr=8.00e-04 | 18.1%@S16  T=1.36s eta=16:02:19 | 65.4K token/s | 
[epoch_0]_18541  loss=3.485589 |g|=0.367	lr=8.00e-04 | 18.9%@S16  T=1.36s eta=16:00:04 | 65.1K token/s | 
[epoch_0]_18551  loss=3.455361 |g|=0.387	lr=8.00e-04 | 19.7%@S16  T=1.37s eta=16:09:49 | 64.9K token/s | 
[epoch_0]_18561  loss=3.435316 |g|=0.356	lr=7.99e-04 | 20.5%@S16  T=1.38s eta=16:15:36 | 64.6K token/s | 
[epoch_0]_18571  loss=3.471890 |g|=0.381	lr=7.99e-04 | 21.3%@S16  T=1.35s eta=15:58:19 | 64.4K token/s | 
[epoch_0]_18581  loss=3.470878 |g|=0.376	lr=7.99e-04 | 22.2%@S16  T=1.49s eta=17:36:33 | 63.9K token/s | 
[epoch_0]_18591  loss=3.487439 |g|=0.367	lr=7.99e-04 | 23.0%@S16  T=1.07s eta=12:35:55 | 64.5K token/s | 
[Fuyou] head="5" update algorithm=4 t=2.21s
[eval] 
	 Loss@"edu_fineweb1B"=3.485(0.0025) nBranch=1 nToken=4.01M best=3.4878(91) E2T=-0.0789 T=13.4614(0)s x=0
	#3.4853±0.1066 tps=298K(4.01408M) a=[3.29857,3.75877] T=13.4614(sec)
[Section@18600] layer[0-6] tasks=15(nPassBack=0) last_loss=3.56424(-0.00523186) N=(580,16128,15708 1859900)
[epoch_0]_18601  loss=3.492667 |g|=0.357	lr=7.99e-04 | 23.8%@S16  T=4.35s eta=2d 03:13:41 | 62.3K token/s | 
[epoch_0]_18611  loss=3.441292 |g|=0.425	lr=7.98e-04 | 24.6%@S16  T=1.38s eta=16:13:41 | 62.1K token/s | 
[epoch_0]_18621  loss=3.496482 |g|=0.379	lr=7.98e-04 | 25.4%@S16  T=1.38s eta=16:13:56 | 62.0K token/s | 
[epoch_0]_18631  loss=3.406236 |g|=0.374	lr=7.98e-04 | 26.3%@S16  T=1.38s eta=16:13:06 | 61.9K token/s | 
[epoch_0]_18641  loss=3.441345 |g|=0.394	lr=7.98e-04 | 27.1%@S16  T=1.29s eta=15:13:24 | 61.9K token/s | 
[epoch_0]_18651  loss=3.514218 |g|=0.356	lr=7.98e-04 | 27.9%@S16  T=1.40s eta=16:25:36 | 61.8K token/s | 
[epoch_0]_18661  loss=3.499086 |g|=0.35	lr=7.97e-04 | 28.7%@S16  T=1.39s eta=16:20:15 | 61.6K token/s | 
[epoch_0]_18671  loss=3.460769 |g|=0.372	lr=7.97e-04 | 29.5%@S16  T=1.47s eta=17:17:13 | 61.3K token/s | 
[epoch_0]_18681  loss=3.537328 |g|=0.384	lr=7.97e-04 | 30.4%@S16  T=1.03s eta=12:07:08 | 62.3K token/s | 
[epoch_0]_18691  loss=3.440358 |g|=0.38	lr=7.97e-04 | 31.2%@S16  T=1.04s eta=12:11:27 | 63.1K token/s | 
[Fuyou] head="0" update algorithm=4 t=2.27s
[Section@18700] layer[6-12] tasks=15(nPassBack=0) last_loss=3.5029(0.0215569) N=(580,16212,15792 1869900)
[epoch_0]_18701  loss=3.455394 |g|=0.328	lr=7.97e-04 | 32.0%@S16  T=1.46s eta=17:12:25 | 62.7K token/s | 
[epoch_0]_18711  loss=3.518620 |g|=0.382	lr=7.96e-04 | 32.8%@S16  T=1.38s eta=16:15:12 | 62.6K token/s | 
[epoch_0]_18721  loss=3.513144 |g|=0.357	lr=7.96e-04 | 33.6%@S16  T=1.39s eta=16:23:29 | 62.4K token/s | 
[epoch_0]_18731  loss=3.596040 |g|=0.368	lr=7.96e-04 | 34.4%@S16  T=1.39s eta=16:22:03 | 62.2K token/s | 
[epoch_0]_18741  loss=3.457754 |g|=0.379	lr=7.96e-04 | 35.3%@S16  T=1.36s eta=16:02:05 | 62.1K token/s | 
[epoch_0]_18751  loss=3.430715 |g|=0.426	lr=7.96e-04 | 36.1%@S16  T=1.01s eta=11:48:41 | 63.1K token/s | 
[epoch_0]_18761  loss=3.474970 |g|=0.359	lr=7.95e-04 | 36.9%@S16  T=1.05s eta=12:17:41 | 63.8K token/s | 
[epoch_0]_18771  loss=3.501734 |g|=0.338	lr=7.95e-04 | 37.7%@S16  T=1.02s eta=11:55:34 | 64.7K token/s | 
[epoch_0]_18781  loss=3.449748 |g|=0.339	lr=7.95e-04 | 38.5%@S16  T=1.02s eta=11:55:03 | 65.5K token/s | 
[epoch_0]_18791  loss=3.517132 |g|=0.37	lr=7.95e-04 | 39.4%@S16  T=1.01s eta=11:51:47 | 66.2K token/s | 
[Fuyou] head="1" update algorithm=4 t=2.11s
[eval] 
	 Loss@"edu_fineweb1B"=3.482(0.0028) nBranch=1 nToken=4.01M best=3.4853(92) E2T=-0.00884 T=13.4821(0)s x=0
	#3.48246±0.1069 tps=298K(4.01408M) a=[3.29925,3.76355] T=13.4821(sec)
[Section@18800] layer[12-18] tasks=15(nPassBack=0) last_loss=3.4913(0.0884378) N=(580,16296,15876 1879900)
[epoch_0]_18801  loss=3.490402 |g|=0.33	lr=7.94e-04 | 40.2%@S16  T=4.15s eta=2d 00:39:40 | 63.9K token/s | 
[epoch_0]_18811  loss=3.482111 |g|=0.37	lr=7.94e-04 | 41.0%@S16  T=1.02s eta=11:57:18 | 64.7K token/s | 
[epoch_0]_18821  loss=3.403554 |g|=0.366	lr=7.94e-04 | 41.8%@S16  T=1.03s eta=12:02:43 | 65.5K token/s | 
[epoch_0]_18831  loss=3.521834 |g|=0.332	lr=7.94e-04 | 42.6%@S16  T=1.01s eta=11:50:00 | 66.3K token/s | 
[epoch_0]_18841  loss=3.487891 |g|=0.387	lr=7.94e-04 | 43.5%@S16  T=1.02s eta=11:54:49 | 67.0K token/s | 
[epoch_0]_18851  loss=3.462811 |g|=0.376	lr=7.93e-04 | 44.3%@S16  T=1.00s eta=11:46:30 | 67.7K token/s | 
[epoch_0]_18861  loss=3.486655 |g|=0.348	lr=7.93e-04 | 45.1%@S16  T=1.01s eta=11:51:38 | 68.4K token/s | 
[epoch_0]_18871  loss=3.528025 |g|=0.331	lr=7.93e-04 | 45.9%@S16  T=1.03s eta=12:04:10 | 68.9K token/s | 
[epoch_0]_18881  loss=3.541897 |g|=0.372	lr=7.93e-04 | 46.7%@S16  T=1.02s eta=11:53:41 | 69.5K token/s | 
[epoch_0]_18891  loss=3.496956 |g|=0.368	lr=7.93e-04 | 47.6%@S16  T=1.02s eta=11:53:04 | 70.1K token/s | 
[Fuyou] head="2" update algorithm=4 t=2.10s
[Section@18900] layer[18-24] tasks=15(nPassBack=0) last_loss=3.53114(-0.0416803) N=(580,16380,15960 1889900)
[epoch_0]_18901  loss=3.444840 |g|=0.368	lr=7.92e-04 | 48.4%@S16  T=1.29s eta=15:04:48 | 69.7K token/s | 
[epoch_0]_18911  loss=3.467563 |g|=0.328	lr=7.92e-04 | 49.2%@S16  T=1.00s eta=11:43:24 | 70.3K token/s | 
[epoch_0]_18921  loss=3.383495 |g|=0.362	lr=7.92e-04 | 50.0%@S16  T=1.01s eta=11:48:58 | 70.9K token/s | 
[epoch_0]_18931  loss=3.504190 |g|=0.363	lr=7.92e-04 | 50.8%@S16  T=1.01s eta=11:48:57 | 71.4K token/s | 
[epoch_0]_18941  loss=3.447378 |g|=0.343	lr=7.92e-04 | 51.7%@S16  T=1.01s eta=11:49:48 | 71.9K token/s | 
[epoch_0]_18951  loss=3.434574 |g|=0.369	lr=7.91e-04 | 52.5%@S16  T=1.00s eta=11:44:45 | 72.4K token/s | 
[epoch_0]_18961  loss=3.466612 |g|=0.381	lr=7.91e-04 | 53.3%@S16  T=1.01s eta=11:50:57 | 72.8K token/s | 
[epoch_0]_18971  loss=3.456406 |g|=0.339	lr=7.91e-04 | 54.1%@S16  T=1.01s eta=11:46:52 | 73.2K token/s | 
[epoch_0]_18981  loss=3.483596 |g|=0.37	lr=7.91e-04 | 54.9%@S16  T=1.01s eta=11:46:49 | 73.6K token/s | 
[epoch_0]_18991  loss=3.525876 |g|=0.386	lr=7.91e-04 | 55.7%@S16  T=1.02s eta=11:54:40 | 73.9K token/s | 
[Fuyou] head="3" update algorithm=4 t=2.04s
[eval] 
	 Loss@"edu_fineweb1B"=3.481(0.0015) nBranch=1 nToken=4.01M best=3.4825(93) E2T=-0.00408 T=13.4942(0)s x=0
	#3.48097±0.1062 tps=297K(4.01408M) a=[3.29543,3.75579] T=13.4942(sec)
[Section@19000] layer[24-30] tasks=15(nPassBack=0) last_loss=3.48505(-0.0191996) N=(580,16464,16044 1899900)
[epoch_0]_19001  loss=3.526410 |g|=0.384	lr=7.90e-04 | 56.6%@S16  T=4.15s eta=2d 00:25:25 | 71.2K token/s | 
[epoch_0]_19011  loss=3.459677 |g|=0.356	lr=7.90e-04 | 57.4%@S16  T=1.01s eta=11:50:36 | 71.7K token/s | 
[epoch_0]_19021  loss=3.431978 |g|=0.352	lr=7.90e-04 | 58.2%@S16  T=1.03s eta=12:03:27 | 72.1K token/s | 
[epoch_0]_19031  loss=3.566128 |g|=0.386	lr=7.90e-04 | 59.0%@S16  T=1.02s eta=11:51:17 | 72.5K token/s | 
[epoch_0]_19041  loss=3.465067 |g|=0.376	lr=7.89e-04 | 59.8%@S16  T=1.02s eta=11:51:38 | 72.9K token/s | 
[epoch_0]_19051  loss=3.544066 |g|=0.37	lr=7.89e-04 | 60.7%@S16  T=1.02s eta=11:52:33 | 73.3K token/s | 
[epoch_0]_19061  loss=3.537416 |g|=0.37	lr=7.89e-04 | 61.5%@S16  T=1.02s eta=11:51:31 | 73.7K token/s | 
[epoch_0]_19071  loss=3.434816 |g|=0.37	lr=7.89e-04 | 62.3%@S16  T=1.01s eta=11:45:24 | 74.0K token/s | 
[epoch_0]_19081  loss=3.445215 |g|=0.36	lr=7.89e-04 | 63.1%@S16  T=1.01s eta=11:47:58 | 74.4K token/s | 
[epoch_0]_19091  loss=3.447568 |g|=0.36	lr=7.88e-04 | 63.9%@S16  T=1.02s eta=11:52:31 | 74.7K token/s | 
[Fuyou] head="4" update algorithm=4 t=2.10s
[Section@19100] layer[30-36] tasks=15(nPassBack=0) last_loss=3.46081(-0.00604844) N=(580,16548,16128 1909900)
[epoch_0]_19101  loss=3.444003 |g|=0.359	lr=7.88e-04 | 64.8%@S16  T=1.39s eta=16:11:23 | 73.9K token/s | 
[epoch_0]_19111  loss=3.463930 |g|=0.335	lr=7.88e-04 | 65.6%@S16  T=1.02s eta=11:50:13 | 74.2K token/s | 
[epoch_0]_19121  loss=3.490792 |g|=0.349	lr=7.88e-04 | 66.4%@S16  T=1.01s eta=11:46:15 | 74.6K token/s | 
[epoch_0]_19131  loss=3.501966 |g|=0.372	lr=7.88e-04 | 67.2%@S16  T=1.02s eta=11:55:24 | 74.8K token/s | 
[epoch_0]_19141  loss=3.464385 |g|=0.371	lr=7.87e-04 | 68.0%@S16  T=1.02s eta=11:52:09 | 75.1K token/s | 
[epoch_0]_19151  loss=3.439114 |g|=0.369	lr=7.87e-04 | 68.9%@S16  T=1.02s eta=11:51:13 | 75.4K token/s | 
[epoch_0]_19161  loss=3.512498 |g|=0.371	lr=7.87e-04 | 69.7%@S16  T=1.03s eta=11:56:07 | 75.6K token/s | 
[epoch_0]_19171  loss=3.489134 |g|=0.389	lr=7.87e-04 | 70.5%@S16  T=1.03s eta=11:57:14 | 75.8K token/s | 
[epoch_0]_19181  loss=3.451779 |g|=0.359	lr=7.86e-04 | 71.3%@S16  T=1.05s eta=12:14:11 | 75.9K token/s | 
[epoch_0]_19191  loss=3.537645 |g|=0.361	lr=7.86e-04 | 72.1%@S16  T=1.05s eta=12:15:06 | 76.0K token/s | 
[Fuyou] head="5" update algorithm=4 t=2.08s
[eval] 
	 Loss@"edu_fineweb1B"=3.477(0.0041) nBranch=1 nToken=4.01M best=3.4810(94) E2T=-0.015 T=13.4942(0)s x=0
	#3.47686±0.1056 tps=297K(4.01408M) a=[3.29371,3.75285] T=13.4942(sec)
[Section@19200] layer[0-6] tasks=15(nPassBack=0) last_loss=3.49189(0.0723445) N=(580,16632,16212 1919900)
[epoch_0]_19201  loss=3.475462 |g|=0.351	lr=7.86e-04 | 73.0%@S16  T=4.14s eta=2d 00:03:47 | 73.2K token/s | 
[epoch_0]_19211  loss=3.533710 |g|=0.39	lr=7.86e-04 | 73.8%@S16  T=1.04s eta=12:04:15 | 73.5K token/s | 
[epoch_0]_19221  loss=3.452463 |g|=0.385	lr=7.86e-04 | 74.6%@S16  T=1.05s eta=12:09:06 | 73.7K token/s | 
[epoch_0]_19231  loss=3.481211 |g|=0.384	lr=7.85e-04 | 75.4%@S16  T=1.02s eta=11:48:42 | 74.1K token/s | 
[epoch_0]_19241  loss=3.432346 |g|=0.385	lr=7.85e-04 | 76.2%@S16  T=1.01s eta=11:46:09 | 74.4K token/s | 
[epoch_0]_19251  loss=3.466154 |g|=0.342	lr=7.85e-04 | 77.0%@S16  T=1.02s eta=11:53:42 | 74.7K token/s | 
[epoch_0]_19261  loss=3.497481 |g|=0.361	lr=7.85e-04 | 77.9%@S16  T=1.02s eta=11:51:13 | 74.9K token/s | 
[epoch_0]_19271  loss=3.532618 |g|=0.353	lr=7.85e-04 | 78.7%@S16  T=1.03s eta=11:56:12 | 75.2K token/s | 
[epoch_0]_19281  loss=3.428888 |g|=0.367	lr=7.84e-04 | 79.5%@S16  T=1.02s eta=11:48:56 | 75.4K token/s | 
[epoch_0]_19291  loss=3.531437 |g|=0.398	lr=7.84e-04 | 80.3%@S16  T=1.02s eta=11:52:22 | 75.7K token/s | 
[Fuyou] head="0" update algorithm=4 t=2.08s
[Section@19300] layer[6-12] tasks=15(nPassBack=0) last_loss=3.44335(0.05955) N=(580,16716,16296 1929900)
[epoch_0]_19301  loss=3.480073 |g|=0.347	lr=7.84e-04 | 81.1%@S16  T=1.30s eta=15:07:22 | 75.0K token/s | 
[epoch_0]_19311  loss=3.434697 |g|=0.35	lr=7.84e-04 | 82.0%@S16  T=1.01s eta=11:45:16 | 75.3K token/s | 
[epoch_0]_19321  loss=3.474057 |g|=0.37	lr=7.84e-04 | 82.8%@S16  T=1.01s eta=11:43:34 | 75.6K token/s | 
[epoch_0]_19331  loss=3.427520 |g|=0.353	lr=7.83e-04 | 83.6%@S16  T=1.02s eta=11:50:21 | 75.8K token/s | 
[epoch_0]_19341  loss=3.522728 |g|=0.338	lr=7.83e-04 | 84.4%@S16  T=1.01s eta=11:45:14 | 76.1K token/s | 
[epoch_0]_19351  loss=3.477764 |g|=0.38	lr=7.83e-04 | 85.2%@S16  T=1.01s eta=11:43:29 | 76.3K token/s | 
[epoch_0]_19361  loss=3.495292 |g|=0.363	lr=7.83e-04 | 86.1%@S16  T=1.01s eta=11:40:07 | 76.6K token/s | 
[epoch_0]_19371  loss=3.502849 |g|=0.356	lr=7.82e-04 | 86.9%@S16  T=1.01s eta=11:41:03 | 76.8K token/s | 
[epoch_0]_19381  loss=3.449360 |g|=0.357	lr=7.82e-04 | 87.7%@S16  T=1.02s eta=11:46:51 | 77.0K token/s | 
[epoch_0]_19391  loss=3.495577 |g|=0.343	lr=7.82e-04 | 88.5%@S16  T=1.01s eta=11:44:00 | 77.2K token/s | 
[Fuyou] head="1" update algorithm=4 t=2.15s
[eval] 
	 Loss@"edu_fineweb1B"=3.477(-0.00035) nBranch=1 nToken=4.01M best=3.4769(95) E2T=-0.0185 T=13.5028(0)s x=0
	#3.47721±0.1063 tps=297K(4.01408M) a=[3.28892,3.75625] T=13.5028(sec)
[Section@19400] layer[12-18] tasks=15(nPassBack=0) last_loss=3.49568(-0.00437498) N=(580,16800,16380 1939900)
[epoch_0]_19401  loss=3.408388 |g|=0.378	lr=7.82e-04 | 89.3%@S16  T=4.17s eta=2d 00:16:42 | 74.3K token/s | 
[epoch_0]_19411  loss=3.492704 |g|=0.393	lr=7.82e-04 | 90.2%@S16  T=1.03s eta=11:55:22 | 74.5K token/s | 
[epoch_0]_19421  loss=3.477759 |g|=0.362	lr=7.81e-04 | 91.0%@S16  T=1.02s eta=11:45:32 | 74.8K token/s | 
[epoch_0]_19431  loss=3.498985 |g|=0.363	lr=7.81e-04 | 91.8%@S16  T=1.02s eta=11:49:40 | 75.1K token/s | 
[epoch_0]_19441  loss=3.471554 |g|=0.357	lr=7.81e-04 | 92.6%@S16  T=1.02s eta=11:49:45 | 75.3K token/s | 
[epoch_0]_19451  loss=3.396011 |g|=0.378	lr=7.81e-04 | 93.4%@S16  T=1.01s eta=11:41:48 | 75.6K token/s | 
[epoch_0]_19461  loss=3.408087 |g|=0.364	lr=7.81e-04 | 94.3%@S16  T=1.01s eta=11:40:31 | 75.9K token/s | 
[epoch_0]_19471  loss=3.453961 |g|=0.391	lr=7.80e-04 | 95.1%@S16  T=1.01s eta=11:36:18 | 76.2K token/s | 
[epoch_0]_19481  loss=3.455348 |g|=0.37	lr=7.80e-04 | 95.9%@S16  T=1.02s eta=11:45:32 | 76.4K token/s | 
[epoch_0]_19491  loss=3.462948 |g|=0.348	lr=7.80e-04 | 96.7%@S16  T=1.01s eta=11:40:38 | 76.6K token/s | 
[Fuyou] head="2" update algorithm=4 t=2.02s
[Section@19500] layer[18-24] tasks=15(nPassBack=0) last_loss=3.44838(0.0827689) N=(580,16884,16464 1949900)
[epoch_0]_19501  loss=3.430808 |g|=0.374	lr=7.80e-04 | 97.5%@S16  T=1.45s eta=16:46:23 | 75.6K token/s | 
[epoch_0]_19511  loss=3.544793 |g|=0.377	lr=7.79e-04 | 98.3%@S16  T=1.01s eta=11:39:36 | 75.9K token/s | 
[epoch_0]_19521  loss=3.468278 |g|=0.354	lr=7.79e-04 | 99.2%@S16  T=1.02s eta=11:42:55 | 76.1K token/s | 
[epoch_0]_19531  loss=3.412335 |g|=0.368	lr=7.79e-04 | 100.0%@S16  T=1.05s eta=12:03:07 | 76.2K token/s | 
-------- End of shard_16@"./Datasets/edu_fineweb1B/edu_fineweb_train_000469.bin"-------- 
[shard-17]@"./Datasets/edu_fineweb1B/edu_fineweb_train_000470.bin": tokens=100(M) nShardSamples=1220(1660152) 
[epoch_0]_19541  loss=3.560781 |g|=0.34	lr=7.79e-04 | 0.8%@S17  T=1.02s eta=11:45:43 | 76.4K token/s | 
[epoch_0]_19551  loss=3.471558 |g|=0.383	lr=7.79e-04 | 1.6%@S17  T=1.01s eta=11:39:40 | 76.7K token/s | 
[epoch_0]_19561  loss=3.527566 |g|=0.364	lr=7.78e-04 | 2.4%@S17  T=1.03s eta=11:55:04 | 76.8K token/s | 
[epoch_0]_19571  loss=3.425973 |g|=0.4	lr=7.78e-04 | 3.3%@S17  T=1.01s eta=11:34:50 | 77.0K token/s | 
[epoch_0]_19581  loss=3.430278 |g|=0.383	lr=7.78e-04 | 4.1%@S17  T=1.01s eta=11:38:37 | 77.2K token/s | 
[epoch_0]_19591  loss=3.471690 |g|=0.369	lr=7.78e-04 | 4.9%@S17  T=1.02s eta=11:42:45 | 77.4K token/s | 
[Fuyou] head="3" update algorithm=4 t=2.06s
[eval] 
	 Loss@"edu_fineweb1B"=3.473(0.0039) nBranch=1 nToken=4.01M best=3.4772(96) E2T=-0.0483 T=13.5072(0)s x=0
	#3.47327±0.1060 tps=297K(4.01408M) a=[3.29109,3.75333] T=13.5072(sec)
[Section@19600] layer[24-30] tasks=15(nPassBack=0) last_loss=3.52161(-0.0365567) N=(580,16968,16548 1959900)
[epoch_0]_19601  loss=3.568977 |g|=0.347	lr=7.78e-04 | 5.7%@S17  T=4.13s eta=1d 23:35:08 | 74.5K token/s | 
[epoch_0]_19611  loss=3.518334 |g|=0.349	lr=7.77e-04 | 6.5%@S17  T=1.16s eta=13:22:25 | 74.3K token/s | 
[epoch_0]_19621  loss=3.525707 |g|=0.338	lr=7.77e-04 | 7.4%@S17  T=1.02s eta=11:47:26 | 74.6K token/s | 
[epoch_0]_19631  loss=3.440150 |g|=0.35	lr=7.77e-04 | 8.2%@S17  T=1.02s eta=11:40:34 | 74.9K token/s | 
[epoch_0]_19641  loss=3.510625 |g|=0.336	lr=7.77e-04 | 9.0%@S17  T=1.00s eta=11:32:06 | 75.2K token/s | 
[epoch_0]_19651  loss=3.453414 |g|=0.355	lr=7.76e-04 | 9.8%@S17  T=1.02s eta=11:41:40 | 75.5K token/s | 
[epoch_0]_19661  loss=3.522733 |g|=0.355	lr=7.76e-04 | 10.6%@S17  T=1.01s eta=11:35:31 | 75.8K token/s | 
[epoch_0]_19671  loss=3.522498 |g|=0.378	lr=7.76e-04 | 11.5%@S17  T=1.05s eta=12:06:34 | 75.9K token/s | 
[epoch_0]_19681  loss=3.469452 |g|=0.329	lr=7.76e-04 | 12.3%@S17  T=1.02s eta=11:43:21 | 76.1K token/s | 
[epoch_0]_19691  loss=3.456260 |g|=0.386	lr=7.76e-04 | 13.1%@S17  T=1.01s eta=11:38:54 | 76.3K token/s | 
[Fuyou] head="4" update algorithm=4 t=2.10s
[Section@19700] layer[30-36] tasks=15(nPassBack=0) last_loss=3.5308(-0.0699887) N=(580,17052,16632 1969900)
[epoch_0]_19701  loss=3.450162 |g|=0.316	lr=7.75e-04 | 13.9%@S17  T=1.52s eta=17:25:57 | 75.2K token/s | 
[epoch_0]_19711  loss=3.453918 |g|=0.398	lr=7.75e-04 | 14.7%@S17  T=1.01s eta=11:36:07 | 75.5K token/s | 
[epoch_0]_19721  loss=3.447883 |g|=0.338	lr=7.75e-04 | 15.5%@S17  T=1.01s eta=11:33:11 | 75.8K token/s | 
[epoch_0]_19731  loss=3.484618 |g|=0.394	lr=7.75e-04 | 16.4%@S17  T=1.05s eta=12:02:21 | 75.9K token/s | 
[epoch_0]_19741  loss=3.475103 |g|=0.361	lr=7.75e-04 | 17.2%@S17  T=1.02s eta=11:41:44 | 76.1K token/s | 
[epoch_0]_19751  loss=3.499909 |g|=0.358	lr=7.74e-04 | 18.0%@S17  T=1.03s eta=11:50:29 | 76.3K token/s | 
[epoch_0]_19761  loss=3.440365 |g|=0.36	lr=7.74e-04 | 18.8%@S17  T=1.02s eta=11:40:39 | 76.5K token/s | 
[epoch_0]_19771  loss=3.461546 |g|=0.354	lr=7.74e-04 | 19.6%@S17  T=1.08s eta=12:19:33 | 76.5K token/s | 
[epoch_0]_19781  loss=3.493414 |g|=0.35	lr=7.74e-04 | 20.5%@S17  T=1.01s eta=11:36:45 | 76.7K token/s | 
[epoch_0]_19791  loss=3.360596 |g|=0.385	lr=7.73e-04 | 21.3%@S17  T=1.01s eta=11:32:50 | 76.9K token/s | 
[Fuyou] head="5" update algorithm=4 t=2.09s
[eval] 
	 Loss@"edu_fineweb1B"=3.473(-0.00012) nBranch=1 nToken=4.01M best=3.4733(97) E2T=0.0103 T=13.4898(0)s x=0
	#3.47339±0.1063 tps=298K(4.01408M) a=[3.29836,3.7543] T=13.4898(sec)
[Section@19800] layer[0-6] tasks=15(nPassBack=0) last_loss=3.46308(0.0288172) N=(580,17136,16716 1979900)
[epoch_0]_19801  loss=3.394809 |g|=0.346	lr=7.73e-04 | 22.1%@S17  T=4.16s eta=1d 23:41:28 | 74.1K token/s | 
[epoch_0]_19811  loss=3.459096 |g|=0.375	lr=7.73e-04 | 22.9%@S17  T=1.01s eta=11:30:53 | 74.4K token/s | 
[epoch_0]_19821  loss=3.444956 |g|=0.365	lr=7.73e-04 | 23.7%@S17  T=1.02s eta=11:40:09 | 74.7K token/s | 
[epoch_0]_19831  loss=3.530078 |g|=0.384	lr=7.73e-04 | 24.6%@S17  T=1.04s eta=11:56:11 | 74.9K token/s | 
[epoch_0]_19841  loss=3.394819 |g|=0.352	lr=7.72e-04 | 25.4%@S17  T=1.01s eta=11:31:37 | 75.2K token/s | 
[epoch_0]_19851  loss=3.500414 |g|=0.368	lr=7.72e-04 | 26.2%@S17  T=1.01s eta=11:32:02 | 75.5K token/s | 
[epoch_0]_19861  loss=3.459066 |g|=0.367	lr=7.72e-04 | 27.0%@S17  T=1.03s eta=11:45:43 | 75.7K token/s | 
[epoch_0]_19871  loss=3.389347 |g|=0.347	lr=7.72e-04 | 27.8%@S17  T=1.01s eta=11:35:40 | 76.0K token/s | 
[epoch_0]_19881  loss=3.411941 |g|=0.35	lr=7.71e-04 | 28.7%@S17  T=1.01s eta=11:31:54 | 76.3K token/s | 
[epoch_0]_19891  loss=3.493223 |g|=0.365	lr=7.71e-04 | 29.5%@S17  T=1.02s eta=11:37:38 | 76.5K token/s | 
[Fuyou] head="0" update algorithm=4 t=2.07s
[Section@19900] layer[6-12] tasks=15(nPassBack=0) last_loss=3.39413(0.0492129) N=(580,17220,16800 1989900)
[epoch_0]_19901  loss=3.560982 |g|=0.381	lr=7.71e-04 | 30.3%@S17  T=1.30s eta=14:48:55 | 75.8K token/s | 
[epoch_0]_19911  loss=3.550501 |g|=0.366	lr=7.71e-04 | 31.1%@S17  T=1.01s eta=11:29:40 | 76.1K token/s | 
[epoch_0]_19921  loss=3.505776 |g|=0.362	lr=7.71e-04 | 31.9%@S17  T=1.02s eta=11:36:32 | 76.3K token/s | 
[epoch_0]_19931  loss=3.420169 |g|=0.366	lr=7.70e-04 | 32.8%@S17  T=1.02s eta=11:40:52 | 76.5K token/s | 
[epoch_0]_19941  loss=3.463026 |g|=0.369	lr=7.70e-04 | 33.6%@S17  T=1.02s eta=11:35:22 | 76.7K token/s | 
[epoch_0]_19951  loss=3.525007 |g|=0.353	lr=7.70e-04 | 34.4%@S17  T=1.02s eta=11:36:01 | 76.9K token/s | 
[epoch_0]_19961  loss=3.495946 |g|=0.356	lr=7.70e-04 | 35.2%@S17  T=1.02s eta=11:38:49 | 77.1K token/s | 
[epoch_0]_19971  loss=3.419161 |g|=0.384	lr=7.70e-04 | 36.0%@S17  T=1.04s eta=11:50:01 | 77.2K token/s | 
[epoch_0]_19981  loss=3.413008 |g|=0.378	lr=7.69e-04 | 36.8%@S17  T=1.01s eta=11:34:20 | 77.3K token/s | 
[epoch_0]_19991  loss=3.435051 |g|=0.357	lr=7.69e-04 | 37.7%@S17  T=1.02s eta=11:37:35 | 77.5K token/s | 
[Fuyou] head="1" update algorithm=4 t=2.11s
[eval] 
	 Loss@"edu_fineweb1B"=3.473(0.00059) nBranch=1 nToken=4.01M best=3.4734(98) E2T=-0.000794 T=13.4933(0)s x=0
	#3.47281±0.1071 tps=297K(4.01408M) a=[3.28852,3.75729] T=13.4933(sec)
[Section@20000] layer[12-18] tasks=15(nPassBack=0) last_loss=3.4736(0.0220785) N=(580,17304,16884 1999900)
[epoch_0]_20001  loss=3.485739 |g|=0.372	lr=7.69e-04 | 38.5%@S17  T=4.15s eta=1d 23:18:21 | 74.6K token/s | 
[epoch_0]_20011  loss=3.423310 |g|=0.337	lr=7.69e-04 | 39.3%@S17  T=1.05s eta=11:54:46 | 74.8K token/s | 
[epoch_0]_20021  loss=3.371084 |g|=0.359	lr=7.68e-04 | 40.1%@S17  T=1.03s eta=11:43:48 | 75.0K token/s | 
[epoch_0]_20031  loss=3.459968 |g|=0.382	lr=7.68e-04 | 40.9%@S17  T=1.03s eta=11:41:28 | 75.3K token/s | 
[epoch_0]_20041  loss=3.483037 |g|=0.367	lr=7.68e-04 | 41.8%@S17  T=1.01s eta=11:31:06 | 75.6K token/s | 
[epoch_0]_20051  loss=3.418673 |g|=0.374	lr=7.68e-04 | 42.6%@S17  T=1.01s eta=11:31:32 | 75.8K token/s | 
[epoch_0]_20061  loss=3.470899 |g|=0.356	lr=7.68e-04 | 43.4%@S17  T=1.01s eta=11:32:52 | 76.1K token/s | 
[epoch_0]_20071  loss=3.423104 |g|=0.36	lr=7.67e-04 | 44.2%@S17  T=1.02s eta=11:35:29 | 76.3K token/s | 
[epoch_0]_20081  loss=3.540640 |g|=0.393	lr=7.67e-04 | 45.0%@S17  T=1.04s eta=11:48:42 | 76.4K token/s | 
[epoch_0]_20091  loss=3.453406 |g|=0.359	lr=7.67e-04 | 45.9%@S17  T=1.01s eta=11:31:21 | 76.6K token/s | 
[Fuyou] head="2" update algorithm=4 t=2.10s
[Section@20100] layer[18-24] tasks=15(nPassBack=0) last_loss=3.49966(-0.05128) N=(580,17388,16968 2009900)
[epoch_0]_20101  loss=3.384849 |g|=0.331	lr=7.67e-04 | 46.7%@S17  T=1.30s eta=14:50:06 | 75.9K token/s | 
[epoch_0]_20111  loss=3.478230 |g|=0.381	lr=7.66e-04 | 47.5%@S17  T=1.02s eta=11:35:00 | 76.2K token/s | 
[epoch_0]_20121  loss=3.477025 |g|=0.376	lr=7.66e-04 | 48.3%@S17  T=1.02s eta=11:33:38 | 76.4K token/s | 
[epoch_0]_20131  loss=3.469377 |g|=0.359	lr=7.66e-04 | 49.1%@S17  T=1.02s eta=11:31:59 | 76.6K token/s | 
[epoch_0]_20141  loss=3.462893 |g|=0.343	lr=7.66e-04 | 50.0%@S17  T=1.02s eta=11:33:51 | 76.8K token/s | 
[epoch_0]_20151  loss=3.459603 |g|=0.403	lr=7.66e-04 | 50.8%@S17  T=1.01s eta=11:27:52 | 77.0K token/s | 
[epoch_0]_20161  loss=3.465328 |g|=0.365	lr=7.65e-04 | 51.6%@S17  T=1.01s eta=11:27:19 | 77.2K token/s | 
[epoch_0]_20171  loss=3.427035 |g|=0.344	lr=7.65e-04 | 52.4%@S17  T=1.02s eta=11:32:59 | 77.4K token/s | 
[epoch_0]_20181  loss=3.451952 |g|=0.338	lr=7.65e-04 | 53.2%@S17  T=1.03s eta=11:40:41 | 77.5K token/s | 
[epoch_0]_20191  loss=3.411464 |g|=0.352	lr=7.65e-04 | 54.1%@S17  T=1.02s eta=11:35:27 | 77.6K token/s | 
[Fuyou] head="3" update algorithm=4 t=2.07s
[eval] 
	 Loss@"edu_fineweb1B"=3.468(0.0052) nBranch=1 nToken=4.01M best=3.4728(99) E2T=0.0131 T=13.503(0)s x=0
	#3.46764±0.1069 tps=297K(4.01408M) a=[3.28592,3.75394] T=13.503(sec)
[Section@20200] layer[24-30] tasks=15(nPassBack=0) last_loss=3.45455(0.0670617) N=(580,17472,17052 2019900)
[epoch_0]_20201  loss=3.491275 |g|=0.346	lr=7.65e-04 | 54.9%@S17  T=4.14s eta=1d 22:54:22 | 74.7K token/s | 
[epoch_0]_20211  loss=3.464544 |g|=0.373	lr=7.64e-04 | 55.7%@S17  T=1.01s eta=11:24:09 | 75.1K token/s | 
[epoch_0]_20221  loss=3.401935 |g|=0.355	lr=7.64e-04 | 56.5%@S17  T=1.05s eta=11:53:59 | 75.2K token/s | 
[epoch_0]_20231  loss=3.462190 |g|=0.331	lr=7.64e-04 | 57.3%@S17  T=1.01s eta=11:29:55 | 75.5K token/s | 
[epoch_0]_20241  loss=3.479158 |g|=0.348	lr=7.64e-04 | 58.1%@S17  T=1.01s eta=11:30:04 | 75.8K token/s | 
[epoch_0]_20251  loss=3.489283 |g|=0.365	lr=7.63e-04 | 59.0%@S17  T=1.02s eta=11:35:25 | 76.0K token/s | 
[epoch_0]_20261  loss=3.511495 |g|=0.375	lr=7.63e-04 | 59.8%@S17  T=1.05s eta=11:55:53 | 76.1K token/s | 
[epoch_0]_20271  loss=3.478815 |g|=0.366	lr=7.63e-04 | 60.6%@S17  T=1.02s eta=11:30:26 | 76.3K token/s | 
[epoch_0]_20281  loss=3.449778 |g|=0.359	lr=7.63e-04 | 61.4%@S17  T=1.02s eta=11:32:55 | 76.5K token/s | 
[epoch_0]_20291  loss=3.360147 |g|=0.348	lr=7.63e-04 | 62.2%@S17  T=1.03s eta=11:38:42 | 76.7K token/s | 
[Fuyou] head="4" update algorithm=4 t=2.07s
[Section@20300] layer[30-36] tasks=15(nPassBack=0) last_loss=3.47887(0.0519316) N=(580,17556,17136 2029900)
[epoch_0]_20301  loss=3.438144 |g|=0.374	lr=7.62e-04 | 63.1%@S17  T=1.29s eta=14:37:29 | 76.0K token/s | 
[epoch_0]_20311  loss=3.500482 |g|=0.398	lr=7.62e-04 | 63.9%@S17  T=1.02s eta=11:29:24 | 76.2K token/s | 
[epoch_0]_20321  loss=3.515455 |g|=0.338	lr=7.62e-04 | 64.7%@S17  T=1.03s eta=11:39:48 | 76.4K token/s | 
[epoch_0]_20331  loss=3.496359 |g|=0.351	lr=7.62e-04 | 65.5%@S17  T=1.04s eta=11:45:06 | 76.5K token/s | 
[epoch_0]_20341  loss=3.477618 |g|=0.376	lr=7.61e-04 | 66.3%@S17  T=1.02s eta=11:28:37 | 76.7K token/s | 
[epoch_0]_20351  loss=3.514398 |g|=0.357	lr=7.61e-04 | 67.2%@S17  T=1.02s eta=11:29:23 | 76.9K token/s | 
[epoch_0]_20361  loss=3.485095 |g|=0.379	lr=7.61e-04 | 68.0%@S17  T=1.04s eta=11:42:03 | 77.0K token/s | 
[epoch_0]_20371  loss=3.400383 |g|=0.387	lr=7.61e-04 | 68.8%@S17  T=1.02s eta=11:32:33 | 77.2K token/s | 
[epoch_0]_20381  loss=3.426343 |g|=0.373	lr=7.61e-04 | 69.6%@S17  T=1.02s eta=11:32:21 | 77.3K token/s | 
[epoch_0]_20391  loss=3.464368 |g|=0.346	lr=7.60e-04 | 70.4%@S17  T=1.03s eta=11:38:18 | 77.4K token/s | 
[Fuyou] head="5" update algorithm=4 t=2.09s
[eval] 
	 Loss@"edu_fineweb1B"=3.469(-0.00092) nBranch=1 nToken=4.01M best=3.4676(100) E2T=-0.0409 T=13.5026(0)s x=0
	#3.46856±0.1081 tps=297K(4.01408M) a=[3.28625,3.75755] T=13.5026(sec)
[Section@20400] layer[0-6] tasks=15(nPassBack=0) last_loss=3.50947(-0.0463948) N=(580,17640,17220 2039900)
[epoch_0]_20401  loss=3.461322 |g|=0.369	lr=7.60e-04 | 71.3%@S17  T=4.16s eta=1d 22:58:03 | 74.5K token/s | 
[epoch_0]_20411  loss=3.510128 |g|=0.368	lr=7.60e-04 | 72.1%@S17  T=1.02s eta=11:31:35 | 74.8K token/s | 
[epoch_0]_20421  loss=3.525230 |g|=0.391	lr=7.60e-04 | 72.9%@S17  T=1.01s eta=11:26:29 | 75.1K token/s | 
[epoch_0]_20431  loss=3.445795 |g|=0.361	lr=7.59e-04 | 73.7%@S17  T=1.02s eta=11:33:30 | 75.4K token/s | 
[epoch_0]_20441  loss=3.449820 |g|=0.386	lr=7.59e-04 | 74.5%@S17  T=1.02s eta=11:31:48 | 75.6K token/s | 
[epoch_0]_20451  loss=3.465307 |g|=0.354	lr=7.59e-04 | 75.4%@S17  T=1.03s eta=11:39:33 | 75.8K token/s | 
[epoch_0]_20461  loss=3.473917 |g|=0.313	lr=7.59e-04 | 76.2%@S17  T=1.05s eta=11:52:15 | 75.9K token/s | 
[epoch_0]_20471  loss=3.458035 |g|=0.363	lr=7.59e-04 | 77.0%@S17  T=1.02s eta=11:28:16 | 76.1K token/s | 
[epoch_0]_20481  loss=3.418486 |g|=0.388	lr=7.58e-04 | 77.8%@S17  T=1.02s eta=11:28:53 | 76.3K token/s | 
[epoch_0]_20491  loss=3.474913 |g|=0.359	lr=7.58e-04 | 78.6%@S17  T=1.02s eta=11:28:27 | 76.5K token/s | 
[Fuyou] head="0" update algorithm=4 t=2.04s
[Section@20500] layer[6-12] tasks=15(nPassBack=0) last_loss=3.53604(-0.141901) N=(580,17724,17304 2049900)
[epoch_0]_20501  loss=3.480301 |g|=0.337	lr=7.58e-04 | 79.4%@S17  T=1.29s eta=14:31:40 | 75.9K token/s | 
[epoch_0]_20511  loss=3.514587 |g|=0.376	lr=7.58e-04 | 80.3%@S17  T=1.05s eta=11:48:06 | 76.0K token/s | 
[epoch_0]_20521  loss=3.503061 |g|=0.377	lr=7.57e-04 | 81.1%@S17  T=1.02s eta=11:29:00 | 76.2K token/s | 
[epoch_0]_20531  loss=3.447985 |g|=0.376	lr=7.57e-04 | 81.9%@S17  T=1.04s eta=11:43:14 | 76.3K token/s | 
[epoch_0]_20541  loss=3.520131 |g|=0.362	lr=7.57e-04 | 82.7%@S17  T=1.02s eta=11:25:23 | 76.5K token/s | 
[epoch_0]_20551  loss=3.476643 |g|=0.399	lr=7.57e-04 | 83.5%@S17  T=1.02s eta=11:25:56 | 76.7K token/s | 
[epoch_0]_20561  loss=3.435359 |g|=0.368	lr=7.57e-04 | 84.4%@S17  T=1.02s eta=11:29:29 | 76.9K token/s | 
[epoch_0]_20571  loss=3.493968 |g|=0.371	lr=7.56e-04 | 85.2%@S17  T=1.05s eta=11:44:49 | 77.0K token/s | 
[epoch_0]_20581  loss=3.414141 |g|=0.364	lr=7.56e-04 | 86.0%@S17  T=1.02s eta=11:28:28 | 77.2K token/s | 
[epoch_0]_20591  loss=3.493452 |g|=0.373	lr=7.56e-04 | 86.8%@S17  T=1.03s eta=11:33:43 | 77.3K token/s | 
[Fuyou] head="1" update algorithm=4 t=2.19s
[eval] 
	 Loss@"edu_fineweb1B"=3.467(0.0017) nBranch=1 nToken=4.01M best=3.4686(101) E2T=0.0294 T=13.5118(0)s x=0
	#3.46687±0.1071 tps=297K(4.01408M) a=[3.28771,3.75322] T=13.5118(sec)
[Section@20600] layer[12-18] tasks=15(nPassBack=0) last_loss=3.43745(0.0361469) N=(580,17808,17388 2059900)
[epoch_0]_20601  loss=3.460558 |g|=0.353	lr=7.56e-04 | 87.6%@S17  T=4.16s eta=1d 22:40:28 | 74.4K token/s | 
[epoch_0]_20611  loss=3.437341 |g|=0.331	lr=7.55e-04 | 88.5%@S17  T=1.02s eta=11:28:43 | 74.7K token/s | 
[epoch_0]_20621  loss=3.408887 |g|=0.351	lr=7.55e-04 | 89.3%@S17  T=1.02s eta=11:25:08 | 75.0K token/s | 
[epoch_0]_20631  loss=3.485151 |g|=0.359	lr=7.55e-04 | 90.1%@S17  T=1.04s eta=11:38:04 | 75.2K token/s | 
[epoch_0]_20641  loss=3.412996 |g|=0.372	lr=7.55e-04 | 90.9%@S17  T=1.01s eta=11:19:28 | 75.5K token/s | 
[epoch_0]_20651  loss=3.366426 |g|=0.379	lr=7.55e-04 | 91.7%@S17  T=1.02s eta=11:23:42 | 75.7K token/s | 
[epoch_0]_20661  loss=3.442413 |g|=0.368	lr=7.54e-04 | 92.6%@S17  T=1.03s eta=11:33:23 | 75.9K token/s | 
[epoch_0]_20671  loss=3.415467 |g|=0.367	lr=7.54e-04 | 93.4%@S17  T=1.01s eta=11:19:02 | 76.2K token/s | 
[epoch_0]_20681  loss=3.448462 |g|=0.359	lr=7.54e-04 | 94.2%@S17  T=1.03s eta=11:32:34 | 76.4K token/s | 
[epoch_0]_20691  loss=3.477124 |g|=0.347	lr=7.54e-04 | 95.0%@S17  T=1.02s eta=11:28:51 | 76.5K token/s | 
[Fuyou] head="2" update algorithm=4 t=2.09s
[Section@20700] layer[18-24] tasks=15(nPassBack=0) last_loss=3.46199(0.0376658) N=(580,17892,17472 2069900)
[epoch_0]_20701  loss=3.438563 |g|=0.34	lr=7.53e-04 | 95.8%@S17  T=1.30s eta=14:35:48 | 75.9K token/s | 
[epoch_0]_20711  loss=3.419433 |g|=0.385	lr=7.53e-04 | 96.7%@S17  T=1.01s eta=11:15:45 | 76.1K token/s | 
[epoch_0]_20721  loss=3.481100 |g|=0.365	lr=7.53e-04 | 97.5%@S17  T=1.06s eta=11:48:56 | 76.2K token/s | 
[epoch_0]_20731  loss=3.389841 |g|=0.356	lr=7.53e-04 | 98.3%@S17  T=1.02s eta=11:24:00 | 76.4K token/s | 
[epoch_0]_20741  loss=3.502162 |g|=0.369	lr=7.53e-04 | 99.1%@S17  T=1.02s eta=11:25:21 | 76.6K token/s | 
[epoch_0]_20751  loss=3.445836 |g|=0.374	lr=7.52e-04 | 99.9%@S17  T=1.03s eta=11:29:13 | 76.8K token/s | 
-------- End of shard_17@"./Datasets/edu_fineweb1B/edu_fineweb_train_000470.bin"-------- 
[shard-18]@"./Datasets/edu_fineweb1B/edu_fineweb_train_000471.bin": tokens=100(M) nShardSamples=1220(1757808) 
[epoch_0]_20761  loss=3.481721 |g|=0.373	lr=7.52e-04 | 0.7%@S18  T=1.05s eta=11:42:58 | 76.8K token/s | 
[epoch_0]_20771  loss=3.402580 |g|=0.361	lr=7.52e-04 | 1.6%@S18  T=1.01s eta=11:20:36 | 77.0K token/s | 
[epoch_0]_20781  loss=3.448586 |g|=0.374	lr=7.52e-04 | 2.4%@S18  T=1.02s eta=11:25:12 | 77.2K token/s | 
[epoch_0]_20791  loss=3.396101 |g|=0.388	lr=7.51e-04 | 3.2%@S18  T=1.02s eta=11:23:23 | 77.4K token/s | 
[Fuyou] head="3" update algorithm=4 t=2.08s
[eval] 
	 Loss@"edu_fineweb1B"=3.464(0.0025) nBranch=1 nToken=4.01M best=3.4669(102) E2T=0.0803 T=13.5059(0)s x=0
	#3.46435±0.1067 tps=297K(4.01408M) a=[3.28466,3.7474] T=13.5059(sec)
[Section@20800] layer[24-30] tasks=15(nPassBack=0) last_loss=3.38406(0.0704803) N=(580,17976,17556 2079900)
[epoch_0]_20801  loss=3.409934 |g|=0.318	lr=7.51e-04 | 4.0%@S18  T=4.15s eta=1d 22:23:17 | 74.5K token/s | 
[epoch_0]_20811  loss=3.518957 |g|=0.375	lr=7.51e-04 | 4.8%@S18  T=1.01s eta=11:20:26 | 74.8K token/s | 
[epoch_0]_20821  loss=3.493827 |g|=0.35	lr=7.51e-04 | 5.7%@S18  T=1.02s eta=11:25:26 | 75.1K token/s | 
[epoch_0]_20831  loss=3.558302 |g|=0.357	lr=7.51e-04 | 6.5%@S18  T=1.05s eta=11:43:51 | 75.2K token/s | 
[epoch_0]_20841  loss=3.477249 |g|=0.351	lr=7.50e-04 | 7.3%@S18  T=1.01s eta=11:17:41 | 75.5K token/s | 
[epoch_0]_20851  loss=3.525376 |g|=0.357	lr=7.50e-04 | 8.1%@S18  T=1.01s eta=11:17:37 | 75.8K token/s | 
[epoch_0]_20861  loss=3.457953 |g|=0.371	lr=7.50e-04 | 8.9%@S18  T=1.02s eta=11:19:41 | 76.0K token/s | 
[epoch_0]_20871  loss=3.423465 |g|=0.356	lr=7.50e-04 | 9.8%@S18  T=1.05s eta=11:41:45 | 76.1K token/s | 
[epoch_0]_20881  loss=3.392960 |g|=0.33	lr=7.49e-04 | 10.6%@S18  T=1.02s eta=11:20:48 | 76.3K token/s | 
[epoch_0]_20891  loss=3.439016 |g|=0.376	lr=7.49e-04 | 11.4%@S18  T=1.01s eta=11:17:29 | 76.6K token/s | 
[Fuyou] head="4" update algorithm=4 t=2.09s
[Section@20900] layer[30-36] tasks=15(nPassBack=0) last_loss=3.49069(-0.0118239) N=(580,18060,17640 2089900)
[epoch_0]_20901  loss=3.479194 |g|=0.338	lr=7.49e-04 | 12.2%@S18  T=1.30s eta=14:30:49 | 75.9K token/s | 
[epoch_0]_20911  loss=3.467173 |g|=0.364	lr=7.49e-04 | 13.0%@S18  T=1.02s eta=11:21:49 | 76.1K token/s | 
[epoch_0]_20921  loss=3.459226 |g|=0.37	lr=7.49e-04 | 13.9%@S18  T=1.02s eta=11:23:27 | 76.3K token/s | 
[epoch_0]_20931  loss=3.509251 |g|=0.388	lr=7.48e-04 | 14.7%@S18  T=1.04s eta=11:35:52 | 76.4K token/s | 
[epoch_0]_20941  loss=3.479645 |g|=0.362	lr=7.48e-04 | 15.5%@S18  T=1.02s eta=11:19:08 | 76.6K token/s | 
[epoch_0]_20951  loss=3.439689 |g|=0.398	lr=7.48e-04 | 16.3%@S18  T=1.03s eta=11:28:34 | 76.8K token/s | 
[epoch_0]_20961  loss=3.446434 |g|=0.371	lr=7.48e-04 | 17.1%@S18  T=1.04s eta=11:32:27 | 76.9K token/s | 
[epoch_0]_20971  loss=3.455302 |g|=0.385	lr=7.47e-04 | 17.9%@S18  T=1.02s eta=11:20:27 | 77.1K token/s | 
[epoch_0]_20981  loss=3.455636 |g|=0.336	lr=7.47e-04 | 18.8%@S18  T=1.02s eta=11:22:32 | 77.2K token/s | 
[epoch_0]_20991  loss=3.475248 |g|=0.368	lr=7.47e-04 | 19.6%@S18  T=1.03s eta=11:27:39 | 77.3K token/s | 
[Fuyou] head="5" update algorithm=4 t=2.04s
[eval] 
	 Loss@"edu_fineweb1B"=3.458(0.0065) nBranch=1 nToken=4.01M best=3.4644(103) E2T=0.00195 T=13.4924(0)s x=0
	#3.45787±0.1070 tps=298K(4.01408M) a=[3.27826,3.73906] T=13.4924(sec)
[Section@21000] layer[0-6] tasks=15(nPassBack=0) last_loss=3.45592(0.05355) N=(580,18144,17724 2099900)
[epoch_0]_21001  loss=3.487711 |g|=0.331	lr=7.47e-04 | 20.4%@S18  T=4.15s eta=1d 22:12:08 | 74.5K token/s | 
[epoch_0]_21011  loss=3.430816 |g|=0.362	lr=7.47e-04 | 21.2%@S18  T=1.03s eta=11:24:06 | 74.7K token/s | 
[epoch_0]_21021  loss=3.427753 |g|=0.342	lr=7.46e-04 | 22.0%@S18  T=1.03s eta=11:23:58 | 75.0K token/s | 
[epoch_0]_21031  loss=3.491275 |g|=0.38	lr=7.46e-04 | 22.9%@S18  T=1.05s eta=11:41:23 | 75.1K token/s | 
[epoch_0]_21041  loss=3.469705 |g|=0.37	lr=7.46e-04 | 23.7%@S18  T=1.02s eta=11:20:29 | 75.4K token/s | 
[epoch_0]_21051  loss=3.484088 |g|=0.369	lr=7.46e-04 | 24.5%@S18  T=1.01s eta=11:13:34 | 75.7K token/s | 
[epoch_0]_21061  loss=3.393949 |g|=0.367	lr=7.45e-04 | 25.3%@S18  T=1.03s eta=11:25:20 | 75.9K token/s | 
[epoch_0]_21071  loss=3.538616 |g|=0.34	lr=7.45e-04 | 26.1%@S18  T=1.05s eta=11:38:11 | 76.0K token/s | 
[epoch_0]_21081  loss=3.457074 |g|=0.372	lr=7.45e-04 | 27.0%@S18  T=1.02s eta=11:22:10 | 76.2K token/s | 
[epoch_0]_21091  loss=3.484677 |g|=0.351	lr=7.45e-04 | 27.8%@S18  T=1.02s eta=11:20:36 | 76.4K token/s | 
[Fuyou] head="0" update algorithm=4 t=2.08s
[Section@21100] layer[6-12] tasks=15(nPassBack=0) last_loss=3.42794(0.108092) N=(580,18228,17808 2109900)
[epoch_0]_21101  loss=3.459953 |g|=0.348	lr=7.45e-04 | 28.6%@S18  T=1.30s eta=14:28:15 | 75.7K token/s | 
[epoch_0]_21111  loss=3.477393 |g|=0.389	lr=7.44e-04 | 29.4%@S18  T=1.03s eta=11:24:27 | 75.9K token/s | 
[epoch_0]_21121  loss=3.392425 |g|=0.386	lr=7.44e-04 | 30.2%@S18  T=1.02s eta=11:21:32 | 76.1K token/s | 
[epoch_0]_21131  loss=3.375299 |g|=0.378	lr=7.44e-04 | 31.1%@S18  T=1.02s eta=11:20:53 | 76.3K token/s | 
[epoch_0]_21141  loss=3.549247 |g|=0.364	lr=7.44e-04 | 31.9%@S18  T=1.05s eta=11:38:45 | 76.4K token/s | 
[epoch_0]_21151  loss=3.510801 |g|=0.342	lr=7.43e-04 | 32.7%@S18  T=1.02s eta=11:18:52 | 76.6K token/s | 
[epoch_0]_21161  loss=3.487201 |g|=0.386	lr=7.43e-04 | 33.5%@S18  T=1.02s eta=11:17:56 | 76.8K token/s | 
[epoch_0]_21171  loss=3.524295 |g|=0.344	lr=7.43e-04 | 34.3%@S18  T=1.02s eta=11:17:41 | 76.9K token/s | 
[epoch_0]_21181  loss=3.391367 |g|=0.406	lr=7.43e-04 | 35.2%@S18  T=1.06s eta=11:41:38 | 77.0K token/s | 
[epoch_0]_21191  loss=3.501976 |g|=0.355	lr=7.42e-04 | 36.0%@S18  T=1.02s eta=11:19:35 | 77.1K token/s | 
[Fuyou] head="1" update algorithm=4 t=2.10s
[eval] 
	 Loss@"edu_fineweb1B"=3.453(0.0046) nBranch=1 nToken=4.01M best=3.4579(104) E2T=-0.0438 T=13.4941(0)s x=0
	#3.45325±0.1067 tps=297K(4.01408M) a=[3.27462,3.73637] T=13.4941(sec)
[Section@21200] layer[12-18] tasks=15(nPassBack=0) last_loss=3.4971(-0.0596421) N=(580,18312,17892 2119900)
[epoch_0]_21201  loss=3.570832 |g|=0.383	lr=7.42e-04 | 36.8%@S18  T=4.14s eta=1d 21:49:26 | 74.3K token/s | 
[epoch_0]_21211  loss=3.498230 |g|=0.353	lr=7.42e-04 | 37.6%@S18  T=1.05s eta=11:37:06 | 74.4K token/s | 
[epoch_0]_21221  loss=3.396399 |g|=0.337	lr=7.42e-04 | 38.4%@S18  T=1.02s eta=11:17:24 | 74.7K token/s | 
[epoch_0]_21231  loss=3.383373 |g|=0.384	lr=7.42e-04 | 39.2%@S18  T=1.03s eta=11:24:49 | 75.0K token/s | 
[epoch_0]_21241  loss=3.418119 |g|=0.337	lr=7.41e-04 | 40.1%@S18  T=1.01s eta=11:12:04 | 75.3K token/s | 
[epoch_0]_21251  loss=3.437232 |g|=0.352	lr=7.41e-04 | 40.9%@S18  T=1.02s eta=11:18:22 | 75.5K token/s | 
[epoch_0]_21261  loss=3.503477 |g|=0.326	lr=7.41e-04 | 41.7%@S18  T=1.02s eta=11:18:28 | 75.7K token/s | 
[epoch_0]_21271  loss=3.439389 |g|=0.372	lr=7.41e-04 | 42.5%@S18  T=1.04s eta=11:27:06 | 75.9K token/s | 
[epoch_0]_21281  loss=3.479786 |g|=0.348	lr=7.40e-04 | 43.3%@S18  T=1.02s eta=11:13:24 | 76.1K token/s | 
[epoch_0]_21291  loss=3.480204 |g|=0.351	lr=7.40e-04 | 44.2%@S18  T=1.02s eta=11:15:36 | 76.3K token/s | 
[Fuyou] head="2" update algorithm=4 t=2.09s
[Section@21300] layer[18-24] tasks=15(nPassBack=0) last_loss=3.47675(-0.0147605) N=(580,18396,17976 2129900)
[epoch_0]_21301  loss=3.436534 |g|=0.382	lr=7.40e-04 | 45.0%@S18  T=1.30s eta=14:19:41 | 75.7K token/s | 
[epoch_0]_21311  loss=3.513086 |g|=0.351	lr=7.40e-04 | 45.8%@S18  T=1.02s eta=11:13:35 | 75.9K token/s | 
[epoch_0]_21321  loss=3.527343 |g|=0.363	lr=7.40e-04 | 46.6%@S18  T=1.04s eta=11:26:19 | 76.1K token/s | 
[epoch_0]_21331  loss=3.508715 |g|=0.361	lr=7.39e-04 | 47.4%@S18  T=1.03s eta=11:20:46 | 76.2K token/s | 
[epoch_0]_21341  loss=3.437980 |g|=0.386	lr=7.39e-04 | 48.3%@S18  T=1.02s eta=11:15:48 | 76.4K token/s | 
[epoch_0]_21351  loss=3.455343 |g|=0.407	lr=7.39e-04 | 49.1%@S18  T=1.04s eta=11:28:55 | 76.6K token/s | 
[epoch_0]_21361  loss=3.491966 |g|=0.383	lr=7.39e-04 | 49.9%@S18  T=1.01s eta=11:07:07 | 76.8K token/s | 
[epoch_0]_21371  loss=3.442964 |g|=0.357	lr=7.38e-04 | 50.7%@S18  T=1.03s eta=11:18:39 | 76.9K token/s | 
[epoch_0]_21381  loss=3.478663 |g|=0.356	lr=7.38e-04 | 51.5%@S18  T=1.03s eta=11:19:38 | 77.1K token/s | 
[epoch_0]_21391  loss=3.482615 |g|=0.395	lr=7.38e-04 | 52.4%@S18  T=1.06s eta=11:42:40 | 77.1K token/s | 
[Fuyou] head="3" update algorithm=4 t=2.08s
[eval] 
	 Loss@"edu_fineweb1B"=3.451(0.0018) nBranch=1 nToken=4.01M best=3.4532(105) E2T=-0.00828 T=13.503(0)s x=0
	#3.45143±0.1074 tps=297K(4.01408M) a=[3.26577,3.7369] T=13.503(sec)
[Section@21400] layer[24-30] tasks=15(nPassBack=0) last_loss=3.45972(-0.0756519) N=(580,18480,18060 2139900)
[epoch_0]_21401  loss=3.375993 |g|=0.35	lr=7.38e-04 | 53.2%@S18  T=4.14s eta=1d 21:35:40 | 74.2K token/s | 
[epoch_0]_21411  loss=3.464533 |g|=0.36	lr=7.38e-04 | 54.0%@S18  T=1.02s eta=11:12:03 | 74.5K token/s | 
[epoch_0]_21421  loss=3.497626 |g|=0.386	lr=7.37e-04 | 54.8%@S18  T=1.02s eta=11:14:18 | 74.8K token/s | 
[epoch_0]_21431  loss=3.481378 |g|=0.377	lr=7.37e-04 | 55.6%@S18  T=1.04s eta=11:26:41 | 75.0K token/s | 
[epoch_0]_21441  loss=3.455363 |g|=0.36	lr=7.37e-04 | 56.5%@S18  T=1.02s eta=11:14:09 | 75.3K token/s | 
[epoch_0]_21451  loss=3.430686 |g|=0.349	lr=7.37e-04 | 57.3%@S18  T=1.02s eta=11:12:22 | 75.5K token/s | 
[epoch_0]_21461  loss=3.499928 |g|=0.339	lr=7.36e-04 | 58.1%@S18  T=1.05s eta=11:33:39 | 75.6K token/s | 
[epoch_0]_21471  loss=3.399657 |g|=0.384	lr=7.36e-04 | 58.9%@S18  T=1.03s eta=11:16:13 | 75.8K token/s | 
[epoch_0]_21481  loss=3.462937 |g|=0.336	lr=7.36e-04 | 59.7%@S18  T=1.01s eta=11:07:38 | 76.1K token/s | 
[epoch_0]_21491  loss=3.409333 |g|=0.356	lr=7.36e-04 | 60.5%@S18  T=1.02s eta=11:14:08 | 76.3K token/s | 
[Fuyou] head="4" update algorithm=4 t=2.03s
[Section@21500] layer[30-36] tasks=15(nPassBack=0) last_loss=3.45026(0.0404305) N=(580,18564,18144 2149900)
[epoch_0]_21501  loss=3.420821 |g|=0.361	lr=7.35e-04 | 61.4%@S18  T=1.30s eta=14:13:50 | 75.6K token/s | 
[epoch_0]_21511  loss=3.473469 |g|=0.355	lr=7.35e-04 | 62.2%@S18  T=1.02s eta=11:12:09 | 75.9K token/s | 
[epoch_0]_21521  loss=3.417710 |g|=0.37	lr=7.35e-04 | 63.0%@S18  T=1.06s eta=11:41:00 | 75.9K token/s | 
[epoch_0]_21531  loss=3.459089 |g|=0.351	lr=7.35e-04 | 63.8%@S18  T=1.02s eta=11:11:52 | 76.1K token/s | 
[epoch_0]_21541  loss=3.460317 |g|=0.33	lr=7.35e-04 | 64.6%@S18  T=1.03s eta=11:16:55 | 76.3K token/s | 
[epoch_0]_21551  loss=3.480539 |g|=0.353	lr=7.34e-04 | 65.5%@S18  T=1.03s eta=11:20:21 | 76.5K token/s | 
[epoch_0]_21561  loss=3.466650 |g|=0.358	lr=7.34e-04 | 66.3%@S18  T=1.03s eta=11:17:48 | 76.6K token/s | 
[epoch_0]_21571  loss=3.368183 |g|=0.444	lr=7.34e-04 | 67.1%@S18  T=1.02s eta=11:09:55 | 76.8K token/s | 
[epoch_0]_21581  loss=3.435115 |g|=0.361	lr=7.34e-04 | 67.9%@S18  T=1.01s eta=11:06:21 | 77.0K token/s | 
[epoch_0]_21591  loss=3.522381 |g|=0.389	lr=7.33e-04 | 68.7%@S18  T=1.05s eta=11:28:08 | 77.1K token/s | 
[Fuyou] head="5" update algorithm=4 t=2.08s
[eval] 
	 Loss@"edu_fineweb1B"=3.449(0.0022) nBranch=1 nToken=4.01M best=3.4514(106) E2T=-0.0393 T=13.4988(0)s x=0
	#3.44923±0.1071 tps=297K(4.01408M) a=[3.26314,3.73156] T=13.4988(sec)
[Section@21600] layer[0-6] tasks=15(nPassBack=0) last_loss=3.48851(-0.032593) N=(580,18648,18228 2159900)
[epoch_0]_21601  loss=3.475780 |g|=0.339	lr=7.33e-04 | 69.6%@S18  T=4.16s eta=1d 21:34:05 | 74.2K token/s | 
[epoch_0]_21611  loss=3.424283 |g|=0.406	lr=7.33e-04 | 70.4%@S18  T=1.03s eta=11:17:12 | 74.5K token/s | 
[epoch_0]_21621  loss=3.495285 |g|=0.388	lr=7.33e-04 | 71.2%@S18  T=1.04s eta=11:20:59 | 74.7K token/s | 
[epoch_0]_21631  loss=3.402988 |g|=0.326	lr=7.33e-04 | 72.0%@S18  T=1.02s eta=11:10:26 | 75.0K token/s | 
[epoch_0]_21641  loss=3.482309 |g|=0.388	lr=7.32e-04 | 72.8%@S18  T=1.02s eta=11:09:40 | 75.2K token/s | 
[epoch_0]_21651  loss=3.442961 |g|=0.388	lr=7.32e-04 | 73.7%@S18  T=1.05s eta=11:28:09 | 75.4K token/s | 
[epoch_0]_21661  loss=3.418847 |g|=0.355	lr=7.32e-04 | 74.5%@S18  T=1.04s eta=11:25:39 | 75.5K token/s | 
[epoch_0]_21671  loss=3.418113 |g|=0.356	lr=7.32e-04 | 75.3%@S18  T=1.02s eta=11:07:26 | 75.8K token/s | 
[epoch_0]_21681  loss=3.408840 |g|=0.343	lr=7.31e-04 | 76.1%@S18  T=1.02s eta=11:07:07 | 76.0K token/s | 
[epoch_0]_21691  loss=3.460741 |g|=0.343	lr=7.31e-04 | 76.9%@S18  T=1.02s eta=11:11:08 | 76.2K token/s | 
[Fuyou] head="0" update algorithm=4 t=2.10s
[Section@21700] layer[6-12] tasks=15(nPassBack=0) last_loss=3.47011(-0.0421634) N=(580,18732,18312 2169900)
[epoch_0]_21701  loss=3.431107 |g|=0.347	lr=7.31e-04 | 77.8%@S18  T=1.31s eta=14:21:57 | 75.5K token/s | 
[epoch_0]_21711  loss=3.428498 |g|=0.364	lr=7.31e-04 | 78.6%@S18  T=1.01s eta=11:05:11 | 75.8K token/s | 
[epoch_0]_21721  loss=3.412025 |g|=0.363	lr=7.30e-04 | 79.4%@S18  T=1.03s eta=11:13:06 | 76.0K token/s | 
[epoch_0]_21731  loss=3.420218 |g|=0.393	lr=7.30e-04 | 80.2%@S18  T=1.03s eta=11:15:41 | 76.2K token/s | 
[epoch_0]_21741  loss=3.487130 |g|=0.378	lr=7.30e-04 | 81.0%@S18  T=1.06s eta=11:37:07 | 76.2K token/s | 
[epoch_0]_21751  loss=3.423684 |g|=0.367	lr=7.30e-04 | 81.8%@S18  T=1.02s eta=11:07:52 | 76.4K token/s | 
[epoch_0]_21761  loss=3.369447 |g|=0.351	lr=7.30e-04 | 82.7%@S18  T=1.03s eta=11:12:21 | 76.6K token/s | 
[epoch_0]_21771  loss=3.456815 |g|=0.333	lr=7.29e-04 | 83.5%@S18  T=1.03s eta=11:17:03 | 76.7K token/s | 
[epoch_0]_21781  loss=3.395224 |g|=0.354	lr=7.29e-04 | 84.3%@S18  T=1.04s eta=11:17:58 | 76.8K token/s | 
[epoch_0]_21791  loss=3.371946 |g|=0.344	lr=7.29e-04 | 85.1%@S18  T=1.02s eta=11:04:59 | 77.0K token/s | 
[Fuyou] head="1" update algorithm=4 t=2.11s
[eval] 
	 Loss@"edu_fineweb1B"=3.449(0.00032) nBranch=1 nToken=4.01M best=3.4492(107) E2T=-0.0779 T=13.5089(0)s x=0
	#3.4489±0.1076 tps=297K(4.01408M) a=[3.26428,3.73176] T=13.5089(sec)
[Section@21800] layer[12-18] tasks=15(nPassBack=0) last_loss=3.52677(-0.0296764) N=(580,18816,18396 2179900)
[epoch_0]_21801  loss=3.531808 |g|=0.34	lr=7.29e-04 | 85.9%@S18  T=4.17s eta=1d 21:24:45 | 74.1K token/s | 
[epoch_0]_21811  loss=3.414596 |g|=0.393	lr=7.28e-04 | 86.8%@S18  T=1.06s eta=11:31:03 | 74.3K token/s | 
[epoch_0]_21821  loss=3.462675 |g|=0.363	lr=7.28e-04 | 87.6%@S18  T=1.02s eta=11:08:08 | 74.6K token/s | 
[epoch_0]_21831  loss=3.446162 |g|=0.36	lr=7.28e-04 | 88.4%@S18  T=1.02s eta=11:08:31 | 74.9K token/s | 
[epoch_0]_21841  loss=3.476944 |g|=0.368	lr=7.28e-04 | 89.2%@S18  T=1.02s eta=11:05:49 | 75.1K token/s | 
[epoch_0]_21851  loss=3.332873 |g|=0.345	lr=7.27e-04 | 90.0%@S18  T=1.03s eta=11:14:16 | 75.4K token/s | 
[epoch_0]_21861  loss=3.517066 |g|=0.351	lr=7.27e-04 | 90.9%@S18  T=1.06s eta=11:32:29 | 75.5K token/s | 
[epoch_0]_21871  loss=3.435875 |g|=0.38	lr=7.27e-04 | 91.7%@S18  T=1.02s eta=11:07:18 | 75.7K token/s | 
[epoch_0]_21881  loss=3.427176 |g|=0.413	lr=7.27e-04 | 92.5%@S18  T=1.02s eta=11:04:35 | 75.9K token/s | 
[epoch_0]_21891  loss=3.457089 |g|=0.358	lr=7.27e-04 | 93.3%@S18  T=1.02s eta=11:08:19 | 76.1K token/s | 
[Fuyou] head="2" update algorithm=4 t=2.08s
[Section@21900] layer[18-24] tasks=15(nPassBack=0) last_loss=3.36361(0.113136) N=(580,18900,18480 2189900)
[epoch_0]_21901  loss=3.450501 |g|=0.343	lr=7.26e-04 | 94.1%@S18  T=1.30s eta=14:07:57 | 75.5K token/s | 
[epoch_0]_21911  loss=3.462671 |g|=0.382	lr=7.26e-04 | 95.0%@S18  T=1.03s eta=11:09:22 | 75.7K token/s | 
[epoch_0]_21921  loss=3.444593 |g|=0.36	lr=7.26e-04 | 95.8%@S18  T=1.03s eta=11:08:48 | 75.9K token/s | 
[epoch_0]_21931  loss=3.393283 |g|=0.403	lr=7.26e-04 | 96.6%@S18  T=1.02s eta=11:02:22 | 76.1K token/s | 
[epoch_0]_21941  loss=3.426122 |g|=0.358	lr=7.25e-04 | 97.4%@S18  T=1.02s eta=11:05:48 | 76.3K token/s | 
[epoch_0]_21951  loss=3.521586 |g|=0.358	lr=7.25e-04 | 98.2%@S18  T=1.03s eta=11:10:12 | 76.5K token/s | 
[epoch_0]_21961  loss=3.499695 |g|=0.375	lr=7.25e-04 | 99.1%@S18  T=1.04s eta=11:19:30 | 76.6K token/s | 
[epoch_0]_21971  loss=3.430427 |g|=0.4	lr=7.25e-04 | 99.9%@S18  T=1.03s eta=11:07:21 | 76.8K token/s | 
[epoch_0]_21972  loss=3.346491 |g|=0.364	lr=7.25e-04 | 100.0%@S18  T=1.05s eta=11:26:24 | 76.8K token/s | 
-------- End of shard_18@"./Datasets/edu_fineweb1B/edu_fineweb_train_000471.bin"-------- 
[shard-19]@"./Datasets/edu_fineweb1B/edu_fineweb_train_000472.bin": tokens=100(M) nShardSamples=1220(1855464) 
[epoch_0]_21981  loss=3.492325 |g|=0.395	lr=7.24e-04 | 0.7%@S19  T=1.01s eta=10:58:45 | 77.0K token/s | 
[epoch_0]_21991  loss=3.377339 |g|=0.374	lr=7.24e-04 | 1.5%@S19  T=1.01s eta=11:00:14 | 77.2K token/s | 
[Fuyou] head="3" update algorithm=4 t=2.03s
[eval] 
	 Loss@"edu_fineweb1B"=3.446(0.0024) nBranch=1 nToken=4.01M best=3.4489(108) E2T=-0.0318 T=13.4898(0)s x=0
	#3.44647±0.1078 tps=298K(4.01408M) a=[3.26246,3.73124] T=13.4898(sec)
[Section@22000] layer[24-30] tasks=15(nPassBack=0) last_loss=3.4783(-0.0185871) N=(580,18984,18564 2199900)
[epoch_0]_22001  loss=3.449952 |g|=0.374	lr=7.24e-04 | 2.3%@S19  T=4.15s eta=1d 21:00:35 | 74.3K token/s | 
[epoch_0]_22011  loss=3.398654 |g|=0.387	lr=7.24e-04 | 3.1%@S19  T=1.05s eta=11:21:26 | 74.5K token/s | 
[epoch_0]_22021  loss=3.496253 |g|=0.377	lr=7.24e-04 | 4.0%@S19  T=1.02s eta=11:05:41 | 74.8K token/s | 
[epoch_0]_22031  loss=3.459875 |g|=0.362	lr=7.23e-04 | 4.8%@S19  T=1.03s eta=11:12:13 | 75.0K token/s | 
[epoch_0]_22041  loss=3.517551 |g|=0.367	lr=7.23e-04 | 5.6%@S19  T=1.02s eta=11:03:27 | 75.3K token/s | 
[epoch_0]_22051  loss=3.441768 |g|=0.379	lr=7.23e-04 | 6.4%@S19  T=1.02s eta=11:00:56 | 75.5K token/s | 
[epoch_0]_22061  loss=3.394350 |g|=0.384	lr=7.23e-04 | 7.2%@S19  T=1.02s eta=11:04:08 | 75.8K token/s | 
[epoch_0]_22071  loss=3.486382 |g|=0.367	lr=7.22e-04 | 8.1%@S19  T=1.03s eta=11:07:32 | 76.0K token/s | 
[epoch_0]_22081  loss=3.497323 |g|=0.414	lr=7.22e-04 | 8.9%@S19  T=1.02s eta=11:04:05 | 76.2K token/s | 
[epoch_0]_22091  loss=3.485779 |g|=0.338	lr=7.22e-04 | 9.7%@S19  T=1.02s eta=10:59:14 | 76.4K token/s | 
[Fuyou] head="4" update algorithm=4 t=2.09s
[Section@22100] layer[30-36] tasks=15(nPassBack=0) last_loss=3.46094(-0.0106759) N=(580,19068,18648 2209900)
[epoch_0]_22101  loss=3.489957 |g|=0.344	lr=7.22e-04 | 10.5%@S19  T=1.31s eta=14:06:52 | 75.7K token/s | 
[epoch_0]_22111  loss=3.525279 |g|=0.341	lr=7.21e-04 | 11.3%@S19  T=1.02s eta=11:03:52 | 75.9K token/s | 
[epoch_0]_22121  loss=3.440558 |g|=0.381	lr=7.21e-04 | 12.2%@S19  T=1.01s eta=10:57:20 | 76.2K token/s | 
[epoch_0]_22131  loss=3.507550 |g|=0.346	lr=7.21e-04 | 13.0%@S19  T=1.03s eta=11:07:44 | 76.3K token/s | 
[epoch_0]_22141  loss=3.529007 |g|=0.405	lr=7.21e-04 | 13.8%@S19  T=1.03s eta=11:05:16 | 76.5K token/s | 
[epoch_0]_22151  loss=3.401872 |g|=0.361	lr=7.21e-04 | 14.6%@S19  T=1.05s eta=11:17:35 | 76.6K token/s | 
[epoch_0]_22161  loss=3.472541 |g|=0.367	lr=7.20e-04 | 15.4%@S19  T=1.03s eta=11:05:58 | 76.8K token/s | 
[epoch_0]_22171  loss=3.485530 |g|=0.393	lr=7.20e-04 | 16.3%@S19  T=1.02s eta=11:00:12 | 76.9K token/s | 
[epoch_0]_22181  loss=3.524747 |g|=0.34	lr=7.20e-04 | 17.1%@S19  T=1.06s eta=11:27:53 | 77.0K token/s | 
[epoch_0]_22191  loss=3.431602 |g|=0.366	lr=7.20e-04 | 17.9%@S19  T=1.06s eta=11:26:43 | 77.0K token/s | 
[Fuyou] head="5" update algorithm=4 t=2.07s
[eval] 
	 Loss@"edu_fineweb1B"=3.447(-0.00072) nBranch=1 nToken=4.01M best=3.4465(109) E2T=-0.0708 T=13.4961(0)s x=0
	#3.44719±0.1074 tps=297K(4.01408M) a=[3.2637,3.72999] T=13.4961(sec)
[Section@22200] layer[0-6] tasks=15(nPassBack=0) last_loss=3.51799(-0.0294721) N=(580,19152,18732 2219900)
[epoch_0]_22201  loss=3.445723 |g|=0.343	lr=7.19e-04 | 18.7%@S19  T=4.14s eta=1d 20:40:33 | 74.1K token/s | 
[epoch_0]_22211  loss=3.437181 |g|=0.363	lr=7.19e-04 | 19.5%@S19  T=1.02s eta=11:00:52 | 74.4K token/s | 
[epoch_0]_22221  loss=3.366873 |g|=0.355	lr=7.19e-04 | 20.4%@S19  T=1.05s eta=11:17:14 | 74.6K token/s | 
[epoch_0]_22231  loss=3.461936 |g|=0.375	lr=7.19e-04 | 21.2%@S19  T=1.03s eta=11:03:36 | 74.9K token/s | 
[epoch_0]_22241  loss=3.488834 |g|=0.343	lr=7.18e-04 | 22.0%@S19  T=1.03s eta=11:03:28 | 75.1K token/s | 
[epoch_0]_22251  loss=3.422556 |g|=0.359	lr=7.18e-04 | 22.8%@S19  T=1.04s eta=11:10:16 | 75.3K token/s | 
[epoch_0]_22261  loss=3.439016 |g|=0.369	lr=7.18e-04 | 23.6%@S19  T=1.05s eta=11:20:31 | 75.4K token/s | 
[epoch_0]_22271  loss=3.447514 |g|=0.362	lr=7.18e-04 | 24.4%@S19  T=1.02s eta=10:59:58 | 75.7K token/s | 
[epoch_0]_22281  loss=3.514494 |g|=0.36	lr=7.18e-04 | 25.3%@S19  T=1.03s eta=11:03:58 | 75.9K token/s | 
[epoch_0]_22291  loss=3.460155 |g|=0.36	lr=7.17e-04 | 26.1%@S19  T=1.03s eta=11:04:02 | 76.1K token/s | 
[Fuyou] head="0" update algorithm=4 t=2.08s
[Section@22300] layer[6-12] tasks=15(nPassBack=0) last_loss=3.45167(0.0184321) N=(580,19236,18816 2229900)
[epoch_0]_22301  loss=3.565228 |g|=0.369	lr=7.17e-04 | 26.9%@S19  T=1.47s eta=15:47:56 | 75.0K token/s | 
[epoch_0]_22311  loss=3.490751 |g|=0.367	lr=7.17e-04 | 27.7%@S19  T=1.05s eta=11:19:26 | 75.2K token/s | 
[epoch_0]_22321  loss=3.530588 |g|=0.379	lr=7.17e-04 | 28.5%@S19  T=1.04s eta=11:13:05 | 75.4K token/s | 
[epoch_0]_22331  loss=3.491119 |g|=0.349	lr=7.16e-04 | 29.4%@S19  T=1.06s eta=11:22:55 | 75.5K token/s | 
[epoch_0]_22341  loss=3.451497 |g|=0.343	lr=7.16e-04 | 30.2%@S19  T=1.02s eta=11:00:48 | 75.7K token/s | 
[epoch_0]_22351  loss=3.449378 |g|=0.374	lr=7.16e-04 | 31.0%@S19  T=1.01s eta=10:53:16 | 75.9K token/s | 
[epoch_0]_22361  loss=3.431389 |g|=0.397	lr=7.16e-04 | 31.8%@S19  T=1.05s eta=11:16:01 | 76.0K token/s | 
[epoch_0]_22371  loss=3.436319 |g|=0.376	lr=7.15e-04 | 32.6%@S19  T=1.06s eta=11:22:21 | 76.1K token/s | 
[epoch_0]_22381  loss=3.379153 |g|=0.367	lr=7.15e-04 | 33.5%@S19  T=1.02s eta=10:55:47 | 76.3K token/s | 
[epoch_0]_22391  loss=3.441051 |g|=0.354	lr=7.15e-04 | 34.3%@S19  T=1.02s eta=10:58:55 | 76.5K token/s | 
[Fuyou] head="1" update algorithm=4 t=2.08s
[eval] 
	 Loss@"edu_fineweb1B"=3.448(-0.001) nBranch=1 nToken=4.01M best=3.4465(109) E2T=-0.0213 T=13.5076(0)s x=0
	#3.44822±0.1075 tps=297K(4.01408M) a=[3.26407,3.72831] T=13.5076(sec)
[Section@22400] layer[12-18] tasks=15(nPassBack=0) last_loss=3.46953(0.0572402) N=(580,19320,18900 2239900)
[epoch_0]_22401  loss=3.427727 |g|=0.355	lr=7.15e-04 | 35.1%@S19  T=4.16s eta=1d 20:37:16 | 73.7K token/s | 
[epoch_0]_22411  loss=3.470526 |g|=0.345	lr=7.14e-04 | 35.9%@S19  T=1.03s eta=11:05:00 | 74.0K token/s | 
[epoch_0]_22421  loss=3.446091 |g|=0.382	lr=7.14e-04 | 36.7%@S19  T=1.02s eta=10:56:35 | 74.3K token/s | 
[epoch_0]_22431  loss=3.500245 |g|=0.358	lr=7.14e-04 | 37.6%@S19  T=1.05s eta=11:14:51 | 74.5K token/s | 
[epoch_0]_22441  loss=3.474975 |g|=0.353	lr=7.14e-04 | 38.4%@S19  T=1.02s eta=10:58:27 | 74.7K token/s | 
[epoch_0]_22451  loss=3.456272 |g|=0.366	lr=7.14e-04 | 39.2%@S19  T=1.03s eta=11:02:53 | 75.0K token/s | 
[epoch_0]_22461  loss=3.356663 |g|=0.36	lr=7.13e-04 | 40.0%@S19  T=1.03s eta=11:01:25 | 75.2K token/s | 
[epoch_0]_22471  loss=3.426162 |g|=0.426	lr=7.13e-04 | 40.8%@S19  T=1.06s eta=11:18:15 | 75.3K token/s | 
[epoch_0]_22481  loss=3.395919 |g|=0.378	lr=7.13e-04 | 41.6%@S19  T=1.01s eta=10:51:16 | 75.6K token/s | 
[epoch_0]_22491  loss=3.425032 |g|=0.369	lr=7.13e-04 | 42.5%@S19  T=1.04s eta=11:07:08 | 75.8K token/s | 
[Fuyou] head="2" update algorithm=4 t=2.03s
[Section@22500] layer[18-24] tasks=15(nPassBack=0) last_loss=3.43649(-0.0728772) N=(580,19404,18984 2249900)
[epoch_0]_22501  loss=3.435920 |g|=0.343	lr=7.12e-04 | 43.3%@S19  T=1.35s eta=14:25:53 | 75.0K token/s | 
[epoch_0]_22511  loss=3.456222 |g|=0.379	lr=7.12e-04 | 44.1%@S19  T=1.03s eta=10:59:43 | 75.3K token/s | 
[epoch_0]_22521  loss=3.389573 |g|=0.356	lr=7.12e-04 | 44.9%@S19  T=1.03s eta=10:59:26 | 75.5K token/s | 
[epoch_0]_22531  loss=3.396276 |g|=0.368	lr=7.12e-04 | 45.7%@S19  T=1.05s eta=11:15:51 | 75.6K token/s | 
[epoch_0]_22541  loss=3.456036 |g|=0.349	lr=7.11e-04 | 46.6%@S19  T=1.02s eta=10:56:34 | 75.8K token/s | 
[epoch_0]_22551  loss=3.368948 |g|=0.398	lr=7.11e-04 | 47.4%@S19  T=1.06s eta=11:17:15 | 75.9K token/s | 
[epoch_0]_22561  loss=3.317170 |g|=0.363	lr=7.11e-04 | 48.2%@S19  T=1.02s eta=10:52:59 | 76.1K token/s | 
[epoch_0]_22571  loss=3.434182 |g|=0.348	lr=7.11e-04 | 49.0%@S19  T=1.02s eta=10:53:23 | 76.3K token/s | 
[epoch_0]_22581  loss=3.407468 |g|=0.341	lr=7.11e-04 | 49.8%@S19  T=1.03s eta=10:57:38 | 76.5K token/s | 
[epoch_0]_22591  loss=3.357923 |g|=0.362	lr=7.10e-04 | 50.7%@S19  T=1.09s eta=11:36:54 | 76.5K token/s | 
[Fuyou] head="3" update algorithm=4 t=2.08s
[eval] 
	 Loss@"edu_fineweb1B"=3.445(0.0031) nBranch=1 nToken=4.01M best=3.4482(111) E2T=-0.00106 T=13.5034(0)s x=0
	#3.44514±0.1084 tps=297K(4.01408M) a=[3.26033,3.73166] T=13.5034(sec)
[Section@22600] layer[24-30] tasks=15(nPassBack=0) last_loss=3.4462(0.0321004) N=(580,19488,19068 2259900)
[epoch_0]_22601  loss=3.430357 |g|=0.365	lr=7.10e-04 | 51.5%@S19  T=4.21s eta=1d 20:57:02 | 73.6K token/s | 
[epoch_0]_22611  loss=3.449531 |g|=0.37	lr=7.10e-04 | 52.3%@S19  T=1.03s eta=10:59:37 | 73.9K token/s | 
[epoch_0]_22621  loss=3.398998 |g|=0.395	lr=7.10e-04 | 53.1%@S19  T=1.04s eta=11:03:32 | 74.2K token/s | 
[epoch_0]_22631  loss=3.434600 |g|=0.389	lr=7.09e-04 | 53.9%@S19  T=1.04s eta=11:08:13 | 74.4K token/s | 
[epoch_0]_22641  loss=3.459880 |g|=0.358	lr=7.09e-04 | 54.8%@S19  T=1.01s eta=10:46:52 | 74.7K token/s | 
[epoch_0]_22651  loss=3.413421 |g|=0.387	lr=7.09e-04 | 55.6%@S19  T=1.03s eta=10:56:38 | 75.0K token/s | 
[epoch_0]_22661  loss=3.397427 |g|=0.398	lr=7.09e-04 | 56.4%@S19  T=1.04s eta=11:01:59 | 75.2K token/s | 
[epoch_0]_22671  loss=3.398406 |g|=0.328	lr=7.08e-04 | 57.2%@S19  T=1.06s eta=11:19:01 | 75.3K token/s | 
[epoch_0]_22681  loss=3.416056 |g|=0.385	lr=7.08e-04 | 58.0%@S19  T=1.03s eta=11:00:52 | 75.5K token/s | 
[epoch_0]_22691  loss=3.413726 |g|=0.355	lr=7.08e-04 | 58.9%@S19  T=1.03s eta=10:56:08 | 75.7K token/s | 
[Fuyou] head="4" update algorithm=4 t=2.19s
[Section@22700] layer[30-36] tasks=15(nPassBack=0) last_loss=3.47744(-0.0165064) N=(580,19572,19152 2269900)
[epoch_0]_22701  loss=3.403557 |g|=0.351	lr=7.08e-04 | 59.7%@S19  T=1.37s eta=14:34:06 | 74.9K token/s | 
[epoch_0]_22711  loss=3.452890 |g|=0.355	lr=7.07e-04 | 60.5%@S19  T=1.03s eta=10:55:37 | 75.1K token/s | 
[epoch_0]_22721  loss=3.409111 |g|=0.359	lr=7.07e-04 | 61.3%@S19  T=1.02s eta=10:51:02 | 75.4K token/s | 
[epoch_0]_22731  loss=3.448811 |g|=0.396	lr=7.07e-04 | 62.1%@S19  T=1.03s eta=10:58:37 | 75.6K token/s | 
[epoch_0]_22741  loss=3.384262 |g|=0.374	lr=7.07e-04 | 62.9%@S19  T=1.06s eta=11:13:27 | 75.7K token/s | 
[epoch_0]_22751  loss=3.469835 |g|=0.374	lr=7.07e-04 | 63.8%@S19  T=1.03s eta=10:55:15 | 75.9K token/s | 
[epoch_0]_22761  loss=3.447266 |g|=0.388	lr=7.06e-04 | 64.6%@S19  T=1.02s eta=10:52:01 | 76.1K token/s | 
[epoch_0]_22771  loss=3.425014 |g|=0.361	lr=7.06e-04 | 65.4%@S19  T=1.04s eta=11:03:23 | 76.3K token/s | 
[epoch_0]_22781  loss=3.432972 |g|=0.336	lr=7.06e-04 | 66.2%@S19  T=1.05s eta=11:10:23 | 76.3K token/s | 
[epoch_0]_22791  loss=3.385501 |g|=0.371	lr=7.06e-04 | 67.0%@S19  T=1.01s eta=10:45:28 | 76.6K token/s | 
[Fuyou] head="5" update algorithm=4 t=2.03s
[eval] 
	 Loss@"edu_fineweb1B"=3.447(-0.0016) nBranch=1 nToken=4.01M best=3.4451(112) E2T=-0.031 T=13.4827(0)s x=0
	#3.44675±0.1081 tps=298K(4.01408M) a=[3.26796,3.72803] T=13.4827(sec)
[Section@22800] layer[0-6] tasks=15(nPassBack=0) last_loss=3.47771(0.0402799) N=(580,19656,19236 2279900)
[epoch_0]_22801  loss=3.447602 |g|=0.337	lr=7.05e-04 | 67.9%@S19  T=4.15s eta=1d 20:06:15 | 73.7K token/s | 
[epoch_0]_22811  loss=3.379972 |g|=0.382	lr=7.05e-04 | 68.7%@S19  T=1.06s eta=11:12:35 | 73.9K token/s | 
[epoch_0]_22821  loss=3.559644 |g|=0.4	lr=7.05e-04 | 69.5%@S19  T=1.06s eta=11:13:47 | 74.1K token/s | 
[epoch_0]_22831  loss=3.408459 |g|=0.385	lr=7.05e-04 | 70.3%@S19  T=1.02s eta=10:51:53 | 74.4K token/s | 
[epoch_0]_22841  loss=3.463451 |g|=0.356	lr=7.04e-04 | 71.1%@S19  T=1.04s eta=11:01:23 | 74.6K token/s | 
[epoch_0]_22851  loss=3.483283 |g|=0.381	lr=7.04e-04 | 72.0%@S19  T=1.05s eta=11:06:25 | 74.8K token/s | 
[epoch_0]_22861  loss=3.377506 |g|=0.404	lr=7.04e-04 | 72.8%@S19  T=1.02s eta=10:50:03 | 75.1K token/s | 
[epoch_0]_22871  loss=3.408920 |g|=0.365	lr=7.04e-04 | 73.6%@S19  T=1.02s eta=10:50:09 | 75.3K token/s | 
[epoch_0]_22881  loss=3.472613 |g|=0.373	lr=7.03e-04 | 74.4%@S19  T=1.03s eta=10:57:02 | 75.5K token/s | 
[epoch_0]_22891  loss=3.512223 |g|=0.364	lr=7.03e-04 | 75.2%@S19  T=1.07s eta=11:22:38 | 75.6K token/s | 
[Fuyou] head="0" update algorithm=4 t=2.19s
[Section@22900] layer[6-12] tasks=15(nPassBack=0) last_loss=3.38197(0.069705) N=(580,19740,19320 2289900)
[epoch_0]_22901  loss=3.395221 |g|=0.374	lr=7.03e-04 | 76.1%@S19  T=1.45s eta=15:20:12 | 74.6K token/s | 
[epoch_0]_22911  loss=3.401722 |g|=0.366	lr=7.03e-04 | 76.9%@S19  T=1.02s eta=10:48:26 | 74.9K token/s | 
[epoch_0]_22921  loss=3.388245 |g|=0.348	lr=7.03e-04 | 77.7%@S19  T=1.06s eta=11:10:40 | 75.0K token/s | 
[epoch_0]_22931  loss=3.418612 |g|=0.359	lr=7.02e-04 | 78.5%@S19  T=1.02s eta=10:48:38 | 75.3K token/s | 
[epoch_0]_22941  loss=3.499291 |g|=0.342	lr=7.02e-04 | 79.3%@S19  T=1.03s eta=10:53:58 | 75.5K token/s | 
[epoch_0]_22951  loss=3.408672 |g|=0.352	lr=7.02e-04 | 80.2%@S19  T=1.02s eta=10:48:51 | 75.7K token/s | 
[epoch_0]_22961  loss=3.412677 |g|=0.356	lr=7.02e-04 | 81.0%@S19  T=1.05s eta=11:08:53 | 75.8K token/s | 
[epoch_0]_22971  loss=3.502626 |g|=0.379	lr=7.01e-04 | 81.8%@S19  T=1.02s eta=10:48:22 | 76.0K token/s | 
[epoch_0]_22981  loss=3.397078 |g|=0.372	lr=7.01e-04 | 82.6%@S19  T=1.03s eta=10:50:25 | 76.2K token/s | 
[epoch_0]_22991  loss=3.439550 |g|=0.361	lr=7.01e-04 | 83.4%@S19  T=1.05s eta=11:06:18 | 76.3K token/s | 
[Fuyou] head="1" update algorithm=4 t=2.08s
[eval] 
	 Loss@"edu_fineweb1B"=3.446(0.0011) nBranch=1 nToken=4.01M best=3.4451(112) E2T=0.0304 T=13.497(0)s x=0
	#3.4456±0.1079 tps=297K(4.01408M) a=[3.26445,3.73052] T=13.497(sec)
[Section@23000] layer[12-18] tasks=15(nPassBack=0) last_loss=3.41519(0.0543461) N=(580,19824,19404 2299900)
[epoch_0]_23001  loss=3.463537 |g|=0.369	lr=7.01e-04 | 84.2%@S19  T=4.14s eta=1d 19:45:54 | 73.5K token/s | 
[epoch_0]_23011  loss=3.452991 |g|=0.338	lr=7.00e-04 | 85.1%@S19  T=1.03s eta=10:52:37 | 73.8K token/s | 
[epoch_0]_23021  loss=3.360583 |g|=0.371	lr=7.00e-04 | 85.9%@S19  T=1.03s eta=10:53:01 | 74.1K token/s | 
[epoch_0]_23031  loss=3.507458 |g|=0.374	lr=7.00e-04 | 86.7%@S19  T=1.02s eta=10:47:45 | 74.4K token/s | 
[epoch_0]_23041  loss=3.393312 |g|=0.367	lr=7.00e-04 | 87.5%@S19  T=1.03s eta=10:51:18 | 74.6K token/s | 
[epoch_0]_23051  loss=3.486649 |g|=0.338	lr=6.99e-04 | 88.3%@S19  T=1.02s eta=10:48:08 | 74.9K token/s | 
[epoch_0]_23061  loss=3.423300 |g|=0.348	lr=6.99e-04 | 89.2%@S19  T=1.04s eta=10:56:50 | 75.1K token/s | 
[epoch_0]_23071  loss=3.482696 |g|=0.343	lr=6.99e-04 | 90.0%@S19  T=1.05s eta=11:02:05 | 75.3K token/s | 
[epoch_0]_23081  loss=3.504785 |g|=0.357	lr=6.99e-04 | 90.8%@S19  T=1.02s eta=10:42:23 | 75.5K token/s | 
[epoch_0]_23091  loss=3.434216 |g|=0.345	lr=6.99e-04 | 91.6%@S19  T=1.02s eta=10:45:08 | 75.8K token/s | 
[Fuyou] head="2" update algorithm=4 t=2.10s
[Section@23100] layer[18-24] tasks=15(nPassBack=0) last_loss=3.36888(0.0676074) N=(580,19908,19488 2309900)
[epoch_0]_23101  loss=3.442006 |g|=0.34	lr=6.98e-04 | 92.4%@S19  T=1.40s eta=14:42:16 | 74.9K token/s | 
[epoch_0]_23111  loss=3.523900 |g|=0.379	lr=6.98e-04 | 93.3%@S19  T=1.03s eta=10:48:10 | 75.2K token/s | 
[epoch_0]_23121  loss=3.409532 |g|=0.361	lr=6.98e-04 | 94.1%@S19  T=1.02s eta=10:44:04 | 75.4K token/s | 
[epoch_0]_23131  loss=3.447093 |g|=0.337	lr=6.98e-04 | 94.9%@S19  T=1.03s eta=10:52:04 | 75.6K token/s | 
[epoch_0]_23141  loss=3.424775 |g|=0.371	lr=6.97e-04 | 95.7%@S19  T=1.03s eta=10:52:29 | 75.8K token/s | 
[epoch_0]_23151  loss=3.353288 |g|=0.417	lr=6.97e-04 | 96.5%@S19  T=1.05s eta=11:04:15 | 75.9K token/s | 
[epoch_0]_23161  loss=3.457612 |g|=0.37	lr=6.97e-04 | 97.4%@S19  T=1.03s eta=10:49:47 | 76.1K token/s | 
[epoch_0]_23171  loss=3.468408 |g|=0.348	lr=6.97e-04 | 98.2%@S19  T=1.02s eta=10:46:21 | 76.3K token/s | 
[epoch_0]_23181  loss=3.455838 |g|=0.328	lr=6.96e-04 | 99.0%@S19  T=1.04s eta=10:56:23 | 76.4K token/s | 
[epoch_0]_23191  loss=3.486011 |g|=0.373	lr=6.96e-04 | 99.8%@S19  T=1.02s eta=10:44:21 | 76.6K token/s | 
[epoch_0]_23193  loss=3.404625 |g|=0.338	lr=6.96e-04 | 100.0%@S19  T=1.03s eta=10:50:58 | 76.7K token/s | 
-------- End of shard_19@"./Datasets/edu_fineweb1B/edu_fineweb_train_000472.bin"-------- 
[shard-20]@"./Datasets/edu_fineweb1B/edu_fineweb_train_000473.bin": tokens=100(M) nShardSamples=1220(1953120) 
[Fuyou] head="3" update algorithm=4 t=2.07s
[eval] 
	 Loss@"edu_fineweb1B"=3.443(0.003) nBranch=1 nToken=4.01M best=3.4456(114) E2T=0.0171 T=13.5024(0)s x=0
	#3.44261±0.1074 tps=297K(4.01408M) a=[3.26194,3.72478] T=13.5024(sec)
[Section@23200] layer[24-30] tasks=15(nPassBack=0) last_loss=3.42553(0.0206757) N=(580,19992,19572 2319900)
[epoch_0]_23201  loss=3.450731 |g|=0.353	lr=6.96e-04 | 0.6%@S20  T=4.18s eta=1d 19:54:35 | 73.9K token/s | 
[epoch_0]_23211  loss=3.440300 |g|=0.381	lr=6.96e-04 | 1.5%@S20  T=1.02s eta=10:45:33 | 74.2K token/s | 
[epoch_0]_23221  loss=3.393241 |g|=0.387	lr=6.95e-04 | 2.3%@S20  T=1.06s eta=11:05:02 | 74.4K token/s | 
[epoch_0]_23231  loss=3.528324 |g|=0.358	lr=6.95e-04 | 3.1%@S20  T=1.04s eta=10:56:15 | 74.6K token/s | 
[epoch_0]_23241  loss=3.438845 |g|=0.384	lr=6.95e-04 | 3.9%@S20  T=1.03s eta=10:46:08 | 74.8K token/s | 
[epoch_0]_23251  loss=3.382687 |g|=0.37	lr=6.95e-04 | 4.7%@S20  T=1.03s eta=10:46:26 | 75.1K token/s | 
[epoch_0]_23261  loss=3.444185 |g|=0.408	lr=6.94e-04 | 5.5%@S20  T=1.05s eta=11:03:16 | 75.2K token/s | 
[epoch_0]_23271  loss=3.429317 |g|=0.401	lr=6.94e-04 | 6.4%@S20  T=1.03s eta=10:48:37 | 75.4K token/s | 
[epoch_0]_23281  loss=3.512155 |g|=0.368	lr=6.94e-04 | 7.2%@S20  T=1.03s eta=10:48:21 | 75.6K token/s | 
[epoch_0]_23291  loss=3.414844 |g|=0.362	lr=6.94e-04 | 8.0%@S20  T=1.02s eta=10:44:01 | 75.9K token/s | 
[Fuyou] head="4" update algorithm=4 t=2.10s
[Section@23300] layer[30-36] tasks=15(nPassBack=0) last_loss=3.49436(-0.0169106) N=(580,20076,19656 2329900)
[epoch_0]_23301  loss=3.460948 |g|=0.345	lr=6.94e-04 | 8.8%@S20  T=1.33s eta=13:55:58 | 75.1K token/s | 
[epoch_0]_23311  loss=3.439555 |g|=0.368	lr=6.93e-04 | 9.6%@S20  T=1.02s eta=10:43:42 | 75.4K token/s | 
[epoch_0]_23321  loss=3.452232 |g|=0.357	lr=6.93e-04 | 10.5%@S20  T=1.08s eta=11:16:28 | 75.4K token/s | 
[epoch_0]_23331  loss=3.421079 |g|=0.371	lr=6.93e-04 | 11.3%@S20  T=1.10s eta=11:31:01 | 75.4K token/s | 
[epoch_0]_23341  loss=3.380896 |g|=0.374	lr=6.93e-04 | 12.1%@S20  T=1.02s eta=10:43:52 | 75.6K token/s | 
[epoch_0]_23351  loss=3.443168 |g|=0.382	lr=6.92e-04 | 12.9%@S20  T=1.03s eta=10:45:52 | 75.8K token/s | 
[epoch_0]_23361  loss=3.420816 |g|=0.341	lr=6.92e-04 | 13.7%@S20  T=1.04s eta=10:50:44 | 76.0K token/s | 
[epoch_0]_23371  loss=3.428904 |g|=0.398	lr=6.92e-04 | 14.6%@S20  T=1.05s eta=11:00:34 | 76.1K token/s | 
[epoch_0]_23381  loss=3.460014 |g|=0.335	lr=6.92e-04 | 15.4%@S20  T=1.03s eta=10:46:16 | 76.2K token/s | 
[epoch_0]_23391  loss=3.451571 |g|=0.345	lr=6.91e-04 | 16.2%@S20  T=1.02s eta=10:42:23 | 76.4K token/s | 
[Fuyou] head="5" update algorithm=4 t=2.11s
[eval] 
	 Loss@"edu_fineweb1B"=3.430(0.013) nBranch=1 nToken=4.01M best=3.4426(115) E2T=-0.0141 T=13.5007(0)s x=0
	#3.42984±0.1074 tps=297K(4.01408M) a=[3.2452,3.71199] T=13.5007(sec)
[Section@23400] layer[0-6] tasks=15(nPassBack=0) last_loss=3.44391(0.0337954) N=(580,20160,19740 2339900)
[epoch_0]_23401  loss=3.438364 |g|=0.348	lr=6.91e-04 | 17.0%@S20  T=4.17s eta=1d 19:34:50 | 73.6K token/s | 
[epoch_0]_23411  loss=3.378442 |g|=0.328	lr=6.91e-04 | 17.8%@S20  T=1.04s eta=10:49:07 | 73.9K token/s | 
[epoch_0]_23421  loss=3.532688 |g|=0.352	lr=6.91e-04 | 18.7%@S20  T=1.04s eta=10:50:02 | 74.1K token/s | 
[epoch_0]_23431  loss=3.408398 |g|=0.348	lr=6.90e-04 | 19.5%@S20  T=1.06s eta=11:03:12 | 74.3K token/s | 
[epoch_0]_23441  loss=3.443245 |g|=0.417	lr=6.90e-04 | 20.3%@S20  T=1.04s eta=10:49:52 | 74.5K token/s | 
[epoch_0]_23451  loss=3.384719 |g|=0.331	lr=6.90e-04 | 21.1%@S20  T=1.03s eta=10:43:22 | 74.8K token/s | 
[epoch_0]_23461  loss=3.392547 |g|=0.359	lr=6.90e-04 | 21.9%@S20  T=1.04s eta=10:53:05 | 75.0K token/s | 
[epoch_0]_23471  loss=3.443959 |g|=0.352	lr=6.89e-04 | 22.8%@S20  T=1.05s eta=10:54:31 | 75.1K token/s | 
[epoch_0]_23481  loss=3.452116 |g|=0.358	lr=6.89e-04 | 23.6%@S20  T=1.03s eta=10:44:11 | 75.4K token/s | 
[epoch_0]_23491  loss=3.427521 |g|=0.425	lr=6.89e-04 | 24.4%@S20  T=1.02s eta=10:37:14 | 75.6K token/s | 
[Fuyou] head="0" update algorithm=4 t=2.12s
[Section@23500] layer[6-12] tasks=15(nPassBack=0) last_loss=3.46504(-0.0830679) N=(580,20244,19824 2349900)
[epoch_0]_23501  loss=3.314126 |g|=0.392	lr=6.89e-04 | 25.2%@S20  T=1.50s eta=15:38:54 | 74.6K token/s | 
[epoch_0]_23511  loss=3.376147 |g|=0.353	lr=6.89e-04 | 26.0%@S20  T=1.01s eta=10:32:16 | 74.9K token/s | 
[epoch_0]_23521  loss=3.421681 |g|=0.379	lr=6.88e-04 | 26.8%@S20  T=1.03s eta=10:44:43 | 75.1K token/s | 
[epoch_0]_23531  loss=3.403346 |g|=0.352	lr=6.88e-04 | 27.7%@S20  T=1.02s eta=10:40:14 | 75.4K token/s | 
[epoch_0]_23541  loss=3.493693 |g|=0.387	lr=6.88e-04 | 28.5%@S20  T=1.04s eta=10:48:08 | 75.5K token/s | 
[epoch_0]_23551  loss=3.405698 |g|=0.392	lr=6.88e-04 | 29.3%@S20  T=1.07s eta=11:06:31 | 75.6K token/s | 
[epoch_0]_23561  loss=3.402730 |g|=0.368	lr=6.87e-04 | 30.1%@S20  T=1.02s eta=10:39:19 | 75.8K token/s | 
[epoch_0]_23571  loss=3.363091 |g|=0.346	lr=6.87e-04 | 30.9%@S20  T=1.03s eta=10:44:21 | 76.0K token/s | 
[epoch_0]_23581  loss=3.346190 |g|=0.388	lr=6.87e-04 | 31.8%@S20  T=1.03s eta=10:43:44 | 76.2K token/s | 
[epoch_0]_23591  loss=3.431858 |g|=0.399	lr=6.87e-04 | 32.6%@S20  T=1.08s eta=11:10:59 | 76.2K token/s | 
[Fuyou] head="1" update algorithm=4 t=2.10s
[eval] 
	 Loss@"edu_fineweb1B"=3.426(0.0043) nBranch=1 nToken=4.01M best=3.4298(116) E2T=0.0592 T=13.5016(0)s x=0
	#3.42557±0.1066 tps=297K(4.01408M) a=[3.24493,3.70324] T=13.5016(sec)
[Section@23600] layer[12-18] tasks=15(nPassBack=0) last_loss=3.3664(0.0487859) N=(580,20328,19908 2359900)
[epoch_0]_23601  loss=3.440792 |g|=0.375	lr=6.86e-04 | 33.4%@S20  T=4.17s eta=1d 19:18:57 | 73.4K token/s | 
[epoch_0]_23611  loss=3.424424 |g|=0.376	lr=6.86e-04 | 34.2%@S20  T=1.02s eta=10:38:38 | 73.7K token/s | 
[epoch_0]_23621  loss=3.418666 |g|=0.367	lr=6.86e-04 | 35.0%@S20  T=1.03s eta=10:39:15 | 74.0K token/s | 
[epoch_0]_23631  loss=3.505335 |g|=0.409	lr=6.86e-04 | 35.9%@S20  T=1.06s eta=11:00:37 | 74.2K token/s | 
[epoch_0]_23641  loss=3.358679 |g|=0.357	lr=6.85e-04 | 36.7%@S20  T=1.02s eta=10:37:06 | 74.5K token/s | 
[epoch_0]_23651  loss=3.408334 |g|=0.359	lr=6.85e-04 | 37.5%@S20  T=1.02s eta=10:37:48 | 74.7K token/s | 
[epoch_0]_23661  loss=3.461544 |g|=0.346	lr=6.85e-04 | 38.3%@S20  T=1.04s eta=10:49:34 | 74.9K token/s | 
[epoch_0]_23671  loss=3.363564 |g|=0.371	lr=6.85e-04 | 39.1%@S20  T=1.07s eta=11:08:28 | 75.0K token/s | 
[epoch_0]_23681  loss=3.405390 |g|=0.36	lr=6.84e-04 | 40.0%@S20  T=1.03s eta=10:42:25 | 75.2K token/s | 
[epoch_0]_23691  loss=3.395967 |g|=0.354	lr=6.84e-04 | 40.8%@S20  T=1.02s eta=10:35:51 | 75.5K token/s | 
[Fuyou] head="2" update algorithm=4 t=2.09s
[Section@23700] layer[18-24] tasks=15(nPassBack=0) last_loss=3.42096(-0.0520794) N=(580,20412,19992 2369900)
[epoch_0]_23701  loss=3.423365 |g|=0.358	lr=6.84e-04 | 41.6%@S20  T=1.49s eta=15:25:32 | 74.4K token/s | 
[epoch_0]_23711  loss=3.435759 |g|=0.373	lr=6.84e-04 | 42.4%@S20  T=1.04s eta=10:46:19 | 74.7K token/s | 
[epoch_0]_23721  loss=3.396651 |g|=0.369	lr=6.83e-04 | 43.2%@S20  T=1.02s eta=10:33:13 | 75.0K token/s | 
[epoch_0]_23731  loss=3.416629 |g|=0.378	lr=6.83e-04 | 44.0%@S20  T=1.02s eta=10:35:00 | 75.2K token/s | 
[epoch_0]_23741  loss=3.302607 |g|=0.365	lr=6.83e-04 | 44.9%@S20  T=1.03s eta=10:41:39 | 75.4K token/s | 
[epoch_0]_23751  loss=3.400544 |g|=0.353	lr=6.83e-04 | 45.7%@S20  T=1.08s eta=11:08:59 | 75.5K token/s | 
[epoch_0]_23761  loss=3.384614 |g|=0.399	lr=6.83e-04 | 46.5%@S20  T=1.05s eta=10:51:48 | 75.6K token/s | 
[epoch_0]_23771  loss=3.449222 |g|=0.35	lr=6.82e-04 | 47.3%@S20  T=1.03s eta=10:41:25 | 75.8K token/s | 
[epoch_0]_23781  loss=3.448710 |g|=0.41	lr=6.82e-04 | 48.1%@S20  T=1.05s eta=10:48:52 | 75.9K token/s | 
[epoch_0]_23791  loss=3.424624 |g|=0.382	lr=6.82e-04 | 49.0%@S20  T=1.06s eta=10:57:55 | 76.0K token/s | 
[Fuyou] head="3" update algorithm=4 t=2.02s
[eval] 
	 Loss@"edu_fineweb1B"=3.425(0.00056) nBranch=1 nToken=4.01M best=3.4256(117) E2T=0.0772 T=13.4967(0)s x=0
	#3.42501±0.1071 tps=297K(4.01408M) a=[3.23761,3.70182] T=13.4967(sec)
[Section@23800] layer[24-30] tasks=15(nPassBack=0) last_loss=3.34777(0.0777574) N=(580,20496,20076 2379900)
[epoch_0]_23801  loss=3.403860 |g|=0.335	lr=6.82e-04 | 49.8%@S20  T=4.15s eta=1d 18:58:05 | 73.2K token/s | 
[epoch_0]_23811  loss=3.410097 |g|=0.402	lr=6.81e-04 | 50.6%@S20  T=1.03s eta=10:37:03 | 73.5K token/s | 
[epoch_0]_23821  loss=3.441467 |g|=0.376	lr=6.81e-04 | 51.4%@S20  T=1.02s eta=10:34:58 | 73.8K token/s | 
[epoch_0]_23831  loss=3.397749 |g|=0.374	lr=6.81e-04 | 52.2%@S20  T=1.04s eta=10:46:47 | 74.1K token/s | 
[epoch_0]_23841  loss=3.349344 |g|=0.364	lr=6.81e-04 | 53.1%@S20  T=1.03s eta=10:40:23 | 74.3K token/s | 
[epoch_0]_23851  loss=3.367314 |g|=0.368	lr=6.80e-04 | 53.9%@S20  T=1.02s eta=10:32:46 | 74.6K token/s | 
[epoch_0]_23861  loss=3.399526 |g|=0.41	lr=6.80e-04 | 54.7%@S20  T=1.02s eta=10:33:38 | 74.9K token/s | 
[epoch_0]_23871  loss=3.394243 |g|=0.384	lr=6.80e-04 | 55.5%@S20  T=1.03s eta=10:39:41 | 75.1K token/s | 
[epoch_0]_23881  loss=3.311447 |g|=0.379	lr=6.80e-04 | 56.3%@S20  T=1.06s eta=10:57:36 | 75.2K token/s | 
[epoch_0]_23891  loss=3.413952 |g|=0.361	lr=6.79e-04 | 57.2%@S20  T=1.02s eta=10:31:09 | 75.5K token/s | 
[Fuyou] head="4" update algorithm=4 t=2.11s
[Section@23900] layer[30-36] tasks=15(nPassBack=0) last_loss=3.44878(0.045578) N=(580,20580,20160 2389900)
[epoch_0]_23901  loss=3.440981 |g|=0.335	lr=6.79e-04 | 58.0%@S20  T=1.53s eta=15:48:25 | 74.4K token/s | 
[epoch_0]_23911  loss=3.388174 |g|=0.357	lr=6.79e-04 | 58.8%@S20  T=1.04s eta=10:44:15 | 74.6K token/s | 
[epoch_0]_23921  loss=3.416901 |g|=0.352	lr=6.79e-04 | 59.6%@S20  T=1.08s eta=11:10:07 | 74.6K token/s | 
[epoch_0]_23931  loss=3.368909 |g|=0.384	lr=6.78e-04 | 60.4%@S20  T=1.01s eta=10:23:22 | 75.0K token/s | 
[epoch_0]_23941  loss=3.430189 |g|=0.365	lr=6.78e-04 | 61.3%@S20  T=1.03s eta=10:34:27 | 75.2K token/s | 
[epoch_0]_23951  loss=3.381148 |g|=0.399	lr=6.78e-04 | 62.1%@S20  T=1.03s eta=10:37:21 | 75.4K token/s | 
[epoch_0]_23961  loss=3.386821 |g|=0.368	lr=6.78e-04 | 62.9%@S20  T=1.07s eta=11:01:34 | 75.5K token/s | 
[epoch_0]_23971  loss=3.357396 |g|=0.37	lr=6.77e-04 | 63.7%@S20  T=1.03s eta=10:36:36 | 75.7K token/s | 
[epoch_0]_23981  loss=3.493781 |g|=0.379	lr=6.77e-04 | 64.5%@S20  T=1.03s eta=10:38:51 | 75.9K token/s | 
[epoch_0]_23991  loss=3.406411 |g|=0.384	lr=6.77e-04 | 65.3%@S20  T=1.02s eta=10:32:44 | 76.1K token/s | 
[Fuyou] head="5" update algorithm=4 t=2.09s
[eval] 
	 Loss@"edu_fineweb1B"=3.418(0.0071) nBranch=1 nToken=4.01M best=3.4250(118) E2T=0.027 T=13.489(0)s x=0
	#3.41794±0.1070 tps=298K(4.01408M) a=[3.23612,3.70006] T=13.489(sec)
[Section@24000] layer[0-6] tasks=15(nPassBack=0) last_loss=3.39097(0.0529392) N=(580,20664,20244 2399900)
[epoch_0]_24001  loss=3.417143 |g|=0.338	lr=6.77e-04 | 66.2%@S20  T=4.15s eta=1d 18:40:47 | 73.2K token/s | 
[epoch_0]_24011  loss=3.434463 |g|=0.383	lr=6.77e-04 | 67.0%@S20  T=1.03s eta=10:36:40 | 73.5K token/s | 
[epoch_0]_24021  loss=3.414386 |g|=0.39	lr=6.76e-04 | 67.8%@S20  T=1.03s eta=10:34:18 | 73.9K token/s | 
[epoch_0]_24031  loss=3.361042 |g|=0.4	lr=6.76e-04 | 68.6%@S20  T=1.03s eta=10:32:50 | 74.2K token/s | 
[epoch_0]_24041  loss=3.436341 |g|=0.344	lr=6.76e-04 | 69.4%@S20  T=1.03s eta=10:33:01 | 74.4K token/s | 
[epoch_0]_24051  loss=3.419105 |g|=0.391	lr=6.76e-04 | 70.3%@S20  T=1.03s eta=10:34:25 | 74.7K token/s | 
[epoch_0]_24061  loss=3.447359 |g|=0.391	lr=6.75e-04 | 71.1%@S20  T=1.04s eta=10:43:35 | 74.9K token/s | 
[epoch_0]_24071  loss=3.458042 |g|=0.381	lr=6.75e-04 | 71.9%@S20  T=1.06s eta=10:55:04 | 75.0K token/s | 
[epoch_0]_24081  loss=3.430157 |g|=0.356	lr=6.75e-04 | 72.7%@S20  T=1.03s eta=10:32:31 | 75.2K token/s | 
[epoch_0]_24091  loss=3.433729 |g|=0.348	lr=6.75e-04 | 73.5%@S20  T=1.03s eta=10:34:07 | 75.4K token/s | 
[Fuyou] head="0" update algorithm=4 t=2.09s
[Section@24100] layer[6-12] tasks=15(nPassBack=0) last_loss=3.4249(0.0401371) N=(580,20748,20328 2409900)
[epoch_0]_24101  loss=3.393153 |g|=0.349	lr=6.74e-04 | 74.4%@S20  T=1.31s eta=13:26:04 | 74.8K token/s | 
[epoch_0]_24111  loss=3.364272 |g|=0.364	lr=6.74e-04 | 75.2%@S20  T=1.04s eta=10:42:02 | 75.0K token/s | 
[epoch_0]_24121  loss=3.409341 |g|=0.365	lr=6.74e-04 | 76.0%@S20  T=1.02s eta=10:25:26 | 75.3K token/s | 
[epoch_0]_24131  loss=3.381418 |g|=0.365	lr=6.74e-04 | 76.8%@S20  T=1.03s eta=10:35:24 | 75.5K token/s | 
[epoch_0]_24141  loss=3.459078 |g|=0.364	lr=6.73e-04 | 77.6%@S20  T=1.04s eta=10:40:38 | 75.6K token/s | 
[epoch_0]_24151  loss=3.393247 |g|=0.393	lr=6.73e-04 | 78.5%@S20  T=1.05s eta=10:48:07 | 75.7K token/s | 
[epoch_0]_24161  loss=3.377510 |g|=0.376	lr=6.73e-04 | 79.3%@S20  T=1.02s eta=10:24:46 | 76.0K token/s | 
[epoch_0]_24171  loss=3.464680 |g|=0.373	lr=6.73e-04 | 80.1%@S20  T=1.03s eta=10:30:35 | 76.2K token/s | 
[epoch_0]_24181  loss=3.445711 |g|=0.394	lr=6.72e-04 | 80.9%@S20  T=1.03s eta=10:35:06 | 76.3K token/s | 
[epoch_0]_24191  loss=3.403417 |g|=0.369	lr=6.72e-04 | 81.7%@S20  T=1.06s eta=10:51:33 | 76.4K token/s | 
[Fuyou] head="1" update algorithm=4 t=2.10s
[eval] 
	 Loss@"edu_fineweb1B"=3.416(0.0015) nBranch=1 nToken=4.01M best=3.4179(119) E2T=-0.0102 T=13.5017(0)s x=0
	#3.4164±0.1060 tps=297K(4.01408M) a=[3.23473,3.69367] T=13.5017(sec)
[Section@24200] layer[12-18] tasks=15(nPassBack=0) last_loss=3.42659(-0.0601914) N=(580,20832,20412 2419900)
[epoch_0]_24201  loss=3.384138 |g|=0.336	lr=6.72e-04 | 82.6%@S20  T=4.17s eta=1d 18:37:11 | 73.5K token/s | 
[epoch_0]_24211  loss=3.381537 |g|=0.367	lr=6.72e-04 | 83.4%@S20  T=1.02s eta=10:25:46 | 73.9K token/s | 
[epoch_0]_24221  loss=3.379078 |g|=0.384	lr=6.71e-04 | 84.2%@S20  T=1.04s eta=10:35:12 | 74.1K token/s | 
[epoch_0]_24231  loss=3.427285 |g|=0.358	lr=6.71e-04 | 85.0%@S20  T=1.03s eta=10:33:27 | 74.4K token/s | 
[epoch_0]_24241  loss=3.404688 |g|=0.354	lr=6.71e-04 | 85.8%@S20  T=1.03s eta=10:28:44 | 74.7K token/s | 
[epoch_0]_24251  loss=3.386820 |g|=0.374	lr=6.71e-04 | 86.6%@S20  T=1.04s eta=10:39:05 | 74.9K token/s | 
[epoch_0]_24261  loss=3.410102 |g|=0.391	lr=6.70e-04 | 87.5%@S20  T=1.04s eta=10:38:37 | 75.0K token/s | 
[epoch_0]_24271  loss=3.416370 |g|=0.374	lr=6.70e-04 | 88.3%@S20  T=1.06s eta=10:47:41 | 75.2K token/s | 
[epoch_0]_24281  loss=3.463265 |g|=0.378	lr=6.70e-04 | 89.1%@S20  T=1.03s eta=10:30:32 | 75.4K token/s | 
[epoch_0]_24291  loss=3.395535 |g|=0.361	lr=6.70e-04 | 89.9%@S20  T=1.02s eta=10:25:34 | 75.6K token/s | 
[Fuyou] head="2" update algorithm=4 t=2.04s
[Section@24300] layer[18-24] tasks=15(nPassBack=0) last_loss=3.36558(0.0553865) N=(580,20916,20496 2429900)
[epoch_0]_24301  loss=3.439004 |g|=0.345	lr=6.69e-04 | 90.7%@S20  T=1.41s eta=14:23:26 | 74.8K token/s | 
[epoch_0]_24311  loss=3.355865 |g|=0.409	lr=6.69e-04 | 91.6%@S20  T=1.04s eta=10:35:35 | 75.0K token/s | 
[epoch_0]_24321  loss=3.417470 |g|=0.389	lr=6.69e-04 | 92.4%@S20  T=1.03s eta=10:29:41 | 75.2K token/s | 
[epoch_0]_24331  loss=3.362400 |g|=0.378	lr=6.69e-04 | 93.2%@S20  T=1.03s eta=10:27:11 | 75.4K token/s | 
[epoch_0]_24341  loss=3.404956 |g|=0.406	lr=6.69e-04 | 94.0%@S20  T=1.03s eta=10:32:57 | 75.6K token/s | 
[epoch_0]_24351  loss=3.364474 |g|=0.35	lr=6.68e-04 | 94.8%@S20  T=1.09s eta=11:06:15 | 75.6K token/s | 
[epoch_0]_24361  loss=3.378847 |g|=0.36	lr=6.68e-04 | 95.7%@S20  T=1.03s eta=10:30:55 | 75.8K token/s | 
[epoch_0]_24371  loss=3.457571 |g|=0.404	lr=6.68e-04 | 96.5%@S20  T=1.03s eta=10:26:36 | 76.0K token/s | 
[epoch_0]_24381  loss=3.395853 |g|=0.345	lr=6.68e-04 | 97.3%@S20  T=1.05s eta=10:39:41 | 76.1K token/s | 
[epoch_0]_24391  loss=3.401770 |g|=0.384	lr=6.67e-04 | 98.1%@S20  T=1.06s eta=10:49:28 | 76.1K token/s | 
[Fuyou] head="3" update algorithm=4 t=2.14s
[eval] 
	 Loss@"edu_fineweb1B"=3.413(0.003) nBranch=1 nToken=4.01M best=3.4164(120) E2T=0.00979 T=13.5013(0)s x=0
	#3.41338±0.1080 tps=297K(4.01408M) a=[3.22803,3.69286] T=13.5013(sec)
[Section@24400] layer[24-30] tasks=15(nPassBack=0) last_loss=3.40359(-0.0558186) N=(580,21000,20580 2439900)
[epoch_0]_24401  loss=3.340945 |g|=0.335	lr=6.67e-04 | 98.9%@S20  T=4.16s eta=1d 18:20:32 | 73.3K token/s | 
[epoch_0]_24411  loss=3.358631 |g|=0.388	lr=6.67e-04 | 99.8%@S20  T=1.03s eta=10:28:57 | 73.6K token/s | 
[epoch_0]_24413  loss=3.396951 |g|=0.375	lr=6.67e-04 | 99.9%@S20  T=1.04s eta=10:33:36 | 73.9K token/s | 
[epoch_0]_24414  loss=3.454488 |g|=0.413	lr=6.67e-04 | 100.0%@S20  T=1.04s eta=10:32:20 | 74.2K token/s | 
-------- End of shard_20@"./Datasets/edu_fineweb1B/edu_fineweb_train_000473.bin"-------- 
[shard-21]@"./Datasets/edu_fineweb1B/edu_fineweb_train_000474.bin": tokens=100(M) nShardSamples=1220(2050776) 
[epoch_0]_24421  loss=3.464709 |g|=0.373	lr=6.67e-04 | 0.6%@S21  T=1.03s eta=10:29:49 | 74.4K token/s | 
[epoch_0]_24431  loss=3.430047 |g|=0.361	lr=6.66e-04 | 1.4%@S21  T=1.05s eta=10:41:13 | 74.6K token/s | 
[epoch_0]_24441  loss=3.426064 |g|=0.388	lr=6.66e-04 | 2.2%@S21  T=1.01s eta=10:18:38 | 74.9K token/s | 
[epoch_0]_24451  loss=3.413488 |g|=0.412	lr=6.66e-04 | 3.0%@S21  T=1.03s eta=10:28:17 | 75.1K token/s | 
[epoch_0]_24461  loss=3.507219 |g|=0.396	lr=6.66e-04 | 3.9%@S21  T=1.04s eta=10:36:49 | 75.3K token/s | 
[epoch_0]_24471  loss=3.496065 |g|=0.398	lr=6.65e-04 | 4.7%@S21  T=1.06s eta=10:43:17 | 75.4K token/s | 
[epoch_0]_24481  loss=3.452562 |g|=0.364	lr=6.65e-04 | 5.5%@S21  T=1.03s eta=10:26:18 | 75.6K token/s | 
[epoch_0]_24491  loss=3.421902 |g|=0.354	lr=6.65e-04 | 6.3%@S21  T=1.03s eta=10:26:20 | 75.8K token/s | 
[Fuyou] head="4" update algorithm=4 t=2.10s
[Section@24500] layer[30-36] tasks=15(nPassBack=0) last_loss=3.52151(-0.0727353) N=(580,21084,20664 2449900)
[epoch_0]_24501  loss=3.535489 |g|=0.373	lr=6.65e-04 | 7.1%@S21  T=1.30s eta=13:12:35 | 75.2K token/s | 
[epoch_0]_24511  loss=3.469919 |g|=0.381	lr=6.64e-04 | 7.9%@S21  T=1.02s eta=10:20:55 | 75.4K token/s | 
[epoch_0]_24521  loss=3.505127 |g|=0.37	lr=6.64e-04 | 8.8%@S21  T=1.03s eta=10:27:36 | 75.6K token/s | 
[epoch_0]_24531  loss=3.414243 |g|=0.375	lr=6.64e-04 | 9.6%@S21  T=1.07s eta=10:53:40 | 75.7K token/s | 
[epoch_0]_24541  loss=3.496130 |g|=0.386	lr=6.64e-04 | 10.4%@S21  T=1.02s eta=10:20:20 | 75.9K token/s | 
[epoch_0]_24551  loss=3.372202 |g|=0.348	lr=6.63e-04 | 11.2%@S21  T=1.03s eta=10:25:23 | 76.1K token/s | 
[epoch_0]_24561  loss=3.441659 |g|=0.37	lr=6.63e-04 | 12.0%@S21  T=1.03s eta=10:29:04 | 76.2K token/s | 
[epoch_0]_24571  loss=3.492921 |g|=0.366	lr=6.63e-04 | 12.9%@S21  T=1.05s eta=10:35:40 | 76.3K token/s | 
[epoch_0]_24581  loss=3.395119 |g|=0.337	lr=6.63e-04 | 13.7%@S21  T=1.03s eta=10:25:25 | 76.5K token/s | 
[epoch_0]_24591  loss=3.444895 |g|=0.353	lr=6.62e-04 | 14.5%@S21  T=1.03s eta=10:23:42 | 76.7K token/s | 
[Fuyou] head="5" update algorithm=4 t=2.10s
[eval] 
	 Loss@"edu_fineweb1B"=3.419(-0.0058) nBranch=1 nToken=4.01M best=3.4164(120) E2T=0.0152 T=13.4999(0)s x=0
	#3.41915±0.1073 tps=297K(4.01408M) a=[3.23098,3.69996] T=13.4999(sec)
[Section@24600] layer[0-6] tasks=15(nPassBack=0) last_loss=3.40392(-0.0129457) N=(580,21168,20748 2459900)
[epoch_0]_24601  loss=3.430408 |g|=0.344	lr=6.62e-04 | 15.3%@S21  T=4.17s eta=1d 18:11:28 | 73.8K token/s | 
[epoch_0]_24611  loss=3.468002 |g|=0.404	lr=6.62e-04 | 16.1%@S21  T=1.06s eta=10:45:32 | 74.0K token/s | 
[epoch_0]_24621  loss=3.387578 |g|=0.384	lr=6.62e-04 | 17.0%@S21  T=1.02s eta=10:22:02 | 74.3K token/s | 
[epoch_0]_24631  loss=3.445064 |g|=0.394	lr=6.61e-04 | 17.8%@S21  T=1.04s eta=10:33:34 | 74.5K token/s | 
[epoch_0]_24641  loss=3.399679 |g|=0.378	lr=6.61e-04 | 18.6%@S21  T=1.07s eta=10:47:51 | 74.6K token/s | 
[epoch_0]_24651  loss=3.428529 |g|=0.367	lr=6.61e-04 | 19.4%@S21  T=1.06s eta=10:40:05 | 74.7K token/s | 
[epoch_0]_24661  loss=3.434893 |g|=0.352	lr=6.61e-04 | 20.2%@S21  T=1.03s eta=10:25:21 | 75.0K token/s | 
[epoch_0]_24671  loss=3.515991 |g|=0.354	lr=6.60e-04 | 21.1%@S21  T=1.04s eta=10:31:28 | 75.2K token/s | 
[epoch_0]_24681  loss=3.494956 |g|=0.336	lr=6.60e-04 | 21.9%@S21  T=1.06s eta=10:44:05 | 75.3K token/s | 
[epoch_0]_24691  loss=3.407936 |g|=0.366	lr=6.60e-04 | 22.7%@S21  T=1.03s eta=10:22:05 | 75.5K token/s | 
[Fuyou] head="0" update algorithm=4 t=2.08s
[Section@24700] layer[6-12] tasks=15(nPassBack=0) last_loss=3.48111(-0.0562079) N=(580,21252,20832 2469900)
[epoch_0]_24701  loss=3.372014 |g|=0.328	lr=6.60e-04 | 23.5%@S21  T=1.51s eta=15:15:44 | 74.4K token/s | 
[epoch_0]_24711  loss=3.378169 |g|=0.409	lr=6.60e-04 | 24.3%@S21  T=1.02s eta=10:16:03 | 74.7K token/s | 
[epoch_0]_24721  loss=3.467841 |g|=0.367	lr=6.59e-04 | 25.2%@S21  T=1.02s eta=10:19:15 | 75.0K token/s | 
[epoch_0]_24731  loss=3.405354 |g|=0.373	lr=6.59e-04 | 26.0%@S21  T=1.03s eta=10:22:30 | 75.2K token/s | 
[epoch_0]_24741  loss=3.373913 |g|=0.389	lr=6.59e-04 | 26.8%@S21  T=1.03s eta=10:25:03 | 75.4K token/s | 
[epoch_0]_24751  loss=3.495496 |g|=0.415	lr=6.59e-04 | 27.6%@S21  T=1.07s eta=10:47:49 | 75.5K token/s | 
[epoch_0]_24761  loss=3.429867 |g|=0.372	lr=6.58e-04 | 28.4%@S21  T=1.03s eta=10:25:06 | 75.7K token/s | 
[epoch_0]_24771  loss=3.421999 |g|=0.373	lr=6.58e-04 | 29.2%@S21  T=1.03s eta=10:20:58 | 75.9K token/s | 
[epoch_0]_24781  loss=3.423067 |g|=0.365	lr=6.58e-04 | 30.1%@S21  T=1.03s eta=10:25:16 | 76.0K token/s | 
[epoch_0]_24791  loss=3.407063 |g|=0.401	lr=6.58e-04 | 30.9%@S21  T=1.05s eta=10:33:28 | 76.1K token/s | 
[Fuyou] head="1" update algorithm=4 t=2.09s
[eval] 
	 Loss@"edu_fineweb1B"=3.421(-0.0016) nBranch=1 nToken=4.01M best=3.4164(120) E2T=-0.00215 T=13.4921(0)s x=0
	#3.42079±0.1083 tps=298K(4.01408M) a=[3.2378,3.70179] T=13.4921(sec)
[Section@24800] layer[12-18] tasks=15(nPassBack=0) last_loss=3.42293(0.00365901) N=(580,21336,20916 2479900)
[epoch_0]_24801  loss=3.375920 |g|=0.329	lr=6.57e-04 | 31.7%@S21  T=4.16s eta=1d 17:54:23 | 73.3K token/s | 
[epoch_0]_24811  loss=3.427546 |g|=0.378	lr=6.57e-04 | 32.5%@S21  T=1.02s eta=10:17:39 | 73.7K token/s | 
[epoch_0]_24821  loss=3.457398 |g|=0.353	lr=6.57e-04 | 33.3%@S21  T=1.03s eta=10:24:11 | 73.9K token/s | 
[epoch_0]_24831  loss=3.413997 |g|=0.383	lr=6.57e-04 | 34.2%@S21  T=1.07s eta=10:47:04 | 74.1K token/s | 
[epoch_0]_24841  loss=3.392334 |g|=0.358	lr=6.56e-04 | 35.0%@S21  T=1.05s eta=10:34:23 | 74.2K token/s | 
[epoch_0]_24851  loss=3.397930 |g|=0.364	lr=6.56e-04 | 35.8%@S21  T=1.04s eta=10:27:33 | 74.5K token/s | 
[epoch_0]_24861  loss=3.396309 |g|=0.372	lr=6.56e-04 | 36.6%@S21  T=1.06s eta=10:37:42 | 74.6K token/s | 
[epoch_0]_24871  loss=3.455175 |g|=0.342	lr=6.56e-04 | 37.4%@S21  T=1.04s eta=10:25:06 | 74.8K token/s | 
[epoch_0]_24881  loss=3.341585 |g|=0.381	lr=6.55e-04 | 38.3%@S21  T=1.02s eta=10:17:37 | 75.1K token/s | 
[epoch_0]_24891  loss=3.466553 |g|=0.39	lr=6.55e-04 | 39.1%@S21  T=1.02s eta=10:17:21 | 75.3K token/s | 
[Fuyou] head="2" update algorithm=4 t=2.11s
[Section@24900] layer[18-24] tasks=15(nPassBack=0) last_loss=3.42289(-0.0573118) N=(580,21420,21000 2489900)
[epoch_0]_24901  loss=3.500256 |g|=0.339	lr=6.55e-04 | 39.9%@S21  T=1.31s eta=13:11:53 | 74.7K token/s | 
[epoch_0]_24911  loss=3.351343 |g|=0.367	lr=6.55e-04 | 40.7%@S21  T=1.03s eta=10:18:09 | 74.9K token/s | 
[epoch_0]_24921  loss=3.394140 |g|=0.35	lr=6.54e-04 | 41.5%@S21  T=1.03s eta=10:18:47 | 75.2K token/s | 
[epoch_0]_24931  loss=3.469882 |g|=0.386	lr=6.54e-04 | 42.4%@S21  T=1.03s eta=10:21:26 | 75.4K token/s | 
[epoch_0]_24941  loss=3.305737 |g|=0.391	lr=6.54e-04 | 43.2%@S21  T=1.02s eta=10:14:52 | 75.6K token/s | 
[epoch_0]_24951  loss=3.443712 |g|=0.368	lr=6.54e-04 | 44.0%@S21  T=1.07s eta=10:44:00 | 75.7K token/s | 
[epoch_0]_24961  loss=3.436205 |g|=0.341	lr=6.53e-04 | 44.8%@S21  T=1.03s eta=10:16:32 | 75.9K token/s | 
[epoch_0]_24971  loss=3.438479 |g|=0.439	lr=6.53e-04 | 45.6%@S21  T=1.03s eta=10:20:11 | 76.1K token/s | 
[epoch_0]_24981  loss=3.463696 |g|=0.376	lr=6.53e-04 | 46.4%@S21  T=1.03s eta=10:21:26 | 76.2K token/s | 
[epoch_0]_24991  loss=3.467163 |g|=0.381	lr=6.53e-04 | 47.3%@S21  T=1.05s eta=10:28:05 | 76.3K token/s | 
[Fuyou] head="3" update algorithm=4 t=2.09s
[eval] 
	 Loss@"edu_fineweb1B"=3.421(-0.00029) nBranch=1 nToken=4.01M best=3.4164(120) E2T=-0.0586 T=13.4934(0)s x=0
	#3.42107±0.1080 tps=297K(4.01408M) a=[3.23325,3.70313] T=13.4934(sec)
[Section@25000] layer[24-30] tasks=15(nPassBack=0) last_loss=3.47966(-0.0760748) N=(580,21504,21084 2499900)
[epoch_0]_25001  loss=3.400911 |g|=0.371	lr=6.52e-04 | 48.1%@S21  T=4.16s eta=1d 17:41:17 | 73.5K token/s | 
[epoch_0]_25011  loss=3.376493 |g|=0.358	lr=6.52e-04 | 48.9%@S21  T=1.07s eta=10:39:27 | 73.7K token/s | 
[epoch_0]_25021  loss=3.434927 |g|=0.362	lr=6.52e-04 | 49.7%@S21  T=1.04s eta=10:23:54 | 73.9K token/s | 
[epoch_0]_25031  loss=3.471473 |g|=0.371	lr=6.52e-04 | 50.5%@S21  T=1.05s eta=10:32:11 | 74.1K token/s | 
[epoch_0]_25041  loss=3.460586 |g|=0.368	lr=6.51e-04 | 51.4%@S21  T=1.03s eta=10:18:12 | 74.4K token/s | 
[epoch_0]_25051  loss=3.474416 |g|=0.388	lr=6.51e-04 | 52.2%@S21  T=1.04s eta=10:21:56 | 74.6K token/s | 
[epoch_0]_25061  loss=3.408977 |g|=0.387	lr=6.51e-04 | 53.0%@S21  T=1.03s eta=10:14:55 | 74.9K token/s | 
[epoch_0]_25071  loss=3.392965 |g|=0.362	lr=6.51e-04 | 53.8%@S21  T=1.05s eta=10:26:52 | 75.0K token/s | 
[epoch_0]_25081  loss=3.447492 |g|=0.396	lr=6.50e-04 | 54.6%@S21  T=1.08s eta=10:44:12 | 75.1K token/s | 
[epoch_0]_25091  loss=3.403989 |g|=0.398	lr=6.50e-04 | 55.5%@S21  T=1.04s eta=10:20:04 | 75.3K token/s | 
[Fuyou] head="4" update algorithm=4 t=2.10s
[Section@25100] layer[30-36] tasks=15(nPassBack=0) last_loss=3.46568(0.0558276) N=(580,21588,21168 2509900)
[epoch_0]_25101  loss=3.391419 |g|=0.344	lr=6.50e-04 | 56.3%@S21  T=1.42s eta=14:11:07 | 74.4K token/s | 
[epoch_0]_25111  loss=3.346967 |g|=0.356	lr=6.50e-04 | 57.1%@S21  T=1.05s eta=10:27:28 | 74.6K token/s | 
[epoch_0]_25121  loss=3.381654 |g|=0.345	lr=6.49e-04 | 57.9%@S21  T=1.07s eta=10:37:45 | 74.7K token/s | 
[epoch_0]_25131  loss=3.372404 |g|=0.336	lr=6.49e-04 | 58.7%@S21  T=1.02s eta=10:11:43 | 75.0K token/s | 
[epoch_0]_25141  loss=3.424228 |g|=0.364	lr=6.49e-04 | 59.6%@S21  T=1.03s eta=10:17:39 | 75.2K token/s | 
[epoch_0]_25151  loss=3.508134 |g|=0.395	lr=6.49e-04 | 60.4%@S21  T=1.05s eta=10:25:58 | 75.4K token/s | 
[epoch_0]_25161  loss=3.431252 |g|=0.402	lr=6.48e-04 | 61.2%@S21  T=1.04s eta=10:22:30 | 75.5K token/s | 
[epoch_0]_25171  loss=3.448587 |g|=0.45	lr=6.48e-04 | 62.0%@S21  T=1.07s eta=10:37:57 | 75.6K token/s | 
[epoch_0]_25181  loss=3.394854 |g|=0.416	lr=6.48e-04 | 62.8%@S21  T=1.03s eta=10:17:43 | 75.8K token/s | 
[epoch_0]_25191  loss=3.438559 |g|=0.375	lr=6.48e-04 | 63.7%@S21  T=1.05s eta=10:29:29 | 75.9K token/s | 
[Fuyou] head="5" update algorithm=4 t=2.20s
[eval] 
	 Loss@"edu_fineweb1B"=3.421(0.00038) nBranch=1 nToken=4.01M best=3.4164(120) E2T=-0.0191 T=13.4767(0)s x=0
	#3.42069±0.1075 tps=298K(4.01408M) a=[3.23887,3.70321] T=13.4767(sec)
[Section@25200] layer[0-6] tasks=15(nPassBack=0) last_loss=3.43982(-0.0359011) N=(580,21672,21252 2519900)
[epoch_0]_25201  loss=3.439378 |g|=0.344	lr=6.47e-04 | 64.5%@S21  T=4.20s eta=1d 17:50:27 | 73.1K token/s | 
[epoch_0]_25211  loss=3.363857 |g|=0.359	lr=6.47e-04 | 65.3%@S21  T=1.07s eta=10:37:48 | 73.2K token/s | 
[epoch_0]_25221  loss=3.379236 |g|=0.394	lr=6.47e-04 | 66.1%@S21  T=1.02s eta=10:11:29 | 73.6K token/s | 
[epoch_0]_25231  loss=3.387048 |g|=0.377	lr=6.47e-04 | 66.9%@S21  T=1.05s eta=10:23:48 | 73.8K token/s | 
[epoch_0]_25241  loss=3.440529 |g|=0.351	lr=6.46e-04 | 67.7%@S21  T=1.04s eta=10:18:54 | 74.1K token/s | 
[epoch_0]_25251  loss=3.502533 |g|=0.356	lr=6.46e-04 | 68.6%@S21  T=1.02s eta=10:09:04 | 74.4K token/s | 
[epoch_0]_25261  loss=3.421533 |g|=0.361	lr=6.46e-04 | 69.4%@S21  T=1.03s eta=10:15:56 | 74.6K token/s | 
[epoch_0]_25271  loss=3.444616 |g|=0.376	lr=6.46e-04 | 70.2%@S21  T=1.04s eta=10:22:14 | 74.8K token/s | 
[epoch_0]_25281  loss=3.510871 |g|=0.403	lr=6.46e-04 | 71.0%@S21  T=1.06s eta=10:33:11 | 74.9K token/s | 
[epoch_0]_25291  loss=3.442934 |g|=0.338	lr=6.45e-04 | 71.8%@S21  T=1.03s eta=10:15:07 | 75.1K token/s | 
[Fuyou] head="0" update algorithm=4 t=2.02s
[Section@25300] layer[6-12] tasks=15(nPassBack=0) last_loss=3.41434(0.0667732) N=(580,21756,21336 2529900)
[epoch_0]_25301  loss=3.395430 |g|=0.343	lr=6.45e-04 | 72.7%@S21  T=1.29s eta=12:48:03 | 74.6K token/s | 
[epoch_0]_25311  loss=3.484978 |g|=0.411	lr=6.45e-04 | 73.5%@S21  T=1.02s eta=10:09:53 | 74.8K token/s | 
[epoch_0]_25321  loss=3.442170 |g|=0.365	lr=6.45e-04 | 74.3%@S21  T=1.03s eta=10:15:04 | 75.1K token/s | 
[epoch_0]_25331  loss=3.448261 |g|=0.359	lr=6.44e-04 | 75.1%@S21  T=1.04s eta=10:18:24 | 75.2K token/s | 
[epoch_0]_25341  loss=3.435963 |g|=0.37	lr=6.44e-04 | 75.9%@S21  T=1.04s eta=10:18:50 | 75.4K token/s | 
[epoch_0]_25351  loss=3.462357 |g|=0.372	lr=6.44e-04 | 76.8%@S21  T=1.06s eta=10:28:32 | 75.5K token/s | 
[epoch_0]_25361  loss=3.409831 |g|=0.394	lr=6.44e-04 | 77.6%@S21  T=1.03s eta=10:14:56 | 75.7K token/s | 
[epoch_0]_25371  loss=3.359871 |g|=0.371	lr=6.43e-04 | 78.4%@S21  T=1.03s eta=10:11:28 | 75.9K token/s | 
[epoch_0]_25381  loss=3.427161 |g|=0.364	lr=6.43e-04 | 79.2%@S21  T=1.03s eta=10:13:19 | 76.1K token/s | 
[epoch_0]_25391  loss=3.430036 |g|=0.379	lr=6.43e-04 | 80.0%@S21  T=1.07s eta=10:36:00 | 76.1K token/s | 
[Fuyou] head="1" update algorithm=4 t=2.10s
[eval] 
	 Loss@"edu_fineweb1B"=3.423(-0.002) nBranch=1 nToken=4.01M best=3.4164(120) E2T=0.0373 T=13.5037(0)s x=0
	#3.42269±0.1081 tps=297K(4.01408M) a=[3.23651,3.70717] T=13.5037(sec)
[Section@25400] layer[12-18] tasks=15(nPassBack=0) last_loss=3.38539(0.0375421) N=(580,21840,21420 2539900)
[epoch_0]_25401  loss=3.493605 |g|=0.368	lr=6.43e-04 | 80.9%@S21  T=4.17s eta=1d 17:16:00 | 73.3K token/s | 
[epoch_0]_25411  loss=3.452148 |g|=0.367	lr=6.42e-04 | 81.7%@S21  T=1.03s eta=10:13:31 | 73.6K token/s | 
[epoch_0]_25421  loss=3.460835 |g|=0.362	lr=6.42e-04 | 82.5%@S21  T=1.04s eta=10:16:03 | 73.8K token/s | 
[epoch_0]_25431  loss=3.424121 |g|=0.357	lr=6.42e-04 | 83.3%@S21  T=1.06s eta=10:31:10 | 74.0K token/s | 
[epoch_0]_25441  loss=3.411956 |g|=0.446	lr=6.42e-04 | 84.1%@S21  T=1.03s eta=10:10:29 | 74.3K token/s | 
[epoch_0]_25451  loss=3.449645 |g|=0.356	lr=6.41e-04 | 85.0%@S21  T=1.03s eta=10:13:37 | 74.5K token/s | 
[epoch_0]_25461  loss=3.381900 |g|=0.36	lr=6.41e-04 | 85.8%@S21  T=1.04s eta=10:16:28 | 74.7K token/s | 
[epoch_0]_25471  loss=3.394932 |g|=0.359	lr=6.41e-04 | 86.6%@S21  T=1.06s eta=10:26:54 | 74.9K token/s | 
[epoch_0]_25481  loss=3.447077 |g|=0.359	lr=6.41e-04 | 87.4%@S21  T=1.03s eta=10:11:14 | 75.1K token/s | 
[epoch_0]_25491  loss=3.455873 |g|=0.363	lr=6.40e-04 | 88.2%@S21  T=1.04s eta=10:18:25 | 75.3K token/s | 
[Fuyou] head="2" update algorithm=4 t=2.09s
[Section@25500] layer[18-24] tasks=15(nPassBack=0) last_loss=3.44592(-0.0230331) N=(580,21924,21504 2549900)
[epoch_0]_25501  loss=3.408810 |g|=0.401	lr=6.40e-04 | 89.0%@S21  T=1.33s eta=13:05:16 | 74.6K token/s | 
[epoch_0]_25511  loss=3.366541 |g|=0.364	lr=6.40e-04 | 89.9%@S21  T=1.03s eta=10:08:09 | 74.9K token/s | 
[epoch_0]_25521  loss=3.406191 |g|=0.368	lr=6.40e-04 | 90.7%@S21  T=1.02s eta=10:06:08 | 75.1K token/s | 
[epoch_0]_25531  loss=3.386045 |g|=0.426	lr=6.39e-04 | 91.5%@S21  T=1.04s eta=10:13:35 | 75.3K token/s | 
[epoch_0]_25541  loss=3.476059 |g|=0.354	lr=6.39e-04 | 92.3%@S21  T=1.04s eta=10:15:17 | 75.5K token/s | 
[epoch_0]_25551  loss=3.435614 |g|=0.401	lr=6.39e-04 | 93.1%@S21  T=1.07s eta=10:31:45 | 75.5K token/s | 
[epoch_0]_25561  loss=3.463112 |g|=0.368	lr=6.39e-04 | 94.0%@S21  T=1.03s eta=10:09:42 | 75.7K token/s | 
[epoch_0]_25571  loss=3.389273 |g|=0.397	lr=6.38e-04 | 94.8%@S21  T=1.03s eta=10:10:45 | 75.9K token/s | 
[epoch_0]_25581  loss=3.425920 |g|=0.367	lr=6.38e-04 | 95.6%@S21  T=1.03s eta=10:11:22 | 76.1K token/s | 
[epoch_0]_25591  loss=3.375793 |g|=0.373	lr=6.38e-04 | 96.4%@S21  T=1.05s eta=10:18:17 | 76.2K token/s | 
[Fuyou] head="3" update algorithm=4 t=2.04s
[eval] 
	 Loss@"edu_fineweb1B"=3.420(0.0028) nBranch=1 nToken=4.01M best=3.4164(120) E2T=-1.88e-05 T=13.5102(0)s x=0
	#3.41986±0.1081 tps=297K(4.01408M) a=[3.23576,3.70247] T=13.5102(sec)
[Section@25600] layer[24-30] tasks=15(nPassBack=0) last_loss=3.41988(0.0597823) N=(580,22008,21588 2559900)
[epoch_0]_25601  loss=3.416147 |g|=0.345	lr=6.38e-04 | 97.2%@S21  T=4.20s eta=1d 17:17:43 | 73.4K token/s | 
[epoch_0]_25611  loss=3.355521 |g|=0.359	lr=6.37e-04 | 98.1%@S21  T=1.06s eta=10:23:29 | 73.6K token/s | 
[epoch_0]_25621  loss=3.501953 |g|=0.386	lr=6.37e-04 | 98.9%@S21  T=1.05s eta=10:18:28 | 73.8K token/s | 
[epoch_0]_25631  loss=3.438911 |g|=0.365	lr=6.37e-04 | 99.7%@S21  T=1.05s eta=10:21:17 | 74.0K token/s | 
[epoch_0]_25634  loss=3.381528 |g|=0.367	lr=6.37e-04 | 99.9%@S21  T=1.03s eta=10:07:48 | 74.3K token/s | 
-------- End of shard_21@"./Datasets/edu_fineweb1B/edu_fineweb_train_000474.bin"-------- 
[shard-22]@"./Datasets/edu_fineweb1B/edu_fineweb_train_000475.bin": tokens=100(M) nShardSamples=1220(2148432) 
[epoch_0]_25641  loss=3.369525 |g|=0.363	lr=6.37e-04 | 0.5%@S22  T=1.06s eta=10:25:31 | 74.4K token/s | 
[epoch_0]_25651  loss=3.406098 |g|=0.371	lr=6.36e-04 | 1.3%@S22  T=1.02s eta=10:03:55 | 74.7K token/s | 
[epoch_0]_25661  loss=3.408105 |g|=0.365	lr=6.36e-04 | 2.2%@S22  T=1.03s eta=10:06:51 | 74.9K token/s | 
[epoch_0]_25671  loss=3.458194 |g|=0.355	lr=6.36e-04 | 3.0%@S22  T=1.04s eta=10:14:44 | 75.1K token/s | 
[epoch_0]_25681  loss=3.473227 |g|=0.362	lr=6.36e-04 | 3.8%@S22  T=1.10s eta=10:46:59 | 75.1K token/s | 
[epoch_0]_25691  loss=3.404306 |g|=0.36	lr=6.35e-04 | 4.6%@S22  T=1.03s eta=10:06:10 | 75.3K token/s | 
[Fuyou] head="4" update algorithm=4 t=2.08s
[Section@25700] layer[30-36] tasks=15(nPassBack=0) last_loss=3.47959(-0.013901) N=(580,22092,21672 2569900)
[epoch_0]_25701  loss=3.374089 |g|=0.358	lr=6.35e-04 | 5.4%@S22  T=1.56s eta=15:20:31 | 74.2K token/s | 
[epoch_0]_25711  loss=3.420141 |g|=0.373	lr=6.35e-04 | 6.3%@S22  T=1.04s eta=10:11:31 | 74.4K token/s | 
[epoch_0]_25721  loss=3.399724 |g|=0.383	lr=6.35e-04 | 7.1%@S22  T=1.07s eta=10:31:46 | 74.5K token/s | 
[epoch_0]_25731  loss=3.334202 |g|=0.369	lr=6.34e-04 | 7.9%@S22  T=1.03s eta=10:05:08 | 74.8K token/s | 
[epoch_0]_25741  loss=3.401178 |g|=0.373	lr=6.34e-04 | 8.7%@S22  T=1.04s eta=10:14:11 | 74.9K token/s | 
[epoch_0]_25751  loss=3.443349 |g|=0.351	lr=6.34e-04 | 9.5%@S22  T=1.04s eta=10:14:13 | 75.1K token/s | 
[epoch_0]_25761  loss=3.393762 |g|=0.377	lr=6.34e-04 | 10.3%@S22  T=1.06s eta=10:22:59 | 75.2K token/s | 
[epoch_0]_25771  loss=3.366236 |g|=0.365	lr=6.33e-04 | 11.2%@S22  T=1.07s eta=10:27:39 | 75.3K token/s | 
[epoch_0]_25781  loss=3.415586 |g|=0.395	lr=6.33e-04 | 12.0%@S22  T=1.03s eta=10:06:19 | 75.5K token/s | 
[epoch_0]_25791  loss=3.393477 |g|=0.366	lr=6.33e-04 | 12.8%@S22  T=1.03s eta=10:06:47 | 75.7K token/s | 
[Fuyou] head="5" update algorithm=4 t=2.30s
[eval] 
	 Loss@"edu_fineweb1B"=3.407(0.013) nBranch=1 nToken=4.01M best=3.4199(127) E2T=-0.0239 T=13.4844(0)s x=0
	#3.40653±0.1076 tps=298K(4.01408M) a=[3.21534,3.68615] T=13.4844(sec)
[Section@25800] layer[0-6] tasks=15(nPassBack=0) last_loss=3.4304(0.0094173) N=(580,22176,21756 2579900)
[epoch_0]_25801  loss=3.441449 |g|=0.349	lr=6.33e-04 | 13.6%@S22  T=4.17s eta=1d 16:48:47 | 72.9K token/s | 
[epoch_0]_25811  loss=3.476785 |g|=0.363	lr=6.32e-04 | 14.4%@S22  T=1.03s eta=10:06:58 | 73.2K token/s | 
[epoch_0]_25821  loss=3.395984 |g|=0.34	lr=6.32e-04 | 15.3%@S22  T=1.03s eta=10:04:57 | 73.5K token/s | 
[epoch_0]_25831  loss=3.420579 |g|=0.355	lr=6.32e-04 | 16.1%@S22  T=1.07s eta=10:29:17 | 73.7K token/s | 
[epoch_0]_25841  loss=3.450425 |g|=0.372	lr=6.32e-04 | 16.9%@S22  T=1.03s eta=10:05:45 | 74.0K token/s | 
[epoch_0]_25851  loss=3.405138 |g|=0.425	lr=6.31e-04 | 17.7%@S22  T=1.04s eta=10:09:33 | 74.2K token/s | 
[epoch_0]_25861  loss=3.420871 |g|=0.38	lr=6.31e-04 | 18.5%@S22  T=1.04s eta=10:09:08 | 74.4K token/s | 
[epoch_0]_25871  loss=3.393951 |g|=0.365	lr=6.31e-04 | 19.4%@S22  T=1.04s eta=10:10:14 | 74.6K token/s | 
[epoch_0]_25881  loss=3.411403 |g|=0.392	lr=6.31e-04 | 20.2%@S22  T=1.03s eta=10:03:13 | 74.9K token/s | 
[epoch_0]_25891  loss=3.385672 |g|=0.395	lr=6.30e-04 | 21.0%@S22  T=1.03s eta=10:02:34 | 75.1K token/s | 
[Fuyou] head="0" update algorithm=4 t=2.08s
[Section@25900] layer[6-12] tasks=15(nPassBack=0) last_loss=3.3865(0.0278332) N=(580,22260,21840 2589900)
[epoch_0]_25901  loss=3.426029 |g|=0.433	lr=6.30e-04 | 21.8%@S22  T=1.31s eta=12:46:48 | 74.5K token/s | 
[epoch_0]_25911  loss=3.404874 |g|=0.343	lr=6.30e-04 | 22.6%@S22  T=1.02s eta=09:59:40 | 74.8K token/s | 
[epoch_0]_25921  loss=3.396242 |g|=0.348	lr=6.30e-04 | 23.5%@S22  T=1.03s eta=10:04:51 | 75.0K token/s | 
[epoch_0]_25931  loss=3.368117 |g|=0.367	lr=6.29e-04 | 24.3%@S22  T=1.04s eta=10:06:50 | 75.2K token/s | 
[epoch_0]_25941  loss=3.412466 |g|=0.414	lr=6.29e-04 | 25.1%@S22  T=1.03s eta=10:03:55 | 75.4K token/s | 
[epoch_0]_25951  loss=3.354672 |g|=0.373	lr=6.29e-04 | 25.9%@S22  T=1.07s eta=10:24:41 | 75.5K token/s | 
[epoch_0]_25961  loss=3.360393 |g|=0.366	lr=6.29e-04 | 26.7%@S22  T=1.04s eta=10:06:05 | 75.6K token/s | 
[epoch_0]_25971  loss=3.348390 |g|=0.375	lr=6.28e-04 | 27.6%@S22  T=1.03s eta=10:03:16 | 75.8K token/s | 
[epoch_0]_25981  loss=3.376073 |g|=0.349	lr=6.28e-04 | 28.4%@S22  T=1.03s eta=10:02:35 | 76.0K token/s | 
[epoch_0]_25991  loss=3.387773 |g|=0.379	lr=6.28e-04 | 29.2%@S22  T=1.06s eta=10:19:06 | 76.1K token/s | 
[Fuyou] head="1" update algorithm=4 t=2.08s
[eval] 
	 Loss@"edu_fineweb1B"=3.400(0.0069) nBranch=1 nToken=4.01M best=3.4065(128) E2T=0.0463 T=13.5014(0)s x=0
	#3.39967±0.1080 tps=297K(4.01408M) a=[3.20932,3.68243] T=13.5014(sec)
[Section@26000] layer[12-18] tasks=15(nPassBack=0) last_loss=3.35334(0.032052) N=(580,22344,21924 2599900)
[epoch_0]_26001  loss=3.270287 |g|=0.344	lr=6.28e-04 | 30.0%@S22  T=4.17s eta=1d 16:32:39 | 73.3K token/s | 
[epoch_0]_26011  loss=3.417585 |g|=0.377	lr=6.27e-04 | 30.8%@S22  T=1.03s eta=10:03:03 | 73.6K token/s | 
[epoch_0]_26021  loss=3.479773 |g|=0.386	lr=6.27e-04 | 31.6%@S22  T=1.04s eta=10:07:27 | 73.8K token/s | 
[epoch_0]_26031  loss=3.448570 |g|=0.413	lr=6.27e-04 | 32.5%@S22  T=1.06s eta=10:18:28 | 74.0K token/s | 
[epoch_0]_26041  loss=3.394004 |g|=0.432	lr=6.27e-04 | 33.3%@S22  T=1.04s eta=10:09:14 | 74.2K token/s | 
[epoch_0]_26051  loss=3.404988 |g|=0.375	lr=6.26e-04 | 34.1%@S22  T=1.04s eta=10:08:38 | 74.4K token/s | 
[epoch_0]_26061  loss=3.379375 |g|=0.369	lr=6.26e-04 | 34.9%@S22  T=1.03s eta=10:01:49 | 74.7K token/s | 
[epoch_0]_26071  loss=3.378504 |g|=0.369	lr=6.26e-04 | 35.7%@S22  T=1.04s eta=10:08:49 | 74.9K token/s | 
[epoch_0]_26081  loss=3.355027 |g|=0.358	lr=6.26e-04 | 36.6%@S22  T=1.08s eta=10:26:24 | 74.9K token/s | 
[epoch_0]_26091  loss=3.404510 |g|=0.374	lr=6.25e-04 | 37.4%@S22  T=1.03s eta=09:57:37 | 75.2K token/s | 
[Fuyou] head="2" update algorithm=4 t=2.08s
[Section@26100] layer[18-24] tasks=15(nPassBack=0) last_loss=3.38941(0.0565112) N=(580,22428,22008 2609900)
[epoch_0]_26101  loss=3.444685 |g|=0.355	lr=6.25e-04 | 38.2%@S22  T=1.35s eta=13:07:55 | 74.4K token/s | 
[epoch_0]_26111  loss=3.419114 |g|=0.362	lr=6.25e-04 | 39.0%@S22  T=1.02s eta=09:54:43 | 74.7K token/s | 
[epoch_0]_26121  loss=3.312584 |g|=0.367	lr=6.25e-04 | 39.8%@S22  T=1.07s eta=10:19:54 | 74.8K token/s | 
[epoch_0]_26131  loss=3.344647 |g|=0.378	lr=6.24e-04 | 40.7%@S22  T=1.04s eta=10:02:49 | 75.0K token/s | 
[epoch_0]_26141  loss=3.375549 |g|=0.36	lr=6.24e-04 | 41.5%@S22  T=1.03s eta=09:59:08 | 75.3K token/s | 
[epoch_0]_26151  loss=3.361307 |g|=0.355	lr=6.24e-04 | 42.3%@S22  T=1.04s eta=10:03:12 | 75.4K token/s | 
[epoch_0]_26161  loss=3.411634 |g|=0.379	lr=6.24e-04 | 43.1%@S22  T=1.07s eta=10:21:34 | 75.5K token/s | 
[epoch_0]_26171  loss=3.404275 |g|=0.363	lr=6.23e-04 | 43.9%@S22  T=1.03s eta=10:00:27 | 75.7K token/s | 
[epoch_0]_26181  loss=3.367232 |g|=0.368	lr=6.23e-04 | 44.8%@S22  T=1.03s eta=10:01:07 | 75.9K token/s | 
[epoch_0]_26191  loss=3.426721 |g|=0.375	lr=6.23e-04 | 45.6%@S22  T=1.04s eta=10:03:12 | 76.0K token/s | 
[Fuyou] head="3" update algorithm=4 t=2.09s
[eval] 
	 Loss@"edu_fineweb1B"=3.397(0.0026) nBranch=1 nToken=4.01M best=3.3997(129) E2T=-0.0427 T=13.4943(0)s x=0
	#3.39712±0.1081 tps=297K(4.01408M) a=[3.19631,3.67468] T=13.4943(sec)
[Section@26200] layer[24-30] tasks=15(nPassBack=0) last_loss=3.43983(-0.0199518) N=(580,22512,22092 2619900)
[epoch_0]_26201  loss=3.422710 |g|=0.347	lr=6.23e-04 | 46.4%@S22  T=4.17s eta=1d 16:20:27 | 73.2K token/s | 
[epoch_0]_26211  loss=3.364241 |g|=0.397	lr=6.22e-04 | 47.2%@S22  T=1.06s eta=10:13:45 | 73.4K token/s | 
[epoch_0]_26221  loss=3.385341 |g|=0.37	lr=6.22e-04 | 48.0%@S22  T=1.03s eta=09:58:55 | 73.7K token/s | 
[epoch_0]_26231  loss=3.496139 |g|=0.372	lr=6.22e-04 | 48.9%@S22  T=1.08s eta=10:24:33 | 73.8K token/s | 
[epoch_0]_26241  loss=3.379041 |g|=0.364	lr=6.22e-04 | 49.7%@S22  T=1.04s eta=10:05:44 | 74.1K token/s | 
[epoch_0]_26251  loss=3.394060 |g|=0.36	lr=6.21e-04 | 50.5%@S22  T=1.03s eta=09:59:58 | 74.3K token/s | 
[epoch_0]_26261  loss=3.426452 |g|=0.389	lr=6.21e-04 | 51.3%@S22  T=1.07s eta=10:21:19 | 74.4K token/s | 
[epoch_0]_26271  loss=3.317695 |g|=0.387	lr=6.21e-04 | 52.1%@S22  T=1.05s eta=10:07:19 | 74.6K token/s | 
[epoch_0]_26281  loss=3.413614 |g|=0.358	lr=6.21e-04 | 52.9%@S22  T=1.09s eta=10:29:55 | 74.6K token/s | 
[epoch_0]_26291  loss=3.356203 |g|=0.357	lr=6.20e-04 | 53.8%@S22  T=1.04s eta=10:03:16 | 74.8K token/s | 
[Fuyou] head="4" update algorithm=4 t=2.03s
[Section@26300] layer[30-36] tasks=15(nPassBack=0) last_loss=3.38444(0.0951478) N=(580,22596,22176 2629900)
[epoch_0]_26301  loss=3.452649 |g|=0.341	lr=6.20e-04 | 54.6%@S22  T=1.51s eta=14:36:29 | 73.8K token/s | 
[epoch_0]_26311  loss=3.406139 |g|=0.352	lr=6.20e-04 | 55.4%@S22  T=1.03s eta=09:56:21 | 74.1K token/s | 
[epoch_0]_26321  loss=3.368517 |g|=0.387	lr=6.20e-04 | 56.2%@S22  T=1.06s eta=10:14:43 | 74.2K token/s | 
[epoch_0]_26331  loss=3.349723 |g|=0.403	lr=6.19e-04 | 57.0%@S22  T=1.08s eta=10:22:31 | 74.3K token/s | 
[epoch_0]_26341  loss=3.375276 |g|=0.416	lr=6.19e-04 | 57.9%@S22  T=1.05s eta=10:07:05 | 74.5K token/s | 
[epoch_0]_26351  loss=3.343069 |g|=0.372	lr=6.19e-04 | 58.7%@S22  T=1.04s eta=09:59:12 | 74.7K token/s | 
[epoch_0]_26361  loss=3.368452 |g|=0.398	lr=6.19e-04 | 59.5%@S22  T=1.06s eta=10:11:17 | 74.9K token/s | 
[epoch_0]_26371  loss=3.359988 |g|=0.35	lr=6.18e-04 | 60.3%@S22  T=1.07s eta=10:17:14 | 75.0K token/s | 
[epoch_0]_26381  loss=3.398518 |g|=0.367	lr=6.18e-04 | 61.1%@S22  T=1.05s eta=10:08:28 | 75.1K token/s | 
[epoch_0]_26391  loss=3.349387 |g|=0.376	lr=6.18e-04 | 62.0%@S22  T=1.04s eta=10:01:10 | 75.3K token/s | 
[Fuyou] head="5" update algorithm=4 t=2.10s
[eval] 
	 Loss@"edu_fineweb1B"=3.394(0.0029) nBranch=1 nToken=4.01M best=3.3971(130) E2T=-0.00693 T=13.5071(0)s x=0
	#3.3942±0.1099 tps=297K(4.01408M) a=[3.19264,3.67485] T=13.5071(sec)
[Section@26400] layer[0-6] tasks=15(nPassBack=0) last_loss=3.40113(0.0292687) N=(580,22680,22260 2639900)
[epoch_0]_26401  loss=3.350891 |g|=0.364	lr=6.18e-04 | 62.8%@S22  T=4.18s eta=1d 16:10:21 | 72.5K token/s | 
[epoch_0]_26411  loss=3.372481 |g|=0.42	lr=6.17e-04 | 63.6%@S22  T=1.07s eta=10:18:19 | 72.7K token/s | 
[epoch_0]_26421  loss=3.341558 |g|=0.347	lr=6.17e-04 | 64.4%@S22  T=1.04s eta=09:58:09 | 73.0K token/s | 
[epoch_0]_26431  loss=3.291262 |g|=0.379	lr=6.17e-04 | 65.2%@S22  T=1.05s eta=10:03:35 | 73.3K token/s | 
[epoch_0]_26441  loss=3.454053 |g|=0.381	lr=6.17e-04 | 66.1%@S22  T=1.06s eta=10:12:18 | 73.5K token/s | 
[epoch_0]_26451  loss=3.383274 |g|=0.379	lr=6.16e-04 | 66.9%@S22  T=1.03s eta=09:54:48 | 73.8K token/s | 
[epoch_0]_26461  loss=3.297605 |g|=0.389	lr=6.16e-04 | 67.7%@S22  T=1.04s eta=10:00:32 | 74.0K token/s | 
[epoch_0]_26471  loss=3.355564 |g|=0.37	lr=6.16e-04 | 68.5%@S22  T=1.04s eta=10:01:53 | 74.2K token/s | 
[epoch_0]_26481  loss=3.352582 |g|=0.417	lr=6.16e-04 | 69.3%@S22  T=1.07s eta=10:17:16 | 74.3K token/s | 
[epoch_0]_26491  loss=3.398766 |g|=0.406	lr=6.15e-04 | 70.1%@S22  T=1.04s eta=09:56:29 | 74.6K token/s | 
[Fuyou] head="0" update algorithm=4 t=2.12s
[Section@26500] layer[6-12] tasks=15(nPassBack=0) last_loss=3.37196(0.014544) N=(580,22764,22344 2649900)
[epoch_0]_26501  loss=3.327788 |g|=0.354	lr=6.15e-04 | 71.0%@S22  T=1.33s eta=12:45:57 | 73.9K token/s | 
[epoch_0]_26511  loss=3.392982 |g|=0.397	lr=6.15e-04 | 71.8%@S22  T=1.02s eta=09:45:02 | 74.3K token/s | 
[epoch_0]_26521  loss=3.339531 |g|=0.383	lr=6.15e-04 | 72.6%@S22  T=1.07s eta=10:16:17 | 74.4K token/s | 
[epoch_0]_26531  loss=3.379930 |g|=0.34	lr=6.14e-04 | 73.4%@S22  T=1.03s eta=09:53:29 | 74.6K token/s | 
[epoch_0]_26541  loss=3.336650 |g|=0.377	lr=6.14e-04 | 74.2%@S22  T=1.03s eta=09:54:22 | 74.8K token/s | 
[epoch_0]_26551  loss=3.371993 |g|=0.38	lr=6.14e-04 | 75.1%@S22  T=1.04s eta=09:58:14 | 75.0K token/s | 
[epoch_0]_26561  loss=3.410873 |g|=0.397	lr=6.14e-04 | 75.9%@S22  T=1.05s eta=10:04:44 | 75.2K token/s | 
[epoch_0]_26571  loss=3.388093 |g|=0.359	lr=6.13e-04 | 76.7%@S22  T=1.06s eta=10:06:21 | 75.3K token/s | 
[epoch_0]_26581  loss=3.351814 |g|=0.408	lr=6.13e-04 | 77.5%@S22  T=1.03s eta=09:51:44 | 75.5K token/s | 
[epoch_0]_26591  loss=3.403902 |g|=0.401	lr=6.13e-04 | 78.3%@S22  T=1.03s eta=09:50:07 | 75.7K token/s | 
[Fuyou] head="1" update algorithm=4 t=2.05s
[eval] 
	 Loss@"edu_fineweb1B"=3.390(0.0041) nBranch=1 nToken=4.01M best=3.3942(131) E2T=-0.036 T=13.4948(0)s x=0
	#3.39008±0.1090 tps=297K(4.01408M) a=[3.18287,3.66832] T=13.4948(sec)
[Section@26600] layer[12-18] tasks=15(nPassBack=0) last_loss=3.42611(-0.0727689) N=(580,22848,22428 2659900)
[epoch_0]_26601  loss=3.467342 |g|=0.398	lr=6.13e-04 | 79.2%@S22  T=4.16s eta=1d 15:49:57 | 72.9K token/s | 
[epoch_0]_26611  loss=3.356591 |g|=0.368	lr=6.12e-04 | 80.0%@S22  T=1.03s eta=09:53:38 | 73.2K token/s | 
[epoch_0]_26621  loss=3.364354 |g|=0.418	lr=6.12e-04 | 80.8%@S22  T=1.04s eta=09:54:47 | 73.5K token/s | 
[epoch_0]_26631  loss=3.342598 |g|=0.387	lr=6.12e-04 | 81.6%@S22  T=1.05s eta=10:00:20 | 73.8K token/s | 
[epoch_0]_26641  loss=3.400356 |g|=0.396	lr=6.12e-04 | 82.4%@S22  T=1.07s eta=10:11:26 | 73.9K token/s | 
[epoch_0]_26651  loss=3.388788 |g|=0.38	lr=6.11e-04 | 83.3%@S22  T=1.03s eta=09:48:21 | 74.2K token/s | 
[epoch_0]_26661  loss=3.389321 |g|=0.375	lr=6.11e-04 | 84.1%@S22  T=1.03s eta=09:48:25 | 74.5K token/s | 
[epoch_0]_26671  loss=3.333782 |g|=0.359	lr=6.11e-04 | 84.9%@S22  T=1.04s eta=09:54:41 | 74.7K token/s | 
[epoch_0]_26681  loss=3.383804 |g|=0.39	lr=6.11e-04 | 85.7%@S22  T=1.05s eta=10:01:27 | 74.9K token/s | 
[epoch_0]_26691  loss=3.371125 |g|=0.37	lr=6.10e-04 | 86.5%@S22  T=1.03s eta=09:49:26 | 75.1K token/s | 
[Fuyou] head="2" update algorithm=4 t=2.08s
[Section@26700] layer[18-24] tasks=15(nPassBack=0) last_loss=3.36428(0.0251305) N=(580,22932,22512 2669900)
[epoch_0]_26701  loss=3.323286 |g|=0.339	lr=6.10e-04 | 87.4%@S22  T=1.32s eta=12:37:18 | 74.4K token/s | 
[epoch_0]_26711  loss=3.405208 |g|=0.348	lr=6.10e-04 | 88.2%@S22  T=1.04s eta=09:55:57 | 74.6K token/s | 
[epoch_0]_26721  loss=3.353051 |g|=0.37	lr=6.10e-04 | 89.0%@S22  T=1.06s eta=10:03:50 | 74.8K token/s | 
[epoch_0]_26731  loss=3.424597 |g|=0.375	lr=6.09e-04 | 89.8%@S22  T=1.03s eta=09:49:49 | 75.0K token/s | 
[epoch_0]_26741  loss=3.289438 |g|=0.351	lr=6.09e-04 | 90.6%@S22  T=1.03s eta=09:51:08 | 75.2K token/s | 
[epoch_0]_26751  loss=3.327461 |g|=0.353	lr=6.09e-04 | 91.4%@S22  T=1.04s eta=09:52:24 | 75.4K token/s | 
[epoch_0]_26761  loss=3.336211 |g|=0.353	lr=6.09e-04 | 92.3%@S22  T=1.05s eta=09:59:45 | 75.6K token/s | 
[epoch_0]_26771  loss=3.355093 |g|=0.371	lr=6.08e-04 | 93.1%@S22  T=1.07s eta=10:13:47 | 75.6K token/s | 
[epoch_0]_26781  loss=3.440831 |g|=0.35	lr=6.08e-04 | 93.9%@S22  T=1.03s eta=09:49:20 | 75.8K token/s | 
[epoch_0]_26791  loss=3.360774 |g|=0.378	lr=6.08e-04 | 94.7%@S22  T=1.03s eta=09:48:37 | 76.0K token/s | 
[Fuyou] head="3" update algorithm=4 t=2.09s
[eval] 
	 Loss@"edu_fineweb1B"=3.388(0.0026) nBranch=1 nToken=4.01M best=3.3901(132) E2T=0.0196 T=13.4913(0)s x=0
	#3.38751±0.1089 tps=298K(4.01408M) a=[3.18614,3.66604] T=13.4913(sec)
[Section@26800] layer[24-30] tasks=15(nPassBack=0) last_loss=3.36793(0.0718994) N=(580,23016,22596 2679900)
[epoch_0]_26801  loss=3.305516 |g|=0.358	lr=6.08e-04 | 95.5%@S22  T=4.15s eta=1d 15:30:13 | 73.1K token/s | 
[epoch_0]_26811  loss=3.421180 |g|=0.407	lr=6.07e-04 | 96.4%@S22  T=1.05s eta=10:00:56 | 73.4K token/s | 
[epoch_0]_26821  loss=3.371659 |g|=0.371	lr=6.07e-04 | 97.2%@S22  T=1.03s eta=09:49:18 | 73.7K token/s | 
[epoch_0]_26831  loss=3.387447 |g|=0.368	lr=6.07e-04 | 98.0%@S22  T=1.05s eta=10:00:05 | 73.9K token/s | 
[epoch_0]_26841  loss=3.433789 |g|=0.352	lr=6.07e-04 | 98.8%@S22  T=1.06s eta=10:04:40 | 74.0K token/s | 
[epoch_0]_26851  loss=3.367713 |g|=0.363	lr=6.06e-04 | 99.6%@S22  T=1.07s eta=10:11:51 | 74.2K token/s | 
[epoch_0]_26855  loss=3.419421 |g|=0.337	lr=6.06e-04 | 100.0%@S22  T=1.03s eta=09:46:20 | 74.4K token/s | 
-------- End of shard_22@"./Datasets/edu_fineweb1B/edu_fineweb_train_000475.bin"-------- 
[shard-23]@"./Datasets/edu_fineweb1B/edu_fineweb_train_000476.bin": tokens=100(M) nShardSamples=1220(2246088) 
[epoch_0]_26861  loss=3.452952 |g|=0.377	lr=6.06e-04 | 0.5%@S23  T=1.03s eta=09:44:49 | 74.7K token/s | 
[epoch_0]_26871  loss=3.445374 |g|=0.374	lr=6.06e-04 | 1.3%@S23  T=1.02s eta=09:41:27 | 75.0K token/s | 
[epoch_0]_26881  loss=3.466205 |g|=0.387	lr=6.06e-04 | 2.1%@S23  T=1.04s eta=09:54:29 | 75.1K token/s | 
[epoch_0]_26891  loss=3.435820 |g|=0.421	lr=6.05e-04 | 2.9%@S23  T=1.05s eta=09:59:33 | 75.3K token/s | 
[Fuyou] head="4" update algorithm=4 t=2.07s
[Section@26900] layer[30-36] tasks=15(nPassBack=0) last_loss=3.36767(0.016767) N=(580,23100,22680 2689900)
[epoch_0]_26901  loss=3.426180 |g|=0.379	lr=6.05e-04 | 3.7%@S23  T=1.39s eta=13:08:12 | 74.5K token/s | 
[epoch_0]_26911  loss=3.400061 |g|=0.37	lr=6.05e-04 | 4.6%@S23  T=1.02s eta=09:40:47 | 74.8K token/s | 
[epoch_0]_26921  loss=3.401590 |g|=0.365	lr=6.05e-04 | 5.4%@S23  T=1.04s eta=09:49:25 | 75.0K token/s | 
[epoch_0]_26931  loss=3.447830 |g|=0.427	lr=6.04e-04 | 6.2%@S23  T=1.05s eta=09:55:15 | 75.1K token/s | 
[epoch_0]_26941  loss=3.520735 |g|=0.433	lr=6.04e-04 | 7.0%@S23  T=1.05s eta=09:59:00 | 75.3K token/s | 
[epoch_0]_26951  loss=3.440714 |g|=0.392	lr=6.04e-04 | 7.8%@S23  T=1.03s eta=09:43:24 | 75.5K token/s | 
[epoch_0]_26961  loss=3.403723 |g|=0.393	lr=6.04e-04 | 8.7%@S23  T=1.02s eta=09:41:31 | 75.7K token/s | 
[epoch_0]_26971  loss=3.345350 |g|=0.374	lr=6.03e-04 | 9.5%@S23  T=1.03s eta=09:45:32 | 75.9K token/s | 
[epoch_0]_26981  loss=3.427684 |g|=0.392	lr=6.03e-04 | 10.3%@S23  T=1.05s eta=09:54:27 | 76.0K token/s | 
[epoch_0]_26991  loss=3.462116 |g|=0.405	lr=6.03e-04 | 11.1%@S23  T=1.08s eta=10:11:01 | 76.0K token/s | 
[Fuyou] head="5" update algorithm=4 t=2.08s
[eval] 
	 Loss@"edu_fineweb1B"=3.393(-0.0053) nBranch=1 nToken=4.01M best=3.3901(132) E2T=0.0241 T=13.4852(0)s x=0
	#3.39283±0.1100 tps=298K(4.01408M) a=[3.20023,3.68026] T=13.4852(sec)
[Section@27000] layer[0-6] tasks=15(nPassBack=0) last_loss=3.36869(0.0324459) N=(580,23184,22764 2699900)
[epoch_0]_27001  loss=3.343013 |g|=0.343	lr=6.03e-04 | 11.9%@S23  T=4.16s eta=1d 15:18:26 | 73.2K token/s | 
[epoch_0]_27011  loss=3.320055 |g|=0.36	lr=6.02e-04 | 12.7%@S23  T=1.02s eta=09:40:57 | 73.5K token/s | 
[epoch_0]_27021  loss=3.412285 |g|=0.35	lr=6.02e-04 | 13.6%@S23  T=1.05s eta=09:52:31 | 73.8K token/s | 
[epoch_0]_27031  loss=3.369544 |g|=0.378	lr=6.02e-04 | 14.4%@S23  T=1.03s eta=09:46:28 | 74.1K token/s | 
[epoch_0]_27041  loss=3.450454 |g|=0.356	lr=6.02e-04 | 15.2%@S23  T=1.03s eta=09:44:38 | 74.3K token/s | 
[epoch_0]_27051  loss=3.395072 |g|=0.385	lr=6.01e-04 | 16.0%@S23  T=1.03s eta=09:45:33 | 74.6K token/s | 
[epoch_0]_27061  loss=3.387272 |g|=0.356	lr=6.01e-04 | 16.8%@S23  T=1.05s eta=09:52:48 | 74.7K token/s | 
[epoch_0]_27071  loss=3.413377 |g|=0.357	lr=6.01e-04 | 17.7%@S23  T=1.06s eta=10:00:30 | 74.9K token/s | 
[epoch_0]_27081  loss=3.470239 |g|=0.392	lr=6.01e-04 | 18.5%@S23  T=1.03s eta=09:41:15 | 75.1K token/s | 
[epoch_0]_27091  loss=3.403446 |g|=0.379	lr=6.00e-04 | 19.3%@S23  T=1.03s eta=09:40:43 | 75.3K token/s | 
[Fuyou] head="0" update algorithm=4 t=2.07s
[Section@27100] layer[6-12] tasks=15(nPassBack=0) last_loss=3.36599(0.00596666) N=(580,23268,22848 2709900)
[epoch_0]_27101  loss=3.426940 |g|=0.354	lr=6.00e-04 | 20.1%@S23  T=1.51s eta=14:13:04 | 74.3K token/s | 
[epoch_0]_27111  loss=3.431834 |g|=0.398	lr=6.00e-04 | 20.9%@S23  T=1.04s eta=09:45:50 | 74.5K token/s | 
[epoch_0]_27121  loss=3.418360 |g|=0.382	lr=6.00e-04 | 21.8%@S23  T=1.03s eta=09:42:31 | 74.8K token/s | 
[epoch_0]_27131  loss=3.377074 |g|=0.381	lr=5.99e-04 | 22.6%@S23  T=1.03s eta=09:41:50 | 75.0K token/s | 
[epoch_0]_27141  loss=3.413775 |g|=0.395	lr=5.99e-04 | 23.4%@S23  T=1.03s eta=09:43:43 | 75.2K token/s | 
[epoch_0]_27151  loss=3.387000 |g|=0.384	lr=5.99e-04 | 24.2%@S23  T=1.05s eta=09:52:53 | 75.4K token/s | 
[epoch_0]_27161  loss=3.428876 |g|=0.398	lr=5.99e-04 | 25.0%@S23  T=1.06s eta=09:57:05 | 75.5K token/s | 
[epoch_0]_27171  loss=3.414935 |g|=0.348	lr=5.98e-04 | 25.9%@S23  T=1.03s eta=09:42:59 | 75.7K token/s | 
[epoch_0]_27181  loss=3.474547 |g|=0.381	lr=5.98e-04 | 26.7%@S23  T=1.04s eta=09:46:59 | 75.8K token/s | 
[epoch_0]_27191  loss=3.368186 |g|=0.39	lr=5.98e-04 | 27.5%@S23  T=1.04s eta=09:45:42 | 76.0K token/s | 
[Fuyou] head="1" update algorithm=4 t=2.12s
[eval] 
	 Loss@"edu_fineweb1B"=3.396(-0.0035) nBranch=1 nToken=4.01M best=3.3901(132) E2T=0.0185 T=13.4851(0)s x=0
	#3.39638±0.1084 tps=298K(4.01408M) a=[3.20442,3.68141] T=13.4851(sec)
[Section@27200] layer[12-18] tasks=15(nPassBack=0) last_loss=3.3779(0.0482068) N=(580,23352,22932 2719900)
[epoch_0]_27201  loss=3.369873 |g|=0.349	lr=5.98e-04 | 28.3%@S23  T=4.17s eta=1d 15:13:35 | 73.2K token/s | 
[epoch_0]_27211  loss=3.454145 |g|=0.381	lr=5.97e-04 | 29.1%@S23  T=1.05s eta=09:50:52 | 73.4K token/s | 
[epoch_0]_27221  loss=3.362734 |g|=0.354	lr=5.97e-04 | 30.0%@S23  T=1.04s eta=09:44:20 | 73.7K token/s | 
[epoch_0]_27231  loss=3.305888 |g|=0.361	lr=5.97e-04 | 30.8%@S23  T=1.07s eta=10:05:25 | 73.8K token/s | 
[epoch_0]_27241  loss=3.378152 |g|=0.383	lr=5.96e-04 | 31.6%@S23  T=1.04s eta=09:43:47 | 74.1K token/s | 
[epoch_0]_27251  loss=3.421503 |g|=0.387	lr=5.96e-04 | 32.4%@S23  T=1.05s eta=09:48:43 | 74.3K token/s | 
[epoch_0]_27261  loss=3.417350 |g|=0.361	lr=5.96e-04 | 33.2%@S23  T=1.04s eta=09:45:10 | 74.5K token/s | 
[epoch_0]_27271  loss=3.383856 |g|=0.385	lr=5.96e-04 | 34.0%@S23  T=1.05s eta=09:51:38 | 74.7K token/s | 
[epoch_0]_27281  loss=3.395651 |g|=0.367	lr=5.95e-04 | 34.9%@S23  T=1.06s eta=09:54:22 | 74.8K token/s | 
[epoch_0]_27291  loss=3.407635 |g|=0.351	lr=5.95e-04 | 35.7%@S23  T=1.03s eta=09:37:02 | 75.1K token/s | 
[Fuyou] head="2" update algorithm=4 t=2.01s
[Section@27300] layer[18-24] tasks=15(nPassBack=0) last_loss=3.40468(-0.0404022) N=(580,23436,23016 2729900)
[epoch_0]_27301  loss=3.379020 |g|=0.352	lr=5.95e-04 | 36.5%@S23  T=1.33s eta=12:28:57 | 74.4K token/s | 
[epoch_0]_27311  loss=3.383742 |g|=0.391	lr=5.95e-04 | 37.3%@S23  T=1.03s eta=09:40:27 | 74.6K token/s | 
[epoch_0]_27321  loss=3.390304 |g|=0.379	lr=5.94e-04 | 38.1%@S23  T=1.07s eta=10:00:55 | 74.7K token/s | 
[epoch_0]_27331  loss=3.447324 |g|=0.389	lr=5.94e-04 | 39.0%@S23  T=1.04s eta=09:46:35 | 74.9K token/s | 
[epoch_0]_27341  loss=3.381709 |g|=0.393	lr=5.94e-04 | 39.8%@S23  T=1.05s eta=09:47:07 | 75.1K token/s | 
[epoch_0]_27351  loss=3.370942 |g|=0.349	lr=5.94e-04 | 40.6%@S23  T=1.04s eta=09:45:55 | 75.3K token/s | 
[epoch_0]_27361  loss=3.386686 |g|=0.357	lr=5.93e-04 | 41.4%@S23  T=1.04s eta=09:45:07 | 75.4K token/s | 
[epoch_0]_27371  loss=3.307726 |g|=0.361	lr=5.93e-04 | 42.2%@S23  T=1.04s eta=09:44:20 | 75.6K token/s | 
[epoch_0]_27381  loss=3.411969 |g|=0.362	lr=5.93e-04 | 43.1%@S23  T=1.03s eta=09:39:06 | 75.8K token/s | 
[epoch_0]_27391  loss=3.472184 |g|=0.353	lr=5.93e-04 | 43.9%@S23  T=1.04s eta=09:41:06 | 75.9K token/s | 
[Fuyou] head="3" update algorithm=4 t=2.08s
[eval] 
	 Loss@"edu_fineweb1B"=3.396(2.4e-05) nBranch=1 nToken=4.01M best=3.3901(132) E2T=0.0211 T=13.4934(0)s x=0
	#3.39636±0.1096 tps=297K(4.01408M) a=[3.20743,3.68341] T=13.4934(sec)
[Section@27400] layer[24-30] tasks=15(nPassBack=0) last_loss=3.37524(-0.00730324) N=(580,23520,23100 2739900)
[epoch_0]_27401  loss=3.466290 |g|=0.362	lr=5.92e-04 | 44.7%@S23  T=4.17s eta=1d 14:56:23 | 73.1K token/s | 
[epoch_0]_27411  loss=3.372667 |g|=0.384	lr=5.92e-04 | 45.5%@S23  T=1.06s eta=09:51:27 | 73.4K token/s | 
[epoch_0]_27421  loss=3.414338 |g|=0.397	lr=5.92e-04 | 46.3%@S23  T=1.03s eta=09:37:54 | 73.7K token/s | 
[epoch_0]_27431  loss=3.434733 |g|=0.362	lr=5.92e-04 | 47.2%@S23  T=1.03s eta=09:36:23 | 74.0K token/s | 
[epoch_0]_27441  loss=3.358069 |g|=0.383	lr=5.91e-04 | 48.0%@S23  T=1.04s eta=09:43:37 | 74.2K token/s | 
[epoch_0]_27451  loss=3.432807 |g|=0.361	lr=5.91e-04 | 48.8%@S23  T=1.10s eta=10:13:21 | 74.2K token/s | 
[epoch_0]_27461  loss=3.394973 |g|=0.38	lr=5.91e-04 | 49.6%@S23  T=1.04s eta=09:40:01 | 74.5K token/s | 
[epoch_0]_27471  loss=3.371422 |g|=0.353	lr=5.91e-04 | 50.4%@S23  T=1.04s eta=09:42:51 | 74.7K token/s | 
[epoch_0]_27481  loss=3.385197 |g|=0.394	lr=5.90e-04 | 51.3%@S23  T=1.03s eta=09:38:44 | 74.9K token/s | 
[epoch_0]_27491  loss=3.293452 |g|=0.387	lr=5.90e-04 | 52.1%@S23  T=1.05s eta=09:47:29 | 75.0K token/s | 
[Fuyou] head="4" update algorithm=4 t=2.04s
[Section@27500] layer[30-36] tasks=15(nPassBack=0) last_loss=3.35447(0.0131965) N=(580,23604,23184 2749900)
[epoch_0]_27501  loss=3.413892 |g|=0.376	lr=5.90e-04 | 52.9%@S23  T=1.43s eta=13:18:52 | 74.2K token/s | 
[epoch_0]_27511  loss=3.346022 |g|=0.37	lr=5.90e-04 | 53.7%@S23  T=1.03s eta=09:32:42 | 74.4K token/s | 
[epoch_0]_27521  loss=3.386763 |g|=0.378	lr=5.89e-04 | 54.5%@S23  T=1.03s eta=09:35:11 | 74.7K token/s | 
[epoch_0]_27531  loss=3.399516 |g|=0.373	lr=5.89e-04 | 55.3%@S23  T=1.05s eta=09:47:13 | 74.9K token/s | 
[epoch_0]_27541  loss=3.348869 |g|=0.366	lr=5.89e-04 | 56.2%@S23  T=1.04s eta=09:42:14 | 75.0K token/s | 
[epoch_0]_27551  loss=3.382930 |g|=0.357	lr=5.89e-04 | 57.0%@S23  T=1.08s eta=10:02:54 | 75.1K token/s | 
[epoch_0]_27561  loss=3.416803 |g|=0.391	lr=5.88e-04 | 57.8%@S23  T=1.04s eta=09:41:34 | 75.3K token/s | 
[epoch_0]_27571  loss=3.389299 |g|=0.43	lr=5.88e-04 | 58.6%@S23  T=1.03s eta=09:32:43 | 75.5K token/s | 
[epoch_0]_27581  loss=3.411768 |g|=0.38	lr=5.88e-04 | 59.4%@S23  T=1.04s eta=09:38:38 | 75.7K token/s | 
[epoch_0]_27591  loss=3.403818 |g|=0.35	lr=5.88e-04 | 60.3%@S23  T=1.04s eta=09:41:52 | 75.8K token/s | 
[Fuyou] head="5" update algorithm=4 t=2.08s
[eval] 
	 Loss@"edu_fineweb1B"=3.397(-0.00089) nBranch=1 nToken=4.01M best=3.3901(132) E2T=-0.0956 T=13.4928(0)s x=0
	#3.39725±0.1086 tps=297K(4.01408M) a=[3.21218,3.6809] T=13.4928(sec)
[Section@27600] layer[0-6] tasks=15(nPassBack=0) last_loss=3.49285(-0.124159) N=(580,23688,23268 2759900)
[epoch_0]_27601  loss=3.384825 |g|=0.349	lr=5.87e-04 | 61.1%@S23  T=4.17s eta=1d 14:44:40 | 73.0K token/s | 
[epoch_0]_27611  loss=3.406322 |g|=0.379	lr=5.87e-04 | 61.9%@S23  T=1.04s eta=09:37:02 | 73.3K token/s | 
[epoch_0]_27621  loss=3.369934 |g|=0.349	lr=5.87e-04 | 62.7%@S23  T=1.04s eta=09:36:24 | 73.6K token/s | 
[epoch_0]_27631  loss=3.425547 |g|=0.437	lr=5.87e-04 | 63.5%@S23  T=1.06s eta=09:49:51 | 73.8K token/s | 
[epoch_0]_27641  loss=3.431473 |g|=0.398	lr=5.86e-04 | 64.4%@S23  T=1.03s eta=09:31:31 | 74.1K token/s | 
[epoch_0]_27651  loss=3.374599 |g|=0.36	lr=5.86e-04 | 65.2%@S23  T=1.04s eta=09:38:43 | 74.3K token/s | 
[epoch_0]_27661  loss=3.329655 |g|=0.375	lr=5.86e-04 | 66.0%@S23  T=1.05s eta=09:45:32 | 74.5K token/s | 
[epoch_0]_27671  loss=3.397309 |g|=0.384	lr=5.86e-04 | 66.8%@S23  T=1.04s eta=09:40:53 | 74.7K token/s | 
[epoch_0]_27681  loss=3.412783 |g|=0.379	lr=5.85e-04 | 67.6%@S23  T=1.06s eta=09:47:25 | 74.8K token/s | 
[epoch_0]_27691  loss=3.334294 |g|=0.363	lr=5.85e-04 | 68.5%@S23  T=1.04s eta=09:37:53 | 75.0K token/s | 
[Fuyou] head="0" update algorithm=4 t=2.06s
[Section@27700] layer[6-12] tasks=15(nPassBack=0) last_loss=3.41213(-0.0461352) N=(580,23772,23352 2769900)
[epoch_0]_27701  loss=3.411596 |g|=0.386	lr=5.85e-04 | 69.3%@S23  T=1.41s eta=13:02:18 | 74.2K token/s | 
[epoch_0]_27711  loss=3.325020 |g|=0.355	lr=5.85e-04 | 70.1%@S23  T=1.03s eta=09:32:03 | 74.4K token/s | 
[epoch_0]_27721  loss=3.393938 |g|=0.373	lr=5.84e-04 | 70.9%@S23  T=1.06s eta=09:48:31 | 74.6K token/s | 
[epoch_0]_27731  loss=3.364232 |g|=0.355	lr=5.84e-04 | 71.7%@S23  T=1.04s eta=09:37:22 | 74.8K token/s | 
[epoch_0]_27741  loss=3.271194 |g|=0.365	lr=5.84e-04 | 72.5%@S23  T=1.03s eta=09:32:08 | 75.0K token/s | 
[epoch_0]_27751  loss=3.419591 |g|=0.421	lr=5.84e-04 | 73.4%@S23  T=1.04s eta=09:36:35 | 75.2K token/s | 
[epoch_0]_27761  loss=3.375520 |g|=0.363	lr=5.83e-04 | 74.2%@S23  T=1.05s eta=09:41:09 | 75.4K token/s | 
[epoch_0]_27771  loss=3.431632 |g|=0.411	lr=5.83e-04 | 75.0%@S23  T=1.06s eta=09:49:10 | 75.5K token/s | 
[epoch_0]_27781  loss=3.405629 |g|=0.368	lr=5.83e-04 | 75.8%@S23  T=1.06s eta=09:47:59 | 75.5K token/s | 
[epoch_0]_27791  loss=3.429922 |g|=0.389	lr=5.83e-04 | 76.6%@S23  T=1.03s eta=09:27:56 | 75.8K token/s | 
[Fuyou] head="1" update algorithm=4 t=2.02s
[eval] 
	 Loss@"edu_fineweb1B"=3.396(0.0011) nBranch=1 nToken=4.01M best=3.3901(132) E2T=0.0157 T=13.4839(0)s x=0
	#3.39619±0.1086 tps=298K(4.01408M) a=[3.21019,3.68336] T=13.4839(sec)
[Section@27800] layer[12-18] tasks=15(nPassBack=0) last_loss=3.38044(-0.0025425) N=(580,23856,23436 2779900)
[epoch_0]_27801  loss=3.381452 |g|=0.368	lr=5.82e-04 | 77.5%@S23  T=4.17s eta=1d 14:27:08 | 73.0K token/s | 
[epoch_0]_27811  loss=3.394668 |g|=0.369	lr=5.82e-04 | 78.3%@S23  T=1.09s eta=10:02:37 | 73.1K token/s | 
[epoch_0]_27821  loss=3.381685 |g|=0.364	lr=5.82e-04 | 79.1%@S23  T=1.04s eta=09:37:03 | 73.3K token/s | 
[epoch_0]_27831  loss=3.383998 |g|=0.4	lr=5.82e-04 | 79.9%@S23  T=1.04s eta=09:33:03 | 73.6K token/s | 
[epoch_0]_27841  loss=3.413363 |g|=0.38	lr=5.81e-04 | 80.7%@S23  T=1.05s eta=09:43:25 | 73.8K token/s | 
[epoch_0]_27851  loss=3.287606 |g|=0.408	lr=5.81e-04 | 81.6%@S23  T=1.05s eta=09:42:09 | 74.0K token/s | 
[epoch_0]_27861  loss=3.426443 |g|=0.381	lr=5.81e-04 | 82.4%@S23  T=1.03s eta=09:30:18 | 74.3K token/s | 
[epoch_0]_27871  loss=3.407845 |g|=0.371	lr=5.81e-04 | 83.2%@S23  T=1.04s eta=09:34:41 | 74.5K token/s | 
[epoch_0]_27881  loss=3.482289 |g|=0.39	lr=5.80e-04 | 84.0%@S23  T=1.04s eta=09:34:21 | 74.7K token/s | 
[epoch_0]_27891  loss=3.408835 |g|=0.384	lr=5.80e-04 | 84.8%@S23  T=1.06s eta=09:44:37 | 74.9K token/s | 
[Fuyou] head="2" update algorithm=4 t=2.06s
[Section@27900] layer[18-24] tasks=15(nPassBack=0) last_loss=3.41699(-0.0123065) N=(580,23940,23520 2789900)
[epoch_0]_27901  loss=3.447294 |g|=0.36	lr=5.80e-04 | 85.7%@S23  T=1.56s eta=14:21:17 | 73.8K token/s | 
[epoch_0]_27911  loss=3.413672 |g|=0.397	lr=5.80e-04 | 86.5%@S23  T=1.04s eta=09:35:04 | 74.0K token/s | 
[epoch_0]_27921  loss=3.426275 |g|=0.381	lr=5.79e-04 | 87.3%@S23  T=1.04s eta=09:32:01 | 74.3K token/s | 
[epoch_0]_27931  loss=3.429502 |g|=0.393	lr=5.79e-04 | 88.1%@S23  T=1.06s eta=09:43:31 | 74.4K token/s | 
[epoch_0]_27941  loss=3.362553 |g|=0.372	lr=5.79e-04 | 88.9%@S23  T=1.05s eta=09:38:24 | 74.6K token/s | 
[epoch_0]_27951  loss=3.358464 |g|=0.357	lr=5.78e-04 | 89.8%@S23  T=1.05s eta=09:41:00 | 74.8K token/s | 
[epoch_0]_27961  loss=3.297249 |g|=0.386	lr=5.78e-04 | 90.6%@S23  T=1.05s eta=09:36:19 | 74.9K token/s | 
[epoch_0]_27971  loss=3.427192 |g|=0.379	lr=5.78e-04 | 91.4%@S23  T=1.06s eta=09:41:47 | 75.1K token/s | 
[epoch_0]_27981  loss=3.387962 |g|=0.362	lr=5.78e-04 | 92.2%@S23  T=1.07s eta=09:49:24 | 75.1K token/s | 
[epoch_0]_27991  loss=3.334126 |g|=0.385	lr=5.77e-04 | 93.0%@S23  T=1.07s eta=09:51:14 | 75.2K token/s | 
[Fuyou] head="3" update algorithm=4 t=2.02s
[eval] 
	 Loss@"edu_fineweb1B"=3.394(0.0018) nBranch=1 nToken=4.01M best=3.3901(132) E2T=0.0312 T=13.4923(0)s x=0
	#3.39443±0.1089 tps=298K(4.01408M) a=[3.21254,3.68511] T=13.4923(sec)
[Section@28000] layer[24-30] tasks=15(nPassBack=0) last_loss=3.36319(0.0120459) N=(580,24024,23604 2799900)
[epoch_0]_28001  loss=3.377429 |g|=0.391	lr=5.77e-04 | 93.8%@S23  T=4.17s eta=1d 14:13:52 | 72.4K token/s | 
[epoch_0]_28011  loss=3.409637 |g|=0.377	lr=5.77e-04 | 94.7%@S23  T=1.05s eta=09:36:44 | 72.7K token/s | 
[epoch_0]_28021  loss=3.345036 |g|=0.423	lr=5.77e-04 | 95.5%@S23  T=1.04s eta=09:30:32 | 73.0K token/s | 
[epoch_0]_28031  loss=3.453599 |g|=0.412	lr=5.76e-04 | 96.3%@S23  T=1.06s eta=09:43:01 | 73.2K token/s | 
[epoch_0]_28041  loss=3.348536 |g|=0.361	lr=5.76e-04 | 97.1%@S23  T=1.08s eta=09:53:40 | 73.4K token/s | 
[epoch_0]_28051  loss=3.408533 |g|=0.367	lr=5.76e-04 | 97.9%@S23  T=1.04s eta=09:30:57 | 73.6K token/s | 
[epoch_0]_28061  loss=3.356102 |g|=0.383	lr=5.76e-04 | 98.8%@S23  T=1.03s eta=09:26:05 | 73.9K token/s | 
[epoch_0]_28071  loss=3.378239 |g|=0.4	lr=5.75e-04 | 99.6%@S23  T=1.03s eta=09:27:20 | 74.2K token/s | 
[epoch_0]_28076  loss=3.373740 |g|=0.402	lr=5.75e-04 | 100.0%@S23  T=1.05s eta=09:35:36 | 74.4K token/s | 
-------- End of shard_23@"./Datasets/edu_fineweb1B/edu_fineweb_train_000476.bin"-------- 
[shard-24]@"./Datasets/edu_fineweb1B/edu_fineweb_train_000477.bin": tokens=100(M) nShardSamples=1220(2343744) 
[epoch_0]_28081  loss=3.442145 |g|=0.4	lr=5.75e-04 | 0.4%@S24  T=1.07s eta=09:46:20 | 74.5K token/s | 
[epoch_0]_28091  loss=3.423033 |g|=0.413	lr=5.75e-04 | 1.2%@S24  T=1.06s eta=09:41:08 | 74.7K token/s | 
[Fuyou] head="4" update algorithm=4 t=2.07s
[Section@28100] layer[30-36] tasks=15(nPassBack=0) last_loss=3.42359(-0.0691149) N=(580,24108,23688 2809900)
[epoch_0]_28101  loss=3.443081 |g|=0.389	lr=5.75e-04 | 2.0%@S24  T=1.45s eta=13:15:20 | 73.8K token/s | 
[epoch_0]_28111  loss=3.383850 |g|=0.372	lr=5.74e-04 | 2.9%@S24  T=1.03s eta=09:26:50 | 74.0K token/s | 
[epoch_0]_28121  loss=3.427800 |g|=0.435	lr=5.74e-04 | 3.7%@S24  T=1.04s eta=09:30:36 | 74.3K token/s | 
[epoch_0]_28131  loss=3.350211 |g|=0.369	lr=5.74e-04 | 4.5%@S24  T=1.05s eta=09:36:00 | 74.5K token/s | 
[epoch_0]_28141  loss=3.392111 |g|=0.361	lr=5.74e-04 | 5.3%@S24  T=1.03s eta=09:26:34 | 74.7K token/s | 
[epoch_0]_28151  loss=3.365251 |g|=0.399	lr=5.73e-04 | 6.1%@S24  T=1.04s eta=09:28:49 | 74.9K token/s | 
[epoch_0]_28161  loss=3.386683 |g|=0.37	lr=5.73e-04 | 7.0%@S24  T=1.04s eta=09:30:54 | 75.1K token/s | 
[epoch_0]_28171  loss=3.400175 |g|=0.407	lr=5.73e-04 | 7.8%@S24  T=1.05s eta=09:35:08 | 75.2K token/s | 
[epoch_0]_28181  loss=3.344312 |g|=0.385	lr=5.73e-04 | 8.6%@S24  T=1.09s eta=09:54:56 | 75.3K token/s | 
[epoch_0]_28191  loss=3.412739 |g|=0.406	lr=5.72e-04 | 9.4%@S24  T=1.04s eta=09:29:13 | 75.4K token/s | 
[Fuyou] head="5" update algorithm=4 t=2.06s
[eval] 
	 Loss@"edu_fineweb1B"=3.382(0.012) nBranch=1 nToken=4.01M best=3.3944(139) E2T=0.0152 T=13.487(0)s x=0
	#3.38219±0.1080 tps=298K(4.01408M) a=[3.19476,3.66955] T=13.487(sec)
[Section@28200] layer[0-6] tasks=15(nPassBack=0) last_loss=3.36697(0.125873) N=(580,24192,23772 2819900)
[epoch_0]_28201  loss=3.377838 |g|=0.365	lr=5.72e-04 | 10.2%@S24  T=4.14s eta=1d 13:43:18 | 72.6K token/s | 
[epoch_0]_28211  loss=3.361343 |g|=0.359	lr=5.72e-04 | 11.1%@S24  T=1.03s eta=09:25:09 | 73.0K token/s | 
[epoch_0]_28221  loss=3.375208 |g|=0.377	lr=5.72e-04 | 11.9%@S24  T=1.05s eta=09:35:18 | 73.2K token/s | 
[epoch_0]_28231  loss=3.408258 |g|=0.429	lr=5.71e-04 | 12.7%@S24  T=1.06s eta=09:38:39 | 73.4K token/s | 
[epoch_0]_28241  loss=3.458161 |g|=0.366	lr=5.71e-04 | 13.5%@S24  T=1.06s eta=09:39:43 | 73.6K token/s | 
[epoch_0]_28251  loss=3.444072 |g|=0.411	lr=5.71e-04 | 14.3%@S24  T=1.04s eta=09:30:16 | 73.9K token/s | 
[epoch_0]_28261  loss=3.367127 |g|=0.356	lr=5.71e-04 | 15.1%@S24  T=1.04s eta=09:27:53 | 74.1K token/s | 
[epoch_0]_28271  loss=3.312091 |g|=0.387	lr=5.70e-04 | 16.0%@S24  T=1.04s eta=09:28:46 | 74.3K token/s | 
[epoch_0]_28281  loss=3.457706 |g|=0.369	lr=5.70e-04 | 16.8%@S24  T=1.08s eta=09:48:18 | 74.4K token/s | 
[epoch_0]_28291  loss=3.374923 |g|=0.38	lr=5.70e-04 | 17.6%@S24  T=1.04s eta=09:28:10 | 74.6K token/s | 
[Fuyou] head="0" update algorithm=4 t=2.05s
[Section@28300] layer[6-12] tasks=15(nPassBack=0) last_loss=3.34635(0.065778) N=(580,24276,23856 2829900)
[epoch_0]_28301  loss=3.399217 |g|=0.362	lr=5.70e-04 | 18.4%@S24  T=1.34s eta=12:09:24 | 74.0K token/s | 
[epoch_0]_28311  loss=3.464370 |g|=0.394	lr=5.69e-04 | 19.2%@S24  T=1.03s eta=09:22:17 | 74.2K token/s | 
[epoch_0]_28321  loss=3.438905 |g|=0.368	lr=5.69e-04 | 20.1%@S24  T=1.06s eta=09:39:32 | 74.4K token/s | 
[epoch_0]_28331  loss=3.474250 |g|=0.399	lr=5.69e-04 | 20.9%@S24  T=1.04s eta=09:25:05 | 74.6K token/s | 
[epoch_0]_28341  loss=3.432022 |g|=0.415	lr=5.69e-04 | 21.7%@S24  T=1.03s eta=09:19:45 | 74.9K token/s | 
[epoch_0]_28351  loss=3.383040 |g|=0.419	lr=5.68e-04 | 22.5%@S24  T=1.04s eta=09:24:38 | 75.1K token/s | 
[epoch_0]_28361  loss=3.382669 |g|=0.389	lr=5.68e-04 | 23.3%@S24  T=1.05s eta=09:30:37 | 75.2K token/s | 
[epoch_0]_28371  loss=3.361583 |g|=0.381	lr=5.68e-04 | 24.2%@S24  T=1.08s eta=09:47:30 | 75.3K token/s | 
[epoch_0]_28381  loss=3.340884 |g|=0.413	lr=5.68e-04 | 25.0%@S24  T=1.03s eta=09:21:55 | 75.5K token/s | 
[epoch_0]_28391  loss=3.389908 |g|=0.397	lr=5.67e-04 | 25.8%@S24  T=1.04s eta=09:26:34 | 75.6K token/s | 
[Fuyou] head="1" update algorithm=4 t=2.07s
[eval] 
	 Loss@"edu_fineweb1B"=3.380(0.0026) nBranch=1 nToken=4.01M best=3.3822(140) E2T=-0.043 T=13.4899(0)s x=0
	#3.37963±0.1078 tps=298K(4.01408M) a=[3.18929,3.66399] T=13.4899(sec)
[Section@28400] layer[12-18] tasks=15(nPassBack=0) last_loss=3.42266(-0.0422206) N=(580,24360,23940 2839900)
[epoch_0]_28401  loss=3.338641 |g|=0.36	lr=5.67e-04 | 26.6%@S24  T=4.16s eta=1d 13:44:37 | 72.8K token/s | 
[epoch_0]_28411  loss=3.458736 |g|=0.417	lr=5.67e-04 | 27.4%@S24  T=1.07s eta=09:41:52 | 73.0K token/s | 
[epoch_0]_28421  loss=3.408772 |g|=0.382	lr=5.67e-04 | 28.3%@S24  T=1.03s eta=09:20:18 | 73.3K token/s | 
[epoch_0]_28431  loss=3.460879 |g|=0.408	lr=5.66e-04 | 29.1%@S24  T=1.05s eta=09:28:27 | 73.6K token/s | 
[epoch_0]_28441  loss=3.372291 |g|=0.389	lr=5.66e-04 | 29.9%@S24  T=1.06s eta=09:36:53 | 73.8K token/s | 
[epoch_0]_28451  loss=3.356432 |g|=0.371	lr=5.66e-04 | 30.7%@S24  T=1.07s eta=09:39:19 | 73.9K token/s | 
[epoch_0]_28461  loss=3.369730 |g|=0.397	lr=5.65e-04 | 31.5%@S24  T=1.04s eta=09:27:14 | 74.1K token/s | 
[epoch_0]_28471  loss=3.451068 |g|=0.415	lr=5.65e-04 | 32.4%@S24  T=1.04s eta=09:24:26 | 74.4K token/s | 
[epoch_0]_28481  loss=3.373197 |g|=0.378	lr=5.65e-04 | 33.2%@S24  T=1.04s eta=09:25:30 | 74.6K token/s | 
[epoch_0]_28491  loss=3.448516 |g|=0.394	lr=5.65e-04 | 34.0%@S24  T=1.06s eta=09:32:17 | 74.7K token/s | 
[Fuyou] head="2" update algorithm=4 t=2.14s
[Section@28500] layer[18-24] tasks=15(nPassBack=0) last_loss=3.30247(0.114515) N=(580,24444,24024 2849900)
[epoch_0]_28501  loss=3.391918 |g|=0.372	lr=5.64e-04 | 34.8%@S24  T=1.42s eta=12:49:04 | 73.9K token/s | 
[epoch_0]_28511  loss=3.349710 |g|=0.398	lr=5.64e-04 | 35.6%@S24  T=1.04s eta=09:23:16 | 74.1K token/s | 
[epoch_0]_28521  loss=3.377825 |g|=0.363	lr=5.64e-04 | 36.4%@S24  T=1.06s eta=09:32:42 | 74.3K token/s | 
[epoch_0]_28531  loss=3.394910 |g|=0.448	lr=5.64e-04 | 37.3%@S24  T=1.04s eta=09:25:38 | 74.5K token/s | 
[epoch_0]_28541  loss=3.425975 |g|=0.395	lr=5.63e-04 | 38.1%@S24  T=1.09s eta=09:47:44 | 74.6K token/s | 
[epoch_0]_28551  loss=3.333559 |g|=0.416	lr=5.63e-04 | 38.9%@S24  T=1.03s eta=09:19:37 | 74.8K token/s | 
[epoch_0]_28561  loss=3.435024 |g|=0.357	lr=5.63e-04 | 39.7%@S24  T=1.03s eta=09:19:12 | 75.0K token/s | 
[epoch_0]_28571  loss=3.360339 |g|=0.392	lr=5.63e-04 | 40.5%@S24  T=1.05s eta=09:28:39 | 75.2K token/s | 
[epoch_0]_28581  loss=3.470398 |g|=0.366	lr=5.62e-04 | 41.4%@S24  T=1.04s eta=09:24:30 | 75.3K token/s | 
[epoch_0]_28591  loss=3.410868 |g|=0.38	lr=5.62e-04 | 42.2%@S24  T=1.08s eta=09:42:01 | 75.4K token/s | 
[Fuyou] head="3" update algorithm=4 t=2.10s
[eval] 
	 Loss@"edu_fineweb1B"=3.376(0.0032) nBranch=1 nToken=4.01M best=3.3796(141) E2T=-0.0149 T=13.5077(0)s x=0
	#3.37645±0.1073 tps=297K(4.01408M) a=[3.18944,3.65891] T=13.5077(sec)
[Section@28600] layer[24-30] tasks=15(nPassBack=0) last_loss=3.39132(-0.0281258) N=(580,24528,24108 2859900)
[epoch_0]_28601  loss=3.411481 |g|=0.347	lr=5.62e-04 | 43.0%@S24  T=4.19s eta=1d 13:47:16 | 72.6K token/s | 
[epoch_0]_28611  loss=3.402679 |g|=0.372	lr=5.62e-04 | 43.8%@S24  T=1.08s eta=09:45:38 | 72.7K token/s | 
[epoch_0]_28621  loss=3.388274 |g|=0.414	lr=5.61e-04 | 44.6%@S24  T=1.03s eta=09:15:39 | 73.1K token/s | 
[epoch_0]_28631  loss=3.473240 |g|=0.406	lr=5.61e-04 | 45.5%@S24  T=1.05s eta=09:27:51 | 73.3K token/s | 
[epoch_0]_28641  loss=3.399450 |g|=0.392	lr=5.61e-04 | 46.3%@S24  T=1.08s eta=09:44:12 | 73.4K token/s | 
[epoch_0]_28651  loss=3.363870 |g|=0.357	lr=5.61e-04 | 47.1%@S24  T=1.03s eta=09:18:34 | 73.7K token/s | 
[epoch_0]_28661  loss=3.375469 |g|=0.412	lr=5.60e-04 | 47.9%@S24  T=1.04s eta=09:18:51 | 74.0K token/s | 
[epoch_0]_28671  loss=3.368067 |g|=0.435	lr=5.60e-04 | 48.7%@S24  T=1.04s eta=09:22:33 | 74.2K token/s | 
[epoch_0]_28681  loss=3.305436 |g|=0.412	lr=5.60e-04 | 49.6%@S24  T=1.04s eta=09:22:13 | 74.4K token/s | 
[epoch_0]_28691  loss=3.411849 |g|=0.38	lr=5.60e-04 | 50.4%@S24  T=1.08s eta=09:44:43 | 74.5K token/s | 
[Fuyou] head="4" update algorithm=4 t=2.13s
[Section@28700] layer[30-36] tasks=15(nPassBack=0) last_loss=3.39194(0.0316503) N=(580,24612,24192 2869900)
[epoch_0]_28701  loss=3.359995 |g|=0.354	lr=5.59e-04 | 51.2%@S24  T=1.36s eta=12:12:30 | 73.8K token/s | 
[epoch_0]_28711  loss=3.461967 |g|=0.365	lr=5.59e-04 | 52.0%@S24  T=1.04s eta=09:18:35 | 74.0K token/s | 
[epoch_0]_28721  loss=3.319345 |g|=0.366	lr=5.59e-04 | 52.8%@S24  T=1.04s eta=09:19:43 | 74.3K token/s | 
[epoch_0]_28731  loss=3.404344 |g|=0.381	lr=5.59e-04 | 53.7%@S24  T=1.08s eta=09:43:44 | 74.3K token/s | 
[epoch_0]_28741  loss=3.330753 |g|=0.407	lr=5.58e-04 | 54.5%@S24  T=1.03s eta=09:16:17 | 74.6K token/s | 
[epoch_0]_28751  loss=3.311617 |g|=0.368	lr=5.58e-04 | 55.3%@S24  T=1.04s eta=09:20:01 | 74.8K token/s | 
[epoch_0]_28761  loss=3.383727 |g|=0.359	lr=5.58e-04 | 56.1%@S24  T=1.04s eta=09:19:49 | 75.0K token/s | 
[epoch_0]_28771  loss=3.405506 |g|=0.378	lr=5.58e-04 | 56.9%@S24  T=1.04s eta=09:21:02 | 75.2K token/s | 
[epoch_0]_28781  loss=3.404869 |g|=0.431	lr=5.57e-04 | 57.7%@S24  T=1.07s eta=09:34:09 | 75.2K token/s | 
[epoch_0]_28791  loss=3.353236 |g|=0.357	lr=5.57e-04 | 58.6%@S24  T=1.03s eta=09:15:35 | 75.4K token/s | 
[Fuyou] head="5" update algorithm=4 t=2.08s
[eval] 
	 Loss@"edu_fineweb1B"=3.373(0.0035) nBranch=1 nToken=4.01M best=3.3765(142) E2T=-0.0207 T=13.4952(0)s x=0
	#3.37294±0.1077 tps=297K(4.01408M) a=[3.18556,3.65332] T=13.4952(sec)
[Section@28800] layer[0-6] tasks=15(nPassBack=0) last_loss=3.39368(-0.0267031) N=(580,24696,24276 2879900)
[epoch_0]_28801  loss=3.404297 |g|=0.382	lr=5.57e-04 | 59.4%@S24  T=4.20s eta=1d 13:34:54 | 72.6K token/s | 
[epoch_0]_28811  loss=3.359820 |g|=0.402	lr=5.57e-04 | 60.2%@S24  T=1.05s eta=09:21:31 | 72.9K token/s | 
[epoch_0]_28821  loss=3.368470 |g|=0.389	lr=5.56e-04 | 61.0%@S24  T=1.05s eta=09:26:05 | 73.2K token/s | 
[epoch_0]_28831  loss=3.395607 |g|=0.411	lr=5.56e-04 | 61.8%@S24  T=1.04s eta=09:18:20 | 73.5K token/s | 
[epoch_0]_28841  loss=3.373729 |g|=0.405	lr=5.56e-04 | 62.7%@S24  T=1.03s eta=09:12:25 | 73.8K token/s | 
[epoch_0]_28851  loss=3.368727 |g|=0.376	lr=5.56e-04 | 63.5%@S24  T=1.04s eta=09:17:14 | 74.0K token/s | 
[epoch_0]_28861  loss=3.367632 |g|=0.399	lr=5.55e-04 | 64.3%@S24  T=1.08s eta=09:36:48 | 74.1K token/s | 
[epoch_0]_28871  loss=3.387982 |g|=0.394	lr=5.55e-04 | 65.1%@S24  T=1.07s eta=09:31:22 | 74.3K token/s | 
[epoch_0]_28881  loss=3.369286 |g|=0.388	lr=5.55e-04 | 65.9%@S24  T=1.04s eta=09:15:35 | 74.5K token/s | 
[epoch_0]_28891  loss=3.431695 |g|=0.363	lr=5.54e-04 | 66.8%@S24  T=1.05s eta=09:24:54 | 74.7K token/s | 
[Fuyou] head="0" update algorithm=4 t=2.09s
[Section@28900] layer[6-12] tasks=15(nPassBack=0) last_loss=3.40688(-0.0605283) N=(580,24780,24360 2889900)
[epoch_0]_28901  loss=3.382784 |g|=0.349	lr=5.54e-04 | 67.6%@S24  T=1.38s eta=12:20:52 | 73.9K token/s | 
[epoch_0]_28911  loss=3.378295 |g|=0.396	lr=5.54e-04 | 68.4%@S24  T=1.03s eta=09:09:26 | 74.2K token/s | 
[epoch_0]_28921  loss=3.363575 |g|=0.368	lr=5.54e-04 | 69.2%@S24  T=1.04s eta=09:14:33 | 74.4K token/s | 
[epoch_0]_28931  loss=3.447561 |g|=0.383	lr=5.53e-04 | 70.0%@S24  T=1.04s eta=09:18:27 | 74.6K token/s | 
[epoch_0]_28941  loss=3.418059 |g|=0.384	lr=5.53e-04 | 70.9%@S24  T=1.05s eta=09:20:53 | 74.8K token/s | 
[epoch_0]_28951  loss=3.366318 |g|=0.369	lr=5.53e-04 | 71.7%@S24  T=1.04s eta=09:18:25 | 75.0K token/s | 
[epoch_0]_28961  loss=3.391867 |g|=0.37	lr=5.53e-04 | 72.5%@S24  T=1.09s eta=09:42:25 | 75.0K token/s | 
[epoch_0]_28971  loss=3.341322 |g|=0.389	lr=5.52e-04 | 73.3%@S24  T=1.04s eta=09:15:03 | 75.2K token/s | 
[epoch_0]_28981  loss=3.345841 |g|=0.361	lr=5.52e-04 | 74.1%@S24  T=1.03s eta=09:10:42 | 75.4K token/s | 
[epoch_0]_28991  loss=3.298686 |g|=0.388	lr=5.52e-04 | 74.9%@S24  T=1.03s eta=09:12:07 | 75.6K token/s | 
[Fuyou] head="1" update algorithm=4 t=2.10s
[eval] 
	 Loss@"edu_fineweb1B"=3.371(0.0019) nBranch=1 nToken=4.01M best=3.3729(143) E2T=-0.0594 T=13.4977(0)s x=0
	#3.37101±0.1079 tps=297K(4.01408M) a=[3.1838,3.65071] T=13.4977(sec)
[Section@29000] layer[12-18] tasks=15(nPassBack=0) last_loss=3.43045(-0.00778985) N=(580,24864,24444 2899900)
[epoch_0]_29001  loss=3.356542 |g|=0.375	lr=5.52e-04 | 75.8%@S24  T=4.19s eta=1d 13:18:20 | 72.8K token/s | 
[epoch_0]_29011  loss=3.358398 |g|=0.374	lr=5.51e-04 | 76.6%@S24  T=1.06s eta=09:27:07 | 73.0K token/s | 
[epoch_0]_29021  loss=3.362618 |g|=0.378	lr=5.51e-04 | 77.4%@S24  T=1.04s eta=09:16:26 | 73.3K token/s | 
[epoch_0]_29031  loss=3.330674 |g|=0.407	lr=5.51e-04 | 78.2%@S24  T=1.05s eta=09:19:33 | 73.5K token/s | 
[epoch_0]_29041  loss=3.402217 |g|=0.391	lr=5.51e-04 | 79.0%@S24  T=1.05s eta=09:18:09 | 73.8K token/s | 
[epoch_0]_29051  loss=3.425213 |g|=0.389	lr=5.50e-04 | 79.9%@S24  T=1.08s eta=09:38:22 | 73.8K token/s | 
[epoch_0]_29061  loss=3.358222 |g|=0.358	lr=5.50e-04 | 80.7%@S24  T=1.02s eta=09:06:07 | 74.2K token/s | 
[epoch_0]_29071  loss=3.329542 |g|=0.35	lr=5.50e-04 | 81.5%@S24  T=1.04s eta=09:11:44 | 74.4K token/s | 
[epoch_0]_29081  loss=3.350000 |g|=0.387	lr=5.50e-04 | 82.3%@S24  T=1.05s eta=09:20:43 | 74.6K token/s | 
[epoch_0]_29091  loss=3.432055 |g|=0.387	lr=5.49e-04 | 83.1%@S24  T=1.06s eta=09:26:38 | 74.7K token/s | 
[Fuyou] head="2" update algorithm=4 t=2.11s
[Section@29100] layer[18-24] tasks=15(nPassBack=0) last_loss=3.43292(-0.130442) N=(580,24948,24528 2909900)
[epoch_0]_29101  loss=3.311310 |g|=0.377	lr=5.49e-04 | 84.0%@S24  T=1.39s eta=12:19:32 | 73.9K token/s | 
[epoch_0]_29111  loss=3.405556 |g|=0.376	lr=5.49e-04 | 84.8%@S24  T=1.03s eta=09:06:48 | 74.2K token/s | 
[epoch_0]_29121  loss=3.353947 |g|=0.398	lr=5.49e-04 | 85.6%@S24  T=1.04s eta=09:12:31 | 74.4K token/s | 
[epoch_0]_29131  loss=3.371712 |g|=0.38	lr=5.48e-04 | 86.4%@S24  T=1.05s eta=09:18:29 | 74.6K token/s | 
[epoch_0]_29141  loss=3.368916 |g|=0.372	lr=5.48e-04 | 87.2%@S24  T=1.06s eta=09:24:02 | 74.7K token/s | 
[epoch_0]_29151  loss=3.449551 |g|=0.405	lr=5.48e-04 | 88.1%@S24  T=1.09s eta=09:41:33 | 74.7K token/s | 
[epoch_0]_29161  loss=3.379624 |g|=0.372	lr=5.48e-04 | 88.9%@S24  T=1.03s eta=09:09:30 | 75.0K token/s | 
[epoch_0]_29171  loss=3.382842 |g|=0.395	lr=5.47e-04 | 89.7%@S24  T=1.05s eta=09:15:06 | 75.1K token/s | 
[epoch_0]_29181  loss=3.430685 |g|=0.384	lr=5.47e-04 | 90.5%@S24  T=1.06s eta=09:22:15 | 75.2K token/s | 
[epoch_0]_29191  loss=3.422393 |g|=0.388	lr=5.47e-04 | 91.3%@S24  T=1.05s eta=09:18:34 | 75.4K token/s | 
[Fuyou] head="3" update algorithm=4 t=2.03s
[eval] 
	 Loss@"edu_fineweb1B"=3.368(0.0028) nBranch=1 nToken=4.01M best=3.3710(144) E2T=-0.0115 T=13.5052(0)s x=0
	#3.36825±0.1081 tps=297K(4.01408M) a=[3.1815,3.6516] T=13.5052(sec)
[Section@29200] layer[24-30] tasks=15(nPassBack=0) last_loss=3.37973(0.0115876) N=(580,25032,24612 2919900)
[epoch_0]_29201  loss=3.279251 |g|=0.337	lr=5.47e-04 | 92.2%@S24  T=4.17s eta=1d 12:52:46 | 72.6K token/s | 
[epoch_0]_29211  loss=3.350728 |g|=0.381	lr=5.46e-04 | 93.0%@S24  T=1.08s eta=09:31:47 | 72.8K token/s | 
[epoch_0]_29221  loss=3.374765 |g|=0.413	lr=5.46e-04 | 93.8%@S24  T=1.04s eta=09:11:19 | 73.1K token/s | 
[epoch_0]_29231  loss=3.423488 |g|=0.405	lr=5.46e-04 | 94.6%@S24  T=1.05s eta=09:15:54 | 73.3K token/s | 
[epoch_0]_29241  loss=3.340811 |g|=0.402	lr=5.46e-04 | 95.4%@S24  T=1.07s eta=09:25:05 | 73.5K token/s | 
[epoch_0]_29251  loss=3.420070 |g|=0.371	lr=5.45e-04 | 96.2%@S24  T=1.06s eta=09:19:56 | 73.7K token/s | 
[epoch_0]_29261  loss=3.385234 |g|=0.378	lr=5.45e-04 | 97.1%@S24  T=1.03s eta=09:06:39 | 74.0K token/s | 
[epoch_0]_29271  loss=3.420743 |g|=0.377	lr=5.45e-04 | 97.9%@S24  T=1.04s eta=09:08:56 | 74.2K token/s | 
[epoch_0]_29281  loss=3.419941 |g|=0.383	lr=5.44e-04 | 98.7%@S24  T=1.05s eta=09:16:19 | 74.4K token/s | 
[epoch_0]_29291  loss=3.322436 |g|=0.394	lr=5.44e-04 | 99.5%@S24  T=1.07s eta=09:23:30 | 74.5K token/s | 
[epoch_0]_29296  loss=3.383423 |g|=0.37	lr=5.44e-04 | 99.9%@S24  T=1.09s eta=09:35:03 | 74.6K token/s | 
-------- End of shard_24@"./Datasets/edu_fineweb1B/edu_fineweb_train_000477.bin"-------- 
[shard-25]@"./Datasets/edu_fineweb1B/edu_fineweb_train_000478.bin": tokens=100(M) nShardSamples=1220(2441400) 
[Fuyou] head="4" update algorithm=4 t=2.06s
[Section@29300] layer[30-36] tasks=15(nPassBack=0) last_loss=3.42098(-0.0290387) N=(580,25116,24696 2929900)
[epoch_0]_29301  loss=3.421076 |g|=0.384	lr=5.44e-04 | 0.3%@S25  T=1.33s eta=11:43:26 | 73.9K token/s | 
[epoch_0]_29311  loss=3.346292 |g|=0.389	lr=5.44e-04 | 1.2%@S25  T=1.07s eta=09:24:06 | 74.1K token/s | 
[epoch_0]_29321  loss=3.431782 |g|=0.41	lr=5.43e-04 | 2.0%@S25  T=1.06s eta=09:20:04 | 74.2K token/s | 
[epoch_0]_29331  loss=3.359400 |g|=0.392	lr=5.43e-04 | 2.8%@S25  T=1.05s eta=09:16:42 | 74.4K token/s | 
[epoch_0]_29341  loss=3.344625 |g|=0.392	lr=5.43e-04 | 3.6%@S25  T=1.03s eta=09:01:32 | 74.7K token/s | 
[epoch_0]_29351  loss=3.391740 |g|=0.377	lr=5.43e-04 | 4.4%@S25  T=1.04s eta=09:09:18 | 74.9K token/s | 
[epoch_0]_29361  loss=3.489607 |g|=0.386	lr=5.42e-04 | 5.3%@S25  T=1.04s eta=09:10:19 | 75.1K token/s | 
[epoch_0]_29371  loss=3.355459 |g|=0.398	lr=5.42e-04 | 6.1%@S25  T=1.06s eta=09:17:05 | 75.2K token/s | 
[epoch_0]_29381  loss=3.381888 |g|=0.372	lr=5.42e-04 | 6.9%@S25  T=1.07s eta=09:25:47 | 75.3K token/s | 
[epoch_0]_29391  loss=3.337808 |g|=0.385	lr=5.42e-04 | 7.7%@S25  T=1.04s eta=09:06:15 | 75.4K token/s | 
[Fuyou] head="5" update algorithm=4 t=2.01s
[eval] 
	 Loss@"edu_fineweb1B"=3.374(-0.0053) nBranch=1 nToken=4.01M best=3.3710(144) E2T=0.0126 T=13.4913(0)s x=0
	#3.37351±0.1068 tps=298K(4.01408M) a=[3.18716,3.65404] T=13.4913(sec)
[Section@29400] layer[0-6] tasks=15(nPassBack=0) last_loss=3.36094(0.0327349) N=(580,25200,24780 2939900)
[epoch_0]_29401  loss=3.314363 |g|=0.357	lr=5.41e-04 | 8.5%@S25  T=4.17s eta=1d 12:39:02 | 72.7K token/s | 
[epoch_0]_29411  loss=3.407470 |g|=0.401	lr=5.41e-04 | 9.4%@S25  T=1.06s eta=09:20:57 | 72.9K token/s | 
[epoch_0]_29421  loss=3.377088 |g|=0.353	lr=5.41e-04 | 10.2%@S25  T=1.06s eta=09:19:46 | 73.1K token/s | 
[epoch_0]_29431  loss=3.378255 |g|=0.38	lr=5.41e-04 | 11.0%@S25  T=1.04s eta=09:09:23 | 73.4K token/s | 
[epoch_0]_29441  loss=3.393986 |g|=0.388	lr=5.40e-04 | 11.8%@S25  T=1.05s eta=09:11:21 | 73.6K token/s | 
[epoch_0]_29451  loss=3.311028 |g|=0.379	lr=5.40e-04 | 12.6%@S25  T=1.05s eta=09:12:30 | 73.8K token/s | 
[epoch_0]_29461  loss=3.326783 |g|=0.414	lr=5.40e-04 | 13.5%@S25  T=1.08s eta=09:27:28 | 73.9K token/s | 
[epoch_0]_29471  loss=3.363608 |g|=0.401	lr=5.40e-04 | 14.3%@S25  T=1.03s eta=09:03:29 | 74.2K token/s | 
[epoch_0]_29481  loss=3.343809 |g|=0.362	lr=5.39e-04 | 15.1%@S25  T=1.05s eta=09:13:27 | 74.4K token/s | 
[epoch_0]_29491  loss=3.381945 |g|=0.391	lr=5.39e-04 | 15.9%@S25  T=1.05s eta=09:14:03 | 74.5K token/s | 
[Fuyou] head="0" update algorithm=4 t=2.09s
[Section@29500] layer[6-12] tasks=15(nPassBack=0) last_loss=3.34815(0.058728) N=(580,25284,24864 2949900)
[epoch_0]_29501  loss=3.389848 |g|=0.357	lr=5.39e-04 | 16.7%@S25  T=1.35s eta=11:48:10 | 73.9K token/s | 
[epoch_0]_29511  loss=3.413155 |g|=0.384	lr=5.39e-04 | 17.5%@S25  T=1.03s eta=09:03:46 | 74.1K token/s | 
[epoch_0]_29521  loss=3.405942 |g|=0.387	lr=5.38e-04 | 18.4%@S25  T=1.04s eta=09:06:53 | 74.4K token/s | 
[epoch_0]_29531  loss=3.389225 |g|=0.403	lr=5.38e-04 | 19.2%@S25  T=1.04s eta=09:07:18 | 74.6K token/s | 
[epoch_0]_29541  loss=3.365548 |g|=0.39	lr=5.38e-04 | 20.0%@S25  T=1.04s eta=09:05:43 | 74.8K token/s | 
[epoch_0]_29551  loss=3.366619 |g|=0.383	lr=5.38e-04 | 20.8%@S25  T=1.07s eta=09:23:03 | 74.9K token/s | 
[epoch_0]_29561  loss=3.318265 |g|=0.413	lr=5.37e-04 | 21.6%@S25  T=1.06s eta=09:17:27 | 75.0K token/s | 
[epoch_0]_29571  loss=3.338719 |g|=0.372	lr=5.37e-04 | 22.5%@S25  T=1.04s eta=09:06:24 | 75.1K token/s | 
[epoch_0]_29581  loss=3.287399 |g|=0.402	lr=5.37e-04 | 23.3%@S25  T=1.04s eta=09:04:46 | 75.3K token/s | 
[epoch_0]_29591  loss=3.333996 |g|=0.38	lr=5.37e-04 | 24.1%@S25  T=1.06s eta=09:13:31 | 75.4K token/s | 
[Fuyou] head="1" update algorithm=4 t=2.06s
[eval] 
	 Loss@"edu_fineweb1B"=3.374(-2.3e-05) nBranch=1 nToken=4.01M best=3.3710(144) E2T=0.0265 T=13.4963(0)s x=0
	#3.37353±0.1078 tps=297K(4.01408M) a=[3.18521,3.6611] T=13.4963(sec)
[Section@29600] layer[12-18] tasks=15(nPassBack=0) last_loss=3.347(0.0834541) N=(580,25368,24948 2959900)
[epoch_0]_29601  loss=3.401047 |g|=0.358	lr=5.36e-04 | 24.9%@S25  T=4.16s eta=1d 12:19:44 | 72.7K token/s | 
[epoch_0]_29611  loss=3.375072 |g|=0.389	lr=5.36e-04 | 25.7%@S25  T=1.04s eta=09:05:21 | 73.0K token/s | 
[epoch_0]_29621  loss=3.339572 |g|=0.398	lr=5.36e-04 | 26.6%@S25  T=1.05s eta=09:08:42 | 73.2K token/s | 
[epoch_0]_29631  loss=3.397080 |g|=0.359	lr=5.36e-04 | 27.4%@S25  T=1.05s eta=09:10:24 | 73.5K token/s | 
[epoch_0]_29641  loss=3.359632 |g|=0.354	lr=5.35e-04 | 28.2%@S25  T=1.07s eta=09:19:28 | 73.6K token/s | 
[epoch_0]_29651  loss=3.377343 |g|=0.386	lr=5.35e-04 | 29.0%@S25  T=1.05s eta=09:09:48 | 73.8K token/s | 
[epoch_0]_29661  loss=3.350191 |g|=0.397	lr=5.35e-04 | 29.8%@S25  T=1.05s eta=09:07:24 | 74.0K token/s | 
[epoch_0]_29671  loss=3.325122 |g|=0.354	lr=5.34e-04 | 30.7%@S25  T=1.04s eta=09:01:34 | 74.3K token/s | 
[epoch_0]_29681  loss=3.333020 |g|=0.375	lr=5.34e-04 | 31.5%@S25  T=1.06s eta=09:13:44 | 74.4K token/s | 
[epoch_0]_29691  loss=3.467293 |g|=0.359	lr=5.34e-04 | 32.3%@S25  T=1.08s eta=09:22:56 | 74.5K token/s | 
[Fuyou] head="2" update algorithm=4 t=2.07s
[Section@29700] layer[18-24] tasks=15(nPassBack=0) last_loss=3.39561(0.0373046) N=(580,25452,25032 2969900)
[epoch_0]_29701  loss=3.416780 |g|=0.35	lr=5.34e-04 | 33.1%@S25  T=1.40s eta=12:13:07 | 73.7K token/s | 
[epoch_0]_29711  loss=3.298465 |g|=0.353	lr=5.33e-04 | 33.9%@S25  T=1.03s eta=09:00:20 | 74.0K token/s | 
[epoch_0]_29721  loss=3.377701 |g|=0.38	lr=5.33e-04 | 34.8%@S25  T=1.05s eta=09:06:26 | 74.2K token/s | 
[epoch_0]_29731  loss=3.295126 |g|=0.409	lr=5.33e-04 | 35.6%@S25  T=1.05s eta=09:08:24 | 74.4K token/s | 
[epoch_0]_29741  loss=3.343174 |g|=0.402	lr=5.33e-04 | 36.4%@S25  T=1.09s eta=09:27:18 | 74.4K token/s | 
[epoch_0]_29751  loss=3.311325 |g|=0.411	lr=5.32e-04 | 37.2%@S25  T=1.03s eta=08:55:48 | 74.7K token/s | 
[epoch_0]_29761  loss=3.395947 |g|=0.41	lr=5.32e-04 | 38.0%@S25  T=1.05s eta=09:07:07 | 74.9K token/s | 
[epoch_0]_29771  loss=3.288013 |g|=0.38	lr=5.32e-04 | 38.8%@S25  T=1.04s eta=09:02:15 | 75.1K token/s | 
[epoch_0]_29781  loss=3.366920 |g|=0.384	lr=5.32e-04 | 39.7%@S25  T=1.05s eta=09:07:27 | 75.2K token/s | 
[epoch_0]_29791  loss=3.332542 |g|=0.39	lr=5.31e-04 | 40.5%@S25  T=1.09s eta=09:26:11 | 75.2K token/s | 
[Fuyou] head="3" update algorithm=4 t=2.16s
[eval] 
	 Loss@"edu_fineweb1B"=3.374(-0.00097) nBranch=1 nToken=4.01M best=3.3710(144) E2T=0.0236 T=13.5045(0)s x=0
	#3.37449±0.1084 tps=297K(4.01408M) a=[3.19159,3.66166] T=13.5045(sec)
[Section@29800] layer[24-30] tasks=15(nPassBack=0) last_loss=3.3509(0.028825) N=(580,25536,25116 2979900)
[epoch_0]_29801  loss=3.362048 |g|=0.379	lr=5.31e-04 | 41.3%@S25  T=4.19s eta=1d 12:23:12 | 72.4K token/s | 
[epoch_0]_29811  loss=3.354094 |g|=0.397	lr=5.31e-04 | 42.1%@S25  T=1.08s eta=09:24:10 | 72.6K token/s | 
[epoch_0]_29821  loss=3.316649 |g|=0.37	lr=5.31e-04 | 42.9%@S25  T=1.05s eta=09:03:55 | 72.9K token/s | 
[epoch_0]_29831  loss=3.396083 |g|=0.38	lr=5.30e-04 | 43.8%@S25  T=1.05s eta=09:07:50 | 73.1K token/s | 
[epoch_0]_29841  loss=3.337187 |g|=0.37	lr=5.30e-04 | 44.6%@S25  T=1.07s eta=09:14:45 | 73.3K token/s | 
[epoch_0]_29851  loss=3.360229 |g|=0.371	lr=5.30e-04 | 45.4%@S25  T=1.04s eta=08:59:05 | 73.6K token/s | 
[epoch_0]_29861  loss=3.449460 |g|=0.392	lr=5.30e-04 | 46.2%@S25  T=1.04s eta=08:59:53 | 73.8K token/s | 
[epoch_0]_29871  loss=3.384930 |g|=0.424	lr=5.29e-04 | 47.0%@S25  T=1.04s eta=09:00:53 | 74.1K token/s | 
[epoch_0]_29881  loss=3.345616 |g|=0.348	lr=5.29e-04 | 47.9%@S25  T=1.06s eta=09:09:47 | 74.3K token/s | 
[epoch_0]_29891  loss=3.230885 |g|=0.435	lr=5.29e-04 | 48.7%@S25  T=1.07s eta=09:12:49 | 74.4K token/s | 
[Fuyou] head="4" update algorithm=4 t=2.05s
[Section@29900] layer[30-36] tasks=15(nPassBack=0) last_loss=3.32285(0.0981233) N=(580,25620,25200 2989900)
[epoch_0]_29901  loss=3.393778 |g|=0.362	lr=5.29e-04 | 49.5%@S25  T=1.39s eta=12:01:53 | 73.6K token/s | 
[epoch_0]_29911  loss=3.266799 |g|=0.376	lr=5.28e-04 | 50.3%@S25  T=1.04s eta=08:58:29 | 73.9K token/s | 
[epoch_0]_29921  loss=3.397242 |g|=0.401	lr=5.28e-04 | 51.1%@S25  T=1.07s eta=09:16:21 | 74.0K token/s | 
[epoch_0]_29931  loss=3.461118 |g|=0.405	lr=5.28e-04 | 52.0%@S25  T=1.06s eta=09:08:33 | 74.2K token/s | 
[epoch_0]_29941  loss=3.420073 |g|=0.391	lr=5.28e-04 | 52.8%@S25  T=1.07s eta=09:15:08 | 74.3K token/s | 
[epoch_0]_29951  loss=3.354561 |g|=0.366	lr=5.27e-04 | 53.6%@S25  T=1.04s eta=08:59:52 | 74.5K token/s | 
[epoch_0]_29961  loss=3.281835 |g|=0.358	lr=5.27e-04 | 54.4%@S25  T=1.03s eta=08:55:42 | 74.7K token/s | 
[epoch_0]_29971  loss=3.350792 |g|=0.395	lr=5.27e-04 | 55.2%@S25  T=1.05s eta=09:01:38 | 74.9K token/s | 
[epoch_0]_29981  loss=3.481111 |g|=0.371	lr=5.27e-04 | 56.1%@S25  T=1.07s eta=09:12:34 | 75.0K token/s | 
[epoch_0]_29991  loss=3.330590 |g|=0.381	lr=5.26e-04 | 56.9%@S25  T=1.08s eta=09:17:21 | 75.1K token/s | 
[Fuyou] head="5" update algorithm=4 t=2.07s
[eval] 
	 Loss@"edu_fineweb1B"=3.376(-0.0015) nBranch=1 nToken=4.01M best=3.3710(144) E2T=0.0701 T=13.5042(0)s x=0
	#3.37597±0.1087 tps=297K(4.01408M) a=[3.18515,3.66412] T=13.5042(sec)
[Section@30000] layer[0-6] tasks=15(nPassBack=0) last_loss=3.30587(0.055068) N=(580,25704,25284 2999900)
[epoch_0]_30001  loss=3.416171 |g|=0.357	lr=5.26e-04 | 57.7%@S25  T=4.17s eta=1d 11:55:59 | 72.3K token/s | 
[epoch_0]_30011  loss=3.334470 |g|=0.368	lr=5.26e-04 | 58.5%@S25  T=1.04s eta=08:58:29 | 72.6K token/s | 
[epoch_0]_30021  loss=3.367734 |g|=0.428	lr=5.25e-04 | 59.3%@S25  T=1.04s eta=08:58:59 | 72.9K token/s | 
[epoch_0]_30031  loss=3.361583 |g|=0.381	lr=5.25e-04 | 60.1%@S25  T=1.04s eta=08:56:59 | 73.2K token/s | 
[epoch_0]_30041  loss=3.376492 |g|=0.376	lr=5.25e-04 | 61.0%@S25  T=1.05s eta=09:01:31 | 73.4K token/s | 
[epoch_0]_30051  loss=3.359478 |g|=0.384	lr=5.25e-04 | 61.8%@S25  T=1.05s eta=09:02:49 | 73.7K token/s | 
[epoch_0]_30061  loss=3.354790 |g|=0.378	lr=5.24e-04 | 62.6%@S25  T=1.04s eta=08:59:12 | 73.9K token/s | 
[epoch_0]_30071  loss=3.398068 |g|=0.391	lr=5.24e-04 | 63.4%@S25  T=1.06s eta=09:06:56 | 74.1K token/s | 
[epoch_0]_30081  loss=3.274932 |g|=0.41	lr=5.24e-04 | 64.2%@S25  T=1.08s eta=09:14:39 | 74.2K token/s | 
[epoch_0]_30091  loss=3.351738 |g|=0.4	lr=5.24e-04 | 65.1%@S25  T=1.03s eta=08:52:25 | 74.4K token/s | 
[Fuyou] head="0" update algorithm=4 t=1.99s
[Section@30100] layer[6-12] tasks=15(nPassBack=0) last_loss=3.36981(-0.0216599) N=(580,25788,25368 3009900)
[epoch_0]_30101  loss=3.374488 |g|=0.363	lr=5.23e-04 | 65.9%@S25  T=1.34s eta=11:28:51 | 73.8K token/s | 
[epoch_0]_30111  loss=3.323289 |g|=0.394	lr=5.23e-04 | 66.7%@S25  T=1.04s eta=08:58:23 | 74.0K token/s | 
[epoch_0]_30121  loss=3.382019 |g|=0.39	lr=5.23e-04 | 67.5%@S25  T=1.02s eta=08:47:54 | 74.3K token/s | 
[epoch_0]_30131  loss=3.348522 |g|=0.407	lr=5.23e-04 | 68.3%@S25  T=1.04s eta=08:54:09 | 74.5K token/s | 
[epoch_0]_30141  loss=3.300980 |g|=0.395	lr=5.22e-04 | 69.2%@S25  T=1.04s eta=08:54:55 | 74.8K token/s | 
[epoch_0]_30151  loss=3.344376 |g|=0.405	lr=5.22e-04 | 70.0%@S25  T=1.05s eta=09:00:11 | 74.9K token/s | 
[epoch_0]_30161  loss=3.380906 |g|=0.423	lr=5.22e-04 | 70.8%@S25  T=1.08s eta=09:16:57 | 75.0K token/s | 
[epoch_0]_30171  loss=3.429100 |g|=0.38	lr=5.22e-04 | 71.6%@S25  T=1.03s eta=08:51:28 | 75.2K token/s | 
[epoch_0]_30181  loss=3.296923 |g|=0.392	lr=5.21e-04 | 72.4%@S25  T=1.05s eta=08:57:47 | 75.3K token/s | 
[epoch_0]_30191  loss=3.353895 |g|=0.389	lr=5.21e-04 | 73.3%@S25  T=1.05s eta=08:59:16 | 75.5K token/s | 
[Fuyou] head="1" update algorithm=4 t=2.05s
[eval] 
	 Loss@"edu_fineweb1B"=3.377(-0.0013) nBranch=1 nToken=4.01M best=3.3710(144) E2T=0.0697 T=13.495(0)s x=0
	#3.37731±0.1091 tps=297K(4.01408M) a=[3.19734,3.66891] T=13.495(sec)
[Section@30200] layer[12-18] tasks=15(nPassBack=0) last_loss=3.30761(0.039392) N=(580,25872,25452 3019900)
[epoch_0]_30201  loss=3.367430 |g|=0.365	lr=5.21e-04 | 74.1%@S25  T=4.18s eta=1d 11:47:32 | 72.7K token/s | 
[epoch_0]_30211  loss=3.346375 |g|=0.358	lr=5.21e-04 | 74.9%@S25  T=1.07s eta=09:09:37 | 72.9K token/s | 
[epoch_0]_30221  loss=3.405283 |g|=0.405	lr=5.20e-04 | 75.7%@S25  T=1.04s eta=08:56:02 | 73.2K token/s | 
[epoch_0]_30231  loss=3.302958 |g|=0.404	lr=5.20e-04 | 76.5%@S25  T=1.03s eta=08:48:09 | 73.5K token/s | 
[epoch_0]_30241  loss=3.285692 |g|=0.376	lr=5.20e-04 | 77.4%@S25  T=1.08s eta=09:12:03 | 73.6K token/s | 
[epoch_0]_30251  loss=3.405159 |g|=0.4	lr=5.20e-04 | 78.2%@S25  T=1.05s eta=08:56:29 | 73.9K token/s | 
[epoch_0]_30261  loss=3.281355 |g|=0.401	lr=5.19e-04 | 79.0%@S25  T=1.04s eta=08:52:37 | 74.1K token/s | 
[epoch_0]_30271  loss=3.346295 |g|=0.371	lr=5.19e-04 | 79.8%@S25  T=1.04s eta=08:55:10 | 74.3K token/s | 
[epoch_0]_30281  loss=3.364949 |g|=0.371	lr=5.19e-04 | 80.6%@S25  T=1.05s eta=09:00:22 | 74.5K token/s | 
[epoch_0]_30291  loss=3.384248 |g|=0.431	lr=5.19e-04 | 81.4%@S25  T=1.09s eta=09:17:53 | 74.5K token/s | 
[Fuyou] head="2" update algorithm=4 t=2.06s
[Section@30300] layer[18-24] tasks=15(nPassBack=0) last_loss=3.35313(0.0424855) N=(580,25956,25536 3029900)
[epoch_0]_30301  loss=3.326193 |g|=0.359	lr=5.18e-04 | 82.3%@S25  T=1.56s eta=13:17:28 | 73.4K token/s | 
[epoch_0]_30311  loss=3.313073 |g|=0.426	lr=5.18e-04 | 83.1%@S25  T=1.04s eta=08:51:04 | 73.7K token/s | 
[epoch_0]_30321  loss=3.316942 |g|=0.387	lr=5.18e-04 | 83.9%@S25  T=1.05s eta=08:56:16 | 73.9K token/s | 
[epoch_0]_30331  loss=3.315549 |g|=0.368	lr=5.18e-04 | 84.7%@S25  T=1.08s eta=09:13:02 | 74.0K token/s | 
[epoch_0]_30341  loss=3.320157 |g|=0.379	lr=5.17e-04 | 85.5%@S25  T=1.04s eta=08:51:15 | 74.3K token/s | 
[epoch_0]_30351  loss=3.423149 |g|=0.386	lr=5.17e-04 | 86.4%@S25  T=1.05s eta=08:55:14 | 74.5K token/s | 
[epoch_0]_30361  loss=3.384845 |g|=0.378	lr=5.17e-04 | 87.2%@S25  T=1.04s eta=08:50:13 | 74.7K token/s | 
[epoch_0]_30371  loss=3.317201 |g|=0.368	lr=5.16e-04 | 88.0%@S25  T=1.06s eta=08:59:39 | 74.8K token/s | 
[epoch_0]_30381  loss=3.319157 |g|=0.393	lr=5.16e-04 | 88.8%@S25  T=1.06s eta=09:00:29 | 75.0K token/s | 
[epoch_0]_30391  loss=3.418302 |g|=0.394	lr=5.16e-04 | 89.6%@S25  T=1.03s eta=08:46:06 | 75.2K token/s | 
[Fuyou] head="3" update algorithm=4 t=2.08s
[eval] 
	 Loss@"edu_fineweb1B"=3.373(0.0042) nBranch=1 nToken=4.01M best=3.3710(144) E2T=-0.00123 T=13.4972(0)s x=0
	#3.37306±0.1084 tps=297K(4.01408M) a=[3.19448,3.66071] T=13.4972(sec)
[Section@30400] layer[24-30] tasks=15(nPassBack=0) last_loss=3.37429(-0.0233905) N=(580,26040,25620 3039900)
[epoch_0]_30401  loss=3.279558 |g|=0.361	lr=5.16e-04 | 90.5%@S25  T=4.18s eta=1d 11:32:19 | 72.4K token/s | 
[epoch_0]_30411  loss=3.341488 |g|=0.385	lr=5.15e-04 | 91.3%@S25  T=1.04s eta=08:51:12 | 72.7K token/s | 
[epoch_0]_30421  loss=3.290210 |g|=0.394	lr=5.15e-04 | 92.1%@S25  T=1.05s eta=08:56:04 | 73.0K token/s | 
[epoch_0]_30431  loss=3.285069 |g|=0.387	lr=5.15e-04 | 92.9%@S25  T=1.07s eta=09:07:26 | 73.2K token/s | 
[epoch_0]_30441  loss=3.354842 |g|=0.399	lr=5.15e-04 | 93.7%@S25  T=1.03s eta=08:45:12 | 73.5K token/s | 
[epoch_0]_30451  loss=3.347727 |g|=0.4	lr=5.14e-04 | 94.6%@S25  T=1.03s eta=08:45:56 | 73.8K token/s | 
[epoch_0]_30461  loss=3.357142 |g|=0.36	lr=5.14e-04 | 95.4%@S25  T=1.05s eta=08:55:50 | 74.0K token/s | 
[epoch_0]_30471  loss=3.423543 |g|=0.39	lr=5.14e-04 | 96.2%@S25  T=1.06s eta=09:01:59 | 74.1K token/s | 
[epoch_0]_30481  loss=3.364817 |g|=0.379	lr=5.14e-04 | 97.0%@S25  T=1.06s eta=08:59:01 | 74.3K token/s | 
[epoch_0]_30491  loss=3.383168 |g|=0.399	lr=5.13e-04 | 97.8%@S25  T=1.04s eta=08:49:02 | 74.5K token/s | 
[Fuyou] head="4" update algorithm=4 t=2.08s
[Section@30500] layer[30-36] tasks=15(nPassBack=0) last_loss=3.35104(-0.0281889) N=(580,26124,25704 3049900)
[epoch_0]_30501  loss=3.407495 |g|=0.377	lr=5.13e-04 | 98.6%@S25  T=1.55s eta=13:09:23 | 73.4K token/s | 
[epoch_0]_30511  loss=3.306720 |g|=0.369	lr=5.13e-04 | 99.5%@S25  T=1.04s eta=08:46:37 | 73.7K token/s | 
[epoch_0]_30517  loss=3.370242 |g|=0.371	lr=5.13e-04 | 100.0%@S25  T=1.04s eta=08:51:07 | 74.0K token/s | 
-------- End of shard_25@"./Datasets/edu_fineweb1B/edu_fineweb_train_000478.bin"-------- 
[shard-26]@"./Datasets/edu_fineweb1B/edu_fineweb_train_000479.bin": tokens=100(M) nShardSamples=1220(2539056) 
[epoch_0]_30521  loss=3.394214 |g|=0.392	lr=5.13e-04 | 0.3%@S26  T=1.07s eta=09:02:40 | 74.1K token/s | 
[epoch_0]_30531  loss=3.338198 |g|=0.377	lr=5.12e-04 | 1.1%@S26  T=1.07s eta=09:06:05 | 74.2K token/s | 
[epoch_0]_30541  loss=3.442522 |g|=0.387	lr=5.12e-04 | 1.9%@S26  T=1.03s eta=08:42:38 | 74.5K token/s | 
[epoch_0]_30551  loss=3.393167 |g|=0.391	lr=5.12e-04 | 2.7%@S26  T=1.05s eta=08:53:56 | 74.7K token/s | 
[epoch_0]_30561  loss=3.400332 |g|=0.389	lr=5.12e-04 | 3.6%@S26  T=1.04s eta=08:49:46 | 74.8K token/s | 
[epoch_0]_30571  loss=3.414518 |g|=0.388	lr=5.11e-04 | 4.4%@S26  T=1.07s eta=09:01:43 | 74.9K token/s | 
[epoch_0]_30581  loss=3.419235 |g|=0.404	lr=5.11e-04 | 5.2%@S26  T=1.08s eta=09:09:17 | 75.0K token/s | 
[epoch_0]_30591  loss=3.366728 |g|=0.381	lr=5.11e-04 | 6.0%@S26  T=1.04s eta=08:47:28 | 75.2K token/s | 
[Fuyou] head="5" update algorithm=4 t=2.02s
[eval] 
	 Loss@"edu_fineweb1B"=3.365(0.0083) nBranch=1 nToken=4.01M best=3.3731(151) E2T=0.00685 T=13.4988(0)s x=0
	#3.36479±0.1085 tps=297K(4.01408M) a=[3.18549,3.65181] T=13.4988(sec)
[Section@30600] layer[0-6] tasks=15(nPassBack=0) last_loss=3.35794(-0.0520625) N=(580,26208,25788 3059900)
[epoch_0]_30601  loss=3.362960 |g|=0.422	lr=5.11e-04 | 6.8%@S26  T=4.16s eta=1d 11:08:14 | 72.4K token/s | 
[epoch_0]_30611  loss=3.350389 |g|=0.39	lr=5.10e-04 | 7.7%@S26  T=1.04s eta=08:46:28 | 72.7K token/s | 
[epoch_0]_30621  loss=3.404433 |g|=0.441	lr=5.10e-04 | 8.5%@S26  T=1.04s eta=08:47:55 | 73.0K token/s | 
[epoch_0]_30631  loss=3.332844 |g|=0.395	lr=5.10e-04 | 9.3%@S26  T=1.09s eta=09:10:37 | 73.1K token/s | 
[epoch_0]_30641  loss=3.404684 |g|=0.416	lr=5.10e-04 | 10.1%@S26  T=1.04s eta=08:48:47 | 73.4K token/s | 
[epoch_0]_30651  loss=3.407339 |g|=0.398	lr=5.09e-04 | 10.9%@S26  T=1.03s eta=08:41:14 | 73.7K token/s | 
[epoch_0]_30661  loss=3.381883 |g|=0.398	lr=5.09e-04 | 11.8%@S26  T=1.04s eta=08:47:03 | 74.0K token/s | 
[epoch_0]_30671  loss=3.434078 |g|=0.383	lr=5.09e-04 | 12.6%@S26  T=1.05s eta=08:52:51 | 74.2K token/s | 
[epoch_0]_30681  loss=3.373887 |g|=0.393	lr=5.09e-04 | 13.4%@S26  T=1.06s eta=08:54:05 | 74.3K token/s | 
[epoch_0]_30691  loss=3.347437 |g|=0.373	lr=5.08e-04 | 14.2%@S26  T=1.08s eta=09:07:53 | 74.4K token/s | 
[Fuyou] head="0" update algorithm=4 t=2.09s
[Section@30700] layer[6-12] tasks=15(nPassBack=0) last_loss=3.34574(0.0240707) N=(580,26292,25872 3069900)
[epoch_0]_30701  loss=3.407501 |g|=0.363	lr=5.08e-04 | 15.0%@S26  T=1.53s eta=12:53:01 | 73.4K token/s | 
[epoch_0]_30711  loss=3.340133 |g|=0.377	lr=5.08e-04 | 15.9%@S26  T=1.04s eta=08:46:01 | 73.6K token/s | 
[epoch_0]_30721  loss=3.320057 |g|=0.408	lr=5.07e-04 | 16.7%@S26  T=1.06s eta=08:53:15 | 73.8K token/s | 
[epoch_0]_30731  loss=3.422858 |g|=0.391	lr=5.07e-04 | 17.5%@S26  T=1.08s eta=09:06:44 | 73.9K token/s | 
[epoch_0]_30741  loss=3.397781 |g|=0.396	lr=5.07e-04 | 18.3%@S26  T=1.05s eta=08:51:18 | 74.1K token/s | 
[epoch_0]_30751  loss=3.410797 |g|=0.406	lr=5.07e-04 | 19.1%@S26  T=1.04s eta=08:43:19 | 74.4K token/s | 
[epoch_0]_30761  loss=3.336009 |g|=0.381	lr=5.06e-04 | 19.9%@S26  T=1.04s eta=08:46:27 | 74.6K token/s | 
[epoch_0]_30771  loss=3.385947 |g|=0.358	lr=5.06e-04 | 20.8%@S26  T=1.07s eta=08:59:13 | 74.7K token/s | 
[epoch_0]_30781  loss=3.386445 |g|=0.399	lr=5.06e-04 | 21.6%@S26  T=1.08s eta=09:02:51 | 74.7K token/s | 
[epoch_0]_30791  loss=3.316856 |g|=0.411	lr=5.06e-04 | 22.4%@S26  T=1.05s eta=08:47:33 | 74.9K token/s | 
[Fuyou] head="1" update algorithm=4 t=2.01s
[eval] 
	 Loss@"edu_fineweb1B"=3.359(0.0061) nBranch=1 nToken=4.01M best=3.3648(152) E2T=-0.0887 T=13.4787(0)s x=0
	#3.3587±0.1075 tps=298K(4.01408M) a=[3.18061,3.6463] T=13.4787(sec)
[Section@30800] layer[12-18] tasks=15(nPassBack=0) last_loss=3.44741(-0.139799) N=(580,26376,25956 3079900)
[epoch_0]_30801  loss=3.354101 |g|=0.366	lr=5.05e-04 | 23.2%@S26  T=4.18s eta=1d 11:04:34 | 72.1K token/s | 
[epoch_0]_30811  loss=3.271929 |g|=0.383	lr=5.05e-04 | 24.0%@S26  T=1.04s eta=08:43:14 | 72.5K token/s | 
[epoch_0]_30821  loss=3.389640 |g|=0.412	lr=5.05e-04 | 24.9%@S26  T=1.09s eta=09:06:58 | 72.6K token/s | 
[epoch_0]_30831  loss=3.381414 |g|=0.397	lr=5.05e-04 | 25.7%@S26  T=1.08s eta=09:01:43 | 72.8K token/s | 
[epoch_0]_30841  loss=3.281260 |g|=0.431	lr=5.04e-04 | 26.5%@S26  T=1.05s eta=08:47:39 | 73.1K token/s | 
[epoch_0]_30851  loss=3.373396 |g|=0.422	lr=5.04e-04 | 27.3%@S26  T=1.06s eta=08:50:52 | 73.3K token/s | 
[epoch_0]_30861  loss=3.392168 |g|=0.413	lr=5.04e-04 | 28.1%@S26  T=1.05s eta=08:48:16 | 73.5K token/s | 
[epoch_0]_30871  loss=3.391881 |g|=0.423	lr=5.04e-04 | 29.0%@S26  T=1.05s eta=08:47:18 | 73.8K token/s | 
[epoch_0]_30881  loss=3.405074 |g|=0.393	lr=5.03e-04 | 29.8%@S26  T=1.10s eta=09:12:44 | 73.8K token/s | 
[epoch_0]_30891  loss=3.395819 |g|=0.383	lr=5.03e-04 | 30.6%@S26  T=1.06s eta=08:52:27 | 74.0K token/s | 
[Fuyou] head="2" update algorithm=4 t=2.08s
[Section@30900] layer[18-24] tasks=15(nPassBack=0) last_loss=3.33271(0.0204117) N=(580,26460,26040 3089900)
[epoch_0]_30901  loss=3.366256 |g|=0.41	lr=5.03e-04 | 31.4%@S26  T=1.44s eta=12:01:22 | 73.1K token/s | 
[epoch_0]_30911  loss=3.363511 |g|=0.408	lr=5.03e-04 | 32.2%@S26  T=1.04s eta=08:44:25 | 73.4K token/s | 
[epoch_0]_30921  loss=3.322707 |g|=0.388	lr=5.02e-04 | 33.1%@S26  T=1.05s eta=08:49:02 | 73.6K token/s | 
[epoch_0]_30931  loss=3.373241 |g|=0.397	lr=5.02e-04 | 33.9%@S26  T=1.07s eta=08:54:21 | 73.8K token/s | 
[epoch_0]_30941  loss=3.303071 |g|=0.372	lr=5.02e-04 | 34.7%@S26  T=1.05s eta=08:49:02 | 74.0K token/s | 
[epoch_0]_30951  loss=3.321777 |g|=0.39	lr=5.02e-04 | 35.5%@S26  T=1.06s eta=08:49:20 | 74.1K token/s | 
[epoch_0]_30961  loss=3.272943 |g|=0.395	lr=5.01e-04 | 36.3%@S26  T=1.05s eta=08:43:49 | 74.4K token/s | 
[epoch_0]_30971  loss=3.370910 |g|=0.371	lr=5.01e-04 | 37.2%@S26  T=1.06s eta=08:50:50 | 74.5K token/s | 
[epoch_0]_30981  loss=3.347111 |g|=0.364	lr=5.01e-04 | 38.0%@S26  T=1.07s eta=08:53:37 | 74.6K token/s | 
[epoch_0]_30991  loss=3.357800 |g|=0.379	lr=5.01e-04 | 38.8%@S26  T=1.10s eta=09:09:25 | 74.6K token/s | 
[Fuyou] head="3" update algorithm=4 t=2.05s
[eval] 
	 Loss@"edu_fineweb1B"=3.353(0.0054) nBranch=1 nToken=4.01M best=3.3587(153) E2T=-0.0323 T=13.5107(0)s x=0
	#3.35326±0.1068 tps=297K(4.01408M) a=[3.1763,3.64023] T=13.5107(sec)
[Section@31000] layer[24-30] tasks=15(nPassBack=0) last_loss=3.38558(-0.0112846) N=(580,26544,26124 3099900)
[epoch_0]_31001  loss=3.431123 |g|=0.372	lr=5.00e-04 | 39.6%@S26  T=4.18s eta=1d 10:53:09 | 71.9K token/s | 
[epoch_0]_31011  loss=3.389854 |g|=0.436	lr=5.00e-04 | 40.4%@S26  T=1.10s eta=09:10:47 | 72.0K token/s | 
[epoch_0]_31021  loss=3.378133 |g|=0.374	lr=5.00e-04 | 41.2%@S26  T=1.05s eta=08:45:54 | 72.3K token/s | 
[epoch_0]_31031  loss=3.447598 |g|=0.403	lr=5.00e-04 | 42.1%@S26  T=1.07s eta=08:52:35 | 72.5K token/s | 
[epoch_0]_31041  loss=3.291795 |g|=0.372	lr=4.99e-04 | 42.9%@S26  T=1.09s eta=09:02:29 | 72.7K token/s | 
[epoch_0]_31051  loss=3.356510 |g|=0.393	lr=4.99e-04 | 43.7%@S26  T=1.05s eta=08:45:59 | 72.9K token/s | 
[epoch_0]_31061  loss=3.355345 |g|=0.384	lr=4.99e-04 | 44.5%@S26  T=1.05s eta=08:42:33 | 73.2K token/s | 
[epoch_0]_31071  loss=3.376408 |g|=0.372	lr=4.98e-04 | 45.3%@S26  T=1.04s eta=08:39:55 | 73.5K token/s | 
[epoch_0]_31081  loss=3.284573 |g|=0.4	lr=4.98e-04 | 46.2%@S26  T=1.05s eta=08:41:42 | 73.7K token/s | 
[epoch_0]_31091  loss=3.385283 |g|=0.405	lr=4.98e-04 | 47.0%@S26  T=1.08s eta=08:57:57 | 73.8K token/s | 
[Fuyou] head="4" update algorithm=4 t=2.07s
[Section@31100] layer[30-36] tasks=15(nPassBack=0) last_loss=3.37919(-0.0281429) N=(580,26628,26208 3109900)
[epoch_0]_31101  loss=3.339058 |g|=0.353	lr=4.98e-04 | 47.8%@S26  T=1.43s eta=11:53:48 | 73.0K token/s | 
[epoch_0]_31111  loss=3.333862 |g|=0.438	lr=4.97e-04 | 48.6%@S26  T=1.04s eta=08:40:35 | 73.3K token/s | 
[epoch_0]_31121  loss=3.353363 |g|=0.4	lr=4.97e-04 | 49.4%@S26  T=1.04s eta=08:38:19 | 73.6K token/s | 
[epoch_0]_31131  loss=3.405717 |g|=0.434	lr=4.97e-04 | 50.3%@S26  T=1.05s eta=08:43:12 | 73.8K token/s | 
[epoch_0]_31141  loss=3.394778 |g|=0.421	lr=4.97e-04 | 51.1%@S26  T=1.05s eta=08:44:30 | 74.0K token/s | 
[epoch_0]_31151  loss=3.300847 |g|=0.378	lr=4.96e-04 | 51.9%@S26  T=1.08s eta=08:59:52 | 74.1K token/s | 
[epoch_0]_31161  loss=3.327956 |g|=0.368	lr=4.96e-04 | 52.7%@S26  T=1.04s eta=08:39:45 | 74.3K token/s | 
[epoch_0]_31171  loss=3.393595 |g|=0.378	lr=4.96e-04 | 53.5%@S26  T=1.05s eta=08:42:57 | 74.5K token/s | 
[epoch_0]_31181  loss=3.413001 |g|=0.44	lr=4.96e-04 | 54.4%@S26  T=1.04s eta=08:37:47 | 74.7K token/s | 
[epoch_0]_31191  loss=3.354187 |g|=0.401	lr=4.95e-04 | 55.2%@S26  T=1.05s eta=08:43:38 | 74.8K token/s | 
[Fuyou] head="5" update algorithm=4 t=2.04s
[eval] 
	 Loss@"edu_fineweb1B"=3.351(0.0025) nBranch=1 nToken=4.01M best=3.3533(154) E2T=0.0026 T=13.4924(0)s x=0
	#3.35072±0.1073 tps=298K(4.01408M) a=[3.17071,3.63943] T=13.4924(sec)
[Section@31200] layer[0-6] tasks=15(nPassBack=0) last_loss=3.34812(0.00981355) N=(580,26712,26292 3119900)
[epoch_0]_31201  loss=3.319261 |g|=0.407	lr=4.95e-04 | 56.0%@S26  T=4.18s eta=1d 10:37:55 | 72.1K token/s | 
[epoch_0]_31211  loss=3.343180 |g|=0.391	lr=4.95e-04 | 56.8%@S26  T=1.04s eta=08:34:35 | 72.4K token/s | 
[epoch_0]_31221  loss=3.332996 |g|=0.364	lr=4.95e-04 | 57.6%@S26  T=1.04s eta=08:37:14 | 72.7K token/s | 
[epoch_0]_31231  loss=3.376774 |g|=0.401	lr=4.94e-04 | 58.5%@S26  T=1.10s eta=09:04:58 | 72.8K token/s | 
[epoch_0]_31241  loss=3.432639 |g|=0.409	lr=4.94e-04 | 59.3%@S26  T=1.05s eta=08:40:29 | 73.1K token/s | 
[epoch_0]_31251  loss=3.464649 |g|=0.426	lr=4.94e-04 | 60.1%@S26  T=1.06s eta=08:43:42 | 73.3K token/s | 
[epoch_0]_31261  loss=3.336686 |g|=0.396	lr=4.94e-04 | 60.9%@S26  T=1.05s eta=08:40:45 | 73.6K token/s | 
[epoch_0]_31271  loss=3.292502 |g|=0.414	lr=4.93e-04 | 61.7%@S26  T=1.05s eta=08:42:12 | 73.8K token/s | 
[epoch_0]_31281  loss=3.415606 |g|=0.429	lr=4.93e-04 | 62.5%@S26  T=1.07s eta=08:50:11 | 73.9K token/s | 
[epoch_0]_31291  loss=3.333405 |g|=0.403	lr=4.93e-04 | 63.4%@S26  T=1.07s eta=08:52:11 | 74.0K token/s | 
[Fuyou] head="0" update algorithm=4 t=2.08s
[Section@31300] layer[6-12] tasks=15(nPassBack=0) last_loss=3.40934(-0.0635998) N=(580,26796,26376 3129900)
[epoch_0]_31301  loss=3.416440 |g|=0.398	lr=4.93e-04 | 64.2%@S26  T=1.35s eta=11:08:12 | 73.4K token/s | 
[epoch_0]_31311  loss=3.390733 |g|=0.385	lr=4.92e-04 | 65.0%@S26  T=1.05s eta=08:38:51 | 73.6K token/s | 
[epoch_0]_31321  loss=3.335057 |g|=0.386	lr=4.92e-04 | 65.8%@S26  T=1.08s eta=08:53:05 | 73.7K token/s | 
[epoch_0]_31331  loss=3.348836 |g|=0.379	lr=4.92e-04 | 66.6%@S26  T=1.05s eta=08:41:25 | 73.9K token/s | 
[epoch_0]_31341  loss=3.318374 |g|=0.421	lr=4.92e-04 | 67.5%@S26  T=1.06s eta=08:43:29 | 74.1K token/s | 
[epoch_0]_31351  loss=3.334366 |g|=0.395	lr=4.91e-04 | 68.3%@S26  T=1.06s eta=08:45:13 | 74.3K token/s | 
[epoch_0]_31361  loss=3.302788 |g|=0.374	lr=4.91e-04 | 69.1%@S26  T=1.06s eta=08:43:49 | 74.4K token/s | 
[epoch_0]_31371  loss=3.354135 |g|=0.387	lr=4.91e-04 | 69.9%@S26  T=1.10s eta=09:04:01 | 74.4K token/s | 
[epoch_0]_31381  loss=3.340343 |g|=0.408	lr=4.91e-04 | 70.7%@S26  T=1.09s eta=08:58:39 | 74.5K token/s | 
[epoch_0]_31391  loss=3.395439 |g|=0.408	lr=4.90e-04 | 71.6%@S26  T=1.05s eta=08:36:35 | 74.7K token/s | 
[Fuyou] head="1" update algorithm=4 t=2.07s
[eval] 
	 Loss@"edu_fineweb1B"=3.349(0.0014) nBranch=1 nToken=4.01M best=3.3507(155) E2T=0.0129 T=13.4938(0)s x=0
	#3.34933±0.1062 tps=297K(4.01408M) a=[3.17046,3.63343] T=13.4938(sec)
[Section@31400] layer[12-18] tasks=15(nPassBack=0) last_loss=3.33643(0.110973) N=(580,26880,26460 3139900)
[epoch_0]_31401  loss=3.322917 |g|=0.377	lr=4.90e-04 | 72.4%@S26  T=4.23s eta=1d 10:50:09 | 71.9K token/s | 
[epoch_0]_31411  loss=3.326579 |g|=0.372	lr=4.90e-04 | 73.2%@S26  T=1.06s eta=08:44:41 | 72.2K token/s | 
[epoch_0]_31421  loss=3.348202 |g|=0.394	lr=4.89e-04 | 74.0%@S26  T=1.04s eta=08:32:30 | 72.5K token/s | 
[epoch_0]_31431  loss=3.388769 |g|=0.408	lr=4.89e-04 | 74.8%@S26  T=1.05s eta=08:38:13 | 72.8K token/s | 
[epoch_0]_31441  loss=3.333409 |g|=0.408	lr=4.89e-04 | 75.7%@S26  T=1.05s eta=08:37:21 | 73.0K token/s | 
[epoch_0]_31451  loss=3.366639 |g|=0.377	lr=4.89e-04 | 76.5%@S26  T=1.06s eta=08:40:32 | 73.3K token/s | 
[epoch_0]_31461  loss=3.343317 |g|=0.373	lr=4.88e-04 | 77.3%@S26  T=1.08s eta=08:51:05 | 73.4K token/s | 
[epoch_0]_31471  loss=3.338048 |g|=0.392	lr=4.88e-04 | 78.1%@S26  T=1.07s eta=08:46:31 | 73.6K token/s | 
[epoch_0]_31481  loss=3.349046 |g|=0.441	lr=4.88e-04 | 78.9%@S26  T=1.05s eta=08:38:16 | 73.8K token/s | 
[epoch_0]_31491  loss=3.370579 |g|=0.408	lr=4.88e-04 | 79.8%@S26  T=1.04s eta=08:31:59 | 74.0K token/s | 
[Fuyou] head="2" update algorithm=4 t=2.00s
[Section@31500] layer[18-24] tasks=15(nPassBack=0) last_loss=3.30117(0.031549) N=(580,26964,26544 3149900)
[epoch_0]_31501  loss=3.350964 |g|=0.364	lr=4.87e-04 | 80.6%@S26  T=1.51s eta=12:21:25 | 73.0K token/s | 
[epoch_0]_31511  loss=3.220037 |g|=0.388	lr=4.87e-04 | 81.4%@S26  T=1.04s eta=08:32:42 | 73.3K token/s | 
[epoch_0]_31521  loss=3.377512 |g|=0.425	lr=4.87e-04 | 82.2%@S26  T=1.07s eta=08:45:47 | 73.5K token/s | 
[epoch_0]_31531  loss=3.371696 |g|=0.385	lr=4.87e-04 | 83.0%@S26  T=1.05s eta=08:37:15 | 73.7K token/s | 
[epoch_0]_31541  loss=3.411813 |g|=0.402	lr=4.86e-04 | 83.8%@S26  T=1.05s eta=08:35:03 | 73.9K token/s | 
[epoch_0]_31551  loss=3.309202 |g|=0.376	lr=4.86e-04 | 84.7%@S26  T=1.06s eta=08:40:17 | 74.1K token/s | 
[epoch_0]_31561  loss=3.342676 |g|=0.398	lr=4.86e-04 | 85.5%@S26  T=1.04s eta=08:30:47 | 74.3K token/s | 
[epoch_0]_31571  loss=3.323690 |g|=0.389	lr=4.86e-04 | 86.3%@S26  T=1.07s eta=08:47:44 | 74.4K token/s | 
[epoch_0]_31581  loss=3.283735 |g|=0.424	lr=4.85e-04 | 87.1%@S26  T=1.08s eta=08:52:09 | 74.5K token/s | 
[epoch_0]_31591  loss=3.419259 |g|=0.392	lr=4.85e-04 | 87.9%@S26  T=1.04s eta=08:32:35 | 74.7K token/s | 
[Fuyou] head="3" update algorithm=4 t=2.05s
[eval] 
	 Loss@"edu_fineweb1B"=3.348(0.0011) nBranch=1 nToken=4.01M best=3.3493(156) E2T=0.00798 T=13.4887(0)s x=0
	#3.34823±0.1061 tps=298K(4.01408M) a=[3.16806,3.63476] T=13.4887(sec)
[Section@31600] layer[24-30] tasks=15(nPassBack=0) last_loss=3.34025(0.0453331) N=(580,27048,26628 3159900)
[epoch_0]_31601  loss=3.331562 |g|=0.394	lr=4.85e-04 | 88.8%@S26  T=4.20s eta=1d 10:20:21 | 71.9K token/s | 
[epoch_0]_31611  loss=3.337839 |g|=0.394	lr=4.85e-04 | 89.6%@S26  T=1.05s eta=08:36:36 | 72.2K token/s | 
[epoch_0]_31621  loss=3.317133 |g|=0.411	lr=4.84e-04 | 90.4%@S26  T=1.03s eta=08:26:32 | 72.6K token/s | 
[epoch_0]_31631  loss=3.388770 |g|=0.399	lr=4.84e-04 | 91.2%@S26  T=1.05s eta=08:33:39 | 72.9K token/s | 
[epoch_0]_31641  loss=3.392463 |g|=0.407	lr=4.84e-04 | 92.0%@S26  T=1.05s eta=08:36:07 | 73.1K token/s | 
[epoch_0]_31651  loss=3.403465 |g|=0.387	lr=4.84e-04 | 92.9%@S26  T=1.05s eta=08:36:17 | 73.3K token/s | 
[epoch_0]_31661  loss=3.302956 |g|=0.373	lr=4.83e-04 | 93.7%@S26  T=1.05s eta=08:35:37 | 73.6K token/s | 
[epoch_0]_31671  loss=3.323565 |g|=0.389	lr=4.83e-04 | 94.5%@S26  T=1.09s eta=08:51:09 | 73.6K token/s | 
[epoch_0]_31681  loss=3.402296 |g|=0.383	lr=4.83e-04 | 95.3%@S26  T=1.08s eta=08:47:48 | 73.8K token/s | 
[epoch_0]_31691  loss=3.377998 |g|=0.431	lr=4.83e-04 | 96.1%@S26  T=1.05s eta=08:33:03 | 74.0K token/s | 
[Fuyou] head="4" update algorithm=4 t=2.00s
[Section@31700] layer[30-36] tasks=15(nPassBack=0) last_loss=3.39177(-0.0125825) N=(580,27132,26712 3169900)
[epoch_0]_31701  loss=3.285627 |g|=0.415	lr=4.82e-04 | 97.0%@S26  T=1.38s eta=11:15:27 | 73.2K token/s | 
[epoch_0]_31711  loss=3.288781 |g|=0.42	lr=4.82e-04 | 97.8%@S26  T=1.06s eta=08:37:11 | 73.5K token/s | 
[epoch_0]_31721  loss=3.342427 |g|=0.404	lr=4.82e-04 | 98.6%@S26  T=1.08s eta=08:48:13 | 73.6K token/s | 
[epoch_0]_31731  loss=3.367596 |g|=0.399	lr=4.82e-04 | 99.4%@S26  T=1.07s eta=08:44:34 | 73.7K token/s | 
[epoch_0]_31738  loss=3.336248 |g|=0.405	lr=4.81e-04 | 100.0%@S26  T=1.06s eta=08:37:59 | 73.9K token/s | 
-------- End of shard_26@"./Datasets/edu_fineweb1B/edu_fineweb_train_000479.bin"-------- 
[shard-27]@"./Datasets/edu_fineweb1B/edu_fineweb_train_000480.bin": tokens=100(M) nShardSamples=1220(2636712) 
[epoch_0]_31741  loss=3.275694 |g|=0.388	lr=4.81e-04 | 0.2%@S27  T=1.06s eta=08:36:54 | 74.1K token/s | 
[epoch_0]_31751  loss=3.402321 |g|=0.375	lr=4.81e-04 | 1.0%@S27  T=1.03s eta=08:25:06 | 74.3K token/s | 
[epoch_0]_31761  loss=3.390794 |g|=0.377	lr=4.81e-04 | 1.9%@S27  T=1.04s eta=08:28:34 | 74.5K token/s | 
[epoch_0]_31771  loss=3.374189 |g|=0.416	lr=4.80e-04 | 2.7%@S27  T=1.04s eta=08:28:09 | 74.7K token/s | 
[epoch_0]_31781  loss=3.353579 |g|=0.403	lr=4.80e-04 | 3.5%@S27  T=1.07s eta=08:40:59 | 74.8K token/s | 
[epoch_0]_31791  loss=3.384052 |g|=0.388	lr=4.80e-04 | 4.3%@S27  T=1.05s eta=08:29:54 | 75.0K token/s | 
[Fuyou] head="5" update algorithm=4 t=2.07s
[eval] 
	 Loss@"edu_fineweb1B"=3.350(-0.0014) nBranch=1 nToken=4.01M best=3.3493(156) E2T=-0.00804 T=13.4939(0)s x=0
	#3.34964±0.1063 tps=297K(4.01408M) a=[3.16886,3.63275] T=13.4939(sec)
[Section@31800] layer[0-6] tasks=15(nPassBack=0) last_loss=3.35768(-0.00955963) N=(580,27216,26796 3179900)
[epoch_0]_31801  loss=3.364896 |g|=0.372	lr=4.80e-04 | 5.1%@S27  T=4.18s eta=1d 09:54:26 | 72.2K token/s | 
[epoch_0]_31811  loss=3.426566 |g|=0.386	lr=4.79e-04 | 6.0%@S27  T=1.06s eta=08:37:22 | 72.5K token/s | 
[epoch_0]_31821  loss=3.312168 |g|=0.397	lr=4.79e-04 | 6.8%@S27  T=1.04s eta=08:28:41 | 72.8K token/s | 
[epoch_0]_31831  loss=3.310727 |g|=0.403	lr=4.79e-04 | 7.6%@S27  T=1.07s eta=08:43:05 | 72.9K token/s | 
[epoch_0]_31841  loss=3.336644 |g|=0.403	lr=4.79e-04 | 8.4%@S27  T=1.04s eta=08:27:17 | 73.2K token/s | 
[epoch_0]_31851  loss=3.354953 |g|=0.41	lr=4.78e-04 | 9.2%@S27  T=1.05s eta=08:30:44 | 73.5K token/s | 
[epoch_0]_31861  loss=3.347864 |g|=0.414	lr=4.78e-04 | 10.1%@S27  T=1.05s eta=08:32:54 | 73.7K token/s | 
[epoch_0]_31871  loss=3.349312 |g|=0.387	lr=4.78e-04 | 10.9%@S27  T=1.06s eta=08:36:36 | 73.8K token/s | 
[epoch_0]_31881  loss=3.409298 |g|=0.414	lr=4.78e-04 | 11.7%@S27  T=1.07s eta=08:41:11 | 74.0K token/s | 
[epoch_0]_31891  loss=3.248670 |g|=0.395	lr=4.77e-04 | 12.5%@S27  T=1.05s eta=08:28:34 | 74.2K token/s | 
[Fuyou] head="0" update algorithm=4 t=2.34s
[Section@31900] layer[6-12] tasks=15(nPassBack=0) last_loss=3.32574(0.0836015) N=(580,27300,26880 3189900)
[epoch_0]_31901  loss=3.425987 |g|=0.425	lr=4.77e-04 | 13.3%@S27  T=1.47s eta=11:53:22 | 73.3K token/s | 
[epoch_0]_31911  loss=3.278255 |g|=0.43	lr=4.77e-04 | 14.2%@S27  T=1.03s eta=08:20:37 | 73.6K token/s | 
[epoch_0]_31921  loss=3.352665 |g|=0.398	lr=4.77e-04 | 15.0%@S27  T=1.05s eta=08:31:30 | 73.8K token/s | 
[epoch_0]_31931  loss=3.338754 |g|=0.394	lr=4.76e-04 | 15.8%@S27  T=1.07s eta=08:38:04 | 73.9K token/s | 
[epoch_0]_31941  loss=3.353677 |g|=0.373	lr=4.76e-04 | 16.6%@S27  T=1.05s eta=08:27:55 | 74.1K token/s | 
[epoch_0]_31951  loss=3.261219 |g|=0.384	lr=4.76e-04 | 17.4%@S27  T=1.04s eta=08:24:32 | 74.4K token/s | 
[epoch_0]_31961  loss=3.338790 |g|=0.394	lr=4.76e-04 | 18.3%@S27  T=1.05s eta=08:30:18 | 74.5K token/s | 
[epoch_0]_31971  loss=3.327442 |g|=0.379	lr=4.75e-04 | 19.1%@S27  T=1.06s eta=08:35:26 | 74.7K token/s | 
[epoch_0]_31981  loss=3.306195 |g|=0.409	lr=4.75e-04 | 19.9%@S27  T=1.07s eta=08:37:14 | 74.8K token/s | 
[epoch_0]_31991  loss=3.269487 |g|=0.378	lr=4.75e-04 | 20.7%@S27  T=1.04s eta=08:23:25 | 75.0K token/s | 
[Fuyou] head="1" update algorithm=4 t=2.07s
[eval] 
	 Loss@"edu_fineweb1B"=3.349(0.0011) nBranch=1 nToken=4.01M best=3.3496(158) E2T=0.0425 T=13.4878(0)s x=0
	#3.34857±0.1062 tps=298K(4.01408M) a=[3.17046,3.63537] T=13.4878(sec)
[Section@32000] layer[12-18] tasks=15(nPassBack=0) last_loss=3.30609(0.03034) N=(580,27384,26964 3199900)
[epoch_0]_32001  loss=3.353713 |g|=0.388	lr=4.75e-04 | 21.5%@S27  T=4.20s eta=1d 09:54:24 | 72.2K token/s | 
[epoch_0]_32011  loss=3.339987 |g|=0.421	lr=4.74e-04 | 22.3%@S27  T=1.05s eta=08:27:28 | 72.5K token/s | 
[epoch_0]_32021  loss=3.365783 |g|=0.393	lr=4.74e-04 | 23.2%@S27  T=1.04s eta=08:22:51 | 72.8K token/s | 
[epoch_0]_32031  loss=3.327803 |g|=0.432	lr=4.74e-04 | 24.0%@S27  T=1.04s eta=08:25:05 | 73.1K token/s | 
[epoch_0]_32041  loss=3.365723 |g|=0.397	lr=4.74e-04 | 24.8%@S27  T=1.04s eta=08:20:17 | 73.4K token/s | 
[epoch_0]_32051  loss=3.322643 |g|=0.372	lr=4.73e-04 | 25.6%@S27  T=1.05s eta=08:27:05 | 73.6K token/s | 
[epoch_0]_32061  loss=3.344294 |g|=0.397	lr=4.73e-04 | 26.4%@S27  T=1.06s eta=08:34:10 | 73.8K token/s | 
[epoch_0]_32071  loss=3.217869 |g|=0.398	lr=4.73e-04 | 27.3%@S27  T=1.09s eta=08:47:26 | 73.8K token/s | 
[epoch_0]_32081  loss=3.370316 |g|=0.405	lr=4.73e-04 | 28.1%@S27  T=1.05s eta=08:27:50 | 74.0K token/s | 
[epoch_0]_32091  loss=3.364855 |g|=0.403	lr=4.72e-04 | 28.9%@S27  T=1.05s eta=08:26:50 | 74.2K token/s | 
[Fuyou] head="2" update algorithm=4 t=2.07s
[Section@32100] layer[18-24] tasks=15(nPassBack=0) last_loss=3.36107(-0.0599055) N=(580,27468,27048 3209900)
[epoch_0]_32101  loss=3.259229 |g|=0.352	lr=4.72e-04 | 29.7%@S27  T=1.32s eta=10:35:13 | 73.6K token/s | 
[epoch_0]_32111  loss=3.357269 |g|=0.389	lr=4.72e-04 | 30.5%@S27  T=1.04s eta=08:22:51 | 73.9K token/s | 
[epoch_0]_32121  loss=3.366226 |g|=0.368	lr=4.71e-04 | 31.4%@S27  T=1.04s eta=08:20:45 | 74.1K token/s | 
[epoch_0]_32131  loss=3.317515 |g|=0.376	lr=4.71e-04 | 32.2%@S27  T=1.05s eta=08:24:04 | 74.3K token/s | 
[epoch_0]_32141  loss=3.371788 |g|=0.389	lr=4.71e-04 | 33.0%@S27  T=1.05s eta=08:25:30 | 74.5K token/s | 
[epoch_0]_32151  loss=3.259066 |g|=0.386	lr=4.71e-04 | 33.8%@S27  T=1.09s eta=08:43:44 | 74.6K token/s | 
[epoch_0]_32161  loss=3.308891 |g|=0.39	lr=4.70e-04 | 34.6%@S27  T=1.13s eta=09:02:45 | 74.5K token/s | 
[epoch_0]_32171  loss=3.317212 |g|=0.377	lr=4.70e-04 | 35.5%@S27  T=1.08s eta=08:41:33 | 74.5K token/s | 
[epoch_0]_32181  loss=3.273237 |g|=0.41	lr=4.70e-04 | 36.3%@S27  T=1.06s eta=08:29:19 | 74.7K token/s | 
[epoch_0]_32191  loss=3.318853 |g|=0.399	lr=4.70e-04 | 37.1%@S27  T=1.04s eta=08:22:02 | 74.8K token/s | 
[Fuyou] head="3" update algorithm=4 t=2.04s
[eval] 
	 Loss@"edu_fineweb1B"=3.347(0.0016) nBranch=1 nToken=4.01M best=3.3486(159) E2T=-0.00229 T=13.4877(0)s x=0
	#3.34698±0.1067 tps=298K(4.01408M) a=[3.17019,3.6366] T=13.4877(sec)
[Section@32200] layer[24-30] tasks=15(nPassBack=0) last_loss=3.34926(-0.00901437) N=(580,27552,27132 3219900)
[epoch_0]_32201  loss=3.254089 |g|=0.372	lr=4.69e-04 | 37.9%@S27  T=4.19s eta=1d 09:33:45 | 72.1K token/s | 
[epoch_0]_32211  loss=3.362299 |g|=0.408	lr=4.69e-04 | 38.7%@S27  T=1.07s eta=08:34:02 | 72.3K token/s | 
[epoch_0]_32221  loss=3.317770 |g|=0.405	lr=4.69e-04 | 39.6%@S27  T=1.05s eta=08:25:32 | 72.6K token/s | 
[epoch_0]_32231  loss=3.405387 |g|=0.377	lr=4.69e-04 | 40.4%@S27  T=1.04s eta=08:18:53 | 72.9K token/s | 
[epoch_0]_32241  loss=3.272279 |g|=0.383	lr=4.68e-04 | 41.2%@S27  T=1.06s eta=08:30:28 | 73.1K token/s | 
[epoch_0]_32251  loss=3.387846 |g|=0.454	lr=4.68e-04 | 42.0%@S27  T=1.09s eta=08:41:03 | 73.2K token/s | 
[epoch_0]_32261  loss=3.350698 |g|=0.392	lr=4.68e-04 | 42.8%@S27  T=1.07s eta=08:34:44 | 73.4K token/s | 
[epoch_0]_32271  loss=3.268327 |g|=0.378	lr=4.68e-04 | 43.6%@S27  T=1.06s eta=08:29:12 | 73.6K token/s | 
[epoch_0]_32281  loss=3.362514 |g|=0.393	lr=4.67e-04 | 44.5%@S27  T=1.07s eta=08:33:57 | 73.7K token/s | 
[epoch_0]_32291  loss=3.306693 |g|=0.388	lr=4.67e-04 | 45.3%@S27  T=1.05s eta=08:23:57 | 73.9K token/s | 
[Fuyou] head="4" update algorithm=4 t=2.08s
[Section@32300] layer[30-36] tasks=15(nPassBack=0) last_loss=3.34487(0.0469019) N=(580,27636,27216 3229900)
[epoch_0]_32301  loss=3.229411 |g|=0.399	lr=4.67e-04 | 46.1%@S27  T=1.40s eta=11:08:18 | 73.1K token/s | 
[epoch_0]_32311  loss=3.345841 |g|=0.388	lr=4.67e-04 | 46.9%@S27  T=1.06s eta=08:25:13 | 73.4K token/s | 
[epoch_0]_32321  loss=3.326616 |g|=0.392	lr=4.66e-04 | 47.7%@S27  T=1.08s eta=08:34:57 | 73.5K token/s | 
[epoch_0]_32331  loss=3.306650 |g|=0.382	lr=4.66e-04 | 48.6%@S27  T=1.05s eta=08:21:08 | 73.7K token/s | 
[epoch_0]_32341  loss=3.237172 |g|=0.378	lr=4.66e-04 | 49.4%@S27  T=1.05s eta=08:20:27 | 74.0K token/s | 
[epoch_0]_32351  loss=3.349172 |g|=0.413	lr=4.66e-04 | 50.2%@S27  T=1.06s eta=08:26:49 | 74.1K token/s | 
[epoch_0]_32361  loss=3.404483 |g|=0.384	lr=4.65e-04 | 51.0%@S27  T=1.07s eta=08:29:33 | 74.3K token/s | 
[epoch_0]_32371  loss=3.323323 |g|=0.399	lr=4.65e-04 | 51.8%@S27  T=1.10s eta=08:46:34 | 74.3K token/s | 
[epoch_0]_32381  loss=3.313207 |g|=0.39	lr=4.65e-04 | 52.7%@S27  T=1.06s eta=08:27:21 | 74.4K token/s | 
[epoch_0]_32391  loss=3.340333 |g|=0.391	lr=4.65e-04 | 53.5%@S27  T=1.05s eta=08:21:10 | 74.6K token/s | 
[Fuyou] head="5" update algorithm=4 t=2.02s
[eval] 
	 Loss@"edu_fineweb1B"=3.346(0.00053) nBranch=1 nToken=4.01M best=3.3470(160) E2T=-0.0362 T=13.4909(0)s x=0
	#3.34644±0.1066 tps=298K(4.01408M) a=[3.1675,3.63449] T=13.4909(sec)
[Section@32400] layer[0-6] tasks=15(nPassBack=0) last_loss=3.38261(-0.024925) N=(580,27720,27300 3239900)
[epoch_0]_32401  loss=3.311874 |g|=0.384	lr=4.64e-04 | 54.3%@S27  T=4.19s eta=1d 09:18:53 | 71.8K token/s | 
[epoch_0]_32411  loss=3.283253 |g|=0.414	lr=4.64e-04 | 55.1%@S27  T=1.08s eta=08:35:26 | 72.0K token/s | 
[epoch_0]_32421  loss=3.353957 |g|=0.397	lr=4.64e-04 | 55.9%@S27  T=1.06s eta=08:23:40 | 72.3K token/s | 
[epoch_0]_32431  loss=3.269828 |g|=0.414	lr=4.64e-04 | 56.8%@S27  T=1.07s eta=08:28:17 | 72.5K token/s | 
[epoch_0]_32441  loss=3.320255 |g|=0.458	lr=4.63e-04 | 57.6%@S27  T=1.09s eta=08:38:38 | 72.7K token/s | 
[epoch_0]_32451  loss=3.288647 |g|=0.421	lr=4.63e-04 | 58.4%@S27  T=1.09s eta=08:37:42 | 72.8K token/s | 
[epoch_0]_32461  loss=3.380933 |g|=0.391	lr=4.63e-04 | 59.2%@S27  T=1.03s eta=08:12:05 | 73.1K token/s | 
[epoch_0]_32471  loss=3.273605 |g|=0.391	lr=4.63e-04 | 60.0%@S27  T=1.05s eta=08:18:17 | 73.4K token/s | 
[epoch_0]_32481  loss=3.420390 |g|=0.431	lr=4.62e-04 | 60.9%@S27  T=1.04s eta=08:15:35 | 73.7K token/s | 
[epoch_0]_32491  loss=3.237601 |g|=0.403	lr=4.62e-04 | 61.7%@S27  T=1.06s eta=08:24:03 | 73.8K token/s | 
[Fuyou] head="0" update algorithm=4 t=2.07s
[Section@32500] layer[6-12] tasks=15(nPassBack=0) last_loss=3.23432(0.0914202) N=(580,27804,27384 3249900)
[epoch_0]_32501  loss=3.422374 |g|=0.386	lr=4.62e-04 | 62.5%@S27  T=1.33s eta=10:32:32 | 73.2K token/s | 
[epoch_0]_32511  loss=3.320203 |g|=0.429	lr=4.61e-04 | 63.3%@S27  T=1.04s eta=08:16:14 | 73.5K token/s | 
[epoch_0]_32521  loss=3.335160 |g|=0.449	lr=4.61e-04 | 64.1%@S27  T=1.07s eta=08:30:43 | 73.6K token/s | 
[epoch_0]_32531  loss=3.367538 |g|=0.389	lr=4.61e-04 | 64.9%@S27  T=1.08s eta=08:32:10 | 73.7K token/s | 
[epoch_0]_32541  loss=3.354311 |g|=0.399	lr=4.61e-04 | 65.8%@S27  T=1.05s eta=08:17:18 | 74.0K token/s | 
[epoch_0]_32551  loss=3.380467 |g|=0.372	lr=4.60e-04 | 66.6%@S27  T=1.05s eta=08:19:45 | 74.2K token/s | 
[epoch_0]_32561  loss=3.342049 |g|=0.437	lr=4.60e-04 | 67.4%@S27  T=1.05s eta=08:18:06 | 74.4K token/s | 
[epoch_0]_32571  loss=3.385722 |g|=0.417	lr=4.60e-04 | 68.2%@S27  T=1.07s eta=08:25:33 | 74.5K token/s | 
[epoch_0]_32581  loss=3.348817 |g|=0.412	lr=4.60e-04 | 69.0%@S27  T=1.11s eta=08:44:03 | 74.5K token/s | 
[epoch_0]_32591  loss=3.314433 |g|=0.393	lr=4.59e-04 | 69.9%@S27  T=1.04s eta=08:13:42 | 74.7K token/s | 
[Fuyou] head="1" update algorithm=4 t=2.07s
[eval] 
	 Loss@"edu_fineweb1B"=3.346(0.00017) nBranch=1 nToken=4.01M best=3.3464(161) E2T=-0.086 T=13.4938(0)s x=0
	#3.34627±0.1070 tps=297K(4.01408M) a=[3.16964,3.63914] T=13.4938(sec)
[Section@32600] layer[12-18] tasks=15(nPassBack=0) last_loss=3.43225(-0.126158) N=(580,27888,27468 3259900)
[epoch_0]_32601  loss=3.331588 |g|=0.378	lr=4.59e-04 | 70.7%@S27  T=4.17s eta=1d 08:57:59 | 71.9K token/s | 
[epoch_0]_32611  loss=3.341760 |g|=0.395	lr=4.59e-04 | 71.5%@S27  T=1.05s eta=08:19:13 | 72.2K token/s | 
[epoch_0]_32621  loss=3.314709 |g|=0.388	lr=4.59e-04 | 72.3%@S27  T=1.05s eta=08:16:54 | 72.5K token/s | 
[epoch_0]_32631  loss=3.290357 |g|=0.392	lr=4.58e-04 | 73.1%@S27  T=1.07s eta=08:28:54 | 72.7K token/s | 
[epoch_0]_32641  loss=3.384602 |g|=0.389	lr=4.58e-04 | 74.0%@S27  T=1.04s eta=08:14:25 | 73.0K token/s | 
[epoch_0]_32651  loss=3.322191 |g|=0.401	lr=4.58e-04 | 74.8%@S27  T=1.05s eta=08:14:59 | 73.2K token/s | 
[epoch_0]_32661  loss=3.353806 |g|=0.406	lr=4.58e-04 | 75.6%@S27  T=1.05s eta=08:14:43 | 73.5K token/s | 
[epoch_0]_32671  loss=3.315864 |g|=0.412	lr=4.57e-04 | 76.4%@S27  T=1.05s eta=08:17:13 | 73.7K token/s | 
[epoch_0]_32681  loss=3.274457 |g|=0.421	lr=4.57e-04 | 77.2%@S27  T=1.10s eta=08:38:10 | 73.8K token/s | 
[epoch_0]_32691  loss=3.332639 |g|=0.404	lr=4.57e-04 | 78.1%@S27  T=1.05s eta=08:18:07 | 74.0K token/s | 
[Fuyou] head="2" update algorithm=4 t=2.08s
[Section@32700] layer[18-24] tasks=15(nPassBack=0) last_loss=3.35143(0.00964427) N=(580,27972,27552 3269900)
[epoch_0]_32701  loss=3.395447 |g|=0.381	lr=4.57e-04 | 78.9%@S27  T=1.35s eta=10:37:52 | 73.3K token/s | 
[epoch_0]_32711  loss=3.274364 |g|=0.42	lr=4.56e-04 | 79.7%@S27  T=1.04s eta=08:12:29 | 73.6K token/s | 
[epoch_0]_32721  loss=3.346106 |g|=0.385	lr=4.56e-04 | 80.5%@S27  T=1.06s eta=08:22:03 | 73.7K token/s | 
[epoch_0]_32731  loss=3.300715 |g|=0.426	lr=4.56e-04 | 81.3%@S27  T=1.09s eta=08:35:04 | 73.8K token/s | 
[epoch_0]_32741  loss=3.348384 |g|=0.411	lr=4.56e-04 | 82.2%@S27  T=1.04s eta=08:10:38 | 74.0K token/s | 
[epoch_0]_32751  loss=3.371137 |g|=0.401	lr=4.55e-04 | 83.0%@S27  T=1.05s eta=08:16:40 | 74.2K token/s | 
[epoch_0]_32761  loss=3.331173 |g|=0.409	lr=4.55e-04 | 83.8%@S27  T=1.05s eta=08:12:34 | 74.4K token/s | 
[epoch_0]_32771  loss=3.367160 |g|=0.411	lr=4.55e-04 | 84.6%@S27  T=1.05s eta=08:15:43 | 74.6K token/s | 
[epoch_0]_32781  loss=3.346455 |g|=0.406	lr=4.55e-04 | 85.4%@S27  T=1.07s eta=08:25:56 | 74.7K token/s | 
[epoch_0]_32791  loss=3.316992 |g|=0.421	lr=4.54e-04 | 86.2%@S27  T=1.08s eta=08:29:50 | 74.7K token/s | 
[Fuyou] head="3" update algorithm=4 t=2.09s
[eval] 
	 Loss@"edu_fineweb1B"=3.346(0.00051) nBranch=1 nToken=4.01M best=3.3463(162) E2T=0.0532 T=13.5017(0)s x=0
	#3.34576±0.1057 tps=297K(4.01408M) a=[3.17054,3.63253] T=13.5017(sec)
[Section@32800] layer[24-30] tasks=15(nPassBack=0) last_loss=3.29253(0.056735) N=(580,28056,27636 3279900)
[epoch_0]_32801  loss=3.352442 |g|=0.384	lr=4.54e-04 | 87.1%@S27  T=4.19s eta=1d 08:49:22 | 72.0K token/s | 
[epoch_0]_32811  loss=3.225774 |g|=0.435	lr=4.54e-04 | 87.9%@S27  T=1.07s eta=08:24:23 | 72.2K token/s | 
[epoch_0]_32821  loss=3.314834 |g|=0.412	lr=4.54e-04 | 88.7%@S27  T=1.05s eta=08:12:03 | 72.5K token/s | 
[epoch_0]_32831  loss=3.276000 |g|=0.401	lr=4.53e-04 | 89.5%@S27  T=1.07s eta=08:22:11 | 72.7K token/s | 
[epoch_0]_32841  loss=3.363960 |g|=0.395	lr=4.53e-04 | 90.3%@S27  T=1.08s eta=08:29:00 | 72.9K token/s | 
[epoch_0]_32851  loss=3.394751 |g|=0.386	lr=4.53e-04 | 91.2%@S27  T=1.09s eta=08:31:52 | 73.0K token/s | 
[epoch_0]_32861  loss=3.352715 |g|=0.404	lr=4.53e-04 | 92.0%@S27  T=1.05s eta=08:13:20 | 73.2K token/s | 
[epoch_0]_32871  loss=3.324860 |g|=0.42	lr=4.52e-04 | 92.8%@S27  T=1.06s eta=08:15:23 | 73.4K token/s | 
[epoch_0]_32881  loss=3.279855 |g|=0.383	lr=4.52e-04 | 93.6%@S27  T=1.05s eta=08:13:20 | 73.7K token/s | 
[epoch_0]_32891  loss=3.319737 |g|=0.417	lr=4.52e-04 | 94.4%@S27  T=1.05s eta=08:13:30 | 73.9K token/s | 
[Fuyou] head="4" update algorithm=4 t=2.07s
[Section@32900] layer[30-36] tasks=15(nPassBack=0) last_loss=3.40472(-0.0598538) N=(580,28140,27720 3289900)
[epoch_0]_32901  loss=3.257689 |g|=0.401	lr=4.51e-04 | 95.3%@S27  T=1.33s eta=10:23:38 | 73.3K token/s | 
[epoch_0]_32911  loss=3.405660 |g|=0.383	lr=4.51e-04 | 96.1%@S27  T=1.08s eta=08:26:57 | 73.4K token/s | 
[epoch_0]_32921  loss=3.334308 |g|=0.401	lr=4.51e-04 | 96.9%@S27  T=1.04s eta=08:09:14 | 73.6K token/s | 
[epoch_0]_32931  loss=3.308642 |g|=0.397	lr=4.51e-04 | 97.7%@S27  T=1.05s eta=08:13:39 | 73.8K token/s | 
[epoch_0]_32941  loss=3.300991 |g|=0.399	lr=4.50e-04 | 98.5%@S27  T=1.06s eta=08:14:54 | 74.0K token/s | 
[epoch_0]_32951  loss=3.281152 |g|=0.398	lr=4.50e-04 | 99.4%@S27  T=1.07s eta=08:20:52 | 74.2K token/s | 
[epoch_0]_32958  loss=3.265488 |g|=0.385	lr=4.50e-04 | 99.9%@S27  T=1.05s eta=08:10:05 | 74.4K token/s | 
-------- End of shard_27@"./Datasets/edu_fineweb1B/edu_fineweb_train_000480.bin"-------- 
[shard-28]@"./Datasets/edu_fineweb1B/edu_fineweb_train_000481.bin": tokens=100(M) nShardSamples=1220(2734368) 
[epoch_0]_32961  loss=3.339103 |g|=0.399	lr=4.50e-04 | 0.2%@S28  T=1.09s eta=08:31:36 | 74.4K token/s | 
[epoch_0]_32971  loss=3.463447 |g|=0.423	lr=4.50e-04 | 1.0%@S28  T=1.05s eta=08:13:02 | 74.6K token/s | 
[epoch_0]_32981  loss=3.356827 |g|=0.444	lr=4.49e-04 | 1.8%@S28  T=1.05s eta=08:11:25 | 74.7K token/s | 
[epoch_0]_32991  loss=3.393661 |g|=0.402	lr=4.49e-04 | 2.6%@S28  T=1.05s eta=08:11:26 | 74.9K token/s | 
[Fuyou] head="5" update algorithm=4 t=2.08s
[eval] 
	 Loss@"edu_fineweb1B"=3.340(0.0061) nBranch=1 nToken=4.01M best=3.3458(163) E2T=-0.0043 T=13.4847(0)s x=0
	#3.3397±0.1063 tps=298K(4.01408M) a=[3.15719,3.6253] T=13.4847(sec)
[Section@33000] layer[0-6] tasks=15(nPassBack=0) last_loss=3.344(0.0386043) N=(580,28224,27804 3299900)
[epoch_0]_33001  loss=3.377605 |g|=0.371	lr=4.49e-04 | 3.4%@S28  T=4.18s eta=1d 08:33:49 | 72.1K token/s | 
[epoch_0]_33011  loss=3.418579 |g|=0.394	lr=4.49e-04 | 4.3%@S28  T=1.08s eta=08:23:53 | 72.3K token/s | 
[epoch_0]_33021  loss=3.486335 |g|=0.362	lr=4.48e-04 | 5.1%@S28  T=1.05s eta=08:12:25 | 72.6K token/s | 
[epoch_0]_33031  loss=3.346573 |g|=0.401	lr=4.48e-04 | 5.9%@S28  T=1.06s eta=08:12:54 | 72.8K token/s | 
[epoch_0]_33041  loss=3.385321 |g|=0.393	lr=4.48e-04 | 6.7%@S28  T=1.09s eta=08:29:07 | 72.9K token/s | 
[epoch_0]_33051  loss=3.317507 |g|=0.404	lr=4.48e-04 | 7.5%@S28  T=1.09s eta=08:26:40 | 73.1K token/s | 
[epoch_0]_33061  loss=3.416167 |g|=0.422	lr=4.47e-04 | 8.4%@S28  T=1.05s eta=08:09:04 | 73.3K token/s | 
[epoch_0]_33071  loss=3.389992 |g|=0.434	lr=4.47e-04 | 9.2%@S28  T=1.05s eta=08:10:37 | 73.5K token/s | 
[epoch_0]_33081  loss=3.444125 |g|=0.413	lr=4.47e-04 | 10.0%@S28  T=1.06s eta=08:11:57 | 73.7K token/s | 
[epoch_0]_33091  loss=3.337344 |g|=0.393	lr=4.47e-04 | 10.8%@S28  T=1.06s eta=08:12:46 | 73.9K token/s | 
[Fuyou] head="0" update algorithm=4 t=2.10s
[Section@33100] layer[6-12] tasks=15(nPassBack=0) last_loss=3.35252(-0.118209) N=(580,28308,27888 3309900)
[epoch_0]_33101  loss=3.334356 |g|=0.395	lr=4.46e-04 | 11.6%@S28  T=1.34s eta=10:22:31 | 73.3K token/s | 
[epoch_0]_33111  loss=3.379231 |g|=0.39	lr=4.46e-04 | 12.5%@S28  T=1.05s eta=08:08:26 | 73.5K token/s | 
[epoch_0]_33121  loss=3.360441 |g|=0.407	lr=4.46e-04 | 13.3%@S28  T=1.07s eta=08:15:56 | 73.7K token/s | 
[epoch_0]_33131  loss=3.263177 |g|=0.411	lr=4.46e-04 | 14.1%@S28  T=1.11s eta=08:37:01 | 73.7K token/s | 
[epoch_0]_33141  loss=3.324644 |g|=0.401	lr=4.45e-04 | 14.9%@S28  T=1.05s eta=08:08:30 | 73.9K token/s | 
[epoch_0]_33151  loss=3.360923 |g|=0.435	lr=4.45e-04 | 15.7%@S28  T=1.06s eta=08:11:53 | 74.1K token/s | 
[epoch_0]_33161  loss=3.383487 |g|=0.426	lr=4.45e-04 | 16.6%@S28  T=1.04s eta=08:04:06 | 74.3K token/s | 
[epoch_0]_33171  loss=3.443013 |g|=0.415	lr=4.45e-04 | 17.4%@S28  T=1.06s eta=08:10:07 | 74.5K token/s | 
[epoch_0]_33181  loss=3.399945 |g|=0.404	lr=4.44e-04 | 18.2%@S28  T=1.08s eta=08:20:11 | 74.6K token/s | 
[epoch_0]_33191  loss=3.343545 |g|=0.397	lr=4.44e-04 | 19.0%@S28  T=1.11s eta=08:32:57 | 74.5K token/s | 
[Fuyou] head="1" update algorithm=4 t=2.09s
[eval] 
	 Loss@"edu_fineweb1B"=3.335(0.0048) nBranch=1 nToken=4.01M best=3.3397(164) E2T=-9.3e-05 T=13.4921(0)s x=0
	#3.33485±0.1062 tps=298K(4.01408M) a=[3.15735,3.61862] T=13.4921(sec)
[Section@33200] layer[12-18] tasks=15(nPassBack=0) last_loss=3.33495(0.0973053) N=(580,28392,27972 3319900)
[epoch_0]_33201  loss=3.372715 |g|=0.412	lr=4.44e-04 | 19.8%@S28  T=4.19s eta=1d 08:21:46 | 71.8K token/s | 
[epoch_0]_33211  loss=3.322583 |g|=0.386	lr=4.44e-04 | 20.7%@S28  T=1.06s eta=08:11:00 | 72.1K token/s | 
[epoch_0]_33221  loss=3.349279 |g|=0.405	lr=4.43e-04 | 21.5%@S28  T=1.05s eta=08:06:26 | 72.4K token/s | 
[epoch_0]_33231  loss=3.362256 |g|=0.425	lr=4.43e-04 | 22.3%@S28  T=1.07s eta=08:14:42 | 72.6K token/s | 
[epoch_0]_33241  loss=3.405643 |g|=0.433	lr=4.43e-04 | 23.1%@S28  T=1.06s eta=08:09:49 | 72.8K token/s | 
[epoch_0]_33251  loss=3.436824 |g|=0.396	lr=4.43e-04 | 23.9%@S28  T=1.05s eta=08:07:56 | 73.1K token/s | 
[epoch_0]_33261  loss=3.442016 |g|=0.392	lr=4.42e-04 | 24.7%@S28  T=1.07s eta=08:16:46 | 73.2K token/s | 
[epoch_0]_33271  loss=3.356679 |g|=0.421	lr=4.42e-04 | 25.6%@S28  T=1.06s eta=08:08:37 | 73.5K token/s | 
[epoch_0]_33281  loss=3.329415 |g|=0.383	lr=4.42e-04 | 26.4%@S28  T=1.08s eta=08:21:02 | 73.6K token/s | 
[epoch_0]_33291  loss=3.352428 |g|=0.4	lr=4.42e-04 | 27.2%@S28  T=1.07s eta=08:14:26 | 73.7K token/s | 
[Fuyou] head="2" update algorithm=4 t=2.01s
[Section@33300] layer[18-24] tasks=15(nPassBack=0) last_loss=3.39384(-0.0424087) N=(580,28476,28056 3329900)
[epoch_0]_33301  loss=3.376870 |g|=0.384	lr=4.41e-04 | 28.0%@S28  T=1.42s eta=10:55:54 | 72.9K token/s | 
[epoch_0]_33311  loss=3.424403 |g|=0.409	lr=4.41e-04 | 28.8%@S28  T=1.06s eta=08:08:06 | 73.1K token/s | 
[epoch_0]_33321  loss=3.368955 |g|=0.413	lr=4.41e-04 | 29.7%@S28  T=1.05s eta=08:06:46 | 73.4K token/s | 
[epoch_0]_33331  loss=3.319156 |g|=0.415	lr=4.41e-04 | 30.5%@S28  T=1.07s eta=08:12:51 | 73.5K token/s | 
[epoch_0]_33341  loss=3.400772 |g|=0.433	lr=4.40e-04 | 31.3%@S28  T=1.09s eta=08:21:30 | 73.6K token/s | 
[epoch_0]_33351  loss=3.314564 |g|=0.403	lr=4.40e-04 | 32.1%@S28  T=1.10s eta=08:25:53 | 73.7K token/s | 
[epoch_0]_33361  loss=3.356687 |g|=0.427	lr=4.40e-04 | 32.9%@S28  T=1.05s eta=08:06:27 | 73.9K token/s | 
[epoch_0]_33371  loss=3.385346 |g|=0.414	lr=4.39e-04 | 33.8%@S28  T=1.04s eta=08:00:54 | 74.1K token/s | 
[epoch_0]_33381  loss=3.366782 |g|=0.386	lr=4.39e-04 | 34.6%@S28  T=1.06s eta=08:06:16 | 74.3K token/s | 
[epoch_0]_33391  loss=3.362396 |g|=0.395	lr=4.39e-04 | 35.4%@S28  T=1.07s eta=08:13:16 | 74.4K token/s | 
[Fuyou] head="3" update algorithm=4 t=2.08s
[eval] 
	 Loss@"edu_fineweb1B"=3.332(0.0032) nBranch=1 nToken=4.01M best=3.3349(165) E2T=-0.0469 T=13.491(0)s x=0
	#3.3317±0.1053 tps=298K(4.01408M) a=[3.1477,3.61163] T=13.491(sec)
[Section@33400] layer[24-30] tasks=15(nPassBack=0) last_loss=3.37857(-0.0860465) N=(580,28560,28140 3339900)
[epoch_0]_33401  loss=3.338009 |g|=0.426	lr=4.39e-04 | 36.2%@S28  T=4.19s eta=1d 08:08:35 | 71.7K token/s | 
[epoch_0]_33411  loss=3.327738 |g|=0.395	lr=4.38e-04 | 37.0%@S28  T=1.08s eta=08:17:44 | 71.9K token/s | 
[epoch_0]_33421  loss=3.346158 |g|=0.388	lr=4.38e-04 | 37.9%@S28  T=1.06s eta=08:08:22 | 72.1K token/s | 
[epoch_0]_33431  loss=3.399137 |g|=0.382	lr=4.38e-04 | 38.7%@S28  T=1.07s eta=08:12:14 | 72.4K token/s | 
[epoch_0]_33441  loss=3.412021 |g|=0.416	lr=4.38e-04 | 39.5%@S28  T=1.11s eta=08:29:31 | 72.4K token/s | 
[epoch_0]_33451  loss=3.358866 |g|=0.396	lr=4.37e-04 | 40.3%@S28  T=1.06s eta=08:06:02 | 72.7K token/s | 
[epoch_0]_33461  loss=3.251353 |g|=0.388	lr=4.37e-04 | 41.1%@S28  T=1.04s eta=07:59:28 | 73.0K token/s | 
[epoch_0]_33471  loss=3.404971 |g|=0.43	lr=4.37e-04 | 42.0%@S28  T=1.05s eta=08:02:09 | 73.2K token/s | 
[epoch_0]_33481  loss=3.356670 |g|=0.392	lr=4.37e-04 | 42.8%@S28  T=1.07s eta=08:09:51 | 73.4K token/s | 
[epoch_0]_33491  loss=3.368026 |g|=0.426	lr=4.36e-04 | 43.6%@S28  T=1.08s eta=08:14:08 | 73.5K token/s | 
[Fuyou] head="4" update algorithm=4 t=2.04s
[Section@33500] layer[30-36] tasks=15(nPassBack=0) last_loss=3.39115(0.0135684) N=(580,28644,28224 3349900)
[epoch_0]_33501  loss=3.346583 |g|=0.409	lr=4.36e-04 | 44.4%@S28  T=1.32s eta=10:07:27 | 73.0K token/s | 
[epoch_0]_33511  loss=3.340763 |g|=0.433	lr=4.36e-04 | 45.2%@S28  T=1.05s eta=08:03:32 | 73.2K token/s | 
[epoch_0]_33521  loss=3.400467 |g|=0.394	lr=4.36e-04 | 46.0%@S28  T=1.07s eta=08:11:29 | 73.4K token/s | 
[epoch_0]_33531  loss=3.330208 |g|=0.398	lr=4.35e-04 | 46.9%@S28  T=1.11s eta=08:27:09 | 73.4K token/s | 
[epoch_0]_33541  loss=3.365760 |g|=0.393	lr=4.35e-04 | 47.7%@S28  T=1.05s eta=08:01:46 | 73.6K token/s | 
[epoch_0]_33551  loss=3.348355 |g|=0.41	lr=4.35e-04 | 48.5%@S28  T=1.06s eta=08:06:25 | 73.8K token/s | 
[epoch_0]_33561  loss=3.384201 |g|=0.379	lr=4.35e-04 | 49.3%@S28  T=1.05s eta=08:01:06 | 74.0K token/s | 
[epoch_0]_33571  loss=3.392576 |g|=0.402	lr=4.34e-04 | 50.1%@S28  T=1.07s eta=08:10:18 | 74.1K token/s | 
[epoch_0]_33581  loss=3.387347 |g|=0.412	lr=4.34e-04 | 51.0%@S28  T=1.06s eta=08:04:43 | 74.3K token/s | 
[epoch_0]_33591  loss=3.418175 |g|=0.428	lr=4.34e-04 | 51.8%@S28  T=1.09s eta=08:20:06 | 74.3K token/s | 
[Fuyou] head="5" update algorithm=4 t=2.07s
[eval] 
	 Loss@"edu_fineweb1B"=3.328(0.0034) nBranch=1 nToken=4.01M best=3.3317(166) E2T=-0.0598 T=13.4883(0)s x=0
	#3.32827±0.1057 tps=298K(4.01408M) a=[3.1391,3.6067] T=13.4883(sec)
[Section@33600] layer[0-6] tasks=15(nPassBack=0) last_loss=3.38806(-0.0440621) N=(580,28728,28308 3359900)
[epoch_0]_33601  loss=3.343076 |g|=0.392	lr=4.34e-04 | 52.6%@S28  T=4.20s eta=1d 07:58:10 | 71.6K token/s | 
[epoch_0]_33611  loss=3.363000 |g|=0.419	lr=4.33e-04 | 53.4%@S28  T=1.06s eta=08:02:20 | 71.9K token/s | 
[epoch_0]_33621  loss=3.320132 |g|=0.389	lr=4.33e-04 | 54.2%@S28  T=1.07s eta=08:07:43 | 72.1K token/s | 
[epoch_0]_33631  loss=3.307958 |g|=0.402	lr=4.33e-04 | 55.1%@S28  T=1.10s eta=08:24:12 | 72.2K token/s | 
[epoch_0]_33641  loss=3.299419 |g|=0.396	lr=4.33e-04 | 55.9%@S28  T=1.07s eta=08:09:47 | 72.4K token/s | 
[epoch_0]_33651  loss=3.339231 |g|=0.42	lr=4.32e-04 | 56.7%@S28  T=1.06s eta=08:01:37 | 72.7K token/s | 
[epoch_0]_33661  loss=3.396383 |g|=0.424	lr=4.32e-04 | 57.5%@S28  T=1.06s eta=08:03:22 | 72.9K token/s | 
[epoch_0]_33671  loss=3.408735 |g|=0.427	lr=4.32e-04 | 58.3%@S28  T=1.06s eta=08:02:52 | 73.2K token/s | 
[epoch_0]_33681  loss=3.326997 |g|=0.407	lr=4.32e-04 | 59.2%@S28  T=1.08s eta=08:11:47 | 73.3K token/s | 
[epoch_0]_33691  loss=3.302815 |g|=0.415	lr=4.31e-04 | 60.0%@S28  T=1.09s eta=08:16:13 | 73.4K token/s | 
[Fuyou] head="0" update algorithm=4 t=2.08s
[Section@33700] layer[6-12] tasks=15(nPassBack=0) last_loss=3.35792(-0.0053947) N=(580,28812,28392 3369900)
[epoch_0]_33701  loss=3.402457 |g|=0.4	lr=4.31e-04 | 60.8%@S28  T=1.38s eta=10:27:58 | 72.7K token/s | 
[epoch_0]_33711  loss=3.342973 |g|=0.399	lr=4.31e-04 | 61.6%@S28  T=1.06s eta=08:02:14 | 72.9K token/s | 
[epoch_0]_33721  loss=3.349111 |g|=0.399	lr=4.31e-04 | 62.4%@S28  T=1.07s eta=08:05:28 | 73.1K token/s | 
[epoch_0]_33731  loss=3.370989 |g|=0.42	lr=4.30e-04 | 63.3%@S28  T=1.08s eta=08:09:47 | 73.3K token/s | 
[epoch_0]_33741  loss=3.305469 |g|=0.434	lr=4.30e-04 | 64.1%@S28  T=1.08s eta=08:12:05 | 73.4K token/s | 
[epoch_0]_33751  loss=3.319841 |g|=0.403	lr=4.30e-04 | 64.9%@S28  T=1.09s eta=08:13:55 | 73.5K token/s | 
[epoch_0]_33761  loss=3.381336 |g|=0.422	lr=4.30e-04 | 65.7%@S28  T=1.05s eta=07:59:16 | 73.7K token/s | 
[epoch_0]_33771  loss=3.318511 |g|=0.41	lr=4.29e-04 | 66.5%@S28  T=1.09s eta=08:13:02 | 73.8K token/s | 
[epoch_0]_33781  loss=3.350287 |g|=0.398	lr=4.29e-04 | 67.3%@S28  T=1.06s eta=07:59:16 | 74.0K token/s | 
[epoch_0]_33791  loss=3.366226 |g|=0.379	lr=4.29e-04 | 68.2%@S28  T=1.06s eta=07:59:45 | 74.2K token/s | 
[Fuyou] head="1" update algorithm=4 t=2.08s
[eval] 
	 Loss@"edu_fineweb1B"=3.326(0.0023) nBranch=1 nToken=4.01M best=3.3283(167) E2T=-0.0724 T=13.4985(0)s x=0
	#3.32598±0.1061 tps=297K(4.01408M) a=[3.14519,3.6067] T=13.4985(sec)
[Section@33800] layer[12-18] tasks=15(nPassBack=0) last_loss=3.3984(-0.063448) N=(580,28896,28476 3379900)
[epoch_0]_33801  loss=3.389055 |g|=0.39	lr=4.29e-04 | 69.0%@S28  T=4.20s eta=1d 07:47:24 | 71.4K token/s | 
[epoch_0]_33811  loss=3.383645 |g|=0.405	lr=4.28e-04 | 69.8%@S28  T=1.06s eta=08:00:49 | 71.7K token/s | 
[epoch_0]_33821  loss=3.325253 |g|=0.424	lr=4.28e-04 | 70.6%@S28  T=1.05s eta=07:56:16 | 72.0K token/s | 
[epoch_0]_33831  loss=3.408571 |g|=0.397	lr=4.28e-04 | 71.4%@S28  T=1.12s eta=08:28:49 | 72.1K token/s | 
[epoch_0]_33841  loss=3.396696 |g|=0.427	lr=4.28e-04 | 72.3%@S28  T=1.05s eta=07:55:31 | 72.4K token/s | 
[epoch_0]_33851  loss=3.293866 |g|=0.446	lr=4.27e-04 | 73.1%@S28  T=1.05s eta=07:53:38 | 72.7K token/s | 
[epoch_0]_33861  loss=3.311497 |g|=0.412	lr=4.27e-04 | 73.9%@S28  T=1.05s eta=07:57:39 | 72.9K token/s | 
[epoch_0]_33871  loss=3.386650 |g|=0.392	lr=4.27e-04 | 74.7%@S28  T=1.06s eta=08:00:05 | 73.1K token/s | 
[epoch_0]_33881  loss=3.376699 |g|=0.446	lr=4.27e-04 | 75.5%@S28  T=1.07s eta=08:04:29 | 73.3K token/s | 
[epoch_0]_33891  loss=3.337100 |g|=0.42	lr=4.26e-04 | 76.4%@S28  T=1.11s eta=08:20:05 | 73.4K token/s | 
[Fuyou] head="2" update algorithm=4 t=2.08s
[Section@33900] layer[18-24] tasks=15(nPassBack=0) last_loss=3.3464(0.0474398) N=(580,28980,28560 3389900)
[epoch_0]_33901  loss=3.378257 |g|=0.415	lr=4.26e-04 | 77.2%@S28  T=1.58s eta=11:53:45 | 72.3K token/s | 
[epoch_0]_33911  loss=3.344784 |g|=0.397	lr=4.26e-04 | 78.0%@S28  T=1.07s eta=08:02:56 | 72.5K token/s | 
[epoch_0]_33921  loss=3.365674 |g|=0.401	lr=4.25e-04 | 78.8%@S28  T=1.05s eta=07:56:16 | 72.8K token/s | 
[epoch_0]_33931  loss=3.302532 |g|=0.444	lr=4.25e-04 | 79.6%@S28  T=1.07s eta=08:02:22 | 73.0K token/s | 
[epoch_0]_33941  loss=3.284000 |g|=0.442	lr=4.25e-04 | 80.5%@S28  T=1.10s eta=08:18:13 | 73.0K token/s | 
[epoch_0]_33951  loss=3.425138 |g|=0.404	lr=4.25e-04 | 81.3%@S28  T=1.06s eta=07:56:49 | 73.3K token/s | 
[epoch_0]_33961  loss=3.299753 |g|=0.43	lr=4.24e-04 | 82.1%@S28  T=1.05s eta=07:53:06 | 73.5K token/s | 
[epoch_0]_33971  loss=3.389909 |g|=0.427	lr=4.24e-04 | 82.9%@S28  T=1.06s eta=07:57:04 | 73.7K token/s | 
[epoch_0]_33981  loss=3.386750 |g|=0.43	lr=4.24e-04 | 83.7%@S28  T=1.08s eta=08:04:49 | 73.8K token/s | 
[epoch_0]_33991  loss=3.319366 |g|=0.395	lr=4.24e-04 | 84.6%@S28  T=1.06s eta=07:59:44 | 74.0K token/s | 
[Fuyou] head="3" update algorithm=4 t=2.02s
[eval] 
	 Loss@"edu_fineweb1B"=3.325(0.0011) nBranch=1 nToken=4.01M best=3.3260(168) E2T=-0.0226 T=13.4917(0)s x=0
	#3.3249±0.1056 tps=298K(4.01408M) a=[3.1475,3.61112] T=13.4917(sec)
[Section@34000] layer[24-30] tasks=15(nPassBack=0) last_loss=3.34753(0.0310407) N=(580,29064,28644 3399900)
[epoch_0]_34001  loss=3.333625 |g|=0.416	lr=4.23e-04 | 85.4%@S28  T=4.18s eta=1d 07:25:31 | 71.3K token/s | 
[epoch_0]_34011  loss=3.307822 |g|=0.395	lr=4.23e-04 | 86.2%@S28  T=1.08s eta=08:08:26 | 71.5K token/s | 
[epoch_0]_34021  loss=3.386749 |g|=0.431	lr=4.23e-04 | 87.0%@S28  T=1.06s eta=07:56:33 | 71.8K token/s | 
[epoch_0]_34031  loss=3.307488 |g|=0.435	lr=4.23e-04 | 87.8%@S28  T=1.06s eta=07:58:54 | 72.0K token/s | 
[epoch_0]_34041  loss=3.317013 |g|=0.409	lr=4.22e-04 | 88.6%@S28  T=1.08s eta=08:07:10 | 72.2K token/s | 
[epoch_0]_34051  loss=3.344978 |g|=0.394	lr=4.22e-04 | 89.5%@S28  T=1.08s eta=08:07:07 | 72.4K token/s | 
[epoch_0]_34061  loss=3.405596 |g|=0.433	lr=4.22e-04 | 90.3%@S28  T=1.05s eta=07:52:28 | 72.7K token/s | 
[epoch_0]_34071  loss=3.337320 |g|=0.402	lr=4.22e-04 | 91.1%@S28  T=1.05s eta=07:50:29 | 72.9K token/s | 
[epoch_0]_34081  loss=3.362230 |g|=0.415	lr=4.21e-04 | 91.9%@S28  T=1.06s eta=07:54:37 | 73.2K token/s | 
[epoch_0]_34091  loss=3.293059 |g|=0.406	lr=4.21e-04 | 92.7%@S28  T=1.07s eta=07:58:27 | 73.4K token/s | 
[Fuyou] head="4" update algorithm=4 t=2.05s
[Section@34100] layer[30-36] tasks=15(nPassBack=0) last_loss=3.27021(0.120947) N=(580,29148,28728 3409900)
[epoch_0]_34101  loss=3.326239 |g|=0.407	lr=4.21e-04 | 93.6%@S28  T=1.34s eta=10:00:19 | 72.7K token/s | 
[epoch_0]_34111  loss=3.358394 |g|=0.405	lr=4.21e-04 | 94.4%@S28  T=1.04s eta=07:47:40 | 73.0K token/s | 
[epoch_0]_34121  loss=3.342077 |g|=0.451	lr=4.20e-04 | 95.2%@S28  T=1.06s eta=07:56:33 | 73.2K token/s | 
[epoch_0]_34131  loss=3.329156 |g|=0.424	lr=4.20e-04 | 96.0%@S28  T=1.07s eta=07:59:18 | 73.4K token/s | 
[epoch_0]_34141  loss=3.337115 |g|=0.419	lr=4.20e-04 | 96.8%@S28  T=1.10s eta=08:11:32 | 73.5K token/s | 
[epoch_0]_34151  loss=3.370457 |g|=0.399	lr=4.20e-04 | 97.7%@S28  T=1.05s eta=07:51:09 | 73.7K token/s | 
[epoch_0]_34161  loss=3.357441 |g|=0.393	lr=4.19e-04 | 98.5%@S28  T=1.06s eta=07:53:28 | 73.9K token/s | 
[epoch_0]_34171  loss=3.358335 |g|=0.429	lr=4.19e-04 | 99.3%@S28  T=1.07s eta=07:58:42 | 74.0K token/s | 
[epoch_0]_34179  loss=3.383876 |g|=0.456	lr=4.19e-04 | 100.0%@S28  T=1.10s eta=08:12:28 | 74.0K token/s | 
-------- End of shard_28@"./Datasets/edu_fineweb1B/edu_fineweb_train_000481.bin"-------- 
[shard-29]@"./Datasets/edu_fineweb1B/edu_fineweb_train_000482.bin": tokens=100(M) nShardSamples=1220(2832024) 
[epoch_0]_34181  loss=3.440145 |g|=0.435	lr=4.19e-04 | 0.1%@S29  T=1.14s eta=08:31:53 | 73.9K token/s | 
[epoch_0]_34191  loss=3.379451 |g|=0.395	lr=4.19e-04 | 0.9%@S29  T=1.08s eta=08:04:04 | 74.0K token/s | 
[Fuyou] head="5" update algorithm=4 t=2.16s
[eval] 
	 Loss@"edu_fineweb1B"=3.323(0.0019) nBranch=1 nToken=4.01M best=3.3249(169) E2T=0.00462 T=13.4854(0)s x=0
	#3.32304±0.1056 tps=298K(4.01408M) a=[3.14225,3.60762] T=13.4854(sec)
[Section@34200] layer[0-6] tasks=15(nPassBack=0) last_loss=3.31843(0.0696361) N=(580,29232,28812 3419900)
[epoch_0]_34201  loss=3.344166 |g|=0.405	lr=4.18e-04 | 1.8%@S29  T=4.18s eta=1d 07:11:34 | 71.3K token/s | 
[epoch_0]_34211  loss=3.349945 |g|=0.402	lr=4.18e-04 | 2.6%@S29  T=1.09s eta=08:07:26 | 71.5K token/s | 
[epoch_0]_34221  loss=3.365834 |g|=0.441	lr=4.18e-04 | 3.4%@S29  T=1.07s eta=07:56:57 | 71.7K token/s | 
[epoch_0]_34231  loss=3.356289 |g|=0.404	lr=4.18e-04 | 4.2%@S29  T=1.08s eta=08:03:44 | 71.9K token/s | 
[epoch_0]_34241  loss=3.315264 |g|=0.413	lr=4.17e-04 | 5.0%@S29  T=1.09s eta=08:04:35 | 72.1K token/s | 
[epoch_0]_34251  loss=3.329076 |g|=0.428	lr=4.17e-04 | 5.9%@S29  T=1.08s eta=08:00:25 | 72.3K token/s | 
[epoch_0]_34261  loss=3.331762 |g|=0.405	lr=4.17e-04 | 6.7%@S29  T=1.05s eta=07:47:20 | 72.6K token/s | 
[epoch_0]_34271  loss=3.377735 |g|=0.401	lr=4.17e-04 | 7.5%@S29  T=1.06s eta=07:51:51 | 72.9K token/s | 
[epoch_0]_34281  loss=3.334446 |g|=0.404	lr=4.16e-04 | 8.3%@S29  T=1.06s eta=07:53:41 | 73.1K token/s | 
[epoch_0]_34291  loss=3.341073 |g|=0.403	lr=4.16e-04 | 9.1%@S29  T=1.07s eta=07:54:49 | 73.3K token/s | 
[Fuyou] head="0" update algorithm=4 t=2.08s
[Section@34300] layer[6-12] tasks=15(nPassBack=0) last_loss=3.33564(0.0222771) N=(580,29316,28896 3429900)
[epoch_0]_34301  loss=3.274910 |g|=0.423	lr=4.16e-04 | 9.9%@S29  T=1.41s eta=10:26:06 | 72.5K token/s | 
[epoch_0]_34311  loss=3.334213 |g|=0.395	lr=4.16e-04 | 10.8%@S29  T=1.09s eta=08:06:36 | 72.6K token/s | 
[epoch_0]_34321  loss=3.301101 |g|=0.399	lr=4.15e-04 | 11.6%@S29  T=1.06s eta=07:52:33 | 72.9K token/s | 
[epoch_0]_34331  loss=3.307278 |g|=0.394	lr=4.15e-04 | 12.4%@S29  T=1.05s eta=07:47:51 | 73.1K token/s | 
[epoch_0]_34341  loss=3.445540 |g|=0.446	lr=4.15e-04 | 13.2%@S29  T=1.06s eta=07:53:44 | 73.3K token/s | 
[epoch_0]_34351  loss=3.280493 |g|=0.401	lr=4.15e-04 | 14.0%@S29  T=1.12s eta=08:16:16 | 73.3K token/s | 
[epoch_0]_34361  loss=3.353719 |g|=0.424	lr=4.14e-04 | 14.9%@S29  T=1.06s eta=07:49:46 | 73.5K token/s | 
[epoch_0]_34371  loss=3.290322 |g|=0.406	lr=4.14e-04 | 15.7%@S29  T=1.06s eta=07:49:00 | 73.7K token/s | 
[epoch_0]_34381  loss=3.255152 |g|=0.404	lr=4.14e-04 | 16.5%@S29  T=1.06s eta=07:49:35 | 73.9K token/s | 
[epoch_0]_34391  loss=3.277560 |g|=0.376	lr=4.14e-04 | 17.3%@S29  T=1.06s eta=07:52:27 | 74.1K token/s | 
[Fuyou] head="1" update algorithm=4 t=2.10s
[eval] 
	 Loss@"edu_fineweb1B"=3.320(0.0027) nBranch=1 nToken=4.01M best=3.3230(170) E2T=-0.089 T=13.4809(0)s x=0
	#3.32037±0.1058 tps=298K(4.01408M) a=[3.14247,3.60717] T=13.4809(sec)
[Section@34400] layer[12-18] tasks=15(nPassBack=0) last_loss=3.40934(-0.0109463) N=(580,29400,28980 3439900)
[epoch_0]_34401  loss=3.316986 |g|=0.389	lr=4.13e-04 | 18.1%@S29  T=4.18s eta=1d 06:55:56 | 71.3K token/s | 
[epoch_0]_34411  loss=3.341693 |g|=0.428	lr=4.13e-04 | 19.0%@S29  T=1.07s eta=07:53:03 | 71.6K token/s | 
[epoch_0]_34421  loss=3.285970 |g|=0.397	lr=4.13e-04 | 19.8%@S29  T=1.06s eta=07:51:11 | 71.9K token/s | 
[epoch_0]_34431  loss=3.391550 |g|=0.42	lr=4.13e-04 | 20.6%@S29  T=1.09s eta=08:02:07 | 72.1K token/s | 
[epoch_0]_34441  loss=3.242966 |g|=0.402	lr=4.12e-04 | 21.4%@S29  T=1.10s eta=08:06:21 | 72.2K token/s | 
[epoch_0]_34451  loss=3.350305 |g|=0.399	lr=4.12e-04 | 22.2%@S29  T=1.07s eta=07:52:25 | 72.4K token/s | 
[epoch_0]_34461  loss=3.256728 |g|=0.388	lr=4.12e-04 | 23.1%@S29  T=1.05s eta=07:43:43 | 72.7K token/s | 
[epoch_0]_34471  loss=3.400638 |g|=0.418	lr=4.12e-04 | 23.9%@S29  T=1.06s eta=07:48:35 | 73.0K token/s | 
[epoch_0]_34481  loss=3.320009 |g|=0.413	lr=4.11e-04 | 24.7%@S29  T=1.06s eta=07:47:11 | 73.2K token/s | 
[epoch_0]_34491  loss=3.334439 |g|=0.396	lr=4.11e-04 | 25.5%@S29  T=1.08s eta=07:59:55 | 73.3K token/s | 
[Fuyou] head="2" update algorithm=4 t=2.09s
[Section@34500] layer[18-24] tasks=15(nPassBack=0) last_loss=3.31652(0.0298738) N=(580,29484,29064 3449900)
[epoch_0]_34501  loss=3.331029 |g|=0.388	lr=4.11e-04 | 26.3%@S29  T=1.57s eta=11:34:20 | 72.2K token/s | 
[epoch_0]_34511  loss=3.307722 |g|=0.398	lr=4.11e-04 | 27.1%@S29  T=1.07s eta=07:51:54 | 72.5K token/s | 
[epoch_0]_34521  loss=3.348723 |g|=0.402	lr=4.10e-04 | 28.0%@S29  T=1.06s eta=07:47:40 | 72.7K token/s | 
[epoch_0]_34531  loss=3.307457 |g|=0.416	lr=4.10e-04 | 28.8%@S29  T=1.06s eta=07:49:04 | 72.9K token/s | 
[epoch_0]_34541  loss=3.278251 |g|=0.425	lr=4.10e-04 | 29.6%@S29  T=1.07s eta=07:52:59 | 73.1K token/s | 
[epoch_0]_34551  loss=3.317812 |g|=0.467	lr=4.10e-04 | 30.4%@S29  T=1.08s eta=07:58:13 | 73.2K token/s | 
[epoch_0]_34561  loss=3.334051 |g|=0.437	lr=4.09e-04 | 31.2%@S29  T=1.06s eta=07:46:28 | 73.5K token/s | 
[epoch_0]_34571  loss=3.286784 |g|=0.414	lr=4.09e-04 | 32.1%@S29  T=1.06s eta=07:47:51 | 73.6K token/s | 
[epoch_0]_34581  loss=3.272152 |g|=0.395	lr=4.09e-04 | 32.9%@S29  T=1.07s eta=07:51:58 | 73.8K token/s | 
[epoch_0]_34591  loss=3.360061 |g|=0.423	lr=4.09e-04 | 33.7%@S29  T=1.06s eta=07:48:45 | 73.9K token/s | 
[Fuyou] head="3" update algorithm=4 t=2.08s
[eval] 
	 Loss@"edu_fineweb1B"=3.322(-0.0012) nBranch=1 nToken=4.01M best=3.3204(171) E2T=-0.00207 T=13.4854(0)s x=0
	#3.32159±0.1065 tps=298K(4.01408M) a=[3.1417,3.60839] T=13.4854(sec)
[Section@34600] layer[24-30] tasks=15(nPassBack=0) last_loss=3.32366(0.0238752) N=(580,29568,29148 3459900)
[epoch_0]_34601  loss=3.320996 |g|=0.398	lr=4.08e-04 | 34.5%@S29  T=4.17s eta=1d 06:37:57 | 71.2K token/s | 
[epoch_0]_34611  loss=3.314147 |g|=0.465	lr=4.08e-04 | 35.3%@S29  T=1.09s eta=07:58:16 | 71.4K token/s | 
[epoch_0]_34621  loss=3.227897 |g|=0.413	lr=4.08e-04 | 36.2%@S29  T=1.05s eta=07:43:04 | 71.8K token/s | 
[epoch_0]_34631  loss=3.257658 |g|=0.388	lr=4.08e-04 | 37.0%@S29  T=1.07s eta=07:52:20 | 72.0K token/s | 
[epoch_0]_34641  loss=3.245029 |g|=0.409	lr=4.07e-04 | 37.8%@S29  T=1.09s eta=07:57:47 | 72.2K token/s | 
[epoch_0]_34651  loss=3.302584 |g|=0.394	lr=4.07e-04 | 38.6%@S29  T=1.10s eta=08:03:39 | 72.3K token/s | 
[epoch_0]_34661  loss=3.332865 |g|=0.379	lr=4.07e-04 | 39.4%@S29  T=1.05s eta=07:42:14 | 72.6K token/s | 
[epoch_0]_34671  loss=3.365721 |g|=0.408	lr=4.07e-04 | 40.3%@S29  T=1.05s eta=07:42:05 | 72.8K token/s | 
[epoch_0]_34681  loss=3.274719 |g|=0.387	lr=4.06e-04 | 41.1%@S29  T=1.06s eta=07:44:35 | 73.1K token/s | 
[epoch_0]_34691  loss=3.346649 |g|=0.403	lr=4.06e-04 | 41.9%@S29  T=1.07s eta=07:51:18 | 73.2K token/s | 
[Fuyou] head="4" update algorithm=4 t=2.07s
[Section@34700] layer[30-36] tasks=15(nPassBack=0) last_loss=3.33122(-0.0610127) N=(580,29652,29232 3469900)
[epoch_0]_34701  loss=3.262465 |g|=0.392	lr=4.06e-04 | 42.7%@S29  T=1.36s eta=09:55:36 | 72.6K token/s | 
[epoch_0]_34711  loss=3.381592 |g|=0.39	lr=4.05e-04 | 43.5%@S29  T=1.07s eta=07:48:01 | 72.8K token/s | 
[epoch_0]_34721  loss=3.213853 |g|=0.395	lr=4.05e-04 | 44.4%@S29  T=1.06s eta=07:44:54 | 73.0K token/s | 
[epoch_0]_34731  loss=3.329579 |g|=0.446	lr=4.05e-04 | 45.2%@S29  T=1.08s eta=07:51:43 | 73.2K token/s | 
[epoch_0]_34741  loss=3.307099 |g|=0.404	lr=4.05e-04 | 46.0%@S29  T=1.11s eta=08:04:31 | 73.2K token/s | 
[epoch_0]_34751  loss=3.389532 |g|=0.434	lr=4.04e-04 | 46.8%@S29  T=1.06s eta=07:43:58 | 73.4K token/s | 
[epoch_0]_34761  loss=3.303722 |g|=0.418	lr=4.04e-04 | 47.6%@S29  T=1.06s eta=07:45:42 | 73.6K token/s | 
[epoch_0]_34771  loss=3.290309 |g|=0.426	lr=4.04e-04 | 48.4%@S29  T=1.06s eta=07:42:47 | 73.8K token/s | 
[epoch_0]_34781  loss=3.290992 |g|=0.391	lr=4.04e-04 | 49.3%@S29  T=1.07s eta=07:49:00 | 73.9K token/s | 
[epoch_0]_34791  loss=3.298441 |g|=0.415	lr=4.03e-04 | 50.1%@S29  T=1.07s eta=07:50:03 | 74.0K token/s | 
[Fuyou] head="5" update algorithm=4 t=2.08s
[eval] 
	 Loss@"edu_fineweb1B"=3.319(0.0022) nBranch=1 nToken=4.01M best=3.3216(172) E2T=0.0476 T=13.49(0)s x=0
	#3.31942±0.1065 tps=298K(4.01408M) a=[3.13366,3.60977] T=13.49(sec)
[Section@34800] layer[0-6] tasks=15(nPassBack=0) last_loss=3.27186(0.0465667) N=(580,29736,29316 3479900)
[epoch_0]_34801  loss=3.345377 |g|=0.405	lr=4.03e-04 | 50.9%@S29  T=4.20s eta=1d 06:36:08 | 71.3K token/s | 
[epoch_0]_34811  loss=3.263628 |g|=0.396	lr=4.03e-04 | 51.7%@S29  T=1.05s eta=07:40:37 | 71.6K token/s | 
[epoch_0]_34821  loss=3.362165 |g|=0.419	lr=4.03e-04 | 52.5%@S29  T=1.06s eta=07:44:47 | 71.9K token/s | 
[epoch_0]_34831  loss=3.338229 |g|=0.434	lr=4.02e-04 | 53.4%@S29  T=1.08s eta=07:50:41 | 72.1K token/s | 
[epoch_0]_34841  loss=3.279440 |g|=0.424	lr=4.02e-04 | 54.2%@S29  T=1.10s eta=08:01:13 | 72.2K token/s | 
[epoch_0]_34851  loss=3.325613 |g|=0.435	lr=4.02e-04 | 55.0%@S29  T=1.06s eta=07:41:09 | 72.5K token/s | 
[epoch_0]_34861  loss=3.348871 |g|=0.421	lr=4.02e-04 | 55.8%@S29  T=1.06s eta=07:41:38 | 72.7K token/s | 
[epoch_0]_34871  loss=3.264131 |g|=0.389	lr=4.01e-04 | 56.6%@S29  T=1.05s eta=07:39:43 | 73.0K token/s | 
[epoch_0]_34881  loss=3.261911 |g|=0.396	lr=4.01e-04 | 57.5%@S29  T=1.06s eta=07:43:13 | 73.2K token/s | 
[epoch_0]_34891  loss=3.282812 |g|=0.415	lr=4.01e-04 | 58.3%@S29  T=1.05s eta=07:38:32 | 73.4K token/s | 
[Fuyou] head="0" update algorithm=4 t=2.07s
[Section@34900] layer[6-12] tasks=15(nPassBack=0) last_loss=3.25499(0.0806496) N=(580,29820,29400 3489900)
[epoch_0]_34901  loss=3.324554 |g|=0.423	lr=4.01e-04 | 59.1%@S29  T=1.47s eta=10:39:46 | 72.5K token/s | 
[epoch_0]_34911  loss=3.360184 |g|=0.437	lr=4.00e-04 | 59.9%@S29  T=1.08s eta=07:49:05 | 72.7K token/s | 
[epoch_0]_34921  loss=3.257099 |g|=0.421	lr=4.00e-04 | 60.7%@S29  T=1.06s eta=07:41:01 | 72.9K token/s | 
[epoch_0]_34931  loss=3.338180 |g|=0.417	lr=4.00e-04 | 61.6%@S29  T=1.07s eta=07:46:28 | 73.1K token/s | 
[epoch_0]_34941  loss=3.264932 |g|=0.439	lr=4.00e-04 | 62.4%@S29  T=1.07s eta=07:43:16 | 73.3K token/s | 
[epoch_0]_34951  loss=3.336874 |g|=0.423	lr=3.99e-04 | 63.2%@S29  T=1.07s eta=07:44:01 | 73.5K token/s | 
[epoch_0]_34961  loss=3.329249 |g|=0.414	lr=3.99e-04 | 64.0%@S29  T=1.09s eta=07:55:24 | 73.5K token/s | 
[epoch_0]_34971  loss=3.296959 |g|=0.394	lr=3.99e-04 | 64.8%@S29  T=1.10s eta=07:57:21 | 73.6K token/s | 
[epoch_0]_34981  loss=3.307019 |g|=0.407	lr=3.99e-04 | 65.7%@S29  T=1.06s eta=07:39:34 | 73.8K token/s | 
[epoch_0]_34991  loss=3.294437 |g|=0.412	lr=3.98e-04 | 66.5%@S29  T=1.06s eta=07:42:13 | 73.9K token/s | 
[Fuyou] head="1" update algorithm=4 t=2.11s
[eval] 
	 Loss@"edu_fineweb1B"=3.318(0.0012) nBranch=1 nToken=4.01M best=3.3194(173) E2T=-0.0362 T=13.4869(0)s x=0
	#3.3182±0.1069 tps=298K(4.01408M) a=[3.12601,3.60587] T=13.4869(sec)
[Section@35000] layer[12-18] tasks=15(nPassBack=0) last_loss=3.3544(0.0549462) N=(580,29904,29484 3499900)
[epoch_0]_35001  loss=3.315842 |g|=0.393	lr=3.98e-04 | 67.3%@S29  T=4.21s eta=1d 06:26:17 | 71.2K token/s | 
[epoch_0]_35011  loss=3.312894 |g|=0.439	lr=3.98e-04 | 68.1%@S29  T=1.08s eta=07:50:13 | 71.4K token/s | 
[epoch_0]_35021  loss=3.412956 |g|=0.424	lr=3.98e-04 | 68.9%@S29  T=1.08s eta=07:47:34 | 71.7K token/s | 
[epoch_0]_35031  loss=3.381009 |g|=0.432	lr=3.97e-04 | 69.7%@S29  T=1.07s eta=07:45:21 | 71.9K token/s | 
[epoch_0]_35041  loss=3.241785 |g|=0.407	lr=3.97e-04 | 70.6%@S29  T=1.08s eta=07:47:32 | 72.1K token/s | 
[epoch_0]_35051  loss=3.282987 |g|=0.446	lr=3.97e-04 | 71.4%@S29  T=1.09s eta=07:53:18 | 72.2K token/s | 
[epoch_0]_35061  loss=3.269855 |g|=0.401	lr=3.97e-04 | 72.2%@S29  T=1.06s eta=07:38:56 | 72.5K token/s | 
[epoch_0]_35071  loss=3.350725 |g|=0.426	lr=3.96e-04 | 73.0%@S29  T=1.05s eta=07:36:27 | 72.7K token/s | 
[epoch_0]_35081  loss=3.280065 |g|=0.393	lr=3.96e-04 | 73.8%@S29  T=1.06s eta=07:40:10 | 73.0K token/s | 
[epoch_0]_35091  loss=3.312457 |g|=0.386	lr=3.96e-04 | 74.7%@S29  T=1.05s eta=07:36:07 | 73.2K token/s | 
[Fuyou] head="2" update algorithm=4 t=2.16s
[Section@35100] layer[18-24] tasks=15(nPassBack=0) last_loss=3.29866(0.017859) N=(580,29988,29568 3509900)
[epoch_0]_35101  loss=3.308408 |g|=0.415	lr=3.96e-04 | 75.5%@S29  T=1.42s eta=10:14:57 | 72.4K token/s | 
[epoch_0]_35111  loss=3.270025 |g|=0.402	lr=3.95e-04 | 76.3%@S29  T=1.06s eta=07:36:26 | 72.7K token/s | 
[epoch_0]_35121  loss=3.313191 |g|=0.415	lr=3.95e-04 | 77.1%@S29  T=1.06s eta=07:36:40 | 72.9K token/s | 
[epoch_0]_35131  loss=3.230769 |g|=0.441	lr=3.95e-04 | 77.9%@S29  T=1.06s eta=07:37:31 | 73.1K token/s | 
[epoch_0]_35141  loss=3.330233 |g|=0.418	lr=3.95e-04 | 78.8%@S29  T=1.06s eta=07:38:25 | 73.3K token/s | 
[epoch_0]_35151  loss=3.298669 |g|=0.425	lr=3.94e-04 | 79.6%@S29  T=1.06s eta=07:38:32 | 73.5K token/s | 
[epoch_0]_35161  loss=3.307938 |g|=0.417	lr=3.94e-04 | 80.4%@S29  T=1.06s eta=07:37:36 | 73.7K token/s | 
[epoch_0]_35171  loss=3.259008 |g|=0.422	lr=3.94e-04 | 81.2%@S29  T=1.11s eta=07:59:16 | 73.7K token/s | 
[epoch_0]_35181  loss=3.312418 |g|=0.416	lr=3.94e-04 | 82.0%@S29  T=1.09s eta=07:50:19 | 73.8K token/s | 
[epoch_0]_35191  loss=3.180948 |g|=0.413	lr=3.93e-04 | 82.9%@S29  T=1.05s eta=07:31:50 | 74.0K token/s | 
[Fuyou] head="3" update algorithm=4 t=2.10s
[eval] 
	 Loss@"edu_fineweb1B"=3.317(0.0011) nBranch=1 nToken=4.01M best=3.3182(174) E2T=-0.0168 T=13.4875(0)s x=0
	#3.31706±0.1075 tps=298K(4.01408M) a=[3.13086,3.60949] T=13.4875(sec)
[Section@35200] layer[24-30] tasks=15(nPassBack=0) last_loss=3.33386(-0.0102079) N=(580,30072,29652 3519900)
[epoch_0]_35201  loss=3.278794 |g|=0.384	lr=3.93e-04 | 83.7%@S29  T=4.20s eta=1d 06:06:23 | 71.3K token/s | 
[epoch_0]_35211  loss=3.242191 |g|=0.394	lr=3.93e-04 | 84.5%@S29  T=1.05s eta=07:33:42 | 71.6K token/s | 
[epoch_0]_35221  loss=3.362323 |g|=0.387	lr=3.93e-04 | 85.3%@S29  T=1.06s eta=07:36:54 | 71.9K token/s | 
[epoch_0]_35231  loss=3.281711 |g|=0.411	lr=3.92e-04 | 86.1%@S29  T=1.11s eta=07:59:20 | 71.9K token/s | 
[epoch_0]_35241  loss=3.392860 |g|=0.428	lr=3.92e-04 | 87.0%@S29  T=1.07s eta=07:38:27 | 72.2K token/s | 
[epoch_0]_35251  loss=3.323557 |g|=0.377	lr=3.92e-04 | 87.8%@S29  T=1.06s eta=07:36:25 | 72.4K token/s | 
[epoch_0]_35261  loss=3.268232 |g|=0.416	lr=3.92e-04 | 88.6%@S29  T=1.07s eta=07:37:30 | 72.7K token/s | 
[epoch_0]_35271  loss=3.299013 |g|=0.409	lr=3.91e-04 | 89.4%@S29  T=1.06s eta=07:36:15 | 72.9K token/s | 
[epoch_0]_35281  loss=3.268875 |g|=0.403	lr=3.91e-04 | 90.2%@S29  T=1.10s eta=07:51:01 | 73.0K token/s | 
[epoch_0]_35291  loss=3.353988 |g|=0.444	lr=3.91e-04 | 91.0%@S29  T=1.11s eta=07:54:21 | 73.0K token/s | 
[Fuyou] head="4" update algorithm=4 t=2.01s
[Section@35300] layer[30-36] tasks=15(nPassBack=0) last_loss=3.33603(-0.00480747) N=(580,30156,29736 3529900)
[epoch_0]_35301  loss=3.324266 |g|=0.421	lr=3.91e-04 | 91.9%@S29  T=1.42s eta=10:06:55 | 72.3K token/s | 
[epoch_0]_35311  loss=3.280134 |g|=0.43	lr=3.90e-04 | 92.7%@S29  T=1.06s eta=07:36:07 | 72.5K token/s | 
[epoch_0]_35321  loss=3.297718 |g|=0.432	lr=3.90e-04 | 93.5%@S29  T=1.07s eta=07:37:10 | 72.7K token/s | 
[epoch_0]_35331  loss=3.315961 |g|=0.412	lr=3.90e-04 | 94.3%@S29  T=1.07s eta=07:40:27 | 72.9K token/s | 
[epoch_0]_35341  loss=3.394241 |g|=0.436	lr=3.90e-04 | 95.1%@S29  T=1.08s eta=07:44:06 | 73.0K token/s | 
[epoch_0]_35351  loss=3.207256 |g|=0.382	lr=3.89e-04 | 96.0%@S29  T=1.10s eta=07:50:51 | 73.1K token/s | 
[epoch_0]_35361  loss=3.233150 |g|=0.394	lr=3.89e-04 | 96.8%@S29  T=1.09s eta=07:47:33 | 73.2K token/s | 
[epoch_0]_35371  loss=3.321332 |g|=0.425	lr=3.89e-04 | 97.6%@S29  T=1.04s eta=07:25:22 | 73.5K token/s | 
[epoch_0]_35381  loss=3.306253 |g|=0.438	lr=3.89e-04 | 98.4%@S29  T=1.06s eta=07:32:28 | 73.7K token/s | 
[epoch_0]_35391  loss=3.286558 |g|=0.408	lr=3.88e-04 | 99.2%@S29  T=1.07s eta=07:35:11 | 73.8K token/s | 
[Fuyou] head="5" update algorithm=4 t=2.08s
[eval] 
	 Loss@"edu_fineweb1B"=3.315(0.0021) nBranch=1 nToken=4.01M best=3.3171(175) E2T=0.0552 T=13.4853(0)s x=0
	#3.31492±0.1071 tps=298K(4.01408M) a=[3.13046,3.60543] T=13.4853(sec)
[Section@35400] layer[0-6] tasks=15(nPassBack=0) last_loss=3.25972(0.0121379) N=(580,30240,29820 3539900)
[epoch_0]_35400  loss=3.250937 |g|=0.438	lr=3.88e-04 | 100.0%@S29  T=11.51s eta=3d 09:58:21 | 70.5K token/s | 
-------- End of shard_29@"./Datasets/edu_fineweb1B/edu_fineweb_train_000482.bin"-------- 
[shard-30]@"./Datasets/edu_fineweb1B/edu_fineweb_train_000483.bin": tokens=100(M) nShardSamples=1220(2929680) 
[epoch_0]_35401  loss=3.317507 |g|=0.392	lr=3.88e-04 | 0.1%@S30  T=4.50s eta=1d 08:00:53 | 67.9K token/s | 
[epoch_0]_35411  loss=3.290088 |g|=0.394	lr=3.88e-04 | 0.9%@S30  T=1.09s eta=07:46:53 | 68.2K token/s | 
[epoch_0]_35421  loss=3.372776 |g|=0.418	lr=3.88e-04 | 1.7%@S30  T=1.06s eta=07:30:38 | 68.7K token/s | 
[epoch_0]_35431  loss=3.388879 |g|=0.457	lr=3.87e-04 | 2.5%@S30  T=1.06s eta=07:32:06 | 69.1K token/s | 
[epoch_0]_35441  loss=3.291633 |g|=0.422	lr=3.87e-04 | 3.3%@S30  T=1.12s eta=07:56:06 | 69.3K token/s | 
[epoch_0]_35451  loss=3.321003 |g|=0.414	lr=3.87e-04 | 4.2%@S30  T=1.09s eta=07:45:59 | 69.6K token/s | 
[epoch_0]_35461  loss=3.313508 |g|=0.395	lr=3.87e-04 | 5.0%@S30  T=1.06s eta=07:33:09 | 70.0K token/s | 
[epoch_0]_35471  loss=3.300626 |g|=0.456	lr=3.86e-04 | 5.8%@S30  T=1.06s eta=07:32:07 | 70.4K token/s | 
[epoch_0]_35481  loss=3.334828 |g|=0.414	lr=3.86e-04 | 6.6%@S30  T=1.07s eta=07:35:34 | 70.7K token/s | 
[epoch_0]_35491  loss=3.349363 |g|=0.417	lr=3.86e-04 | 7.4%@S30  T=1.07s eta=07:33:40 | 71.0K token/s | 
[Fuyou] head="0" update algorithm=4 t=2.01s
[Section@35500] layer[6-12] tasks=15(nPassBack=0) last_loss=3.39705(-0.142057) N=(580,30324,29904 3549900)
[epoch_0]_35501  loss=3.281202 |g|=0.406	lr=3.86e-04 | 8.3%@S30  T=1.55s eta=10:59:09 | 70.1K token/s | 
[epoch_0]_35511  loss=3.303661 |g|=0.405	lr=3.85e-04 | 9.1%@S30  T=1.04s eta=07:23:12 | 70.5K token/s | 
[epoch_0]_35521  loss=3.315270 |g|=0.402	lr=3.85e-04 | 9.9%@S30  T=1.05s eta=07:27:04 | 70.9K token/s | 
[epoch_0]_35531  loss=3.263035 |g|=0.39	lr=3.85e-04 | 10.7%@S30  T=1.05s eta=07:27:48 | 71.2K token/s | 
[epoch_0]_35541  loss=3.252326 |g|=0.427	lr=3.85e-04 | 11.5%@S30  T=1.06s eta=07:30:30 | 71.5K token/s | 
[epoch_0]_35551  loss=3.289914 |g|=0.389	lr=3.84e-04 | 12.3%@S30  T=1.08s eta=07:38:16 | 71.7K token/s | 
[epoch_0]_35561  loss=3.362335 |g|=0.417	lr=3.84e-04 | 13.2%@S30  T=1.09s eta=07:42:00 | 71.9K token/s | 
[epoch_0]_35571  loss=3.340341 |g|=0.431	lr=3.84e-04 | 14.0%@S30  T=1.11s eta=07:49:10 | 72.0K token/s | 
[epoch_0]_35581  loss=3.331377 |g|=0.433	lr=3.84e-04 | 14.8%@S30  T=1.06s eta=07:27:38 | 72.3K token/s | 
[epoch_0]_35591  loss=3.360737 |g|=0.409	lr=3.83e-04 | 15.6%@S30  T=1.05s eta=07:24:48 | 72.6K token/s | 
[Fuyou] head="1" update algorithm=4 t=2.07s
[eval] 
	 Loss@"edu_fineweb1B"=3.308(0.007) nBranch=1 nToken=4.01M best=3.3149(176) E2T=-0.0181 T=13.4867(0)s x=0
	#3.30792±0.1067 tps=298K(4.01408M) a=[3.11803,3.5957] T=13.4867(sec)
[Section@35600] layer[12-18] tasks=15(nPassBack=0) last_loss=3.32597(0.0284212) N=(580,30408,29988 3559900)
[epoch_0]_35601  loss=3.324021 |g|=0.387	lr=3.83e-04 | 16.4%@S30  T=4.23s eta=1d 05:52:27 | 69.9K token/s | 
[epoch_0]_35611  loss=3.393019 |g|=0.421	lr=3.83e-04 | 17.3%@S30  T=1.13s eta=07:58:46 | 70.1K token/s | 
[epoch_0]_35621  loss=3.300469 |g|=0.43	lr=3.83e-04 | 18.1%@S30  T=1.07s eta=07:31:34 | 70.4K token/s | 
[epoch_0]_35631  loss=3.348332 |g|=0.413	lr=3.82e-04 | 18.9%@S30  T=1.06s eta=07:30:29 | 70.7K token/s | 
[epoch_0]_35641  loss=3.303164 |g|=0.429	lr=3.82e-04 | 19.7%@S30  T=1.09s eta=07:39:45 | 71.0K token/s | 
[epoch_0]_35651  loss=3.321165 |g|=0.411	lr=3.82e-04 | 20.5%@S30  T=1.13s eta=07:59:37 | 71.0K token/s | 
[epoch_0]_35661  loss=3.303889 |g|=0.401	lr=3.82e-04 | 21.4%@S30  T=1.10s eta=07:45:42 | 71.2K token/s | 
[epoch_0]_35671  loss=3.322851 |g|=0.412	lr=3.81e-04 | 22.2%@S30  T=1.06s eta=07:27:55 | 71.5K token/s | 
[epoch_0]_35681  loss=3.307698 |g|=0.436	lr=3.81e-04 | 23.0%@S30  T=1.06s eta=07:28:15 | 71.8K token/s | 
[epoch_0]_35691  loss=3.352477 |g|=0.417	lr=3.81e-04 | 23.8%@S30  T=1.06s eta=07:28:01 | 72.1K token/s | 
[Fuyou] head="2" update algorithm=4 t=2.07s
[Section@35700] layer[18-24] tasks=15(nPassBack=0) last_loss=3.36524(-0.066581) N=(580,30492,30072 3569900)
[epoch_0]_35701  loss=3.300827 |g|=0.408	lr=3.81e-04 | 24.6%@S30  T=1.52s eta=10:42:46 | 71.1K token/s | 
[epoch_0]_35711  loss=3.243992 |g|=0.422	lr=3.80e-04 | 25.5%@S30  T=1.05s eta=07:22:35 | 71.5K token/s | 
[epoch_0]_35721  loss=3.365297 |g|=0.428	lr=3.80e-04 | 26.3%@S30  T=1.05s eta=07:24:49 | 71.8K token/s | 
[epoch_0]_35731  loss=3.353396 |g|=0.438	lr=3.80e-04 | 27.1%@S30  T=1.07s eta=07:30:35 | 72.1K token/s | 
[epoch_0]_35741  loss=3.336462 |g|=0.423	lr=3.80e-04 | 27.9%@S30  T=1.07s eta=07:30:01 | 72.3K token/s | 
[epoch_0]_35751  loss=3.241402 |g|=0.398	lr=3.79e-04 | 28.7%@S30  T=1.06s eta=07:28:07 | 72.5K token/s | 
[epoch_0]_35761  loss=3.345489 |g|=0.429	lr=3.79e-04 | 29.5%@S30  T=1.09s eta=07:41:03 | 72.6K token/s | 
[epoch_0]_35771  loss=3.319398 |g|=0.389	lr=3.79e-04 | 30.4%@S30  T=1.10s eta=07:41:13 | 72.7K token/s | 
[epoch_0]_35781  loss=3.285702 |g|=0.435	lr=3.79e-04 | 31.2%@S30  T=1.06s eta=07:24:51 | 73.0K token/s | 
[epoch_0]_35791  loss=3.282509 |g|=0.438	lr=3.78e-04 | 32.0%@S30  T=1.08s eta=07:34:36 | 73.1K token/s | 
[Fuyou] head="3" update algorithm=4 t=2.10s
[eval] 
	 Loss@"edu_fineweb1B"=3.305(0.0024) nBranch=1 nToken=4.01M best=3.3079(177) E2T=0.074 T=13.4954(0)s x=0
	#3.30549±0.1068 tps=297K(4.01408M) a=[3.12458,3.59345] T=13.4954(sec)
[Section@35800] layer[24-30] tasks=15(nPassBack=0) last_loss=3.23144(0.102425) N=(580,30576,30156 3579900)
[epoch_0]_35801  loss=3.246392 |g|=0.425	lr=3.78e-04 | 32.8%@S30  T=4.22s eta=1d 05:32:44 | 70.4K token/s | 
[epoch_0]_35811  loss=3.338478 |g|=0.398	lr=3.78e-04 | 33.6%@S30  T=1.09s eta=07:38:51 | 70.7K token/s | 
[epoch_0]_35821  loss=3.341480 |g|=0.428	lr=3.78e-04 | 34.5%@S30  T=1.08s eta=07:31:52 | 70.9K token/s | 
[epoch_0]_35831  loss=3.275304 |g|=0.437	lr=3.77e-04 | 35.3%@S30  T=1.07s eta=07:29:43 | 71.2K token/s | 
[epoch_0]_35841  loss=3.345828 |g|=0.438	lr=3.77e-04 | 36.1%@S30  T=1.07s eta=07:27:32 | 71.5K token/s | 
[epoch_0]_35851  loss=3.292884 |g|=0.409	lr=3.77e-04 | 36.9%@S30  T=1.09s eta=07:38:02 | 71.7K token/s | 
[epoch_0]_35861  loss=3.333579 |g|=0.438	lr=3.77e-04 | 37.7%@S30  T=1.11s eta=07:46:48 | 71.8K token/s | 
[epoch_0]_35871  loss=3.198482 |g|=0.454	lr=3.76e-04 | 38.6%@S30  T=1.10s eta=07:40:53 | 71.9K token/s | 
[epoch_0]_35881  loss=3.287474 |g|=0.408	lr=3.76e-04 | 39.4%@S30  T=1.06s eta=07:26:25 | 72.2K token/s | 
[epoch_0]_35891  loss=3.226462 |g|=0.401	lr=3.76e-04 | 40.2%@S30  T=1.07s eta=07:29:10 | 72.4K token/s | 
[Fuyou] head="4" update algorithm=4 t=2.08s
[Section@35900] layer[30-36] tasks=15(nPassBack=0) last_loss=3.36907(-0.0330465) N=(580,30660,30240 3589900)
[epoch_0]_35901  loss=3.391770 |g|=0.398	lr=3.76e-04 | 41.0%@S30  T=1.74s eta=12:07:39 | 71.1K token/s | 
[epoch_0]_35911  loss=3.332118 |g|=0.404	lr=3.75e-04 | 41.8%@S30  T=1.05s eta=07:21:00 | 71.5K token/s | 
[epoch_0]_35921  loss=3.354395 |g|=0.409	lr=3.75e-04 | 42.7%@S30  T=1.09s eta=07:35:38 | 71.6K token/s | 
[epoch_0]_35931  loss=3.294266 |g|=0.395	lr=3.75e-04 | 43.5%@S30  T=1.11s eta=07:45:30 | 71.7K token/s | 
[epoch_0]_35941  loss=3.270638 |g|=0.452	lr=3.75e-04 | 44.3%@S30  T=1.10s eta=07:38:34 | 71.9K token/s | 
[epoch_0]_35951  loss=3.300977 |g|=0.405	lr=3.74e-04 | 45.1%@S30  T=1.08s eta=07:29:34 | 72.1K token/s | 
[epoch_0]_35961  loss=3.308879 |g|=0.428	lr=3.74e-04 | 45.9%@S30  T=1.06s eta=07:24:23 | 72.4K token/s | 
[epoch_0]_35971  loss=3.313302 |g|=0.42	lr=3.74e-04 | 46.8%@S30  T=1.07s eta=07:27:46 | 72.6K token/s | 
[epoch_0]_35981  loss=3.279561 |g|=0.397	lr=3.74e-04 | 47.6%@S30  T=1.07s eta=07:28:15 | 72.7K token/s | 
[epoch_0]_35991  loss=3.324071 |g|=0.409	lr=3.73e-04 | 48.4%@S30  T=1.08s eta=07:32:49 | 72.9K token/s | 
[Fuyou] head="5" update algorithm=4 t=2.10s
[eval] 
	 Loss@"edu_fineweb1B"=3.304(0.0018) nBranch=1 nToken=4.01M best=3.3055(178) E2T=0.00597 T=13.4961(0)s x=0
	#3.30367±0.1065 tps=297K(4.01408M) a=[3.11703,3.59298] T=13.4961(sec)
[Section@36000] layer[0-6] tasks=15(nPassBack=0) last_loss=3.2977(-0.0379732) N=(580,30744,30324 3599900)
[epoch_0]_36001  loss=3.321609 |g|=0.415	lr=3.73e-04 | 49.2%@S30  T=4.21s eta=1d 05:15:43 | 70.2K token/s | 
[epoch_0]_36011  loss=3.322806 |g|=0.425	lr=3.73e-04 | 50.0%@S30  T=1.11s eta=07:42:42 | 70.4K token/s | 
[epoch_0]_36021  loss=3.305009 |g|=0.406	lr=3.73e-04 | 50.8%@S30  T=1.07s eta=07:27:41 | 70.7K token/s | 
[epoch_0]_36031  loss=3.346085 |g|=0.46	lr=3.72e-04 | 51.7%@S30  T=1.08s eta=07:28:13 | 71.0K token/s | 
[epoch_0]_36041  loss=3.276548 |g|=0.46	lr=3.72e-04 | 52.5%@S30  T=1.10s eta=07:39:16 | 71.1K token/s | 
[epoch_0]_36051  loss=3.321264 |g|=0.44	lr=3.72e-04 | 53.3%@S30  T=1.09s eta=07:35:30 | 71.3K token/s | 
[epoch_0]_36061  loss=3.341575 |g|=0.467	lr=3.72e-04 | 54.1%@S30  T=1.09s eta=07:31:55 | 71.5K token/s | 
[epoch_0]_36071  loss=3.304559 |g|=0.401	lr=3.71e-04 | 54.9%@S30  T=1.08s eta=07:28:07 | 71.8K token/s | 
[epoch_0]_36081  loss=3.375278 |g|=0.428	lr=3.71e-04 | 55.8%@S30  T=1.07s eta=07:26:05 | 72.0K token/s | 
[epoch_0]_36091  loss=3.329704 |g|=0.435	lr=3.71e-04 | 56.6%@S30  T=1.09s eta=07:34:35 | 72.1K token/s | 
[Fuyou] head="0" update algorithm=4 t=2.09s
[Section@36100] layer[6-12] tasks=15(nPassBack=0) last_loss=3.31427(0.0827768) N=(580,30828,30408 3609900)
[epoch_0]_36101  loss=3.273246 |g|=0.405	lr=3.71e-04 | 57.4%@S30  T=1.36s eta=09:25:00 | 71.5K token/s | 
[epoch_0]_36111  loss=3.350500 |g|=0.422	lr=3.71e-04 | 58.2%@S30  T=1.06s eta=07:21:55 | 71.8K token/s | 
[epoch_0]_36121  loss=3.304633 |g|=0.408	lr=3.70e-04 | 59.0%@S30  T=1.07s eta=07:24:09 | 72.0K token/s | 
[epoch_0]_36131  loss=3.352867 |g|=0.428	lr=3.70e-04 | 59.9%@S30  T=1.07s eta=07:25:25 | 72.3K token/s | 
[epoch_0]_36141  loss=3.312128 |g|=0.432	lr=3.70e-04 | 60.7%@S30  T=1.06s eta=07:19:03 | 72.5K token/s | 
[epoch_0]_36151  loss=3.249072 |g|=0.411	lr=3.70e-04 | 61.5%@S30  T=1.08s eta=07:26:03 | 72.7K token/s | 
[epoch_0]_36161  loss=3.301140 |g|=0.43	lr=3.69e-04 | 62.3%@S30  T=1.09s eta=07:32:30 | 72.8K token/s | 
[epoch_0]_36171  loss=3.255808 |g|=0.422	lr=3.69e-04 | 63.1%@S30  T=1.12s eta=07:43:13 | 72.8K token/s | 
[epoch_0]_36181  loss=3.243542 |g|=0.424	lr=3.69e-04 | 64.0%@S30  T=1.06s eta=07:17:37 | 73.1K token/s | 
[epoch_0]_36191  loss=3.341771 |g|=0.433	lr=3.69e-04 | 64.8%@S30  T=1.05s eta=07:15:39 | 73.3K token/s | 
[Fuyou] head="1" update algorithm=4 t=2.07s
[eval] 
	 Loss@"edu_fineweb1B"=3.302(0.0017) nBranch=1 nToken=4.01M best=3.3037(179) E2T=-0.0671 T=13.4919(0)s x=0
	#3.302±0.1068 tps=298K(4.01408M) a=[3.11738,3.58791] T=13.4919(sec)
[Section@36200] layer[12-18] tasks=15(nPassBack=0) last_loss=3.36911(-0.0431361) N=(580,30912,30492 3619900)
[epoch_0]_36201  loss=3.347015 |g|=0.43	lr=3.68e-04 | 65.6%@S30  T=4.24s eta=1d 05:14:04 | 70.6K token/s | 
[epoch_0]_36211  loss=3.234109 |g|=0.407	lr=3.68e-04 | 66.4%@S30  T=1.06s eta=07:20:05 | 70.9K token/s | 
[epoch_0]_36221  loss=3.257045 |g|=0.406	lr=3.68e-04 | 67.2%@S30  T=1.05s eta=07:15:43 | 71.3K token/s | 
[epoch_0]_36231  loss=3.294999 |g|=0.423	lr=3.68e-04 | 68.1%@S30  T=1.06s eta=07:18:41 | 71.6K token/s | 
[epoch_0]_36241  loss=3.243580 |g|=0.435	lr=3.67e-04 | 68.9%@S30  T=1.06s eta=07:18:42 | 71.9K token/s | 
[epoch_0]_36251  loss=3.364361 |g|=0.396	lr=3.67e-04 | 69.7%@S30  T=1.06s eta=07:16:03 | 72.1K token/s | 
[epoch_0]_36261  loss=3.318249 |g|=0.436	lr=3.67e-04 | 70.5%@S30  T=1.10s eta=07:33:16 | 72.3K token/s | 
[epoch_0]_36271  loss=3.252206 |g|=0.43	lr=3.67e-04 | 71.3%@S30  T=1.08s eta=07:27:41 | 72.4K token/s | 
[epoch_0]_36281  loss=3.316000 |g|=0.42	lr=3.66e-04 | 72.1%@S30  T=1.06s eta=07:17:43 | 72.7K token/s | 
[epoch_0]_36291  loss=3.376292 |g|=0.455	lr=3.66e-04 | 73.0%@S30  T=1.06s eta=07:18:34 | 72.9K token/s | 
[Fuyou] head="2" update algorithm=4 t=2.10s
[Section@36300] layer[18-24] tasks=15(nPassBack=0) last_loss=3.30883(0.0564103) N=(580,30996,30576 3629900)
[epoch_0]_36301  loss=3.348712 |g|=0.398	lr=3.66e-04 | 73.8%@S30  T=1.40s eta=09:38:11 | 72.2K token/s | 
[epoch_0]_36311  loss=3.296844 |g|=0.418	lr=3.66e-04 | 74.6%@S30  T=1.08s eta=07:23:50 | 72.4K token/s | 
[epoch_0]_36321  loss=3.327296 |g|=0.404	lr=3.65e-04 | 75.4%@S30  T=1.09s eta=07:30:30 | 72.5K token/s | 
[epoch_0]_36331  loss=3.323116 |g|=0.401	lr=3.65e-04 | 76.2%@S30  T=1.07s eta=07:18:57 | 72.7K token/s | 
[epoch_0]_36341  loss=3.297065 |g|=0.414	lr=3.65e-04 | 77.1%@S30  T=1.06s eta=07:17:28 | 72.9K token/s | 
[epoch_0]_36351  loss=3.300465 |g|=0.423	lr=3.65e-04 | 77.9%@S30  T=1.07s eta=07:18:35 | 73.1K token/s | 
[epoch_0]_36361  loss=3.310072 |g|=0.411	lr=3.64e-04 | 78.7%@S30  T=1.08s eta=07:22:44 | 73.3K token/s | 
[epoch_0]_36371  loss=3.349524 |g|=0.428	lr=3.64e-04 | 79.5%@S30  T=1.09s eta=07:28:49 | 73.4K token/s | 
[epoch_0]_36381  loss=3.343860 |g|=0.434	lr=3.64e-04 | 80.3%@S30  T=1.09s eta=07:28:56 | 73.4K token/s | 
[epoch_0]_36391  loss=3.412738 |g|=0.421	lr=3.64e-04 | 81.2%@S30  T=1.04s eta=07:07:53 | 73.7K token/s | 
[Fuyou] head="3" update algorithm=4 t=2.00s
[eval] 
	 Loss@"edu_fineweb1B"=3.301(0.0013) nBranch=1 nToken=4.01M best=3.3020(180) E2T=0.0466 T=13.4866(0)s x=0
	#3.30072±0.1074 tps=298K(4.01408M) a=[3.11494,3.58795] T=13.4866(sec)
[Section@36400] layer[24-30] tasks=15(nPassBack=0) last_loss=3.25407(-0.0226345) N=(580,31080,30660 3639900)
[epoch_0]_36401  loss=3.323917 |g|=0.419	lr=3.63e-04 | 82.0%@S30  T=4.19s eta=1d 04:38:53 | 71.0K token/s | 
[epoch_0]_36411  loss=3.309846 |g|=0.414	lr=3.63e-04 | 82.8%@S30  T=1.05s eta=07:12:55 | 71.3K token/s | 
[epoch_0]_36421  loss=3.229575 |g|=0.425	lr=3.63e-04 | 83.6%@S30  T=1.06s eta=07:15:41 | 71.6K token/s | 
[epoch_0]_36431  loss=3.398945 |g|=0.429	lr=3.63e-04 | 84.4%@S30  T=1.12s eta=07:37:40 | 71.7K token/s | 
[epoch_0]_36441  loss=3.344021 |g|=0.419	lr=3.62e-04 | 85.3%@S30  T=1.10s eta=07:30:48 | 71.8K token/s | 
[epoch_0]_36451  loss=3.259752 |g|=0.472	lr=3.62e-04 | 86.1%@S30  T=1.06s eta=07:13:55 | 72.1K token/s | 
[epoch_0]_36461  loss=3.352091 |g|=0.437	lr=3.62e-04 | 86.9%@S30  T=1.07s eta=07:17:07 | 72.3K token/s | 
[epoch_0]_36471  loss=3.324023 |g|=0.446	lr=3.62e-04 | 87.7%@S30  T=1.06s eta=07:13:25 | 72.6K token/s | 
[epoch_0]_36481  loss=3.301355 |g|=0.427	lr=3.61e-04 | 88.5%@S30  T=1.06s eta=07:14:47 | 72.8K token/s | 
[epoch_0]_36491  loss=3.249557 |g|=0.4	lr=3.61e-04 | 89.4%@S30  T=1.10s eta=07:30:09 | 72.9K token/s | 
[Fuyou] head="4" update algorithm=4 t=2.07s
[Section@36500] layer[30-36] tasks=15(nPassBack=0) last_loss=3.32729(0.0417771) N=(580,31164,30744 3649900)
[epoch_0]_36501  loss=3.277613 |g|=0.408	lr=3.61e-04 | 90.2%@S30  T=1.39s eta=09:27:20 | 72.2K token/s | 
[epoch_0]_36511  loss=3.340401 |g|=0.413	lr=3.61e-04 | 91.0%@S30  T=1.07s eta=07:16:38 | 72.4K token/s | 
[epoch_0]_36521  loss=3.299577 |g|=0.443	lr=3.60e-04 | 91.8%@S30  T=1.07s eta=07:17:20 | 72.6K token/s | 
[epoch_0]_36531  loss=3.295841 |g|=0.411	lr=3.60e-04 | 92.6%@S30  T=1.07s eta=07:15:53 | 72.8K token/s | 
[epoch_0]_36541  loss=3.324992 |g|=0.418	lr=3.60e-04 | 93.4%@S30  T=1.08s eta=07:21:08 | 73.0K token/s | 
[epoch_0]_36551  loss=3.286542 |g|=0.447	lr=3.60e-04 | 94.3%@S30  T=1.11s eta=07:34:42 | 73.0K token/s | 
[epoch_0]_36561  loss=3.305646 |g|=0.458	lr=3.59e-04 | 95.1%@S30  T=1.08s eta=07:18:49 | 73.2K token/s | 
[epoch_0]_36571  loss=3.333537 |g|=0.407	lr=3.59e-04 | 95.9%@S30  T=1.06s eta=07:11:14 | 73.4K token/s | 
[epoch_0]_36581  loss=3.353451 |g|=0.481	lr=3.59e-04 | 96.7%@S30  T=1.07s eta=07:15:48 | 73.6K token/s | 
[epoch_0]_36591  loss=3.258647 |g|=0.405	lr=3.59e-04 | 97.5%@S30  T=1.07s eta=07:16:35 | 73.7K token/s | 
[Fuyou] head="5" update algorithm=4 t=2.01s
[eval] 
	 Loss@"edu_fineweb1B"=3.299(0.0021) nBranch=1 nToken=4.01M best=3.3007(181) E2T=-0.0661 T=13.49(0)s x=0
	#3.29864±0.1078 tps=298K(4.01408M) a=[3.11146,3.58673] T=13.49(sec)
[Section@36600] layer[0-6] tasks=15(nPassBack=0) last_loss=3.36476(-0.0670657) N=(580,31248,30828 3659900)
[epoch_0]_36601  loss=3.362574 |g|=0.391	lr=3.58e-04 | 98.4%@S30  T=4.18s eta=1d 04:21:22 | 71.0K token/s | 
[epoch_0]_36611  loss=3.295778 |g|=0.436	lr=3.58e-04 | 99.2%@S30  T=1.05s eta=07:08:42 | 71.3K token/s | 
[epoch_0]_36620  loss=3.350833 |g|=0.405	lr=3.58e-04 | 99.9%@S30  T=1.06s eta=07:13:13 | 71.6K token/s | 
[epoch_0]_36621  loss=3.289556 |g|=0.41	lr=3.58e-04 | 100.0%@S30  T=1.07s eta=07:14:04 | 71.9K token/s | 
-------- End of shard_30@"./Datasets/edu_fineweb1B/edu_fineweb_train_000483.bin"-------- 
[shard-31]@"./Datasets/edu_fineweb1B/edu_fineweb_train_000484.bin": tokens=100(M) nShardSamples=1220(3027336) 
[epoch_0]_36631  loss=3.293927 |g|=0.4	lr=3.58e-04 | 0.8%@S31  T=1.08s eta=07:17:32 | 72.1K token/s | 
[epoch_0]_36641  loss=3.275140 |g|=0.418	lr=3.57e-04 | 1.6%@S31  T=1.11s eta=07:29:28 | 72.2K token/s | 
[epoch_0]_36651  loss=3.335739 |g|=0.424	lr=3.57e-04 | 2.5%@S31  T=1.09s eta=07:24:39 | 72.3K token/s | 
[epoch_0]_36661  loss=3.317597 |g|=0.4	lr=3.57e-04 | 3.3%@S31  T=1.05s eta=07:05:34 | 72.6K token/s | 
[epoch_0]_36671  loss=3.232658 |g|=0.443	lr=3.57e-04 | 4.1%@S31  T=1.05s eta=07:07:17 | 72.9K token/s | 
[epoch_0]_36681  loss=3.322794 |g|=0.416	lr=3.56e-04 | 4.9%@S31  T=1.04s eta=07:03:05 | 73.2K token/s | 
[epoch_0]_36691  loss=3.282065 |g|=0.429	lr=3.56e-04 | 5.7%@S31  T=1.10s eta=07:24:38 | 73.2K token/s | 
[Fuyou] head="0" update algorithm=4 t=2.06s
[Section@36700] layer[6-12] tasks=15(nPassBack=0) last_loss=3.31279(0.00148559) N=(580,31332,30912 3669900)
[epoch_0]_36701  loss=3.230920 |g|=0.398	lr=3.56e-04 | 6.6%@S31  T=1.68s eta=11:20:52 | 72.0K token/s | 
[epoch_0]_36711  loss=3.267265 |g|=0.431	lr=3.56e-04 | 7.4%@S31  T=1.07s eta=07:11:56 | 72.3K token/s | 
[epoch_0]_36721  loss=3.259308 |g|=0.426	lr=3.55e-04 | 8.2%@S31  T=1.07s eta=07:11:53 | 72.5K token/s | 
[epoch_0]_36731  loss=3.333560 |g|=0.404	lr=3.55e-04 | 9.0%@S31  T=1.08s eta=07:18:36 | 72.7K token/s | 
[epoch_0]_36741  loss=3.326058 |g|=0.443	lr=3.55e-04 | 9.8%@S31  T=1.11s eta=07:30:06 | 72.7K token/s | 
[epoch_0]_36751  loss=3.308132 |g|=0.412	lr=3.55e-04 | 10.7%@S31  T=1.10s eta=07:25:38 | 72.8K token/s | 
[epoch_0]_36761  loss=3.273260 |g|=0.451	lr=3.54e-04 | 11.5%@S31  T=1.06s eta=07:08:55 | 73.0K token/s | 
[epoch_0]_36771  loss=3.319193 |g|=0.41	lr=3.54e-04 | 12.3%@S31  T=1.06s eta=07:07:25 | 73.2K token/s | 
[epoch_0]_36781  loss=3.297958 |g|=0.44	lr=3.54e-04 | 13.1%@S31  T=1.06s eta=07:10:28 | 73.4K token/s | 
[epoch_0]_36791  loss=3.344347 |g|=0.427	lr=3.54e-04 | 13.9%@S31  T=1.08s eta=07:15:46 | 73.5K token/s | 
[Fuyou] head="1" update algorithm=4 t=2.05s
[eval] 
	 Loss@"edu_fineweb1B"=3.295(0.0041) nBranch=1 nToken=4.01M best=3.2986(182) E2T=-0.00997 T=13.4901(0)s x=0
	#3.29454±0.1079 tps=298K(4.01408M) a=[3.11363,3.58243] T=13.4901(sec)
[Section@36800] layer[12-18] tasks=15(nPassBack=0) last_loss=3.30451(0.0645974) N=(580,31416,30996 3679900)
[epoch_0]_36801  loss=3.240062 |g|=0.403	lr=3.54e-04 | 14.7%@S31  T=4.17s eta=1d 04:05:52 | 70.9K token/s | 
[epoch_0]_36811  loss=3.284615 |g|=0.433	lr=3.53e-04 | 15.6%@S31  T=1.18s eta=07:58:08 | 70.8K token/s | 
[epoch_0]_36821  loss=3.170782 |g|=0.412	lr=3.53e-04 | 16.4%@S31  T=1.07s eta=07:10:07 | 71.1K token/s | 
[epoch_0]_36831  loss=3.306874 |g|=0.412	lr=3.53e-04 | 17.2%@S31  T=1.08s eta=07:14:32 | 71.3K token/s | 
[epoch_0]_36841  loss=3.278438 |g|=0.43	lr=3.53e-04 | 18.0%@S31  T=1.10s eta=07:22:14 | 71.5K token/s | 
[epoch_0]_36851  loss=3.331244 |g|=0.446	lr=3.52e-04 | 18.8%@S31  T=1.09s eta=07:18:04 | 71.7K token/s | 
[epoch_0]_36861  loss=3.284008 |g|=0.408	lr=3.52e-04 | 19.7%@S31  T=1.05s eta=07:03:58 | 72.0K token/s | 
[epoch_0]_36871  loss=3.310688 |g|=0.411	lr=3.52e-04 | 20.5%@S31  T=1.05s eta=07:04:42 | 72.3K token/s | 
[epoch_0]_36881  loss=3.285499 |g|=0.445	lr=3.52e-04 | 21.3%@S31  T=1.07s eta=07:09:46 | 72.5K token/s | 
[epoch_0]_36891  loss=3.296921 |g|=0.435	lr=3.51e-04 | 22.1%@S31  T=1.06s eta=07:06:10 | 72.7K token/s | 
[Fuyou] head="2" update algorithm=4 t=2.07s
[Section@36900] layer[18-24] tasks=15(nPassBack=0) last_loss=3.30107(0.00775933) N=(580,31500,31080 3689900)
[epoch_0]_36901  loss=3.314715 |g|=0.392	lr=3.51e-04 | 22.9%@S31  T=1.62s eta=10:52:07 | 71.6K token/s | 
[epoch_0]_36911  loss=3.263093 |g|=0.42	lr=3.51e-04 | 23.8%@S31  T=1.07s eta=07:08:48 | 71.9K token/s | 
[epoch_0]_36921  loss=3.345324 |g|=0.436	lr=3.51e-04 | 24.6%@S31  T=1.06s eta=07:06:35 | 72.2K token/s | 
[epoch_0]_36931  loss=3.304343 |g|=0.465	lr=3.50e-04 | 25.4%@S31  T=1.08s eta=07:14:57 | 72.3K token/s | 
[epoch_0]_36941  loss=3.303968 |g|=0.431	lr=3.50e-04 | 26.2%@S31  T=1.11s eta=07:24:52 | 72.4K token/s | 
[epoch_0]_36951  loss=3.261981 |g|=0.434	lr=3.50e-04 | 27.0%@S31  T=1.09s eta=07:19:08 | 72.5K token/s | 
[epoch_0]_36961  loss=3.329256 |g|=0.406	lr=3.50e-04 | 27.9%@S31  T=1.07s eta=07:07:20 | 72.8K token/s | 
[epoch_0]_36971  loss=3.285389 |g|=0.434	lr=3.49e-04 | 28.7%@S31  T=1.07s eta=07:08:03 | 73.0K token/s | 
[epoch_0]_36981  loss=3.401299 |g|=0.451	lr=3.49e-04 | 29.5%@S31  T=1.06s eta=07:03:50 | 73.2K token/s | 
[epoch_0]_36991  loss=3.289913 |g|=0.413	lr=3.49e-04 | 30.3%@S31  T=1.08s eta=07:11:53 | 73.3K token/s | 
[Fuyou] head="3" update algorithm=4 t=2.08s
[eval] 
	 Loss@"edu_fineweb1B"=3.293(0.0018) nBranch=1 nToken=4.01M best=3.2945(183) E2T=-0.0134 T=13.4962(0)s x=0
	#3.29274±0.1073 tps=297K(4.01408M) a=[3.11508,3.5821] T=13.4962(sec)
[Section@37000] layer[24-30] tasks=15(nPassBack=0) last_loss=3.30614(-0.052063) N=(580,31584,31164 3699900)
[epoch_0]_37001  loss=3.264760 |g|=0.401	lr=3.49e-04 | 31.1%@S31  T=4.17s eta=1d 03:50:14 | 70.6K token/s | 
[epoch_0]_37011  loss=3.334678 |g|=0.441	lr=3.48e-04 | 31.9%@S31  T=1.11s eta=07:23:05 | 70.8K token/s | 
[epoch_0]_37021  loss=3.277599 |g|=0.482	lr=3.48e-04 | 32.8%@S31  T=1.06s eta=07:05:55 | 71.1K token/s | 
[epoch_0]_37031  loss=3.348700 |g|=0.432	lr=3.48e-04 | 33.6%@S31  T=1.08s eta=07:12:32 | 71.3K token/s | 
[epoch_0]_37041  loss=3.326581 |g|=0.413	lr=3.48e-04 | 34.4%@S31  T=1.10s eta=07:19:53 | 71.5K token/s | 
[epoch_0]_37051  loss=3.372878 |g|=0.422	lr=3.47e-04 | 35.2%@S31  T=1.10s eta=07:21:21 | 71.6K token/s | 
[epoch_0]_37061  loss=3.292708 |g|=0.402	lr=3.47e-04 | 36.0%@S31  T=1.06s eta=07:04:48 | 71.9K token/s | 
[epoch_0]_37071  loss=3.291528 |g|=0.429	lr=3.47e-04 | 36.9%@S31  T=1.07s eta=07:07:28 | 72.1K token/s | 
[epoch_0]_37081  loss=3.353999 |g|=0.403	lr=3.47e-04 | 37.7%@S31  T=1.05s eta=07:01:08 | 72.4K token/s | 
[epoch_0]_37091  loss=3.274262 |g|=0.418	lr=3.46e-04 | 38.5%@S31  T=1.07s eta=07:07:18 | 72.6K token/s | 
[Fuyou] head="4" update algorithm=4 t=2.09s
[Section@37100] layer[30-36] tasks=15(nPassBack=0) last_loss=3.27865(0.0486426) N=(580,31668,31248 3709900)
[epoch_0]_37101  loss=3.310268 |g|=0.405	lr=3.46e-04 | 39.3%@S31  T=1.58s eta=10:30:04 | 71.6K token/s | 
[epoch_0]_37111  loss=3.227732 |g|=0.431	lr=3.46e-04 | 40.1%@S31  T=1.06s eta=07:02:45 | 71.9K token/s | 
[epoch_0]_37121  loss=3.266341 |g|=0.465	lr=3.46e-04 | 41.0%@S31  T=1.06s eta=07:04:20 | 72.1K token/s | 
[epoch_0]_37131  loss=3.337056 |g|=0.407	lr=3.45e-04 | 41.8%@S31  T=1.08s eta=07:10:17 | 72.3K token/s | 
[epoch_0]_37141  loss=3.246757 |g|=0.454	lr=3.45e-04 | 42.6%@S31  T=1.10s eta=07:17:10 | 72.4K token/s | 
[epoch_0]_37151  loss=3.312834 |g|=0.397	lr=3.45e-04 | 43.4%@S31  T=1.09s eta=07:14:25 | 72.6K token/s | 
[epoch_0]_37161  loss=3.273285 |g|=0.409	lr=3.45e-04 | 44.2%@S31  T=1.08s eta=07:09:49 | 72.7K token/s | 
[epoch_0]_37171  loss=3.224576 |g|=0.425	lr=3.44e-04 | 45.1%@S31  T=1.07s eta=07:05:52 | 72.9K token/s | 
[epoch_0]_37181  loss=3.271509 |g|=0.459	lr=3.44e-04 | 45.9%@S31  T=1.06s eta=07:02:48 | 73.1K token/s | 
[epoch_0]_37191  loss=3.305146 |g|=0.457	lr=3.44e-04 | 46.7%@S31  T=1.08s eta=07:10:07 | 73.2K token/s | 
[Fuyou] head="5" update algorithm=4 t=2.08s
[eval] 
	 Loss@"edu_fineweb1B"=3.293(7.2e-05) nBranch=1 nToken=4.01M best=3.2927(184) E2T=-0.00371 T=13.4859(0)s x=0
	#3.29266±0.1074 tps=298K(4.01408M) a=[3.11621,3.58164] T=13.4859(sec)
[Section@37200] layer[0-6] tasks=15(nPassBack=0) last_loss=3.29638(0.0683851) N=(580,31752,31332 3719900)
[epoch_0]_37201  loss=3.331312 |g|=0.402	lr=3.44e-04 | 47.5%@S31  T=4.20s eta=1d 03:49:15 | 70.6K token/s | 
[epoch_0]_37211  loss=3.262258 |g|=0.486	lr=3.43e-04 | 48.3%@S31  T=1.09s eta=07:10:59 | 70.8K token/s | 
[epoch_0]_37221  loss=3.318020 |g|=0.425	lr=3.43e-04 | 49.2%@S31  T=1.06s eta=07:01:07 | 71.1K token/s | 
[epoch_0]_37231  loss=3.306763 |g|=0.428	lr=3.43e-04 | 50.0%@S31  T=1.08s eta=07:09:19 | 71.4K token/s | 
[epoch_0]_37241  loss=3.320604 |g|=0.437	lr=3.43e-04 | 50.8%@S31  T=1.10s eta=07:17:28 | 71.5K token/s | 
[epoch_0]_37251  loss=3.246629 |g|=0.444	lr=3.43e-04 | 51.6%@S31  T=1.13s eta=07:27:26 | 71.6K token/s | 
[epoch_0]_37261  loss=3.317602 |g|=0.447	lr=3.42e-04 | 52.4%@S31  T=1.07s eta=07:02:44 | 71.8K token/s | 
[epoch_0]_37271  loss=3.300138 |g|=0.417	lr=3.42e-04 | 53.2%@S31  T=1.06s eta=07:01:10 | 72.1K token/s | 
[epoch_0]_37281  loss=3.287591 |g|=0.42	lr=3.42e-04 | 54.1%@S31  T=1.06s eta=06:59:08 | 72.3K token/s | 
[epoch_0]_37291  loss=3.300935 |g|=0.434	lr=3.42e-04 | 54.9%@S31  T=1.06s eta=07:01:17 | 72.6K token/s | 
[Fuyou] head="0" update algorithm=4 t=2.05s
[Section@37300] layer[6-12] tasks=15(nPassBack=0) last_loss=3.29897(0.0138209) N=(580,31836,31416 3729900)
[epoch_0]_37301  loss=3.258401 |g|=0.391	lr=3.41e-04 | 55.7%@S31  T=1.46s eta=09:37:16 | 71.7K token/s | 
[epoch_0]_37311  loss=3.250991 |g|=0.409	lr=3.41e-04 | 56.5%@S31  T=1.07s eta=07:03:32 | 72.0K token/s | 
[epoch_0]_37321  loss=3.348902 |g|=0.433	lr=3.41e-04 | 57.3%@S31  T=1.10s eta=07:13:35 | 72.1K token/s | 
[epoch_0]_37331  loss=3.302856 |g|=0.466	lr=3.41e-04 | 58.2%@S31  T=1.07s eta=07:01:05 | 72.4K token/s | 
[epoch_0]_37341  loss=3.224989 |g|=0.423	lr=3.40e-04 | 59.0%@S31  T=1.07s eta=07:01:13 | 72.6K token/s | 
[epoch_0]_37351  loss=3.230353 |g|=0.453	lr=3.40e-04 | 59.8%@S31  T=1.05s eta=06:55:30 | 72.8K token/s | 
[epoch_0]_37361  loss=3.371658 |g|=0.475	lr=3.40e-04 | 60.6%@S31  T=1.07s eta=07:02:28 | 73.0K token/s | 
[epoch_0]_37371  loss=3.249262 |g|=0.423	lr=3.40e-04 | 61.4%@S31  T=1.13s eta=07:27:04 | 73.0K token/s | 
[epoch_0]_37381  loss=3.331092 |g|=0.427	lr=3.39e-04 | 62.3%@S31  T=1.11s eta=07:17:15 | 73.0K token/s | 
[epoch_0]_37391  loss=3.225668 |g|=0.43	lr=3.39e-04 | 63.1%@S31  T=1.06s eta=06:58:07 | 73.2K token/s | 
[Fuyou] head="1" update algorithm=4 t=2.09s
[eval] 
	 Loss@"edu_fineweb1B"=3.290(0.003) nBranch=1 nToken=4.01M best=3.2927(185) E2T=-0.0217 T=13.5004(0)s x=0
	#3.28968±0.1073 tps=297K(4.01408M) a=[3.11017,3.57905] T=13.5004(sec)
[Section@37400] layer[12-18] tasks=15(nPassBack=0) last_loss=3.31143(-0.00691748) N=(580,31920,31500 3739900)
[epoch_0]_37401  loss=3.303998 |g|=0.444	lr=3.39e-04 | 63.9%@S31  T=4.20s eta=1d 03:35:09 | 70.6K token/s | 
[epoch_0]_37411  loss=3.210939 |g|=0.409	lr=3.39e-04 | 64.7%@S31  T=1.05s eta=06:54:00 | 70.9K token/s | 
[epoch_0]_37421  loss=3.282840 |g|=0.405	lr=3.38e-04 | 65.5%@S31  T=1.08s eta=07:04:37 | 71.2K token/s | 
[epoch_0]_37431  loss=3.316706 |g|=0.398	lr=3.38e-04 | 66.4%@S31  T=1.06s eta=06:57:59 | 71.5K token/s | 
[epoch_0]_37441  loss=3.329535 |g|=0.429	lr=3.38e-04 | 67.2%@S31  T=1.06s eta=06:57:28 | 71.8K token/s | 
[epoch_0]_37451  loss=3.343366 |g|=0.446	lr=3.38e-04 | 68.0%@S31  T=1.06s eta=06:55:17 | 72.0K token/s | 
[epoch_0]_37461  loss=3.274308 |g|=0.441	lr=3.37e-04 | 68.8%@S31  T=1.06s eta=06:57:28 | 72.3K token/s | 
[epoch_0]_37471  loss=3.377219 |g|=0.436	lr=3.37e-04 | 69.6%@S31  T=1.07s eta=07:00:25 | 72.5K token/s | 
[epoch_0]_37481  loss=3.324506 |g|=0.426	lr=3.37e-04 | 70.5%@S31  T=1.08s eta=07:02:29 | 72.7K token/s | 
[epoch_0]_37491  loss=3.276369 |g|=0.417	lr=3.37e-04 | 71.3%@S31  T=1.10s eta=07:10:55 | 72.8K token/s | 
[Fuyou] head="2" update algorithm=4 t=2.07s
[Section@37500] layer[18-24] tasks=15(nPassBack=0) last_loss=3.35192(-0.0508504) N=(580,32004,31584 3749900)
[epoch_0]_37501  loss=3.303324 |g|=0.421	lr=3.36e-04 | 72.1%@S31  T=1.59s eta=10:24:07 | 71.7K token/s | 
[epoch_0]_37511  loss=3.244152 |g|=0.449	lr=3.36e-04 | 72.9%@S31  T=1.07s eta=06:58:11 | 72.0K token/s | 
[epoch_0]_37521  loss=3.235586 |g|=0.437	lr=3.36e-04 | 73.7%@S31  T=1.06s eta=06:55:24 | 72.2K token/s | 
[epoch_0]_37531  loss=3.294846 |g|=0.441	lr=3.36e-04 | 74.5%@S31  T=1.08s eta=07:03:02 | 72.4K token/s | 
[epoch_0]_37541  loss=3.243323 |g|=0.419	lr=3.35e-04 | 75.4%@S31  T=1.13s eta=07:23:48 | 72.4K token/s | 
[epoch_0]_37551  loss=3.256833 |g|=0.443	lr=3.35e-04 | 76.2%@S31  T=1.11s eta=07:16:06 | 72.5K token/s | 
[epoch_0]_37561  loss=3.245078 |g|=0.429	lr=3.35e-04 | 77.0%@S31  T=1.07s eta=06:59:37 | 72.7K token/s | 
[epoch_0]_37571  loss=3.354129 |g|=0.416	lr=3.35e-04 | 77.8%@S31  T=1.05s eta=06:52:28 | 72.9K token/s | 
[epoch_0]_37581  loss=3.284528 |g|=0.439	lr=3.35e-04 | 78.6%@S31  T=1.06s eta=06:54:56 | 73.1K token/s | 
[epoch_0]_37591  loss=3.300885 |g|=0.419	lr=3.34e-04 | 79.5%@S31  T=1.08s eta=07:00:47 | 73.3K token/s | 
[Fuyou] head="3" update algorithm=4 t=2.07s
[eval] 
	 Loss@"edu_fineweb1B"=3.289(0.00088) nBranch=1 nToken=4.01M best=3.2897(186) E2T=0.101 T=13.4942(0)s x=0
	#3.2888±0.1072 tps=297K(4.01408M) a=[3.11162,3.57563] T=13.4942(sec)
[Section@37600] layer[24-30] tasks=15(nPassBack=0) last_loss=3.18753(0.118607) N=(580,32088,31668 3759900)
[epoch_0]_37601  loss=3.361079 |g|=0.425	lr=3.34e-04 | 80.3%@S31  T=4.20s eta=1d 03:21:03 | 70.6K token/s | 
[epoch_0]_37611  loss=3.257512 |g|=0.442	lr=3.34e-04 | 81.1%@S31  T=1.10s eta=07:09:36 | 70.8K token/s | 
[epoch_0]_37621  loss=3.321993 |g|=0.44	lr=3.34e-04 | 81.9%@S31  T=1.05s eta=06:49:21 | 71.1K token/s | 
[epoch_0]_37631  loss=3.312469 |g|=0.4	lr=3.33e-04 | 82.7%@S31  T=1.06s eta=06:54:45 | 71.4K token/s | 
[epoch_0]_37641  loss=3.261074 |g|=0.422	lr=3.33e-04 | 83.6%@S31  T=1.08s eta=06:59:40 | 71.7K token/s | 
[epoch_0]_37651  loss=3.226488 |g|=0.401	lr=3.33e-04 | 84.4%@S31  T=1.08s eta=07:02:45 | 71.9K token/s | 
[epoch_0]_37661  loss=3.272748 |g|=0.426	lr=3.33e-04 | 85.2%@S31  T=1.12s eta=07:16:17 | 71.9K token/s | 
[epoch_0]_37671  loss=3.369181 |g|=0.44	lr=3.32e-04 | 86.0%@S31  T=1.11s eta=07:11:08 | 72.0K token/s | 
[epoch_0]_37681  loss=3.245541 |g|=0.414	lr=3.32e-04 | 86.8%@S31  T=1.07s eta=06:56:21 | 72.3K token/s | 
[epoch_0]_37691  loss=3.376686 |g|=0.449	lr=3.32e-04 | 87.7%@S31  T=1.06s eta=06:50:30 | 72.5K token/s | 
[Fuyou] head="4" update algorithm=4 t=2.14s
[Section@37700] layer[30-36] tasks=15(nPassBack=0) last_loss=3.32394(-0.0452828) N=(580,32172,31752 3769900)
[epoch_0]_37701  loss=3.284192 |g|=0.423	lr=3.32e-04 | 88.5%@S31  T=1.42s eta=09:11:24 | 71.8K token/s | 
[epoch_0]_37711  loss=3.286435 |g|=0.436	lr=3.31e-04 | 89.3%@S31  T=1.06s eta=06:53:48 | 72.0K token/s | 
[epoch_0]_37721  loss=3.240407 |g|=0.415	lr=3.31e-04 | 90.1%@S31  T=1.10s eta=07:06:29 | 72.2K token/s | 
[epoch_0]_37731  loss=3.248168 |g|=0.399	lr=3.31e-04 | 90.9%@S31  T=1.06s eta=06:52:17 | 72.4K token/s | 
[epoch_0]_37741  loss=3.329722 |g|=0.455	lr=3.31e-04 | 91.8%@S31  T=1.06s eta=06:51:55 | 72.7K token/s | 
[epoch_0]_37751  loss=3.331958 |g|=0.441	lr=3.30e-04 | 92.6%@S31  T=1.08s eta=06:57:19 | 72.8K token/s | 
[epoch_0]_37761  loss=3.322700 |g|=0.426	lr=3.30e-04 | 93.4%@S31  T=1.06s eta=06:51:05 | 73.1K token/s | 
[epoch_0]_37771  loss=3.224600 |g|=0.394	lr=3.30e-04 | 94.2%@S31  T=1.08s eta=06:59:12 | 73.2K token/s | 
[epoch_0]_37781  loss=3.250371 |g|=0.441	lr=3.30e-04 | 95.0%@S31  T=1.11s eta=07:09:11 | 73.2K token/s | 
[epoch_0]_37791  loss=3.342044 |g|=0.413	lr=3.29e-04 | 95.8%@S31  T=1.10s eta=07:04:53 | 73.3K token/s | 
[Fuyou] head="5" update algorithm=4 t=2.09s
[eval] 
	 Loss@"edu_fineweb1B"=3.288(0.00091) nBranch=1 nToken=4.01M best=3.2888(187) E2T=0.0344 T=13.495(0)s x=0
	#3.2879±0.1071 tps=297K(4.01408M) a=[3.11313,3.57522] T=13.495(sec)
[Section@37800] layer[0-6] tasks=15(nPassBack=0) last_loss=3.25351(0.0428693) N=(580,32256,31836 3779900)
[epoch_0]_37801  loss=3.315784 |g|=0.405	lr=3.29e-04 | 96.7%@S31  T=4.21s eta=1d 03:12:00 | 70.6K token/s | 
[epoch_0]_37811  loss=3.293822 |g|=0.427	lr=3.29e-04 | 97.5%@S31  T=1.07s eta=06:54:26 | 70.9K token/s | 
[epoch_0]_37821  loss=3.369517 |g|=0.426	lr=3.29e-04 | 98.3%@S31  T=1.06s eta=06:50:40 | 71.2K token/s | 
[epoch_0]_37831  loss=3.298566 |g|=0.449	lr=3.29e-04 | 99.1%@S31  T=1.14s eta=07:19:28 | 71.3K token/s | 
[epoch_0]_37841  loss=3.236915 |g|=0.422	lr=3.28e-04 | 99.9%@S31  T=1.08s eta=06:55:57 | 71.5K token/s | 
-------- End of shard_31@"./Datasets/edu_fineweb1B/edu_fineweb_train_000484.bin"-------- 
[shard-32]@"./Datasets/edu_fineweb1B/edu_fineweb_train_000485.bin": tokens=100(M) nShardSamples=1220(3124992) 
[epoch_0]_37851  loss=3.371141 |g|=0.45	lr=3.28e-04 | 0.8%@S32  T=1.06s eta=06:49:14 | 71.8K token/s | 
[epoch_0]_37861  loss=3.292878 |g|=0.431	lr=3.28e-04 | 1.6%@S32  T=1.06s eta=06:50:09 | 72.1K token/s | 
[epoch_0]_37871  loss=3.355494 |g|=0.418	lr=3.28e-04 | 2.4%@S32  T=1.07s eta=06:53:53 | 72.3K token/s | 
[epoch_0]_37881  loss=3.296045 |g|=0.417	lr=3.27e-04 | 3.2%@S32  T=1.07s eta=06:54:50 | 72.5K token/s | 
[epoch_0]_37891  loss=3.325969 |g|=0.406	lr=3.27e-04 | 4.0%@S32  T=1.12s eta=07:10:20 | 72.5K token/s | 
[Fuyou] head="0" update algorithm=4 t=2.00s
[Section@37900] layer[6-12] tasks=15(nPassBack=0) last_loss=3.3203(-0.0213306) N=(580,32340,31920 3789900)
[epoch_0]_37901  loss=3.336750 |g|=0.416	lr=3.27e-04 | 4.9%@S32  T=1.47s eta=09:26:35 | 71.7K token/s | 
[epoch_0]_37911  loss=3.303838 |g|=0.415	lr=3.27e-04 | 5.7%@S32  T=1.06s eta=06:47:54 | 72.0K token/s | 
[epoch_0]_37921  loss=3.277832 |g|=0.456	lr=3.26e-04 | 6.5%@S32  T=1.06s eta=06:48:30 | 72.2K token/s | 
[epoch_0]_37931  loss=3.307680 |g|=0.448	lr=3.26e-04 | 7.3%@S32  T=1.08s eta=06:54:26 | 72.4K token/s | 
[epoch_0]_37941  loss=3.294396 |g|=0.415	lr=3.26e-04 | 8.1%@S32  T=1.08s eta=06:55:32 | 72.6K token/s | 
[epoch_0]_37951  loss=3.326541 |g|=0.433	lr=3.26e-04 | 9.0%@S32  T=1.12s eta=07:10:26 | 72.6K token/s | 
[epoch_0]_37961  loss=3.238904 |g|=0.418	lr=3.25e-04 | 9.8%@S32  T=1.10s eta=07:01:35 | 72.7K token/s | 
[epoch_0]_37971  loss=3.312330 |g|=0.447	lr=3.25e-04 | 10.6%@S32  T=1.06s eta=06:45:43 | 73.0K token/s | 
[epoch_0]_37981  loss=3.298112 |g|=0.435	lr=3.25e-04 | 11.4%@S32  T=1.06s eta=06:46:03 | 73.2K token/s | 
[epoch_0]_37991  loss=3.188561 |g|=0.431	lr=3.25e-04 | 12.2%@S32  T=1.06s eta=06:45:57 | 73.4K token/s | 
[Fuyou] head="1" update algorithm=4 t=2.07s
[eval] 
	 Loss@"edu_fineweb1B"=3.287(0.0011) nBranch=1 nToken=4.01M best=3.2879(188) E2T=-0.0248 T=13.4913(0)s x=0
	#3.28681±0.1078 tps=298K(4.01408M) a=[3.10798,3.58152] T=13.4913(sec)
[Section@38000] layer[12-18] tasks=15(nPassBack=0) last_loss=3.31165(-0.000217438) N=(580,32424,32004 3799900)
[epoch_0]_38001  loss=3.327067 |g|=0.434	lr=3.24e-04 | 13.1%@S32  T=4.20s eta=1d 02:53:16 | 70.7K token/s | 
[epoch_0]_38011  loss=3.242691 |g|=0.439	lr=3.24e-04 | 13.9%@S32  T=1.09s eta=06:57:10 | 71.0K token/s | 
[epoch_0]_38021  loss=3.332356 |g|=0.426	lr=3.24e-04 | 14.7%@S32  T=1.07s eta=06:50:03 | 71.2K token/s | 
[epoch_0]_38031  loss=3.311768 |g|=0.45	lr=3.24e-04 | 15.5%@S32  T=1.07s eta=06:50:05 | 71.5K token/s | 
[epoch_0]_38041  loss=3.303355 |g|=0.415	lr=3.23e-04 | 16.3%@S32  T=1.11s eta=07:04:52 | 71.6K token/s | 
[epoch_0]_38051  loss=3.269746 |g|=0.401	lr=3.23e-04 | 17.1%@S32  T=1.13s eta=07:13:12 | 71.7K token/s | 
[epoch_0]_38061  loss=3.285468 |g|=0.416	lr=3.23e-04 | 18.0%@S32  T=1.06s eta=06:45:56 | 72.0K token/s | 
[epoch_0]_38071  loss=3.244600 |g|=0.436	lr=3.23e-04 | 18.8%@S32  T=1.06s eta=06:45:43 | 72.2K token/s | 
[epoch_0]_38081  loss=3.332517 |g|=0.431	lr=3.23e-04 | 19.6%@S32  T=1.07s eta=06:49:03 | 72.4K token/s | 
[epoch_0]_38091  loss=3.263309 |g|=0.417	lr=3.22e-04 | 20.4%@S32  T=1.06s eta=06:46:15 | 72.7K token/s | 
[Fuyou] head="2" update algorithm=4 t=2.03s
[Section@38100] layer[18-24] tasks=15(nPassBack=0) last_loss=3.27923(0.0726945) N=(580,32508,32088 3809900)
[epoch_0]_38101  loss=3.267314 |g|=0.436	lr=3.22e-04 | 21.2%@S32  T=1.34s eta=08:33:39 | 72.1K token/s | 
[epoch_0]_38111  loss=3.362055 |g|=0.434	lr=3.22e-04 | 22.1%@S32  T=1.06s eta=06:45:47 | 72.3K token/s | 
[epoch_0]_38121  loss=3.289341 |g|=0.439	lr=3.22e-04 | 22.9%@S32  T=1.06s eta=06:44:06 | 72.6K token/s | 
[epoch_0]_38131  loss=3.249948 |g|=0.441	lr=3.21e-04 | 23.7%@S32  T=1.05s eta=06:41:35 | 72.9K token/s | 
[epoch_0]_38141  loss=3.322097 |g|=0.424	lr=3.21e-04 | 24.5%@S32  T=1.08s eta=06:52:44 | 73.0K token/s | 
[epoch_0]_38151  loss=3.303483 |g|=0.449	lr=3.21e-04 | 25.3%@S32  T=1.08s eta=06:53:22 | 73.1K token/s | 
[epoch_0]_38161  loss=3.311299 |g|=0.455	lr=3.21e-04 | 26.2%@S32  T=1.12s eta=07:05:49 | 73.1K token/s | 
[epoch_0]_38171  loss=3.390202 |g|=0.436	lr=3.20e-04 | 27.0%@S32  T=1.09s eta=06:56:08 | 73.2K token/s | 
[epoch_0]_38181  loss=3.302100 |g|=0.434	lr=3.20e-04 | 27.8%@S32  T=1.07s eta=06:48:38 | 73.4K token/s | 
[epoch_0]_38191  loss=3.275219 |g|=0.441	lr=3.20e-04 | 28.6%@S32  T=1.06s eta=06:43:03 | 73.6K token/s | 
[Fuyou] head="3" update algorithm=4 t=2.10s
[eval] 
	 Loss@"edu_fineweb1B"=3.287(-0.0003) nBranch=1 nToken=4.01M best=3.2868(189) E2T=-0.0704 T=13.4954(0)s x=0
	#3.28711±0.1079 tps=297K(4.01408M) a=[3.10834,3.57907] T=13.4954(sec)
[Section@38200] layer[24-30] tasks=15(nPassBack=0) last_loss=3.35749(-0.169959) N=(580,32592,32172 3819900)
[epoch_0]_38201  loss=3.319473 |g|=0.414	lr=3.20e-04 | 29.4%@S32  T=4.21s eta=1d 02:41:57 | 70.9K token/s | 
[epoch_0]_38211  loss=3.305583 |g|=0.461	lr=3.19e-04 | 30.3%@S32  T=1.11s eta=07:01:51 | 71.0K token/s | 
[epoch_0]_38221  loss=3.281925 |g|=0.458	lr=3.19e-04 | 31.1%@S32  T=1.07s eta=06:46:57 | 71.3K token/s | 
[epoch_0]_38231  loss=3.361825 |g|=0.448	lr=3.19e-04 | 31.9%@S32  T=1.06s eta=06:43:19 | 71.6K token/s | 
[epoch_0]_38241  loss=3.315584 |g|=0.431	lr=3.19e-04 | 32.7%@S32  T=1.07s eta=06:46:06 | 71.9K token/s | 
[epoch_0]_38251  loss=3.293834 |g|=0.406	lr=3.18e-04 | 33.5%@S32  T=1.07s eta=06:47:41 | 72.1K token/s | 
[epoch_0]_38261  loss=3.396020 |g|=0.434	lr=3.18e-04 | 34.4%@S32  T=1.10s eta=06:57:40 | 72.2K token/s | 
[epoch_0]_38271  loss=3.284620 |g|=0.455	lr=3.18e-04 | 35.2%@S32  T=1.10s eta=06:55:54 | 72.3K token/s | 
[epoch_0]_38281  loss=3.289349 |g|=0.419	lr=3.18e-04 | 36.0%@S32  T=1.05s eta=06:37:43 | 72.6K token/s | 
[epoch_0]_38291  loss=3.238609 |g|=0.419	lr=3.17e-04 | 36.8%@S32  T=1.07s eta=06:45:20 | 72.8K token/s | 
[Fuyou] head="4" update algorithm=4 t=2.02s
[Section@38300] layer[30-36] tasks=15(nPassBack=0) last_loss=3.2864(0.0375397) N=(580,32676,32256 3829900)
[epoch_0]_38301  loss=3.212226 |g|=0.425	lr=3.17e-04 | 37.6%@S32  T=1.36s eta=08:33:53 | 72.2K token/s | 
[epoch_0]_38311  loss=3.284107 |g|=0.428	lr=3.17e-04 | 38.4%@S32  T=1.05s eta=06:39:11 | 72.5K token/s | 
[epoch_0]_38321  loss=3.332071 |g|=0.45	lr=3.17e-04 | 39.3%@S32  T=1.10s eta=06:56:38 | 72.6K token/s | 
[epoch_0]_38331  loss=3.311570 |g|=0.421	lr=3.17e-04 | 40.1%@S32  T=1.06s eta=06:42:28 | 72.8K token/s | 
[epoch_0]_38341  loss=3.247381 |g|=0.432	lr=3.16e-04 | 40.9%@S32  T=1.07s eta=06:45:11 | 73.0K token/s | 
[epoch_0]_38351  loss=3.228373 |g|=0.437	lr=3.16e-04 | 41.7%@S32  T=1.07s eta=06:45:57 | 73.1K token/s | 
[epoch_0]_38361  loss=3.224259 |g|=0.421	lr=3.16e-04 | 42.5%@S32  T=1.08s eta=06:46:56 | 73.3K token/s | 
[epoch_0]_38371  loss=3.260939 |g|=0.423	lr=3.16e-04 | 43.4%@S32  T=1.09s eta=06:53:10 | 73.4K token/s | 
[epoch_0]_38381  loss=3.241223 |g|=0.429	lr=3.15e-04 | 44.2%@S32  T=1.12s eta=07:02:08 | 73.4K token/s | 
[epoch_0]_38391  loss=3.238720 |g|=0.408	lr=3.15e-04 | 45.0%@S32  T=1.07s eta=06:43:24 | 73.5K token/s | 
[Fuyou] head="5" update algorithm=4 t=2.05s
[eval] 
	 Loss@"edu_fineweb1B"=3.285(0.002) nBranch=1 nToken=4.01M best=3.2871(190) E2T=-0.0636 T=13.4879(0)s x=0
	#3.28515±0.1078 tps=298K(4.01408M) a=[3.10682,3.57516] T=13.4879(sec)
[Section@38400] layer[0-6] tasks=15(nPassBack=0) last_loss=3.3487(-0.0951934) N=(580,32760,32340 3839900)
[epoch_0]_38401  loss=3.355937 |g|=0.429	lr=3.15e-04 | 45.8%@S32  T=4.19s eta=1d 02:21:12 | 70.8K token/s | 
[epoch_0]_38411  loss=3.279240 |g|=0.435	lr=3.15e-04 | 46.6%@S32  T=1.08s eta=06:48:04 | 71.1K token/s | 
[epoch_0]_38421  loss=3.214431 |g|=0.457	lr=3.14e-04 | 47.5%@S32  T=1.10s eta=06:55:52 | 71.2K token/s | 
[epoch_0]_38431  loss=3.201591 |g|=0.424	lr=3.14e-04 | 48.3%@S32  T=1.08s eta=06:48:26 | 71.4K token/s | 
[epoch_0]_38441  loss=3.277161 |g|=0.424	lr=3.14e-04 | 49.1%@S32  T=1.08s eta=06:45:49 | 71.7K token/s | 
[epoch_0]_38451  loss=3.303777 |g|=0.433	lr=3.14e-04 | 49.9%@S32  T=1.07s eta=06:43:50 | 71.9K token/s | 
[epoch_0]_38461  loss=3.346416 |g|=0.452	lr=3.13e-04 | 50.7%@S32  T=1.08s eta=06:44:46 | 72.1K token/s | 
[epoch_0]_38471  loss=3.299396 |g|=0.455	lr=3.13e-04 | 51.6%@S32  T=1.07s eta=06:41:01 | 72.4K token/s | 
[epoch_0]_38481  loss=3.326304 |g|=0.441	lr=3.13e-04 | 52.4%@S32  T=1.08s eta=06:45:30 | 72.5K token/s | 
[epoch_0]_38491  loss=3.282384 |g|=0.441	lr=3.13e-04 | 53.2%@S32  T=1.12s eta=06:59:27 | 72.6K token/s | 
[Fuyou] head="0" update algorithm=4 t=2.08s
[Section@38500] layer[6-12] tasks=15(nPassBack=0) last_loss=3.25413(0.0661626) N=(580,32844,32424 3849900)
[epoch_0]_38501  loss=3.309746 |g|=0.417	lr=3.13e-04 | 54.0%@S32  T=1.41s eta=08:48:49 | 71.9K token/s | 
[epoch_0]_38511  loss=3.283112 |g|=0.43	lr=3.12e-04 | 54.8%@S32  T=1.05s eta=06:35:34 | 72.1K token/s | 
[epoch_0]_38521  loss=3.275328 |g|=0.442	lr=3.12e-04 | 55.6%@S32  T=1.05s eta=06:34:15 | 72.4K token/s | 
[epoch_0]_38531  loss=3.250859 |g|=0.435	lr=3.12e-04 | 56.5%@S32  T=1.06s eta=06:36:14 | 72.7K token/s | 
[epoch_0]_38541  loss=3.232490 |g|=0.411	lr=3.12e-04 | 57.3%@S32  T=1.09s eta=06:49:08 | 72.8K token/s | 
[epoch_0]_38551  loss=3.221220 |g|=0.427	lr=3.11e-04 | 58.1%@S32  T=1.12s eta=06:59:38 | 72.8K token/s | 
[epoch_0]_38561  loss=3.271571 |g|=0.406	lr=3.11e-04 | 58.9%@S32  T=1.14s eta=07:07:26 | 72.8K token/s | 
[epoch_0]_38571  loss=3.332163 |g|=0.419	lr=3.11e-04 | 59.7%@S32  T=1.07s eta=06:39:22 | 73.0K token/s | 
[epoch_0]_38581  loss=3.287300 |g|=0.424	lr=3.11e-04 | 60.6%@S32  T=1.05s eta=06:32:55 | 73.2K token/s | 
[epoch_0]_38591  loss=3.259769 |g|=0.414	lr=3.10e-04 | 61.4%@S32  T=1.08s eta=06:42:26 | 73.4K token/s | 
[Fuyou] head="1" update algorithm=4 t=2.21s
[eval] 
	 Loss@"edu_fineweb1B"=3.284(0.00084) nBranch=1 nToken=4.01M best=3.2851(191) E2T=0.0246 T=13.4877(0)s x=0
	#3.28431±0.1083 tps=298K(4.01408M) a=[3.10493,3.5737] T=13.4877(sec)
[Section@38600] layer[12-18] tasks=15(nPassBack=0) last_loss=3.25967(0.0519791) N=(580,32928,32508 3859900)
[epoch_0]_38601  loss=3.286184 |g|=0.41	lr=3.10e-04 | 62.2%@S32  T=4.21s eta=1d 02:14:38 | 70.7K token/s | 
[epoch_0]_38611  loss=3.301998 |g|=0.435	lr=3.10e-04 | 63.0%@S32  T=1.12s eta=06:59:36 | 70.8K token/s | 
[epoch_0]_38621  loss=3.335521 |g|=0.427	lr=3.10e-04 | 63.8%@S32  T=1.08s eta=06:42:06 | 71.1K token/s | 
[epoch_0]_38631  loss=3.318716 |g|=0.431	lr=3.09e-04 | 64.7%@S32  T=1.07s eta=06:39:53 | 71.3K token/s | 
[epoch_0]_38641  loss=3.303417 |g|=0.434	lr=3.09e-04 | 65.5%@S32  T=1.06s eta=06:36:48 | 71.6K token/s | 
[epoch_0]_38651  loss=3.314031 |g|=0.443	lr=3.09e-04 | 66.3%@S32  T=1.10s eta=06:50:11 | 71.8K token/s | 
[epoch_0]_38661  loss=3.266777 |g|=0.425	lr=3.09e-04 | 67.1%@S32  T=1.12s eta=06:56:57 | 71.8K token/s | 
[epoch_0]_38671  loss=3.322007 |g|=0.434	lr=3.08e-04 | 67.9%@S32  T=1.07s eta=06:37:38 | 72.1K token/s | 
[epoch_0]_38681  loss=3.273850 |g|=0.415	lr=3.08e-04 | 68.8%@S32  T=1.06s eta=06:34:13 | 72.4K token/s | 
[epoch_0]_38691  loss=3.150668 |g|=0.443	lr=3.08e-04 | 69.6%@S32  T=1.06s eta=06:35:30 | 72.6K token/s | 
[Fuyou] head="2" update algorithm=4 t=2.06s
[Section@38700] layer[18-24] tasks=15(nPassBack=0) last_loss=3.30154(-0.0223114) N=(580,33012,32592 3869900)
[epoch_0]_38701  loss=3.236455 |g|=0.39	lr=3.08e-04 | 70.4%@S32  T=1.55s eta=09:37:06 | 71.6K token/s | 
[epoch_0]_38711  loss=3.238569 |g|=0.482	lr=3.08e-04 | 71.2%@S32  T=1.06s eta=06:32:55 | 71.9K token/s | 
[epoch_0]_38721  loss=3.339985 |g|=0.4	lr=3.07e-04 | 72.0%@S32  T=1.11s eta=06:53:57 | 72.0K token/s | 
[epoch_0]_38731  loss=3.190880 |g|=0.451	lr=3.07e-04 | 72.9%@S32  T=1.06s eta=06:33:13 | 72.3K token/s | 
[epoch_0]_38741  loss=3.232065 |g|=0.455	lr=3.07e-04 | 73.7%@S32  T=1.07s eta=06:35:55 | 72.5K token/s | 
[epoch_0]_38751  loss=3.255780 |g|=0.455	lr=3.07e-04 | 74.5%@S32  T=1.07s eta=06:35:39 | 72.7K token/s | 
[epoch_0]_38761  loss=3.297365 |g|=0.4	lr=3.06e-04 | 75.3%@S32  T=1.07s eta=06:37:30 | 72.9K token/s | 
[epoch_0]_38771  loss=3.304315 |g|=0.418	lr=3.06e-04 | 76.1%@S32  T=1.10s eta=06:48:50 | 73.0K token/s | 
[epoch_0]_38781  loss=3.253669 |g|=0.446	lr=3.06e-04 | 76.9%@S32  T=1.11s eta=06:52:34 | 73.0K token/s | 
[epoch_0]_38791  loss=3.303998 |g|=0.54	lr=3.06e-04 | 77.8%@S32  T=1.05s eta=06:27:28 | 73.3K token/s | 
[Fuyou] head="3" update algorithm=4 t=2.08s
[eval] 
	 Loss@"edu_fineweb1B"=3.282(0.0025) nBranch=1 nToken=4.01M best=3.2843(192) E2T=-0.0708 T=13.4989(0)s x=0
	#3.28184±0.1082 tps=297K(4.01408M) a=[3.09862,3.56851] T=13.4989(sec)
[Section@38800] layer[24-30] tasks=15(nPassBack=0) last_loss=3.35262(0.00487328) N=(580,33096,32676 3879900)
[epoch_0]_38801  loss=3.238828 |g|=0.421	lr=3.05e-04 | 78.6%@S32  T=4.22s eta=1d 02:02:57 | 70.6K token/s | 
[epoch_0]_38811  loss=3.296429 |g|=0.423	lr=3.05e-04 | 79.4%@S32  T=1.07s eta=06:37:08 | 70.9K token/s | 
[epoch_0]_38821  loss=3.287634 |g|=0.428	lr=3.05e-04 | 80.2%@S32  T=1.08s eta=06:40:12 | 71.1K token/s | 
[epoch_0]_38831  loss=3.347099 |g|=0.452	lr=3.05e-04 | 81.0%@S32  T=1.11s eta=06:50:17 | 71.3K token/s | 
[epoch_0]_38841  loss=3.241572 |g|=0.439	lr=3.04e-04 | 81.9%@S32  T=1.12s eta=06:53:18 | 71.4K token/s | 
[epoch_0]_38851  loss=3.365578 |g|=0.427	lr=3.04e-04 | 82.7%@S32  T=1.11s eta=06:49:36 | 71.5K token/s | 
[epoch_0]_38861  loss=3.270831 |g|=0.423	lr=3.04e-04 | 83.5%@S32  T=1.07s eta=06:37:10 | 71.7K token/s | 
[epoch_0]_38871  loss=3.355676 |g|=0.45	lr=3.04e-04 | 84.3%@S32  T=1.08s eta=06:37:07 | 72.0K token/s | 
[epoch_0]_38881  loss=3.288924 |g|=0.42	lr=3.04e-04 | 85.1%@S32  T=1.08s eta=06:38:54 | 72.1K token/s | 
[epoch_0]_38891  loss=3.427719 |g|=0.451	lr=3.03e-04 | 86.0%@S32  T=1.09s eta=06:40:46 | 72.3K token/s | 
[Fuyou] head="4" update algorithm=4 t=2.13s
[Section@38900] layer[30-36] tasks=15(nPassBack=0) last_loss=3.22904(0.0573602) N=(580,33180,32760 3889900)
[epoch_0]_38901  loss=3.206592 |g|=0.414	lr=3.03e-04 | 86.8%@S32  T=1.36s eta=08:23:05 | 71.7K token/s | 
[epoch_0]_38911  loss=3.279966 |g|=0.443	lr=3.03e-04 | 87.6%@S32  T=1.07s eta=06:32:54 | 72.0K token/s | 
[epoch_0]_38921  loss=3.287105 |g|=0.453	lr=3.03e-04 | 88.4%@S32  T=1.08s eta=06:37:52 | 72.2K token/s | 
[epoch_0]_38931  loss=3.274168 |g|=0.434	lr=3.02e-04 | 89.2%@S32  T=1.08s eta=06:39:21 | 72.3K token/s | 
[epoch_0]_38941  loss=3.382767 |g|=0.456	lr=3.02e-04 | 90.1%@S32  T=1.11s eta=06:47:17 | 72.4K token/s | 
[epoch_0]_38951  loss=3.247560 |g|=0.417	lr=3.02e-04 | 90.9%@S32  T=1.09s eta=06:39:56 | 72.6K token/s | 
[epoch_0]_38961  loss=3.333776 |g|=0.462	lr=3.02e-04 | 91.7%@S32  T=1.14s eta=07:00:40 | 72.5K token/s | 
[epoch_0]_38971  loss=3.296992 |g|=0.443	lr=3.01e-04 | 92.5%@S32  T=1.11s eta=06:48:14 | 72.6K token/s | 
[epoch_0]_38981  loss=3.301591 |g|=0.427	lr=3.01e-04 | 93.3%@S32  T=1.08s eta=06:35:53 | 72.8K token/s | 
[epoch_0]_38991  loss=3.216660 |g|=0.401	lr=3.01e-04 | 94.2%@S32  T=1.07s eta=06:32:56 | 72.9K token/s | 
[Fuyou] head="5" update algorithm=4 t=2.09s
[eval] 
	 Loss@"edu_fineweb1B"=3.281(0.00037) nBranch=1 nToken=4.01M best=3.2818(193) E2T=0.00489 T=13.4892(0)s x=0
	#3.28147±0.1079 tps=298K(4.01408M) a=[3.10223,3.56872] T=13.4892(sec)
[Section@39000] layer[0-6] tasks=15(nPassBack=0) last_loss=3.27658(0.0721197) N=(580,33264,32844 3899900)
[epoch_0]_39001  loss=3.347384 |g|=0.461	lr=3.01e-04 | 95.0%@S32  T=4.25s eta=1d 02:00:51 | 70.3K token/s | 
[epoch_0]_39011  loss=3.297547 |g|=0.46	lr=3.00e-04 | 95.8%@S32  T=1.09s eta=06:40:56 | 70.5K token/s | 
[epoch_0]_39021  loss=3.299094 |g|=0.417	lr=3.00e-04 | 96.6%@S32  T=1.11s eta=06:48:52 | 70.6K token/s | 
[epoch_0]_39031  loss=3.256901 |g|=0.424	lr=3.00e-04 | 97.4%@S32  T=1.08s eta=06:37:50 | 70.9K token/s | 
[epoch_0]_39041  loss=3.283396 |g|=0.418	lr=3.00e-04 | 98.2%@S32  T=1.09s eta=06:38:37 | 71.1K token/s | 
[epoch_0]_39051  loss=3.254995 |g|=0.471	lr=3.00e-04 | 99.1%@S32  T=1.07s eta=06:33:28 | 71.4K token/s | 
[epoch_0]_39061  loss=3.315923 |g|=0.441	lr=2.99e-04 | 99.9%@S32  T=1.09s eta=06:38:41 | 71.6K token/s | 
[epoch_0]_39062  loss=3.230042 |g|=0.429	lr=2.99e-04 | 100.0%@S32  T=1.08s eta=06:36:55 | 71.8K token/s | 
-------- End of shard_32@"./Datasets/edu_fineweb1B/edu_fineweb_train_000485.bin"-------- 
[shard-33]@"./Datasets/edu_fineweb1B/edu_fineweb_train_000486.bin": tokens=100(M) nShardSamples=1220(3222648) 
[epoch_0]_39071  loss=3.290646 |g|=0.447	lr=2.99e-04 | 0.7%@S33  T=1.09s eta=06:38:54 | 71.9K token/s | 
[epoch_0]_39081  loss=3.311345 |g|=0.45	lr=2.99e-04 | 1.5%@S33  T=1.11s eta=06:46:21 | 72.0K token/s | 
[epoch_0]_39091  loss=3.241323 |g|=0.472	lr=2.99e-04 | 2.3%@S33  T=1.10s eta=06:43:25 | 72.1K token/s | 
[Fuyou] head="0" update algorithm=4 t=2.22s
[Section@39100] layer[6-12] tasks=15(nPassBack=0) last_loss=3.3152(-0.0610664) N=(580,33348,32928 3909900)
[epoch_0]_39101  loss=3.216506 |g|=0.418	lr=2.98e-04 | 3.2%@S33  T=1.42s eta=08:37:46 | 71.4K token/s | 
[epoch_0]_39111  loss=3.377846 |g|=0.434	lr=2.98e-04 | 4.0%@S33  T=1.07s eta=06:32:04 | 71.7K token/s | 
[epoch_0]_39121  loss=3.262971 |g|=0.438	lr=2.98e-04 | 4.8%@S33  T=1.07s eta=06:29:29 | 71.9K token/s | 
[epoch_0]_39131  loss=3.346947 |g|=0.433	lr=2.98e-04 | 5.6%@S33  T=1.09s eta=06:39:06 | 72.1K token/s | 
[epoch_0]_39141  loss=3.234100 |g|=0.43	lr=2.97e-04 | 6.4%@S33  T=1.14s eta=06:57:20 | 72.1K token/s | 
[epoch_0]_39151  loss=3.272613 |g|=0.444	lr=2.97e-04 | 7.3%@S33  T=1.11s eta=06:45:29 | 72.1K token/s | 
[epoch_0]_39161  loss=3.293207 |g|=0.433	lr=2.97e-04 | 8.1%@S33  T=1.08s eta=06:34:09 | 72.3K token/s | 
[epoch_0]_39171  loss=3.269011 |g|=0.436	lr=2.97e-04 | 8.9%@S33  T=1.08s eta=06:33:27 | 72.5K token/s | 
[epoch_0]_39181  loss=3.235427 |g|=0.483	lr=2.97e-04 | 9.7%@S33  T=1.07s eta=06:28:28 | 72.7K token/s | 
[epoch_0]_39191  loss=3.385298 |g|=0.435	lr=2.96e-04 | 10.5%@S33  T=1.07s eta=06:28:43 | 72.9K token/s | 
[Fuyou] head="1" update algorithm=4 t=2.02s
[eval] 
	 Loss@"edu_fineweb1B"=3.275(0.0063) nBranch=1 nToken=4.01M best=3.2815(194) E2T=-0.036 T=13.4933(0)s x=0
	#3.27518±0.1068 tps=297K(4.01408M) a=[3.09714,3.56091] T=13.4933(sec)
[Section@39200] layer[12-18] tasks=15(nPassBack=0) last_loss=3.3112(-0.0515332) N=(580,33432,33012 3919900)
[epoch_0]_39201  loss=3.245882 |g|=0.424	lr=2.96e-04 | 11.4%@S33  T=4.21s eta=1d 01:33:20 | 70.2K token/s | 
[epoch_0]_39211  loss=3.284999 |g|=0.43	lr=2.96e-04 | 12.2%@S33  T=1.16s eta=07:00:15 | 70.3K token/s | 
[epoch_0]_39221  loss=3.373870 |g|=0.456	lr=2.96e-04 | 13.0%@S33  T=1.07s eta=06:30:26 | 70.6K token/s | 
[epoch_0]_39231  loss=3.361987 |g|=0.472	lr=2.95e-04 | 13.8%@S33  T=1.09s eta=06:34:30 | 70.8K token/s | 
[epoch_0]_39241  loss=3.259273 |g|=0.44	lr=2.95e-04 | 14.6%@S33  T=1.08s eta=06:33:36 | 71.1K token/s | 
[epoch_0]_39251  loss=3.304866 |g|=0.463	lr=2.95e-04 | 15.5%@S33  T=1.10s eta=06:40:39 | 71.2K token/s | 
[epoch_0]_39261  loss=3.336519 |g|=0.442	lr=2.95e-04 | 16.3%@S33  T=1.13s eta=06:50:53 | 71.3K token/s | 
[epoch_0]_39271  loss=3.299347 |g|=0.448	lr=2.94e-04 | 17.1%@S33  T=1.11s eta=06:42:29 | 71.4K token/s | 
[epoch_0]_39281  loss=3.285813 |g|=0.444	lr=2.94e-04 | 17.9%@S33  T=1.08s eta=06:31:57 | 71.6K token/s | 
[epoch_0]_39291  loss=3.300036 |g|=0.44	lr=2.94e-04 | 18.7%@S33  T=1.07s eta=06:29:15 | 71.9K token/s | 
[Fuyou] head="2" update algorithm=4 t=2.10s
[Section@39300] layer[18-24] tasks=15(nPassBack=0) last_loss=3.34929(-0.0477531) N=(580,33516,33096 3929900)
[epoch_0]_39301  loss=3.296635 |g|=0.428	lr=2.94e-04 | 19.5%@S33  T=1.58s eta=09:33:37 | 70.8K token/s | 
[epoch_0]_39311  loss=3.353424 |g|=0.445	lr=2.93e-04 | 20.4%@S33  T=1.07s eta=06:29:05 | 71.1K token/s | 
[epoch_0]_39321  loss=3.303237 |g|=0.429	lr=2.93e-04 | 21.2%@S33  T=1.13s eta=06:50:05 | 71.2K token/s | 
[epoch_0]_39331  loss=3.284768 |g|=0.437	lr=2.93e-04 | 22.0%@S33  T=1.07s eta=06:28:05 | 71.4K token/s | 
[epoch_0]_39341  loss=3.268842 |g|=0.431	lr=2.93e-04 | 22.8%@S33  T=1.08s eta=06:31:01 | 71.6K token/s | 
[epoch_0]_39351  loss=3.289113 |g|=0.441	lr=2.93e-04 | 23.6%@S33  T=1.08s eta=06:28:38 | 71.9K token/s | 
[epoch_0]_39361  loss=3.288546 |g|=0.422	lr=2.92e-04 | 24.5%@S33  T=1.09s eta=06:34:11 | 72.0K token/s | 
[epoch_0]_39371  loss=3.280477 |g|=0.427	lr=2.92e-04 | 25.3%@S33  T=1.08s eta=06:30:39 | 72.2K token/s | 
[epoch_0]_39381  loss=3.294548 |g|=0.451	lr=2.92e-04 | 26.1%@S33  T=1.09s eta=06:32:09 | 72.4K token/s | 
[epoch_0]_39391  loss=3.320912 |g|=0.444	lr=2.92e-04 | 26.9%@S33  T=1.10s eta=06:37:58 | 72.5K token/s | 
[Fuyou] head="3" update algorithm=4 t=2.31s
[eval] 
	 Loss@"edu_fineweb1B"=3.271(0.0039) nBranch=1 nToken=4.01M best=3.2752(195) E2T=-0.0459 T=13.4874(0)s x=0
	#3.27127±0.1063 tps=298K(4.01408M) a=[3.09227,3.55266] T=13.4874(sec)
[Section@39400] layer[24-30] tasks=15(nPassBack=0) last_loss=3.31716(0.0354555) N=(580,33600,33180 3939900)
[epoch_0]_39401  loss=3.291274 |g|=0.415	lr=2.91e-04 | 27.7%@S33  T=4.24s eta=1d 01:29:54 | 69.8K token/s | 
[epoch_0]_39411  loss=3.329463 |g|=0.417	lr=2.91e-04 | 28.6%@S33  T=1.15s eta=06:55:10 | 69.9K token/s | 
[epoch_0]_39421  loss=3.255407 |g|=0.434	lr=2.91e-04 | 29.4%@S33  T=1.07s eta=06:26:48 | 70.2K token/s | 
[epoch_0]_39431  loss=3.245946 |g|=0.45	lr=2.91e-04 | 30.2%@S33  T=1.08s eta=06:29:54 | 70.5K token/s | 
[epoch_0]_39441  loss=3.262361 |g|=0.446	lr=2.90e-04 | 31.0%@S33  T=1.09s eta=06:32:36 | 70.7K token/s | 
[epoch_0]_39451  loss=3.249918 |g|=0.462	lr=2.90e-04 | 31.8%@S33  T=1.09s eta=06:30:45 | 70.9K token/s | 
[epoch_0]_39461  loss=3.283366 |g|=0.469	lr=2.90e-04 | 32.7%@S33  T=1.13s eta=06:45:40 | 71.0K token/s | 
[epoch_0]_39471  loss=3.205954 |g|=0.46	lr=2.90e-04 | 33.5%@S33  T=1.12s eta=06:41:26 | 71.1K token/s | 
[epoch_0]_39481  loss=3.293550 |g|=0.436	lr=2.90e-04 | 34.3%@S33  T=1.09s eta=06:30:17 | 71.4K token/s | 
[epoch_0]_39491  loss=3.217384 |g|=0.457	lr=2.89e-04 | 35.1%@S33  T=1.07s eta=06:23:33 | 71.6K token/s | 
[Fuyou] head="4" update algorithm=4 t=2.16s
[Section@39500] layer[30-36] tasks=15(nPassBack=0) last_loss=3.25011(-0.0210702) N=(580,33684,33264 3949900)
[epoch_0]_39501  loss=3.303471 |g|=0.424	lr=2.89e-04 | 35.9%@S33  T=1.55s eta=09:16:05 | 70.7K token/s | 
[epoch_0]_39511  loss=3.281353 |g|=0.455	lr=2.89e-04 | 36.8%@S33  T=1.09s eta=06:31:09 | 70.9K token/s | 
[epoch_0]_39521  loss=3.242534 |g|=0.444	lr=2.89e-04 | 37.6%@S33  T=1.07s eta=06:25:11 | 71.2K token/s | 
[epoch_0]_39531  loss=3.239780 |g|=0.456	lr=2.88e-04 | 38.4%@S33  T=1.09s eta=06:31:20 | 71.4K token/s | 
[epoch_0]_39541  loss=3.295830 |g|=0.436	lr=2.88e-04 | 39.2%@S33  T=1.10s eta=06:34:04 | 71.5K token/s | 
[epoch_0]_39551  loss=3.251555 |g|=0.473	lr=2.88e-04 | 40.0%@S33  T=1.06s eta=06:19:47 | 71.8K token/s | 
[epoch_0]_39561  loss=3.293435 |g|=0.474	lr=2.88e-04 | 40.8%@S33  T=1.07s eta=06:22:44 | 72.0K token/s | 
[epoch_0]_39571  loss=3.297316 |g|=0.45	lr=2.87e-04 | 41.7%@S33  T=1.07s eta=06:22:41 | 72.3K token/s | 
[epoch_0]_39581  loss=3.298955 |g|=0.458	lr=2.87e-04 | 42.5%@S33  T=1.08s eta=06:24:48 | 72.5K token/s | 
[epoch_0]_39591  loss=3.266407 |g|=0.455	lr=2.87e-04 | 43.3%@S33  T=1.08s eta=06:26:54 | 72.6K token/s | 
[Fuyou] head="5" update algorithm=4 t=2.03s
[eval] 
	 Loss@"edu_fineweb1B"=3.269(0.0023) nBranch=1 nToken=4.01M best=3.2713(196) E2T=-0.0146 T=13.4895(0)s x=0
	#3.26898±0.1064 tps=298K(4.01408M) a=[3.09508,3.54742] T=13.4895(sec)
[Section@39600] layer[0-6] tasks=15(nPassBack=0) last_loss=3.28362(-0.00703478) N=(580,33768,33348 3959900)
[epoch_0]_39601  loss=3.280918 |g|=0.435	lr=2.87e-04 | 44.1%@S33  T=4.20s eta=1d 01:00:59 | 70.0K token/s | 
[epoch_0]_39611  loss=3.263952 |g|=0.438	lr=2.87e-04 | 44.9%@S33  T=1.10s eta=06:32:43 | 70.2K token/s | 
[epoch_0]_39621  loss=3.245681 |g|=0.429	lr=2.86e-04 | 45.8%@S33  T=1.07s eta=06:20:51 | 70.5K token/s | 
[epoch_0]_39631  loss=3.269640 |g|=0.453	lr=2.86e-04 | 46.6%@S33  T=1.08s eta=06:25:12 | 70.8K token/s | 
[epoch_0]_39641  loss=3.211985 |g|=0.412	lr=2.86e-04 | 47.4%@S33  T=1.10s eta=06:33:28 | 71.0K token/s | 
[epoch_0]_39651  loss=3.309481 |g|=0.43	lr=2.86e-04 | 48.2%@S33  T=1.13s eta=06:43:12 | 71.0K token/s | 
[epoch_0]_39661  loss=3.239129 |g|=0.423	lr=2.85e-04 | 49.0%@S33  T=1.06s eta=06:16:12 | 71.4K token/s | 
[epoch_0]_39671  loss=3.258679 |g|=0.425	lr=2.85e-04 | 49.9%@S33  T=1.08s eta=06:24:59 | 71.6K token/s | 
[epoch_0]_39681  loss=3.327517 |g|=0.452	lr=2.85e-04 | 50.7%@S33  T=1.08s eta=06:22:49 | 71.8K token/s | 
[epoch_0]_39691  loss=3.295558 |g|=0.433	lr=2.85e-04 | 51.5%@S33  T=1.07s eta=06:19:46 | 72.1K token/s | 
[Fuyou] head="0" update algorithm=4 t=2.09s
[Section@39700] layer[6-12] tasks=15(nPassBack=0) last_loss=3.34018(-0.0249794) N=(580,33852,33432 3969900)
[epoch_0]_39701  loss=3.261182 |g|=0.452	lr=2.84e-04 | 52.3%@S33  T=1.42s eta=08:26:33 | 71.3K token/s | 
[epoch_0]_39711  loss=3.303988 |g|=0.454	lr=2.84e-04 | 53.1%@S33  T=1.08s eta=06:23:29 | 71.6K token/s | 
[epoch_0]_39721  loss=3.234829 |g|=0.464	lr=2.84e-04 | 54.0%@S33  T=1.11s eta=06:34:56 | 71.7K token/s | 
[epoch_0]_39731  loss=3.249518 |g|=0.436	lr=2.84e-04 | 54.8%@S33  T=1.06s eta=06:16:14 | 71.9K token/s | 
[epoch_0]_39741  loss=3.274033 |g|=0.461	lr=2.84e-04 | 55.6%@S33  T=1.08s eta=06:21:54 | 72.2K token/s | 
[epoch_0]_39751  loss=3.348767 |g|=0.447	lr=2.83e-04 | 56.4%@S33  T=1.07s eta=06:18:47 | 72.4K token/s | 
[epoch_0]_39761  loss=3.306909 |g|=0.428	lr=2.83e-04 | 57.2%@S33  T=1.07s eta=06:19:37 | 72.6K token/s | 
[epoch_0]_39771  loss=3.285667 |g|=0.482	lr=2.83e-04 | 58.0%@S33  T=1.14s eta=06:42:23 | 72.6K token/s | 
[epoch_0]_39781  loss=3.283821 |g|=0.453	lr=2.83e-04 | 58.9%@S33  T=1.12s eta=06:38:00 | 72.6K token/s | 
[epoch_0]_39791  loss=3.270415 |g|=0.449	lr=2.82e-04 | 59.7%@S33  T=1.12s eta=06:36:15 | 72.6K token/s | 
[Fuyou] head="1" update algorithm=4 t=2.17s
[eval] 
	 Loss@"edu_fineweb1B"=3.266(0.0029) nBranch=1 nToken=4.01M best=3.2690(197) E2T=-0.0435 T=13.4778(0)s x=0
	#3.26607±0.1065 tps=298K(4.01408M) a=[3.08561,3.54658] T=13.4778(sec)
[Section@39800] layer[12-18] tasks=15(nPassBack=0) last_loss=3.30955(0.00165081) N=(580,33936,33516 3979900)
[epoch_0]_39801  loss=3.275221 |g|=0.45	lr=2.82e-04 | 60.5%@S33  T=4.22s eta=1d 00:51:46 | 70.0K token/s | 
[epoch_0]_39811  loss=3.196961 |g|=0.444	lr=2.82e-04 | 61.3%@S33  T=1.11s eta=06:33:14 | 70.1K token/s | 
[epoch_0]_39821  loss=3.289910 |g|=0.431	lr=2.82e-04 | 62.1%@S33  T=1.08s eta=06:22:25 | 70.4K token/s | 
[epoch_0]_39831  loss=3.278151 |g|=0.444	lr=2.81e-04 | 63.0%@S33  T=1.08s eta=06:23:05 | 70.7K token/s | 
[epoch_0]_39841  loss=3.292004 |g|=0.509	lr=2.81e-04 | 63.8%@S33  T=1.12s eta=06:36:54 | 70.8K token/s | 
[epoch_0]_39851  loss=3.228297 |g|=0.429	lr=2.81e-04 | 64.6%@S33  T=1.16s eta=06:50:05 | 70.8K token/s | 
[epoch_0]_39861  loss=3.243384 |g|=0.444	lr=2.81e-04 | 65.4%@S33  T=1.10s eta=06:29:20 | 71.0K token/s | 
[epoch_0]_39871  loss=3.269496 |g|=0.541	lr=2.81e-04 | 66.2%@S33  T=1.07s eta=06:17:25 | 71.2K token/s | 
[epoch_0]_39881  loss=3.321637 |g|=0.497	lr=2.80e-04 | 67.1%@S33  T=1.09s eta=06:22:44 | 71.4K token/s | 
[epoch_0]_39891  loss=3.304343 |g|=0.465	lr=2.80e-04 | 67.9%@S33  T=1.06s eta=06:15:18 | 71.7K token/s | 
[Fuyou] head="2" update algorithm=4 t=2.11s
[Section@39900] layer[18-24] tasks=15(nPassBack=0) last_loss=3.31294(0.0363503) N=(580,34020,33600 3989900)
[epoch_0]_39901  loss=3.233325 |g|=0.42	lr=2.80e-04 | 68.7%@S33  T=1.36s eta=08:00:15 | 71.1K token/s | 
[epoch_0]_39911  loss=3.239549 |g|=0.44	lr=2.80e-04 | 69.5%@S33  T=1.06s eta=06:14:45 | 71.4K token/s | 
[epoch_0]_39921  loss=3.255945 |g|=0.425	lr=2.79e-04 | 70.3%@S33  T=1.08s eta=06:20:32 | 71.6K token/s | 
[epoch_0]_39931  loss=3.337192 |g|=0.431	lr=2.79e-04 | 71.2%@S33  T=1.06s eta=06:14:06 | 71.9K token/s | 
[epoch_0]_39941  loss=3.303218 |g|=0.428	lr=2.79e-04 | 72.0%@S33  T=1.09s eta=06:22:31 | 72.1K token/s | 
[epoch_0]_39951  loss=3.279557 |g|=0.442	lr=2.79e-04 | 72.8%@S33  T=1.07s eta=06:17:34 | 72.3K token/s | 
[epoch_0]_39961  loss=3.205146 |g|=0.471	lr=2.78e-04 | 73.6%@S33  T=1.12s eta=06:34:38 | 72.3K token/s | 
[epoch_0]_39971  loss=3.325115 |g|=0.475	lr=2.78e-04 | 74.4%@S33  T=1.11s eta=06:28:05 | 72.4K token/s | 
[epoch_0]_39981  loss=3.162498 |g|=0.445	lr=2.78e-04 | 75.3%@S33  T=1.08s eta=06:18:06 | 72.6K token/s | 
[epoch_0]_39991  loss=3.218996 |g|=0.433	lr=2.78e-04 | 76.1%@S33  T=1.07s eta=06:15:02 | 72.8K token/s | 
[Fuyou] head="3" update algorithm=4 t=2.00s
[eval] 
	 Loss@"edu_fineweb1B"=3.264(0.002) nBranch=1 nToken=4.01M best=3.2661(198) E2T=0.00149 T=13.4866(0)s x=0
	#3.26404±0.1061 tps=298K(4.01408M) a=[3.08481,3.54752] T=13.4866(sec)
[Section@40000] layer[24-30] tasks=15(nPassBack=0) last_loss=3.26255(0.0546131) N=(580,34104,33684 3999900)
[epoch_0]_40001  loss=3.319048 |g|=0.425	lr=2.78e-04 | 76.9%@S33  T=4.21s eta=1d 00:37:32 | 70.1K token/s | 
[epoch_0]_40011  loss=3.257128 |g|=0.457	lr=2.77e-04 | 77.7%@S33  T=1.07s eta=06:15:04 | 70.4K token/s | 
[epoch_0]_40021  loss=3.336847 |g|=0.446	lr=2.77e-04 | 78.5%@S33  T=1.11s eta=06:28:03 | 70.6K token/s | 
[epoch_0]_40031  loss=3.284568 |g|=0.473	lr=2.77e-04 | 79.3%@S33  T=1.11s eta=06:29:14 | 70.8K token/s | 
[epoch_0]_40041  loss=3.252715 |g|=0.446	lr=2.77e-04 | 80.2%@S33  T=1.07s eta=06:14:51 | 71.1K token/s | 
[epoch_0]_40051  loss=3.199034 |g|=0.44	lr=2.76e-04 | 81.0%@S33  T=1.07s eta=06:14:26 | 71.3K token/s | 
[epoch_0]_40061  loss=3.334857 |g|=0.433	lr=2.76e-04 | 81.8%@S33  T=1.06s eta=06:11:47 | 71.6K token/s | 
[epoch_0]_40071  loss=3.288848 |g|=0.452	lr=2.76e-04 | 82.6%@S33  T=1.07s eta=06:12:33 | 71.9K token/s | 
[epoch_0]_40081  loss=3.217177 |g|=0.466	lr=2.76e-04 | 83.4%@S33  T=1.08s eta=06:17:11 | 72.1K token/s | 
[epoch_0]_40091  loss=3.324600 |g|=0.463	lr=2.76e-04 | 84.3%@S33  T=1.12s eta=06:30:27 | 72.1K token/s | 
[Fuyou] head="4" update algorithm=4 t=2.08s
[Section@40100] layer[30-36] tasks=15(nPassBack=0) last_loss=3.34435(-0.0942495) N=(580,34188,33768 4009900)
[epoch_0]_40101  loss=3.247432 |g|=0.423	lr=2.75e-04 | 85.1%@S33  T=1.48s eta=08:36:36 | 71.3K token/s | 
[epoch_0]_40111  loss=3.284545 |g|=0.444	lr=2.75e-04 | 85.9%@S33  T=1.07s eta=06:13:36 | 71.5K token/s | 
[epoch_0]_40121  loss=3.210375 |g|=0.426	lr=2.75e-04 | 86.7%@S33  T=1.07s eta=06:12:33 | 71.8K token/s | 
[epoch_0]_40131  loss=3.372251 |g|=0.43	lr=2.75e-04 | 87.5%@S33  T=1.07s eta=06:12:46 | 72.0K token/s | 
[epoch_0]_40141  loss=3.225592 |g|=0.426	lr=2.74e-04 | 88.4%@S33  T=1.10s eta=06:22:37 | 72.2K token/s | 
[epoch_0]_40151  loss=3.256485 |g|=0.467	lr=2.74e-04 | 89.2%@S33  T=1.16s eta=06:43:05 | 72.1K token/s | 
[epoch_0]_40161  loss=3.258464 |g|=0.483	lr=2.74e-04 | 90.0%@S33  T=1.10s eta=06:23:16 | 72.2K token/s | 
[epoch_0]_40171  loss=3.331856 |g|=0.455	lr=2.74e-04 | 90.8%@S33  T=1.08s eta=06:16:32 | 72.4K token/s | 
[epoch_0]_40181  loss=3.302253 |g|=0.453	lr=2.73e-04 | 91.6%@S33  T=1.09s eta=06:19:25 | 72.5K token/s | 
[epoch_0]_40191  loss=3.276660 |g|=0.459	lr=2.73e-04 | 92.5%@S33  T=1.08s eta=06:16:09 | 72.7K token/s | 
[Fuyou] head="5" update algorithm=4 t=2.08s
[eval] 
	 Loss@"edu_fineweb1B"=3.262(0.0025) nBranch=1 nToken=4.01M best=3.2640(199) E2T=-0.0566 T=13.4778(0)s x=0
	#3.26153±0.1070 tps=298K(4.01408M) a=[3.08321,3.54906] T=13.4778(sec)
[Section@40200] layer[0-6] tasks=15(nPassBack=0) last_loss=3.31816(-0.0345433) N=(580,34272,33852 4019900)
[epoch_0]_40201  loss=3.241456 |g|=0.432	lr=2.73e-04 | 93.3%@S33  T=4.21s eta=1d 00:23:01 | 70.0K token/s | 
[epoch_0]_40211  loss=3.289931 |g|=0.453	lr=2.73e-04 | 94.1%@S33  T=1.16s eta=06:40:52 | 70.1K token/s | 
[epoch_0]_40221  loss=3.274789 |g|=0.422	lr=2.73e-04 | 94.9%@S33  T=1.07s eta=06:11:58 | 70.4K token/s | 
[epoch_0]_40231  loss=3.333207 |g|=0.439	lr=2.72e-04 | 95.7%@S33  T=1.09s eta=06:18:00 | 70.6K token/s | 
[epoch_0]_40241  loss=3.255891 |g|=0.419	lr=2.72e-04 | 96.6%@S33  T=1.08s eta=06:15:29 | 70.9K token/s | 
[epoch_0]_40251  loss=3.258628 |g|=0.452	lr=2.72e-04 | 97.4%@S33  T=1.11s eta=06:25:46 | 71.0K token/s | 
[epoch_0]_40261  loss=3.245954 |g|=0.455	lr=2.72e-04 | 98.2%@S33  T=1.13s eta=06:31:43 | 71.1K token/s | 
[epoch_0]_40271  loss=3.278069 |g|=0.448	lr=2.71e-04 | 99.0%@S33  T=1.11s eta=06:22:56 | 71.2K token/s | 
[epoch_0]_40281  loss=3.202888 |g|=0.456	lr=2.71e-04 | 99.8%@S33  T=1.08s eta=06:12:59 | 71.5K token/s | 
[epoch_0]_40283  loss=3.269214 |g|=0.46	lr=2.71e-04 | 100.0%@S33  T=1.13s eta=06:29:34 | 71.5K token/s | 
-------- End of shard_33@"./Datasets/edu_fineweb1B/edu_fineweb_train_000486.bin"-------- 
[shard-34]@"./Datasets/edu_fineweb1B/edu_fineweb_train_000487.bin": tokens=100(M) nShardSamples=1220(3320304) 
[epoch_0]_40291  loss=3.268746 |g|=0.454	lr=2.71e-04 | 0.6%@S34  T=1.07s eta=06:10:08 | 71.8K token/s | 
[Fuyou] head="0" update algorithm=4 t=2.10s
[Section@40300] layer[6-12] tasks=15(nPassBack=0) last_loss=3.29298(0.0472016) N=(580,34356,33936 4029900)
[epoch_0]_40301  loss=3.324517 |g|=0.443	lr=2.71e-04 | 1.5%@S34  T=1.36s eta=07:48:40 | 71.2K token/s | 
[epoch_0]_40311  loss=3.262435 |g|=0.431	lr=2.71e-04 | 2.3%@S34  T=1.07s eta=06:10:09 | 71.5K token/s | 
[epoch_0]_40321  loss=3.298288 |g|=0.444	lr=2.70e-04 | 3.1%@S34  T=1.08s eta=06:12:51 | 71.7K token/s | 
[epoch_0]_40331  loss=3.333539 |g|=0.463	lr=2.70e-04 | 3.9%@S34  T=1.08s eta=06:11:34 | 71.9K token/s | 
[epoch_0]_40341  loss=3.273057 |g|=0.443	lr=2.70e-04 | 4.7%@S34  T=1.12s eta=06:27:47 | 71.9K token/s | 
[epoch_0]_40351  loss=3.298840 |g|=0.442	lr=2.70e-04 | 5.6%@S34  T=1.09s eta=06:14:47 | 72.1K token/s | 
[epoch_0]_40361  loss=3.303349 |g|=0.427	lr=2.69e-04 | 6.4%@S34  T=1.08s eta=06:13:00 | 72.3K token/s | 
[epoch_0]_40371  loss=3.221990 |g|=0.431	lr=2.69e-04 | 7.2%@S34  T=1.13s eta=06:30:35 | 72.3K token/s | 
[epoch_0]_40381  loss=3.279603 |g|=0.416	lr=2.69e-04 | 8.0%@S34  T=1.08s eta=06:11:00 | 72.5K token/s | 
[epoch_0]_40391  loss=3.299160 |g|=0.436	lr=2.69e-04 | 8.8%@S34  T=1.06s eta=06:05:28 | 72.7K token/s | 
[Fuyou] head="1" update algorithm=4 t=2.08s
[eval] 
	 Loss@"edu_fineweb1B"=3.265(-0.0031) nBranch=1 nToken=4.01M best=3.2640(199) E2T=-0.0261 T=13.4857(0)s x=0
	#3.26464±0.1074 tps=298K(4.01408M) a=[3.08557,3.55517] T=13.4857(sec)
[Section@40400] layer[12-18] tasks=15(nPassBack=0) last_loss=3.29074(0.0188155) N=(580,34440,34020 4039900)
[epoch_0]_40401  loss=3.363222 |g|=0.463	lr=2.68e-04 | 9.7%@S34  T=4.20s eta=1d 00:03:23 | 70.1K token/s | 
[epoch_0]_40411  loss=3.303089 |g|=0.448	lr=2.68e-04 | 10.5%@S34  T=1.08s eta=06:11:50 | 70.3K token/s | 
[epoch_0]_40421  loss=3.298979 |g|=0.465	lr=2.68e-04 | 11.3%@S34  T=1.07s eta=06:08:00 | 70.6K token/s | 
[epoch_0]_40431  loss=3.250163 |g|=0.44	lr=2.68e-04 | 12.1%@S34  T=1.06s eta=06:02:53 | 71.0K token/s | 
[epoch_0]_40441  loss=3.284826 |g|=0.426	lr=2.68e-04 | 12.9%@S34  T=1.07s eta=06:06:30 | 71.3K token/s | 
[epoch_0]_40451  loss=3.266910 |g|=0.444	lr=2.67e-04 | 13.8%@S34  T=1.10s eta=06:16:18 | 71.4K token/s | 
[epoch_0]_40461  loss=3.231896 |g|=0.429	lr=2.67e-04 | 14.6%@S34  T=1.08s eta=06:10:33 | 71.7K token/s | 
[epoch_0]_40471  loss=3.238588 |g|=0.43	lr=2.67e-04 | 15.4%@S34  T=1.06s eta=06:04:35 | 71.9K token/s | 
[epoch_0]_40481  loss=3.284217 |g|=0.418	lr=2.67e-04 | 16.2%@S34  T=1.11s eta=06:21:29 | 72.0K token/s | 
[epoch_0]_40491  loss=3.260853 |g|=0.448	lr=2.66e-04 | 17.0%@S34  T=1.06s eta=06:03:55 | 72.3K token/s | 
[Fuyou] head="2" update algorithm=4 t=2.07s
[Section@40500] layer[18-24] tasks=15(nPassBack=0) last_loss=3.26497(0.047971) N=(580,34524,34104 4049900)
[epoch_0]_40501  loss=3.210695 |g|=0.441	lr=2.66e-04 | 17.9%@S34  T=1.57s eta=08:56:38 | 71.3K token/s | 
[epoch_0]_40511  loss=3.267940 |g|=0.418	lr=2.66e-04 | 18.7%@S34  T=1.07s eta=06:06:35 | 71.5K token/s | 
[epoch_0]_40521  loss=3.313730 |g|=0.458	lr=2.66e-04 | 19.5%@S34  T=1.07s eta=06:06:34 | 71.8K token/s | 
[epoch_0]_40531  loss=3.307260 |g|=0.514	lr=2.66e-04 | 20.3%@S34  T=1.08s eta=06:07:45 | 72.0K token/s | 
[epoch_0]_40541  loss=3.236415 |g|=0.46	lr=2.65e-04 | 21.1%@S34  T=1.08s eta=06:07:56 | 72.2K token/s | 
[epoch_0]_40551  loss=3.255550 |g|=0.451	lr=2.65e-04 | 21.9%@S34  T=1.06s eta=06:01:56 | 72.4K token/s | 
[epoch_0]_40561  loss=3.298766 |g|=0.455	lr=2.65e-04 | 22.8%@S34  T=1.06s eta=06:01:34 | 72.7K token/s | 
[epoch_0]_40571  loss=3.305679 |g|=0.438	lr=2.65e-04 | 23.6%@S34  T=1.10s eta=06:15:26 | 72.8K token/s | 
[epoch_0]_40581  loss=3.282229 |g|=0.485	lr=2.64e-04 | 24.4%@S34  T=1.07s eta=06:05:11 | 73.0K token/s | 
[epoch_0]_40591  loss=3.315515 |g|=0.436	lr=2.64e-04 | 25.2%@S34  T=1.08s eta=06:07:14 | 73.1K token/s | 
[Fuyou] head="3" update algorithm=4 t=2.07s
[eval] 
	 Loss@"edu_fineweb1B"=3.264(0.00096) nBranch=1 nToken=4.01M best=3.2646(201) E2T=-0.0446 T=13.4854(0)s x=0
	#3.26368±0.1072 tps=298K(4.01408M) a=[3.08467,3.54958] T=13.4854(sec)
[Section@40600] layer[24-30] tasks=15(nPassBack=0) last_loss=3.3083(-0.0457561) N=(580,34608,34188 4059900)
[epoch_0]_40601  loss=3.305798 |g|=0.435	lr=2.64e-04 | 26.0%@S34  T=4.19s eta=23:48:23 | 70.4K token/s | 
[epoch_0]_40611  loss=3.292161 |g|=0.431	lr=2.64e-04 | 26.9%@S34  T=1.09s eta=06:09:53 | 70.7K token/s | 
[epoch_0]_40621  loss=3.326154 |g|=0.437	lr=2.64e-04 | 27.7%@S34  T=1.07s eta=06:03:28 | 71.0K token/s | 
[epoch_0]_40631  loss=3.237702 |g|=0.427	lr=2.63e-04 | 28.5%@S34  T=1.05s eta=05:58:39 | 71.3K token/s | 
[epoch_0]_40641  loss=3.290768 |g|=0.436	lr=2.63e-04 | 29.3%@S34  T=1.07s eta=06:02:24 | 71.6K token/s | 
[epoch_0]_40651  loss=3.320829 |g|=0.435	lr=2.63e-04 | 30.1%@S34  T=1.11s eta=06:17:46 | 71.7K token/s | 
[epoch_0]_40661  loss=3.329065 |g|=0.444	lr=2.63e-04 | 31.0%@S34  T=1.08s eta=06:06:43 | 71.9K token/s | 
[epoch_0]_40671  loss=3.293539 |g|=0.448	lr=2.62e-04 | 31.8%@S34  T=1.06s eta=05:58:40 | 72.2K token/s | 
[epoch_0]_40681  loss=3.252475 |g|=0.47	lr=2.62e-04 | 32.6%@S34  T=1.07s eta=06:03:25 | 72.4K token/s | 
[epoch_0]_40691  loss=3.196191 |g|=0.428	lr=2.62e-04 | 33.4%@S34  T=1.07s eta=06:02:45 | 72.6K token/s | 
[Fuyou] head="4" update algorithm=4 t=2.08s
[Section@40700] layer[30-36] tasks=15(nPassBack=0) last_loss=3.22837(0.115981) N=(580,34692,34272 4069900)
[epoch_0]_40701  loss=3.258121 |g|=0.453	lr=2.62e-04 | 34.2%@S34  T=1.49s eta=08:26:22 | 71.7K token/s | 
[epoch_0]_40711  loss=3.247612 |g|=0.452	lr=2.61e-04 | 35.1%@S34  T=1.08s eta=06:04:22 | 71.9K token/s | 
[epoch_0]_40721  loss=3.293870 |g|=0.426	lr=2.61e-04 | 35.9%@S34  T=1.10s eta=06:11:53 | 72.1K token/s | 
[epoch_0]_40731  loss=3.228962 |g|=0.414	lr=2.61e-04 | 36.7%@S34  T=1.07s eta=06:02:33 | 72.3K token/s | 
[epoch_0]_40741  loss=3.314496 |g|=0.488	lr=2.61e-04 | 37.5%@S34  T=1.08s eta=06:05:09 | 72.5K token/s | 
[epoch_0]_40751  loss=3.292493 |g|=0.453	lr=2.61e-04 | 38.3%@S34  T=1.09s eta=06:08:03 | 72.6K token/s | 
[epoch_0]_40761  loss=3.276694 |g|=0.445	lr=2.60e-04 | 39.2%@S34  T=1.06s eta=05:59:16 | 72.8K token/s | 
[epoch_0]_40771  loss=3.297796 |g|=0.427	lr=2.60e-04 | 40.0%@S34  T=1.06s eta=05:59:35 | 73.0K token/s | 
[epoch_0]_40781  loss=3.303664 |g|=0.448	lr=2.60e-04 | 40.8%@S34  T=1.13s eta=06:21:21 | 73.0K token/s | 
[epoch_0]_40791  loss=3.282421 |g|=0.433	lr=2.60e-04 | 41.6%@S34  T=1.08s eta=06:05:46 | 73.1K token/s | 
[Fuyou] head="5" update algorithm=4 t=2.07s
[eval] 
	 Loss@"edu_fineweb1B"=3.262(0.0013) nBranch=1 nToken=4.01M best=3.2637(202) E2T=-0.00113 T=13.4901(0)s x=0
	#3.26239±0.1075 tps=298K(4.01408M) a=[3.08333,3.55237] T=13.4901(sec)
[Section@40800] layer[0-6] tasks=15(nPassBack=0) last_loss=3.26352(0.0546401) N=(580,34776,34356 4079900)
[epoch_0]_40801  loss=3.244205 |g|=0.439	lr=2.59e-04 | 42.4%@S34  T=4.25s eta=23:51:40 | 70.4K token/s | 
[epoch_0]_40811  loss=3.271194 |g|=0.43	lr=2.59e-04 | 43.2%@S34  T=1.07s eta=05:59:33 | 70.8K token/s | 
[epoch_0]_40821  loss=3.266942 |g|=0.469	lr=2.59e-04 | 44.1%@S34  T=1.11s eta=06:13:54 | 70.9K token/s | 
[epoch_0]_40831  loss=3.225775 |g|=0.445	lr=2.59e-04 | 44.9%@S34  T=1.09s eta=06:08:37 | 71.1K token/s | 
[epoch_0]_40841  loss=3.239630 |g|=0.442	lr=2.59e-04 | 45.7%@S34  T=1.08s eta=06:02:21 | 71.4K token/s | 
[epoch_0]_40851  loss=3.265378 |g|=0.443	lr=2.58e-04 | 46.5%@S34  T=1.08s eta=06:04:47 | 71.6K token/s | 
[epoch_0]_40861  loss=3.312479 |g|=0.455	lr=2.58e-04 | 47.3%@S34  T=1.11s eta=06:12:24 | 71.7K token/s | 
[epoch_0]_40871  loss=3.153060 |g|=0.44	lr=2.58e-04 | 48.2%@S34  T=1.07s eta=05:58:12 | 71.9K token/s | 
[epoch_0]_40881  loss=3.331140 |g|=0.44	lr=2.58e-04 | 49.0%@S34  T=1.06s eta=05:56:58 | 72.2K token/s | 
[epoch_0]_40891  loss=3.289127 |g|=0.429	lr=2.57e-04 | 49.8%@S34  T=1.11s eta=06:14:00 | 72.3K token/s | 
[Fuyou] head="0" update algorithm=4 t=2.18s
[Section@40900] layer[6-12] tasks=15(nPassBack=0) last_loss=3.24581(0.0471659) N=(580,34860,34440 4089900)
[epoch_0]_40901  loss=3.284345 |g|=0.438	lr=2.57e-04 | 50.6%@S34  T=1.54s eta=08:35:21 | 71.3K token/s | 
[epoch_0]_40911  loss=3.191437 |g|=0.435	lr=2.57e-04 | 51.4%@S34  T=1.07s eta=05:58:40 | 71.6K token/s | 
[epoch_0]_40921  loss=3.232829 |g|=0.445	lr=2.57e-04 | 52.3%@S34  T=1.10s eta=06:09:53 | 71.7K token/s | 
[epoch_0]_40931  loss=3.241203 |g|=0.421	lr=2.57e-04 | 53.1%@S34  T=1.07s eta=05:59:21 | 72.0K token/s | 
[epoch_0]_40941  loss=3.236030 |g|=0.422	lr=2.56e-04 | 53.9%@S34  T=1.07s eta=05:58:26 | 72.2K token/s | 
[epoch_0]_40951  loss=3.292826 |g|=0.428	lr=2.56e-04 | 54.7%@S34  T=1.08s eta=06:01:16 | 72.4K token/s | 
[epoch_0]_40961  loss=3.261024 |g|=0.487	lr=2.56e-04 | 55.5%@S34  T=1.07s eta=05:58:55 | 72.6K token/s | 
[epoch_0]_40971  loss=3.202568 |g|=0.429	lr=2.56e-04 | 56.4%@S34  T=1.07s eta=05:58:09 | 72.8K token/s | 
[epoch_0]_40981  loss=3.281173 |g|=0.425	lr=2.55e-04 | 57.2%@S34  T=1.10s eta=06:08:28 | 72.8K token/s | 
[epoch_0]_40991  loss=3.300132 |g|=0.441	lr=2.55e-04 | 58.0%@S34  T=1.08s eta=06:01:31 | 73.0K token/s | 
[Fuyou] head="1" update algorithm=4 t=2.08s
[eval] 
	 Loss@"edu_fineweb1B"=3.263(-0.00086) nBranch=1 nToken=4.01M best=3.2624(203) E2T=-0.0662 T=13.4873(0)s x=0
	#3.26326±0.1083 tps=298K(4.01408M) a=[3.08008,3.55757] T=13.4873(sec)
[Section@41000] layer[12-18] tasks=15(nPassBack=0) last_loss=3.32945(-0.0387185) N=(580,34944,34524 4099900)
[epoch_0]_41001  loss=3.283886 |g|=0.449	lr=2.55e-04 | 58.8%@S34  T=4.21s eta=23:25:38 | 70.3K token/s | 
[epoch_0]_41011  loss=3.235073 |g|=0.438	lr=2.55e-04 | 59.6%@S34  T=1.06s eta=05:54:02 | 70.7K token/s | 
[epoch_0]_41021  loss=3.287249 |g|=0.434	lr=2.55e-04 | 60.4%@S34  T=1.08s eta=06:00:29 | 70.9K token/s | 
[epoch_0]_41031  loss=3.266163 |g|=0.447	lr=2.54e-04 | 61.3%@S34  T=1.11s eta=06:09:04 | 71.1K token/s | 
[epoch_0]_41041  loss=3.369261 |g|=0.445	lr=2.54e-04 | 62.1%@S34  T=1.07s eta=05:58:03 | 71.3K token/s | 
[epoch_0]_41051  loss=3.347274 |g|=0.517	lr=2.54e-04 | 62.9%@S34  T=1.09s eta=06:01:23 | 71.5K token/s | 
[epoch_0]_41061  loss=3.195613 |g|=0.428	lr=2.54e-04 | 63.7%@S34  T=1.15s eta=06:21:17 | 71.5K token/s | 
[epoch_0]_41071  loss=3.309564 |g|=0.462	lr=2.53e-04 | 64.5%@S34  T=1.07s eta=05:56:02 | 71.8K token/s | 
[epoch_0]_41081  loss=3.286294 |g|=0.449	lr=2.53e-04 | 65.4%@S34  T=1.07s eta=05:55:24 | 72.0K token/s | 
[epoch_0]_41091  loss=3.209999 |g|=0.444	lr=2.53e-04 | 66.2%@S34  T=1.10s eta=06:07:01 | 72.1K token/s | 
[Fuyou] head="2" update algorithm=4 t=2.08s
[Section@41100] layer[18-24] tasks=15(nPassBack=0) last_loss=3.29153(-0.0265605) N=(580,35028,34608 4109900)
[epoch_0]_41101  loss=3.224005 |g|=0.449	lr=2.53e-04 | 67.0%@S34  T=1.61s eta=08:53:20 | 71.1K token/s | 
[epoch_0]_41111  loss=3.227756 |g|=0.429	lr=2.53e-04 | 67.8%@S34  T=1.08s eta=05:58:13 | 71.3K token/s | 
[epoch_0]_41121  loss=3.285426 |g|=0.49	lr=2.52e-04 | 68.6%@S34  T=1.10s eta=06:05:01 | 71.5K token/s | 
[epoch_0]_41131  loss=3.278160 |g|=0.424	lr=2.52e-04 | 69.5%@S34  T=1.07s eta=05:55:25 | 71.7K token/s | 
[epoch_0]_41141  loss=3.283247 |g|=0.439	lr=2.52e-04 | 70.3%@S34  T=1.08s eta=05:57:38 | 71.9K token/s | 
[epoch_0]_41151  loss=3.257450 |g|=0.476	lr=2.52e-04 | 71.1%@S34  T=1.08s eta=05:58:55 | 72.1K token/s | 
[epoch_0]_41161  loss=3.338037 |g|=0.446	lr=2.51e-04 | 71.9%@S34  T=1.10s eta=06:03:35 | 72.3K token/s | 
[epoch_0]_41171  loss=3.265719 |g|=0.441	lr=2.51e-04 | 72.7%@S34  T=1.06s eta=05:52:14 | 72.5K token/s | 
[epoch_0]_41181  loss=3.282596 |g|=0.463	lr=2.51e-04 | 73.6%@S34  T=1.09s eta=06:01:32 | 72.6K token/s | 
[epoch_0]_41191  loss=3.210882 |g|=0.443	lr=2.51e-04 | 74.4%@S34  T=1.14s eta=06:18:41 | 72.6K token/s | 
[Fuyou] head="3" update algorithm=4 t=2.08s
[eval] 
	 Loss@"edu_fineweb1B"=3.261(0.0019) nBranch=1 nToken=4.01M best=3.2633(204) E2T=1.84e-05 T=13.489(0)s x=0
	#3.26134±0.1081 tps=298K(4.01408M) a=[3.08476,3.5536] T=13.489(sec)
[Section@41200] layer[24-30] tasks=15(nPassBack=0) last_loss=3.26132(0.0469818) N=(580,35112,34692 4119900)
[epoch_0]_41201  loss=3.310816 |g|=0.446	lr=2.51e-04 | 75.2%@S34  T=4.22s eta=23:14:23 | 69.9K token/s | 
[epoch_0]_41211  loss=3.232019 |g|=0.428	lr=2.50e-04 | 76.0%@S34  T=1.07s eta=05:54:01 | 70.2K token/s | 
[epoch_0]_41221  loss=3.205754 |g|=0.441	lr=2.50e-04 | 76.8%@S34  T=1.09s eta=05:58:55 | 70.5K token/s | 
[epoch_0]_41231  loss=3.274247 |g|=0.459	lr=2.50e-04 | 77.7%@S34  T=1.08s eta=05:58:03 | 70.7K token/s | 
[epoch_0]_41241  loss=3.257637 |g|=0.461	lr=2.50e-04 | 78.5%@S34  T=1.09s eta=06:00:03 | 71.0K token/s | 
[epoch_0]_41251  loss=3.276460 |g|=0.448	lr=2.49e-04 | 79.3%@S34  T=1.12s eta=06:07:45 | 71.1K token/s | 
[epoch_0]_41261  loss=3.312054 |g|=0.44	lr=2.49e-04 | 80.1%@S34  T=1.09s eta=05:58:44 | 71.3K token/s | 
[epoch_0]_41271  loss=3.235687 |g|=0.461	lr=2.49e-04 | 80.9%@S34  T=1.08s eta=05:56:15 | 71.5K token/s | 
[epoch_0]_41281  loss=3.271490 |g|=0.438	lr=2.49e-04 | 81.7%@S34  T=1.14s eta=06:15:16 | 71.5K token/s | 
[epoch_0]_41291  loss=3.338550 |g|=0.463	lr=2.49e-04 | 82.6%@S34  T=1.06s eta=05:49:48 | 71.8K token/s | 
[Fuyou] head="4" update algorithm=4 t=2.14s
[Section@41300] layer[30-36] tasks=15(nPassBack=0) last_loss=3.2926(-0.0642235) N=(580,35196,34776 4129900)
[epoch_0]_41301  loss=3.270219 |g|=0.457	lr=2.48e-04 | 83.4%@S34  T=1.42s eta=07:48:21 | 71.1K token/s | 
[epoch_0]_41311  loss=3.272955 |g|=0.459	lr=2.48e-04 | 84.2%@S34  T=1.05s eta=05:43:46 | 71.5K token/s | 
[epoch_0]_41321  loss=3.325883 |g|=0.472	lr=2.48e-04 | 85.0%@S34  T=1.08s eta=05:54:14 | 71.7K token/s | 
[epoch_0]_41331  loss=3.231641 |g|=0.418	lr=2.48e-04 | 85.8%@S34  T=1.09s eta=05:57:42 | 71.9K token/s | 
[epoch_0]_41341  loss=3.292717 |g|=0.442	lr=2.48e-04 | 86.7%@S34  T=1.11s eta=06:04:15 | 72.0K token/s | 
[epoch_0]_41351  loss=3.269257 |g|=0.452	lr=2.47e-04 | 87.5%@S34  T=1.06s eta=05:49:17 | 72.2K token/s | 
[epoch_0]_41361  loss=3.260993 |g|=0.437	lr=2.47e-04 | 88.3%@S34  T=1.08s eta=05:55:22 | 72.4K token/s | 
[epoch_0]_41371  loss=3.250135 |g|=0.427	lr=2.47e-04 | 89.1%@S34  T=1.12s eta=06:05:47 | 72.4K token/s | 
[epoch_0]_41381  loss=3.299805 |g|=0.481	lr=2.47e-04 | 89.9%@S34  T=1.07s eta=05:51:05 | 72.6K token/s | 
[epoch_0]_41391  loss=3.229942 |g|=0.469	lr=2.46e-04 | 90.8%@S34  T=1.08s eta=05:53:47 | 72.8K token/s | 
[Fuyou] head="5" update algorithm=4 t=2.07s
[eval] 
	 Loss@"edu_fineweb1B"=3.260(0.0013) nBranch=1 nToken=4.01M best=3.2613(205) E2T=0.0279 T=13.4887(0)s x=0
	#3.26005±0.1078 tps=298K(4.01408M) a=[3.08537,3.55447] T=13.4887(sec)
[Section@41400] layer[0-6] tasks=15(nPassBack=0) last_loss=3.23213(0.0313921) N=(580,35280,34860 4139900)
[epoch_0]_41401  loss=3.305109 |g|=0.445	lr=2.46e-04 | 91.6%@S34  T=4.20s eta=22:55:04 | 70.1K token/s | 
[epoch_0]_41411  loss=3.197367 |g|=0.442	lr=2.46e-04 | 92.4%@S34  T=1.06s eta=05:46:44 | 70.5K token/s | 
[epoch_0]_41421  loss=3.208998 |g|=0.47	lr=2.46e-04 | 93.2%@S34  T=1.08s eta=05:52:50 | 70.7K token/s | 
[epoch_0]_41431  loss=3.224011 |g|=0.5	lr=2.46e-04 | 94.0%@S34  T=1.08s eta=05:52:19 | 71.0K token/s | 
[epoch_0]_41441  loss=3.213713 |g|=0.498	lr=2.45e-04 | 94.9%@S34  T=1.10s eta=05:58:58 | 71.2K token/s | 
[epoch_0]_41451  loss=3.234639 |g|=0.445	lr=2.45e-04 | 95.7%@S34  T=1.10s eta=05:58:43 | 71.4K token/s | 
[epoch_0]_41461  loss=3.278978 |g|=0.457	lr=2.45e-04 | 96.5%@S34  T=1.08s eta=05:53:54 | 71.6K token/s | 
[epoch_0]_41471  loss=3.260475 |g|=0.455	lr=2.45e-04 | 97.3%@S34  T=1.09s eta=05:55:00 | 71.7K token/s | 
[epoch_0]_41481  loss=3.147107 |g|=0.443	lr=2.44e-04 | 98.1%@S34  T=1.14s eta=06:11:43 | 71.7K token/s | 
[epoch_0]_41491  loss=3.300280 |g|=0.469	lr=2.44e-04 | 99.0%@S34  T=1.07s eta=05:49:57 | 72.0K token/s | 
[Fuyou] head="0" update algorithm=4 t=2.09s
[Section@41500] layer[6-12] tasks=15(nPassBack=0) last_loss=3.23146(0.0143557) N=(580,35364,34944 4149900)
[epoch_0]_41501  loss=3.201772 |g|=0.454	lr=2.44e-04 | 99.8%@S34  T=1.57s eta=08:32:44 | 71.0K token/s | 
[epoch_0]_41503  loss=3.266408 |g|=0.435	lr=2.44e-04 | 99.9%@S34  T=1.20s eta=06:30:45 | 70.8K token/s | 
-------- End of shard_34@"./Datasets/edu_fineweb1B/edu_fineweb_train_000487.bin"-------- 
[shard-35]@"./Datasets/edu_fineweb1B/edu_fineweb_train_000792.bin": tokens=100(M) nShardSamples=1220(3417960) 
[epoch_0]_41511  loss=3.246263 |g|=0.454	lr=2.44e-04 | 0.6%@S35  T=1.08s eta=05:52:34 | 71.1K token/s | 
[epoch_0]_41521  loss=3.236644 |g|=0.44	lr=2.44e-04 | 1.4%@S35  T=1.07s eta=05:47:30 | 71.4K token/s | 
[epoch_0]_41531  loss=3.226392 |g|=0.454	lr=2.43e-04 | 2.2%@S35  T=1.06s eta=05:45:53 | 71.6K token/s | 
[epoch_0]_41541  loss=3.352423 |g|=0.456	lr=2.43e-04 | 3.0%@S35  T=1.10s eta=05:56:02 | 71.8K token/s | 
[epoch_0]_41551  loss=3.222782 |g|=0.442	lr=2.43e-04 | 3.9%@S35  T=1.11s eta=05:59:23 | 71.9K token/s | 
[epoch_0]_41561  loss=3.217918 |g|=0.444	lr=2.43e-04 | 4.7%@S35  T=1.06s eta=05:45:23 | 72.2K token/s | 
[epoch_0]_41571  loss=3.301803 |g|=0.464	lr=2.42e-04 | 5.5%@S35  T=1.08s eta=05:49:52 | 72.3K token/s | 
[epoch_0]_41581  loss=3.233461 |g|=0.435	lr=2.42e-04 | 6.3%@S35  T=1.10s eta=05:58:16 | 72.4K token/s | 
[epoch_0]_41591  loss=3.234832 |g|=0.467	lr=2.42e-04 | 7.1%@S35  T=1.07s eta=05:47:23 | 72.6K token/s | 
[Fuyou] head="1" update algorithm=4 t=2.09s
[eval] 
	 Loss@"edu_fineweb1B"=3.261(-0.00051) nBranch=1 nToken=4.01M best=3.2600(206) E2T=0.0309 T=13.4957(0)s x=0
	#3.26056±0.1082 tps=297K(4.01408M) a=[3.0819,3.55543] T=13.4957(sec)
[Section@41600] layer[12-18] tasks=15(nPassBack=0) last_loss=3.22962(0.0998309) N=(580,35448,35028 4159900)
[epoch_0]_41601  loss=3.270557 |g|=0.457	lr=2.42e-04 | 8.0%@S35  T=4.22s eta=22:45:26 | 70.0K token/s | 
[epoch_0]_41611  loss=3.181634 |g|=0.422	lr=2.42e-04 | 8.8%@S35  T=1.08s eta=05:50:26 | 70.3K token/s | 
[epoch_0]_41621  loss=3.297170 |g|=0.421	lr=2.41e-04 | 9.6%@S35  T=1.09s eta=05:51:43 | 70.5K token/s | 
[epoch_0]_41631  loss=3.242207 |g|=0.509	lr=2.41e-04 | 10.4%@S35  T=1.06s eta=05:43:55 | 70.8K token/s | 
[epoch_0]_41641  loss=3.185728 |g|=0.433	lr=2.41e-04 | 11.2%@S35  T=1.07s eta=05:44:16 | 71.1K token/s | 
[epoch_0]_41651  loss=3.243124 |g|=0.429	lr=2.41e-04 | 12.1%@S35  T=1.09s eta=05:51:09 | 71.4K token/s | 
[epoch_0]_41661  loss=3.236171 |g|=0.434	lr=2.41e-04 | 12.9%@S35  T=1.11s eta=05:59:43 | 71.5K token/s | 
[epoch_0]_41671  loss=3.240907 |g|=0.423	lr=2.40e-04 | 13.7%@S35  T=1.08s eta=05:48:13 | 71.7K token/s | 
[epoch_0]_41681  loss=3.250950 |g|=0.446	lr=2.40e-04 | 14.5%@S35  T=1.09s eta=05:50:25 | 71.9K token/s | 
[epoch_0]_41691  loss=3.305304 |g|=0.459	lr=2.40e-04 | 15.3%@S35  T=1.13s eta=06:03:28 | 71.9K token/s | 
[Fuyou] head="2" update algorithm=4 t=2.05s
[Section@41700] layer[18-24] tasks=15(nPassBack=0) last_loss=3.22099(0.0705428) N=(580,35532,35112 4169900)
[epoch_0]_41701  loss=3.224749 |g|=0.474	lr=2.40e-04 | 16.2%@S35  T=1.46s eta=07:50:07 | 71.1K token/s | 
[epoch_0]_41711  loss=3.111153 |g|=0.459	lr=2.39e-04 | 17.0%@S35  T=1.10s eta=05:52:55 | 71.3K token/s | 
[epoch_0]_41721  loss=3.249908 |g|=0.449	lr=2.39e-04 | 17.8%@S35  T=1.11s eta=05:58:54 | 71.4K token/s | 
[epoch_0]_41731  loss=3.278950 |g|=0.439	lr=2.39e-04 | 18.6%@S35  T=1.09s eta=05:50:31 | 71.6K token/s | 
[epoch_0]_41741  loss=3.197106 |g|=0.437	lr=2.39e-04 | 19.4%@S35  T=1.11s eta=05:56:19 | 71.7K token/s | 
[epoch_0]_41751  loss=3.195435 |g|=0.438	lr=2.39e-04 | 20.3%@S35  T=1.11s eta=05:56:03 | 71.8K token/s | 
[epoch_0]_41761  loss=3.260967 |g|=0.46	lr=2.38e-04 | 21.1%@S35  T=1.07s eta=05:44:35 | 72.1K token/s | 
[epoch_0]_41771  loss=3.241694 |g|=0.485	lr=2.38e-04 | 21.9%@S35  T=1.09s eta=05:49:42 | 72.2K token/s | 
[epoch_0]_41781  loss=3.182250 |g|=0.434	lr=2.38e-04 | 22.7%@S35  T=1.11s eta=05:57:07 | 72.3K token/s | 
[epoch_0]_41791  loss=3.226329 |g|=0.449	lr=2.38e-04 | 23.5%@S35  T=1.08s eta=05:45:57 | 72.5K token/s | 
[Fuyou] head="3" update algorithm=4 t=2.11s
[eval] 
	 Loss@"edu_fineweb1B"=3.259(0.0011) nBranch=1 nToken=4.01M best=3.2606(207) E2T=-0.00422 T=13.4878(0)s x=0
	#3.25947±0.1086 tps=298K(4.01408M) a=[3.07557,3.55557] T=13.4878(sec)
[Section@41800] layer[24-30] tasks=15(nPassBack=0) last_loss=3.26369(-0.00236773) N=(580,35616,35196 4179900)
[epoch_0]_41801  loss=3.283050 |g|=0.436	lr=2.37e-04 | 24.3%@S35  T=4.24s eta=22:38:15 | 69.8K token/s | 
[epoch_0]_41811  loss=3.167280 |g|=0.494	lr=2.37e-04 | 25.2%@S35  T=1.12s eta=05:57:25 | 70.0K token/s | 
[epoch_0]_41821  loss=3.157351 |g|=0.437	lr=2.37e-04 | 26.0%@S35  T=1.08s eta=05:46:10 | 70.3K token/s | 
[epoch_0]_41831  loss=3.178481 |g|=0.425	lr=2.37e-04 | 26.8%@S35  T=1.15s eta=06:07:07 | 70.3K token/s | 
[epoch_0]_41841  loss=3.293095 |g|=0.464	lr=2.37e-04 | 27.6%@S35  T=1.08s eta=05:45:24 | 70.6K token/s | 
[epoch_0]_41851  loss=3.230118 |g|=0.438	lr=2.36e-04 | 28.4%@S35  T=1.08s eta=05:45:27 | 70.9K token/s | 
[epoch_0]_41861  loss=3.167841 |g|=0.433	lr=2.36e-04 | 29.3%@S35  T=1.13s eta=06:01:50 | 71.0K token/s | 
[epoch_0]_41871  loss=3.168437 |g|=0.468	lr=2.36e-04 | 30.1%@S35  T=1.08s eta=05:45:11 | 71.2K token/s | 
[epoch_0]_41881  loss=3.174610 |g|=0.452	lr=2.36e-04 | 30.9%@S35  T=1.08s eta=05:46:09 | 71.4K token/s | 
[epoch_0]_41891  loss=3.229787 |g|=0.46	lr=2.36e-04 | 31.7%@S35  T=1.10s eta=05:49:53 | 71.6K token/s | 
[Fuyou] head="4" update algorithm=4 t=2.03s
[Section@41900] layer[30-36] tasks=15(nPassBack=0) last_loss=3.20031(0.092288) N=(580,35700,35280 4189900)
[epoch_0]_41901  loss=3.250836 |g|=0.458	lr=2.35e-04 | 32.5%@S35  T=1.51s eta=08:00:03 | 70.7K token/s | 
[epoch_0]_41911  loss=3.250755 |g|=0.42	lr=2.35e-04 | 33.4%@S35  T=1.08s eta=05:44:50 | 71.0K token/s | 
[epoch_0]_41921  loss=3.163815 |g|=0.439	lr=2.35e-04 | 34.2%@S35  T=1.09s eta=05:45:57 | 71.2K token/s | 
[epoch_0]_41931  loss=3.193578 |g|=0.456	lr=2.35e-04 | 35.0%@S35  T=1.15s eta=06:05:27 | 71.2K token/s | 
[epoch_0]_41941  loss=3.200749 |g|=0.431	lr=2.34e-04 | 35.8%@S35  T=1.10s eta=05:49:04 | 71.4K token/s | 
[epoch_0]_41951  loss=3.201389 |g|=0.5	lr=2.34e-04 | 36.6%@S35  T=1.08s eta=05:44:43 | 71.6K token/s | 
[epoch_0]_41961  loss=3.199337 |g|=0.442	lr=2.34e-04 | 37.5%@S35  T=1.11s eta=05:54:11 | 71.7K token/s | 
[epoch_0]_41971  loss=3.196738 |g|=0.464	lr=2.34e-04 | 38.3%@S35  T=1.08s eta=05:43:41 | 71.9K token/s | 
[epoch_0]_41981  loss=3.263567 |g|=0.444	lr=2.34e-04 | 39.1%@S35  T=1.07s eta=05:40:05 | 72.1K token/s | 
[epoch_0]_41991  loss=3.242530 |g|=0.446	lr=2.33e-04 | 39.9%@S35  T=1.09s eta=05:47:30 | 72.2K token/s | 
[Fuyou] head="5" update algorithm=4 t=2.08s
[eval] 
	 Loss@"edu_fineweb1B"=3.258(0.0018) nBranch=1 nToken=4.01M best=3.2595(208) E2T=0.0311 T=13.493(0)s x=0
	#3.25768±0.1087 tps=297K(4.01408M) a=[3.06869,3.55385] T=13.493(sec)
[Section@42000] layer[0-6] tasks=15(nPassBack=0) last_loss=3.22658(0.00554252) N=(580,35784,35364 4199900)
[epoch_0]_42001  loss=3.249980 |g|=0.444	lr=2.33e-04 | 40.7%@S35  T=4.22s eta=22:19:05 | 69.6K token/s | 
[epoch_0]_42011  loss=3.236571 |g|=0.472	lr=2.33e-04 | 41.6%@S35  T=1.08s eta=05:43:24 | 69.9K token/s | 
[epoch_0]_42021  loss=3.291020 |g|=0.473	lr=2.33e-04 | 42.4%@S35  T=1.09s eta=05:46:44 | 70.2K token/s | 
[epoch_0]_42031  loss=3.268409 |g|=0.443	lr=2.33e-04 | 43.2%@S35  T=1.07s eta=05:38:30 | 70.5K token/s | 
[epoch_0]_42041  loss=3.235796 |g|=0.462	lr=2.32e-04 | 44.0%@S35  T=1.09s eta=05:45:29 | 70.7K token/s | 
[epoch_0]_42051  loss=3.153488 |g|=0.446	lr=2.32e-04 | 44.8%@S35  T=1.11s eta=05:50:28 | 70.9K token/s | 
[epoch_0]_42061  loss=3.132020 |g|=0.46	lr=2.32e-04 | 45.6%@S35  T=1.08s eta=05:41:27 | 71.1K token/s | 
[epoch_0]_42071  loss=3.220590 |g|=0.453	lr=2.32e-04 | 46.5%@S35  T=1.08s eta=05:40:13 | 71.4K token/s | 
[epoch_0]_42081  loss=3.234622 |g|=0.44	lr=2.31e-04 | 47.3%@S35  T=1.10s eta=05:48:31 | 71.5K token/s | 
[epoch_0]_42091  loss=3.177954 |g|=0.455	lr=2.31e-04 | 48.1%@S35  T=1.06s eta=05:34:35 | 71.8K token/s | 
[Fuyou] head="0" update algorithm=4 t=2.03s
[Section@42100] layer[6-12] tasks=15(nPassBack=0) last_loss=3.27138(-0.0399227) N=(580,35868,35448 4209900)
[epoch_0]_42101  loss=3.238354 |g|=0.433	lr=2.31e-04 | 48.9%@S35  T=1.38s eta=07:16:53 | 71.2K token/s | 
[epoch_0]_42111  loss=3.252767 |g|=0.449	lr=2.31e-04 | 49.7%@S35  T=1.08s eta=05:41:11 | 71.4K token/s | 
[epoch_0]_42121  loss=3.266996 |g|=0.442	lr=2.31e-04 | 50.6%@S35  T=1.07s eta=05:37:44 | 71.7K token/s | 
[epoch_0]_42131  loss=3.241203 |g|=0.454	lr=2.30e-04 | 51.4%@S35  T=1.08s eta=05:41:03 | 71.9K token/s | 
[epoch_0]_42141  loss=3.170458 |g|=0.465	lr=2.30e-04 | 52.2%@S35  T=1.12s eta=05:52:32 | 71.9K token/s | 
[epoch_0]_42151  loss=3.273310 |g|=0.459	lr=2.30e-04 | 53.0%@S35  T=1.09s eta=05:42:09 | 72.1K token/s | 
[epoch_0]_42161  loss=3.216771 |g|=0.468	lr=2.30e-04 | 53.8%@S35  T=1.08s eta=05:39:29 | 72.3K token/s | 
[epoch_0]_42171  loss=3.177752 |g|=0.445	lr=2.30e-04 | 54.7%@S35  T=1.11s eta=05:48:34 | 72.4K token/s | 
[epoch_0]_42181  loss=3.196625 |g|=0.443	lr=2.29e-04 | 55.5%@S35  T=1.07s eta=05:36:23 | 72.6K token/s | 
[epoch_0]_42191  loss=3.222291 |g|=0.448	lr=2.29e-04 | 56.3%@S35  T=1.08s eta=05:39:37 | 72.7K token/s | 
[Fuyou] head="1" update algorithm=4 t=2.08s
[eval] 
	 Loss@"edu_fineweb1B"=3.258(-0.00012) nBranch=1 nToken=4.01M best=3.2577(209) E2T=0.0807 T=13.49(0)s x=0
	#3.25779±0.1092 tps=298K(4.01408M) a=[3.07327,3.55466] T=13.49(sec)
[Section@42200] layer[12-18] tasks=15(nPassBack=0) last_loss=3.17713(0.0524907) N=(580,35952,35532 4219900)
[epoch_0]_42201  loss=3.217767 |g|=0.434	lr=2.29e-04 | 57.1%@S35  T=4.22s eta=22:03:40 | 70.1K token/s | 
[epoch_0]_42211  loss=3.207852 |g|=0.466	lr=2.29e-04 | 57.9%@S35  T=1.14s eta=05:57:40 | 70.2K token/s | 
[epoch_0]_42221  loss=3.264130 |g|=0.449	lr=2.28e-04 | 58.8%@S35  T=1.11s eta=05:46:54 | 70.3K token/s | 
[epoch_0]_42231  loss=3.213543 |g|=0.448	lr=2.28e-04 | 59.6%@S35  T=1.06s eta=05:33:44 | 70.7K token/s | 
[epoch_0]_42241  loss=3.197628 |g|=0.46	lr=2.28e-04 | 60.4%@S35  T=1.08s eta=05:36:45 | 71.0K token/s | 
[epoch_0]_42251  loss=3.260560 |g|=0.469	lr=2.28e-04 | 61.2%@S35  T=1.09s eta=05:40:42 | 71.2K token/s | 
[epoch_0]_42261  loss=3.174269 |g|=0.435	lr=2.28e-04 | 62.0%@S35  T=1.09s eta=05:41:54 | 71.4K token/s | 
[epoch_0]_42271  loss=3.199851 |g|=0.452	lr=2.27e-04 | 62.9%@S35  T=1.08s eta=05:37:10 | 71.6K token/s | 
[epoch_0]_42281  loss=3.232654 |g|=0.465	lr=2.27e-04 | 63.7%@S35  T=1.10s eta=05:43:47 | 71.7K token/s | 
[epoch_0]_42291  loss=3.204913 |g|=0.431	lr=2.27e-04 | 64.5%@S35  T=1.09s eta=05:40:21 | 71.9K token/s | 
[Fuyou] head="2" update algorithm=4 t=2.01s
[Section@42300] layer[18-24] tasks=15(nPassBack=0) last_loss=3.16454(0.0564492) N=(580,36036,35616 4229900)
[epoch_0]_42301  loss=3.204610 |g|=0.453	lr=2.27e-04 | 65.3%@S35  T=1.46s eta=07:35:52 | 71.1K token/s | 
[epoch_0]_42311  loss=3.196980 |g|=0.469	lr=2.27e-04 | 66.1%@S35  T=1.08s eta=05:37:01 | 71.4K token/s | 
[epoch_0]_42321  loss=3.188267 |g|=0.449	lr=2.26e-04 | 66.9%@S35  T=1.14s eta=05:55:54 | 71.4K token/s | 
[epoch_0]_42331  loss=3.222624 |g|=0.445	lr=2.26e-04 | 67.8%@S35  T=1.08s eta=05:37:02 | 71.6K token/s | 
[epoch_0]_42341  loss=3.144380 |g|=0.495	lr=2.26e-04 | 68.6%@S35  T=1.08s eta=05:36:02 | 71.8K token/s | 
[epoch_0]_42351  loss=3.154705 |g|=0.437	lr=2.26e-04 | 69.4%@S35  T=1.12s eta=05:49:14 | 71.9K token/s | 
[epoch_0]_42361  loss=3.166646 |g|=0.475	lr=2.25e-04 | 70.2%@S35  T=1.07s eta=05:33:10 | 72.1K token/s | 
[epoch_0]_42371  loss=3.212265 |g|=0.455	lr=2.25e-04 | 71.0%@S35  T=1.08s eta=05:35:35 | 72.3K token/s | 
[epoch_0]_42381  loss=3.198471 |g|=0.444	lr=2.25e-04 | 71.9%@S35  T=1.12s eta=05:48:41 | 72.3K token/s | 
[epoch_0]_42391  loss=3.075604 |g|=0.481	lr=2.25e-04 | 72.7%@S35  T=1.07s eta=05:33:59 | 72.5K token/s | 
[Fuyou] head="3" update algorithm=4 t=2.08s
[eval] 
	 Loss@"edu_fineweb1B"=3.255(0.0024) nBranch=1 nToken=4.01M best=3.2578(210) E2T=0.0607 T=13.4801(0)s x=0
	#3.25541±0.1089 tps=298K(4.01408M) a=[3.07078,3.55115] T=13.4801(sec)
[Section@42400] layer[24-30] tasks=15(nPassBack=0) last_loss=3.19474(0.0689442) N=(580,36120,35700 4239900)
[epoch_0]_42401  loss=3.239791 |g|=0.44	lr=2.25e-04 | 73.5%@S35  T=4.21s eta=21:48:00 | 69.9K token/s | 
[epoch_0]_42411  loss=3.238699 |g|=0.458	lr=2.24e-04 | 74.3%@S35  T=1.11s eta=05:45:18 | 70.1K token/s | 
[epoch_0]_42421  loss=3.183047 |g|=0.46	lr=2.24e-04 | 75.1%@S35  T=1.08s eta=05:34:21 | 70.4K token/s | 
[epoch_0]_42431  loss=3.146258 |g|=0.453	lr=2.24e-04 | 76.0%@S35  T=1.10s eta=05:42:33 | 70.6K token/s | 
[epoch_0]_42441  loss=3.211667 |g|=0.428	lr=2.24e-04 | 76.8%@S35  T=1.08s eta=05:34:15 | 70.8K token/s | 
[epoch_0]_42451  loss=3.172636 |g|=0.427	lr=2.24e-04 | 77.6%@S35  T=1.07s eta=05:30:53 | 71.1K token/s | 
[epoch_0]_42461  loss=3.253937 |g|=0.44	lr=2.23e-04 | 78.4%@S35  T=1.10s eta=05:39:26 | 71.3K token/s | 
[epoch_0]_42471  loss=3.178210 |g|=0.45	lr=2.23e-04 | 79.2%@S35  T=1.07s eta=05:29:39 | 71.6K token/s | 
[epoch_0]_42481  loss=3.140493 |g|=0.468	lr=2.23e-04 | 80.1%@S35  T=1.08s eta=05:32:49 | 71.8K token/s | 
[epoch_0]_42491  loss=3.194373 |g|=0.421	lr=2.23e-04 | 80.9%@S35  T=1.10s eta=05:38:45 | 71.9K token/s | 
[Fuyou] head="4" update algorithm=4 t=2.01s
[Section@42500] layer[30-36] tasks=15(nPassBack=0) last_loss=3.22012(-0.0198081) N=(580,36204,35784 4249900)
[epoch_0]_42501  loss=3.178233 |g|=0.434	lr=2.23e-04 | 81.7%@S35  T=1.37s eta=07:02:14 | 71.3K token/s | 
[epoch_0]_42511  loss=3.174732 |g|=0.451	lr=2.22e-04 | 82.5%@S35  T=1.08s eta=05:34:39 | 71.6K token/s | 
[epoch_0]_42521  loss=3.207475 |g|=0.457	lr=2.22e-04 | 83.3%@S35  T=1.10s eta=05:40:55 | 71.7K token/s | 
[epoch_0]_42531  loss=3.240435 |g|=0.466	lr=2.22e-04 | 84.1%@S35  T=1.08s eta=05:34:15 | 71.9K token/s | 
[epoch_0]_42541  loss=3.198433 |g|=0.441	lr=2.22e-04 | 85.0%@S35  T=1.09s eta=05:35:12 | 72.1K token/s | 
[epoch_0]_42551  loss=3.201506 |g|=0.466	lr=2.21e-04 | 85.8%@S35  T=1.09s eta=05:34:43 | 72.2K token/s | 
[epoch_0]_42561  loss=3.176056 |g|=0.429	lr=2.21e-04 | 86.6%@S35  T=1.12s eta=05:44:06 | 72.3K token/s | 
[epoch_0]_42571  loss=3.212743 |g|=0.459	lr=2.21e-04 | 87.4%@S35  T=1.06s eta=05:27:33 | 72.5K token/s | 
[epoch_0]_42581  loss=3.188829 |g|=0.433	lr=2.21e-04 | 88.2%@S35  T=1.07s eta=05:29:43 | 72.7K token/s | 
[epoch_0]_42591  loss=3.156784 |g|=0.43	lr=2.21e-04 | 89.1%@S35  T=1.11s eta=05:40:30 | 72.8K token/s | 
[Fuyou] head="5" update algorithm=4 t=2.09s
[eval] 
	 Loss@"edu_fineweb1B"=3.254(0.0016) nBranch=1 nToken=4.01M best=3.2554(211) E2T=-0.0292 T=13.4787(0)s x=0
	#3.25378±0.1095 tps=298K(4.01408M) a=[3.06434,3.54887] T=13.4787(sec)
[Section@42600] layer[0-6] tasks=15(nPassBack=0) last_loss=3.28298(-0.0563955) N=(580,36288,35868 4259900)
[epoch_0]_42601  loss=3.264074 |g|=0.439	lr=2.20e-04 | 89.9%@S35  T=4.26s eta=21:47:18 | 70.1K token/s | 
[epoch_0]_42611  loss=3.140465 |g|=0.461	lr=2.20e-04 | 90.7%@S35  T=1.11s eta=05:40:50 | 70.3K token/s | 
[epoch_0]_42621  loss=3.249563 |g|=0.459	lr=2.20e-04 | 91.5%@S35  T=1.08s eta=05:30:38 | 70.6K token/s | 
[epoch_0]_42631  loss=3.169160 |g|=0.453	lr=2.20e-04 | 92.3%@S35  T=1.08s eta=05:32:04 | 70.8K token/s | 
[epoch_0]_42641  loss=3.184327 |g|=0.453	lr=2.20e-04 | 93.2%@S35  T=1.11s eta=05:40:50 | 71.0K token/s | 
[epoch_0]_42651  loss=3.238887 |g|=0.462	lr=2.19e-04 | 94.0%@S35  T=1.08s eta=05:29:36 | 71.2K token/s | 
[epoch_0]_42661  loss=3.163209 |g|=0.436	lr=2.19e-04 | 94.8%@S35  T=1.08s eta=05:32:10 | 71.4K token/s | 
[epoch_0]_42671  loss=3.169293 |g|=0.459	lr=2.19e-04 | 95.6%@S35  T=1.13s eta=05:44:44 | 71.5K token/s | 
[epoch_0]_42681  loss=3.205265 |g|=0.488	lr=2.19e-04 | 96.4%@S35  T=1.10s eta=05:35:21 | 71.7K token/s | 
[epoch_0]_42691  loss=3.216785 |g|=0.446	lr=2.19e-04 | 97.3%@S35  T=1.09s eta=05:32:47 | 71.8K token/s | 
[Fuyou] head="0" update algorithm=4 t=2.21s
[Section@42700] layer[6-12] tasks=15(nPassBack=0) last_loss=3.21463(0.0567527) N=(580,36372,35952 4269900)
[epoch_0]_42701  loss=3.196661 |g|=0.435	lr=2.18e-04 | 98.1%@S35  T=1.38s eta=07:01:24 | 71.2K token/s | 
[epoch_0]_42711  loss=3.217158 |g|=0.49	lr=2.18e-04 | 98.9%@S35  T=1.08s eta=05:29:51 | 71.5K token/s | 
[epoch_0]_42721  loss=3.249663 |g|=0.422	lr=2.18e-04 | 99.7%@S35  T=1.09s eta=05:33:49 | 71.6K token/s | 
[epoch_0]_42724  loss=3.176157 |g|=0.441	lr=2.18e-04 | 100.0%@S35  T=1.09s eta=05:33:37 | 71.8K token/s | 
-------- End of shard_35@"./Datasets/edu_fineweb1B/edu_fineweb_train_000792.bin"-------- 
[shard-36]@"./Datasets/edu_fineweb1B/edu_fineweb_train_000793.bin": tokens=100(M) nShardSamples=1220(3515616) 
[epoch_0]_42731  loss=3.208423 |g|=0.447	lr=2.18e-04 | 0.5%@S36  T=1.13s eta=05:43:43 | 71.8K token/s | 
[epoch_0]_42741  loss=3.251612 |g|=0.431	lr=2.17e-04 | 1.4%@S36  T=1.08s eta=05:28:17 | 72.0K token/s | 
[epoch_0]_42751  loss=3.274204 |g|=0.454	lr=2.17e-04 | 2.2%@S36  T=1.10s eta=05:33:50 | 72.2K token/s | 
[epoch_0]_42761  loss=3.246003 |g|=0.454	lr=2.17e-04 | 3.0%@S36  T=1.13s eta=05:43:56 | 72.2K token/s | 
[epoch_0]_42771  loss=3.291829 |g|=0.479	lr=2.17e-04 | 3.8%@S36  T=1.05s eta=05:20:53 | 72.5K token/s | 
[epoch_0]_42781  loss=3.278657 |g|=0.461	lr=2.17e-04 | 4.6%@S36  T=1.08s eta=05:29:14 | 72.6K token/s | 
[epoch_0]_42791  loss=3.280183 |g|=0.481	lr=2.16e-04 | 5.4%@S36  T=1.11s eta=05:37:48 | 72.7K token/s | 
[Fuyou] head="1" update algorithm=4 t=2.07s
[eval] 
	 Loss@"edu_fineweb1B"=3.247(0.0067) nBranch=1 nToken=4.01M best=3.2538(212) E2T=0.0306 T=13.4959(0)s x=0
	#3.24709±0.1081 tps=297K(4.01408M) a=[3.06155,3.53925] T=13.4959(sec)
[Section@42800] layer[12-18] tasks=15(nPassBack=0) last_loss=3.2165(-0.0393682) N=(580,36456,36036 4279900)
[epoch_0]_42801  loss=3.307435 |g|=0.455	lr=2.16e-04 | 6.3%@S36  T=4.21s eta=21:20:31 | 70.0K token/s | 
[epoch_0]_42811  loss=3.243180 |g|=0.441	lr=2.16e-04 | 7.1%@S36  T=1.09s eta=05:30:58 | 70.3K token/s | 
[epoch_0]_42821  loss=3.258618 |g|=0.446	lr=2.16e-04 | 7.9%@S36  T=1.11s eta=05:38:00 | 70.5K token/s | 
[epoch_0]_42831  loss=3.270746 |g|=0.453	lr=2.16e-04 | 8.7%@S36  T=1.08s eta=05:27:34 | 70.7K token/s | 
[epoch_0]_42841  loss=3.219756 |g|=0.452	lr=2.15e-04 | 9.5%@S36  T=1.08s eta=05:28:42 | 71.0K token/s | 
[epoch_0]_42851  loss=3.282803 |g|=0.453	lr=2.15e-04 | 10.4%@S36  T=1.13s eta=05:41:59 | 71.0K token/s | 
[epoch_0]_42861  loss=3.171189 |g|=0.453	lr=2.15e-04 | 11.2%@S36  T=1.08s eta=05:28:01 | 71.3K token/s | 
[epoch_0]_42871  loss=3.212988 |g|=0.455	lr=2.15e-04 | 12.0%@S36  T=1.10s eta=05:34:14 | 71.4K token/s | 
[epoch_0]_42881  loss=3.231241 |g|=0.448	lr=2.15e-04 | 12.8%@S36  T=1.10s eta=05:34:18 | 71.6K token/s | 
[epoch_0]_42891  loss=3.230506 |g|=0.455	lr=2.14e-04 | 13.6%@S36  T=1.08s eta=05:25:25 | 71.8K token/s | 
[Fuyou] head="2" update algorithm=4 t=2.05s
[Section@42900] layer[18-24] tasks=15(nPassBack=0) last_loss=3.26291(-0.0983653) N=(580,36540,36120 4289900)
[epoch_0]_42901  loss=3.292726 |g|=0.473	lr=2.14e-04 | 14.5%@S36  T=1.51s eta=07:35:50 | 70.9K token/s | 
[epoch_0]_42911  loss=3.264713 |g|=0.455	lr=2.14e-04 | 15.3%@S36  T=1.08s eta=05:25:23 | 71.2K token/s | 
[epoch_0]_42921  loss=3.194320 |g|=0.461	lr=2.14e-04 | 16.1%@S36  T=1.13s eta=05:40:33 | 71.2K token/s | 
[epoch_0]_42931  loss=3.251103 |g|=0.459	lr=2.13e-04 | 16.9%@S36  T=1.08s eta=05:26:05 | 71.5K token/s | 
[epoch_0]_42941  loss=3.099097 |g|=0.451	lr=2.13e-04 | 17.7%@S36  T=1.08s eta=05:26:11 | 71.7K token/s | 
[epoch_0]_42951  loss=3.081440 |g|=0.47	lr=2.13e-04 | 18.6%@S36  T=1.12s eta=05:38:06 | 71.8K token/s | 
[epoch_0]_42961  loss=3.197608 |g|=0.52	lr=2.13e-04 | 19.4%@S36  T=1.08s eta=05:26:19 | 71.9K token/s | 
[epoch_0]_42971  loss=3.232414 |g|=0.447	lr=2.13e-04 | 20.2%@S36  T=1.08s eta=05:26:04 | 72.1K token/s | 
[epoch_0]_42981  loss=3.187546 |g|=0.471	lr=2.12e-04 | 21.0%@S36  T=1.09s eta=05:29:12 | 72.3K token/s | 
[epoch_0]_42991  loss=3.269352 |g|=0.481	lr=2.12e-04 | 21.8%@S36  T=1.08s eta=05:25:43 | 72.4K token/s | 
[Fuyou] head="3" update algorithm=4 t=2.07s
[eval] 
	 Loss@"edu_fineweb1B"=3.243(0.0045) nBranch=1 nToken=4.01M best=3.2471(213) E2T=0.00656 T=13.4826(0)s x=0
	#3.24263±0.1083 tps=298K(4.01408M) a=[3.05493,3.53435] T=13.4826(sec)
[Section@43000] layer[24-30] tasks=15(nPassBack=0) last_loss=3.23607(-0.0413299) N=(580,36624,36204 4299900)
[epoch_0]_43001  loss=3.274302 |g|=0.438	lr=2.12e-04 | 22.7%@S36  T=4.26s eta=21:19:40 | 69.8K token/s | 
[epoch_0]_43011  loss=3.206310 |g|=0.447	lr=2.12e-04 | 23.5%@S36  T=1.10s eta=05:30:47 | 70.0K token/s | 
[epoch_0]_43021  loss=3.247750 |g|=0.457	lr=2.12e-04 | 24.3%@S36  T=1.09s eta=05:26:53 | 70.3K token/s | 
[epoch_0]_43031  loss=3.280666 |g|=0.468	lr=2.11e-04 | 25.1%@S36  T=1.08s eta=05:24:28 | 70.5K token/s | 
[epoch_0]_43041  loss=3.245849 |g|=0.458	lr=2.11e-04 | 25.9%@S36  T=1.14s eta=05:42:00 | 70.6K token/s | 
[epoch_0]_43051  loss=3.262886 |g|=0.466	lr=2.11e-04 | 26.7%@S36  T=1.10s eta=05:29:34 | 70.8K token/s | 
[epoch_0]_43061  loss=3.142034 |g|=0.429	lr=2.11e-04 | 27.6%@S36  T=1.10s eta=05:28:52 | 71.0K token/s | 
[epoch_0]_43071  loss=3.245223 |g|=0.457	lr=2.11e-04 | 28.4%@S36  T=1.12s eta=05:34:43 | 71.1K token/s | 
[epoch_0]_43081  loss=3.178124 |g|=0.458	lr=2.10e-04 | 29.2%@S36  T=1.08s eta=05:24:33 | 71.3K token/s | 
[epoch_0]_43091  loss=3.170521 |g|=0.47	lr=2.10e-04 | 30.0%@S36  T=1.08s eta=05:23:58 | 71.5K token/s | 
[Fuyou] head="4" update algorithm=4 t=2.07s
[Section@43100] layer[30-36] tasks=15(nPassBack=0) last_loss=3.25458(-0.0344598) N=(580,36708,36288 4309900)
[epoch_0]_43101  loss=3.225305 |g|=0.471	lr=2.10e-04 | 30.8%@S36  T=1.48s eta=07:23:00 | 70.7K token/s | 
[epoch_0]_43111  loss=3.254077 |g|=0.513	lr=2.10e-04 | 31.7%@S36  T=1.08s eta=05:23:45 | 71.0K token/s | 
[epoch_0]_43121  loss=3.223171 |g|=0.458	lr=2.10e-04 | 32.5%@S36  T=1.08s eta=05:23:55 | 71.2K token/s | 
[epoch_0]_43131  loss=3.273608 |g|=0.425	lr=2.09e-04 | 33.3%@S36  T=1.10s eta=05:27:25 | 71.4K token/s | 
[epoch_0]_43141  loss=3.244153 |g|=0.467	lr=2.09e-04 | 34.1%@S36  T=1.08s eta=05:23:15 | 71.6K token/s | 
[epoch_0]_43151  loss=3.257737 |g|=0.451	lr=2.09e-04 | 34.9%@S36  T=1.10s eta=05:29:15 | 71.7K token/s | 
[epoch_0]_43161  loss=3.277100 |g|=0.458	lr=2.09e-04 | 35.8%@S36  T=1.08s eta=05:20:54 | 71.9K token/s | 
[epoch_0]_43171  loss=3.208668 |g|=0.446	lr=2.09e-04 | 36.6%@S36  T=1.13s eta=05:36:57 | 72.0K token/s | 
[epoch_0]_43181  loss=3.252924 |g|=0.456	lr=2.08e-04 | 37.4%@S36  T=1.08s eta=05:20:36 | 72.2K token/s | 
[epoch_0]_43191  loss=3.253213 |g|=0.455	lr=2.08e-04 | 38.2%@S36  T=1.09s eta=05:25:06 | 72.3K token/s | 
[Fuyou] head="5" update algorithm=4 t=2.08s
[eval] 
	 Loss@"edu_fineweb1B"=3.241(0.002) nBranch=1 nToken=4.01M best=3.2426(214) E2T=0.0141 T=13.4799(0)s x=0
	#3.2406±0.1091 tps=298K(4.01408M) a=[3.0543,3.5318] T=13.4799(sec)
[Section@43200] layer[0-6] tasks=15(nPassBack=0) last_loss=3.22649(0.0564888) N=(580,36792,36372 4319900)
[epoch_0]_43201  loss=3.243741 |g|=0.462	lr=2.08e-04 | 39.0%@S36  T=4.22s eta=20:55:03 | 69.6K token/s | 
[epoch_0]_43211  loss=3.223974 |g|=0.478	lr=2.08e-04 | 39.9%@S36  T=1.08s eta=05:20:00 | 70.0K token/s | 
[epoch_0]_43221  loss=3.210580 |g|=0.444	lr=2.07e-04 | 40.7%@S36  T=1.09s eta=05:25:04 | 70.2K token/s | 
[epoch_0]_43231  loss=3.235294 |g|=0.438	lr=2.07e-04 | 41.5%@S36  T=1.09s eta=05:22:25 | 70.5K token/s | 
[epoch_0]_43241  loss=3.158173 |g|=0.446	lr=2.07e-04 | 42.3%@S36  T=1.08s eta=05:20:12 | 70.7K token/s | 
[epoch_0]_43251  loss=3.225319 |g|=0.495	lr=2.07e-04 | 43.1%@S36  T=1.13s eta=05:35:02 | 70.8K token/s | 
[epoch_0]_43261  loss=3.180790 |g|=0.468	lr=2.07e-04 | 44.0%@S36  T=1.07s eta=05:16:05 | 71.1K token/s | 
[epoch_0]_43271  loss=3.260751 |g|=0.485	lr=2.06e-04 | 44.8%@S36  T=1.08s eta=05:20:24 | 71.4K token/s | 
[epoch_0]_43281  loss=3.231970 |g|=0.443	lr=2.06e-04 | 45.6%@S36  T=1.13s eta=05:35:09 | 71.4K token/s | 
[epoch_0]_43291  loss=3.211562 |g|=0.499	lr=2.06e-04 | 46.4%@S36  T=1.08s eta=05:19:34 | 71.6K token/s | 
[Fuyou] head="0" update algorithm=4 t=2.08s
[Section@43300] layer[6-12] tasks=15(nPassBack=0) last_loss=3.22199(-0.00735903) N=(580,36876,36456 4329900)
[epoch_0]_43301  loss=3.224478 |g|=0.445	lr=2.06e-04 | 47.2%@S36  T=1.41s eta=06:57:49 | 70.9K token/s | 
[epoch_0]_43311  loss=3.260624 |g|=0.45	lr=2.06e-04 | 48.0%@S36  T=1.08s eta=05:17:46 | 71.2K token/s | 
[epoch_0]_43321  loss=3.158993 |g|=0.466	lr=2.05e-04 | 48.9%@S36  T=1.09s eta=05:22:02 | 71.4K token/s | 
[epoch_0]_43331  loss=3.217528 |g|=0.483	lr=2.05e-04 | 49.7%@S36  T=1.08s eta=05:19:49 | 71.6K token/s | 
[epoch_0]_43341  loss=3.289822 |g|=0.461	lr=2.05e-04 | 50.5%@S36  T=1.13s eta=05:34:17 | 71.6K token/s | 
[epoch_0]_43351  loss=3.229935 |g|=0.437	lr=2.05e-04 | 51.3%@S36  T=1.10s eta=05:23:49 | 71.8K token/s | 
[epoch_0]_43361  loss=3.255762 |g|=0.456	lr=2.05e-04 | 52.1%@S36  T=1.09s eta=05:19:55 | 72.0K token/s | 
[epoch_0]_43371  loss=3.201185 |g|=0.481	lr=2.04e-04 | 53.0%@S36  T=1.10s eta=05:24:08 | 72.1K token/s | 
[epoch_0]_43381  loss=3.253282 |g|=0.459	lr=2.04e-04 | 53.8%@S36  T=1.07s eta=05:16:17 | 72.3K token/s | 
[epoch_0]_43391  loss=3.199104 |g|=0.456	lr=2.04e-04 | 54.6%@S36  T=1.09s eta=05:20:09 | 72.4K token/s | 
[Fuyou] head="1" update algorithm=4 t=2.32s
[eval] 
	 Loss@"edu_fineweb1B"=3.238(0.0028) nBranch=1 nToken=4.01M best=3.2406(215) E2T=0.0225 T=13.4825(0)s x=0
	#3.23779±0.1083 tps=298K(4.01408M) a=[3.05477,3.52529] T=13.4825(sec)
[Section@43400] layer[12-18] tasks=15(nPassBack=0) last_loss=3.21532(0.00118279) N=(580,36960,36540 4339900)
[epoch_0]_43401  loss=3.248334 |g|=0.464	lr=2.04e-04 | 55.4%@S36  T=4.26s eta=20:50:37 | 69.8K token/s | 
[epoch_0]_43411  loss=3.172784 |g|=0.468	lr=2.04e-04 | 56.2%@S36  T=1.08s eta=05:17:05 | 70.1K token/s | 
[epoch_0]_43421  loss=3.161400 |g|=0.465	lr=2.03e-04 | 57.1%@S36  T=1.10s eta=05:23:27 | 70.3K token/s | 
[epoch_0]_43431  loss=3.131084 |g|=0.498	lr=2.03e-04 | 57.9%@S36  T=1.11s eta=05:26:01 | 70.5K token/s | 
[epoch_0]_43441  loss=3.203345 |g|=0.461	lr=2.03e-04 | 58.7%@S36  T=1.08s eta=05:16:35 | 70.7K token/s | 
[epoch_0]_43451  loss=3.189201 |g|=0.446	lr=2.03e-04 | 59.5%@S36  T=1.09s eta=05:19:59 | 71.0K token/s | 
[epoch_0]_43461  loss=3.234062 |g|=0.471	lr=2.03e-04 | 60.3%@S36  T=1.11s eta=05:25:54 | 71.1K token/s | 
[epoch_0]_43471  loss=3.182443 |g|=0.479	lr=2.02e-04 | 61.2%@S36  T=1.08s eta=05:16:04 | 71.3K token/s | 
[epoch_0]_43481  loss=3.200098 |g|=0.49	lr=2.02e-04 | 62.0%@S36  T=1.12s eta=05:27:46 | 71.4K token/s | 
[epoch_0]_43491  loss=3.310674 |g|=0.502	lr=2.02e-04 | 62.8%@S36  T=1.13s eta=05:29:17 | 71.5K token/s | 
[Fuyou] head="2" update algorithm=4 t=2.10s
[Section@43500] layer[18-24] tasks=15(nPassBack=0) last_loss=3.21605(0.046854) N=(580,37044,36624 4349900)
[epoch_0]_43501  loss=3.190087 |g|=0.44	lr=2.02e-04 | 63.6%@S36  T=1.44s eta=06:59:59 | 70.8K token/s | 
[epoch_0]_43511  loss=3.167806 |g|=0.464	lr=2.02e-04 | 64.4%@S36  T=1.07s eta=05:11:17 | 71.1K token/s | 
[epoch_0]_43521  loss=3.192049 |g|=0.465	lr=2.01e-04 | 65.3%@S36  T=1.11s eta=05:22:57 | 71.2K token/s | 
[epoch_0]_43531  loss=3.236791 |g|=0.49	lr=2.01e-04 | 66.1%@S36  T=1.13s eta=05:28:40 | 71.3K token/s | 
[epoch_0]_43541  loss=3.200641 |g|=0.461	lr=2.01e-04 | 66.9%@S36  T=1.09s eta=05:16:37 | 71.5K token/s | 
[epoch_0]_43551  loss=3.210043 |g|=0.449	lr=2.01e-04 | 67.7%@S36  T=1.09s eta=05:17:59 | 71.7K token/s | 
[epoch_0]_43561  loss=3.226669 |g|=0.49	lr=2.01e-04 | 68.5%@S36  T=1.14s eta=05:33:15 | 71.7K token/s | 
[epoch_0]_43571  loss=3.180070 |g|=0.468	lr=2.00e-04 | 69.3%@S36  T=1.07s eta=05:12:45 | 71.9K token/s | 
[epoch_0]_43581  loss=3.261764 |g|=0.502	lr=2.00e-04 | 70.2%@S36  T=1.07s eta=05:11:46 | 72.1K token/s | 
[epoch_0]_43591  loss=3.126809 |g|=0.459	lr=2.00e-04 | 71.0%@S36  T=1.12s eta=05:26:25 | 72.2K token/s | 
[Fuyou] head="3" update algorithm=4 t=2.07s
[eval] 
	 Loss@"edu_fineweb1B"=3.235(0.0023) nBranch=1 nToken=4.01M best=3.2378(216) E2T=0.0578 T=13.4942(0)s x=0
	#3.23549±0.1086 tps=297K(4.01408M) a=[3.05476,3.5244] T=13.4942(sec)
[Section@43600] layer[24-30] tasks=15(nPassBack=0) last_loss=3.17767(0.0584092) N=(580,37128,36708 4359900)
[epoch_0]_43601  loss=3.163752 |g|=0.475	lr=2.00e-04 | 71.8%@S36  T=4.23s eta=20:29:14 | 69.5K token/s | 
[epoch_0]_43611  loss=3.192338 |g|=0.481	lr=2.00e-04 | 72.6%@S36  T=1.08s eta=05:12:40 | 69.9K token/s | 
[epoch_0]_43621  loss=3.123198 |g|=0.465	lr=1.99e-04 | 73.4%@S36  T=1.12s eta=05:24:02 | 70.0K token/s | 
[epoch_0]_43631  loss=3.249201 |g|=0.462	lr=1.99e-04 | 74.3%@S36  T=1.08s eta=05:14:28 | 70.3K token/s | 
[epoch_0]_43641  loss=3.236316 |g|=0.456	lr=1.99e-04 | 75.1%@S36  T=1.08s eta=05:12:09 | 70.6K token/s | 
[epoch_0]_43651  loss=3.203878 |g|=0.482	lr=1.99e-04 | 75.9%@S36  T=1.12s eta=05:25:15 | 70.7K token/s | 
[epoch_0]_43661  loss=3.234280 |g|=0.454	lr=1.99e-04 | 76.7%@S36  T=1.07s eta=05:09:47 | 71.0K token/s | 
[epoch_0]_43671  loss=3.200253 |g|=0.477	lr=1.98e-04 | 77.5%@S36  T=1.08s eta=05:12:08 | 71.3K token/s | 
[epoch_0]_43681  loss=3.212611 |g|=0.451	lr=1.98e-04 | 78.4%@S36  T=1.12s eta=05:24:23 | 71.3K token/s | 
[epoch_0]_43691  loss=3.191500 |g|=0.456	lr=1.98e-04 | 79.2%@S36  T=1.16s eta=05:34:06 | 71.3K token/s | 
[Fuyou] head="4" update algorithm=4 t=2.06s
[Section@43700] layer[30-36] tasks=15(nPassBack=0) last_loss=3.18501(0.0695674) N=(580,37212,36792 4369900)
[epoch_0]_43701  loss=3.155931 |g|=0.48	lr=1.98e-04 | 80.0%@S36  T=1.42s eta=06:51:29 | 70.6K token/s | 
[epoch_0]_43711  loss=3.216415 |g|=0.477	lr=1.98e-04 | 80.8%@S36  T=1.09s eta=05:14:18 | 70.9K token/s | 
[epoch_0]_43721  loss=3.173941 |g|=0.455	lr=1.97e-04 | 81.6%@S36  T=1.15s eta=05:31:55 | 70.9K token/s | 
[epoch_0]_43731  loss=3.179561 |g|=0.484	lr=1.97e-04 | 82.5%@S36  T=1.08s eta=05:11:57 | 71.1K token/s | 
[epoch_0]_43741  loss=3.227186 |g|=0.473	lr=1.97e-04 | 83.3%@S36  T=1.08s eta=05:12:02 | 71.3K token/s | 
[epoch_0]_43751  loss=3.226205 |g|=0.485	lr=1.97e-04 | 84.1%@S36  T=1.13s eta=05:24:28 | 71.4K token/s | 
[epoch_0]_43761  loss=3.190582 |g|=0.457	lr=1.97e-04 | 84.9%@S36  T=1.07s eta=05:08:31 | 71.7K token/s | 
[epoch_0]_43771  loss=3.266940 |g|=0.445	lr=1.96e-04 | 85.7%@S36  T=1.08s eta=05:09:55 | 71.9K token/s | 
[epoch_0]_43781  loss=3.258983 |g|=0.461	lr=1.96e-04 | 86.5%@S36  T=1.10s eta=05:15:01 | 72.0K token/s | 
[epoch_0]_43791  loss=3.258383 |g|=0.48	lr=1.96e-04 | 87.4%@S36  T=1.11s eta=05:18:07 | 72.1K token/s | 
[Fuyou] head="5" update algorithm=4 t=2.07s
[eval] 
	 Loss@"edu_fineweb1B"=3.234(0.0017) nBranch=1 nToken=4.01M best=3.2355(217) E2T=0.0318 T=13.484(0)s x=0
	#3.2338±0.1084 tps=298K(4.01408M) a=[3.05279,3.51969] T=13.484(sec)
[Section@43800] layer[0-6] tasks=15(nPassBack=0) last_loss=3.202(0.024492) N=(580,37296,36876 4379900)
[epoch_0]_43801  loss=3.243822 |g|=0.473	lr=1.96e-04 | 88.2%@S36  T=4.22s eta=20:11:45 | 69.5K token/s | 
[epoch_0]_43811  loss=3.216705 |g|=0.477	lr=1.96e-04 | 89.0%@S36  T=1.11s eta=05:18:45 | 69.7K token/s | 
[epoch_0]_43821  loss=3.299480 |g|=0.487	lr=1.95e-04 | 89.8%@S36  T=1.09s eta=05:11:50 | 70.0K token/s | 
[epoch_0]_43831  loss=3.239859 |g|=0.491	lr=1.95e-04 | 90.6%@S36  T=1.09s eta=05:11:07 | 70.3K token/s | 
[epoch_0]_43841  loss=3.219323 |g|=0.513	lr=1.95e-04 | 91.5%@S36  T=1.13s eta=05:23:42 | 70.4K token/s | 
[epoch_0]_43851  loss=3.156255 |g|=0.484	lr=1.95e-04 | 92.3%@S36  T=1.09s eta=05:11:31 | 70.6K token/s | 
[epoch_0]_43861  loss=3.144524 |g|=0.484	lr=1.95e-04 | 93.1%@S36  T=1.10s eta=05:13:42 | 70.8K token/s | 
[epoch_0]_43871  loss=3.207759 |g|=0.453	lr=1.94e-04 | 93.9%@S36  T=1.12s eta=05:20:03 | 71.0K token/s | 
[epoch_0]_43881  loss=3.223554 |g|=0.48	lr=1.94e-04 | 94.7%@S36  T=1.09s eta=05:11:24 | 71.2K token/s | 
[epoch_0]_43891  loss=3.142896 |g|=0.478	lr=1.94e-04 | 95.6%@S36  T=1.08s eta=05:08:33 | 71.4K token/s | 
[Fuyou] head="0" update algorithm=4 t=2.32s
[Section@43900] layer[6-12] tasks=15(nPassBack=0) last_loss=3.22963(-0.00764632) N=(580,37380,36960 4389900)
[epoch_0]_43901  loss=3.257971 |g|=0.453	lr=1.94e-04 | 96.4%@S36  T=1.41s eta=06:41:22 | 70.7K token/s | 
[epoch_0]_43911  loss=3.262634 |g|=0.499	lr=1.94e-04 | 97.2%@S36  T=1.09s eta=05:12:26 | 70.9K token/s | 
[epoch_0]_43921  loss=3.239343 |g|=0.479	lr=1.93e-04 | 98.0%@S36  T=1.08s eta=05:08:08 | 71.2K token/s | 
[epoch_0]_43931  loss=3.167776 |g|=0.491	lr=1.93e-04 | 98.8%@S36  T=1.08s eta=05:08:48 | 71.4K token/s | 
[epoch_0]_43941  loss=3.210315 |g|=0.453	lr=1.93e-04 | 99.7%@S36  T=1.09s eta=05:09:20 | 71.6K token/s | 
[epoch_0]_43945  loss=3.219475 |g|=0.471	lr=1.93e-04 | 100.0%@S36  T=1.07s eta=05:06:09 | 71.8K token/s | 
-------- End of shard_36@"./Datasets/edu_fineweb1B/edu_fineweb_train_000793.bin"-------- 
[shard-37]@"./Datasets/edu_fineweb1B/edu_fineweb_train_000794.bin": tokens=100(M) nShardSamples=1220(3613272) 
[epoch_0]_43951  loss=3.191637 |g|=0.459	lr=1.93e-04 | 0.5%@S37  T=1.08s eta=05:06:26 | 72.1K token/s | 
[epoch_0]_43961  loss=3.225570 |g|=0.461	lr=1.93e-04 | 1.3%@S37  T=1.09s eta=05:11:28 | 72.2K token/s | 
[epoch_0]_43971  loss=3.184155 |g|=0.461	lr=1.92e-04 | 2.1%@S37  T=1.11s eta=05:16:48 | 72.3K token/s | 
[epoch_0]_43981  loss=3.214554 |g|=0.47	lr=1.92e-04 | 2.9%@S37  T=1.07s eta=05:03:36 | 72.5K token/s | 
[epoch_0]_43991  loss=3.193863 |g|=0.454	lr=1.92e-04 | 3.8%@S37  T=1.09s eta=05:09:16 | 72.6K token/s | 
[Fuyou] head="1" update algorithm=4 t=2.05s
[eval] 
	 Loss@"edu_fineweb1B"=3.235(-0.00095) nBranch=1 nToken=4.01M best=3.2338(218) E2T=-0.00317 T=13.4887(0)s x=0
	#3.23475±0.1082 tps=298K(4.01408M) a=[3.05782,3.52287] T=13.4887(sec)
[Section@44000] layer[12-18] tasks=15(nPassBack=0) last_loss=3.23792(-0.0226071) N=(580,37464,37044 4399900)
[epoch_0]_44001  loss=3.152843 |g|=0.452	lr=1.92e-04 | 4.6%@S37  T=4.22s eta=19:59:25 | 70.0K token/s | 
[epoch_0]_44011  loss=3.194452 |g|=0.478	lr=1.92e-04 | 5.4%@S37  T=1.09s eta=05:08:54 | 70.2K token/s | 
[epoch_0]_44021  loss=3.265041 |g|=0.446	lr=1.91e-04 | 6.2%@S37  T=1.15s eta=05:25:22 | 70.3K token/s | 
[epoch_0]_44031  loss=3.158664 |g|=0.494	lr=1.91e-04 | 7.0%@S37  T=1.09s eta=05:07:58 | 70.5K token/s | 
[epoch_0]_44041  loss=3.284697 |g|=0.447	lr=1.91e-04 | 7.8%@S37  T=1.09s eta=05:07:40 | 70.8K token/s | 
[epoch_0]_44051  loss=3.218708 |g|=0.44	lr=1.91e-04 | 8.7%@S37  T=1.14s eta=05:22:35 | 70.8K token/s | 
[epoch_0]_44061  loss=3.177346 |g|=0.453	lr=1.91e-04 | 9.5%@S37  T=1.08s eta=05:06:02 | 71.1K token/s | 
[epoch_0]_44071  loss=3.202541 |g|=0.473	lr=1.90e-04 | 10.3%@S37  T=1.10s eta=05:11:26 | 71.2K token/s | 
[epoch_0]_44081  loss=3.238682 |g|=0.474	lr=1.90e-04 | 11.1%@S37  T=1.13s eta=05:17:58 | 71.3K token/s | 
[epoch_0]_44091  loss=3.201842 |g|=0.483	lr=1.90e-04 | 11.9%@S37  T=1.08s eta=05:04:43 | 71.6K token/s | 
[Fuyou] head="2" update algorithm=4 t=2.22s
[Section@44100] layer[18-24] tasks=15(nPassBack=0) last_loss=3.21966(-0.00361133) N=(580,37548,37128 4409900)
[epoch_0]_44101  loss=3.252256 |g|=0.481	lr=1.90e-04 | 12.8%@S37  T=1.44s eta=06:46:00 | 70.8K token/s | 
[epoch_0]_44111  loss=3.221776 |g|=0.473	lr=1.90e-04 | 13.6%@S37  T=1.06s eta=04:58:06 | 71.2K token/s | 
[epoch_0]_44121  loss=3.232455 |g|=0.49	lr=1.89e-04 | 14.4%@S37  T=1.07s eta=05:02:27 | 71.4K token/s | 
[epoch_0]_44131  loss=3.181084 |g|=0.463	lr=1.89e-04 | 15.2%@S37  T=1.12s eta=05:15:29 | 71.5K token/s | 
[epoch_0]_44141  loss=3.184091 |g|=0.457	lr=1.89e-04 | 16.0%@S37  T=1.07s eta=05:01:40 | 71.8K token/s | 
[epoch_0]_44151  loss=3.203784 |g|=0.457	lr=1.89e-04 | 16.9%@S37  T=1.12s eta=05:14:35 | 71.8K token/s | 
[epoch_0]_44161  loss=3.179722 |g|=0.481	lr=1.89e-04 | 17.7%@S37  T=1.09s eta=05:07:49 | 72.0K token/s | 
[epoch_0]_44171  loss=3.181679 |g|=0.452	lr=1.88e-04 | 18.5%@S37  T=1.09s eta=05:07:37 | 72.1K token/s | 
[epoch_0]_44181  loss=3.246542 |g|=0.482	lr=1.88e-04 | 19.3%@S37  T=1.12s eta=05:15:35 | 72.2K token/s | 
[epoch_0]_44191  loss=3.199255 |g|=0.448	lr=1.88e-04 | 20.1%@S37  T=1.08s eta=05:01:58 | 72.4K token/s | 
[Fuyou] head="3" update algorithm=4 t=2.07s
[eval] 
	 Loss@"edu_fineweb1B"=3.234(0.00088) nBranch=1 nToken=4.01M best=3.2338(218) E2T=0.108 T=13.4874(0)s x=0
	#3.23387±0.1088 tps=298K(4.01408M) a=[3.05103,3.52546] T=13.4874(sec)
[Section@44200] layer[24-30] tasks=15(nPassBack=0) last_loss=3.12623(0.0514357) N=(580,37632,37212 4419900)
[epoch_0]_44201  loss=3.195561 |g|=0.457	lr=1.88e-04 | 21.0%@S37  T=4.23s eta=19:46:05 | 69.7K token/s | 
[epoch_0]_44211  loss=3.127180 |g|=0.472	lr=1.88e-04 | 21.8%@S37  T=1.11s eta=05:10:18 | 69.9K token/s | 
[epoch_0]_44221  loss=3.202448 |g|=0.46	lr=1.87e-04 | 22.6%@S37  T=1.08s eta=05:03:19 | 70.2K token/s | 
[epoch_0]_44231  loss=3.156818 |g|=0.464	lr=1.87e-04 | 23.4%@S37  T=1.12s eta=05:14:27 | 70.4K token/s | 
[epoch_0]_44241  loss=3.247427 |g|=0.463	lr=1.87e-04 | 24.2%@S37  T=1.09s eta=05:05:31 | 70.6K token/s | 
[epoch_0]_44251  loss=3.288649 |g|=0.443	lr=1.87e-04 | 25.1%@S37  T=1.08s eta=05:02:27 | 70.8K token/s | 
[epoch_0]_44261  loss=3.222979 |g|=0.48	lr=1.87e-04 | 25.9%@S37  T=1.10s eta=05:06:24 | 71.0K token/s | 
[epoch_0]_44271  loss=3.251562 |g|=0.464	lr=1.86e-04 | 26.7%@S37  T=1.12s eta=05:11:52 | 71.2K token/s | 
[epoch_0]_44281  loss=3.284046 |g|=0.461	lr=1.86e-04 | 27.5%@S37  T=1.08s eta=05:01:36 | 71.4K token/s | 
[epoch_0]_44291  loss=3.139266 |g|=0.475	lr=1.86e-04 | 28.3%@S37  T=1.10s eta=05:07:14 | 71.5K token/s | 
[Fuyou] head="4" update algorithm=4 t=2.07s
[Section@44300] layer[30-36] tasks=15(nPassBack=0) last_loss=3.19193(-0.00691772) N=(580,37716,37296 4429900)
[epoch_0]_44301  loss=3.196793 |g|=0.444	lr=1.86e-04 | 29.1%@S37  T=1.42s eta=06:35:27 | 70.9K token/s | 
[epoch_0]_44311  loss=3.244978 |g|=0.462	lr=1.86e-04 | 30.0%@S37  T=1.09s eta=05:02:30 | 71.1K token/s | 
[epoch_0]_44321  loss=3.165191 |g|=0.491	lr=1.85e-04 | 30.8%@S37  T=1.08s eta=05:01:12 | 71.3K token/s | 
[epoch_0]_44331  loss=3.180518 |g|=0.468	lr=1.85e-04 | 31.6%@S37  T=1.12s eta=05:12:44 | 71.4K token/s | 
[epoch_0]_44341  loss=3.272977 |g|=0.486	lr=1.85e-04 | 32.4%@S37  T=1.10s eta=05:05:05 | 71.6K token/s | 
[epoch_0]_44351  loss=3.183395 |g|=0.452	lr=1.85e-04 | 33.2%@S37  T=1.10s eta=05:06:01 | 71.7K token/s | 
[epoch_0]_44361  loss=3.141278 |g|=0.472	lr=1.85e-04 | 34.1%@S37  T=1.11s eta=05:07:43 | 71.8K token/s | 
[epoch_0]_44371  loss=3.167865 |g|=0.488	lr=1.84e-04 | 34.9%@S37  T=1.09s eta=05:03:07 | 72.0K token/s | 
[epoch_0]_44381  loss=3.189755 |g|=0.485	lr=1.84e-04 | 35.7%@S37  T=1.09s eta=05:01:23 | 72.2K token/s | 
[epoch_0]_44391  loss=3.231487 |g|=0.499	lr=1.84e-04 | 36.5%@S37  T=1.09s eta=05:03:09 | 72.3K token/s | 
[Fuyou] head="5" update algorithm=4 t=2.08s
[eval] 
	 Loss@"edu_fineweb1B"=3.234(-0.0003) nBranch=1 nToken=4.01M best=3.2338(218) E2T=0.0345 T=13.4929(0)s x=0
	#3.23417±0.1091 tps=297K(4.01408M) a=[3.05588,3.52457] T=13.4929(sec)
[Section@44400] layer[0-6] tasks=15(nPassBack=0) last_loss=3.19971(0.00229025) N=(580,37800,37380 4439900)
[epoch_0]_44401  loss=3.228621 |g|=0.474	lr=1.84e-04 | 37.3%@S37  T=4.22s eta=19:30:46 | 69.7K token/s | 
[epoch_0]_44411  loss=3.242393 |g|=0.448	lr=1.84e-04 | 38.2%@S37  T=1.08s eta=04:59:42 | 70.0K token/s | 
[epoch_0]_44421  loss=3.189515 |g|=0.463	lr=1.83e-04 | 39.0%@S37  T=1.09s eta=05:02:45 | 70.2K token/s | 
[epoch_0]_44431  loss=3.198490 |g|=0.442	lr=1.83e-04 | 39.8%@S37  T=1.07s eta=04:57:03 | 70.5K token/s | 
[epoch_0]_44441  loss=3.160581 |g|=0.468	lr=1.83e-04 | 40.6%@S37  T=1.08s eta=04:59:57 | 70.8K token/s | 
[epoch_0]_44451  loss=3.175856 |g|=0.49	lr=1.83e-04 | 41.4%@S37  T=1.12s eta=05:09:43 | 70.9K token/s | 
[epoch_0]_44461  loss=3.246587 |g|=0.503	lr=1.83e-04 | 42.3%@S37  T=1.08s eta=04:57:51 | 71.1K token/s | 
[epoch_0]_44471  loss=3.190935 |g|=0.457	lr=1.82e-04 | 43.1%@S37  T=1.08s eta=04:58:26 | 71.4K token/s | 
[epoch_0]_44481  loss=3.230006 |g|=0.492	lr=1.82e-04 | 43.9%@S37  T=1.11s eta=05:06:41 | 71.5K token/s | 
[epoch_0]_44491  loss=3.200666 |g|=0.428	lr=1.82e-04 | 44.7%@S37  T=1.11s eta=05:07:06 | 71.6K token/s | 
[Fuyou] head="0" update algorithm=4 t=2.10s
[Section@44500] layer[6-12] tasks=15(nPassBack=0) last_loss=3.15764(0.0719924) N=(580,37884,37464 4449900)
[epoch_0]_44501  loss=3.166498 |g|=0.47	lr=1.82e-04 | 45.5%@S37  T=1.40s eta=06:26:43 | 70.9K token/s | 
[epoch_0]_44511  loss=3.190436 |g|=0.45	lr=1.82e-04 | 46.4%@S37  T=1.07s eta=04:55:50 | 71.2K token/s | 
[epoch_0]_44521  loss=3.181514 |g|=0.448	lr=1.81e-04 | 47.2%@S37  T=1.13s eta=05:10:53 | 71.3K token/s | 
[epoch_0]_44531  loss=3.171865 |g|=0.443	lr=1.81e-04 | 48.0%@S37  T=1.08s eta=04:57:08 | 71.5K token/s | 
[epoch_0]_44541  loss=3.129098 |g|=0.451	lr=1.81e-04 | 48.8%@S37  T=1.08s eta=04:57:48 | 71.7K token/s | 
[epoch_0]_44551  loss=3.174576 |g|=0.46	lr=1.81e-04 | 49.6%@S37  T=1.11s eta=05:04:08 | 71.8K token/s | 
[epoch_0]_44561  loss=3.199121 |g|=0.464	lr=1.81e-04 | 50.4%@S37  T=1.09s eta=04:58:51 | 72.0K token/s | 
[epoch_0]_44571  loss=3.169218 |g|=0.458	lr=1.80e-04 | 51.3%@S37  T=1.09s eta=05:00:21 | 72.1K token/s | 
[epoch_0]_44581  loss=3.118870 |g|=0.454	lr=1.80e-04 | 52.1%@S37  T=1.10s eta=05:01:16 | 72.2K token/s | 
[epoch_0]_44591  loss=3.124585 |g|=0.471	lr=1.80e-04 | 52.9%@S37  T=1.10s eta=05:00:41 | 72.4K token/s | 
[Fuyou] head="1" update algorithm=4 t=2.08s
[eval] 
	 Loss@"edu_fineweb1B"=3.232(0.0017) nBranch=1 nToken=4.01M best=3.2342(221) E2T=0.0127 T=13.4703(0)s x=0
	#3.23248±0.1088 tps=298K(4.01408M) a=[3.05387,3.52525] T=13.4703(sec)
[Section@44600] layer[12-18] tasks=15(nPassBack=0) last_loss=3.21977(0.0181527) N=(580,37968,37548 4459900)
[epoch_0]_44601  loss=3.180884 |g|=0.47	lr=1.80e-04 | 53.7%@S37  T=4.23s eta=19:19:38 | 69.7K token/s | 
[epoch_0]_44611  loss=3.213886 |g|=0.492	lr=1.80e-04 | 54.5%@S37  T=1.11s eta=05:04:27 | 69.9K token/s | 
[epoch_0]_44621  loss=3.203165 |g|=0.472	lr=1.80e-04 | 55.4%@S37  T=1.15s eta=05:14:30 | 70.0K token/s | 
[epoch_0]_44631  loss=3.216105 |g|=0.469	lr=1.79e-04 | 56.2%@S37  T=1.08s eta=04:54:15 | 70.3K token/s | 
[epoch_0]_44641  loss=3.232809 |g|=0.485	lr=1.79e-04 | 57.0%@S37  T=1.09s eta=04:58:13 | 70.5K token/s | 
[epoch_0]_44651  loss=3.152792 |g|=0.454	lr=1.79e-04 | 57.8%@S37  T=1.10s eta=05:00:42 | 70.7K token/s | 
[epoch_0]_44661  loss=3.205397 |g|=0.474	lr=1.79e-04 | 58.6%@S37  T=1.08s eta=04:54:08 | 71.0K token/s | 
[epoch_0]_44671  loss=3.166895 |g|=0.455	lr=1.79e-04 | 59.5%@S37  T=1.08s eta=04:54:46 | 71.2K token/s | 
[epoch_0]_44681  loss=3.193693 |g|=0.46	lr=1.78e-04 | 60.3%@S37  T=1.15s eta=05:13:06 | 71.2K token/s | 
[epoch_0]_44691  loss=3.212848 |g|=0.473	lr=1.78e-04 | 61.1%@S37  T=1.09s eta=04:56:56 | 71.4K token/s | 
[Fuyou] head="2" update algorithm=4 t=2.11s
[Section@44700] layer[18-24] tasks=15(nPassBack=0) last_loss=3.17019(0.0494711) N=(580,38052,37632 4469900)
[epoch_0]_44701  loss=3.165016 |g|=0.464	lr=1.78e-04 | 61.9%@S37  T=1.48s eta=06:42:16 | 70.6K token/s | 
[epoch_0]_44711  loss=3.104972 |g|=0.474	lr=1.78e-04 | 62.7%@S37  T=1.06s eta=04:48:05 | 71.0K token/s | 
[epoch_0]_44721  loss=3.146829 |g|=0.488	lr=1.78e-04 | 63.6%@S37  T=1.08s eta=04:53:22 | 71.2K token/s | 
[epoch_0]_44731  loss=3.202519 |g|=0.499	lr=1.77e-04 | 64.4%@S37  T=1.10s eta=04:58:17 | 71.4K token/s | 
[epoch_0]_44741  loss=3.152561 |g|=0.466	lr=1.77e-04 | 65.2%@S37  T=1.12s eta=05:03:02 | 71.5K token/s | 
[epoch_0]_44751  loss=3.205908 |g|=0.467	lr=1.77e-04 | 66.0%@S37  T=1.11s eta=05:01:56 | 71.6K token/s | 
[epoch_0]_44761  loss=3.195202 |g|=0.451	lr=1.77e-04 | 66.8%@S37  T=1.09s eta=04:56:41 | 71.8K token/s | 
[epoch_0]_44771  loss=3.089417 |g|=0.449	lr=1.77e-04 | 67.7%@S37  T=1.11s eta=04:59:50 | 71.9K token/s | 
[epoch_0]_44781  loss=3.191557 |g|=0.475	lr=1.76e-04 | 68.5%@S37  T=1.11s eta=05:01:44 | 72.0K token/s | 
[epoch_0]_44791  loss=3.203743 |g|=0.476	lr=1.76e-04 | 69.3%@S37  T=1.07s eta=04:50:49 | 72.2K token/s | 
[Fuyou] head="3" update algorithm=4 t=2.19s
[eval] 
	 Loss@"edu_fineweb1B"=3.232(0.00038) nBranch=1 nToken=4.01M best=3.2325(222) E2T=0.107 T=13.4697(0)s x=0
	#3.23209±0.1094 tps=298K(4.01408M) a=[3.05148,3.52956] T=13.4697(sec)
[Section@44800] layer[24-30] tasks=15(nPassBack=0) last_loss=3.12464(0.0015924) N=(580,38136,37716 4479900)
[epoch_0]_44801  loss=3.152565 |g|=0.468	lr=1.76e-04 | 70.1%@S37  T=4.24s eta=19:07:00 | 69.5K token/s | 
[epoch_0]_44811  loss=3.231153 |g|=0.459	lr=1.76e-04 | 70.9%@S37  T=1.13s eta=05:05:52 | 69.7K token/s | 
[epoch_0]_44821  loss=3.188661 |g|=0.445	lr=1.76e-04 | 71.7%@S37  T=1.11s eta=04:59:18 | 69.9K token/s | 
[epoch_0]_44831  loss=3.134908 |g|=0.463	lr=1.75e-04 | 72.6%@S37  T=1.13s eta=05:04:52 | 70.0K token/s | 
[epoch_0]_44841  loss=3.125294 |g|=0.441	lr=1.75e-04 | 73.4%@S37  T=1.12s eta=05:01:22 | 70.2K token/s | 
[epoch_0]_44851  loss=3.130718 |g|=0.456	lr=1.75e-04 | 74.2%@S37  T=1.08s eta=04:52:14 | 70.5K token/s | 
[epoch_0]_44861  loss=3.223114 |g|=0.452	lr=1.75e-04 | 75.0%@S37  T=1.11s eta=04:58:18 | 70.6K token/s | 
[epoch_0]_44871  loss=3.166722 |g|=0.497	lr=1.75e-04 | 75.8%@S37  T=1.15s eta=05:08:44 | 70.7K token/s | 
[epoch_0]_44881  loss=3.077829 |g|=0.451	lr=1.75e-04 | 76.7%@S37  T=1.09s eta=04:53:26 | 70.9K token/s | 
[epoch_0]_44891  loss=3.215396 |g|=0.466	lr=1.74e-04 | 77.5%@S37  T=1.09s eta=04:52:38 | 71.1K token/s | 
[Fuyou] head="4" update algorithm=4 t=2.06s
[Section@44900] layer[30-36] tasks=15(nPassBack=0) last_loss=3.17305(0.018878) N=(580,38220,37800 4489900)
[epoch_0]_44901  loss=3.184687 |g|=0.471	lr=1.74e-04 | 78.3%@S37  T=1.39s eta=06:12:39 | 70.5K token/s | 
[epoch_0]_44911  loss=3.233978 |g|=0.489	lr=1.74e-04 | 79.1%@S37  T=1.07s eta=04:48:12 | 70.8K token/s | 
[epoch_0]_44921  loss=3.180692 |g|=0.514	lr=1.74e-04 | 79.9%@S37  T=1.10s eta=04:55:09 | 71.0K token/s | 
[epoch_0]_44931  loss=3.148495 |g|=0.445	lr=1.74e-04 | 80.8%@S37  T=1.06s eta=04:45:43 | 71.3K token/s | 
[epoch_0]_44941  loss=3.133637 |g|=0.467	lr=1.73e-04 | 81.6%@S37  T=1.09s eta=04:53:32 | 71.5K token/s | 
[epoch_0]_44951  loss=3.219873 |g|=0.517	lr=1.73e-04 | 82.4%@S37  T=1.11s eta=04:57:57 | 71.6K token/s | 
[epoch_0]_44961  loss=3.241119 |g|=0.467	lr=1.73e-04 | 83.2%@S37  T=1.12s eta=04:59:24 | 71.7K token/s | 
[epoch_0]_44971  loss=3.223006 |g|=0.463	lr=1.73e-04 | 84.0%@S37  T=1.08s eta=04:49:49 | 71.9K token/s | 
[epoch_0]_44981  loss=3.177878 |g|=0.446	lr=1.73e-04 | 84.9%@S37  T=1.08s eta=04:50:14 | 72.1K token/s | 
[epoch_0]_44991  loss=3.133215 |g|=0.456	lr=1.72e-04 | 85.7%@S37  T=1.12s eta=04:58:41 | 72.1K token/s | 
[Fuyou] head="5" update algorithm=4 t=2.08s
[eval] 
	 Loss@"edu_fineweb1B"=3.231(0.00075) nBranch=1 nToken=4.01M best=3.2321(223) E2T=-0.0263 T=13.4861(0)s x=0
	#3.23134±0.1092 tps=298K(4.01408M) a=[3.05319,3.527] T=13.4861(sec)
[Section@45000] layer[0-6] tasks=15(nPassBack=0) last_loss=3.25766(-0.0579507) N=(580,38304,37884 4499900)
[epoch_0]_45001  loss=3.204226 |g|=0.47	lr=1.72e-04 | 86.5%@S37  T=4.23s eta=18:50:25 | 69.5K token/s | 
[epoch_0]_45011  loss=3.130303 |g|=0.449	lr=1.72e-04 | 87.3%@S37  T=1.10s eta=04:53:42 | 69.7K token/s | 
[epoch_0]_45021  loss=3.263389 |g|=0.468	lr=1.72e-04 | 88.1%@S37  T=1.10s eta=04:54:03 | 70.0K token/s | 
[epoch_0]_45031  loss=3.227312 |g|=0.461	lr=1.72e-04 | 88.9%@S37  T=1.08s eta=04:47:33 | 70.3K token/s | 
[epoch_0]_45041  loss=3.179148 |g|=0.46	lr=1.71e-04 | 89.8%@S37  T=1.10s eta=04:52:51 | 70.5K token/s | 
[epoch_0]_45051  loss=3.182202 |g|=0.45	lr=1.71e-04 | 90.6%@S37  T=1.07s eta=04:45:55 | 70.8K token/s | 
[epoch_0]_45061  loss=3.186661 |g|=0.469	lr=1.71e-04 | 91.4%@S37  T=1.09s eta=04:50:00 | 71.0K token/s | 
[epoch_0]_45071  loss=3.135417 |g|=0.465	lr=1.71e-04 | 92.2%@S37  T=1.10s eta=04:52:24 | 71.2K token/s | 
[epoch_0]_45081  loss=3.262523 |g|=0.465	lr=1.71e-04 | 93.0%@S37  T=1.11s eta=04:54:58 | 71.3K token/s | 
[epoch_0]_45091  loss=3.191184 |g|=0.454	lr=1.71e-04 | 93.9%@S37  T=1.08s eta=04:46:56 | 71.5K token/s | 
[Fuyou] head="0" update algorithm=4 t=2.23s
[Section@45100] layer[6-12] tasks=15(nPassBack=0) last_loss=3.28234(-0.124695) N=(580,38388,37968 4509900)
[epoch_0]_45101  loss=3.216023 |g|=0.452	lr=1.70e-04 | 94.7%@S37  T=1.40s eta=06:10:38 | 70.9K token/s | 
[epoch_0]_45111  loss=3.190734 |g|=0.45	lr=1.70e-04 | 95.5%@S37  T=1.09s eta=04:48:35 | 71.1K token/s | 
[epoch_0]_45121  loss=3.199675 |g|=0.523	lr=1.70e-04 | 96.3%@S37  T=1.10s eta=04:52:32 | 71.3K token/s | 
[epoch_0]_45131  loss=3.223767 |g|=0.459	lr=1.70e-04 | 97.1%@S37  T=1.08s eta=04:46:52 | 71.5K token/s | 
[epoch_0]_45141  loss=3.194276 |g|=0.459	lr=1.70e-04 | 98.0%@S37  T=1.08s eta=04:46:26 | 71.7K token/s | 
[epoch_0]_45151  loss=3.166750 |g|=0.471	lr=1.69e-04 | 98.8%@S37  T=1.09s eta=04:48:30 | 71.9K token/s | 
[epoch_0]_45161  loss=3.171530 |g|=0.454	lr=1.69e-04 | 99.6%@S37  T=1.14s eta=05:01:58 | 71.9K token/s | 
[epoch_0]_45165  loss=3.220877 |g|=0.459	lr=1.69e-04 | 99.9%@S37  T=1.09s eta=04:47:30 | 72.0K token/s | 
-------- End of shard_37@"./Datasets/edu_fineweb1B/edu_fineweb_train_000794.bin"-------- 
[shard-38]@"./Datasets/edu_fineweb1B/edu_fineweb_train_000795.bin": tokens=100(M) nShardSamples=1220(3710928) 
[epoch_0]_45171  loss=3.287430 |g|=0.467	lr=1.69e-04 | 0.4%@S38  T=1.06s eta=04:40:28 | 72.3K token/s | 
[epoch_0]_45181  loss=3.226785 |g|=0.483	lr=1.69e-04 | 1.2%@S38  T=1.09s eta=04:47:48 | 72.5K token/s | 
[epoch_0]_45191  loss=3.180058 |g|=0.486	lr=1.69e-04 | 2.1%@S38  T=1.13s eta=04:57:59 | 72.5K token/s | 
[Fuyou] head="1" update algorithm=4 t=2.00s
[eval] 
	 Loss@"edu_fineweb1B"=3.227(0.0044) nBranch=1 nToken=4.01M best=3.2313(224) E2T=-0.0167 T=13.4879(0)s x=0
	#3.22698±0.1092 tps=298K(4.01408M) a=[3.04834,3.52397] T=13.4879(sec)
[Section@45200] layer[12-18] tasks=15(nPassBack=0) last_loss=3.24366(-0.0238831) N=(580,38472,38052 4519900)
[epoch_0]_45201  loss=3.197687 |g|=0.447	lr=1.68e-04 | 2.9%@S38  T=4.25s eta=18:42:15 | 69.8K token/s | 
[epoch_0]_45211  loss=3.160007 |g|=0.494	lr=1.68e-04 | 3.7%@S38  T=1.11s eta=04:52:36 | 70.0K token/s | 
[epoch_0]_45221  loss=3.205391 |g|=0.522	lr=1.68e-04 | 4.5%@S38  T=1.09s eta=04:46:22 | 70.3K token/s | 
[epoch_0]_45231  loss=3.107032 |g|=0.497	lr=1.68e-04 | 5.3%@S38  T=1.09s eta=04:46:49 | 70.5K token/s | 
[epoch_0]_45241  loss=3.170575 |g|=0.482	lr=1.68e-04 | 6.2%@S38  T=1.11s eta=04:51:32 | 70.7K token/s | 
[epoch_0]_45251  loss=3.153138 |g|=0.513	lr=1.67e-04 | 7.0%@S38  T=1.07s eta=04:42:25 | 71.0K token/s | 
[epoch_0]_45261  loss=3.197602 |g|=0.493	lr=1.67e-04 | 7.8%@S38  T=1.08s eta=04:45:14 | 71.2K token/s | 
[epoch_0]_45271  loss=3.233559 |g|=0.465	lr=1.67e-04 | 8.6%@S38  T=1.10s eta=04:49:08 | 71.4K token/s | 
[epoch_0]_45281  loss=3.277240 |g|=0.535	lr=1.67e-04 | 9.4%@S38  T=1.10s eta=04:50:06 | 71.5K token/s | 
[epoch_0]_45291  loss=3.179288 |g|=0.448	lr=1.67e-04 | 10.2%@S38  T=1.08s eta=04:42:42 | 71.7K token/s | 
[Fuyou] head="2" update algorithm=4 t=2.24s
[Section@45300] layer[18-24] tasks=15(nPassBack=0) last_loss=3.18532(-0.015126) N=(580,38556,38136 4529900)
[epoch_0]_45301  loss=3.207961 |g|=0.474	lr=1.67e-04 | 11.1%@S38  T=1.41s eta=06:10:00 | 71.0K token/s | 
[epoch_0]_45311  loss=3.209776 |g|=0.473	lr=1.66e-04 | 11.9%@S38  T=1.10s eta=04:47:08 | 71.2K token/s | 
[epoch_0]_45321  loss=3.266922 |g|=0.476	lr=1.66e-04 | 12.7%@S38  T=1.08s eta=04:41:39 | 71.5K token/s | 
[epoch_0]_45331  loss=3.216765 |g|=0.481	lr=1.66e-04 | 13.5%@S38  T=1.11s eta=04:49:20 | 71.6K token/s | 
[epoch_0]_45341  loss=3.242622 |g|=0.446	lr=1.66e-04 | 14.3%@S38  T=1.13s eta=04:54:18 | 71.7K token/s | 
[epoch_0]_45351  loss=3.175975 |g|=0.466	lr=1.66e-04 | 15.2%@S38  T=1.09s eta=04:45:50 | 71.8K token/s | 
[epoch_0]_45361  loss=3.275750 |g|=0.477	lr=1.65e-04 | 16.0%@S38  T=1.09s eta=04:45:03 | 72.0K token/s | 
[epoch_0]_45371  loss=3.205709 |g|=0.497	lr=1.65e-04 | 16.8%@S38  T=1.13s eta=04:53:51 | 72.0K token/s | 
[epoch_0]_45381  loss=3.224447 |g|=0.479	lr=1.65e-04 | 17.6%@S38  T=1.07s eta=04:40:12 | 72.2K token/s | 
[epoch_0]_45391  loss=3.220092 |g|=0.463	lr=1.65e-04 | 18.4%@S38  T=1.08s eta=04:42:36 | 72.4K token/s | 
[Fuyou] head="3" update algorithm=4 t=2.02s
[eval] 
	 Loss@"edu_fineweb1B"=3.221(0.0058) nBranch=1 nToken=4.01M best=3.2270(225) E2T=0.00302 T=13.4881(0)s x=0
	#3.22116±0.1089 tps=298K(4.01408M) a=[3.04311,3.51624] T=13.4881(sec)
[Section@45400] layer[24-30] tasks=15(nPassBack=0) last_loss=3.21814(-0.0935044) N=(580,38640,38220 4539900)
[epoch_0]_45401  loss=3.223612 |g|=0.475	lr=1.65e-04 | 19.3%@S38  T=4.21s eta=18:18:11 | 69.8K token/s | 
[epoch_0]_45411  loss=3.228609 |g|=0.474	lr=1.64e-04 | 20.1%@S38  T=1.15s eta=04:58:49 | 69.8K token/s | 
[epoch_0]_45421  loss=3.255357 |g|=0.488	lr=1.64e-04 | 20.9%@S38  T=1.09s eta=04:44:02 | 70.1K token/s | 
[epoch_0]_45431  loss=3.200996 |g|=0.493	lr=1.64e-04 | 21.7%@S38  T=1.14s eta=04:55:29 | 70.2K token/s | 
[epoch_0]_45441  loss=3.261423 |g|=0.484	lr=1.64e-04 | 22.5%@S38  T=1.09s eta=04:42:01 | 70.5K token/s | 
[epoch_0]_45451  loss=3.174789 |g|=0.464	lr=1.64e-04 | 23.4%@S38  T=1.08s eta=04:39:24 | 70.8K token/s | 
[epoch_0]_45461  loss=3.244429 |g|=0.485	lr=1.64e-04 | 24.2%@S38  T=1.12s eta=04:49:54 | 70.9K token/s | 
[epoch_0]_45471  loss=3.269731 |g|=0.474	lr=1.63e-04 | 25.0%@S38  T=1.12s eta=04:51:24 | 71.0K token/s | 
[epoch_0]_45481  loss=3.202456 |g|=0.468	lr=1.63e-04 | 25.8%@S38  T=1.11s eta=04:47:03 | 71.1K token/s | 
[epoch_0]_45491  loss=3.146445 |g|=0.479	lr=1.63e-04 | 26.6%@S38  T=1.10s eta=04:44:25 | 71.3K token/s | 
[Fuyou] head="4" update algorithm=4 t=2.19s
[Section@45500] layer[30-36] tasks=15(nPassBack=0) last_loss=3.22989(-0.0568442) N=(580,38724,38304 4549900)
[epoch_0]_45501  loss=3.210110 |g|=0.468	lr=1.63e-04 | 27.5%@S38  T=1.42s eta=06:07:39 | 70.6K token/s | 
[epoch_0]_45511  loss=3.175265 |g|=0.468	lr=1.63e-04 | 28.3%@S38  T=1.09s eta=04:42:54 | 70.8K token/s | 
[epoch_0]_45521  loss=3.176801 |g|=0.467	lr=1.62e-04 | 29.1%@S38  T=1.08s eta=04:39:37 | 71.1K token/s | 
[epoch_0]_45531  loss=3.172115 |g|=0.469	lr=1.62e-04 | 29.9%@S38  T=1.10s eta=04:44:52 | 71.2K token/s | 
[epoch_0]_45541  loss=3.284547 |g|=0.492	lr=1.62e-04 | 30.7%@S38  T=1.11s eta=04:46:02 | 71.4K token/s | 
[epoch_0]_45551  loss=3.209212 |g|=0.489	lr=1.62e-04 | 31.5%@S38  T=1.09s eta=04:41:41 | 71.6K token/s | 
[epoch_0]_45561  loss=3.201943 |g|=0.471	lr=1.62e-04 | 32.4%@S38  T=1.13s eta=04:50:47 | 71.6K token/s | 
[epoch_0]_45571  loss=3.193786 |g|=0.48	lr=1.62e-04 | 33.2%@S38  T=1.12s eta=04:49:21 | 71.7K token/s | 
[epoch_0]_45581  loss=3.120899 |g|=0.477	lr=1.61e-04 | 34.0%@S38  T=1.09s eta=04:39:57 | 71.9K token/s | 
[epoch_0]_45591  loss=3.101464 |g|=0.49	lr=1.61e-04 | 34.8%@S38  T=1.09s eta=04:40:50 | 72.0K token/s | 
[Fuyou] head="5" update algorithm=4 t=2.02s
[eval] 
	 Loss@"edu_fineweb1B"=3.220(0.0013) nBranch=1 nToken=4.01M best=3.2212(226) E2T=-0.00778 T=13.4875(0)s x=0
	#3.21981±0.1093 tps=298K(4.01408M) a=[3.04154,3.51608] T=13.4875(sec)
[Section@45600] layer[0-6] tasks=15(nPassBack=0) last_loss=3.22759(0.030072) N=(580,38808,38388 4559900)
[epoch_0]_45601  loss=3.226918 |g|=0.502	lr=1.61e-04 | 35.6%@S38  T=4.22s eta=18:06:22 | 69.4K token/s | 
[epoch_0]_45611  loss=3.181117 |g|=0.47	lr=1.61e-04 | 36.5%@S38  T=1.12s eta=04:46:49 | 69.6K token/s | 
[epoch_0]_45621  loss=3.149048 |g|=0.489	lr=1.61e-04 | 37.3%@S38  T=1.15s eta=04:56:07 | 69.7K token/s | 
[epoch_0]_45631  loss=3.140119 |g|=0.471	lr=1.60e-04 | 38.1%@S38  T=1.10s eta=04:41:32 | 69.9K token/s | 
[epoch_0]_45641  loss=3.166445 |g|=0.455	lr=1.60e-04 | 38.9%@S38  T=1.11s eta=04:44:46 | 70.1K token/s | 
[epoch_0]_45651  loss=3.196497 |g|=0.481	lr=1.60e-04 | 39.7%@S38  T=1.13s eta=04:48:34 | 70.3K token/s | 
[epoch_0]_45661  loss=3.150599 |g|=0.47	lr=1.60e-04 | 40.6%@S38  T=1.08s eta=04:38:00 | 70.5K token/s | 
[epoch_0]_45671  loss=3.200587 |g|=0.47	lr=1.60e-04 | 41.4%@S38  T=1.08s eta=04:36:15 | 70.8K token/s | 
[epoch_0]_45681  loss=3.192337 |g|=0.487	lr=1.59e-04 | 42.2%@S38  T=1.12s eta=04:47:49 | 70.9K token/s | 
[epoch_0]_45691  loss=3.181370 |g|=0.47	lr=1.59e-04 | 43.0%@S38  T=1.13s eta=04:50:11 | 71.0K token/s | 
[Fuyou] head="0" update algorithm=4 t=2.08s
[Section@45700] layer[6-12] tasks=15(nPassBack=0) last_loss=3.20013(0.0822065) N=(580,38892,38472 4569900)
[epoch_0]_45701  loss=3.238930 |g|=0.473	lr=1.59e-04 | 43.8%@S38  T=1.40s eta=05:58:35 | 70.3K token/s | 
[epoch_0]_45711  loss=3.251858 |g|=0.489	lr=1.59e-04 | 44.7%@S38  T=1.08s eta=04:36:12 | 70.6K token/s | 
[epoch_0]_45721  loss=3.223990 |g|=0.475	lr=1.59e-04 | 45.5%@S38  T=1.12s eta=04:44:37 | 70.7K token/s | 
[epoch_0]_45731  loss=3.248013 |g|=0.462	lr=1.59e-04 | 46.3%@S38  T=1.07s eta=04:34:04 | 71.0K token/s | 
[epoch_0]_45741  loss=3.140079 |g|=0.474	lr=1.58e-04 | 47.1%@S38  T=1.13s eta=04:47:14 | 71.1K token/s | 
[epoch_0]_45751  loss=3.203772 |g|=0.458	lr=1.58e-04 | 47.9%@S38  T=1.11s eta=04:43:22 | 71.2K token/s | 
[epoch_0]_45761  loss=3.247125 |g|=0.521	lr=1.58e-04 | 48.8%@S38  T=1.08s eta=04:35:24 | 71.5K token/s | 
[epoch_0]_45771  loss=3.121274 |g|=0.467	lr=1.58e-04 | 49.6%@S38  T=1.09s eta=04:36:20 | 71.6K token/s | 
[epoch_0]_45781  loss=3.159916 |g|=0.471	lr=1.58e-04 | 50.4%@S38  T=1.09s eta=04:38:08 | 71.8K token/s | 
[epoch_0]_45791  loss=3.221180 |g|=0.486	lr=1.57e-04 | 51.2%@S38  T=1.15s eta=04:51:59 | 71.8K token/s | 
[Fuyou] head="1" update algorithm=4 t=2.02s
[eval] 
	 Loss@"edu_fineweb1B"=3.217(0.0029) nBranch=1 nToken=4.01M best=3.2198(227) E2T=-0.0268 T=13.4809(0)s x=0
	#3.21695±0.1087 tps=298K(4.01408M) a=[3.03795,3.51111] T=13.4809(sec)
[Section@45800] layer[12-18] tasks=15(nPassBack=0) last_loss=3.24378(-0.000126123) N=(580,38976,38556 4579900)
[epoch_0]_45801  loss=3.147021 |g|=0.461	lr=1.57e-04 | 52.0%@S38  T=4.26s eta=18:02:30 | 69.2K token/s | 
[epoch_0]_45811  loss=3.209103 |g|=0.491	lr=1.57e-04 | 52.8%@S38  T=1.11s eta=04:41:59 | 69.4K token/s | 
[epoch_0]_45821  loss=3.176323 |g|=0.525	lr=1.57e-04 | 53.7%@S38  T=1.09s eta=04:35:34 | 69.7K token/s | 
[epoch_0]_45831  loss=3.189132 |g|=0.493	lr=1.57e-04 | 54.5%@S38  T=1.11s eta=04:40:24 | 69.9K token/s | 
[epoch_0]_45841  loss=3.227035 |g|=0.501	lr=1.57e-04 | 55.3%@S38  T=1.11s eta=04:40:58 | 70.1K token/s | 
[epoch_0]_45851  loss=3.225998 |g|=0.463	lr=1.56e-04 | 56.1%@S38  T=1.08s eta=04:33:26 | 70.4K token/s | 
[epoch_0]_45861  loss=3.234350 |g|=0.477	lr=1.56e-04 | 56.9%@S38  T=1.07s eta=04:31:10 | 70.7K token/s | 
[epoch_0]_45871  loss=3.194515 |g|=0.449	lr=1.56e-04 | 57.8%@S38  T=1.11s eta=04:40:06 | 70.8K token/s | 
[epoch_0]_45881  loss=3.144269 |g|=0.461	lr=1.56e-04 | 58.6%@S38  T=1.13s eta=04:45:25 | 70.9K token/s | 
[epoch_0]_45891  loss=3.226750 |g|=0.498	lr=1.56e-04 | 59.4%@S38  T=1.08s eta=04:32:33 | 71.2K token/s | 
[Fuyou] head="2" update algorithm=4 t=2.06s
[Section@45900] layer[18-24] tasks=15(nPassBack=0) last_loss=3.1556(0.0297239) N=(580,39060,38640 4589900)
[epoch_0]_45901  loss=3.283799 |g|=0.504	lr=1.55e-04 | 60.2%@S38  T=1.37s eta=05:45:16 | 70.6K token/s | 
[epoch_0]_45911  loss=3.237327 |g|=0.517	lr=1.55e-04 | 61.0%@S38  T=1.09s eta=04:34:29 | 70.8K token/s | 
[epoch_0]_45921  loss=3.141290 |g|=0.481	lr=1.55e-04 | 61.9%@S38  T=1.07s eta=04:30:13 | 71.1K token/s | 
[epoch_0]_45931  loss=3.174967 |g|=0.5	lr=1.55e-04 | 62.7%@S38  T=1.09s eta=04:33:58 | 71.3K token/s | 
[epoch_0]_45941  loss=3.184943 |g|=0.511	lr=1.55e-04 | 63.5%@S38  T=1.11s eta=04:40:07 | 71.4K token/s | 
[epoch_0]_45951  loss=3.085814 |g|=0.481	lr=1.55e-04 | 64.3%@S38  T=1.09s eta=04:33:15 | 71.6K token/s | 
[epoch_0]_45961  loss=3.220043 |g|=0.496	lr=1.54e-04 | 65.1%@S38  T=1.10s eta=04:35:48 | 71.8K token/s | 
[epoch_0]_45971  loss=3.292405 |g|=0.482	lr=1.54e-04 | 66.0%@S38  T=1.15s eta=04:48:29 | 71.8K token/s | 
[epoch_0]_45981  loss=3.094985 |g|=0.496	lr=1.54e-04 | 66.8%@S38  T=1.10s eta=04:36:43 | 71.9K token/s | 
[epoch_0]_45991  loss=3.125167 |g|=0.46	lr=1.54e-04 | 67.6%@S38  T=1.09s eta=04:33:27 | 72.0K token/s | 
[Fuyou] head="3" update algorithm=4 t=2.04s
[eval] 
	 Loss@"edu_fineweb1B"=3.215(0.0016) nBranch=1 nToken=4.01M best=3.2169(228) E2T=0.00961 T=13.4873(0)s x=0
	#3.2153±0.1084 tps=298K(4.01408M) a=[3.03946,3.50753] T=13.4873(sec)
[Section@46000] layer[24-30] tasks=15(nPassBack=0) last_loss=3.20569(0.0124478) N=(580,39144,38724 4599900)
[epoch_0]_46001  loss=3.193800 |g|=0.49	lr=1.54e-04 | 68.4%@S38  T=4.23s eta=17:40:39 | 69.4K token/s | 
[epoch_0]_46011  loss=3.175246 |g|=0.492	lr=1.53e-04 | 69.2%@S38  T=1.14s eta=04:44:31 | 69.5K token/s | 
[epoch_0]_46021  loss=3.192478 |g|=0.475	lr=1.53e-04 | 70.1%@S38  T=1.09s eta=04:31:45 | 69.8K token/s | 
[epoch_0]_46031  loss=3.136521 |g|=0.463	lr=1.53e-04 | 70.9%@S38  T=1.15s eta=04:47:00 | 69.9K token/s | 
[epoch_0]_46041  loss=3.161705 |g|=0.484	lr=1.53e-04 | 71.7%@S38  T=1.10s eta=04:34:02 | 70.2K token/s | 
[epoch_0]_46051  loss=3.190814 |g|=0.499	lr=1.53e-04 | 72.5%@S38  T=1.09s eta=04:32:36 | 70.4K token/s | 
[epoch_0]_46061  loss=3.112657 |g|=0.464	lr=1.53e-04 | 73.3%@S38  T=1.11s eta=04:37:47 | 70.6K token/s | 
[epoch_0]_46071  loss=3.111150 |g|=0.485	lr=1.52e-04 | 74.1%@S38  T=1.09s eta=04:31:26 | 70.8K token/s | 
[epoch_0]_46081  loss=3.205641 |g|=0.478	lr=1.52e-04 | 75.0%@S38  T=1.10s eta=04:33:51 | 71.0K token/s | 
[epoch_0]_46091  loss=3.148259 |g|=0.466	lr=1.52e-04 | 75.8%@S38  T=1.10s eta=04:34:23 | 71.2K token/s | 
[Fuyou] head="4" update algorithm=4 t=2.06s
[Section@46100] layer[30-36] tasks=15(nPassBack=0) last_loss=3.18652(0.0433786) N=(580,39228,38808 4609900)
[epoch_0]_46101  loss=3.224474 |g|=0.513	lr=1.52e-04 | 76.6%@S38  T=1.45s eta=06:01:57 | 70.4K token/s | 
[epoch_0]_46111  loss=3.215699 |g|=0.467	lr=1.52e-04 | 77.4%@S38  T=1.09s eta=04:31:49 | 70.6K token/s | 
[epoch_0]_46121  loss=3.146425 |g|=0.474	lr=1.51e-04 | 78.2%@S38  T=1.10s eta=04:34:22 | 70.8K token/s | 
[epoch_0]_46131  loss=3.162321 |g|=0.47	lr=1.51e-04 | 79.1%@S38  T=1.11s eta=04:35:20 | 71.0K token/s | 
[epoch_0]_46141  loss=3.210752 |g|=0.46	lr=1.51e-04 | 79.9%@S38  T=1.09s eta=04:31:13 | 71.2K token/s | 
[epoch_0]_46151  loss=3.175543 |g|=0.473	lr=1.51e-04 | 80.7%@S38  T=1.11s eta=04:34:12 | 71.3K token/s | 
[epoch_0]_46161  loss=3.234639 |g|=0.513	lr=1.51e-04 | 81.5%@S38  T=1.13s eta=04:39:47 | 71.4K token/s | 
[epoch_0]_46171  loss=3.203794 |g|=0.498	lr=1.51e-04 | 82.3%@S38  T=1.09s eta=04:30:14 | 71.6K token/s | 
[epoch_0]_46181  loss=3.198195 |g|=0.467	lr=1.50e-04 | 83.2%@S38  T=1.09s eta=04:30:27 | 71.7K token/s | 
[epoch_0]_46191  loss=3.133877 |g|=0.482	lr=1.50e-04 | 84.0%@S38  T=1.11s eta=04:35:08 | 71.8K token/s | 
[Fuyou] head="5" update algorithm=4 t=2.18s
[eval] 
	 Loss@"edu_fineweb1B"=3.214(0.0013) nBranch=1 nToken=4.01M best=3.2153(229) E2T=0.0242 T=13.4821(0)s x=0
	#3.21399±0.1087 tps=298K(4.01408M) a=[3.03561,3.50784] T=13.4821(sec)
[Section@46200] layer[0-6] tasks=15(nPassBack=0) last_loss=3.18981(0.0377812) N=(580,39312,38892 4619900)
[epoch_0]_46201  loss=3.058355 |g|=0.474	lr=1.50e-04 | 84.8%@S38  T=4.23s eta=17:25:56 | 69.2K token/s | 
[epoch_0]_46211  loss=3.232373 |g|=0.471	lr=1.50e-04 | 85.6%@S38  T=1.18s eta=04:50:52 | 69.2K token/s | 
[epoch_0]_46221  loss=3.118000 |g|=0.538	lr=1.50e-04 | 86.4%@S38  T=1.14s eta=04:40:38 | 69.4K token/s | 
[epoch_0]_46231  loss=3.203764 |g|=0.47	lr=1.49e-04 | 87.3%@S38  T=1.08s eta=04:25:46 | 69.7K token/s | 
[epoch_0]_46241  loss=3.121636 |g|=0.503	lr=1.49e-04 | 88.1%@S38  T=1.09s eta=04:28:12 | 70.0K token/s | 
[epoch_0]_46251  loss=3.170754 |g|=0.476	lr=1.49e-04 | 88.9%@S38  T=1.10s eta=04:32:12 | 70.2K token/s | 
[epoch_0]_46261  loss=3.207286 |g|=0.479	lr=1.49e-04 | 89.7%@S38  T=1.11s eta=04:33:37 | 70.4K token/s | 
[epoch_0]_46271  loss=3.198725 |g|=0.464	lr=1.49e-04 | 90.5%@S38  T=1.10s eta=04:29:47 | 70.6K token/s | 
[epoch_0]_46281  loss=3.223165 |g|=0.5	lr=1.49e-04 | 91.4%@S38  T=1.08s eta=04:26:01 | 70.8K token/s | 
[epoch_0]_46291  loss=3.180369 |g|=0.495	lr=1.48e-04 | 92.2%@S38  T=1.14s eta=04:39:03 | 70.9K token/s | 
[Fuyou] head="0" update algorithm=4 t=2.06s
[Section@46300] layer[6-12] tasks=15(nPassBack=0) last_loss=3.18893(0.0111964) N=(580,39396,38976 4629900)
[epoch_0]_46301  loss=3.241017 |g|=0.495	lr=1.48e-04 | 93.0%@S38  T=1.43s eta=05:52:21 | 70.2K token/s | 
[epoch_0]_46311  loss=3.125054 |g|=0.488	lr=1.48e-04 | 93.8%@S38  T=1.08s eta=04:25:37 | 70.5K token/s | 
[epoch_0]_46321  loss=3.176228 |g|=0.489	lr=1.48e-04 | 94.6%@S38  T=1.09s eta=04:28:27 | 70.7K token/s | 
[epoch_0]_46331  loss=3.146430 |g|=0.497	lr=1.48e-04 | 95.4%@S38  T=1.12s eta=04:34:38 | 70.8K token/s | 
[epoch_0]_46341  loss=3.117885 |g|=0.479	lr=1.48e-04 | 96.3%@S38  T=1.08s eta=04:25:09 | 71.1K token/s | 
[epoch_0]_46351  loss=3.208964 |g|=0.478	lr=1.47e-04 | 97.1%@S38  T=1.08s eta=04:25:19 | 71.3K token/s | 
[epoch_0]_46361  loss=3.207636 |g|=0.494	lr=1.47e-04 | 97.9%@S38  T=1.12s eta=04:34:35 | 71.4K token/s | 
[epoch_0]_46371  loss=3.225812 |g|=0.481	lr=1.47e-04 | 98.7%@S38  T=1.08s eta=04:23:35 | 71.6K token/s | 
[epoch_0]_46381  loss=3.170518 |g|=0.465	lr=1.47e-04 | 99.5%@S38  T=1.10s eta=04:29:14 | 71.7K token/s | 
[epoch_0]_46386  loss=3.187163 |g|=0.487	lr=1.47e-04 | 100.0%@S38  T=1.09s eta=04:27:00 | 71.9K token/s | 
-------- End of shard_38@"./Datasets/edu_fineweb1B/edu_fineweb_train_000795.bin"-------- 
[shard-39]@"./Datasets/edu_fineweb1B/edu_fineweb_train_000796.bin": tokens=100(M) nShardSamples=1220(3808584) 
[epoch_0]_46391  loss=3.186943 |g|=0.47	lr=1.47e-04 | 0.4%@S39  T=1.08s eta=04:23:58 | 72.1K token/s | 
[Fuyou] head="1" update algorithm=4 t=2.01s
[eval] 
	 Loss@"edu_fineweb1B"=3.213(0.0011) nBranch=1 nToken=4.01M best=3.2140(230) E2T=-0.0469 T=13.4776(0)s x=0
	#3.21285±0.1086 tps=298K(4.01408M) a=[3.03271,3.50437] T=13.4776(sec)
[Section@46400] layer[12-18] tasks=15(nPassBack=0) last_loss=3.25979(-0.0160089) N=(580,39480,39060 4639900)
[epoch_0]_46401  loss=3.136057 |g|=0.478	lr=1.46e-04 | 1.2%@S39  T=4.20s eta=17:04:35 | 69.5K token/s | 
[epoch_0]_46411  loss=3.160244 |g|=0.498	lr=1.46e-04 | 2.0%@S39  T=1.07s eta=04:20:30 | 69.8K token/s | 
[epoch_0]_46421  loss=3.106713 |g|=0.457	lr=1.46e-04 | 2.8%@S39  T=1.10s eta=04:27:14 | 70.1K token/s | 
[epoch_0]_46431  loss=3.151169 |g|=0.5	lr=1.46e-04 | 3.6%@S39  T=1.09s eta=04:26:27 | 70.3K token/s | 
[epoch_0]_46441  loss=3.179972 |g|=0.475	lr=1.46e-04 | 4.5%@S39  T=1.09s eta=04:24:48 | 70.5K token/s | 
[epoch_0]_46451  loss=3.180026 |g|=0.465	lr=1.46e-04 | 5.3%@S39  T=1.09s eta=04:25:43 | 70.8K token/s | 
[epoch_0]_46461  loss=3.165407 |g|=0.479	lr=1.45e-04 | 6.1%@S39  T=1.14s eta=04:37:39 | 70.8K token/s | 
[epoch_0]_46471  loss=3.202266 |g|=0.466	lr=1.45e-04 | 6.9%@S39  T=1.09s eta=04:25:26 | 71.0K token/s | 
[epoch_0]_46481  loss=3.193522 |g|=0.481	lr=1.45e-04 | 7.7%@S39  T=1.10s eta=04:26:04 | 71.2K token/s | 
[epoch_0]_46491  loss=3.126656 |g|=0.523	lr=1.45e-04 | 8.6%@S39  T=1.12s eta=04:31:11 | 71.3K token/s | 
[Fuyou] head="2" update algorithm=4 t=2.08s
[Section@46500] layer[18-24] tasks=15(nPassBack=0) last_loss=3.21351(-0.0579157) N=(580,39564,39144 4649900)
[epoch_0]_46501  loss=3.164786 |g|=0.468	lr=1.45e-04 | 9.4%@S39  T=1.43s eta=05:46:33 | 70.6K token/s | 
[epoch_0]_46511  loss=3.146711 |g|=0.489	lr=1.45e-04 | 10.2%@S39  T=1.07s eta=04:17:59 | 70.9K token/s | 
[epoch_0]_46521  loss=3.139477 |g|=0.48	lr=1.44e-04 | 11.0%@S39  T=1.09s eta=04:24:32 | 71.1K token/s | 
[epoch_0]_46531  loss=3.239650 |g|=0.498	lr=1.44e-04 | 11.8%@S39  T=1.14s eta=04:35:38 | 71.1K token/s | 
[epoch_0]_46541  loss=3.164585 |g|=0.5	lr=1.44e-04 | 12.6%@S39  T=1.10s eta=04:24:39 | 71.3K token/s | 
[epoch_0]_46551  loss=3.140996 |g|=0.462	lr=1.44e-04 | 13.5%@S39  T=1.08s eta=04:20:02 | 71.6K token/s | 
[epoch_0]_46561  loss=3.161696 |g|=0.477	lr=1.44e-04 | 14.3%@S39  T=1.10s eta=04:24:51 | 71.7K token/s | 
[epoch_0]_46571  loss=3.158489 |g|=0.48	lr=1.43e-04 | 15.1%@S39  T=1.16s eta=04:40:38 | 71.7K token/s | 
[epoch_0]_46581  loss=3.165591 |g|=0.51	lr=1.43e-04 | 15.9%@S39  T=1.10s eta=04:23:48 | 71.8K token/s | 
[epoch_0]_46591  loss=3.205636 |g|=0.503	lr=1.43e-04 | 16.7%@S39  T=1.07s eta=04:18:30 | 72.0K token/s | 
[Fuyou] head="3" update algorithm=4 t=2.02s
[eval] 
	 Loss@"edu_fineweb1B"=3.213(0.00032) nBranch=1 nToken=4.01M best=3.2129(231) E2T=-0.0292 T=13.4812(0)s x=0
	#3.21253±0.1082 tps=298K(4.01408M) a=[3.0341,3.50472] T=13.4812(sec)
[Section@46600] layer[24-30] tasks=15(nPassBack=0) last_loss=3.24171(-0.0360198) N=(580,39648,39228 4659900)
[epoch_0]_46601  loss=3.172013 |g|=0.515	lr=1.43e-04 | 17.6%@S39  T=4.22s eta=16:55:16 | 69.4K token/s | 
[epoch_0]_46611  loss=3.175202 |g|=0.473	lr=1.43e-04 | 18.4%@S39  T=1.13s eta=04:32:09 | 69.6K token/s | 
[epoch_0]_46621  loss=3.250097 |g|=0.489	lr=1.43e-04 | 19.2%@S39  T=1.09s eta=04:22:34 | 69.8K token/s | 
[epoch_0]_46631  loss=3.209797 |g|=0.481	lr=1.42e-04 | 20.0%@S39  T=1.15s eta=04:35:15 | 69.9K token/s | 
[epoch_0]_46641  loss=3.166554 |g|=0.502	lr=1.42e-04 | 20.8%@S39  T=1.10s eta=04:23:20 | 70.1K token/s | 
[epoch_0]_46651  loss=3.151295 |g|=0.476	lr=1.42e-04 | 21.7%@S39  T=1.09s eta=04:21:32 | 70.4K token/s | 
[epoch_0]_46661  loss=3.157767 |g|=0.505	lr=1.42e-04 | 22.5%@S39  T=1.10s eta=04:22:35 | 70.6K token/s | 
[epoch_0]_46671  loss=3.200148 |g|=0.489	lr=1.42e-04 | 23.3%@S39  T=1.15s eta=04:36:07 | 70.6K token/s | 
[epoch_0]_46681  loss=3.197178 |g|=0.472	lr=1.42e-04 | 24.1%@S39  T=1.10s eta=04:23:47 | 70.8K token/s | 
[epoch_0]_46691  loss=3.162902 |g|=0.462	lr=1.41e-04 | 24.9%@S39  T=1.09s eta=04:21:40 | 71.0K token/s | 
[Fuyou] head="4" update algorithm=4 t=2.08s
[Section@46700] layer[30-36] tasks=15(nPassBack=0) last_loss=3.1924(-0.0058887) N=(580,39732,39312 4669900)
[epoch_0]_46701  loss=3.102127 |g|=0.448	lr=1.41e-04 | 25.8%@S39  T=1.39s eta=05:31:27 | 70.4K token/s | 
[epoch_0]_46711  loss=3.273346 |g|=0.505	lr=1.41e-04 | 26.6%@S39  T=1.08s eta=04:18:41 | 70.7K token/s | 
[epoch_0]_46721  loss=3.117913 |g|=0.471	lr=1.41e-04 | 27.4%@S39  T=1.09s eta=04:20:25 | 70.9K token/s | 
[epoch_0]_46731  loss=3.197431 |g|=0.479	lr=1.41e-04 | 28.2%@S39  T=1.11s eta=04:24:30 | 71.0K token/s | 
[epoch_0]_46741  loss=3.200257 |g|=0.504	lr=1.40e-04 | 29.0%@S39  T=1.15s eta=04:33:57 | 71.0K token/s | 
[epoch_0]_46751  loss=3.182451 |g|=0.464	lr=1.40e-04 | 29.9%@S39  T=1.09s eta=04:18:56 | 71.3K token/s | 
[epoch_0]_46761  loss=3.148314 |g|=0.48	lr=1.40e-04 | 30.7%@S39  T=1.08s eta=04:17:35 | 71.5K token/s | 
[epoch_0]_46771  loss=3.160692 |g|=0.535	lr=1.40e-04 | 31.5%@S39  T=1.11s eta=04:24:46 | 71.6K token/s | 
[epoch_0]_46781  loss=3.156281 |g|=0.49	lr=1.40e-04 | 32.3%@S39  T=1.12s eta=04:25:37 | 71.7K token/s | 
[epoch_0]_46791  loss=3.134346 |g|=0.509	lr=1.40e-04 | 33.1%@S39  T=1.07s eta=04:14:53 | 71.9K token/s | 
[Fuyou] head="5" update algorithm=4 t=2.02s
[eval] 
	 Loss@"edu_fineweb1B"=3.211(0.0011) nBranch=1 nToken=4.01M best=3.2125(232) E2T=0.0504 T=13.4806(0)s x=0
	#3.21142±0.1086 tps=298K(4.01408M) a=[3.03448,3.50404] T=13.4806(sec)
[Section@46800] layer[0-6] tasks=15(nPassBack=0) last_loss=3.16107(0.0287385) N=(580,39816,39396 4679900)
[epoch_0]_46801  loss=3.112105 |g|=0.492	lr=1.39e-04 | 33.9%@S39  T=4.23s eta=16:43:38 | 69.3K token/s | 
[epoch_0]_46811  loss=3.132669 |g|=0.446	lr=1.39e-04 | 34.8%@S39  T=1.12s eta=04:25:30 | 69.5K token/s | 
[epoch_0]_46821  loss=3.196753 |g|=0.49	lr=1.39e-04 | 35.6%@S39  T=1.10s eta=04:21:02 | 69.7K token/s | 
[epoch_0]_46831  loss=3.167805 |g|=0.477	lr=1.39e-04 | 36.4%@S39  T=1.14s eta=04:29:16 | 69.8K token/s | 
[epoch_0]_46841  loss=3.207691 |g|=0.457	lr=1.39e-04 | 37.2%@S39  T=1.09s eta=04:18:14 | 70.1K token/s | 
[epoch_0]_46851  loss=3.153225 |g|=0.503	lr=1.39e-04 | 38.0%@S39  T=1.09s eta=04:17:27 | 70.3K token/s | 
[epoch_0]_46861  loss=3.263121 |g|=0.502	lr=1.38e-04 | 38.9%@S39  T=1.12s eta=04:23:29 | 70.5K token/s | 
[epoch_0]_46871  loss=3.135774 |g|=0.453	lr=1.38e-04 | 39.7%@S39  T=1.12s eta=04:25:08 | 70.6K token/s | 
[epoch_0]_46881  loss=3.163843 |g|=0.544	lr=1.38e-04 | 40.5%@S39  T=1.09s eta=04:16:10 | 70.9K token/s | 
[epoch_0]_46891  loss=3.275762 |g|=0.504	lr=1.38e-04 | 41.3%@S39  T=1.12s eta=04:23:40 | 71.0K token/s | 
[Fuyou] head="0" update algorithm=4 t=2.08s
[Section@46900] layer[6-12] tasks=15(nPassBack=0) last_loss=3.11667(0.0722666) N=(580,39900,39480 4689900)
[epoch_0]_46901  loss=3.239426 |g|=0.491	lr=1.38e-04 | 42.1%@S39  T=1.47s eta=05:45:26 | 70.2K token/s | 
[epoch_0]_46911  loss=3.130113 |g|=0.479	lr=1.38e-04 | 43.0%@S39  T=1.12s eta=04:23:46 | 70.4K token/s | 
[epoch_0]_46921  loss=3.179128 |g|=0.483	lr=1.37e-04 | 43.8%@S39  T=1.09s eta=04:15:31 | 70.6K token/s | 
[epoch_0]_46931  loss=3.219875 |g|=0.473	lr=1.37e-04 | 44.6%@S39  T=1.09s eta=04:15:06 | 70.9K token/s | 
[epoch_0]_46941  loss=3.230357 |g|=0.524	lr=1.37e-04 | 45.4%@S39  T=1.13s eta=04:24:24 | 71.0K token/s | 
[epoch_0]_46951  loss=3.168190 |g|=0.476	lr=1.37e-04 | 46.2%@S39  T=1.09s eta=04:15:43 | 71.2K token/s | 
[epoch_0]_46961  loss=3.184775 |g|=0.472	lr=1.37e-04 | 47.1%@S39  T=1.10s eta=04:17:47 | 71.3K token/s | 
[epoch_0]_46971  loss=3.215598 |g|=0.468	lr=1.36e-04 | 47.9%@S39  T=1.10s eta=04:18:02 | 71.5K token/s | 
[epoch_0]_46981  loss=3.150245 |g|=0.449	lr=1.36e-04 | 48.7%@S39  T=1.12s eta=04:22:25 | 71.6K token/s | 
[epoch_0]_46991  loss=3.100228 |g|=0.464	lr=1.36e-04 | 49.5%@S39  T=1.07s eta=04:11:08 | 71.8K token/s | 
[Fuyou] head="1" update algorithm=4 t=2.01s
[eval] 
	 Loss@"edu_fineweb1B"=3.210(0.0013) nBranch=1 nToken=4.01M best=3.2114(233) E2T=0.0322 T=13.4835(0)s x=0
	#3.21017±0.1084 tps=298K(4.01408M) a=[3.03271,3.50175] T=13.4835(sec)
[Section@47000] layer[12-18] tasks=15(nPassBack=0) last_loss=3.17793(0.0818613) N=(580,39984,39564 4699900)
[epoch_0]_47001  loss=3.195576 |g|=0.509	lr=1.36e-04 | 50.3%@S39  T=4.22s eta=16:27:12 | 69.2K token/s | 
[epoch_0]_47011  loss=3.164754 |g|=0.486	lr=1.36e-04 | 51.2%@S39  T=1.12s eta=04:22:08 | 69.4K token/s | 
[epoch_0]_47021  loss=3.171137 |g|=0.488	lr=1.36e-04 | 52.0%@S39  T=1.14s eta=04:26:08 | 69.5K token/s | 
[epoch_0]_47031  loss=3.167781 |g|=0.447	lr=1.35e-04 | 52.8%@S39  T=1.15s eta=04:27:53 | 69.6K token/s | 
[epoch_0]_47041  loss=3.186843 |g|=0.492	lr=1.35e-04 | 53.6%@S39  T=1.13s eta=04:23:37 | 69.7K token/s | 
[epoch_0]_47051  loss=3.173001 |g|=0.499	lr=1.35e-04 | 54.4%@S39  T=1.08s eta=04:10:38 | 70.1K token/s | 
[epoch_0]_47061  loss=3.118949 |g|=0.484	lr=1.35e-04 | 55.2%@S39  T=1.10s eta=04:15:10 | 70.3K token/s | 
[epoch_0]_47071  loss=3.226261 |g|=0.473	lr=1.35e-04 | 56.1%@S39  T=1.15s eta=04:26:38 | 70.4K token/s | 
[epoch_0]_47081  loss=3.242697 |g|=0.485	lr=1.35e-04 | 56.9%@S39  T=1.09s eta=04:14:21 | 70.6K token/s | 
[epoch_0]_47091  loss=3.202450 |g|=0.485	lr=1.34e-04 | 57.7%@S39  T=1.09s eta=04:12:57 | 70.8K token/s | 
[Fuyou] head="2" update algorithm=4 t=2.24s
[Section@47100] layer[18-24] tasks=15(nPassBack=0) last_loss=3.26453(-0.0510163) N=(580,40068,39648 4709900)
[epoch_0]_47101  loss=3.183464 |g|=0.491	lr=1.34e-04 | 58.5%@S39  T=1.39s eta=05:21:48 | 70.2K token/s | 
[epoch_0]_47111  loss=3.187404 |g|=0.477	lr=1.34e-04 | 59.3%@S39  T=1.10s eta=04:16:20 | 70.4K token/s | 
[epoch_0]_47121  loss=3.217158 |g|=0.501	lr=1.34e-04 | 60.2%@S39  T=1.10s eta=04:14:37 | 70.6K token/s | 
[epoch_0]_47131  loss=3.138621 |g|=0.493	lr=1.34e-04 | 61.0%@S39  T=1.08s eta=04:10:03 | 70.9K token/s | 
[epoch_0]_47141  loss=3.180755 |g|=0.489	lr=1.34e-04 | 61.8%@S39  T=1.15s eta=04:25:42 | 70.9K token/s | 
[epoch_0]_47151  loss=3.102784 |g|=0.493	lr=1.33e-04 | 62.6%@S39  T=1.09s eta=04:12:28 | 71.1K token/s | 
[epoch_0]_47161  loss=3.193294 |g|=0.495	lr=1.33e-04 | 63.4%@S39  T=1.08s eta=04:10:11 | 71.4K token/s | 
[epoch_0]_47171  loss=3.200811 |g|=0.462	lr=1.33e-04 | 64.3%@S39  T=1.11s eta=04:17:17 | 71.5K token/s | 
[epoch_0]_47181  loss=3.222647 |g|=0.468	lr=1.33e-04 | 65.1%@S39  T=1.11s eta=04:16:05 | 71.6K token/s | 
[epoch_0]_47191  loss=3.165804 |g|=0.478	lr=1.33e-04 | 65.9%@S39  T=1.09s eta=04:10:46 | 71.8K token/s | 
[Fuyou] head="3" update algorithm=4 t=2.02s
[eval] 
	 Loss@"edu_fineweb1B"=3.209(0.001) nBranch=1 nToken=4.01M best=3.2102(234) E2T=0.0144 T=13.4914(0)s x=0
	#3.20912±0.1084 tps=298K(4.01408M) a=[3.03238,3.50453] T=13.4914(sec)
[Section@47200] layer[24-30] tasks=15(nPassBack=0) last_loss=3.19476(0.0469584) N=(580,40152,39732 4719900)
[epoch_0]_47201  loss=3.158492 |g|=0.487	lr=1.33e-04 | 66.7%@S39  T=4.22s eta=16:13:27 | 69.2K token/s | 
[epoch_0]_47211  loss=3.126000 |g|=0.487	lr=1.32e-04 | 67.5%@S39  T=1.14s eta=04:22:57 | 69.3K token/s | 
[epoch_0]_47221  loss=3.151896 |g|=0.507	lr=1.32e-04 | 68.4%@S39  T=1.08s eta=04:08:51 | 69.6K token/s | 
[epoch_0]_47231  loss=3.199283 |g|=0.508	lr=1.32e-04 | 69.2%@S39  T=1.12s eta=04:16:55 | 69.8K token/s | 
[epoch_0]_47241  loss=3.143919 |g|=0.474	lr=1.32e-04 | 70.0%@S39  T=1.16s eta=04:27:10 | 69.8K token/s | 
[epoch_0]_47251  loss=3.126442 |g|=0.486	lr=1.32e-04 | 70.8%@S39  T=1.08s eta=04:07:21 | 70.2K token/s | 
[epoch_0]_47261  loss=3.128606 |g|=0.493	lr=1.32e-04 | 71.6%@S39  T=1.09s eta=04:11:01 | 70.4K token/s | 
[epoch_0]_47271  loss=3.158516 |g|=0.516	lr=1.31e-04 | 72.5%@S39  T=1.11s eta=04:15:43 | 70.5K token/s | 
[epoch_0]_47281  loss=3.153934 |g|=0.485	lr=1.31e-04 | 73.3%@S39  T=1.12s eta=04:17:03 | 70.7K token/s | 
[epoch_0]_47291  loss=3.182047 |g|=0.458	lr=1.31e-04 | 74.1%@S39  T=1.09s eta=04:10:43 | 70.9K token/s | 
[Fuyou] head="4" update algorithm=4 t=2.11s
[Section@47300] layer[30-36] tasks=15(nPassBack=0) last_loss=3.11607(0.0763302) N=(580,40236,39816 4729900)
[epoch_0]_47301  loss=3.165542 |g|=0.469	lr=1.31e-04 | 74.9%@S39  T=1.38s eta=05:16:35 | 70.3K token/s | 
[epoch_0]_47311  loss=3.116351 |g|=0.458	lr=1.31e-04 | 75.7%@S39  T=1.09s eta=04:08:41 | 70.6K token/s | 
[epoch_0]_47321  loss=3.228723 |g|=0.47	lr=1.31e-04 | 76.5%@S39  T=1.08s eta=04:07:15 | 70.8K token/s | 
[epoch_0]_47331  loss=3.221014 |g|=0.466	lr=1.30e-04 | 77.4%@S39  T=1.09s eta=04:09:09 | 71.0K token/s | 
[epoch_0]_47341  loss=3.193906 |g|=0.469	lr=1.30e-04 | 78.2%@S39  T=1.12s eta=04:15:51 | 71.1K token/s | 
[epoch_0]_47351  loss=3.160791 |g|=0.483	lr=1.30e-04 | 79.0%@S39  T=1.12s eta=04:14:49 | 71.2K token/s | 
[epoch_0]_47361  loss=3.162954 |g|=0.475	lr=1.30e-04 | 79.8%@S39  T=1.09s eta=04:09:20 | 71.4K token/s | 
[epoch_0]_47371  loss=3.108456 |g|=0.494	lr=1.30e-04 | 80.6%@S39  T=1.11s eta=04:12:48 | 71.5K token/s | 
[epoch_0]_47381  loss=3.153069 |g|=0.489	lr=1.30e-04 | 81.5%@S39  T=1.15s eta=04:21:26 | 71.5K token/s | 
[epoch_0]_47391  loss=3.101520 |g|=0.485	lr=1.29e-04 | 82.3%@S39  T=1.09s eta=04:07:16 | 71.7K token/s | 
[Fuyou] head="5" update algorithm=4 t=2.21s
[eval] 
	 Loss@"edu_fineweb1B"=3.207(0.0016) nBranch=1 nToken=4.01M best=3.2091(235) E2T=0.0406 T=13.4722(0)s x=0
	#3.2075±0.1085 tps=298K(4.01408M) a=[3.03262,3.50517] T=13.4722(sec)
[Section@47400] layer[0-6] tasks=15(nPassBack=0) last_loss=3.1669(-0.00583506) N=(580,40320,39900 4739900)
[epoch_0]_47401  loss=3.278102 |g|=0.504	lr=1.29e-04 | 83.1%@S39  T=4.25s eta=16:05:42 | 69.1K token/s | 
[epoch_0]_47411  loss=3.153520 |g|=0.479	lr=1.29e-04 | 83.9%@S39  T=1.11s eta=04:12:07 | 69.3K token/s | 
[epoch_0]_47421  loss=3.175667 |g|=0.496	lr=1.29e-04 | 84.7%@S39  T=1.10s eta=04:08:54 | 69.6K token/s | 
[epoch_0]_47431  loss=3.181670 |g|=0.491	lr=1.29e-04 | 85.6%@S39  T=1.12s eta=04:12:57 | 69.8K token/s | 
[epoch_0]_47441  loss=3.165434 |g|=0.496	lr=1.29e-04 | 86.4%@S39  T=1.11s eta=04:12:15 | 70.0K token/s | 
[epoch_0]_47451  loss=3.172435 |g|=0.488	lr=1.28e-04 | 87.2%@S39  T=1.12s eta=04:14:01 | 70.1K token/s | 
[epoch_0]_47461  loss=3.184226 |g|=0.503	lr=1.28e-04 | 88.0%@S39  T=1.09s eta=04:06:45 | 70.4K token/s | 
[epoch_0]_47471  loss=3.150538 |g|=0.468	lr=1.28e-04 | 88.8%@S39  T=1.10s eta=04:09:28 | 70.6K token/s | 
[epoch_0]_47481  loss=3.172486 |g|=0.456	lr=1.28e-04 | 89.7%@S39  T=1.15s eta=04:19:57 | 70.6K token/s | 
[epoch_0]_47491  loss=3.180989 |g|=0.497	lr=1.28e-04 | 90.5%@S39  T=1.10s eta=04:07:27 | 70.8K token/s | 
[Fuyou] head="0" update algorithm=4 t=2.09s
[Section@47500] layer[6-12] tasks=15(nPassBack=0) last_loss=3.10794(0.00872827) N=(580,40404,39984 4749900)
[epoch_0]_47501  loss=3.178765 |g|=0.471	lr=1.28e-04 | 91.3%@S39  T=1.54s eta=05:47:42 | 69.9K token/s | 
[epoch_0]_47511  loss=3.167409 |g|=0.469	lr=1.27e-04 | 92.1%@S39  T=1.10s eta=04:06:57 | 70.2K token/s | 
[epoch_0]_47521  loss=3.203575 |g|=0.488	lr=1.27e-04 | 92.9%@S39  T=1.08s eta=04:04:10 | 70.4K token/s | 
[epoch_0]_47531  loss=3.161574 |g|=0.468	lr=1.27e-04 | 93.8%@S39  T=1.07s eta=04:01:23 | 70.7K token/s | 
[epoch_0]_47541  loss=3.128628 |g|=0.475	lr=1.27e-04 | 94.6%@S39  T=1.10s eta=04:08:27 | 70.9K token/s | 
[epoch_0]_47551  loss=3.094743 |g|=0.473	lr=1.27e-04 | 95.4%@S39  T=1.15s eta=04:17:28 | 70.9K token/s | 
[epoch_0]_47561  loss=3.092192 |g|=0.472	lr=1.27e-04 | 96.2%@S39  T=1.07s eta=04:00:43 | 71.2K token/s | 
[epoch_0]_47571  loss=3.105207 |g|=0.476	lr=1.26e-04 | 97.0%@S39  T=1.08s eta=04:02:43 | 71.4K token/s | 
[epoch_0]_47581  loss=3.084331 |g|=0.464	lr=1.26e-04 | 97.8%@S39  T=1.11s eta=04:09:50 | 71.5K token/s | 
[epoch_0]_47591  loss=3.176286 |g|=0.523	lr=1.26e-04 | 98.7%@S39  T=1.12s eta=04:09:59 | 71.6K token/s | 
[Fuyou] head="1" update algorithm=4 t=2.05s
[eval] 
	 Loss@"edu_fineweb1B"=3.206(0.0017) nBranch=1 nToken=4.01M best=3.2075(236) E2T=0.0927 T=13.4785(0)s x=0
	#3.20581±0.1081 tps=298K(4.01408M) a=[3.02833,3.49981] T=13.4785(sec)
[Section@47600] layer[12-18] tasks=15(nPassBack=0) last_loss=3.11308(0.0648494) N=(580,40488,40068 4759900)
[epoch_0]_47601  loss=3.171501 |g|=0.483	lr=1.26e-04 | 99.5%@S39  T=4.25s eta=15:52:31 | 69.0K token/s | 
[epoch_0]_47607  loss=3.062786 |g|=0.474	lr=1.26e-04 | 100.0%@S39  T=1.09s eta=04:04:12 | 69.3K token/s | 
-------- End of shard_39@"./Datasets/edu_fineweb1B/edu_fineweb_train_000796.bin"-------- 
[shard-40]@"./Datasets/edu_fineweb1B/edu_fineweb_train_000797.bin": tokens=100(M) nShardSamples=1220(3906240) 
[epoch_0]_47611  loss=3.203895 |g|=0.48	lr=1.26e-04 | 0.3%@S40  T=1.11s eta=04:08:36 | 69.5K token/s | 
[epoch_0]_47621  loss=3.151513 |g|=0.512	lr=1.26e-04 | 1.1%@S40  T=1.07s eta=04:00:14 | 69.9K token/s | 
[epoch_0]_47631  loss=3.190939 |g|=0.483	lr=1.25e-04 | 1.9%@S40  T=1.08s eta=04:01:48 | 70.2K token/s | 
[epoch_0]_47641  loss=3.167771 |g|=0.517	lr=1.25e-04 | 2.8%@S40  T=1.14s eta=04:14:04 | 70.3K token/s | 
[epoch_0]_47651  loss=3.268786 |g|=0.531	lr=1.25e-04 | 3.6%@S40  T=1.08s eta=04:00:57 | 70.5K token/s | 
[epoch_0]_47661  loss=3.177845 |g|=0.506	lr=1.25e-04 | 4.4%@S40  T=1.08s eta=04:01:38 | 70.8K token/s | 
[epoch_0]_47671  loss=3.115534 |g|=0.481	lr=1.25e-04 | 5.2%@S40  T=1.11s eta=04:07:16 | 70.9K token/s | 
[epoch_0]_47681  loss=3.194561 |g|=0.506	lr=1.25e-04 | 6.0%@S40  T=1.15s eta=04:15:09 | 71.0K token/s | 
[epoch_0]_47691  loss=3.225813 |g|=0.504	lr=1.24e-04 | 6.9%@S40  T=1.09s eta=04:01:39 | 71.2K token/s | 
[Fuyou] head="2" update algorithm=4 t=2.09s
[Section@47700] layer[18-24] tasks=15(nPassBack=0) last_loss=3.1398(0.124724) N=(580,40572,40152 4769900)
[epoch_0]_47701  loss=3.167120 |g|=0.527	lr=1.24e-04 | 7.7%@S40  T=1.46s eta=05:25:13 | 70.4K token/s | 
[epoch_0]_47711  loss=3.206206 |g|=0.509	lr=1.24e-04 | 8.5%@S40  T=1.09s eta=04:02:19 | 70.7K token/s | 
[epoch_0]_47721  loss=3.260500 |g|=0.536	lr=1.24e-04 | 9.3%@S40  T=1.09s eta=04:02:14 | 70.9K token/s | 
[epoch_0]_47731  loss=3.226812 |g|=0.495	lr=1.24e-04 | 10.1%@S40  T=1.08s eta=03:59:19 | 71.1K token/s | 
[epoch_0]_47741  loss=3.173095 |g|=0.509	lr=1.24e-04 | 11.0%@S40  T=1.09s eta=04:02:02 | 71.3K token/s | 
[epoch_0]_47751  loss=3.179947 |g|=0.501	lr=1.23e-04 | 11.8%@S40  T=1.15s eta=04:14:55 | 71.3K token/s | 
[epoch_0]_47761  loss=3.226226 |g|=0.501	lr=1.23e-04 | 12.6%@S40  T=1.10s eta=04:03:04 | 71.5K token/s | 
[epoch_0]_47771  loss=3.203108 |g|=0.467	lr=1.23e-04 | 13.4%@S40  T=1.09s eta=04:01:26 | 71.6K token/s | 
[epoch_0]_47781  loss=3.154410 |g|=0.517	lr=1.23e-04 | 14.2%@S40  T=1.13s eta=04:09:38 | 71.7K token/s | 
[epoch_0]_47791  loss=3.172624 |g|=0.487	lr=1.23e-04 | 15.0%@S40  T=1.13s eta=04:10:09 | 71.7K token/s | 
[Fuyou] head="3" update algorithm=4 t=2.03s
[eval] 
	 Loss@"edu_fineweb1B"=3.201(0.0045) nBranch=1 nToken=4.01M best=3.2058(237) E2T=-0.0262 T=13.4685(0)s x=0
	#3.20134±0.1081 tps=298K(4.01408M) a=[3.02669,3.49433] T=13.4685(sec)
[Section@47800] layer[24-30] tasks=15(nPassBack=0) last_loss=3.22751(-0.0327582) N=(580,40656,40236 4779900)
[epoch_0]_47801  loss=3.225953 |g|=0.486	lr=1.23e-04 | 15.9%@S40  T=4.24s eta=15:35:31 | 69.1K token/s | 
[epoch_0]_47811  loss=3.147851 |g|=0.518	lr=1.22e-04 | 16.7%@S40  T=1.09s eta=04:00:14 | 69.4K token/s | 
[epoch_0]_47821  loss=3.128455 |g|=0.484	lr=1.22e-04 | 17.5%@S40  T=1.14s eta=04:11:14 | 69.5K token/s | 
[epoch_0]_47831  loss=3.155998 |g|=0.501	lr=1.22e-04 | 18.3%@S40  T=1.09s eta=03:58:55 | 69.8K token/s | 
[epoch_0]_47841  loss=3.192758 |g|=0.506	lr=1.22e-04 | 19.1%@S40  T=1.10s eta=04:01:58 | 70.1K token/s | 
[epoch_0]_47851  loss=3.193550 |g|=0.516	lr=1.22e-04 | 20.0%@S40  T=1.11s eta=04:03:56 | 70.2K token/s | 
[epoch_0]_47861  loss=3.225511 |g|=0.48	lr=1.22e-04 | 20.8%@S40  T=1.13s eta=04:08:05 | 70.4K token/s | 
[epoch_0]_47871  loss=3.121135 |g|=0.497	lr=1.21e-04 | 21.6%@S40  T=1.10s eta=04:00:46 | 70.6K token/s | 
[epoch_0]_47881  loss=3.190771 |g|=0.495	lr=1.21e-04 | 22.4%@S40  T=1.10s eta=04:00:53 | 70.8K token/s | 
[epoch_0]_47891  loss=3.083381 |g|=0.508	lr=1.21e-04 | 23.2%@S40  T=1.13s eta=04:08:33 | 70.8K token/s | 
[Fuyou] head="4" update algorithm=4 t=2.04s
[Section@47900] layer[30-36] tasks=15(nPassBack=0) last_loss=3.1527(-0.0366218) N=(580,40740,40320 4789900)
[epoch_0]_47901  loss=3.197929 |g|=0.479	lr=1.21e-04 | 24.1%@S40  T=1.43s eta=05:12:46 | 70.2K token/s | 
[epoch_0]_47911  loss=3.178832 |g|=0.519	lr=1.21e-04 | 24.9%@S40  T=1.10s eta=04:00:44 | 70.4K token/s | 
[epoch_0]_47921  loss=3.217360 |g|=0.48	lr=1.21e-04 | 25.7%@S40  T=1.08s eta=03:56:39 | 70.6K token/s | 
[epoch_0]_47931  loss=3.222981 |g|=0.49	lr=1.20e-04 | 26.5%@S40  T=1.12s eta=04:05:35 | 70.8K token/s | 
[epoch_0]_47941  loss=3.200454 |g|=0.534	lr=1.20e-04 | 27.3%@S40  T=1.10s eta=04:00:03 | 70.9K token/s | 
[epoch_0]_47951  loss=3.204112 |g|=0.459	lr=1.20e-04 | 28.2%@S40  T=1.09s eta=03:58:30 | 71.1K token/s | 
[epoch_0]_47961  loss=3.142544 |g|=0.479	lr=1.20e-04 | 29.0%@S40  T=1.12s eta=04:04:35 | 71.2K token/s | 
[epoch_0]_47971  loss=3.166423 |g|=0.468	lr=1.20e-04 | 29.8%@S40  T=1.18s eta=04:17:46 | 71.1K token/s | 
[epoch_0]_47981  loss=3.133805 |g|=0.474	lr=1.20e-04 | 30.6%@S40  T=1.10s eta=03:59:24 | 71.3K token/s | 
[epoch_0]_47991  loss=3.106100 |g|=0.496	lr=1.20e-04 | 31.4%@S40  T=1.09s eta=03:57:42 | 71.5K token/s | 
[Fuyou] head="5" update algorithm=4 t=2.32s
[eval] 
	 Loss@"edu_fineweb1B"=3.198(0.0035) nBranch=1 nToken=4.01M best=3.2013(238) E2T=-0.0151 T=13.4844(0)s x=0
	#3.19782±0.1088 tps=298K(4.01408M) a=[3.02334,3.49277] T=13.4844(sec)
[Section@48000] layer[0-6] tasks=15(nPassBack=0) last_loss=3.2129(-0.045996) N=(580,40824,40404 4799900)
[epoch_0]_48001  loss=3.203815 |g|=0.494	lr=1.19e-04 | 32.3%@S40  T=4.24s eta=15:21:35 | 68.9K token/s | 
[epoch_0]_48011  loss=3.161692 |g|=0.483	lr=1.19e-04 | 33.1%@S40  T=1.12s eta=04:02:45 | 69.1K token/s | 
[epoch_0]_48021  loss=3.164170 |g|=0.498	lr=1.19e-04 | 33.9%@S40  T=1.09s eta=03:56:49 | 69.4K token/s | 
[epoch_0]_48031  loss=3.212858 |g|=0.477	lr=1.19e-04 | 34.7%@S40  T=1.15s eta=04:09:41 | 69.5K token/s | 
[epoch_0]_48041  loss=3.139748 |g|=0.49	lr=1.19e-04 | 35.5%@S40  T=1.08s eta=03:54:32 | 69.8K token/s | 
[epoch_0]_48051  loss=3.206088 |g|=0.505	lr=1.19e-04 | 36.3%@S40  T=1.09s eta=03:55:38 | 70.0K token/s | 
[epoch_0]_48061  loss=3.143166 |g|=0.465	lr=1.18e-04 | 37.2%@S40  T=1.11s eta=03:59:39 | 70.2K token/s | 
[epoch_0]_48071  loss=3.195518 |g|=0.48	lr=1.18e-04 | 38.0%@S40  T=1.15s eta=04:09:19 | 70.3K token/s | 
[epoch_0]_48081  loss=3.174219 |g|=0.507	lr=1.18e-04 | 38.8%@S40  T=1.09s eta=03:54:21 | 70.5K token/s | 
[epoch_0]_48091  loss=3.178947 |g|=0.469	lr=1.18e-04 | 39.6%@S40  T=1.09s eta=03:55:06 | 70.8K token/s | 
[Fuyou] head="0" update algorithm=4 t=2.07s
[Section@48100] layer[6-12] tasks=15(nPassBack=0) last_loss=3.16304(-0.0551004) N=(580,40908,40488 4809900)
[epoch_0]_48101  loss=3.218875 |g|=0.481	lr=1.18e-04 | 40.4%@S40  T=1.39s eta=04:59:16 | 70.2K token/s | 
[epoch_0]_48111  loss=3.164173 |g|=0.553	lr=1.18e-04 | 41.3%@S40  T=1.10s eta=03:56:28 | 70.4K token/s | 
[epoch_0]_48121  loss=3.165149 |g|=0.501	lr=1.17e-04 | 42.1%@S40  T=1.09s eta=03:54:29 | 70.6K token/s | 
[epoch_0]_48131  loss=3.204669 |g|=0.454	lr=1.17e-04 | 42.9%@S40  T=1.15s eta=04:08:03 | 70.7K token/s | 
[epoch_0]_48141  loss=3.202076 |g|=0.528	lr=1.17e-04 | 43.7%@S40  T=1.09s eta=03:54:32 | 70.9K token/s | 
[epoch_0]_48151  loss=3.163686 |g|=0.494	lr=1.17e-04 | 44.5%@S40  T=1.09s eta=03:54:51 | 71.1K token/s | 
[epoch_0]_48161  loss=3.201667 |g|=0.485	lr=1.17e-04 | 45.4%@S40  T=1.11s eta=03:59:04 | 71.2K token/s | 
[epoch_0]_48171  loss=3.235091 |g|=0.499	lr=1.17e-04 | 46.2%@S40  T=1.11s eta=03:57:22 | 71.3K token/s | 
[epoch_0]_48181  loss=3.228908 |g|=0.529	lr=1.16e-04 | 47.0%@S40  T=1.09s eta=03:53:10 | 71.5K token/s | 
[epoch_0]_48191  loss=3.164741 |g|=0.48	lr=1.16e-04 | 47.8%@S40  T=1.09s eta=03:52:30 | 71.7K token/s | 
[Fuyou] head="1" update algorithm=4 t=2.02s
[eval] 
	 Loss@"edu_fineweb1B"=3.195(0.0029) nBranch=1 nToken=4.01M best=3.1978(239) E2T=0.0948 T=13.4645(0)s x=0
	#3.19495±0.1086 tps=298K(4.01408M) a=[3.02229,3.48906] T=13.4645(sec)
[Section@48200] layer[12-18] tasks=15(nPassBack=0) last_loss=3.1001(0.0129762) N=(580,40992,40572 4819900)
[epoch_0]_48201  loss=3.094158 |g|=0.489	lr=1.16e-04 | 48.6%@S40  T=4.22s eta=15:02:29 | 69.1K token/s | 
[epoch_0]_48211  loss=3.143918 |g|=0.472	lr=1.16e-04 | 49.5%@S40  T=1.12s eta=03:58:27 | 69.3K token/s | 
[epoch_0]_48221  loss=3.157913 |g|=0.504	lr=1.16e-04 | 50.3%@S40  T=1.13s eta=04:01:16 | 69.5K token/s | 
[epoch_0]_48231  loss=3.171646 |g|=0.492	lr=1.16e-04 | 51.1%@S40  T=1.11s eta=03:56:11 | 69.7K token/s | 
[epoch_0]_48241  loss=3.212819 |g|=0.478	lr=1.15e-04 | 51.9%@S40  T=1.09s eta=03:52:08 | 70.0K token/s | 
[epoch_0]_48251  loss=3.242541 |g|=0.483	lr=1.15e-04 | 52.7%@S40  T=1.10s eta=03:55:11 | 70.2K token/s | 
[epoch_0]_48261  loss=3.257964 |g|=0.492	lr=1.15e-04 | 53.6%@S40  T=1.15s eta=04:04:59 | 70.3K token/s | 
[epoch_0]_48271  loss=3.185283 |g|=0.472	lr=1.15e-04 | 54.4%@S40  T=1.09s eta=03:52:49 | 70.5K token/s | 
[epoch_0]_48281  loss=3.126864 |g|=0.485	lr=1.15e-04 | 55.2%@S40  T=1.09s eta=03:52:43 | 70.7K token/s | 
[epoch_0]_48291  loss=3.143943 |g|=0.459	lr=1.15e-04 | 56.0%@S40  T=1.09s eta=03:50:53 | 70.9K token/s | 
[Fuyou] head="2" update algorithm=4 t=2.07s
[Section@48300] layer[18-24] tasks=15(nPassBack=0) last_loss=3.17041(-0.0306041) N=(580,41076,40656 4829900)
[epoch_0]_48301  loss=3.160099 |g|=0.468	lr=1.15e-04 | 56.8%@S40  T=1.60s eta=05:39:46 | 69.9K token/s | 
[epoch_0]_48311  loss=3.129539 |g|=0.48	lr=1.14e-04 | 57.6%@S40  T=1.10s eta=03:52:23 | 70.2K token/s | 
[epoch_0]_48321  loss=3.171864 |g|=0.461	lr=1.14e-04 | 58.5%@S40  T=1.08s eta=03:49:00 | 70.5K token/s | 
[epoch_0]_48331  loss=3.204846 |g|=0.471	lr=1.14e-04 | 59.3%@S40  T=1.14s eta=04:02:05 | 70.5K token/s | 
[epoch_0]_48341  loss=3.204335 |g|=0.503	lr=1.14e-04 | 60.1%@S40  T=1.09s eta=03:49:43 | 70.8K token/s | 
[epoch_0]_48351  loss=3.196581 |g|=0.479	lr=1.14e-04 | 60.9%@S40  T=1.10s eta=03:53:00 | 71.0K token/s | 
[epoch_0]_48361  loss=3.175772 |g|=0.503	lr=1.14e-04 | 61.7%@S40  T=1.11s eta=03:53:52 | 71.1K token/s | 
[epoch_0]_48371  loss=3.198410 |g|=0.521	lr=1.13e-04 | 62.6%@S40  T=1.14s eta=04:00:52 | 71.1K token/s | 
[epoch_0]_48381  loss=3.190026 |g|=0.477	lr=1.13e-04 | 63.4%@S40  T=1.09s eta=03:49:53 | 71.3K token/s | 
[epoch_0]_48391  loss=3.218727 |g|=0.5	lr=1.13e-04 | 64.2%@S40  T=1.09s eta=03:48:47 | 71.5K token/s | 
[Fuyou] head="3" update algorithm=4 t=2.07s
[eval] 
	 Loss@"edu_fineweb1B"=3.193(0.0018) nBranch=1 nToken=4.01M best=3.1950(240) E2T=-0.069 T=13.4563(0)s x=0
	#3.19317±0.1085 tps=298K(4.01408M) a=[3.01683,3.4855] T=13.4563(sec)
[Section@48400] layer[24-30] tasks=15(nPassBack=0) last_loss=3.26219(-0.034677) N=(580,41160,40740 4839900)
[epoch_0]_48401  loss=3.202026 |g|=0.501	lr=1.13e-04 | 65.0%@S40  T=4.24s eta=14:52:11 | 68.9K token/s | 
[epoch_0]_48411  loss=3.166106 |g|=0.482	lr=1.13e-04 | 65.8%@S40  T=1.17s eta=04:05:48 | 69.0K token/s | 
[epoch_0]_48421  loss=3.173982 |g|=0.476	lr=1.13e-04 | 66.7%@S40  T=1.11s eta=03:53:47 | 69.2K token/s | 
[epoch_0]_48431  loss=3.042614 |g|=0.477	lr=1.12e-04 | 67.5%@S40  T=1.16s eta=04:04:11 | 69.3K token/s | 
[epoch_0]_48441  loss=3.132026 |g|=0.471	lr=1.12e-04 | 68.3%@S40  T=1.10s eta=03:51:04 | 69.5K token/s | 
[epoch_0]_48451  loss=3.223362 |g|=0.504	lr=1.12e-04 | 69.1%@S40  T=1.10s eta=03:50:10 | 69.8K token/s | 
[epoch_0]_48461  loss=3.210695 |g|=0.509	lr=1.12e-04 | 69.9%@S40  T=1.11s eta=03:53:30 | 70.0K token/s | 
[epoch_0]_48471  loss=3.222463 |g|=0.489	lr=1.12e-04 | 70.8%@S40  T=1.15s eta=04:01:50 | 70.0K token/s | 
[epoch_0]_48481  loss=3.137410 |g|=0.496	lr=1.12e-04 | 71.6%@S40  T=1.09s eta=03:48:51 | 70.3K token/s | 
[epoch_0]_48491  loss=3.190933 |g|=0.491	lr=1.12e-04 | 72.4%@S40  T=1.10s eta=03:50:54 | 70.5K token/s | 
[Fuyou] head="4" update algorithm=4 t=2.12s
[Section@48500] layer[30-36] tasks=15(nPassBack=0) last_loss=3.22868(-0.0759869) N=(580,41244,40824 4849900)
[epoch_0]_48501  loss=3.122524 |g|=0.459	lr=1.11e-04 | 73.2%@S40  T=1.51s eta=05:15:29 | 69.7K token/s | 
[epoch_0]_48511  loss=3.147452 |g|=0.484	lr=1.11e-04 | 74.0%@S40  T=1.08s eta=03:45:11 | 70.0K token/s | 
[epoch_0]_48521  loss=3.196757 |g|=0.488	lr=1.11e-04 | 74.9%@S40  T=1.09s eta=03:47:54 | 70.2K token/s | 
[epoch_0]_48531  loss=3.151751 |g|=0.48	lr=1.11e-04 | 75.7%@S40  T=1.12s eta=03:52:42 | 70.4K token/s | 
[epoch_0]_48541  loss=3.144715 |g|=0.499	lr=1.11e-04 | 76.5%@S40  T=1.12s eta=03:53:02 | 70.5K token/s | 
[epoch_0]_48551  loss=3.142661 |g|=0.527	lr=1.11e-04 | 77.3%@S40  T=1.10s eta=03:49:40 | 70.7K token/s | 
[epoch_0]_48561  loss=3.139481 |g|=0.501	lr=1.10e-04 | 78.1%@S40  T=1.10s eta=03:48:00 | 70.9K token/s | 
[epoch_0]_48571  loss=3.167795 |g|=0.515	lr=1.10e-04 | 78.9%@S40  T=1.14s eta=03:57:29 | 70.9K token/s | 
[epoch_0]_48581  loss=3.155667 |g|=0.478	lr=1.10e-04 | 79.8%@S40  T=1.09s eta=03:45:13 | 71.2K token/s | 
[epoch_0]_48591  loss=3.161559 |g|=0.481	lr=1.10e-04 | 80.6%@S40  T=1.09s eta=03:45:17 | 71.4K token/s | 
[Fuyou] head="5" update algorithm=4 t=2.10s
[eval] 
	 Loss@"edu_fineweb1B"=3.192(0.0016) nBranch=1 nToken=4.01M best=3.1932(241) E2T=-0.00237 T=13.4458(0)s x=0
	#3.19152±0.1084 tps=299K(4.01408M) a=[3.01689,3.48622] T=13.4458(sec)
[Section@48600] layer[0-6] tasks=15(nPassBack=0) last_loss=3.19389(0.0190051) N=(580,41328,40908 4859900)
[epoch_0]_48601  loss=3.130155 |g|=0.485	lr=1.10e-04 | 81.4%@S40  T=4.22s eta=14:35:29 | 68.8K token/s | 
[epoch_0]_48611  loss=3.194747 |g|=0.514	lr=1.10e-04 | 82.2%@S40  T=1.28s eta=04:24:37 | 68.5K token/s | 
[epoch_0]_48621  loss=3.170919 |g|=0.513	lr=1.10e-04 | 83.0%@S40  T=1.10s eta=03:47:07 | 68.9K token/s | 
[epoch_0]_48631  loss=3.194504 |g|=0.484	lr=1.09e-04 | 83.9%@S40  T=1.16s eta=03:59:42 | 68.9K token/s | 
[epoch_0]_48641  loss=3.120649 |g|=0.483	lr=1.09e-04 | 84.7%@S40  T=1.08s eta=03:43:44 | 69.3K token/s | 
[epoch_0]_48651  loss=3.113420 |g|=0.487	lr=1.09e-04 | 85.5%@S40  T=1.07s eta=03:41:48 | 69.6K token/s | 
[epoch_0]_48661  loss=3.215023 |g|=0.511	lr=1.09e-04 | 86.3%@S40  T=1.12s eta=03:51:19 | 69.8K token/s | 
[epoch_0]_48671  loss=3.254435 |g|=0.52	lr=1.09e-04 | 87.1%@S40  T=1.11s eta=03:48:42 | 70.0K token/s | 
[epoch_0]_48681  loss=3.194923 |g|=0.518	lr=1.09e-04 | 88.0%@S40  T=1.09s eta=03:43:57 | 70.3K token/s | 
[epoch_0]_48691  loss=3.228475 |g|=0.486	lr=1.08e-04 | 88.8%@S40  T=1.09s eta=03:44:24 | 70.5K token/s | 
[Fuyou] head="0" update algorithm=4 t=2.27s
[Section@48700] layer[6-12] tasks=15(nPassBack=0) last_loss=3.1967(-0.033663) N=(580,41412,40992 4869900)
[epoch_0]_48701  loss=3.174853 |g|=0.491	lr=1.08e-04 | 89.6%@S40  T=1.39s eta=04:44:53 | 69.9K token/s | 
[epoch_0]_48711  loss=3.134312 |g|=0.509	lr=1.08e-04 | 90.4%@S40  T=1.13s eta=03:52:16 | 70.1K token/s | 
[epoch_0]_48721  loss=3.195046 |g|=0.483	lr=1.08e-04 | 91.2%@S40  T=1.09s eta=03:43:11 | 70.3K token/s | 
[epoch_0]_48731  loss=3.145936 |g|=0.481	lr=1.08e-04 | 92.1%@S40  T=1.10s eta=03:44:53 | 70.5K token/s | 
[epoch_0]_48741  loss=3.167156 |g|=0.499	lr=1.08e-04 | 92.9%@S40  T=1.08s eta=03:41:52 | 70.8K token/s | 
[epoch_0]_48751  loss=3.148484 |g|=0.519	lr=1.08e-04 | 93.7%@S40  T=1.10s eta=03:45:19 | 71.0K token/s | 
[epoch_0]_48761  loss=3.177766 |g|=0.526	lr=1.07e-04 | 94.5%@S40  T=1.11s eta=03:47:26 | 71.1K token/s | 
[epoch_0]_48771  loss=3.120834 |g|=0.473	lr=1.07e-04 | 95.3%@S40  T=1.09s eta=03:43:09 | 71.3K token/s | 
[epoch_0]_48781  loss=3.131534 |g|=0.488	lr=1.07e-04 | 96.2%@S40  T=1.08s eta=03:39:47 | 71.6K token/s | 
[epoch_0]_48791  loss=3.130573 |g|=0.497	lr=1.07e-04 | 97.0%@S40  T=1.09s eta=03:41:32 | 71.7K token/s | 
[Fuyou] head="1" update algorithm=4 t=2.08s
[eval] 
	 Loss@"edu_fineweb1B"=3.190(0.0019) nBranch=1 nToken=4.01M best=3.1915(242) E2T=0.0749 T=13.4523(0)s x=0
	#3.18964±0.1081 tps=298K(4.01408M) a=[3.01288,3.48338] T=13.4523(sec)
[Section@48800] layer[12-18] tasks=15(nPassBack=0) last_loss=3.11471(-0.014607) N=(580,41496,41076 4879900)
[epoch_0]_48801  loss=3.136182 |g|=0.514	lr=1.07e-04 | 97.8%@S40  T=4.22s eta=14:19:48 | 69.1K token/s | 
[epoch_0]_48811  loss=3.159546 |g|=0.497	lr=1.07e-04 | 98.6%@S40  T=1.10s eta=03:44:20 | 69.4K token/s | 
[epoch_0]_48821  loss=3.191534 |g|=0.489	lr=1.06e-04 | 99.4%@S40  T=1.12s eta=03:48:48 | 69.6K token/s | 
[epoch_0]_48827  loss=3.148689 |g|=0.469	lr=1.06e-04 | 99.9%@S40  T=1.15s eta=03:54:55 | 69.6K token/s | 
[epoch_0]_48828  loss=3.133639 |g|=0.495	lr=1.06e-04 | 100.0%@S40  T=1.13s eta=03:49:00 | 69.8K token/s | 
-------- End of shard_40@"./Datasets/edu_fineweb1B/edu_fineweb_train_000797.bin"-------- 
[shard-41]@"./Datasets/edu_fineweb1B/edu_fineweb_train_000798.bin": tokens=100(M) nShardSamples=1220(4003896) 
[epoch_0]_48831  loss=3.250363 |g|=0.467	lr=1.06e-04 | 0.2%@S41  T=1.14s eta=03:51:31 | 69.9K token/s | 
[epoch_0]_48841  loss=3.154533 |g|=0.496	lr=1.06e-04 | 1.1%@S41  T=1.06s eta=03:35:54 | 70.3K token/s | 
[epoch_0]_48851  loss=3.145164 |g|=0.504	lr=1.06e-04 | 1.9%@S41  T=1.12s eta=03:46:56 | 70.4K token/s | 
[epoch_0]_48861  loss=3.178864 |g|=0.499	lr=1.06e-04 | 2.7%@S41  T=1.09s eta=03:41:59 | 70.6K token/s | 
[epoch_0]_48871  loss=3.156893 |g|=0.495	lr=1.06e-04 | 3.5%@S41  T=1.07s eta=03:36:36 | 70.9K token/s | 
[epoch_0]_48881  loss=3.140258 |g|=0.488	lr=1.06e-04 | 4.3%@S41  T=1.11s eta=03:45:40 | 71.1K token/s | 
[epoch_0]_48891  loss=3.141963 |g|=0.501	lr=1.05e-04 | 5.2%@S41  T=1.11s eta=03:44:00 | 71.2K token/s | 
[Fuyou] head="2" update algorithm=4 t=2.45s
[Section@48900] layer[18-24] tasks=15(nPassBack=0) last_loss=3.14712(0.0232849) N=(580,41580,41160 4889900)
[epoch_0]_48901  loss=3.135602 |g|=0.505	lr=1.05e-04 | 6.0%@S41  T=1.45s eta=04:52:18 | 70.5K token/s | 
[epoch_0]_48911  loss=3.126669 |g|=0.483	lr=1.05e-04 | 6.8%@S41  T=1.07s eta=03:36:29 | 70.8K token/s | 
[epoch_0]_48921  loss=3.077931 |g|=0.484	lr=1.05e-04 | 7.6%@S41  T=1.09s eta=03:40:05 | 71.0K token/s | 
[epoch_0]_48931  loss=3.194485 |g|=0.543	lr=1.05e-04 | 8.4%@S41  T=1.10s eta=03:42:15 | 71.2K token/s | 
[epoch_0]_48941  loss=3.142887 |g|=0.476	lr=1.05e-04 | 9.3%@S41  T=1.09s eta=03:40:36 | 71.4K token/s | 
[epoch_0]_48951  loss=3.122494 |g|=0.508	lr=1.04e-04 | 10.1%@S41  T=1.14s eta=03:48:58 | 71.4K token/s | 
[epoch_0]_48961  loss=3.175788 |g|=0.47	lr=1.04e-04 | 10.9%@S41  T=1.08s eta=03:38:00 | 71.6K token/s | 
[epoch_0]_48971  loss=3.209393 |g|=0.474	lr=1.04e-04 | 11.7%@S41  T=1.09s eta=03:39:55 | 71.8K token/s | 
[epoch_0]_48981  loss=3.204505 |g|=0.509	lr=1.04e-04 | 12.5%@S41  T=1.10s eta=03:40:54 | 71.9K token/s | 
[epoch_0]_48991  loss=3.130993 |g|=0.467	lr=1.04e-04 | 13.4%@S41  T=1.10s eta=03:40:59 | 72.0K token/s | 
[Fuyou] head="3" update algorithm=4 t=2.09s
[eval] 
	 Loss@"edu_fineweb1B"=3.190(-0.00067) nBranch=1 nToken=4.01M best=3.1896(243) E2T=0.146 T=13.4279(0)s x=0
	#3.19031±0.1083 tps=299K(4.01408M) a=[3.01572,3.48436] T=13.4279(sec)
[Section@49000] layer[24-30] tasks=15(nPassBack=0) last_loss=3.04478(0.217407) N=(580,41664,41244 4899900)
[epoch_0]_49001  loss=3.213091 |g|=0.465	lr=1.04e-04 | 14.2%@S41  T=4.25s eta=14:11:51 | 69.4K token/s | 
[epoch_0]_49011  loss=3.180302 |g|=0.497	lr=1.04e-04 | 15.0%@S41  T=1.11s eta=03:41:54 | 69.6K token/s | 
[epoch_0]_49021  loss=3.145550 |g|=0.487	lr=1.03e-04 | 15.8%@S41  T=1.09s eta=03:37:43 | 69.9K token/s | 
[epoch_0]_49031  loss=3.116431 |g|=0.496	lr=1.03e-04 | 16.6%@S41  T=1.09s eta=03:37:47 | 70.2K token/s | 
[epoch_0]_49041  loss=3.189260 |g|=0.504	lr=1.03e-04 | 17.5%@S41  T=1.13s eta=03:45:13 | 70.3K token/s | 
[epoch_0]_49051  loss=3.070502 |g|=0.49	lr=1.03e-04 | 18.3%@S41  T=1.09s eta=03:37:38 | 70.5K token/s | 
[epoch_0]_49061  loss=3.163336 |g|=0.457	lr=1.03e-04 | 19.1%@S41  T=1.08s eta=03:35:25 | 70.8K token/s | 
[epoch_0]_49071  loss=3.226149 |g|=0.489	lr=1.03e-04 | 19.9%@S41  T=1.09s eta=03:37:51 | 71.0K token/s | 
[epoch_0]_49081  loss=3.101742 |g|=0.461	lr=1.03e-04 | 20.7%@S41  T=1.16s eta=03:50:16 | 71.0K token/s | 
[epoch_0]_49091  loss=3.198619 |g|=0.501	lr=1.02e-04 | 21.5%@S41  T=1.10s eta=03:38:27 | 71.2K token/s | 
[Fuyou] head="4" update algorithm=4 t=2.26s
[Section@49100] layer[30-36] tasks=15(nPassBack=0) last_loss=3.2302(-0.00151491) N=(580,41748,41328 4909900)
[epoch_0]_49101  loss=3.149170 |g|=0.493	lr=1.02e-04 | 22.4%@S41  T=1.37s eta=04:33:07 | 70.6K token/s | 
[epoch_0]_49111  loss=3.194739 |g|=0.488	lr=1.02e-04 | 23.2%@S41  T=1.07s eta=03:33:00 | 70.9K token/s | 
[epoch_0]_49121  loss=3.171264 |g|=0.502	lr=1.02e-04 | 24.0%@S41  T=1.07s eta=03:31:36 | 71.2K token/s | 
[epoch_0]_49131  loss=3.132862 |g|=0.472	lr=1.02e-04 | 24.8%@S41  T=1.09s eta=03:35:49 | 71.4K token/s | 
[epoch_0]_49141  loss=3.230451 |g|=0.491	lr=1.02e-04 | 25.6%@S41  T=1.09s eta=03:35:46 | 71.6K token/s | 
[epoch_0]_49151  loss=3.189859 |g|=0.514	lr=1.01e-04 | 26.5%@S41  T=1.09s eta=03:36:28 | 71.8K token/s | 
[epoch_0]_49161  loss=3.150876 |g|=0.488	lr=1.01e-04 | 27.3%@S41  T=1.12s eta=03:41:17 | 71.8K token/s | 
[epoch_0]_49171  loss=3.152145 |g|=0.48	lr=1.01e-04 | 28.1%@S41  T=1.13s eta=03:43:46 | 71.9K token/s | 
[epoch_0]_49181  loss=3.207842 |g|=0.47	lr=1.01e-04 | 28.9%@S41  T=1.08s eta=03:32:29 | 72.1K token/s | 
[epoch_0]_49191  loss=3.082362 |g|=0.491	lr=1.01e-04 | 29.7%@S41  T=1.09s eta=03:34:16 | 72.3K token/s | 
[Fuyou] head="5" update algorithm=4 t=2.06s
[eval] 
	 Loss@"edu_fineweb1B"=3.190(0.00035) nBranch=1 nToken=4.01M best=3.1896(243) E2T=0.0118 T=13.463(0)s x=0
	#3.18997±0.1084 tps=298K(4.01408M) a=[3.01671,3.48561] T=13.463(sec)
[Section@49200] layer[0-6] tasks=15(nPassBack=0) last_loss=3.1782(0.015692) N=(580,41832,41412 4919900)
[epoch_0]_49201  loss=3.117805 |g|=0.481	lr=1.01e-04 | 30.6%@S41  T=4.21s eta=13:50:30 | 69.6K token/s | 
[epoch_0]_49211  loss=3.176364 |g|=0.517	lr=1.01e-04 | 31.4%@S41  T=1.08s eta=03:33:13 | 69.9K token/s | 
[epoch_0]_49221  loss=3.164942 |g|=0.518	lr=1.00e-04 | 32.2%@S41  T=1.14s eta=03:45:23 | 70.0K token/s | 
[epoch_0]_49231  loss=3.151584 |g|=0.474	lr=1.00e-04 | 33.0%@S41  T=1.10s eta=03:36:28 | 70.2K token/s | 
[epoch_0]_49241  loss=3.157132 |g|=0.506	lr=1.00e-04 | 33.8%@S41  T=1.09s eta=03:33:59 | 70.5K token/s | 
[epoch_0]_49251  loss=3.132398 |g|=0.49	lr=1.00e-04 | 34.7%@S41  T=1.12s eta=03:39:16 | 70.6K token/s | 
[epoch_0]_49261  loss=3.188565 |g|=0.483	lr=9.99e-05 | 35.5%@S41  T=1.17s eta=03:49:22 | 70.6K token/s | 
[epoch_0]_49271  loss=3.186811 |g|=0.472	lr=9.97e-05 | 36.3%@S41  T=1.10s eta=03:36:13 | 70.8K token/s | 
[epoch_0]_49281  loss=3.115051 |g|=0.474	lr=9.96e-05 | 37.1%@S41  T=1.09s eta=03:33:37 | 71.0K token/s | 
[epoch_0]_49291  loss=3.124697 |g|=0.497	lr=9.94e-05 | 37.9%@S41  T=1.12s eta=03:38:23 | 71.1K token/s | 
[Fuyou] head="0" update algorithm=4 t=2.10s
[Section@49300] layer[6-12] tasks=15(nPassBack=0) last_loss=3.09267(0.104035) N=(580,41916,41496 4929900)
[epoch_0]_49301  loss=3.174331 |g|=0.475	lr=9.93e-05 | 38.7%@S41  T=1.42s eta=04:37:27 | 70.4K token/s | 
[epoch_0]_49311  loss=3.171378 |g|=0.491	lr=9.91e-05 | 39.6%@S41  T=1.12s eta=03:38:07 | 70.6K token/s | 
[epoch_0]_49321  loss=3.155343 |g|=0.472	lr=9.90e-05 | 40.4%@S41  T=1.14s eta=03:43:26 | 70.6K token/s | 
[epoch_0]_49331  loss=3.135877 |g|=0.493	lr=9.88e-05 | 41.2%@S41  T=1.12s eta=03:37:45 | 70.8K token/s | 
[epoch_0]_49341  loss=3.111842 |g|=0.482	lr=9.87e-05 | 42.0%@S41  T=1.08s eta=03:30:54 | 71.0K token/s | 
[epoch_0]_49351  loss=3.190522 |g|=0.495	lr=9.85e-05 | 42.8%@S41  T=1.09s eta=03:32:46 | 71.2K token/s | 
[epoch_0]_49361  loss=3.143796 |g|=0.47	lr=9.84e-05 | 43.7%@S41  T=1.15s eta=03:44:00 | 71.2K token/s | 
[epoch_0]_49371  loss=3.084160 |g|=0.514	lr=9.82e-05 | 44.5%@S41  T=1.09s eta=03:32:39 | 71.4K token/s | 
[epoch_0]_49381  loss=3.136944 |g|=0.504	lr=9.81e-05 | 45.3%@S41  T=1.10s eta=03:33:19 | 71.6K token/s | 
[epoch_0]_49391  loss=3.170875 |g|=0.483	lr=9.79e-05 | 46.1%@S41  T=1.11s eta=03:36:10 | 71.7K token/s | 
[Fuyou] head="1" update algorithm=4 t=2.09s
[eval] 
	 Loss@"edu_fineweb1B"=3.189(0.001) nBranch=1 nToken=4.01M best=3.1900(245) E2T=0.0555 T=13.4459(0)s x=0
	#3.18896±0.1084 tps=299K(4.01408M) a=[3.01143,3.48335] T=13.4459(sec)
[Section@49400] layer[12-18] tasks=15(nPassBack=0) last_loss=3.13342(-0.0187137) N=(580,42000,41580 4939900)
[epoch_0]_49401  loss=3.085696 |g|=0.492	lr=9.78e-05 | 46.9%@S41  T=4.23s eta=13:39:28 | 69.0K token/s | 
[epoch_0]_49411  loss=3.165883 |g|=0.542	lr=9.77e-05 | 47.8%@S41  T=1.09s eta=03:32:07 | 69.3K token/s | 
[epoch_0]_49421  loss=3.227536 |g|=0.517	lr=9.75e-05 | 48.6%@S41  T=1.16s eta=03:43:45 | 69.4K token/s | 
[epoch_0]_49431  loss=3.095087 |g|=0.494	lr=9.74e-05 | 49.4%@S41  T=1.08s eta=03:28:30 | 69.7K token/s | 
[epoch_0]_49441  loss=3.211084 |g|=0.484	lr=9.72e-05 | 50.2%@S41  T=1.09s eta=03:30:40 | 70.0K token/s | 
[epoch_0]_49451  loss=3.083527 |g|=0.492	lr=9.71e-05 | 51.0%@S41  T=1.10s eta=03:32:54 | 70.2K token/s | 
[epoch_0]_49461  loss=3.189435 |g|=0.503	lr=9.69e-05 | 51.9%@S41  T=1.16s eta=03:43:17 | 70.3K token/s | 
[epoch_0]_49471  loss=3.201612 |g|=0.49	lr=9.68e-05 | 52.7%@S41  T=1.09s eta=03:30:34 | 70.5K token/s | 
[epoch_0]_49481  loss=3.167924 |g|=0.487	lr=9.66e-05 | 53.5%@S41  T=1.09s eta=03:29:45 | 70.7K token/s | 
[epoch_0]_49491  loss=3.145303 |g|=0.504	lr=9.65e-05 | 54.3%@S41  T=1.12s eta=03:35:43 | 70.8K token/s | 
[Fuyou] head="2" update algorithm=4 t=2.06s
[Section@49500] layer[18-24] tasks=15(nPassBack=0) last_loss=3.18495(-0.037828) N=(580,42084,41664 4949900)
[epoch_0]_49501  loss=3.180076 |g|=0.491	lr=9.63e-05 | 55.1%@S41  T=1.39s eta=04:27:18 | 70.2K token/s | 
[epoch_0]_49511  loss=3.109994 |g|=0.502	lr=9.62e-05 | 56.0%@S41  T=1.09s eta=03:30:01 | 70.5K token/s | 
[epoch_0]_49521  loss=3.219816 |g|=0.475	lr=9.60e-05 | 56.8%@S41  T=1.10s eta=03:31:05 | 70.7K token/s | 
[epoch_0]_49531  loss=3.182530 |g|=0.494	lr=9.59e-05 | 57.6%@S41  T=1.15s eta=03:40:09 | 70.7K token/s | 
[epoch_0]_49541  loss=3.188102 |g|=0.49	lr=9.58e-05 | 58.4%@S41  T=1.08s eta=03:27:23 | 71.0K token/s | 
[epoch_0]_49551  loss=3.125938 |g|=0.521	lr=9.56e-05 | 59.2%@S41  T=1.09s eta=03:29:20 | 71.2K token/s | 
[epoch_0]_49561  loss=3.093775 |g|=0.484	lr=9.55e-05 | 60.0%@S41  T=1.13s eta=03:36:14 | 71.2K token/s | 
[epoch_0]_49571  loss=3.106650 |g|=0.491	lr=9.53e-05 | 60.9%@S41  T=1.12s eta=03:33:23 | 71.3K token/s | 
[epoch_0]_49581  loss=3.171085 |g|=0.519	lr=9.52e-05 | 61.7%@S41  T=1.10s eta=03:29:38 | 71.5K token/s | 
[epoch_0]_49591  loss=3.194501 |g|=0.486	lr=9.50e-05 | 62.5%@S41  T=1.11s eta=03:31:26 | 71.6K token/s | 
[Fuyou] head="3" update algorithm=4 t=2.09s
[eval] 
	 Loss@"edu_fineweb1B"=3.188(0.0009) nBranch=1 nToken=4.01M best=3.1890(246) E2T=0.0987 T=13.4359(0)s x=0
	#3.18806±0.1085 tps=299K(4.01408M) a=[3.01134,3.48081] T=13.4359(sec)
[Section@49600] layer[24-30] tasks=15(nPassBack=0) last_loss=3.08932(-0.0445385) N=(580,42168,41748 4959900)
[epoch_0]_49601  loss=3.118237 |g|=0.501	lr=9.49e-05 | 63.3%@S41  T=4.22s eta=13:23:56 | 69.0K token/s | 
[epoch_0]_49611  loss=3.209204 |g|=0.48	lr=9.47e-05 | 64.1%@S41  T=1.13s eta=03:34:44 | 69.2K token/s | 
[epoch_0]_49621  loss=3.142340 |g|=0.503	lr=9.46e-05 | 65.0%@S41  T=1.11s eta=03:31:00 | 69.4K token/s | 
[epoch_0]_49631  loss=3.195007 |g|=0.5	lr=9.45e-05 | 65.8%@S41  T=1.14s eta=03:36:59 | 69.5K token/s | 
[epoch_0]_49641  loss=3.120781 |g|=0.487	lr=9.43e-05 | 66.6%@S41  T=1.09s eta=03:27:19 | 69.8K token/s | 
[epoch_0]_49651  loss=3.151496 |g|=0.487	lr=9.42e-05 | 67.4%@S41  T=1.11s eta=03:30:39 | 70.0K token/s | 
[epoch_0]_49661  loss=3.147424 |g|=0.491	lr=9.40e-05 | 68.2%@S41  T=1.12s eta=03:31:58 | 70.2K token/s | 
[epoch_0]_49671  loss=3.152182 |g|=0.512	lr=9.39e-05 | 69.1%@S41  T=1.16s eta=03:39:28 | 70.2K token/s | 
[epoch_0]_49681  loss=3.096926 |g|=0.508	lr=9.37e-05 | 69.9%@S41  T=1.08s eta=03:25:13 | 70.5K token/s | 
[epoch_0]_49691  loss=3.203950 |g|=0.486	lr=9.36e-05 | 70.7%@S41  T=1.09s eta=03:26:39 | 70.7K token/s | 
[Fuyou] head="4" update algorithm=4 t=2.02s
[Section@49700] layer[30-36] tasks=15(nPassBack=0) last_loss=3.12883(0.101371) N=(580,42252,41832 4969900)
[epoch_0]_49701  loss=3.147717 |g|=0.475	lr=9.35e-05 | 71.5%@S41  T=1.41s eta=04:27:00 | 70.1K token/s | 
[epoch_0]_49711  loss=3.200444 |g|=0.504	lr=9.33e-05 | 72.3%@S41  T=1.10s eta=03:28:08 | 70.3K token/s | 
[epoch_0]_49721  loss=3.146326 |g|=0.49	lr=9.32e-05 | 73.2%@S41  T=1.10s eta=03:27:24 | 70.5K token/s | 
[epoch_0]_49731  loss=3.110923 |g|=0.489	lr=9.30e-05 | 74.0%@S41  T=1.12s eta=03:31:06 | 70.6K token/s | 
[epoch_0]_49741  loss=3.202859 |g|=0.494	lr=9.29e-05 | 74.8%@S41  T=1.12s eta=03:31:17 | 70.7K token/s | 
[epoch_0]_49751  loss=3.067079 |g|=0.48	lr=9.27e-05 | 75.6%@S41  T=1.08s eta=03:23:26 | 71.0K token/s | 
[epoch_0]_49761  loss=3.105566 |g|=0.495	lr=9.26e-05 | 76.4%@S41  T=1.09s eta=03:25:40 | 71.2K token/s | 
[epoch_0]_49771  loss=3.152981 |g|=0.506	lr=9.25e-05 | 77.3%@S41  T=1.14s eta=03:34:06 | 71.2K token/s | 
[epoch_0]_49781  loss=3.158882 |g|=0.492	lr=9.23e-05 | 78.1%@S41  T=1.10s eta=03:26:14 | 71.4K token/s | 
[epoch_0]_49791  loss=3.174583 |g|=0.5	lr=9.22e-05 | 78.9%@S41  T=1.10s eta=03:25:36 | 71.5K token/s | 
[Fuyou] head="5" update algorithm=4 t=2.12s
[eval] 
	 Loss@"edu_fineweb1B"=3.187(0.001) nBranch=1 nToken=4.01M best=3.1881(247) E2T=0.0152 T=13.428(0)s x=0
	#3.18706±0.1084 tps=299K(4.01408M) a=[3.0105,3.47743] T=13.428(sec)
[Section@49800] layer[0-6] tasks=15(nPassBack=0) last_loss=3.1719(0.00630355) N=(580,42336,41916 4979900)
[epoch_0]_49801  loss=3.098405 |g|=0.525	lr=9.20e-05 | 79.7%@S41  T=4.23s eta=13:12:40 | 68.9K token/s | 
[epoch_0]_49811  loss=3.164559 |g|=0.486	lr=9.19e-05 | 80.5%@S41  T=1.06s eta=03:18:38 | 69.3K token/s | 
[epoch_0]_49821  loss=3.164978 |g|=0.493	lr=9.17e-05 | 81.3%@S41  T=1.10s eta=03:24:43 | 69.6K token/s | 
[epoch_0]_49831  loss=3.133143 |g|=0.51	lr=9.16e-05 | 82.2%@S41  T=1.12s eta=03:29:08 | 69.8K token/s | 
[epoch_0]_49841  loss=3.145498 |g|=0.524	lr=9.15e-05 | 83.0%@S41  T=1.09s eta=03:23:50 | 70.0K token/s | 
[epoch_0]_49851  loss=3.117465 |g|=0.484	lr=9.13e-05 | 83.8%@S41  T=1.08s eta=03:21:37 | 70.3K token/s | 
[epoch_0]_49861  loss=3.123788 |g|=0.477	lr=9.12e-05 | 84.6%@S41  T=1.12s eta=03:29:06 | 70.5K token/s | 
[epoch_0]_49871  loss=3.153993 |g|=0.499	lr=9.10e-05 | 85.4%@S41  T=1.17s eta=03:36:49 | 70.5K token/s | 
[epoch_0]_49881  loss=3.119116 |g|=0.488	lr=9.09e-05 | 86.3%@S41  T=1.09s eta=03:23:20 | 70.7K token/s | 
[epoch_0]_49891  loss=3.213730 |g|=0.482	lr=9.08e-05 | 87.1%@S41  T=1.09s eta=03:22:22 | 70.9K token/s | 
[Fuyou] head="0" update algorithm=4 t=2.03s
[Section@49900] layer[6-12] tasks=15(nPassBack=0) last_loss=3.1465(-0.0538361) N=(580,42420,42000 4989900)
[epoch_0]_49901  loss=3.206596 |g|=0.484	lr=9.06e-05 | 87.9%@S41  T=1.43s eta=04:25:42 | 70.2K token/s | 
[epoch_0]_49911  loss=3.194978 |g|=0.5	lr=9.05e-05 | 88.7%@S41  T=1.15s eta=03:33:32 | 70.3K token/s | 
[epoch_0]_49921  loss=3.117838 |g|=0.489	lr=9.03e-05 | 89.5%@S41  T=1.09s eta=03:22:37 | 70.5K token/s | 
[epoch_0]_49931  loss=3.139524 |g|=0.543	lr=9.02e-05 | 90.4%@S41  T=1.11s eta=03:24:47 | 70.7K token/s | 
[epoch_0]_49941  loss=3.147576 |g|=0.501	lr=9.01e-05 | 91.2%@S41  T=1.16s eta=03:34:22 | 70.7K token/s | 
[epoch_0]_49951  loss=3.083478 |g|=0.5	lr=8.99e-05 | 92.0%@S41  T=1.10s eta=03:23:03 | 70.9K token/s | 
[epoch_0]_49961  loss=3.121865 |g|=0.477	lr=8.98e-05 | 92.8%@S41  T=1.10s eta=03:23:12 | 71.0K token/s | 
[epoch_0]_49971  loss=3.189596 |g|=0.477	lr=8.96e-05 | 93.6%@S41  T=1.11s eta=03:23:49 | 71.2K token/s | 
[epoch_0]_49981  loss=3.049443 |g|=0.492	lr=8.95e-05 | 94.5%@S41  T=1.14s eta=03:30:49 | 71.2K token/s | 
[epoch_0]_49991  loss=3.168163 |g|=0.481	lr=8.94e-05 | 95.3%@S41  T=1.10s eta=03:22:05 | 71.4K token/s | 
[Fuyou] head="1" update algorithm=4 t=2.11s
[eval] 
	 Loss@"edu_fineweb1B"=3.187(0.00046) nBranch=1 nToken=4.01M best=3.1871(248) E2T=-0.0288 T=13.4403(0)s x=0
	#3.1866±0.1084 tps=299K(4.01408M) a=[3.01078,3.47952] T=13.4403(sec)
[Section@50000] layer[12-18] tasks=15(nPassBack=0) last_loss=3.21543(-0.0820048) N=(580,42504,42084 4999900)
[epoch_0]_50001  loss=3.095898 |g|=0.504	lr=8.92e-05 | 96.1%@S41  T=4.23s eta=12:57:21 | 68.8K token/s | 
[epoch_0]_50011  loss=3.117571 |g|=0.492	lr=8.91e-05 | 96.9%@S41  T=1.12s eta=03:26:28 | 69.0K token/s | 
[epoch_0]_50021  loss=3.142791 |g|=0.531	lr=8.89e-05 | 97.7%@S41  T=1.08s eta=03:17:44 | 69.3K token/s | 
[epoch_0]_50031  loss=3.128809 |g|=0.52	lr=8.88e-05 | 98.6%@S41  T=1.12s eta=03:25:33 | 69.5K token/s | 
[epoch_0]_50041  loss=3.086800 |g|=0.476	lr=8.87e-05 | 99.4%@S41  T=1.10s eta=03:21:40 | 69.8K token/s | 
[epoch_0]_50048  loss=3.161794 |g|=0.484	lr=8.86e-05 | 99.9%@S41  T=1.16s eta=03:32:45 | 69.8K token/s | 
-------- End of shard_41@"./Datasets/edu_fineweb1B/edu_fineweb_train_000798.bin"-------- 
[shard-42]@"./Datasets/edu_fineweb1B/edu_fineweb_train_000799.bin": tokens=100(M) nShardSamples=1220(4101552) 
[epoch_0]_50051  loss=3.184165 |g|=0.498	lr=8.85e-05 | 0.2%@S42  T=1.10s eta=03:20:59 | 70.0K token/s | 
[epoch_0]_50061  loss=3.206949 |g|=0.525	lr=8.84e-05 | 1.0%@S42  T=1.09s eta=03:19:47 | 70.3K token/s | 
[epoch_0]_50071  loss=3.158754 |g|=0.484	lr=8.82e-05 | 1.8%@S42  T=1.14s eta=03:28:55 | 70.4K token/s | 
[epoch_0]_50081  loss=3.231387 |g|=0.493	lr=8.81e-05 | 2.6%@S42  T=1.09s eta=03:19:54 | 70.6K token/s | 
[epoch_0]_50091  loss=3.139183 |g|=0.503	lr=8.80e-05 | 3.5%@S42  T=1.09s eta=03:18:04 | 70.8K token/s | 
[Fuyou] head="2" update algorithm=4 t=2.07s
[Section@50100] layer[18-24] tasks=15(nPassBack=0) last_loss=3.14812(0.0368352) N=(580,42588,42168 5009900)
[epoch_0]_50101  loss=3.089303 |g|=0.534	lr=8.78e-05 | 4.3%@S42  T=1.39s eta=04:13:00 | 70.2K token/s | 
[epoch_0]_50111  loss=3.116606 |g|=0.503	lr=8.77e-05 | 5.1%@S42  T=1.08s eta=03:16:57 | 70.5K token/s | 
[epoch_0]_50121  loss=3.162017 |g|=0.491	lr=8.76e-05 | 5.9%@S42  T=1.09s eta=03:18:23 | 70.7K token/s | 
[epoch_0]_50131  loss=3.173110 |g|=0.483	lr=8.74e-05 | 6.7%@S42  T=1.15s eta=03:29:27 | 70.8K token/s | 
[epoch_0]_50141  loss=3.194452 |g|=0.501	lr=8.73e-05 | 7.6%@S42  T=1.09s eta=03:17:06 | 71.0K token/s | 
[epoch_0]_50151  loss=3.128588 |g|=0.499	lr=8.71e-05 | 8.4%@S42  T=1.09s eta=03:17:10 | 71.2K token/s | 
[epoch_0]_50161  loss=3.122868 |g|=0.498	lr=8.70e-05 | 9.2%@S42  T=1.11s eta=03:21:11 | 71.3K token/s | 
[epoch_0]_50171  loss=3.214466 |g|=0.476	lr=8.69e-05 | 10.0%@S42  T=1.13s eta=03:24:02 | 71.4K token/s | 
[epoch_0]_50181  loss=3.134081 |g|=0.531	lr=8.67e-05 | 10.8%@S42  T=1.09s eta=03:17:14 | 71.6K token/s | 
[epoch_0]_50191  loss=3.113978 |g|=0.489	lr=8.66e-05 | 11.7%@S42  T=1.11s eta=03:20:48 | 71.7K token/s | 
[Fuyou] head="3" update algorithm=4 t=2.10s
[eval] 
	 Loss@"edu_fineweb1B"=3.181(0.0053) nBranch=1 nToken=4.01M best=3.1866(249) E2T=0.000601 T=13.4359(0)s x=0
	#3.18129±0.1082 tps=299K(4.01408M) a=[3.00394,3.47385] T=13.4359(sec)
[Section@50200] layer[24-30] tasks=15(nPassBack=0) last_loss=3.18069(-0.0913637) N=(580,42672,42252 5019900)
[epoch_0]_50201  loss=3.111128 |g|=0.523	lr=8.64e-05 | 12.5%@S42  T=4.22s eta=12:42:38 | 69.1K token/s | 
[epoch_0]_50211  loss=3.179371 |g|=0.472	lr=8.63e-05 | 13.3%@S42  T=1.11s eta=03:20:36 | 69.3K token/s | 
[epoch_0]_50221  loss=3.160312 |g|=0.501	lr=8.62e-05 | 14.1%@S42  T=1.09s eta=03:16:09 | 69.6K token/s | 
[epoch_0]_50231  loss=3.208051 |g|=0.492	lr=8.60e-05 | 14.9%@S42  T=1.15s eta=03:27:23 | 69.7K token/s | 
[epoch_0]_50241  loss=3.186501 |g|=0.511	lr=8.59e-05 | 15.8%@S42  T=1.10s eta=03:17:24 | 69.9K token/s | 
[epoch_0]_50251  loss=3.242909 |g|=0.506	lr=8.58e-05 | 16.6%@S42  T=1.10s eta=03:17:38 | 70.2K token/s | 
[epoch_0]_50261  loss=3.154666 |g|=0.49	lr=8.56e-05 | 17.4%@S42  T=1.12s eta=03:20:31 | 70.3K token/s | 
[epoch_0]_50271  loss=3.137032 |g|=0.524	lr=8.55e-05 | 18.2%@S42  T=1.13s eta=03:22:35 | 70.4K token/s | 
[epoch_0]_50281  loss=3.165782 |g|=0.527	lr=8.54e-05 | 19.0%@S42  T=1.09s eta=03:14:53 | 70.7K token/s | 
[epoch_0]_50291  loss=3.170922 |g|=0.498	lr=8.52e-05 | 19.9%@S42  T=1.10s eta=03:16:34 | 70.9K token/s | 
[Fuyou] head="4" update algorithm=4 t=2.08s
[Section@50300] layer[30-36] tasks=15(nPassBack=0) last_loss=3.20605(-0.0772223) N=(580,42756,42336 5029900)
[epoch_0]_50301  loss=3.142151 |g|=0.521	lr=8.51e-05 | 20.7%@S42  T=1.71s eta=05:05:18 | 69.7K token/s | 
[epoch_0]_50311  loss=3.070492 |g|=0.488	lr=8.49e-05 | 21.5%@S42  T=1.09s eta=03:14:24 | 70.0K token/s | 
[epoch_0]_50321  loss=3.151348 |g|=0.503	lr=8.48e-05 | 22.3%@S42  T=1.10s eta=03:16:37 | 70.2K token/s | 
[epoch_0]_50331  loss=3.217793 |g|=0.484	lr=8.47e-05 | 23.1%@S42  T=1.15s eta=03:25:35 | 70.3K token/s | 
[epoch_0]_50341  loss=3.132664 |g|=0.487	lr=8.45e-05 | 23.9%@S42  T=1.08s eta=03:12:57 | 70.5K token/s | 
[epoch_0]_50351  loss=3.191570 |g|=0.501	lr=8.44e-05 | 24.8%@S42  T=1.09s eta=03:14:24 | 70.8K token/s | 
[epoch_0]_50361  loss=3.187206 |g|=0.486	lr=8.43e-05 | 25.6%@S42  T=1.10s eta=03:16:12 | 70.9K token/s | 
[epoch_0]_50371  loss=3.210584 |g|=0.525	lr=8.41e-05 | 26.4%@S42  T=1.15s eta=03:24:34 | 71.0K token/s | 
[epoch_0]_50381  loss=3.233675 |g|=0.482	lr=8.40e-05 | 27.2%@S42  T=1.10s eta=03:14:27 | 71.1K token/s | 
[epoch_0]_50391  loss=3.190326 |g|=0.51	lr=8.39e-05 | 28.0%@S42  T=1.11s eta=03:16:28 | 71.3K token/s | 
[Fuyou] head="5" update algorithm=4 t=2.11s
[eval] 
	 Loss@"edu_fineweb1B"=3.179(0.002) nBranch=1 nToken=4.01M best=3.1813(250) E2T=0.0464 T=13.4294(0)s x=0
	#3.1793±0.1085 tps=299K(4.01408M) a=[3.00066,3.4729] T=13.4294(sec)
[Section@50400] layer[0-6] tasks=15(nPassBack=0) last_loss=3.13295(0.0389535) N=(580,42840,42420 5039900)
[epoch_0]_50401  loss=3.078649 |g|=0.537	lr=8.37e-05 | 28.9%@S42  T=4.22s eta=12:27:38 | 68.7K token/s | 
[epoch_0]_50411  loss=3.099621 |g|=0.49	lr=8.36e-05 | 29.7%@S42  T=1.09s eta=03:12:44 | 69.0K token/s | 
[epoch_0]_50421  loss=3.207436 |g|=0.516	lr=8.35e-05 | 30.5%@S42  T=1.12s eta=03:17:27 | 69.2K token/s | 
[epoch_0]_50431  loss=3.204792 |g|=0.509	lr=8.33e-05 | 31.3%@S42  T=1.14s eta=03:21:42 | 69.4K token/s | 
[epoch_0]_50441  loss=3.166457 |g|=0.496	lr=8.32e-05 | 32.1%@S42  T=1.10s eta=03:13:59 | 69.6K token/s | 
[epoch_0]_50451  loss=3.049144 |g|=0.494	lr=8.30e-05 | 33.0%@S42  T=1.11s eta=03:15:09 | 69.8K token/s | 
[epoch_0]_50461  loss=3.162052 |g|=0.519	lr=8.29e-05 | 33.8%@S42  T=1.14s eta=03:20:40 | 70.0K token/s | 
[epoch_0]_50471  loss=3.237600 |g|=0.494	lr=8.28e-05 | 34.6%@S42  T=1.13s eta=03:18:36 | 70.1K token/s | 
[epoch_0]_50481  loss=3.167958 |g|=0.531	lr=8.26e-05 | 35.4%@S42  T=1.09s eta=03:12:26 | 70.3K token/s | 
[epoch_0]_50491  loss=3.175786 |g|=0.494	lr=8.25e-05 | 36.2%@S42  T=1.10s eta=03:12:49 | 70.5K token/s | 
[Fuyou] head="0" update algorithm=4 t=2.09s
[Section@50500] layer[6-12] tasks=15(nPassBack=0) last_loss=3.12663(0.0198753) N=(580,42924,42504 5049900)
[epoch_0]_50501  loss=3.113048 |g|=0.477	lr=8.24e-05 | 37.1%@S42  T=1.45s eta=04:15:21 | 69.8K token/s | 
[epoch_0]_50511  loss=3.208811 |g|=0.519	lr=8.22e-05 | 37.9%@S42  T=1.10s eta=03:13:28 | 70.1K token/s | 
[epoch_0]_50521  loss=3.117169 |g|=0.476	lr=8.21e-05 | 38.7%@S42  T=1.10s eta=03:12:18 | 70.3K token/s | 
[epoch_0]_50531  loss=3.201346 |g|=0.498	lr=8.20e-05 | 39.5%@S42  T=1.09s eta=03:11:31 | 70.5K token/s | 
[epoch_0]_50541  loss=3.153494 |g|=0.502	lr=8.18e-05 | 40.3%@S42  T=1.13s eta=03:18:17 | 70.6K token/s | 
[epoch_0]_50551  loss=3.124125 |g|=0.545	lr=8.17e-05 | 41.1%@S42  T=1.09s eta=03:11:07 | 70.8K token/s | 
[epoch_0]_50561  loss=3.132493 |g|=0.498	lr=8.16e-05 | 42.0%@S42  T=1.09s eta=03:10:35 | 71.0K token/s | 
[epoch_0]_50571  loss=3.157475 |g|=0.5	lr=8.14e-05 | 42.8%@S42  T=1.12s eta=03:14:39 | 71.1K token/s | 
[epoch_0]_50581  loss=3.231930 |g|=0.502	lr=8.13e-05 | 43.6%@S42  T=1.15s eta=03:21:11 | 71.1K token/s | 
[epoch_0]_50591  loss=3.183985 |g|=0.493	lr=8.12e-05 | 44.4%@S42  T=1.09s eta=03:10:29 | 71.3K token/s | 
[Fuyou] head="1" update algorithm=4 t=2.13s
[eval] 
	 Loss@"edu_fineweb1B"=3.177(0.0018) nBranch=1 nToken=4.01M best=3.1793(251) E2T=0.0324 T=13.4202(0)s x=0
	#3.17747±0.1085 tps=299K(4.01408M) a=[3.00006,3.46899] T=13.4202(sec)
[Section@50600] layer[12-18] tasks=15(nPassBack=0) last_loss=3.14507(0.0703549) N=(580,43008,42588 5059900)
[epoch_0]_50601  loss=3.190306 |g|=0.502	lr=8.10e-05 | 45.2%@S42  T=4.23s eta=12:14:48 | 68.7K token/s | 
[epoch_0]_50611  loss=3.165050 |g|=0.52	lr=8.09e-05 | 46.1%@S42  T=1.15s eta=03:19:23 | 68.9K token/s | 
[epoch_0]_50621  loss=3.128438 |g|=0.514	lr=8.08e-05 | 46.9%@S42  T=1.11s eta=03:12:50 | 69.1K token/s | 
[epoch_0]_50631  loss=3.176000 |g|=0.488	lr=8.06e-05 | 47.7%@S42  T=1.15s eta=03:20:11 | 69.2K token/s | 
[epoch_0]_50641  loss=3.144882 |g|=0.492	lr=8.05e-05 | 48.5%@S42  T=1.26s eta=03:38:54 | 69.0K token/s | 
[epoch_0]_50651  loss=3.010257 |g|=0.524	lr=8.04e-05 | 49.3%@S42  T=1.09s eta=03:08:33 | 69.3K token/s | 
[epoch_0]_50661  loss=3.208142 |g|=0.522	lr=8.02e-05 | 50.2%@S42  T=1.10s eta=03:09:26 | 69.6K token/s | 
[epoch_0]_50671  loss=3.133527 |g|=0.491	lr=8.01e-05 | 51.0%@S42  T=1.13s eta=03:15:08 | 69.7K token/s | 
[epoch_0]_50681  loss=3.091471 |g|=0.48	lr=8.00e-05 | 51.8%@S42  T=1.19s eta=03:25:01 | 69.7K token/s | 
[epoch_0]_50691  loss=3.194734 |g|=0.496	lr=7.99e-05 | 52.6%@S42  T=1.13s eta=03:15:38 | 69.8K token/s | 
[Fuyou] head="2" update algorithm=4 t=2.28s
[Section@50700] layer[18-24] tasks=15(nPassBack=0) last_loss=3.17322(-0.0251031) N=(580,43092,42672 5069900)
[epoch_0]_50701  loss=3.118231 |g|=0.501	lr=7.97e-05 | 53.4%@S42  T=1.46s eta=04:11:38 | 69.1K token/s | 
[epoch_0]_50711  loss=3.099930 |g|=0.505	lr=7.96e-05 | 54.3%@S42  T=1.27s eta=03:39:02 | 68.9K token/s | 
[epoch_0]_50721  loss=3.143508 |g|=0.535	lr=7.95e-05 | 55.1%@S42  T=1.08s eta=03:05:13 | 69.2K token/s | 
[epoch_0]_50731  loss=3.125142 |g|=0.474	lr=7.93e-05 | 55.9%@S42  T=1.15s eta=03:17:20 | 69.3K token/s | 
[epoch_0]_50741  loss=3.066935 |g|=0.485	lr=7.92e-05 | 56.7%@S42  T=1.37s eta=03:54:24 | 68.9K token/s | 
[epoch_0]_50751  loss=3.133069 |g|=0.508	lr=7.91e-05 | 57.5%@S42  T=1.10s eta=03:07:58 | 69.2K token/s | 
[epoch_0]_50761  loss=3.122048 |g|=0.536	lr=7.89e-05 | 58.4%@S42  T=1.07s eta=03:03:35 | 69.5K token/s | 
[epoch_0]_50771  loss=3.197751 |g|=0.506	lr=7.88e-05 | 59.2%@S42  T=1.12s eta=03:10:50 | 69.7K token/s | 
[epoch_0]_50781  loss=3.221936 |g|=0.516	lr=7.87e-05 | 60.0%@S42  T=1.27s eta=03:37:19 | 69.4K token/s | 
[epoch_0]_50791  loss=3.147580 |g|=0.496	lr=7.85e-05 | 60.8%@S42  T=1.13s eta=03:12:15 | 69.6K token/s | 
[Fuyou] head="3" update algorithm=4 t=2.06s
[eval] 
	 Loss@"edu_fineweb1B"=3.176(0.0017) nBranch=1 nToken=4.01M best=3.1775(252) E2T=0.045 T=13.4751(0)s x=0
	#3.17578±0.1088 tps=298K(4.01408M) a=[2.99762,3.46991] T=13.4751(sec)
[Section@50800] layer[24-30] tasks=15(nPassBack=0) last_loss=3.13078(0.0499017) N=(580,43176,42756 5079900)
[epoch_0]_50801  loss=3.081228 |g|=0.491	lr=7.84e-05 | 61.6%@S42  T=4.87s eta=13:51:14 | 67.0K token/s | 
[epoch_0]_50811  loss=3.084081 |g|=0.479	lr=7.83e-05 | 62.4%@S42  T=1.14s eta=03:13:32 | 67.2K token/s | 
[epoch_0]_50821  loss=3.153630 |g|=0.49	lr=7.81e-05 | 63.3%@S42  T=1.12s eta=03:10:16 | 67.5K token/s | 
[epoch_0]_50831  loss=3.049711 |g|=0.51	lr=7.80e-05 | 64.1%@S42  T=1.56s eta=04:24:32 | 66.8K token/s | 
[epoch_0]_50841  loss=3.057520 |g|=0.504	lr=7.79e-05 | 64.9%@S42  T=1.15s eta=03:14:56 | 67.0K token/s | 
[epoch_0]_50851  loss=3.198994 |g|=0.497	lr=7.78e-05 | 65.7%@S42  T=1.10s eta=03:07:09 | 67.4K token/s | 
[epoch_0]_50861  loss=3.246945 |g|=0.493	lr=7.76e-05 | 66.5%@S42  T=1.09s eta=03:05:29 | 67.8K token/s | 
[epoch_0]_50871  loss=3.124164 |g|=0.512	lr=7.75e-05 | 67.4%@S42  T=1.21s eta=03:24:36 | 67.8K token/s | 
[epoch_0]_50881  loss=3.139473 |g|=0.555	lr=7.74e-05 | 68.2%@S42  T=1.11s eta=03:07:07 | 68.1K token/s | 
[epoch_0]_50891  loss=3.127846 |g|=0.52	lr=7.72e-05 | 69.0%@S42  T=1.16s eta=03:15:32 | 68.2K token/s | 
[Fuyou] head="4" update algorithm=4 t=3.11s
[Section@50900] layer[30-36] tasks=15(nPassBack=0) last_loss=3.15833(0.047719) N=(580,43260,42840 5089900)
[epoch_0]_50901  loss=3.145845 |g|=0.502	lr=7.71e-05 | 69.8%@S42  T=2.13s eta=06:00:04 | 66.7K token/s | 
[epoch_0]_50911  loss=3.167832 |g|=0.491	lr=7.70e-05 | 70.6%@S42  T=1.10s eta=03:06:08 | 67.1K token/s | 
[epoch_0]_50921  loss=3.171971 |g|=0.494	lr=7.69e-05 | 71.5%@S42  T=1.10s eta=03:06:15 | 67.5K token/s | 
[epoch_0]_50931  loss=3.120633 |g|=0.515	lr=7.67e-05 | 72.3%@S42  T=1.12s eta=03:07:48 | 67.8K token/s | 
[epoch_0]_50941  loss=3.167623 |g|=0.527	lr=7.66e-05 | 73.1%@S42  T=1.09s eta=03:03:18 | 68.1K token/s | 
[epoch_0]_50951  loss=3.147413 |g|=0.527	lr=7.65e-05 | 73.9%@S42  T=1.10s eta=03:05:31 | 68.4K token/s | 
[epoch_0]_50961  loss=3.128900 |g|=0.504	lr=7.63e-05 | 74.7%@S42  T=1.14s eta=03:11:29 | 68.6K token/s | 
[epoch_0]_50971  loss=3.191888 |g|=0.486	lr=7.62e-05 | 75.6%@S42  T=1.65s eta=04:37:17 | 67.6K token/s | 
[epoch_0]_50981  loss=3.193960 |g|=0.517	lr=7.61e-05 | 76.4%@S42  T=1.07s eta=03:00:06 | 68.1K token/s | 
[epoch_0]_50991  loss=3.177483 |g|=0.514	lr=7.60e-05 | 77.2%@S42  T=1.11s eta=03:05:29 | 68.4K token/s | 
[Fuyou] head="5" update algorithm=4 t=2.44s
[eval] 
	 Loss@"edu_fineweb1B"=3.174(0.0019) nBranch=1 nToken=4.01M best=3.1758(253) E2T=0.0671 T=13.5568(0)s x=0
	#3.17388±0.1083 tps=296K(4.01408M) a=[2.99752,3.46488] T=13.5568(sec)
[Section@51000] layer[0-6] tasks=15(nPassBack=0) last_loss=3.1068(0.0261462) N=(580,43344,42924 5099900)
[epoch_0]_51001  loss=3.164816 |g|=0.517	lr=7.58e-05 | 78.0%@S42  T=4.29s eta=11:57:06 | 65.9K token/s | 
[epoch_0]_51011  loss=3.137876 |g|=0.473	lr=7.57e-05 | 78.8%@S42  T=1.10s eta=03:03:50 | 66.3K token/s | 
[epoch_0]_51021  loss=3.210804 |g|=0.511	lr=7.56e-05 | 79.7%@S42  T=1.13s eta=03:08:18 | 66.6K token/s | 
[epoch_0]_51031  loss=3.148372 |g|=0.486	lr=7.54e-05 | 80.5%@S42  T=1.10s eta=03:04:09 | 67.0K token/s | 
[epoch_0]_51041  loss=3.025887 |g|=0.524	lr=7.53e-05 | 81.3%@S42  T=1.15s eta=03:11:26 | 67.2K token/s | 
[epoch_0]_51051  loss=3.115837 |g|=0.519	lr=7.52e-05 | 82.1%@S42  T=1.14s eta=03:09:39 | 67.5K token/s | 
[epoch_0]_51061  loss=3.091164 |g|=0.491	lr=7.51e-05 | 82.9%@S42  T=1.68s eta=04:38:53 | 66.5K token/s | 
[epoch_0]_51071  loss=3.083497 |g|=0.512	lr=7.49e-05 | 83.7%@S42  T=1.10s eta=03:02:17 | 66.9K token/s | 
[epoch_0]_51081  loss=3.162160 |g|=0.506	lr=7.48e-05 | 84.6%@S42  T=1.10s eta=03:02:01 | 67.3K token/s | 
[epoch_0]_51091  loss=3.184557 |g|=0.489	lr=7.47e-05 | 85.4%@S42  T=1.42s eta=03:55:02 | 66.8K token/s | 
[Fuyou] head="0" update algorithm=4 t=2.10s
[Section@51100] layer[6-12] tasks=15(nPassBack=0) last_loss=3.07395(0.0526731) N=(580,43428,43008 5109900)
[epoch_0]_51101  loss=3.027825 |g|=0.511	lr=7.45e-05 | 86.2%@S42  T=1.39s eta=03:50:42 | 66.4K token/s | 
[epoch_0]_51111  loss=3.179695 |g|=0.505	lr=7.44e-05 | 87.0%@S42  T=1.24s eta=03:24:50 | 66.4K token/s | 
[epoch_0]_51121  loss=3.147685 |g|=0.498	lr=7.43e-05 | 87.8%@S42  T=1.12s eta=03:04:40 | 66.8K token/s | 
[epoch_0]_51131  loss=3.178919 |g|=0.491	lr=7.42e-05 | 88.7%@S42  T=1.56s eta=04:17:58 | 66.1K token/s | 
[epoch_0]_51141  loss=3.142684 |g|=0.519	lr=7.40e-05 | 89.5%@S42  T=1.09s eta=03:00:19 | 66.5K token/s | 
[epoch_0]_51151  loss=3.123560 |g|=0.537	lr=7.39e-05 | 90.3%@S42  T=1.12s eta=03:04:47 | 66.8K token/s | 
[epoch_0]_51161  loss=3.120722 |g|=0.489	lr=7.38e-05 | 91.1%@S42  T=1.16s eta=03:11:12 | 67.0K token/s | 
[epoch_0]_51171  loss=3.109515 |g|=0.508	lr=7.37e-05 | 91.9%@S42  T=1.57s eta=04:18:26 | 66.3K token/s | 
[epoch_0]_51181  loss=3.139663 |g|=0.521	lr=7.35e-05 | 92.8%@S42  T=1.11s eta=03:02:26 | 66.6K token/s | 
[epoch_0]_51191  loss=3.146495 |g|=0.501	lr=7.34e-05 | 93.6%@S42  T=1.15s eta=03:08:42 | 66.9K token/s | 
[Fuyou] head="1" update algorithm=4 t=2.01s
[eval] 
	 Loss@"edu_fineweb1B"=3.173(0.0013) nBranch=1 nToken=4.01M best=3.1739(254) E2T=-0.0335 T=13.5421(0)s x=0
	#3.1726±0.1085 tps=296K(4.01408M) a=[2.99657,3.46438] T=13.5421(sec)
[Section@51200] layer[12-18] tasks=15(nPassBack=0) last_loss=3.20606(-0.060987) N=(580,43512,43092 5119900)
[epoch_0]_51201  loss=3.164118 |g|=0.509	lr=7.33e-05 | 94.4%@S42  T=4.26s eta=11:38:53 | 64.5K token/s | 
[epoch_0]_51211  loss=3.256560 |g|=0.519	lr=7.32e-05 | 95.2%@S42  T=1.24s eta=03:22:56 | 64.6K token/s | 
[epoch_0]_51221  loss=3.145932 |g|=0.502	lr=7.30e-05 | 96.0%@S42  T=1.14s eta=03:06:49 | 64.9K token/s | 
[epoch_0]_51231  loss=3.111150 |g|=0.52	lr=7.29e-05 | 96.9%@S42  T=1.31s eta=03:33:30 | 64.8K token/s | 
[epoch_0]_51241  loss=3.116215 |g|=0.489	lr=7.28e-05 | 97.7%@S42  T=1.10s eta=02:59:50 | 65.3K token/s | 
[epoch_0]_51251  loss=3.181199 |g|=0.517	lr=7.27e-05 | 98.5%@S42  T=1.09s eta=02:57:48 | 65.8K token/s | 
[epoch_0]_51261  loss=3.162789 |g|=0.495	lr=7.25e-05 | 99.3%@S42  T=1.38s eta=03:45:31 | 65.5K token/s | 
[epoch_0]_51269  loss=3.130431 |g|=0.496	lr=7.24e-05 | 100.0%@S42  T=1.15s eta=03:07:16 | 65.7K token/s | 
-------- End of shard_42@"./Datasets/edu_fineweb1B/edu_fineweb_train_000799.bin"-------- 
[shard-43]@"./Datasets/edu_fineweb1B/edu_fineweb_train_000800.bin": tokens=100(M) nShardSamples=1220(4199208) 
[epoch_0]_51271  loss=3.099947 |g|=0.498	lr=7.24e-05 | 0.1%@S43  T=1.20s eta=03:15:01 | 65.9K token/s | 
[epoch_0]_51281  loss=3.116961 |g|=0.495	lr=7.23e-05 | 1.0%@S43  T=1.14s eta=03:05:39 | 66.2K token/s | 
[epoch_0]_51291  loss=3.140656 |g|=0.523	lr=7.22e-05 | 1.8%@S43  T=1.08s eta=02:54:52 | 66.7K token/s | 
[Fuyou] head="2" update algorithm=4 t=2.42s
[Section@51300] layer[18-24] tasks=15(nPassBack=0) last_loss=3.10397(0.069252) N=(580,43596,43176 5129900)
[epoch_0]_51301  loss=3.158051 |g|=0.503	lr=7.20e-05 | 2.6%@S43  T=1.76s eta=04:45:22 | 65.7K token/s | 
[epoch_0]_51311  loss=3.136336 |g|=0.503	lr=7.19e-05 | 3.4%@S43  T=1.11s eta=03:00:03 | 66.1K token/s | 
[epoch_0]_51321  loss=3.129885 |g|=0.503	lr=7.18e-05 | 4.2%@S43  T=1.10s eta=02:57:33 | 66.5K token/s | 
[epoch_0]_51331  loss=3.183158 |g|=0.514	lr=7.17e-05 | 5.0%@S43  T=1.53s eta=04:07:10 | 65.8K token/s | 
[epoch_0]_51341  loss=3.129828 |g|=0.486	lr=7.15e-05 | 5.9%@S43  T=1.12s eta=03:01:40 | 66.2K token/s | 
[epoch_0]_51351  loss=3.197557 |g|=0.506	lr=7.14e-05 | 6.7%@S43  T=1.09s eta=02:56:05 | 66.6K token/s | 
[epoch_0]_51361  loss=3.157211 |g|=0.508	lr=7.13e-05 | 7.5%@S43  T=1.10s eta=02:56:48 | 67.0K token/s | 
[epoch_0]_51371  loss=3.123024 |g|=0.488	lr=7.12e-05 | 8.3%@S43  T=1.10s eta=02:57:15 | 67.4K token/s | 
[epoch_0]_51381  loss=3.076615 |g|=0.483	lr=7.10e-05 | 9.1%@S43  T=1.11s eta=02:58:11 | 67.7K token/s | 
[epoch_0]_51391  loss=3.185294 |g|=0.514	lr=7.09e-05 | 10.0%@S43  T=1.13s eta=03:02:02 | 68.0K token/s | 
[Fuyou] head="3" update algorithm=4 t=3.29s
[eval] 
	 Loss@"edu_fineweb1B"=3.173(-0.00014) nBranch=1 nToken=4.01M best=3.1726(255) E2T=0.0315 T=13.4541(0)s x=0
	#3.17274±0.1080 tps=298K(4.01408M) a=[2.99642,3.46318] T=13.4541(sec)
[Section@51400] layer[24-30] tasks=15(nPassBack=0) last_loss=3.14126(-0.0104747) N=(580,43680,43260 5139900)
[epoch_0]_51401  loss=3.104729 |g|=0.516	lr=7.08e-05 | 10.8%@S43  T=4.33s eta=11:34:44 | 65.5K token/s | 
[epoch_0]_51411  loss=3.171849 |g|=0.538	lr=7.07e-05 | 11.6%@S43  T=1.10s eta=02:56:21 | 66.0K token/s | 
[epoch_0]_51421  loss=3.136592 |g|=0.527	lr=7.05e-05 | 12.4%@S43  T=1.57s eta=04:11:16 | 65.3K token/s | 
[epoch_0]_51431  loss=3.058739 |g|=0.491	lr=7.04e-05 | 13.2%@S43  T=1.13s eta=03:00:54 | 65.6K token/s | 
[epoch_0]_51441  loss=3.139255 |g|=0.495	lr=7.03e-05 | 14.1%@S43  T=1.06s eta=02:50:11 | 66.2K token/s | 
[epoch_0]_51451  loss=3.191452 |g|=0.492	lr=7.02e-05 | 14.9%@S43  T=1.09s eta=02:54:46 | 66.6K token/s | 
[epoch_0]_51461  loss=3.145657 |g|=0.491	lr=7.00e-05 | 15.7%@S43  T=1.09s eta=02:53:19 | 67.1K token/s | 
[epoch_0]_51471  loss=3.228157 |g|=0.511	lr=6.99e-05 | 16.5%@S43  T=1.13s eta=02:59:28 | 67.4K token/s | 
[epoch_0]_51481  loss=3.197022 |g|=0.517	lr=6.98e-05 | 17.3%@S43  T=1.16s eta=03:05:24 | 67.5K token/s | 
[epoch_0]_51491  loss=3.158164 |g|=0.522	lr=6.97e-05 | 18.2%@S43  T=1.56s eta=04:07:49 | 66.8K token/s | 
[Fuyou] head="4" update algorithm=4 t=2.36s
[Section@51500] layer[30-36] tasks=15(nPassBack=0) last_loss=3.12951(0.02882) N=(580,43764,43344 5149900)
[epoch_0]_51501  loss=3.099407 |g|=0.513	lr=6.96e-05 | 19.0%@S43  T=1.42s eta=03:45:31 | 66.3K token/s | 
[epoch_0]_51511  loss=3.140934 |g|=0.493	lr=6.94e-05 | 19.8%@S43  T=1.09s eta=02:53:17 | 66.8K token/s | 
[epoch_0]_51521  loss=3.142319 |g|=0.505	lr=6.93e-05 | 20.6%@S43  T=1.38s eta=03:38:03 | 66.4K token/s | 
[epoch_0]_51531  loss=3.069317 |g|=0.501	lr=6.92e-05 | 21.4%@S43  T=1.09s eta=02:53:15 | 66.8K token/s | 
[epoch_0]_51541  loss=3.140201 |g|=0.508	lr=6.91e-05 | 22.3%@S43  T=1.09s eta=02:53:08 | 67.2K token/s | 
[epoch_0]_51551  loss=3.108835 |g|=0.515	lr=6.89e-05 | 23.1%@S43  T=1.11s eta=02:55:13 | 67.6K token/s | 
[epoch_0]_51561  loss=3.064742 |g|=0.499	lr=6.88e-05 | 23.9%@S43  T=1.21s eta=03:10:31 | 67.6K token/s | 
[epoch_0]_51571  loss=3.120053 |g|=0.5	lr=6.87e-05 | 24.7%@S43  T=1.15s eta=03:01:52 | 67.7K token/s | 
[epoch_0]_51581  loss=3.121658 |g|=0.523	lr=6.86e-05 | 25.5%@S43  T=1.09s eta=02:51:41 | 68.1K token/s | 
[epoch_0]_51591  loss=3.109828 |g|=0.5	lr=6.85e-05 | 26.3%@S43  T=1.36s eta=03:33:46 | 67.7K token/s | 
[Fuyou] head="5" update algorithm=4 t=2.32s
[eval] 
	 Loss@"edu_fineweb1B"=3.171(0.0018) nBranch=1 nToken=4.01M best=3.1727(256) E2T=-0.016 T=13.4135(0)s x=0
	#3.17098±0.1085 tps=299K(4.01408M) a=[2.99521,3.46433] T=13.4135(sec)
[Section@51600] layer[0-6] tasks=15(nPassBack=0) last_loss=3.18696(-0.080164) N=(580,43848,43428 5159900)
[epoch_0]_51601  loss=3.160520 |g|=0.501	lr=6.83e-05 | 27.2%@S43  T=4.27s eta=11:10:39 | 65.3K token/s | 
[epoch_0]_51611  loss=3.188062 |g|=0.484	lr=6.82e-05 | 28.0%@S43  T=1.40s eta=03:39:39 | 65.0K token/s | 
[epoch_0]_51621  loss=3.125426 |g|=0.511	lr=6.81e-05 | 28.8%@S43  T=1.10s eta=02:52:50 | 65.4K token/s | 
[epoch_0]_51631  loss=3.064546 |g|=0.485	lr=6.80e-05 | 29.6%@S43  T=1.11s eta=02:53:28 | 65.9K token/s | 
[epoch_0]_51641  loss=3.118454 |g|=0.476	lr=6.79e-05 | 30.4%@S43  T=1.12s eta=02:55:16 | 66.2K token/s | 
[epoch_0]_51651  loss=3.076212 |g|=0.485	lr=6.77e-05 | 31.3%@S43  T=1.12s eta=02:54:57 | 66.6K token/s | 
[epoch_0]_51661  loss=3.105271 |g|=0.499	lr=6.76e-05 | 32.1%@S43  T=1.16s eta=03:01:21 | 66.8K token/s | 
[epoch_0]_51671  loss=3.138274 |g|=0.494	lr=6.75e-05 | 32.9%@S43  T=1.09s eta=02:49:54 | 67.2K token/s | 
[epoch_0]_51681  loss=3.209009 |g|=0.514	lr=6.74e-05 | 33.7%@S43  T=1.56s eta=04:02:45 | 66.5K token/s | 
[epoch_0]_51691  loss=3.149321 |g|=0.501	lr=6.73e-05 | 34.5%@S43  T=1.11s eta=02:52:43 | 66.8K token/s | 
[Fuyou] head="0" update algorithm=4 t=2.26s
[Section@51700] layer[6-12] tasks=15(nPassBack=0) last_loss=3.06455(0.00940537) N=(580,43932,43512 5169900)
[epoch_0]_51701  loss=3.149482 |g|=0.492	lr=6.71e-05 | 35.4%@S43  T=1.40s eta=03:37:48 | 66.4K token/s | 
[epoch_0]_51711  loss=3.066005 |g|=0.545	lr=6.70e-05 | 36.2%@S43  T=1.36s eta=03:31:57 | 66.1K token/s | 
[epoch_0]_51721  loss=3.111477 |g|=0.494	lr=6.69e-05 | 37.0%@S43  T=1.13s eta=02:54:51 | 66.4K token/s | 
[epoch_0]_51731  loss=3.081302 |g|=0.499	lr=6.68e-05 | 37.8%@S43  T=1.13s eta=02:54:32 | 66.8K token/s | 
[epoch_0]_51741  loss=3.106295 |g|=0.507	lr=6.67e-05 | 38.6%@S43  T=1.15s eta=02:58:35 | 67.0K token/s | 
[epoch_0]_51751  loss=3.135743 |g|=0.511	lr=6.65e-05 | 39.5%@S43  T=1.23s eta=03:10:20 | 67.0K token/s | 
[epoch_0]_51761  loss=3.138317 |g|=0.483	lr=6.64e-05 | 40.3%@S43  T=1.09s eta=02:48:30 | 67.4K token/s | 
[epoch_0]_51771  loss=3.076705 |g|=0.505	lr=6.63e-05 | 41.1%@S43  T=1.09s eta=02:49:03 | 67.7K token/s | 
[epoch_0]_51781  loss=3.195847 |g|=0.499	lr=6.62e-05 | 41.9%@S43  T=1.47s eta=03:47:16 | 67.1K token/s | 
[epoch_0]_51791  loss=3.013284 |g|=0.521	lr=6.61e-05 | 42.7%@S43  T=1.11s eta=02:51:14 | 67.5K token/s | 
[Fuyou] head="1" update algorithm=4 t=2.01s
[eval] 
	 Loss@"edu_fineweb1B"=3.171(0.00044) nBranch=1 nToken=4.01M best=3.1710(257) E2T=0.0332 T=13.42(0)s x=0
	#3.17053±0.1083 tps=299K(4.01408M) a=[2.99486,3.46209] T=13.42(sec)
[Section@51800] layer[12-18] tasks=15(nPassBack=0) last_loss=3.13734(0.0687249) N=(580,44016,43596 5179900)
[epoch_0]_51801  loss=3.166472 |g|=0.516	lr=6.59e-05 | 43.5%@S43  T=4.50s eta=11:33:17 | 65.0K token/s | 
[epoch_0]_51811  loss=3.154180 |g|=0.499	lr=6.58e-05 | 44.4%@S43  T=1.18s eta=03:01:50 | 65.2K token/s | 
[epoch_0]_51821  loss=3.177348 |g|=0.482	lr=6.57e-05 | 45.2%@S43  T=1.10s eta=02:49:29 | 65.7K token/s | 
[epoch_0]_51831  loss=3.108615 |g|=0.485	lr=6.56e-05 | 46.0%@S43  T=1.14s eta=02:55:10 | 66.0K token/s | 
[epoch_0]_51841  loss=3.102168 |g|=0.508	lr=6.55e-05 | 46.8%@S43  T=1.18s eta=03:00:59 | 66.1K token/s | 
[epoch_0]_51851  loss=3.063965 |g|=0.515	lr=6.53e-05 | 47.6%@S43  T=1.15s eta=02:56:02 | 66.4K token/s | 
[epoch_0]_51861  loss=3.131643 |g|=0.499	lr=6.52e-05 | 48.5%@S43  T=1.11s eta=02:49:57 | 66.8K token/s | 
[epoch_0]_51871  loss=3.143667 |g|=0.492	lr=6.51e-05 | 49.3%@S43  T=1.53s eta=03:53:42 | 66.1K token/s | 
[epoch_0]_51881  loss=3.098745 |g|=0.534	lr=6.50e-05 | 50.1%@S43  T=1.10s eta=02:48:00 | 66.5K token/s | 
[epoch_0]_51891  loss=3.058772 |g|=0.511	lr=6.49e-05 | 50.9%@S43  T=1.12s eta=02:51:14 | 66.8K token/s | 
[Fuyou] head="2" update algorithm=4 t=2.09s
[Section@51900] layer[18-24] tasks=15(nPassBack=0) last_loss=3.1871(-0.0831304) N=(580,44100,43680 5189900)
[epoch_0]_51901  loss=3.079155 |g|=0.491	lr=6.48e-05 | 51.7%@S43  T=1.40s eta=03:33:31 | 66.4K token/s | 
[epoch_0]_51911  loss=3.149854 |g|=0.488	lr=6.46e-05 | 52.6%@S43  T=1.10s eta=02:47:26 | 66.8K token/s | 
[epoch_0]_51921  loss=3.080501 |g|=0.499	lr=6.45e-05 | 53.4%@S43  T=1.09s eta=02:45:12 | 67.2K token/s | 
[epoch_0]_51931  loss=3.140767 |g|=0.497	lr=6.44e-05 | 54.2%@S43  T=1.12s eta=02:49:58 | 67.5K token/s | 
[epoch_0]_51941  loss=3.228649 |g|=0.539	lr=6.43e-05 | 55.0%@S43  T=1.14s eta=02:52:05 | 67.8K token/s | 
[epoch_0]_51951  loss=3.059914 |g|=0.486	lr=6.42e-05 | 55.8%@S43  T=1.16s eta=02:55:02 | 67.9K token/s | 
[epoch_0]_51961  loss=3.145627 |g|=0.507	lr=6.41e-05 | 56.7%@S43  T=1.11s eta=02:47:36 | 68.2K token/s | 
[epoch_0]_51971  loss=3.149207 |g|=0.537	lr=6.39e-05 | 57.5%@S43  T=1.58s eta=03:59:01 | 67.4K token/s | 
[epoch_0]_51981  loss=3.074291 |g|=0.534	lr=6.38e-05 | 58.3%@S43  T=1.09s eta=02:44:13 | 67.8K token/s | 
[epoch_0]_51991  loss=3.119898 |g|=0.502	lr=6.37e-05 | 59.1%@S43  T=1.16s eta=02:54:50 | 67.9K token/s | 
[Fuyou] head="3" update algorithm=4 t=2.06s
[eval] 
	 Loss@"edu_fineweb1B"=3.169(0.0014) nBranch=1 nToken=4.01M best=3.1705(258) E2T=0.0288 T=13.4972(0)s x=0
	#3.16915±0.1085 tps=297K(4.01408M) a=[2.99306,3.46052] T=13.4972(sec)
[Section@52000] layer[24-30] tasks=15(nPassBack=0) last_loss=3.14033(0.00092864) N=(580,44184,43764 5199900)
[epoch_0]_52001  loss=3.113454 |g|=0.492	lr=6.36e-05 | 59.9%@S43  T=4.24s eta=10:38:15 | 65.5K token/s | 
[epoch_0]_52011  loss=3.117836 |g|=0.477	lr=6.35e-05 | 60.8%@S43  T=1.09s eta=02:44:17 | 66.0K token/s | 
[epoch_0]_52021  loss=2.999168 |g|=0.502	lr=6.34e-05 | 61.6%@S43  T=1.16s eta=02:54:36 | 66.2K token/s | 
[epoch_0]_52031  loss=3.152492 |g|=0.504	lr=6.32e-05 | 62.4%@S43  T=1.27s eta=03:10:31 | 66.1K token/s | 
[epoch_0]_52041  loss=3.092012 |g|=0.541	lr=6.31e-05 | 63.2%@S43  T=1.09s eta=02:43:48 | 66.6K token/s | 
[epoch_0]_52051  loss=3.141850 |g|=0.521	lr=6.30e-05 | 64.0%@S43  T=1.09s eta=02:43:34 | 67.0K token/s | 
[epoch_0]_52061  loss=3.072760 |g|=0.498	lr=6.29e-05 | 64.8%@S43  T=1.48s eta=03:41:58 | 66.4K token/s | 
[epoch_0]_52071  loss=3.137712 |g|=0.482	lr=6.28e-05 | 65.7%@S43  T=1.11s eta=02:46:23 | 66.7K token/s | 
[epoch_0]_52081  loss=3.146207 |g|=0.526	lr=6.27e-05 | 66.5%@S43  T=1.16s eta=02:53:27 | 66.9K token/s | 
[epoch_0]_52091  loss=3.101124 |g|=0.499	lr=6.25e-05 | 67.3%@S43  T=1.10s eta=02:43:59 | 67.3K token/s | 
[Fuyou] head="4" update algorithm=4 t=2.02s
[Section@52100] layer[30-36] tasks=15(nPassBack=0) last_loss=3.13845(-0.00894046) N=(580,44268,43848 5209900)
[epoch_0]_52101  loss=3.093842 |g|=0.521	lr=6.24e-05 | 68.1%@S43  T=1.41s eta=03:29:51 | 66.8K token/s | 
[epoch_0]_52111  loss=3.146792 |g|=0.518	lr=6.23e-05 | 68.9%@S43  T=1.09s eta=02:42:21 | 67.3K token/s | 
[epoch_0]_52121  loss=3.102577 |g|=0.501	lr=6.22e-05 | 69.8%@S43  T=1.15s eta=02:51:24 | 67.4K token/s | 
[epoch_0]_52131  loss=3.048644 |g|=0.504	lr=6.21e-05 | 70.6%@S43  T=1.15s eta=02:51:10 | 67.6K token/s | 
[epoch_0]_52141  loss=3.173807 |g|=0.501	lr=6.20e-05 | 71.4%@S43  T=1.10s eta=02:43:45 | 68.0K token/s | 
[epoch_0]_52151  loss=3.094388 |g|=0.491	lr=6.19e-05 | 72.2%@S43  T=1.10s eta=02:43:27 | 68.3K token/s | 
[epoch_0]_52161  loss=3.085938 |g|=0.51	lr=6.17e-05 | 73.0%@S43  T=1.54s eta=03:47:57 | 67.5K token/s | 
[epoch_0]_52171  loss=3.059631 |g|=0.515	lr=6.16e-05 | 73.9%@S43  T=1.12s eta=02:44:59 | 67.8K token/s | 
[epoch_0]_52181  loss=3.095260 |g|=0.509	lr=6.15e-05 | 74.7%@S43  T=1.16s eta=02:51:13 | 67.9K token/s | 
[epoch_0]_52191  loss=3.120710 |g|=0.501	lr=6.14e-05 | 75.5%@S43  T=1.24s eta=03:03:30 | 67.8K token/s | 
[Fuyou] head="5" update algorithm=4 t=2.14s
[eval] 
	 Loss@"edu_fineweb1B"=3.169(0.00015) nBranch=1 nToken=4.01M best=3.1692(259) E2T=0.0233 T=13.4223(0)s x=0
	#3.169±0.1086 tps=299K(4.01408M) a=[2.99274,3.46224] T=13.4223(sec)
[Section@52200] layer[0-6] tasks=15(nPassBack=0) last_loss=3.14571(0.0412526) N=(580,44352,43932 5219900)
[epoch_0]_52201  loss=3.101585 |g|=0.514	lr=6.13e-05 | 76.3%@S43  T=4.25s eta=10:25:00 | 65.4K token/s | 
[epoch_0]_52211  loss=3.088391 |g|=0.515	lr=6.12e-05 | 77.1%@S43  T=1.47s eta=03:36:47 | 64.9K token/s | 
[epoch_0]_52221  loss=3.142331 |g|=0.518	lr=6.11e-05 | 78.0%@S43  T=1.47s eta=03:35:34 | 64.5K token/s | 
[epoch_0]_52231  loss=3.108646 |g|=0.5	lr=6.09e-05 | 78.8%@S43  T=1.13s eta=02:45:16 | 64.9K token/s | 
[epoch_0]_52241  loss=3.017964 |g|=0.493	lr=6.08e-05 | 79.6%@S43  T=1.13s eta=02:45:36 | 65.3K token/s | 
[epoch_0]_52251  loss=3.052608 |g|=0.483	lr=6.07e-05 | 80.4%@S43  T=1.14s eta=02:47:34 | 65.6K token/s | 
[epoch_0]_52261  loss=3.086812 |g|=0.492	lr=6.06e-05 | 81.2%@S43  T=1.11s eta=02:42:00 | 66.0K token/s | 
[epoch_0]_52271  loss=3.052132 |g|=0.493	lr=6.05e-05 | 82.1%@S43  T=1.12s eta=02:42:54 | 66.4K token/s | 
[epoch_0]_52281  loss=3.171712 |g|=0.505	lr=6.04e-05 | 82.9%@S43  T=1.15s eta=02:48:06 | 66.6K token/s | 
[epoch_0]_52291  loss=3.145672 |g|=0.528	lr=6.03e-05 | 83.7%@S43  T=1.16s eta=02:48:53 | 66.8K token/s | 
[Fuyou] head="0" update algorithm=4 t=2.07s
[Section@52300] layer[6-12] tasks=15(nPassBack=0) last_loss=3.1471(-0.0825489) N=(580,44436,44016 5229900)
[epoch_0]_52301  loss=3.092958 |g|=0.503	lr=6.01e-05 | 84.5%@S43  T=1.77s eta=04:17:10 | 65.8K token/s | 
[epoch_0]_52311  loss=3.102635 |g|=0.525	lr=6.00e-05 | 85.3%@S43  T=1.09s eta=02:38:00 | 66.3K token/s | 
[epoch_0]_52321  loss=3.125997 |g|=0.509	lr=5.99e-05 | 86.1%@S43  T=1.10s eta=02:40:24 | 66.7K token/s | 
[epoch_0]_52331  loss=3.094378 |g|=0.51	lr=5.98e-05 | 87.0%@S43  T=1.13s eta=02:44:01 | 66.9K token/s | 
[epoch_0]_52341  loss=3.103912 |g|=0.511	lr=5.97e-05 | 87.8%@S43  T=1.11s eta=02:41:07 | 67.3K token/s | 
[epoch_0]_52351  loss=3.168875 |g|=0.482	lr=5.96e-05 | 88.6%@S43  T=1.52s eta=03:40:17 | 66.6K token/s | 
[epoch_0]_52361  loss=3.086725 |g|=0.502	lr=5.95e-05 | 89.4%@S43  T=1.09s eta=02:37:55 | 67.0K token/s | 
[epoch_0]_52371  loss=3.129105 |g|=0.499	lr=5.94e-05 | 90.2%@S43  T=1.12s eta=02:41:10 | 67.3K token/s | 
[epoch_0]_52381  loss=3.052971 |g|=0.506	lr=5.92e-05 | 91.1%@S43  T=1.16s eta=02:47:01 | 67.5K token/s | 
[epoch_0]_52391  loss=3.124647 |g|=0.518	lr=5.91e-05 | 91.9%@S43  T=1.15s eta=02:45:30 | 67.7K token/s | 
[Fuyou] head="1" update algorithm=4 t=2.08s
[eval] 
	 Loss@"edu_fineweb1B"=3.168(0.0014) nBranch=1 nToken=4.01M best=3.1690(260) E2T=0.049 T=13.4237(0)s x=0
	#3.16756±0.1084 tps=299K(4.01408M) a=[2.99079,3.46023] T=13.4237(sec)
[Section@52400] layer[12-18] tasks=15(nPassBack=0) last_loss=3.11854(0.0187986) N=(580,44520,44100 5239900)
[epoch_0]_52401  loss=3.079599 |g|=0.509	lr=5.90e-05 | 92.7%@S43  T=4.45s eta=10:40:48 | 65.2K token/s | 
[epoch_0]_52411  loss=3.191794 |g|=0.506	lr=5.89e-05 | 93.5%@S43  T=1.10s eta=02:38:39 | 65.7K token/s | 
[epoch_0]_52421  loss=3.150676 |g|=0.495	lr=5.88e-05 | 94.3%@S43  T=1.11s eta=02:39:11 | 66.1K token/s | 
[epoch_0]_52431  loss=3.148455 |g|=0.515	lr=5.87e-05 | 95.2%@S43  T=1.10s eta=02:37:38 | 66.5K token/s | 
[epoch_0]_52441  loss=3.127319 |g|=0.487	lr=5.86e-05 | 96.0%@S43  T=1.09s eta=02:36:38 | 66.9K token/s | 
[epoch_0]_52451  loss=3.167108 |g|=0.494	lr=5.85e-05 | 96.8%@S43  T=1.11s eta=02:38:06 | 67.3K token/s | 
[epoch_0]_52461  loss=3.183245 |g|=0.515	lr=5.84e-05 | 97.6%@S43  T=1.10s eta=02:37:13 | 67.7K token/s | 
[epoch_0]_52471  loss=3.116872 |g|=0.487	lr=5.82e-05 | 98.4%@S43  T=1.55s eta=03:41:11 | 66.9K token/s | 
[epoch_0]_52481  loss=3.093245 |g|=0.511	lr=5.81e-05 | 99.3%@S43  T=1.13s eta=02:41:08 | 67.2K token/s | 
[epoch_0]_52490  loss=3.216247 |g|=0.521	lr=5.80e-05 | 100.0%@S43  T=1.10s eta=02:37:14 | 67.5K token/s | 
-------- End of shard_43@"./Datasets/edu_fineweb1B/edu_fineweb_train_000800.bin"-------- 
[shard-44]@"./Datasets/edu_fineweb1B/edu_fineweb_train_000801.bin": tokens=100(M) nShardSamples=1220(4296864) 
[epoch_0]_52491  loss=3.112857 |g|=0.533	lr=5.80e-05 | 0.1%@S44  T=1.42s eta=03:22:10 | 67.1K token/s | 
[Fuyou] head="2" update algorithm=4 t=2.27s
[Section@52500] layer[18-24] tasks=15(nPassBack=0) last_loss=3.09278(0.0943203) N=(580,44604,44184 5249900)
[epoch_0]_52501  loss=3.070026 |g|=0.491	lr=5.79e-05 | 0.9%@S44  T=2.05s eta=04:51:00 | 65.7K token/s | 
[epoch_0]_52511  loss=3.176225 |g|=0.514	lr=5.78e-05 | 1.7%@S44  T=1.10s eta=02:36:29 | 66.1K token/s | 
[epoch_0]_52521  loss=3.151569 |g|=0.511	lr=5.77e-05 | 2.5%@S44  T=1.14s eta=02:41:22 | 66.4K token/s | 
[epoch_0]_52531  loss=3.065336 |g|=0.507	lr=5.76e-05 | 3.4%@S44  T=1.10s eta=02:35:45 | 66.8K token/s | 
[epoch_0]_52541  loss=3.142644 |g|=0.506	lr=5.75e-05 | 4.2%@S44  T=1.09s eta=02:34:34 | 67.2K token/s | 
[epoch_0]_52551  loss=3.115660 |g|=0.496	lr=5.74e-05 | 5.0%@S44  T=1.11s eta=02:36:20 | 67.6K token/s | 
[epoch_0]_52561  loss=3.187454 |g|=0.508	lr=5.73e-05 | 5.8%@S44  T=1.15s eta=02:42:36 | 67.8K token/s | 
[epoch_0]_52571  loss=3.150322 |g|=0.52	lr=5.71e-05 | 6.6%@S44  T=1.15s eta=02:41:48 | 67.9K token/s | 
[epoch_0]_52581  loss=3.167683 |g|=0.517	lr=5.70e-05 | 7.4%@S44  T=1.11s eta=02:36:14 | 68.2K token/s | 
[epoch_0]_52591  loss=3.118055 |g|=0.502	lr=5.69e-05 | 8.3%@S44  T=1.09s eta=02:33:52 | 68.6K token/s | 
[Fuyou] head="3" update algorithm=4 t=3.55s
[eval] 
	 Loss@"edu_fineweb1B"=3.165(0.0028) nBranch=1 nToken=4.01M best=3.1676(261) E2T=0.0267 T=13.4354(0)s x=0
	#3.16478±0.1086 tps=299K(4.01408M) a=[2.98749,3.45972] T=13.4354(sec)
[Section@52600] layer[24-30] tasks=15(nPassBack=0) last_loss=3.13808(0.00224543) N=(580,44688,44268 5259900)
[epoch_0]_52601  loss=3.182333 |g|=0.515	lr=5.68e-05 | 9.1%@S44  T=4.35s eta=10:11:59 | 66.1K token/s | 
[epoch_0]_52611  loss=3.115548 |g|=0.499	lr=5.67e-05 | 9.9%@S44  T=1.14s eta=02:39:41 | 66.4K token/s | 
[epoch_0]_52621  loss=3.141311 |g|=0.487	lr=5.66e-05 | 10.7%@S44  T=1.22s eta=02:50:41 | 66.4K token/s | 
[epoch_0]_52631  loss=3.203901 |g|=0.506	lr=5.65e-05 | 11.5%@S44  T=1.14s eta=02:39:30 | 66.7K token/s | 
[epoch_0]_52641  loss=3.167090 |g|=0.497	lr=5.64e-05 | 12.4%@S44  T=1.12s eta=02:37:02 | 67.0K token/s | 
[epoch_0]_52651  loss=3.089701 |g|=0.509	lr=5.63e-05 | 13.2%@S44  T=1.29s eta=02:59:58 | 66.9K token/s | 
[epoch_0]_52661  loss=3.131694 |g|=0.558	lr=5.62e-05 | 14.0%@S44  T=1.09s eta=02:31:39 | 67.3K token/s | 
[epoch_0]_52671  loss=3.141550 |g|=0.505	lr=5.61e-05 | 14.8%@S44  T=1.09s eta=02:32:35 | 67.7K token/s | 
[epoch_0]_52681  loss=3.159499 |g|=0.491	lr=5.59e-05 | 15.6%@S44  T=1.16s eta=02:41:53 | 67.8K token/s | 
[epoch_0]_52691  loss=3.108214 |g|=0.504	lr=5.58e-05 | 16.5%@S44  T=1.13s eta=02:37:04 | 68.0K token/s | 
[Fuyou] head="4" update algorithm=4 t=2.10s
[Section@52700] layer[30-36] tasks=15(nPassBack=0) last_loss=3.07773(0.0607221) N=(580,44772,44352 5269900)
[epoch_0]_52701  loss=3.195175 |g|=0.496	lr=5.57e-05 | 17.3%@S44  T=1.51s eta=03:29:51 | 67.3K token/s | 
[epoch_0]_52711  loss=3.067177 |g|=0.938	lr=5.56e-05 | 18.1%@S44  T=1.08s eta=02:29:35 | 67.8K token/s | 
[epoch_0]_52721  loss=3.149576 |g|=0.492	lr=5.55e-05 | 18.9%@S44  T=1.12s eta=02:34:51 | 68.0K token/s | 
[epoch_0]_52731  loss=3.097354 |g|=0.502	lr=5.54e-05 | 19.7%@S44  T=1.14s eta=02:37:51 | 68.2K token/s | 
[epoch_0]_52741  loss=3.079676 |g|=0.493	lr=5.53e-05 | 20.6%@S44  T=1.10s eta=02:31:42 | 68.6K token/s | 
[epoch_0]_52751  loss=3.054399 |g|=0.516	lr=5.52e-05 | 21.4%@S44  T=1.12s eta=02:34:48 | 68.8K token/s | 
[epoch_0]_52761  loss=3.166889 |g|=0.505	lr=5.51e-05 | 22.2%@S44  T=1.10s eta=02:31:47 | 69.1K token/s | 
[epoch_0]_52771  loss=3.161988 |g|=0.502	lr=5.50e-05 | 23.0%@S44  T=1.12s eta=02:33:47 | 69.3K token/s | 
[epoch_0]_52781  loss=3.113558 |g|=0.498	lr=5.49e-05 | 23.8%@S44  T=1.21s eta=02:46:15 | 69.2K token/s | 
[epoch_0]_52791  loss=3.179997 |g|=0.497	lr=5.48e-05 | 24.7%@S44  T=1.10s eta=02:30:40 | 69.5K token/s | 
[Fuyou] head="5" update algorithm=4 t=2.09s
[eval] 
	 Loss@"edu_fineweb1B"=3.163(0.0014) nBranch=1 nToken=4.01M best=3.1648(262) E2T=-0.0253 T=13.5233(0)s x=0
	#3.16338±0.1084 tps=297K(4.01408M) a=[2.98639,3.45652] T=13.5233(sec)
[Section@52800] layer[0-6] tasks=15(nPassBack=0) last_loss=3.18866(-0.0429447) N=(580,44856,44436 5279900)
[epoch_0]_52801  loss=3.131267 |g|=0.498	lr=5.47e-05 | 25.5%@S44  T=4.31s eta=09:51:06 | 67.0K token/s | 
[epoch_0]_52811  loss=3.138328 |g|=0.515	lr=5.45e-05 | 26.3%@S44  T=1.11s eta=02:32:05 | 67.3K token/s | 
[epoch_0]_52821  loss=3.107899 |g|=0.49	lr=5.44e-05 | 27.1%@S44  T=1.10s eta=02:30:37 | 67.7K token/s | 
[epoch_0]_52831  loss=3.185818 |g|=0.546	lr=5.43e-05 | 27.9%@S44  T=1.13s eta=02:34:31 | 67.9K token/s | 
[epoch_0]_52841  loss=3.266273 |g|=0.521	lr=5.42e-05 | 28.7%@S44  T=1.13s eta=02:33:55 | 68.1K token/s | 
[epoch_0]_52851  loss=3.089011 |g|=0.488	lr=5.41e-05 | 29.6%@S44  T=1.15s eta=02:37:15 | 68.3K token/s | 
[epoch_0]_52861  loss=3.117001 |g|=0.493	lr=5.40e-05 | 30.4%@S44  T=1.66s eta=03:46:03 | 67.3K token/s | 
[epoch_0]_52871  loss=3.157293 |g|=0.518	lr=5.39e-05 | 31.2%@S44  T=1.13s eta=02:33:05 | 67.6K token/s | 
[epoch_0]_52881  loss=3.192039 |g|=0.496	lr=5.38e-05 | 32.0%@S44  T=1.11s eta=02:30:40 | 67.9K token/s | 
[epoch_0]_52891  loss=3.114786 |g|=0.492	lr=5.37e-05 | 32.8%@S44  T=1.10s eta=02:29:30 | 68.2K token/s | 
[Fuyou] head="0" update algorithm=4 t=2.40s
[Section@52900] layer[6-12] tasks=15(nPassBack=0) last_loss=3.15509(-0.00799036) N=(580,44940,44520 5289900)
[epoch_0]_52901  loss=3.242740 |g|=0.513	lr=5.36e-05 | 33.7%@S44  T=1.41s eta=03:10:36 | 67.7K token/s | 
[epoch_0]_52911  loss=3.127551 |g|=0.51	lr=5.35e-05 | 34.5%@S44  T=1.12s eta=02:31:27 | 68.0K token/s | 
[epoch_0]_52921  loss=3.115210 |g|=0.497	lr=5.34e-05 | 35.3%@S44  T=1.10s eta=02:28:06 | 68.4K token/s | 
[epoch_0]_52931  loss=3.126723 |g|=0.505	lr=5.33e-05 | 36.1%@S44  T=1.11s eta=02:30:04 | 68.6K token/s | 
[epoch_0]_52941  loss=3.104714 |g|=0.502	lr=5.32e-05 | 36.9%@S44  T=1.14s eta=02:33:44 | 68.8K token/s | 
[epoch_0]_52951  loss=3.134055 |g|=0.506	lr=5.31e-05 | 37.8%@S44  T=1.12s eta=02:30:54 | 69.0K token/s | 
[epoch_0]_52961  loss=3.153795 |g|=0.517	lr=5.30e-05 | 38.6%@S44  T=1.08s eta=02:25:01 | 69.4K token/s | 
[epoch_0]_52971  loss=3.016301 |g|=0.478	lr=5.29e-05 | 39.4%@S44  T=1.13s eta=02:32:23 | 69.5K token/s | 
[epoch_0]_52981  loss=3.067009 |g|=0.489	lr=5.28e-05 | 40.2%@S44  T=1.12s eta=02:29:55 | 69.7K token/s | 
[epoch_0]_52991  loss=3.143175 |g|=0.493	lr=5.26e-05 | 41.0%@S44  T=1.12s eta=02:29:48 | 69.9K token/s | 
[Fuyou] head="1" update algorithm=4 t=2.08s
[eval] 
	 Loss@"edu_fineweb1B"=3.162(0.0017) nBranch=1 nToken=4.01M best=3.1634(263) E2T=0.0612 T=13.4409(0)s x=0
	#3.16169±0.1082 tps=299K(4.01408M) a=[2.98632,3.45568] T=13.4409(sec)
[Section@53000] layer[12-18] tasks=15(nPassBack=0) last_loss=3.10052(0.0180221) N=(580,45024,44604 5299900)
[epoch_0]_53001  loss=3.048288 |g|=0.513	lr=5.25e-05 | 41.9%@S44  T=4.23s eta=09:26:56 | 67.4K token/s | 
[epoch_0]_53011  loss=3.113029 |g|=0.51	lr=5.24e-05 | 42.7%@S44  T=1.13s eta=02:31:29 | 67.6K token/s | 
[epoch_0]_53021  loss=3.173158 |g|=0.512	lr=5.23e-05 | 43.5%@S44  T=1.11s eta=02:28:36 | 67.9K token/s | 
[epoch_0]_53031  loss=3.168105 |g|=0.559	lr=5.22e-05 | 44.3%@S44  T=1.17s eta=02:36:44 | 68.0K token/s | 
[epoch_0]_53041  loss=3.110461 |g|=0.505	lr=5.21e-05 | 45.1%@S44  T=1.13s eta=02:30:36 | 68.2K token/s | 
[epoch_0]_53051  loss=3.191735 |g|=0.536	lr=5.20e-05 | 46.0%@S44  T=1.11s eta=02:28:17 | 68.5K token/s | 
[epoch_0]_53061  loss=3.149922 |g|=0.499	lr=5.19e-05 | 46.8%@S44  T=1.10s eta=02:26:44 | 68.8K token/s | 
[epoch_0]_53071  loss=3.131182 |g|=0.485	lr=5.18e-05 | 47.6%@S44  T=1.12s eta=02:28:01 | 69.0K token/s | 
[epoch_0]_53081  loss=3.142259 |g|=0.49	lr=5.17e-05 | 48.4%@S44  T=1.15s eta=02:32:24 | 69.1K token/s | 
[epoch_0]_53091  loss=3.058565 |g|=0.493	lr=5.16e-05 | 49.2%@S44  T=1.10s eta=02:26:02 | 69.4K token/s | 
[Fuyou] head="2" update algorithm=4 t=3.34s
[Section@53100] layer[18-24] tasks=15(nPassBack=0) last_loss=3.16454(-0.0717659) N=(580,45108,44688 5309900)
[epoch_0]_53101  loss=3.137578 |g|=0.52	lr=5.15e-05 | 50.0%@S44  T=1.61s eta=03:32:26 | 68.5K token/s | 
[epoch_0]_53111  loss=3.163262 |g|=0.512	lr=5.14e-05 | 50.9%@S44  T=1.09s eta=02:24:14 | 68.8K token/s | 
[epoch_0]_53121  loss=3.057155 |g|=0.49	lr=5.13e-05 | 51.7%@S44  T=1.15s eta=02:31:44 | 68.9K token/s | 
[epoch_0]_53131  loss=3.065697 |g|=0.508	lr=5.12e-05 | 52.5%@S44  T=1.25s eta=02:44:40 | 68.7K token/s | 
[epoch_0]_53141  loss=3.111692 |g|=0.483	lr=5.11e-05 | 53.3%@S44  T=1.09s eta=02:23:16 | 69.1K token/s | 
[epoch_0]_53151  loss=3.136796 |g|=0.495	lr=5.10e-05 | 54.1%@S44  T=1.11s eta=02:25:46 | 69.3K token/s | 
[epoch_0]_53161  loss=3.144927 |g|=0.5	lr=5.09e-05 | 55.0%@S44  T=1.50s eta=03:17:24 | 68.6K token/s | 
[epoch_0]_53171  loss=3.165442 |g|=0.48	lr=5.08e-05 | 55.8%@S44  T=1.16s eta=02:32:28 | 68.6K token/s | 
[epoch_0]_53181  loss=3.109662 |g|=0.5	lr=5.07e-05 | 56.6%@S44  T=1.10s eta=02:23:42 | 68.9K token/s | 
[epoch_0]_53191  loss=3.147571 |g|=0.493	lr=5.06e-05 | 57.4%@S44  T=1.12s eta=02:26:39 | 69.2K token/s | 
[Fuyou] head="3" update algorithm=4 t=2.19s
[eval] 
	 Loss@"edu_fineweb1B"=3.160(0.0019) nBranch=1 nToken=4.01M best=3.1617(264) E2T=0.0197 T=13.427(0)s x=0
	#3.15978±0.1083 tps=299K(4.01408M) a=[2.98516,3.45385] T=13.427(sec)
[Section@53200] layer[24-30] tasks=15(nPassBack=0) last_loss=3.14005(-0.00196838) N=(580,45192,44772 5319900)
[epoch_0]_53201  loss=3.153928 |g|=0.525	lr=5.05e-05 | 58.2%@S44  T=4.23s eta=09:12:53 | 66.7K token/s | 
[epoch_0]_53211  loss=3.133705 |g|=0.478	lr=5.04e-05 | 59.1%@S44  T=1.28s eta=02:46:39 | 66.5K token/s | 
[epoch_0]_53221  loss=3.210088 |g|=0.54	lr=5.03e-05 | 59.9%@S44  T=1.11s eta=02:24:30 | 66.9K token/s | 
[epoch_0]_53231  loss=3.114524 |g|=0.518	lr=5.02e-05 | 60.7%@S44  T=1.10s eta=02:23:22 | 67.3K token/s | 
[epoch_0]_53241  loss=3.095499 |g|=0.481	lr=5.01e-05 | 61.5%@S44  T=1.46s eta=03:09:07 | 66.7K token/s | 
[epoch_0]_53251  loss=3.171076 |g|=0.495	lr=5.00e-05 | 62.3%@S44  T=1.13s eta=02:26:14 | 67.0K token/s | 
[epoch_0]_53261  loss=3.064668 |g|=0.506	lr=4.99e-05 | 63.2%@S44  T=1.10s eta=02:22:48 | 67.4K token/s | 
[epoch_0]_53271  loss=3.169621 |g|=0.516	lr=4.98e-05 | 64.0%@S44  T=1.11s eta=02:23:45 | 67.7K token/s | 
[epoch_0]_53281  loss=3.060212 |g|=0.49	lr=4.97e-05 | 64.8%@S44  T=1.12s eta=02:24:15 | 68.0K token/s | 
[epoch_0]_53291  loss=3.109372 |g|=0.481	lr=4.96e-05 | 65.6%@S44  T=1.14s eta=02:27:34 | 68.2K token/s | 
[Fuyou] head="4" update algorithm=4 t=2.08s
[Section@53300] layer[30-36] tasks=15(nPassBack=0) last_loss=3.10589(-0.0281632) N=(580,45276,44856 5329900)
[epoch_0]_53301  loss=3.148987 |g|=0.487	lr=4.95e-05 | 66.4%@S44  T=1.41s eta=03:02:05 | 67.7K token/s | 
[epoch_0]_53311  loss=3.140429 |g|=0.483	lr=4.94e-05 | 67.2%@S44  T=1.13s eta=02:25:05 | 67.9K token/s | 
[epoch_0]_53321  loss=3.197898 |g|=0.533	lr=4.93e-05 | 68.1%@S44  T=1.09s eta=02:20:35 | 68.3K token/s | 
[epoch_0]_53331  loss=3.100727 |g|=0.513	lr=4.92e-05 | 68.9%@S44  T=1.13s eta=02:25:29 | 68.5K token/s | 
[epoch_0]_53341  loss=3.109625 |g|=0.527	lr=4.91e-05 | 69.7%@S44  T=1.13s eta=02:24:33 | 68.7K token/s | 
[epoch_0]_53351  loss=3.058131 |g|=0.536	lr=4.90e-05 | 70.5%@S44  T=1.10s eta=02:20:34 | 69.0K token/s | 
[epoch_0]_53361  loss=3.042792 |g|=0.495	lr=4.89e-05 | 71.3%@S44  T=1.11s eta=02:21:34 | 69.2K token/s | 
[epoch_0]_53371  loss=3.169160 |g|=0.519	lr=4.88e-05 | 72.2%@S44  T=1.10s eta=02:20:45 | 69.5K token/s | 
[epoch_0]_53381  loss=3.159871 |g|=0.538	lr=4.87e-05 | 73.0%@S44  T=1.15s eta=02:26:46 | 69.6K token/s | 
[epoch_0]_53391  loss=3.174989 |g|=0.528	lr=4.86e-05 | 73.8%@S44  T=1.10s eta=02:19:48 | 69.8K token/s | 
[Fuyou] head="5" update algorithm=4 t=2.08s
[eval] 
	 Loss@"edu_fineweb1B"=3.158(0.0014) nBranch=1 nToken=4.01M best=3.1598(265) E2T=-0.0177 T=13.4372(0)s x=0
	#3.15843±0.1082 tps=299K(4.01408M) a=[2.9828,3.45293] T=13.4372(sec)
[Section@53400] layer[0-6] tasks=15(nPassBack=0) last_loss=3.17612(0.0125384) N=(580,45360,44940 5339900)
[epoch_0]_53401  loss=3.076077 |g|=0.528	lr=4.85e-05 | 74.6%@S44  T=4.23s eta=08:57:41 | 67.3K token/s | 
[epoch_0]_53411  loss=3.145751 |g|=0.519	lr=4.84e-05 | 75.4%@S44  T=1.11s eta=02:21:39 | 67.6K token/s | 
[epoch_0]_53421  loss=3.143077 |g|=0.493	lr=4.83e-05 | 76.3%@S44  T=1.10s eta=02:20:13 | 67.9K token/s | 
[epoch_0]_53431  loss=3.117218 |g|=0.514	lr=4.82e-05 | 77.1%@S44  T=1.10s eta=02:19:34 | 68.3K token/s | 
[epoch_0]_53441  loss=3.118057 |g|=0.502	lr=4.81e-05 | 77.9%@S44  T=1.10s eta=02:19:37 | 68.6K token/s | 
[epoch_0]_53451  loss=3.159074 |g|=0.511	lr=4.80e-05 | 78.7%@S44  T=1.12s eta=02:22:05 | 68.8K token/s | 
[epoch_0]_53461  loss=3.052637 |g|=0.565	lr=4.79e-05 | 79.5%@S44  T=1.13s eta=02:22:54 | 68.9K token/s | 
[epoch_0]_53471  loss=3.127147 |g|=0.506	lr=4.78e-05 | 80.4%@S44  T=1.10s eta=02:19:17 | 69.2K token/s | 
[epoch_0]_53481  loss=3.121461 |g|=0.489	lr=4.77e-05 | 81.2%@S44  T=1.11s eta=02:20:10 | 69.4K token/s | 
[epoch_0]_53491  loss=3.048068 |g|=0.489	lr=4.76e-05 | 82.0%@S44  T=1.14s eta=02:23:53 | 69.5K token/s | 
[Fuyou] head="0" update algorithm=4 t=2.09s
[Section@53500] layer[6-12] tasks=15(nPassBack=0) last_loss=3.14551(0.00957394) N=(580,45444,45024 5349900)
[epoch_0]_53501  loss=3.151778 |g|=0.509	lr=4.75e-05 | 82.8%@S44  T=1.72s eta=03:36:10 | 68.4K token/s | 
[epoch_0]_53511  loss=3.137186 |g|=0.48	lr=4.74e-05 | 83.6%@S44  T=1.10s eta=02:17:22 | 68.8K token/s | 
[epoch_0]_53521  loss=3.099199 |g|=0.512	lr=4.73e-05 | 84.5%@S44  T=1.10s eta=02:17:59 | 69.0K token/s | 
[epoch_0]_53531  loss=3.154333 |g|=0.516	lr=4.72e-05 | 85.3%@S44  T=1.12s eta=02:19:57 | 69.2K token/s | 
[epoch_0]_53541  loss=3.117733 |g|=0.517	lr=4.71e-05 | 86.1%@S44  T=1.16s eta=02:24:40 | 69.3K token/s | 
[epoch_0]_53551  loss=3.049747 |g|=0.502	lr=4.70e-05 | 86.9%@S44  T=1.10s eta=02:17:37 | 69.6K token/s | 
[epoch_0]_53561  loss=3.122354 |g|=0.506	lr=4.69e-05 | 87.7%@S44  T=1.09s eta=02:15:47 | 69.8K token/s | 
[epoch_0]_53571  loss=3.119136 |g|=0.504	lr=4.68e-05 | 88.5%@S44  T=1.11s eta=02:17:54 | 70.0K token/s | 
[epoch_0]_53581  loss=3.138935 |g|=0.531	lr=4.67e-05 | 89.4%@S44  T=1.17s eta=02:25:29 | 70.0K token/s | 
[epoch_0]_53591  loss=3.112262 |g|=0.511	lr=4.66e-05 | 90.2%@S44  T=1.09s eta=02:15:48 | 70.3K token/s | 
[Fuyou] head="1" update algorithm=4 t=2.15s
[eval] 
	 Loss@"edu_fineweb1B"=3.158(0.00093) nBranch=1 nToken=4.01M best=3.1584(266) E2T=0.0356 T=13.4397(0)s x=0
	#3.1575±0.1084 tps=299K(4.01408M) a=[2.98336,3.45389] T=13.4397(sec)
[Section@53600] layer[12-18] tasks=15(nPassBack=0) last_loss=3.12192(-0.0214) N=(580,45528,45108 5359900)
[epoch_0]_53601  loss=3.201834 |g|=0.519	lr=4.65e-05 | 91.0%@S44  T=4.23s eta=08:44:05 | 67.7K token/s | 
[epoch_0]_53611  loss=3.173937 |g|=0.515	lr=4.64e-05 | 91.8%@S44  T=1.15s eta=02:22:05 | 67.9K token/s | 
[epoch_0]_53621  loss=3.016583 |g|=0.52	lr=4.63e-05 | 92.6%@S44  T=1.11s eta=02:17:28 | 68.2K token/s | 
[epoch_0]_53631  loss=3.149692 |g|=0.495	lr=4.62e-05 | 93.5%@S44  T=1.10s eta=02:16:17 | 68.5K token/s | 
[epoch_0]_53641  loss=3.117644 |g|=0.496	lr=4.61e-05 | 94.3%@S44  T=1.47s eta=03:00:33 | 67.9K token/s | 
[epoch_0]_53651  loss=3.196478 |g|=0.538	lr=4.60e-05 | 95.1%@S44  T=1.15s eta=02:21:01 | 68.1K token/s | 
[epoch_0]_53661  loss=3.151630 |g|=0.52	lr=4.59e-05 | 95.9%@S44  T=1.13s eta=02:18:30 | 68.3K token/s | 
[epoch_0]_53671  loss=3.090811 |g|=0.486	lr=4.58e-05 | 96.7%@S44  T=1.24s eta=02:32:47 | 68.2K token/s | 
[epoch_0]_53681  loss=3.087473 |g|=0.523	lr=4.57e-05 | 97.6%@S44  T=1.11s eta=02:16:00 | 68.4K token/s | 
[epoch_0]_53691  loss=3.152462 |g|=0.504	lr=4.56e-05 | 98.4%@S44  T=1.12s eta=02:17:14 | 68.7K token/s | 
[Fuyou] head="2" update algorithm=4 t=2.09s
[Section@53700] layer[18-24] tasks=15(nPassBack=0) last_loss=3.0142(0.150339) N=(580,45612,45192 5369900)
[epoch_0]_53701  loss=3.104640 |g|=0.541	lr=4.55e-05 | 99.2%@S44  T=2.26s eta=04:35:51 | 67.1K token/s | 
[epoch_0]_53710  loss=3.159689 |g|=0.505	lr=4.55e-05 | 99.9%@S44  T=1.11s eta=02:15:55 | 67.4K token/s | 
-------- End of shard_44@"./Datasets/edu_fineweb1B/edu_fineweb_train_000801.bin"-------- 
[shard-45]@"./Datasets/edu_fineweb1B/edu_fineweb_train_000802.bin": tokens=100(M) nShardSamples=1220(4394520) 
[epoch_0]_53711  loss=3.114403 |g|=0.498	lr=4.54e-05 | 0.0%@S45  T=1.44s eta=02:55:41 | 66.9K token/s | 
[epoch_0]_53721  loss=3.128606 |g|=0.539	lr=4.53e-05 | 0.8%@S45  T=1.09s eta=02:12:51 | 67.3K token/s | 
[epoch_0]_53731  loss=3.161261 |g|=0.508	lr=4.53e-05 | 1.7%@S45  T=1.42s eta=02:52:49 | 66.8K token/s | 
[epoch_0]_53741  loss=3.103940 |g|=0.502	lr=4.52e-05 | 2.5%@S45  T=1.15s eta=02:19:29 | 67.0K token/s | 
[epoch_0]_53751  loss=3.128248 |g|=0.49	lr=4.51e-05 | 3.3%@S45  T=1.08s eta=02:11:35 | 67.5K token/s | 
[epoch_0]_53761  loss=3.184187 |g|=0.531	lr=4.50e-05 | 4.1%@S45  T=1.08s eta=02:10:24 | 67.9K token/s | 
[epoch_0]_53771  loss=3.111106 |g|=0.493	lr=4.49e-05 | 4.9%@S45  T=1.11s eta=02:14:25 | 68.2K token/s | 
[epoch_0]_53781  loss=3.091231 |g|=0.492	lr=4.48e-05 | 5.8%@S45  T=1.14s eta=02:18:06 | 68.4K token/s | 
[epoch_0]_53791  loss=3.123770 |g|=0.513	lr=4.47e-05 | 6.6%@S45  T=1.09s eta=02:11:14 | 68.7K token/s | 
[Fuyou] head="3" update algorithm=4 t=2.08s
[eval] 
	 Loss@"edu_fineweb1B"=3.156(0.0012) nBranch=1 nToken=4.01M best=3.1575(267) E2T=0.0584 T=13.4382(0)s x=0
	#3.15631±0.1085 tps=299K(4.01408M) a=[2.98039,3.45008] T=13.4382(sec)
[Section@53800] layer[24-30] tasks=15(nPassBack=0) last_loss=3.09787(0.042182) N=(580,45696,45276 5379900)
[epoch_0]_53801  loss=3.064354 |g|=0.505	lr=4.46e-05 | 7.4%@S45  T=4.21s eta=08:27:59 | 66.2K token/s | 
[epoch_0]_53811  loss=3.061623 |g|=0.495	lr=4.45e-05 | 8.2%@S45  T=1.35s eta=02:42:40 | 66.0K token/s | 
[epoch_0]_53821  loss=3.121200 |g|=0.506	lr=4.44e-05 | 9.0%@S45  T=1.10s eta=02:12:41 | 66.4K token/s | 
[epoch_0]_53831  loss=3.137283 |g|=0.506	lr=4.43e-05 | 9.8%@S45  T=1.14s eta=02:16:24 | 66.7K token/s | 
[epoch_0]_53841  loss=3.090191 |g|=0.51	lr=4.42e-05 | 10.7%@S45  T=1.11s eta=02:13:11 | 67.0K token/s | 
[epoch_0]_53851  loss=3.142053 |g|=0.507	lr=4.41e-05 | 11.5%@S45  T=1.08s eta=02:09:42 | 67.4K token/s | 
[epoch_0]_53861  loss=3.087460 |g|=0.515	lr=4.40e-05 | 12.3%@S45  T=1.10s eta=02:11:48 | 67.8K token/s | 
[epoch_0]_53871  loss=3.138333 |g|=0.495	lr=4.39e-05 | 13.1%@S45  T=1.15s eta=02:16:44 | 68.0K token/s | 
[epoch_0]_53881  loss=3.192693 |g|=0.493	lr=4.38e-05 | 13.9%@S45  T=1.11s eta=02:12:27 | 68.3K token/s | 
[epoch_0]_53891  loss=3.073943 |g|=0.502	lr=4.37e-05 | 14.8%@S45  T=1.10s eta=02:10:59 | 68.6K token/s | 
[Fuyou] head="4" update algorithm=4 t=2.09s
[Section@53900] layer[30-36] tasks=15(nPassBack=0) last_loss=3.07332(0.0325739) N=(580,45780,45360 5389900)
[epoch_0]_53901  loss=3.149855 |g|=0.499	lr=4.36e-05 | 15.6%@S45  T=1.56s eta=03:05:14 | 67.8K token/s | 
[epoch_0]_53911  loss=3.141125 |g|=0.509	lr=4.36e-05 | 16.4%@S45  T=1.10s eta=02:10:38 | 68.1K token/s | 
[epoch_0]_53921  loss=3.100346 |g|=0.485	lr=4.35e-05 | 17.2%@S45  T=1.10s eta=02:09:58 | 68.4K token/s | 
[epoch_0]_53931  loss=3.135239 |g|=0.519	lr=4.34e-05 | 18.0%@S45  T=1.09s eta=02:09:27 | 68.8K token/s | 
[epoch_0]_53941  loss=3.102703 |g|=0.503	lr=4.33e-05 | 18.9%@S45  T=1.09s eta=02:09:00 | 69.1K token/s | 
[epoch_0]_53951  loss=3.097602 |g|=0.505	lr=4.32e-05 | 19.7%@S45  T=1.12s eta=02:11:59 | 69.3K token/s | 
[epoch_0]_53961  loss=3.149565 |g|=0.503	lr=4.31e-05 | 20.5%@S45  T=1.13s eta=02:12:45 | 69.5K token/s | 
[epoch_0]_53971  loss=3.165312 |g|=0.509	lr=4.30e-05 | 21.3%@S45  T=1.10s eta=02:09:30 | 69.7K token/s | 
[epoch_0]_53981  loss=3.174539 |g|=0.517	lr=4.29e-05 | 22.1%@S45  T=1.10s eta=02:09:51 | 69.9K token/s | 
[epoch_0]_53991  loss=3.100131 |g|=0.512	lr=4.28e-05 | 23.0%@S45  T=1.16s eta=02:16:42 | 70.0K token/s | 
[Fuyou] head="5" update algorithm=4 t=2.06s
[eval] 
	 Loss@"edu_fineweb1B"=3.156(0.00035) nBranch=1 nToken=4.01M best=3.1563(268) E2T=0.0569 T=13.4322(0)s x=0
	#3.15596±0.1086 tps=299K(4.01408M) a=[2.98089,3.4512] T=13.4322(sec)
[Section@54000] layer[0-6] tasks=15(nPassBack=0) last_loss=3.0991(0.0770144) N=(580,45864,45444 5399900)
[epoch_0]_54001  loss=3.124883 |g|=0.535	lr=4.27e-05 | 23.8%@S45  T=4.20s eta=08:12:54 | 67.4K token/s | 
[epoch_0]_54011  loss=3.102201 |g|=0.501	lr=4.26e-05 | 24.6%@S45  T=1.33s eta=02:36:08 | 67.1K token/s | 
[epoch_0]_54021  loss=3.134747 |g|=0.531	lr=4.25e-05 | 25.4%@S45  T=1.16s eta=02:15:15 | 67.3K token/s | 
[epoch_0]_54031  loss=3.162215 |g|=0.512	lr=4.24e-05 | 26.2%@S45  T=1.10s eta=02:08:20 | 67.7K token/s | 
[epoch_0]_54041  loss=3.122100 |g|=0.487	lr=4.24e-05 | 27.1%@S45  T=1.12s eta=02:10:47 | 67.9K token/s | 
[epoch_0]_54051  loss=3.122496 |g|=0.501	lr=4.23e-05 | 27.9%@S45  T=1.11s eta=02:08:38 | 68.3K token/s | 
[epoch_0]_54061  loss=3.109853 |g|=0.529	lr=4.22e-05 | 28.7%@S45  T=1.14s eta=02:12:53 | 68.4K token/s | 
[epoch_0]_54071  loss=3.147321 |g|=0.495	lr=4.21e-05 | 29.5%@S45  T=1.22s eta=02:21:44 | 68.4K token/s | 
[epoch_0]_54081  loss=3.113653 |g|=0.501	lr=4.20e-05 | 30.3%@S45  T=1.10s eta=02:07:35 | 68.7K token/s | 
[epoch_0]_54091  loss=3.118934 |g|=0.501	lr=4.19e-05 | 31.1%@S45  T=1.11s eta=02:08:15 | 68.9K token/s | 
[Fuyou] head="0" update algorithm=4 t=2.20s
[Section@54100] layer[6-12] tasks=15(nPassBack=0) last_loss=3.0823(0.0632148) N=(580,45948,45528 5409900)
[epoch_0]_54101  loss=3.003690 |g|=0.485	lr=4.18e-05 | 32.0%@S45  T=1.39s eta=02:40:52 | 68.4K token/s | 
[epoch_0]_54111  loss=3.035279 |g|=0.518	lr=4.17e-05 | 32.8%@S45  T=1.08s eta=02:04:16 | 68.8K token/s | 
[epoch_0]_54121  loss=3.227007 |g|=0.523	lr=4.16e-05 | 33.6%@S45  T=1.13s eta=02:10:03 | 69.0K token/s | 
[epoch_0]_54131  loss=3.203131 |g|=0.518	lr=4.15e-05 | 34.4%@S45  T=1.11s eta=02:08:06 | 69.2K token/s | 
[epoch_0]_54141  loss=3.135697 |g|=0.514	lr=4.14e-05 | 35.2%@S45  T=1.07s eta=02:03:15 | 69.6K token/s | 
[epoch_0]_54151  loss=3.099219 |g|=0.51	lr=4.14e-05 | 36.1%@S45  T=1.09s eta=02:05:04 | 69.9K token/s | 
[epoch_0]_54161  loss=3.182508 |g|=0.506	lr=4.13e-05 | 36.9%@S45  T=1.14s eta=02:10:40 | 70.0K token/s | 
[epoch_0]_54171  loss=3.158205 |g|=0.492	lr=4.12e-05 | 37.7%@S45  T=1.12s eta=02:07:57 | 70.1K token/s | 
[epoch_0]_54181  loss=3.156304 |g|=0.527	lr=4.11e-05 | 38.5%@S45  T=1.08s eta=02:03:37 | 70.4K token/s | 
[epoch_0]_54191  loss=3.121675 |g|=0.522	lr=4.10e-05 | 39.3%@S45  T=1.11s eta=02:06:14 | 70.6K token/s | 
[Fuyou] head="1" update algorithm=4 t=2.03s
[eval] 
	 Loss@"edu_fineweb1B"=3.156(0.00044) nBranch=1 nToken=4.01M best=3.1560(269) E2T=0.0463 T=13.4294(0)s x=0
	#3.15552±0.1085 tps=299K(4.01408M) a=[2.98058,3.45091] T=13.4294(sec)
[Section@54200] layer[12-18] tasks=15(nPassBack=0) last_loss=3.10919(0.0127208) N=(580,46032,45612 5419900)
[epoch_0]_54201  loss=3.067932 |g|=0.511	lr=4.09e-05 | 40.2%@S45  T=4.28s eta=08:07:23 | 68.0K token/s | 
[epoch_0]_54211  loss=3.086076 |g|=0.508	lr=4.08e-05 | 41.0%@S45  T=1.11s eta=02:05:58 | 68.3K token/s | 
[epoch_0]_54221  loss=3.141524 |g|=0.51	lr=4.07e-05 | 41.8%@S45  T=1.13s eta=02:07:47 | 68.5K token/s | 
[epoch_0]_54231  loss=3.114186 |g|=0.504	lr=4.06e-05 | 42.6%@S45  T=1.13s eta=02:08:39 | 68.7K token/s | 
[epoch_0]_54241  loss=3.046483 |g|=0.488	lr=4.06e-05 | 43.4%@S45  T=1.11s eta=02:05:36 | 69.0K token/s | 
[epoch_0]_54251  loss=3.122098 |g|=0.509	lr=4.05e-05 | 44.3%@S45  T=1.12s eta=02:07:10 | 69.2K token/s | 
[epoch_0]_54261  loss=3.081201 |g|=0.495	lr=4.04e-05 | 45.1%@S45  T=1.14s eta=02:08:25 | 69.3K token/s | 
[epoch_0]_54271  loss=3.084921 |g|=0.49	lr=4.03e-05 | 45.9%@S45  T=1.14s eta=02:08:43 | 69.4K token/s | 
[epoch_0]_54281  loss=3.160317 |g|=0.521	lr=4.02e-05 | 46.7%@S45  T=1.11s eta=02:04:39 | 69.7K token/s | 
[epoch_0]_54291  loss=3.170496 |g|=0.5	lr=4.01e-05 | 47.5%@S45  T=1.12s eta=02:05:42 | 69.8K token/s | 
[Fuyou] head="2" update algorithm=4 t=2.42s
[Section@54300] layer[18-24] tasks=15(nPassBack=0) last_loss=3.16616(-0.151957) N=(580,46116,45696 5429900)
[epoch_0]_54301  loss=2.982476 |g|=0.523	lr=4.00e-05 | 48.4%@S45  T=1.50s eta=02:47:52 | 69.1K token/s | 
[epoch_0]_54311  loss=3.106965 |g|=0.503	lr=3.99e-05 | 49.2%@S45  T=1.17s eta=02:10:53 | 69.1K token/s | 
[epoch_0]_54321  loss=3.123321 |g|=0.508	lr=3.98e-05 | 50.0%@S45  T=1.09s eta=02:02:14 | 69.4K token/s | 
[epoch_0]_54331  loss=3.108334 |g|=0.508	lr=3.98e-05 | 50.8%@S45  T=1.12s eta=02:05:02 | 69.6K token/s | 
[epoch_0]_54341  loss=3.175349 |g|=0.513	lr=3.97e-05 | 51.6%@S45  T=1.17s eta=02:10:21 | 69.6K token/s | 
[epoch_0]_54351  loss=3.160612 |g|=0.508	lr=3.96e-05 | 52.4%@S45  T=1.13s eta=02:06:21 | 69.8K token/s | 
[epoch_0]_54361  loss=3.074233 |g|=0.503	lr=3.95e-05 | 53.3%@S45  T=1.10s eta=02:02:26 | 70.0K token/s | 
[epoch_0]_54371  loss=3.038663 |g|=0.514	lr=3.94e-05 | 54.1%@S45  T=1.11s eta=02:03:15 | 70.2K token/s | 
[epoch_0]_54381  loss=3.132388 |g|=0.493	lr=3.93e-05 | 54.9%@S45  T=1.17s eta=02:09:33 | 70.2K token/s | 
[epoch_0]_54391  loss=2.998777 |g|=0.5	lr=3.92e-05 | 55.7%@S45  T=1.11s eta=02:02:36 | 70.4K token/s | 
[Fuyou] head="3" update algorithm=4 t=2.28s
[eval] 
	 Loss@"edu_fineweb1B"=3.155(0.00094) nBranch=1 nToken=4.01M best=3.1555(270) E2T=0.0473 T=13.4244(0)s x=0
	#3.15458±0.1084 tps=299K(4.01408M) a=[2.97979,3.44718] T=13.4244(sec)
[Section@54400] layer[24-30] tasks=15(nPassBack=0) last_loss=3.10728(-0.00940681) N=(580,46200,45780 5439900)
[epoch_0]_54401  loss=3.138231 |g|=0.536	lr=3.91e-05 | 56.5%@S45  T=4.29s eta=07:54:24 | 67.8K token/s | 
[epoch_0]_54411  loss=3.136100 |g|=0.521	lr=3.91e-05 | 57.4%@S45  T=1.13s eta=02:05:16 | 68.0K token/s | 
[epoch_0]_54421  loss=3.131683 |g|=0.514	lr=3.90e-05 | 58.2%@S45  T=1.12s eta=02:03:56 | 68.3K token/s | 
[epoch_0]_54431  loss=3.116692 |g|=0.507	lr=3.89e-05 | 59.0%@S45  T=1.13s eta=02:04:03 | 68.5K token/s | 
[epoch_0]_54441  loss=3.000012 |g|=0.494	lr=3.88e-05 | 59.8%@S45  T=1.13s eta=02:03:50 | 68.7K token/s | 
[epoch_0]_54451  loss=3.072860 |g|=0.526	lr=3.87e-05 | 60.6%@S45  T=1.17s eta=02:08:00 | 68.8K token/s | 
[epoch_0]_54461  loss=3.087686 |g|=0.51	lr=3.86e-05 | 61.5%@S45  T=1.14s eta=02:05:18 | 68.9K token/s | 
[epoch_0]_54471  loss=3.155073 |g|=0.501	lr=3.85e-05 | 62.3%@S45  T=1.10s eta=02:00:50 | 69.2K token/s | 
[epoch_0]_54481  loss=3.145405 |g|=0.505	lr=3.85e-05 | 63.1%@S45  T=1.12s eta=02:01:58 | 69.4K token/s | 
[epoch_0]_54491  loss=3.059518 |g|=0.509	lr=3.84e-05 | 63.9%@S45  T=1.15s eta=02:05:41 | 69.5K token/s | 
[Fuyou] head="4" update algorithm=4 t=2.08s
[Section@54500] layer[30-36] tasks=15(nPassBack=0) last_loss=3.17536(-0.10204) N=(580,46284,45864 5449900)
[epoch_0]_54501  loss=3.192830 |g|=0.512	lr=3.83e-05 | 64.7%@S45  T=1.61s eta=02:55:50 | 68.5K token/s | 
[epoch_0]_54511  loss=3.142227 |g|=0.507	lr=3.82e-05 | 65.6%@S45  T=1.11s eta=02:00:14 | 68.8K token/s | 
[epoch_0]_54521  loss=3.123240 |g|=0.503	lr=3.81e-05 | 66.4%@S45  T=1.11s eta=02:00:15 | 69.1K token/s | 
[epoch_0]_54531  loss=3.135929 |g|=0.494	lr=3.80e-05 | 67.2%@S45  T=1.15s eta=02:05:09 | 69.2K token/s | 
[epoch_0]_54541  loss=3.069643 |g|=0.492	lr=3.79e-05 | 68.0%@S45  T=1.18s eta=02:08:02 | 69.2K token/s | 
[epoch_0]_54551  loss=3.116233 |g|=0.506	lr=3.79e-05 | 68.8%@S45  T=1.11s eta=01:59:32 | 69.4K token/s | 
[epoch_0]_54561  loss=3.146414 |g|=0.492	lr=3.78e-05 | 69.6%@S45  T=1.13s eta=02:02:06 | 69.6K token/s | 
[epoch_0]_54571  loss=3.115591 |g|=0.497	lr=3.77e-05 | 70.5%@S45  T=1.12s eta=02:00:29 | 69.8K token/s | 
[epoch_0]_54581  loss=3.098200 |g|=0.495	lr=3.76e-05 | 71.3%@S45  T=1.16s eta=02:04:49 | 69.8K token/s | 
[epoch_0]_54591  loss=3.143338 |g|=0.539	lr=3.75e-05 | 72.1%@S45  T=1.14s eta=02:02:07 | 69.9K token/s | 
[Fuyou] head="5" update algorithm=4 t=2.07s
[eval] 
	 Loss@"edu_fineweb1B"=3.154(0.00063) nBranch=1 nToken=4.01M best=3.1546(271) E2T=0.115 T=13.45(0)s x=0
	#3.15395±0.1085 tps=298K(4.01408M) a=[2.97979,3.44677] T=13.45(sec)
[Section@54600] layer[0-6] tasks=15(nPassBack=0) last_loss=3.03858(0.0605185) N=(580,46368,45948 5459900)
[epoch_0]_54601  loss=3.011333 |g|=0.508	lr=3.74e-05 | 72.9%@S45  T=4.30s eta=07:41:08 | 67.4K token/s | 
[epoch_0]_54611  loss=3.099359 |g|=0.506	lr=3.73e-05 | 73.7%@S45  T=1.14s eta=02:01:41 | 67.6K token/s | 
[epoch_0]_54621  loss=3.074143 |g|=0.49	lr=3.73e-05 | 74.6%@S45  T=1.12s eta=02:00:04 | 67.9K token/s | 
[epoch_0]_54631  loss=3.144587 |g|=0.484	lr=3.72e-05 | 75.4%@S45  T=1.10s eta=01:57:22 | 68.2K token/s | 
[epoch_0]_54641  loss=3.158759 |g|=0.498	lr=3.71e-05 | 76.2%@S45  T=1.14s eta=02:01:25 | 68.4K token/s | 
[epoch_0]_54651  loss=3.102803 |g|=0.495	lr=3.70e-05 | 77.0%@S45  T=1.18s eta=02:05:33 | 68.4K token/s | 
[epoch_0]_54661  loss=3.128149 |g|=0.53	lr=3.69e-05 | 77.8%@S45  T=1.12s eta=01:59:02 | 68.7K token/s | 
[epoch_0]_54671  loss=3.115123 |g|=0.515	lr=3.68e-05 | 78.7%@S45  T=1.13s eta=01:59:20 | 68.9K token/s | 
[epoch_0]_54681  loss=3.112509 |g|=0.522	lr=3.68e-05 | 79.5%@S45  T=1.13s eta=01:59:16 | 69.1K token/s | 
[epoch_0]_54691  loss=3.068872 |g|=0.507	lr=3.67e-05 | 80.3%@S45  T=1.37s eta=02:24:20 | 68.6K token/s | 
[Fuyou] head="0" update algorithm=4 t=2.03s
[Section@54700] layer[6-12] tasks=15(nPassBack=0) last_loss=3.18622(-0.10392) N=(580,46452,46032 5469900)
[epoch_0]_54701  loss=3.138204 |g|=0.513	lr=3.66e-05 | 81.1%@S45  T=1.54s eta=02:42:26 | 67.8K token/s | 
[epoch_0]_54711  loss=3.094478 |g|=0.507	lr=3.65e-05 | 81.9%@S45  T=1.11s eta=01:57:00 | 68.1K token/s | 
[epoch_0]_54721  loss=3.078530 |g|=0.496	lr=3.64e-05 | 82.8%@S45  T=1.12s eta=01:57:36 | 68.4K token/s | 
[epoch_0]_54731  loss=3.187951 |g|=0.513	lr=3.63e-05 | 83.6%@S45  T=1.13s eta=01:58:32 | 68.6K token/s | 
[epoch_0]_54741  loss=3.057278 |g|=0.493	lr=3.63e-05 | 84.4%@S45  T=1.16s eta=02:02:00 | 68.7K token/s | 
[epoch_0]_54751  loss=3.139891 |g|=0.495	lr=3.62e-05 | 85.2%@S45  T=1.15s eta=02:00:33 | 68.8K token/s | 
[epoch_0]_54761  loss=3.124020 |g|=0.495	lr=3.61e-05 | 86.0%@S45  T=1.10s eta=01:54:52 | 69.1K token/s | 
[epoch_0]_54771  loss=3.117738 |g|=0.513	lr=3.60e-05 | 86.9%@S45  T=1.13s eta=01:57:40 | 69.3K token/s | 
[epoch_0]_54781  loss=3.110173 |g|=0.492	lr=3.59e-05 | 87.7%@S45  T=1.13s eta=01:57:34 | 69.5K token/s | 
[epoch_0]_54791  loss=3.139622 |g|=0.491	lr=3.58e-05 | 88.5%@S45  T=1.19s eta=02:03:41 | 69.4K token/s | 
[Fuyou] head="1" update algorithm=4 t=2.09s
[eval] 
	 Loss@"edu_fineweb1B"=3.153(0.0011) nBranch=1 nToken=4.01M best=3.1540(272) E2T=0.0162 T=13.4481(0)s x=0
	#3.15284±0.1084 tps=298K(4.01408M) a=[2.97914,3.44702] T=13.4481(sec)
[Section@54800] layer[12-18] tasks=15(nPassBack=0) last_loss=3.1366(-0.0274065) N=(580,46536,46116 5479900)
[epoch_0]_54801  loss=3.202899 |g|=0.525	lr=3.58e-05 | 89.3%@S45  T=4.26s eta=07:22:06 | 66.9K token/s | 
[epoch_0]_54811  loss=3.141445 |g|=0.513	lr=3.57e-05 | 90.1%@S45  T=1.12s eta=01:56:02 | 67.2K token/s | 
[epoch_0]_54821  loss=3.067541 |g|=0.502	lr=3.56e-05 | 90.9%@S45  T=1.11s eta=01:54:34 | 67.6K token/s | 
[epoch_0]_54831  loss=3.083004 |g|=0.486	lr=3.55e-05 | 91.8%@S45  T=1.10s eta=01:53:44 | 67.9K token/s | 
[epoch_0]_54841  loss=3.092745 |g|=0.516	lr=3.54e-05 | 92.6%@S45  T=1.12s eta=01:55:51 | 68.2K token/s | 
[epoch_0]_54851  loss=3.066355 |g|=0.505	lr=3.54e-05 | 93.4%@S45  T=1.12s eta=01:55:23 | 68.4K token/s | 
[epoch_0]_54861  loss=3.006537 |g|=0.488	lr=3.53e-05 | 94.2%@S45  T=1.14s eta=01:56:58 | 68.6K token/s | 
[epoch_0]_54871  loss=3.052905 |g|=0.497	lr=3.52e-05 | 95.0%@S45  T=1.17s eta=02:00:30 | 68.7K token/s | 
[epoch_0]_54881  loss=3.171627 |g|=0.502	lr=3.51e-05 | 95.9%@S45  T=1.09s eta=01:51:19 | 69.0K token/s | 
[epoch_0]_54891  loss=3.054472 |g|=0.508	lr=3.50e-05 | 96.7%@S45  T=1.11s eta=01:53:34 | 69.3K token/s | 
[Fuyou] head="2" update algorithm=4 t=2.07s
[Section@54900] layer[18-24] tasks=15(nPassBack=0) last_loss=3.07068(0.0954781) N=(580,46620,46200 5489900)
[epoch_0]_54901  loss=3.173814 |g|=0.553	lr=3.50e-05 | 97.5%@S45  T=1.56s eta=02:39:16 | 68.4K token/s | 
[epoch_0]_54911  loss=3.151857 |g|=0.515	lr=3.49e-05 | 98.3%@S45  T=1.11s eta=01:53:07 | 68.7K token/s | 
[epoch_0]_54921  loss=3.137416 |g|=0.503	lr=3.48e-05 | 99.1%@S45  T=1.11s eta=01:52:56 | 69.0K token/s | 
[epoch_0]_54931  loss=3.133024 |g|=0.499	lr=3.47e-05 | 100.0%@S45  T=1.12s eta=01:53:45 | 69.2K token/s | 
-------- End of shard_45@"./Datasets/edu_fineweb1B/edu_fineweb_train_000802.bin"-------- 
[shard-46]@"./Datasets/edu_fineweb1B/edu_fineweb_train_000803.bin": tokens=100(M) nShardSamples=1220(4492176) 
[epoch_0]_54941  loss=3.185756 |g|=0.523	lr=3.46e-05 | 0.8%@S46  T=1.10s eta=01:51:53 | 69.4K token/s | 
[epoch_0]_54951  loss=3.158188 |g|=0.492	lr=3.46e-05 | 1.6%@S46  T=1.13s eta=01:54:44 | 69.6K token/s | 
[epoch_0]_54961  loss=3.148195 |g|=0.511	lr=3.45e-05 | 2.4%@S46  T=1.10s eta=01:51:01 | 69.8K token/s | 
[epoch_0]_54971  loss=3.126198 |g|=0.497	lr=3.44e-05 | 3.2%@S46  T=1.09s eta=01:50:34 | 70.1K token/s | 
[epoch_0]_54981  loss=3.185094 |g|=0.506	lr=3.43e-05 | 4.1%@S46  T=1.13s eta=01:54:11 | 70.2K token/s | 
[epoch_0]_54991  loss=3.119903 |g|=0.505	lr=3.42e-05 | 4.9%@S46  T=1.14s eta=01:54:37 | 70.3K token/s | 
[Fuyou] head="3" update algorithm=4 t=2.06s
[eval] 
	 Loss@"edu_fineweb1B"=3.152(0.00049) nBranch=1 nToken=4.01M best=3.1528(273) E2T=-0.0424 T=13.4252(0)s x=0
	#3.15235±0.1084 tps=299K(4.01408M) a=[2.9781,3.44769] T=13.4252(sec)
[Section@55000] layer[24-30] tasks=15(nPassBack=0) last_loss=3.19477(-0.0874898) N=(580,46704,46284 5499900)
[epoch_0]_55001  loss=3.183082 |g|=0.526	lr=3.42e-05 | 5.7%@S46  T=4.22s eta=07:04:18 | 67.7K token/s | 
[epoch_0]_55011  loss=3.152168 |g|=0.5	lr=3.41e-05 | 6.5%@S46  T=1.11s eta=01:50:57 | 68.1K token/s | 
[epoch_0]_55021  loss=3.165968 |g|=0.509	lr=3.40e-05 | 7.3%@S46  T=1.15s eta=01:55:37 | 68.2K token/s | 
[epoch_0]_55031  loss=3.136765 |g|=0.528	lr=3.39e-05 | 8.2%@S46  T=1.10s eta=01:50:31 | 68.5K token/s | 
[epoch_0]_55041  loss=3.174618 |g|=0.527	lr=3.38e-05 | 9.0%@S46  T=1.10s eta=01:49:28 | 68.8K token/s | 
[epoch_0]_55051  loss=3.083752 |g|=0.503	lr=3.38e-05 | 9.8%@S46  T=1.12s eta=01:51:52 | 69.0K token/s | 
[epoch_0]_55061  loss=3.124932 |g|=0.496	lr=3.37e-05 | 10.6%@S46  T=1.12s eta=01:51:44 | 69.2K token/s | 
[epoch_0]_55071  loss=3.102087 |g|=0.51	lr=3.36e-05 | 11.4%@S46  T=1.09s eta=01:48:08 | 69.5K token/s | 
[epoch_0]_55081  loss=3.140843 |g|=0.491	lr=3.35e-05 | 12.2%@S46  T=1.12s eta=01:50:42 | 69.7K token/s | 
[epoch_0]_55091  loss=3.016376 |g|=0.502	lr=3.34e-05 | 13.1%@S46  T=1.14s eta=01:52:39 | 69.8K token/s | 
[Fuyou] head="4" update algorithm=4 t=2.08s
[Section@55100] layer[30-36] tasks=15(nPassBack=0) last_loss=3.05549(0.119863) N=(580,46788,46368 5509900)
[epoch_0]_55101  loss=3.176996 |g|=0.516	lr=3.34e-05 | 13.9%@S46  T=1.62s eta=02:40:21 | 68.9K token/s | 
[epoch_0]_55111  loss=3.122836 |g|=0.511	lr=3.33e-05 | 14.7%@S46  T=1.10s eta=01:48:07 | 69.2K token/s | 
[epoch_0]_55121  loss=3.192057 |g|=0.499	lr=3.32e-05 | 15.5%@S46  T=1.11s eta=01:49:39 | 69.4K token/s | 
[epoch_0]_55131  loss=3.099380 |g|=0.498	lr=3.31e-05 | 16.3%@S46  T=1.15s eta=01:53:16 | 69.5K token/s | 
[epoch_0]_55141  loss=3.140170 |g|=0.494	lr=3.31e-05 | 17.2%@S46  T=1.12s eta=01:50:06 | 69.7K token/s | 
[epoch_0]_55151  loss=3.092354 |g|=0.52	lr=3.30e-05 | 18.0%@S46  T=1.10s eta=01:47:25 | 69.9K token/s | 
[epoch_0]_55161  loss=3.046536 |g|=0.487	lr=3.29e-05 | 18.8%@S46  T=1.11s eta=01:49:05 | 70.1K token/s | 
[epoch_0]_55171  loss=3.166369 |g|=0.514	lr=3.28e-05 | 19.6%@S46  T=1.14s eta=01:51:11 | 70.2K token/s | 
[epoch_0]_55181  loss=3.100189 |g|=0.508	lr=3.27e-05 | 20.4%@S46  T=1.16s eta=01:52:49 | 70.2K token/s | 
[epoch_0]_55191  loss=3.141558 |g|=0.506	lr=3.27e-05 | 21.3%@S46  T=1.10s eta=01:47:27 | 70.4K token/s | 
[Fuyou] head="5" update algorithm=4 t=2.05s
[eval] 
	 Loss@"edu_fineweb1B"=3.151(0.0011) nBranch=1 nToken=4.01M best=3.1523(274) E2T=-0.00772 T=13.4244(0)s x=0
	#3.15127±0.1084 tps=299K(4.01408M) a=[2.97589,3.44666] T=13.4244(sec)
[Section@55200] layer[0-6] tasks=15(nPassBack=0) last_loss=3.159(-0.120414) N=(580,46872,46452 5519900)
[epoch_0]_55201  loss=3.024422 |g|=0.549	lr=3.26e-05 | 22.1%@S46  T=4.48s eta=07:15:39 | 67.8K token/s | 
[epoch_0]_55211  loss=3.210073 |g|=0.522	lr=3.25e-05 | 22.9%@S46  T=1.10s eta=01:46:35 | 68.2K token/s | 
[epoch_0]_55221  loss=3.148453 |g|=0.515	lr=3.24e-05 | 23.7%@S46  T=1.11s eta=01:48:00 | 68.4K token/s | 
[epoch_0]_55231  loss=3.119341 |g|=0.51	lr=3.24e-05 | 24.5%@S46  T=1.24s eta=01:59:39 | 68.3K token/s | 
[epoch_0]_55241  loss=3.044803 |g|=0.486	lr=3.23e-05 | 25.4%@S46  T=1.14s eta=01:50:12 | 68.5K token/s | 
[epoch_0]_55251  loss=3.163987 |g|=0.511	lr=3.22e-05 | 26.2%@S46  T=1.11s eta=01:46:42 | 68.8K token/s | 
[epoch_0]_55261  loss=3.036549 |g|=0.501	lr=3.21e-05 | 27.0%@S46  T=1.10s eta=01:46:19 | 69.0K token/s | 
[epoch_0]_55271  loss=3.132480 |g|=0.502	lr=3.21e-05 | 27.8%@S46  T=1.13s eta=01:48:43 | 69.2K token/s | 
[epoch_0]_55281  loss=3.107744 |g|=0.516	lr=3.20e-05 | 28.6%@S46  T=1.16s eta=01:51:38 | 69.3K token/s | 
[epoch_0]_55291  loss=3.103574 |g|=0.505	lr=3.19e-05 | 29.5%@S46  T=1.10s eta=01:45:39 | 69.5K token/s | 
[Fuyou] head="0" update algorithm=4 t=2.05s
[Section@55300] layer[6-12] tasks=15(nPassBack=0) last_loss=3.0186(0.167622) N=(580,46956,46536 5529900)
[epoch_0]_55301  loss=3.064391 |g|=0.52	lr=3.18e-05 | 30.3%@S46  T=1.46s eta=02:19:52 | 68.8K token/s | 
[epoch_0]_55311  loss=3.111270 |g|=0.5	lr=3.18e-05 | 31.1%@S46  T=1.11s eta=01:45:28 | 69.1K token/s | 
[epoch_0]_55321  loss=3.168052 |g|=0.526	lr=3.17e-05 | 31.9%@S46  T=1.32s eta=02:05:41 | 68.7K token/s | 
[epoch_0]_55331  loss=3.082693 |g|=0.513	lr=3.16e-05 | 32.7%@S46  T=1.12s eta=01:46:02 | 69.0K token/s | 
[epoch_0]_55341  loss=3.114479 |g|=0.478	lr=3.15e-05 | 33.5%@S46  T=1.10s eta=01:44:27 | 69.3K token/s | 
[epoch_0]_55351  loss=3.201725 |g|=0.53	lr=3.15e-05 | 34.4%@S46  T=1.13s eta=01:47:09 | 69.4K token/s | 
[epoch_0]_55361  loss=3.052372 |g|=0.524	lr=3.14e-05 | 35.2%@S46  T=1.14s eta=01:47:26 | 69.5K token/s | 
[epoch_0]_55371  loss=3.097266 |g|=0.482	lr=3.13e-05 | 36.0%@S46  T=1.11s eta=01:44:53 | 69.8K token/s | 
[epoch_0]_55381  loss=3.124891 |g|=0.502	lr=3.12e-05 | 36.8%@S46  T=1.13s eta=01:46:22 | 69.9K token/s | 
[epoch_0]_55391  loss=3.130385 |g|=0.494	lr=3.12e-05 | 37.6%@S46  T=1.13s eta=01:45:50 | 70.0K token/s | 
[Fuyou] head="1" update algorithm=4 t=2.10s
[eval] 
	 Loss@"edu_fineweb1B"=3.151(0.00043) nBranch=1 nToken=4.01M best=3.1513(275) E2T=0.0203 T=13.4253(0)s x=0
	#3.15085±0.1082 tps=299K(4.01408M) a=[2.97696,3.44588] T=13.4253(sec)
[Section@55400] layer[12-18] tasks=15(nPassBack=0) last_loss=3.13056(0.0060432) N=(580,47040,46620 5539900)
[epoch_0]_55401  loss=3.203403 |g|=0.54	lr=3.11e-05 | 38.5%@S46  T=4.36s eta=06:49:30 | 67.5K token/s | 
[epoch_0]_55411  loss=3.139922 |g|=0.504	lr=3.10e-05 | 39.3%@S46  T=1.12s eta=01:45:25 | 67.7K token/s | 
[epoch_0]_55421  loss=3.169267 |g|=0.498	lr=3.09e-05 | 40.1%@S46  T=1.13s eta=01:46:01 | 68.0K token/s | 
[epoch_0]_55431  loss=3.158027 |g|=0.518	lr=3.09e-05 | 40.9%@S46  T=1.19s eta=01:51:11 | 68.0K token/s | 
[epoch_0]_55441  loss=3.048452 |g|=0.493	lr=3.08e-05 | 41.7%@S46  T=1.09s eta=01:41:32 | 68.4K token/s | 
[epoch_0]_55451  loss=2.987126 |g|=0.498	lr=3.07e-05 | 42.6%@S46  T=1.09s eta=01:41:22 | 68.7K token/s | 
[epoch_0]_55461  loss=3.086241 |g|=0.501	lr=3.06e-05 | 43.4%@S46  T=1.15s eta=01:47:10 | 68.8K token/s | 
[epoch_0]_55471  loss=3.164383 |g|=0.519	lr=3.06e-05 | 44.2%@S46  T=1.16s eta=01:47:18 | 68.9K token/s | 
[epoch_0]_55481  loss=3.132616 |g|=0.515	lr=3.05e-05 | 45.0%@S46  T=1.09s eta=01:41:08 | 69.2K token/s | 
[epoch_0]_55491  loss=3.121647 |g|=0.499	lr=3.04e-05 | 45.8%@S46  T=1.16s eta=01:46:53 | 69.3K token/s | 
[Fuyou] head="2" update algorithm=4 t=2.08s
[Section@55500] layer[18-24] tasks=15(nPassBack=0) last_loss=3.08226(-0.0115819) N=(580,47124,46704 5549900)
[epoch_0]_55501  loss=3.090266 |g|=0.494	lr=3.03e-05 | 46.7%@S46  T=1.47s eta=02:15:35 | 68.6K token/s | 
[epoch_0]_55511  loss=3.143725 |g|=0.49	lr=3.03e-05 | 47.5%@S46  T=1.10s eta=01:41:00 | 68.9K token/s | 
[epoch_0]_55521  loss=3.103177 |g|=0.509	lr=3.02e-05 | 48.3%@S46  T=1.14s eta=01:44:55 | 69.1K token/s | 
[epoch_0]_55531  loss=3.054264 |g|=0.503	lr=3.01e-05 | 49.1%@S46  T=1.10s eta=01:41:07 | 69.3K token/s | 
[epoch_0]_55541  loss=3.111279 |g|=0.524	lr=3.01e-05 | 49.9%@S46  T=1.12s eta=01:42:38 | 69.5K token/s | 
[epoch_0]_55551  loss=3.074434 |g|=0.513	lr=3.00e-05 | 50.8%@S46  T=1.15s eta=01:44:46 | 69.6K token/s | 
[epoch_0]_55561  loss=3.122706 |g|=0.491	lr=2.99e-05 | 51.6%@S46  T=1.13s eta=01:42:49 | 69.8K token/s | 
[epoch_0]_55571  loss=3.075229 |g|=0.498	lr=2.98e-05 | 52.4%@S46  T=1.10s eta=01:40:03 | 70.0K token/s | 
[epoch_0]_55581  loss=3.197016 |g|=0.5	lr=2.98e-05 | 53.2%@S46  T=1.09s eta=01:39:00 | 70.3K token/s | 
[epoch_0]_55591  loss=3.124053 |g|=0.498	lr=2.97e-05 | 54.0%@S46  T=1.14s eta=01:43:19 | 70.4K token/s | 
[Fuyou] head="3" update algorithm=4 t=2.27s
[eval] 
	 Loss@"edu_fineweb1B"=3.150(0.0008) nBranch=1 nToken=4.01M best=3.1508(276) E2T=0.0628 T=13.5238(0)s x=0
	#3.15004±0.1084 tps=297K(4.01408M) a=[2.97444,3.44518] T=13.5238(sec)
[Section@55600] layer[24-30] tasks=15(nPassBack=0) last_loss=3.08726(0.107506) N=(580,47208,46788 5559900)
[epoch_0]_55601  loss=3.119794 |g|=0.528	lr=2.96e-05 | 54.8%@S46  T=4.29s eta=06:28:12 | 67.8K token/s | 
[epoch_0]_55611  loss=3.126168 |g|=0.502	lr=2.95e-05 | 55.7%@S46  T=1.17s eta=01:45:28 | 67.9K token/s | 
[epoch_0]_55621  loss=3.064635 |g|=0.501	lr=2.95e-05 | 56.5%@S46  T=1.14s eta=01:42:33 | 68.1K token/s | 
[epoch_0]_55631  loss=3.128807 |g|=0.515	lr=2.94e-05 | 57.3%@S46  T=1.65s eta=02:28:34 | 67.2K token/s | 
[epoch_0]_55641  loss=3.190714 |g|=0.508	lr=2.93e-05 | 58.1%@S46  T=1.16s eta=01:44:33 | 67.4K token/s | 
[epoch_0]_55651  loss=3.006505 |g|=0.497	lr=2.93e-05 | 58.9%@S46  T=1.10s eta=01:38:29 | 67.7K token/s | 
[epoch_0]_55661  loss=3.161170 |g|=0.503	lr=2.92e-05 | 59.8%@S46  T=1.11s eta=01:39:12 | 68.0K token/s | 
[epoch_0]_55671  loss=3.133414 |g|=0.529	lr=2.91e-05 | 60.6%@S46  T=1.11s eta=01:39:09 | 68.3K token/s | 
[epoch_0]_55681  loss=3.080743 |g|=0.501	lr=2.90e-05 | 61.4%@S46  T=1.13s eta=01:40:52 | 68.5K token/s | 
[epoch_0]_55691  loss=3.113675 |g|=0.49	lr=2.90e-05 | 62.2%@S46  T=1.14s eta=01:41:41 | 68.7K token/s | 
[Fuyou] head="4" update algorithm=4 t=3.56s
[Section@55700] layer[30-36] tasks=15(nPassBack=0) last_loss=3.15132(-0.0958235) N=(580,47292,46872 5569900)
[epoch_0]_55701  loss=3.152885 |g|=0.493	lr=2.89e-05 | 63.0%@S46  T=1.70s eta=02:30:56 | 67.7K token/s | 
[epoch_0]_55711  loss=3.096028 |g|=0.484	lr=2.88e-05 | 63.9%@S46  T=1.13s eta=01:40:00 | 67.9K token/s | 
[epoch_0]_55721  loss=3.200528 |g|=0.52	lr=2.88e-05 | 64.7%@S46  T=1.11s eta=01:38:38 | 68.2K token/s | 
[epoch_0]_55731  loss=3.194102 |g|=0.514	lr=2.87e-05 | 65.5%@S46  T=1.55s eta=02:16:52 | 67.4K token/s | 
[epoch_0]_55741  loss=3.079843 |g|=0.51	lr=2.86e-05 | 66.3%@S46  T=1.12s eta=01:38:34 | 67.7K token/s | 
[epoch_0]_55751  loss=3.101501 |g|=0.494	lr=2.86e-05 | 67.1%@S46  T=1.15s eta=01:41:21 | 67.9K token/s | 
[epoch_0]_55761  loss=3.199448 |g|=0.508	lr=2.85e-05 | 68.0%@S46  T=1.10s eta=01:37:07 | 68.2K token/s | 
[epoch_0]_55771  loss=3.155398 |g|=0.508	lr=2.84e-05 | 68.8%@S46  T=1.12s eta=01:37:58 | 68.5K token/s | 
[epoch_0]_55781  loss=3.182469 |g|=0.501	lr=2.83e-05 | 69.6%@S46  T=1.11s eta=01:37:12 | 68.7K token/s | 
[epoch_0]_55791  loss=3.059513 |g|=0.494	lr=2.83e-05 | 70.4%@S46  T=1.13s eta=01:38:36 | 68.9K token/s | 
[Fuyou] head="5" update algorithm=4 t=3.74s
[eval] 
	 Loss@"edu_fineweb1B"=3.149(0.00074) nBranch=1 nToken=4.01M best=3.1500(277) E2T=0.0691 T=13.4165(0)s x=0
	#3.1493±0.1084 tps=299K(4.01408M) a=[2.97536,3.44514] T=13.4165(sec)
[Section@55800] layer[0-6] tasks=15(nPassBack=0) last_loss=3.08025(0.0787475) N=(580,47376,46956 5579900)
[epoch_0]_55801  loss=3.112571 |g|=0.544	lr=2.82e-05 | 71.2%@S46  T=4.41s eta=06:24:21 | 66.4K token/s | 
[epoch_0]_55811  loss=3.124374 |g|=0.509	lr=2.81e-05 | 72.0%@S46  T=1.12s eta=01:37:18 | 66.8K token/s | 
[epoch_0]_55821  loss=3.190170 |g|=0.504	lr=2.81e-05 | 72.9%@S46  T=1.30s eta=01:53:17 | 66.6K token/s | 
[epoch_0]_55831  loss=3.029991 |g|=0.486	lr=2.80e-05 | 73.7%@S46  T=1.12s eta=01:37:11 | 66.9K token/s | 
[epoch_0]_55841  loss=3.027715 |g|=0.507	lr=2.79e-05 | 74.5%@S46  T=1.11s eta=01:35:58 | 67.2K token/s | 
[epoch_0]_55851  loss=3.107825 |g|=0.508	lr=2.79e-05 | 75.3%@S46  T=1.58s eta=02:16:31 | 66.5K token/s | 
[epoch_0]_55861  loss=3.065719 |g|=0.516	lr=2.78e-05 | 76.1%@S46  T=1.11s eta=01:35:50 | 66.8K token/s | 
[epoch_0]_55871  loss=3.110999 |g|=0.485	lr=2.77e-05 | 77.0%@S46  T=1.15s eta=01:38:59 | 67.1K token/s | 
[epoch_0]_55881  loss=3.195680 |g|=0.515	lr=2.77e-05 | 77.8%@S46  T=1.12s eta=01:36:01 | 67.4K token/s | 
[epoch_0]_55891  loss=3.114685 |g|=0.487	lr=2.76e-05 | 78.6%@S46  T=1.11s eta=01:35:04 | 67.7K token/s | 
[Fuyou] head="0" update algorithm=4 t=2.07s
[Section@55900] layer[6-12] tasks=15(nPassBack=0) last_loss=3.14343(-0.12483) N=(580,47460,47040 5589900)
[epoch_0]_55901  loss=3.144770 |g|=0.505	lr=2.75e-05 | 79.4%@S46  T=1.60s eta=02:16:34 | 66.9K token/s | 
[epoch_0]_55911  loss=3.143430 |g|=0.538	lr=2.75e-05 | 80.2%@S46  T=1.11s eta=01:34:45 | 67.2K token/s | 
[epoch_0]_55921  loss=3.011544 |g|=0.492	lr=2.74e-05 | 81.1%@S46  T=1.25s eta=01:46:39 | 67.1K token/s | 
[epoch_0]_55931  loss=3.197767 |g|=0.505	lr=2.73e-05 | 81.9%@S46  T=1.13s eta=01:35:50 | 67.4K token/s | 
[epoch_0]_55941  loss=3.148085 |g|=0.501	lr=2.73e-05 | 82.7%@S46  T=1.15s eta=01:37:14 | 67.6K token/s | 
[epoch_0]_55951  loss=3.139140 |g|=0.5	lr=2.72e-05 | 83.5%@S46  T=1.46s eta=02:03:43 | 67.0K token/s | 
[epoch_0]_55961  loss=3.123364 |g|=0.528	lr=2.71e-05 | 84.3%@S46  T=1.11s eta=01:34:08 | 67.4K token/s | 
[epoch_0]_55971  loss=3.103324 |g|=0.515	lr=2.71e-05 | 85.2%@S46  T=1.11s eta=01:33:43 | 67.7K token/s | 
[epoch_0]_55981  loss=2.989096 |g|=0.52	lr=2.70e-05 | 86.0%@S46  T=1.14s eta=01:35:37 | 67.9K token/s | 
[epoch_0]_55991  loss=3.122733 |g|=0.512	lr=2.69e-05 | 86.8%@S46  T=1.17s eta=01:37:56 | 68.0K token/s | 
[Fuyou] head="1" update algorithm=4 t=2.09s
[eval] 
	 Loss@"edu_fineweb1B"=3.148(0.00088) nBranch=1 nToken=4.01M best=3.1493(278) E2T=-0.0504 T=13.4382(0)s x=0
	#3.14843±0.1084 tps=299K(4.01408M) a=[2.97441,3.44364] T=13.4382(sec)
[Section@56000] layer[12-18] tasks=15(nPassBack=0) last_loss=3.19885(-0.0682957) N=(580,47544,47124 5599900)
[epoch_0]_56001  loss=3.091101 |g|=0.524	lr=2.69e-05 | 87.6%@S46  T=4.24s eta=05:55:42 | 65.6K token/s | 
[epoch_0]_56011  loss=3.085596 |g|=0.504	lr=2.68e-05 | 88.4%@S46  T=1.16s eta=01:37:09 | 65.8K token/s | 
[epoch_0]_56021  loss=3.165429 |g|=0.531	lr=2.67e-05 | 89.3%@S46  T=1.12s eta=01:33:47 | 66.2K token/s | 
[epoch_0]_56031  loss=3.143775 |g|=0.523	lr=2.67e-05 | 90.1%@S46  T=1.16s eta=01:36:41 | 66.4K token/s | 
[epoch_0]_56041  loss=3.146378 |g|=0.499	lr=2.66e-05 | 90.9%@S46  T=1.67s eta=02:19:18 | 65.6K token/s | 
[epoch_0]_56051  loss=3.066423 |g|=0.513	lr=2.65e-05 | 91.7%@S46  T=1.13s eta=01:33:51 | 65.9K token/s | 
[epoch_0]_56061  loss=3.127342 |g|=0.504	lr=2.65e-05 | 92.5%@S46  T=1.11s eta=01:32:25 | 66.3K token/s | 
[epoch_0]_56071  loss=3.163830 |g|=0.503	lr=2.64e-05 | 93.3%@S46  T=1.12s eta=01:32:54 | 66.6K token/s | 
[epoch_0]_56081  loss=3.140710 |g|=0.506	lr=2.63e-05 | 94.2%@S46  T=1.11s eta=01:31:39 | 67.0K token/s | 
[epoch_0]_56091  loss=3.013483 |g|=0.491	lr=2.63e-05 | 95.0%@S46  T=1.13s eta=01:33:26 | 67.2K token/s | 
[Fuyou] head="2" update algorithm=4 t=2.02s
[Section@56100] layer[18-24] tasks=15(nPassBack=0) last_loss=3.07073(0.0115371) N=(580,47628,47208 5609900)
[epoch_0]_56101  loss=3.088518 |g|=0.505	lr=2.62e-05 | 95.8%@S46  T=1.37s eta=01:52:53 | 66.9K token/s | 
[epoch_0]_56111  loss=3.129273 |g|=0.488	lr=2.61e-05 | 96.6%@S46  T=1.15s eta=01:34:15 | 67.1K token/s | 
[epoch_0]_56121  loss=3.153774 |g|=0.517	lr=2.61e-05 | 97.4%@S46  T=1.11s eta=01:30:42 | 67.4K token/s | 
[epoch_0]_56131  loss=3.085658 |g|=0.489	lr=2.60e-05 | 98.3%@S46  T=1.12s eta=01:31:12 | 67.7K token/s | 
[epoch_0]_56141  loss=3.128081 |g|=0.497	lr=2.59e-05 | 99.1%@S46  T=1.58s eta=02:09:08 | 66.9K token/s | 
[epoch_0]_56151  loss=3.154161 |g|=0.496	lr=2.59e-05 | 99.9%@S46  T=1.16s eta=01:34:08 | 67.1K token/s | 
[epoch_0]_56152  loss=3.087866 |g|=0.496	lr=2.59e-05 | 100.0%@S46  T=1.12s eta=01:31:06 | 67.4K token/s | 
-------- End of shard_46@"./Datasets/edu_fineweb1B/edu_fineweb_train_000803.bin"-------- 
[shard-47]@"./Datasets/edu_fineweb1B/edu_fineweb_train_000804.bin": tokens=100(M) nShardSamples=1220(4589832) 
[epoch_0]_56161  loss=3.070475 |g|=0.518	lr=2.58e-05 | 0.7%@S47  T=1.07s eta=01:27:04 | 67.9K token/s | 
[epoch_0]_56171  loss=3.223813 |g|=0.506	lr=2.57e-05 | 1.5%@S47  T=1.09s eta=01:28:37 | 68.2K token/s | 
[epoch_0]_56181  loss=3.057631 |g|=0.516	lr=2.57e-05 | 2.4%@S47  T=1.10s eta=01:28:53 | 68.5K token/s | 
[epoch_0]_56191  loss=3.123385 |g|=0.516	lr=2.56e-05 | 3.2%@S47  T=1.14s eta=01:32:22 | 68.7K token/s | 
[Fuyou] head="3" update algorithm=4 t=2.07s
[eval] 
	 Loss@"edu_fineweb1B"=3.147(0.0012) nBranch=1 nToken=4.01M best=3.1484(279) E2T=0.058 T=13.5002(0)s x=0
	#3.14727±0.1083 tps=297K(4.01408M) a=[2.97284,3.44142] T=13.5002(sec)
[Section@56200] layer[24-30] tasks=15(nPassBack=0) last_loss=3.0893(-0.00203657) N=(580,47712,47292 5619900)
[epoch_0]_56201  loss=3.101768 |g|=0.495	lr=2.55e-05 | 4.0%@S47  T=4.41s eta=05:55:12 | 66.2K token/s | 
[epoch_0]_56211  loss=3.212528 |g|=0.505	lr=2.55e-05 | 4.8%@S47  T=1.08s eta=01:26:56 | 66.7K token/s | 
[epoch_0]_56221  loss=3.123879 |g|=0.508	lr=2.54e-05 | 5.6%@S47  T=1.09s eta=01:27:26 | 67.1K token/s | 
[epoch_0]_56231  loss=3.114569 |g|=0.499	lr=2.54e-05 | 6.5%@S47  T=1.43s eta=01:54:18 | 66.6K token/s | 
[epoch_0]_56241  loss=3.108615 |g|=0.504	lr=2.53e-05 | 7.3%@S47  T=1.10s eta=01:27:49 | 67.0K token/s | 
[epoch_0]_56251  loss=3.182300 |g|=0.514	lr=2.52e-05 | 8.1%@S47  T=1.11s eta=01:28:37 | 67.3K token/s | 
[epoch_0]_56261  loss=3.124353 |g|=0.506	lr=2.52e-05 | 8.9%@S47  T=1.09s eta=01:26:31 | 67.7K token/s | 
[epoch_0]_56271  loss=3.107394 |g|=0.504	lr=2.51e-05 | 9.7%@S47  T=1.16s eta=01:32:27 | 67.9K token/s | 
[epoch_0]_56281  loss=3.118587 |g|=0.484	lr=2.50e-05 | 10.6%@S47  T=1.14s eta=01:30:39 | 68.1K token/s | 
[epoch_0]_56291  loss=3.074948 |g|=0.487	lr=2.50e-05 | 11.4%@S47  T=1.11s eta=01:27:58 | 68.3K token/s | 
[Fuyou] head="4" update algorithm=4 t=3.19s
[Section@56300] layer[30-36] tasks=15(nPassBack=0) last_loss=3.13941(0.0119035) N=(580,47796,47376 5629900)
[epoch_0]_56301  loss=3.159182 |g|=0.519	lr=2.49e-05 | 12.2%@S47  T=1.65s eta=02:09:48 | 67.4K token/s | 
[epoch_0]_56311  loss=3.133623 |g|=0.546	lr=2.49e-05 | 13.0%@S47  T=1.16s eta=01:31:22 | 67.6K token/s | 
[epoch_0]_56321  loss=3.115315 |g|=0.513	lr=2.48e-05 | 13.8%@S47  T=1.12s eta=01:27:41 | 67.9K token/s | 
[epoch_0]_56331  loss=3.133385 |g|=0.522	lr=2.47e-05 | 14.6%@S47  T=1.41s eta=01:50:50 | 67.4K token/s | 
[epoch_0]_56341  loss=3.146577 |g|=0.504	lr=2.47e-05 | 15.5%@S47  T=1.10s eta=01:25:55 | 67.7K token/s | 
[epoch_0]_56351  loss=3.148761 |g|=0.508	lr=2.46e-05 | 16.3%@S47  T=1.09s eta=01:25:18 | 68.1K token/s | 
[epoch_0]_56361  loss=3.166222 |g|=0.493	lr=2.45e-05 | 17.1%@S47  T=1.17s eta=01:30:56 | 68.2K token/s | 
[epoch_0]_56371  loss=3.119875 |g|=0.494	lr=2.45e-05 | 17.9%@S47  T=1.14s eta=01:28:16 | 68.4K token/s | 
[epoch_0]_56381  loss=3.148010 |g|=0.503	lr=2.44e-05 | 18.7%@S47  T=1.16s eta=01:29:58 | 68.5K token/s | 
[epoch_0]_56391  loss=3.047905 |g|=0.506	lr=2.44e-05 | 19.6%@S47  T=1.08s eta=01:23:57 | 68.8K token/s | 
[Fuyou] head="5" update algorithm=4 t=3.42s
[eval] 
	 Loss@"edu_fineweb1B"=3.146(0.0016) nBranch=1 nToken=4.01M best=3.1473(280) E2T=-0.00616 T=13.524(0)s x=0
	#3.14564±0.1083 tps=297K(4.01408M) a=[2.9712,3.44014] T=13.524(sec)
[Section@56400] layer[0-6] tasks=15(nPassBack=0) last_loss=3.1518(-0.0715523) N=(580,47880,47460 5639900)
[epoch_0]_56401  loss=3.163369 |g|=0.543	lr=2.43e-05 | 20.4%@S47  T=4.35s eta=05:35:56 | 66.3K token/s | 
[epoch_0]_56411  loss=3.168734 |g|=0.502	lr=2.42e-05 | 21.2%@S47  T=1.15s eta=01:28:38 | 66.6K token/s | 
[epoch_0]_56421  loss=3.222589 |g|=0.515	lr=2.42e-05 | 22.0%@S47  T=1.52s eta=01:56:51 | 66.0K token/s | 
[epoch_0]_56431  loss=3.134312 |g|=0.512	lr=2.41e-05 | 22.8%@S47  T=1.12s eta=01:26:05 | 66.3K token/s | 
[epoch_0]_56441  loss=3.161740 |g|=0.495	lr=2.40e-05 | 23.7%@S47  T=1.17s eta=01:29:25 | 66.5K token/s | 
[epoch_0]_56451  loss=3.106203 |g|=0.517	lr=2.40e-05 | 24.5%@S47  T=1.16s eta=01:28:50 | 66.7K token/s | 
[epoch_0]_56461  loss=3.188119 |g|=0.503	lr=2.39e-05 | 25.3%@S47  T=1.13s eta=01:26:28 | 67.0K token/s | 
[epoch_0]_56471  loss=3.144353 |g|=0.508	lr=2.39e-05 | 26.1%@S47  T=1.12s eta=01:25:18 | 67.3K token/s | 
[epoch_0]_56481  loss=3.128649 |g|=0.517	lr=2.38e-05 | 26.9%@S47  T=1.13s eta=01:25:30 | 67.6K token/s | 
[epoch_0]_56491  loss=3.126522 |g|=0.487	lr=2.37e-05 | 27.8%@S47  T=1.13s eta=01:25:16 | 67.8K token/s | 
[Fuyou] head="0" update algorithm=4 t=2.15s
[Section@56500] layer[6-12] tasks=15(nPassBack=0) last_loss=3.14137(0.00205469) N=(580,47964,47544 5649900)
[epoch_0]_56501  loss=3.152843 |g|=0.522	lr=2.37e-05 | 28.6%@S47  T=1.41s eta=01:46:50 | 67.3K token/s | 
[epoch_0]_56511  loss=3.231709 |g|=0.509	lr=2.36e-05 | 29.4%@S47  T=1.12s eta=01:24:29 | 67.6K token/s | 
[epoch_0]_56521  loss=3.158809 |g|=0.505	lr=2.36e-05 | 30.2%@S47  T=1.15s eta=01:26:47 | 67.8K token/s | 
[epoch_0]_56531  loss=3.164385 |g|=0.498	lr=2.35e-05 | 31.0%@S47  T=1.12s eta=01:23:46 | 68.1K token/s | 
[epoch_0]_56541  loss=3.076021 |g|=0.493	lr=2.34e-05 | 31.9%@S47  T=1.13s eta=01:24:27 | 68.3K token/s | 
[epoch_0]_56551  loss=3.194355 |g|=0.518	lr=2.34e-05 | 32.7%@S47  T=1.15s eta=01:26:18 | 68.4K token/s | 
[epoch_0]_56561  loss=3.123631 |g|=0.507	lr=2.33e-05 | 33.5%@S47  T=1.13s eta=01:24:37 | 68.6K token/s | 
[epoch_0]_56571  loss=3.131539 |g|=0.501	lr=2.33e-05 | 34.3%@S47  T=1.17s eta=01:27:21 | 68.7K token/s | 
[epoch_0]_56581  loss=3.141531 |g|=0.488	lr=2.32e-05 | 35.1%@S47  T=1.20s eta=01:29:09 | 68.6K token/s | 
[epoch_0]_56591  loss=3.133482 |g|=0.507	lr=2.31e-05 | 35.9%@S47  T=1.16s eta=01:25:47 | 68.7K token/s | 
[Fuyou] head="1" update algorithm=4 t=2.43s
[eval] 
	 Loss@"edu_fineweb1B"=3.145(0.00068) nBranch=1 nToken=4.01M best=3.1456(281) E2T=0.0355 T=13.4978(0)s x=0
	#3.14495±0.1082 tps=297K(4.01408M) a=[2.9708,3.43793] T=13.4978(sec)
[Section@56600] layer[12-18] tasks=15(nPassBack=0) last_loss=3.10942(0.0894294) N=(580,48048,47628 5659900)
[epoch_0]_56601  loss=3.042567 |g|=0.521	lr=2.31e-05 | 36.8%@S47  T=4.36s eta=05:22:13 | 66.3K token/s | 
[epoch_0]_56611  loss=3.177464 |g|=0.524	lr=2.30e-05 | 37.6%@S47  T=1.12s eta=01:22:46 | 66.6K token/s | 
[epoch_0]_56621  loss=3.172463 |g|=0.536	lr=2.30e-05 | 38.4%@S47  T=1.13s eta=01:22:57 | 66.9K token/s | 
[epoch_0]_56631  loss=3.117074 |g|=0.5	lr=2.29e-05 | 39.2%@S47  T=1.36s eta=01:39:34 | 66.6K token/s | 
[epoch_0]_56641  loss=3.087976 |g|=0.521	lr=2.29e-05 | 40.0%@S47  T=1.13s eta=01:22:51 | 66.9K token/s | 
[epoch_0]_56651  loss=3.099422 |g|=0.527	lr=2.28e-05 | 40.9%@S47  T=1.13s eta=01:22:42 | 67.1K token/s | 
[epoch_0]_56661  loss=3.170542 |g|=0.518	lr=2.27e-05 | 41.7%@S47  T=1.62s eta=01:58:25 | 66.3K token/s | 
[epoch_0]_56671  loss=3.085288 |g|=0.514	lr=2.27e-05 | 42.5%@S47  T=1.18s eta=01:25:59 | 66.4K token/s | 
[epoch_0]_56681  loss=3.083079 |g|=0.529	lr=2.26e-05 | 43.3%@S47  T=1.16s eta=01:23:53 | 66.7K token/s | 
[epoch_0]_56691  loss=3.204499 |g|=0.506	lr=2.26e-05 | 44.1%@S47  T=1.13s eta=01:21:37 | 67.0K token/s | 
[Fuyou] head="2" update algorithm=4 t=2.16s
[Section@56700] layer[18-24] tasks=15(nPassBack=0) last_loss=3.09829(-0.0275624) N=(580,48132,47712 5669900)
[epoch_0]_56701  loss=3.136546 |g|=0.502	lr=2.25e-05 | 45.0%@S47  T=1.48s eta=01:46:38 | 66.4K token/s | 
[epoch_0]_56711  loss=3.158992 |g|=0.526	lr=2.25e-05 | 45.8%@S47  T=1.18s eta=01:24:53 | 66.6K token/s | 
[epoch_0]_56721  loss=3.133482 |g|=0.5	lr=2.24e-05 | 46.6%@S47  T=1.46s eta=01:44:47 | 66.0K token/s | 
[epoch_0]_56731  loss=3.196446 |g|=0.491	lr=2.23e-05 | 47.4%@S47  T=1.13s eta=01:21:04 | 66.4K token/s | 
[epoch_0]_56741  loss=3.146211 |g|=0.508	lr=2.23e-05 | 48.2%@S47  T=1.16s eta=01:22:51 | 66.6K token/s | 
[epoch_0]_56751  loss=3.237665 |g|=0.526	lr=2.22e-05 | 49.1%@S47  T=1.19s eta=01:25:03 | 66.7K token/s | 
[epoch_0]_56761  loss=3.145454 |g|=0.491	lr=2.22e-05 | 49.9%@S47  T=1.15s eta=01:22:03 | 66.9K token/s | 
[epoch_0]_56771  loss=3.123703 |g|=0.497	lr=2.21e-05 | 50.7%@S47  T=1.21s eta=01:25:55 | 66.9K token/s | 
[epoch_0]_56781  loss=3.058937 |g|=0.51	lr=2.21e-05 | 51.5%@S47  T=1.17s eta=01:22:39 | 67.1K token/s | 
[epoch_0]_56791  loss=3.175157 |g|=0.505	lr=2.20e-05 | 52.3%@S47  T=1.12s eta=01:19:30 | 67.4K token/s | 
[Fuyou] head="3" update algorithm=4 t=2.11s
[eval] 
	 Loss@"edu_fineweb1B"=3.144(0.00069) nBranch=1 nToken=4.01M best=3.1450(282) E2T=0.0354 T=13.4347(0)s x=0
	#3.14426±0.1081 tps=299K(4.01408M) a=[2.97037,3.43695] T=13.4347(sec)
[Section@56800] layer[24-30] tasks=15(nPassBack=0) last_loss=3.10882(-0.0195184) N=(580,48216,47796 5679900)
[epoch_0]_56801  loss=3.130785 |g|=0.521	lr=2.19e-05 | 53.2%@S47  T=4.77s eta=05:36:18 | 64.9K token/s | 
[epoch_0]_56811  loss=3.104832 |g|=0.501	lr=2.19e-05 | 54.0%@S47  T=1.13s eta=01:19:34 | 65.3K token/s | 
[epoch_0]_56821  loss=3.145972 |g|=0.512	lr=2.18e-05 | 54.8%@S47  T=1.16s eta=01:21:42 | 65.5K token/s | 
[epoch_0]_56831  loss=3.071654 |g|=0.496	lr=2.18e-05 | 55.6%@S47  T=1.62s eta=01:53:45 | 64.8K token/s | 
[epoch_0]_56841  loss=3.161528 |g|=0.504	lr=2.17e-05 | 56.4%@S47  T=1.16s eta=01:20:58 | 65.1K token/s | 
[epoch_0]_56851  loss=3.160854 |g|=0.521	lr=2.17e-05 | 57.2%@S47  T=1.15s eta=01:20:00 | 65.4K token/s | 
[epoch_0]_56861  loss=3.121811 |g|=0.535	lr=2.16e-05 | 58.1%@S47  T=1.29s eta=01:29:33 | 65.3K token/s | 
[epoch_0]_56871  loss=3.183531 |g|=0.505	lr=2.16e-05 | 58.9%@S47  T=1.14s eta=01:19:26 | 65.6K token/s | 
[epoch_0]_56881  loss=3.070650 |g|=0.505	lr=2.15e-05 | 59.7%@S47  T=1.17s eta=01:21:17 | 65.8K token/s | 
[epoch_0]_56891  loss=3.134932 |g|=0.499	lr=2.14e-05 | 60.5%@S47  T=1.16s eta=01:19:52 | 66.1K token/s | 
[Fuyou] head="4" update algorithm=4 t=2.12s
[Section@56900] layer[30-36] tasks=15(nPassBack=0) last_loss=3.12268(0.0167303) N=(580,48300,47880 5689900)
[epoch_0]_56901  loss=3.218164 |g|=0.528	lr=2.14e-05 | 61.3%@S47  T=1.46s eta=01:40:23 | 65.6K token/s | 
[epoch_0]_56911  loss=3.224944 |g|=0.508	lr=2.13e-05 | 62.2%@S47  T=1.14s eta=01:18:08 | 65.9K token/s | 
[epoch_0]_56921  loss=3.125987 |g|=0.503	lr=2.13e-05 | 63.0%@S47  T=1.44s eta=01:39:03 | 65.4K token/s | 
[epoch_0]_56931  loss=3.155509 |g|=0.485	lr=2.12e-05 | 63.8%@S47  T=1.16s eta=01:19:18 | 65.7K token/s | 
[epoch_0]_56941  loss=3.120144 |g|=0.489	lr=2.12e-05 | 64.6%@S47  T=1.18s eta=01:20:20 | 65.9K token/s | 
[epoch_0]_56951  loss=3.148642 |g|=0.532	lr=2.11e-05 | 65.4%@S47  T=1.60s eta=01:49:07 | 65.2K token/s | 
[epoch_0]_56961  loss=3.052608 |g|=0.49	lr=2.11e-05 | 66.3%@S47  T=1.10s eta=01:14:40 | 65.6K token/s | 
[epoch_0]_56971  loss=3.143756 |g|=0.489	lr=2.10e-05 | 67.1%@S47  T=1.12s eta=01:15:40 | 66.0K token/s | 
[epoch_0]_56981  loss=3.073983 |g|=0.532	lr=2.10e-05 | 67.9%@S47  T=1.15s eta=01:17:54 | 66.3K token/s | 
[epoch_0]_56991  loss=3.073750 |g|=0.52	lr=2.09e-05 | 68.7%@S47  T=1.15s eta=01:17:13 | 66.5K token/s | 
[Fuyou] head="5" update algorithm=4 t=2.08s
[eval] 
	 Loss@"edu_fineweb1B"=3.144(0.00052) nBranch=1 nToken=4.01M best=3.1443(283) E2T=0.0525 T=13.4373(0)s x=0
	#3.14375±0.1083 tps=299K(4.01408M) a=[2.96838,3.43748] T=13.4373(sec)
[Section@57000] layer[0-6] tasks=15(nPassBack=0) last_loss=3.09123(0.0605695) N=(580,48384,47964 5699900)
[epoch_0]_57001  loss=3.117614 |g|=0.533	lr=2.08e-05 | 69.5%@S47  T=4.65s eta=05:12:19 | 64.1K token/s | 
[epoch_0]_57011  loss=3.136672 |g|=0.509	lr=2.08e-05 | 70.4%@S47  T=1.12s eta=01:15:10 | 64.5K token/s | 
[epoch_0]_57021  loss=3.121281 |g|=0.492	lr=2.07e-05 | 71.2%@S47  T=1.13s eta=01:15:37 | 64.9K token/s | 
[epoch_0]_57031  loss=3.025778 |g|=0.498	lr=2.07e-05 | 72.0%@S47  T=1.60s eta=01:46:54 | 64.2K token/s | 
[epoch_0]_57041  loss=3.094967 |g|=0.504	lr=2.06e-05 | 72.8%@S47  T=1.10s eta=01:13:22 | 64.7K token/s | 
[epoch_0]_57051  loss=3.150146 |g|=0.509	lr=2.06e-05 | 73.6%@S47  T=1.11s eta=01:13:55 | 65.2K token/s | 
[epoch_0]_57061  loss=3.129054 |g|=0.501	lr=2.05e-05 | 74.5%@S47  T=1.13s eta=01:14:38 | 65.6K token/s | 
[epoch_0]_57071  loss=3.102644 |g|=0.491	lr=2.05e-05 | 75.3%@S47  T=1.15s eta=01:16:04 | 65.8K token/s | 
[epoch_0]_57081  loss=3.082709 |g|=0.52	lr=2.04e-05 | 76.1%@S47  T=1.17s eta=01:17:15 | 66.0K token/s | 
[epoch_0]_57091  loss=3.109467 |g|=0.541	lr=2.04e-05 | 76.9%@S47  T=1.11s eta=01:12:56 | 66.4K token/s | 
[Fuyou] head="0" update algorithm=4 t=2.16s
[Section@57100] layer[6-12] tasks=15(nPassBack=0) last_loss=3.12119(0.0201826) N=(580,48468,48048 5709900)
[epoch_0]_57101  loss=3.121344 |g|=0.508	lr=2.03e-05 | 77.7%@S47  T=1.44s eta=01:34:28 | 65.9K token/s | 
[epoch_0]_57111  loss=3.054125 |g|=0.51	lr=2.03e-05 | 78.5%@S47  T=1.15s eta=01:15:10 | 66.2K token/s | 
[epoch_0]_57121  loss=3.032812 |g|=0.487	lr=2.02e-05 | 79.4%@S47  T=1.11s eta=01:12:07 | 66.6K token/s | 
[epoch_0]_57131  loss=3.141870 |g|=0.491	lr=2.02e-05 | 80.2%@S47  T=1.11s eta=01:12:07 | 67.0K token/s | 
[epoch_0]_57141  loss=3.086114 |g|=0.52	lr=2.01e-05 | 81.0%@S47  T=1.11s eta=01:11:47 | 67.3K token/s | 
[epoch_0]_57151  loss=3.158018 |g|=0.519	lr=2.01e-05 | 81.8%@S47  T=1.12s eta=01:12:15 | 67.6K token/s | 
[epoch_0]_57161  loss=3.077840 |g|=0.497	lr=2.00e-05 | 82.6%@S47  T=1.13s eta=01:12:57 | 67.9K token/s | 
[epoch_0]_57171  loss=3.085934 |g|=0.493	lr=2.00e-05 | 83.5%@S47  T=1.17s eta=01:15:22 | 68.0K token/s | 
[epoch_0]_57181  loss=3.157242 |g|=0.504	lr=1.99e-05 | 84.3%@S47  T=1.10s eta=01:10:51 | 68.3K token/s | 
[epoch_0]_57191  loss=3.132484 |g|=0.503	lr=1.98e-05 | 85.1%@S47  T=1.13s eta=01:12:40 | 68.5K token/s | 
[Fuyou] head="1" update algorithm=4 t=2.25s
[eval] 
	 Loss@"edu_fineweb1B"=3.143(0.00086) nBranch=1 nToken=4.01M best=3.1437(284) E2T=0.089 T=13.424(0)s x=0
	#3.14289±0.1083 tps=299K(4.01408M) a=[2.9676,3.43701] T=13.424(sec)
[Section@57200] layer[12-18] tasks=15(nPassBack=0) last_loss=3.05392(0.055506) N=(580,48552,48132 5719900)
[epoch_0]_57201  loss=3.119409 |g|=0.55	lr=1.98e-05 | 85.9%@S47  T=4.25s eta=04:31:37 | 66.0K token/s | 
[epoch_0]_57211  loss=3.143126 |g|=0.524	lr=1.97e-05 | 86.7%@S47  T=1.17s eta=01:14:21 | 66.2K token/s | 
[epoch_0]_57221  loss=3.084009 |g|=0.507	lr=1.97e-05 | 87.6%@S47  T=1.09s eta=01:09:32 | 66.7K token/s | 
[epoch_0]_57231  loss=3.030993 |g|=0.514	lr=1.96e-05 | 88.4%@S47  T=1.15s eta=01:12:44 | 66.9K token/s | 
[epoch_0]_57241  loss=3.147416 |g|=0.492	lr=1.96e-05 | 89.2%@S47  T=1.18s eta=01:14:31 | 67.0K token/s | 
[epoch_0]_57251  loss=3.091450 |g|=0.487	lr=1.95e-05 | 90.0%@S47  T=1.15s eta=01:12:28 | 67.2K token/s | 
[epoch_0]_57261  loss=3.163542 |g|=0.521	lr=1.95e-05 | 90.8%@S47  T=1.12s eta=01:10:17 | 67.6K token/s | 
[epoch_0]_57271  loss=3.066147 |g|=0.503	lr=1.94e-05 | 91.7%@S47  T=1.12s eta=01:09:59 | 67.8K token/s | 
[epoch_0]_57281  loss=3.144637 |g|=0.523	lr=1.94e-05 | 92.5%@S47  T=1.11s eta=01:09:19 | 68.1K token/s | 
[epoch_0]_57291  loss=3.126707 |g|=0.605	lr=1.93e-05 | 93.3%@S47  T=1.17s eta=01:12:48 | 68.3K token/s | 
[Fuyou] head="2" update algorithm=4 t=2.61s
[Section@57300] layer[18-24] tasks=15(nPassBack=0) last_loss=3.06111(0.0371835) N=(580,48636,48216 5729900)
[epoch_0]_57301  loss=3.162330 |g|=0.538	lr=1.93e-05 | 94.1%@S47  T=1.48s eta=01:32:19 | 67.6K token/s | 
[epoch_0]_57311  loss=3.063392 |g|=0.512	lr=1.92e-05 | 94.9%@S47  T=1.13s eta=01:10:19 | 67.8K token/s | 
[epoch_0]_57321  loss=3.097290 |g|=0.523	lr=1.92e-05 | 95.7%@S47  T=1.14s eta=01:10:31 | 68.0K token/s | 
[epoch_0]_57331  loss=3.191670 |g|=0.509	lr=1.91e-05 | 96.6%@S47  T=1.13s eta=01:10:00 | 68.2K token/s | 
[epoch_0]_57341  loss=3.131723 |g|=0.505	lr=1.91e-05 | 97.4%@S47  T=1.14s eta=01:10:08 | 68.4K token/s | 
[epoch_0]_57351  loss=3.132339 |g|=0.511	lr=1.90e-05 | 98.2%@S47  T=1.10s eta=01:07:21 | 68.7K token/s | 
[epoch_0]_57361  loss=3.137474 |g|=0.511	lr=1.90e-05 | 99.0%@S47  T=1.25s eta=01:16:29 | 68.6K token/s | 
[epoch_0]_57371  loss=3.096050 |g|=0.494	lr=1.90e-05 | 99.8%@S47  T=1.12s eta=01:08:10 | 68.8K token/s | 
[epoch_0]_57372  loss=3.163670 |g|=0.506	lr=1.89e-05 | 99.9%@S47  T=1.11s eta=01:08:03 | 69.1K token/s | 
-------- End of shard_47@"./Datasets/edu_fineweb1B/edu_fineweb_train_000804.bin"-------- 
[shard-48]@"./Datasets/edu_fineweb1B/edu_fineweb_train_000805.bin": tokens=100(M) nShardSamples=1220(4687488) 
[epoch_0]_57381  loss=3.148582 |g|=0.556	lr=1.89e-05 | 0.7%@S48  T=1.14s eta=01:09:21 | 69.2K token/s | 
[epoch_0]_57391  loss=3.121500 |g|=0.491	lr=1.89e-05 | 1.5%@S48  T=1.58s eta=01:35:46 | 68.3K token/s | 
[Fuyou] head="3" update algorithm=4 t=2.10s
[eval] 
	 Loss@"edu_fineweb1B"=3.143(0.00033) nBranch=1 nToken=4.01M best=3.1429(285) E2T=0.068 T=13.4307(0)s x=0
	#3.14256±0.1082 tps=299K(4.01408M) a=[2.96786,3.43553] T=13.4307(sec)
[Section@57400] layer[24-30] tasks=15(nPassBack=0) last_loss=3.07452(0.0342953) N=(580,48720,48300 5739900)
[epoch_0]_57401  loss=3.139940 |g|=0.536	lr=1.88e-05 | 2.3%@S48  T=4.25s eta=04:17:35 | 65.9K token/s | 
[epoch_0]_57411  loss=3.045714 |g|=0.514	lr=1.88e-05 | 3.1%@S48  T=1.12s eta=01:07:29 | 66.3K token/s | 
[epoch_0]_57421  loss=3.172418 |g|=0.512	lr=1.87e-05 | 3.9%@S48  T=1.10s eta=01:06:16 | 66.7K token/s | 
[epoch_0]_57431  loss=3.120635 |g|=0.497	lr=1.87e-05 | 4.8%@S48  T=1.10s eta=01:06:04 | 67.1K token/s | 
[epoch_0]_57441  loss=3.121111 |g|=0.502	lr=1.86e-05 | 5.6%@S48  T=1.30s eta=01:17:38 | 66.9K token/s | 
[epoch_0]_57451  loss=3.136514 |g|=0.503	lr=1.86e-05 | 6.4%@S48  T=1.14s eta=01:08:13 | 67.1K token/s | 
[epoch_0]_57461  loss=3.178043 |g|=0.507	lr=1.85e-05 | 7.2%@S48  T=1.09s eta=01:05:10 | 67.5K token/s | 
[epoch_0]_57471  loss=3.090519 |g|=0.517	lr=1.85e-05 | 8.0%@S48  T=1.27s eta=01:15:13 | 67.4K token/s | 
[epoch_0]_57481  loss=3.108328 |g|=0.518	lr=1.84e-05 | 8.9%@S48  T=1.11s eta=01:05:44 | 67.7K token/s | 
[epoch_0]_57491  loss=3.107857 |g|=0.5	lr=1.84e-05 | 9.7%@S48  T=1.19s eta=01:10:02 | 67.7K token/s | 
[Fuyou] head="4" update algorithm=4 t=2.09s
[Section@57500] layer[30-36] tasks=15(nPassBack=0) last_loss=3.09671(0.025979) N=(580,48804,48384 5749900)
[epoch_0]_57501  loss=3.144644 |g|=0.496	lr=1.83e-05 | 10.5%@S48  T=1.50s eta=01:28:18 | 67.1K token/s | 
[epoch_0]_57511  loss=3.120387 |g|=0.538	lr=1.83e-05 | 11.3%@S48  T=1.15s eta=01:07:44 | 67.3K token/s | 
[epoch_0]_57521  loss=3.166810 |g|=0.499	lr=1.82e-05 | 12.1%@S48  T=1.14s eta=01:06:36 | 67.5K token/s | 
[epoch_0]_57531  loss=3.168271 |g|=0.518	lr=1.82e-05 | 13.0%@S48  T=1.18s eta=01:08:52 | 67.6K token/s | 
[epoch_0]_57541  loss=3.066247 |g|=0.487	lr=1.81e-05 | 13.8%@S48  T=1.18s eta=01:08:43 | 67.7K token/s | 
[epoch_0]_57551  loss=3.070511 |g|=0.487	lr=1.81e-05 | 14.6%@S48  T=1.13s eta=01:05:33 | 68.0K token/s | 
[epoch_0]_57561  loss=3.155164 |g|=0.501	lr=1.80e-05 | 15.4%@S48  T=1.11s eta=01:04:05 | 68.3K token/s | 
[epoch_0]_57571  loss=3.090341 |g|=0.515	lr=1.80e-05 | 16.2%@S48  T=1.12s eta=01:04:55 | 68.5K token/s | 
[epoch_0]_57581  loss=3.144587 |g|=0.508	lr=1.80e-05 | 17.0%@S48  T=1.15s eta=01:06:20 | 68.6K token/s | 
[epoch_0]_57591  loss=3.083145 |g|=0.51	lr=1.79e-05 | 17.9%@S48  T=1.07s eta=01:01:14 | 69.0K token/s | 
[Fuyou] head="5" update algorithm=4 t=2.67s
[eval] 
	 Loss@"edu_fineweb1B"=3.142(0.00021) nBranch=1 nToken=4.01M best=3.1426(286) E2T=0.0583 T=13.4274(0)s x=0
	#3.14235±0.1084 tps=299K(4.01408M) a=[2.9675,3.43599] T=13.4274(sec)
[Section@57600] layer[0-6] tasks=15(nPassBack=0) last_loss=3.08408(0.0071485) N=(580,48888,48468 5759900)
[epoch_0]_57601  loss=3.119835 |g|=0.522	lr=1.79e-05 | 18.7%@S48  T=4.26s eta=04:03:56 | 66.5K token/s | 
[epoch_0]_57611  loss=3.113220 |g|=0.501	lr=1.78e-05 | 19.5%@S48  T=1.10s eta=01:02:50 | 66.9K token/s | 
[epoch_0]_57621  loss=3.226994 |g|=0.515	lr=1.78e-05 | 20.3%@S48  T=1.09s eta=01:02:05 | 67.3K token/s | 
[epoch_0]_57631  loss=3.158475 |g|=0.508	lr=1.77e-05 | 21.1%@S48  T=1.05s eta=00:59:29 | 67.9K token/s | 
[epoch_0]_57641  loss=3.096497 |g|=0.505	lr=1.77e-05 | 22.0%@S48  T=1.09s eta=01:01:42 | 68.2K token/s | 
[epoch_0]_57651  loss=3.138484 |g|=0.511	lr=1.76e-05 | 22.8%@S48  T=1.46s eta=01:22:04 | 67.6K token/s | 
[epoch_0]_57661  loss=3.089893 |g|=0.516	lr=1.76e-05 | 23.6%@S48  T=1.06s eta=00:59:45 | 68.1K token/s | 
[epoch_0]_57671  loss=3.128306 |g|=0.518	lr=1.75e-05 | 24.4%@S48  T=1.07s eta=01:00:02 | 68.5K token/s | 
[epoch_0]_57681  loss=3.150587 |g|=0.494	lr=1.75e-05 | 25.2%@S48  T=1.12s eta=01:02:36 | 68.8K token/s | 
[epoch_0]_57691  loss=3.138071 |g|=0.515	lr=1.75e-05 | 26.1%@S48  T=1.10s eta=01:01:24 | 69.0K token/s | 
[Fuyou] head="0" update algorithm=4 t=2.20s
[Section@57700] layer[6-12] tasks=15(nPassBack=0) last_loss=3.13821(-0.0170233) N=(580,48972,48552 5769900)
[epoch_0]_57701  loss=3.138833 |g|=0.507	lr=1.74e-05 | 26.9%@S48  T=1.34s eta=01:14:23 | 68.6K token/s | 
[epoch_0]_57711  loss=3.108048 |g|=0.511	lr=1.74e-05 | 27.7%@S48  T=1.06s eta=00:58:28 | 69.1K token/s | 
[epoch_0]_57721  loss=3.027091 |g|=0.502	lr=1.73e-05 | 28.5%@S48  T=1.05s eta=00:58:15 | 69.5K token/s | 
[epoch_0]_57731  loss=3.094294 |g|=0.505	lr=1.73e-05 | 29.3%@S48  T=1.06s eta=00:58:06 | 69.9K token/s | 
[epoch_0]_57741  loss=3.125481 |g|=0.506	lr=1.72e-05 | 30.2%@S48  T=1.10s eta=01:00:07 | 70.2K token/s | 
[epoch_0]_57751  loss=3.133155 |g|=0.507	lr=1.72e-05 | 31.0%@S48  T=1.12s eta=01:01:07 | 70.3K token/s | 
[epoch_0]_57761  loss=3.128405 |g|=0.535	lr=1.72e-05 | 31.8%@S48  T=1.04s eta=00:56:42 | 70.8K token/s | 
[epoch_0]_57771  loss=3.081597 |g|=0.508	lr=1.71e-05 | 32.6%@S48  T=1.04s eta=00:56:30 | 71.2K token/s | 
[epoch_0]_57781  loss=3.137020 |g|=0.504	lr=1.71e-05 | 33.4%@S48  T=1.41s eta=01:16:17 | 70.5K token/s | 
[epoch_0]_57791  loss=3.133294 |g|=0.497	lr=1.70e-05 | 34.3%@S48  T=1.05s eta=00:56:35 | 70.9K token/s | 
[Fuyou] head="1" update algorithm=4 t=2.09s
[eval] 
	 Loss@"edu_fineweb1B"=3.142(0.00045) nBranch=1 nToken=4.01M best=3.1424(287) E2T=-0.0187 T=13.4622(0)s x=0
	#3.1419±0.1083 tps=298K(4.01408M) a=[2.96699,3.43631] T=13.4622(sec)
[Section@57800] layer[12-18] tasks=15(nPassBack=0) last_loss=3.16062(-0.106705) N=(580,49056,48636 5779900)
[epoch_0]_57801  loss=3.153440 |g|=0.52	lr=1.70e-05 | 35.1%@S48  T=4.49s eta=04:01:54 | 68.3K token/s | 
[epoch_0]_57811  loss=3.046100 |g|=0.507	lr=1.69e-05 | 35.9%@S48  T=1.09s eta=00:58:34 | 68.6K token/s | 
[epoch_0]_57821  loss=3.083789 |g|=0.511	lr=1.69e-05 | 36.7%@S48  T=1.04s eta=00:55:50 | 69.1K token/s | 
[epoch_0]_57831  loss=3.204200 |g|=0.561	lr=1.68e-05 | 37.5%@S48  T=1.11s eta=00:59:14 | 69.4K token/s | 
[epoch_0]_57841  loss=3.161116 |g|=0.519	lr=1.68e-05 | 38.3%@S48  T=1.10s eta=00:58:47 | 69.6K token/s | 
[epoch_0]_57851  loss=3.056770 |g|=0.489	lr=1.68e-05 | 39.2%@S48  T=1.07s eta=00:56:37 | 70.0K token/s | 
[epoch_0]_57861  loss=3.107536 |g|=0.516	lr=1.67e-05 | 40.0%@S48  T=1.07s eta=00:56:40 | 70.3K token/s | 
[epoch_0]_57871  loss=3.168870 |g|=0.507	lr=1.67e-05 | 40.8%@S48  T=1.14s eta=01:00:11 | 70.4K token/s | 
[epoch_0]_57881  loss=3.130573 |g|=0.501	lr=1.66e-05 | 41.6%@S48  T=1.03s eta=00:54:11 | 70.8K token/s | 
[epoch_0]_57891  loss=3.093135 |g|=0.484	lr=1.66e-05 | 42.4%@S48  T=1.05s eta=00:55:07 | 71.2K token/s | 
[Fuyou] head="2" update algorithm=4 t=3.05s
[Section@57900] layer[18-24] tasks=15(nPassBack=0) last_loss=3.15575(-0.0946403) N=(580,49140,48720 5789900)
[epoch_0]_57901  loss=3.051880 |g|=0.51	lr=1.66e-05 | 43.3%@S48  T=1.58s eta=01:22:29 | 70.2K token/s | 
[epoch_0]_57911  loss=3.111522 |g|=0.494	lr=1.65e-05 | 44.1%@S48  T=1.09s eta=00:56:41 | 70.4K token/s | 
[epoch_0]_57921  loss=3.162114 |g|=0.503	lr=1.65e-05 | 44.9%@S48  T=1.05s eta=00:54:35 | 70.8K token/s | 
[epoch_0]_57931  loss=3.080617 |g|=0.491	lr=1.64e-05 | 45.7%@S48  T=1.43s eta=01:13:49 | 70.1K token/s | 
[epoch_0]_57941  loss=3.136263 |g|=0.501	lr=1.64e-05 | 46.5%@S48  T=1.04s eta=00:53:32 | 70.6K token/s | 
[epoch_0]_57951  loss=3.238580 |g|=0.527	lr=1.63e-05 | 47.4%@S48  T=1.04s eta=00:53:14 | 71.0K token/s | 
[epoch_0]_57961  loss=3.115344 |g|=0.522	lr=1.63e-05 | 48.2%@S48  T=1.09s eta=00:55:59 | 71.2K token/s | 
[epoch_0]_57971  loss=3.122398 |g|=0.504	lr=1.63e-05 | 49.0%@S48  T=1.09s eta=00:55:38 | 71.4K token/s | 
[epoch_0]_57981  loss=3.066757 |g|=0.497	lr=1.62e-05 | 49.8%@S48  T=1.06s eta=00:53:45 | 71.7K token/s | 
[epoch_0]_57991  loss=3.174723 |g|=0.497	lr=1.62e-05 | 50.6%@S48  T=1.07s eta=00:54:23 | 71.9K token/s | 
[Fuyou] head="3" update algorithm=4 t=2.05s
[eval] 
	 Loss@"edu_fineweb1B"=3.142(0.00027) nBranch=1 nToken=4.01M best=3.1419(288) E2T=0.0145 T=13.4315(0)s x=0
	#3.14162±0.1084 tps=299K(4.01408M) a=[2.96602,3.43676] T=13.4315(sec)
[Section@58000] layer[24-30] tasks=15(nPassBack=0) last_loss=3.12715(-0.0526323) N=(580,49224,48804 5799900)
[epoch_0]_58001  loss=3.154619 |g|=0.514	lr=1.61e-05 | 51.5%@S48  T=4.19s eta=03:31:42 | 69.3K token/s | 
[epoch_0]_58011  loss=3.104505 |g|=0.503	lr=1.61e-05 | 52.3%@S48  T=1.05s eta=00:53:10 | 69.7K token/s | 
[epoch_0]_58021  loss=3.179408 |g|=0.516	lr=1.61e-05 | 53.1%@S48  T=1.07s eta=00:53:38 | 70.1K token/s | 
[epoch_0]_58031  loss=3.121288 |g|=0.513	lr=1.60e-05 | 53.9%@S48  T=1.10s eta=00:55:14 | 70.3K token/s | 
[epoch_0]_58041  loss=3.165025 |g|=0.494	lr=1.60e-05 | 54.7%@S48  T=1.06s eta=00:52:43 | 70.7K token/s | 
[epoch_0]_58051  loss=3.148569 |g|=0.505	lr=1.59e-05 | 55.6%@S48  T=1.18s eta=00:58:36 | 70.6K token/s | 
[epoch_0]_58061  loss=3.097869 |g|=0.49	lr=1.59e-05 | 56.4%@S48  T=1.10s eta=00:54:19 | 70.8K token/s | 
[epoch_0]_58071  loss=3.073482 |g|=0.496	lr=1.59e-05 | 57.2%@S48  T=1.06s eta=00:52:16 | 71.1K token/s | 
[epoch_0]_58081  loss=3.111115 |g|=0.496	lr=1.58e-05 | 58.0%@S48  T=1.21s eta=00:59:27 | 71.0K token/s | 
[epoch_0]_58091  loss=3.068628 |g|=0.519	lr=1.58e-05 | 58.8%@S48  T=1.08s eta=00:52:46 | 71.2K token/s | 
[Fuyou] head="4" update algorithm=4 t=2.25s
[Section@58100] layer[30-36] tasks=15(nPassBack=0) last_loss=3.12321(-0.0265026) N=(580,49308,48888 5809900)
[epoch_0]_58101  loss=3.070274 |g|=0.527	lr=1.57e-05 | 59.6%@S48  T=1.36s eta=01:06:43 | 70.7K token/s | 
[epoch_0]_58111  loss=3.151390 |g|=0.505	lr=1.57e-05 | 60.5%@S48  T=1.06s eta=00:51:34 | 71.0K token/s | 
[epoch_0]_58121  loss=3.160374 |g|=0.509	lr=1.57e-05 | 61.3%@S48  T=1.05s eta=00:50:47 | 71.4K token/s | 
[epoch_0]_58131  loss=3.120233 |g|=0.497	lr=1.56e-05 | 62.1%@S48  T=1.04s eta=00:50:19 | 71.7K token/s | 
[epoch_0]_58141  loss=3.137567 |g|=0.515	lr=1.56e-05 | 62.9%@S48  T=1.06s eta=00:51:08 | 72.0K token/s | 
[epoch_0]_58151  loss=3.074207 |g|=0.511	lr=1.56e-05 | 63.7%@S48  T=1.07s eta=00:51:38 | 72.2K token/s | 
[epoch_0]_58161  loss=3.042447 |g|=0.498	lr=1.55e-05 | 64.6%@S48  T=1.09s eta=00:52:04 | 72.4K token/s | 
[epoch_0]_58171  loss=3.086854 |g|=0.499	lr=1.55e-05 | 65.4%@S48  T=1.05s eta=00:50:15 | 72.7K token/s | 
[epoch_0]_58181  loss=3.074313 |g|=0.489	lr=1.54e-05 | 66.2%@S48  T=1.27s eta=01:00:26 | 72.3K token/s | 
[epoch_0]_58191  loss=3.102490 |g|=0.489	lr=1.54e-05 | 67.0%@S48  T=1.09s eta=00:51:32 | 72.4K token/s | 
[Fuyou] head="5" update algorithm=4 t=2.05s
[eval] 
	 Loss@"edu_fineweb1B"=3.141(0.00056) nBranch=1 nToken=4.01M best=3.1416(289) E2T=0.0213 T=13.4724(0)s x=0
	#3.14107±0.1084 tps=298K(4.01408M) a=[2.96608,3.43606] T=13.4724(sec)
[Section@58200] layer[0-6] tasks=15(nPassBack=0) last_loss=3.11982(-0.0357311) N=(580,49392,48972 5819900)
[epoch_0]_58201  loss=3.178831 |g|=0.513	lr=1.54e-05 | 67.8%@S48  T=4.37s eta=03:26:13 | 69.7K token/s | 
[epoch_0]_58211  loss=3.143587 |g|=0.493	lr=1.53e-05 | 68.7%@S48  T=1.07s eta=00:50:14 | 70.1K token/s | 
[epoch_0]_58221  loss=3.089907 |g|=0.512	lr=1.53e-05 | 69.5%@S48  T=1.13s eta=00:52:47 | 70.2K token/s | 
[epoch_0]_58231  loss=3.128894 |g|=0.508	lr=1.52e-05 | 70.3%@S48  T=1.36s eta=01:03:26 | 69.7K token/s | 
[epoch_0]_58241  loss=3.141105 |g|=0.503	lr=1.52e-05 | 71.1%@S48  T=1.07s eta=00:49:49 | 70.1K token/s | 
[epoch_0]_58251  loss=3.125073 |g|=0.494	lr=1.52e-05 | 71.9%@S48  T=1.11s eta=00:51:16 | 70.3K token/s | 
[epoch_0]_58261  loss=3.190788 |g|=0.503	lr=1.51e-05 | 72.8%@S48  T=1.13s eta=00:52:11 | 70.4K token/s | 
[epoch_0]_58271  loss=3.178376 |g|=0.498	lr=1.51e-05 | 73.6%@S48  T=1.07s eta=00:49:16 | 70.7K token/s | 
[epoch_0]_58281  loss=3.069307 |g|=0.514	lr=1.51e-05 | 74.4%@S48  T=1.08s eta=00:49:40 | 70.9K token/s | 
[epoch_0]_58291  loss=3.141685 |g|=0.506	lr=1.50e-05 | 75.2%@S48  T=1.11s eta=00:50:58 | 71.1K token/s | 
[Fuyou] head="0" update algorithm=4 t=2.07s
[Section@58300] layer[6-12] tasks=15(nPassBack=0) last_loss=3.16583(-0.0276175) N=(580,49476,49056 5829900)
[epoch_0]_58301  loss=3.156057 |g|=0.523	lr=1.50e-05 | 76.0%@S48  T=1.55s eta=01:10:31 | 70.2K token/s | 
[epoch_0]_58311  loss=3.132128 |g|=0.533	lr=1.50e-05 | 76.9%@S48  T=1.06s eta=00:48:09 | 70.5K token/s | 
[epoch_0]_58321  loss=3.075987 |g|=0.506	lr=1.49e-05 | 77.7%@S48  T=1.09s eta=00:49:28 | 70.7K token/s | 
[epoch_0]_58331  loss=3.196819 |g|=0.527	lr=1.49e-05 | 78.5%@S48  T=1.11s eta=00:49:57 | 70.9K token/s | 
[epoch_0]_58341  loss=3.161052 |g|=0.492	lr=1.48e-05 | 79.3%@S48  T=1.06s eta=00:47:26 | 71.2K token/s | 
[epoch_0]_58351  loss=3.118097 |g|=0.51	lr=1.48e-05 | 80.1%@S48  T=1.09s eta=00:48:36 | 71.4K token/s | 
[epoch_0]_58361  loss=3.109866 |g|=0.501	lr=1.48e-05 | 80.9%@S48  T=1.49s eta=01:06:22 | 70.6K token/s | 
[epoch_0]_58371  loss=3.114428 |g|=0.5	lr=1.47e-05 | 81.8%@S48  T=1.05s eta=00:46:46 | 71.0K token/s | 
[epoch_0]_58381  loss=3.156593 |g|=0.499	lr=1.47e-05 | 82.6%@S48  T=1.06s eta=00:46:51 | 71.3K token/s | 
[epoch_0]_58391  loss=3.113920 |g|=0.493	lr=1.47e-05 | 83.4%@S48  T=1.09s eta=00:48:03 | 71.5K token/s | 
[Fuyou] head="1" update algorithm=4 t=2.06s
[eval] 
	 Loss@"edu_fineweb1B"=3.141(-0.00019) nBranch=1 nToken=4.01M best=3.1411(290) E2T=-0.0224 T=13.441(0)s x=0
	#3.14126±0.1085 tps=299K(4.01408M) a=[2.9661,3.43645] T=13.441(sec)
[Section@58400] layer[12-18] tasks=15(nPassBack=0) last_loss=3.16371(-0.00308228) N=(580,49560,49140 5839900)
[epoch_0]_58401  loss=3.172951 |g|=0.512	lr=1.46e-05 | 84.2%@S48  T=4.20s eta=03:04:13 | 68.9K token/s | 
[epoch_0]_58411  loss=3.121811 |g|=0.504	lr=1.46e-05 | 85.0%@S48  T=1.34s eta=00:58:38 | 68.5K token/s | 
[epoch_0]_58421  loss=3.137845 |g|=0.491	lr=1.46e-05 | 85.9%@S48  T=1.12s eta=00:48:44 | 68.7K token/s | 
[epoch_0]_58431  loss=3.170186 |g|=0.501	lr=1.45e-05 | 86.7%@S48  T=1.07s eta=00:46:20 | 69.1K token/s | 
[epoch_0]_58441  loss=3.186206 |g|=0.5	lr=1.45e-05 | 87.5%@S48  T=1.10s eta=00:47:32 | 69.4K token/s | 
[epoch_0]_58451  loss=3.095898 |g|=0.498	lr=1.45e-05 | 88.3%@S48  T=1.11s eta=00:47:40 | 69.6K token/s | 
[epoch_0]_58461  loss=3.153893 |g|=0.5	lr=1.44e-05 | 89.1%@S48  T=1.10s eta=00:47:00 | 69.9K token/s | 
[epoch_0]_58471  loss=3.174805 |g|=0.498	lr=1.44e-05 | 90.0%@S48  T=1.07s eta=00:45:37 | 70.2K token/s | 
[epoch_0]_58481  loss=3.099619 |g|=0.498	lr=1.44e-05 | 90.8%@S48  T=1.07s eta=00:45:29 | 70.5K token/s | 
[epoch_0]_58491  loss=3.162764 |g|=0.52	lr=1.43e-05 | 91.6%@S48  T=1.10s eta=00:46:48 | 70.7K token/s | 
[Fuyou] head="2" update algorithm=4 t=2.10s
[Section@58500] layer[18-24] tasks=15(nPassBack=0) last_loss=3.11145(0.0442927) N=(580,49644,49224 5849900)
[epoch_0]_58501  loss=3.103153 |g|=0.514	lr=1.43e-05 | 92.4%@S48  T=1.46s eta=01:01:35 | 70.0K token/s | 
[epoch_0]_58511  loss=3.114005 |g|=0.525	lr=1.43e-05 | 93.2%@S48  T=1.07s eta=00:45:07 | 70.3K token/s | 
[epoch_0]_58521  loss=3.173084 |g|=0.527	lr=1.42e-05 | 94.1%@S48  T=1.07s eta=00:44:58 | 70.6K token/s | 
[epoch_0]_58531  loss=3.110179 |g|=0.503	lr=1.42e-05 | 94.9%@S48  T=1.12s eta=00:46:39 | 70.8K token/s | 
[epoch_0]_58541  loss=3.151206 |g|=0.501	lr=1.42e-05 | 95.7%@S48  T=1.42s eta=00:58:55 | 70.1K token/s | 
[epoch_0]_58551  loss=3.177282 |g|=0.498	lr=1.41e-05 | 96.5%@S48  T=1.07s eta=00:44:06 | 70.4K token/s | 
[epoch_0]_58561  loss=3.136404 |g|=0.51	lr=1.41e-05 | 97.3%@S48  T=1.09s eta=00:45:07 | 70.7K token/s | 
[epoch_0]_58571  loss=3.138885 |g|=0.492	lr=1.41e-05 | 98.1%@S48  T=1.07s eta=00:43:47 | 71.0K token/s | 
[epoch_0]_58581  loss=3.139296 |g|=0.512	lr=1.40e-05 | 99.0%@S48  T=1.08s eta=00:44:10 | 71.2K token/s | 
[epoch_0]_58591  loss=3.194522 |g|=0.504	lr=1.40e-05 | 99.8%@S48  T=1.12s eta=00:45:43 | 71.3K token/s | 
[epoch_0]_58593  loss=3.148115 |g|=0.499	lr=1.40e-05 | 100.0%@S48  T=1.08s eta=00:43:48 | 71.5K token/s | 
-------- End of shard_48@"./Datasets/edu_fineweb1B/edu_fineweb_train_000805.bin"-------- 
[shard-49]@"./Datasets/edu_fineweb1B/edu_fineweb_train_000806.bin": tokens=100(M) nShardSamples=1220(4785144) 
[Fuyou] head="3" update algorithm=4 t=2.07s
[eval] 
	 Loss@"edu_fineweb1B"=3.141(0.00067) nBranch=1 nToken=4.01M best=3.1413(291) E2T=0.0775 T=13.4811(0)s x=0
	#3.14059±0.1083 tps=298K(4.01408M) a=[2.96567,3.43603] T=13.4811(sec)
[Section@58600] layer[24-30] tasks=15(nPassBack=0) last_loss=3.06309(0.0640619) N=(580,49728,49308 5859900)
[epoch_0]_58601  loss=3.097167 |g|=0.52	lr=1.40e-05 | 0.6%@S49  T=4.18s eta=02:49:45 | 68.9K token/s | 
[epoch_0]_58611  loss=3.142402 |g|=0.509	lr=1.39e-05 | 1.4%@S49  T=1.07s eta=00:43:24 | 69.3K token/s | 
[epoch_0]_58621  loss=3.028488 |g|=0.513	lr=1.39e-05 | 2.2%@S49  T=1.06s eta=00:42:46 | 69.7K token/s | 
[epoch_0]_58631  loss=3.090765 |g|=0.502	lr=1.39e-05 | 3.1%@S49  T=1.06s eta=00:42:23 | 70.1K token/s | 
[epoch_0]_58641  loss=3.020203 |g|=0.51	lr=1.38e-05 | 3.9%@S49  T=1.09s eta=00:43:34 | 70.3K token/s | 
[epoch_0]_58651  loss=3.156501 |g|=0.496	lr=1.38e-05 | 4.7%@S49  T=1.12s eta=00:44:40 | 70.5K token/s | 
[epoch_0]_58661  loss=3.144262 |g|=0.501	lr=1.38e-05 | 5.5%@S49  T=1.08s eta=00:42:53 | 70.7K token/s | 
[epoch_0]_58671  loss=3.018836 |g|=0.512	lr=1.37e-05 | 6.3%@S49  T=1.06s eta=00:41:41 | 71.0K token/s | 
[epoch_0]_58681  loss=3.098361 |g|=0.498	lr=1.37e-05 | 7.2%@S49  T=1.11s eta=00:43:35 | 71.2K token/s | 
[epoch_0]_58691  loss=3.114037 |g|=0.491	lr=1.37e-05 | 8.0%@S49  T=1.35s eta=00:52:51 | 70.6K token/s | 
[Fuyou] head="4" update algorithm=4 t=2.06s
[Section@58700] layer[30-36] tasks=15(nPassBack=0) last_loss=3.14734(-0.0241354) N=(580,49812,49392 5869900)
[epoch_0]_58701  loss=3.130855 |g|=0.529	lr=1.36e-05 | 8.8%@S49  T=1.39s eta=00:54:10 | 70.1K token/s | 
[epoch_0]_58711  loss=3.130407 |g|=0.51	lr=1.36e-05 | 9.6%@S49  T=1.06s eta=00:41:09 | 70.4K token/s | 
[epoch_0]_58721  loss=3.087942 |g|=0.524	lr=1.36e-05 | 10.4%@S49  T=1.21s eta=00:46:31 | 70.3K token/s | 
[epoch_0]_58731  loss=3.055225 |g|=0.506	lr=1.35e-05 | 11.3%@S49  T=1.04s eta=00:40:04 | 70.7K token/s | 
[epoch_0]_58741  loss=3.109962 |g|=0.502	lr=1.35e-05 | 12.1%@S49  T=1.07s eta=00:40:48 | 71.0K token/s | 
[epoch_0]_58751  loss=3.117150 |g|=0.495	lr=1.35e-05 | 12.9%@S49  T=1.13s eta=00:42:58 | 71.1K token/s | 
[epoch_0]_58761  loss=3.021285 |g|=0.5	lr=1.35e-05 | 13.7%@S49  T=1.05s eta=00:39:56 | 71.4K token/s | 
[epoch_0]_58771  loss=3.198002 |g|=0.493	lr=1.34e-05 | 14.5%@S49  T=1.06s eta=00:39:49 | 71.7K token/s | 
[epoch_0]_58781  loss=3.132117 |g|=0.505	lr=1.34e-05 | 15.4%@S49  T=1.08s eta=00:40:24 | 71.9K token/s | 
[epoch_0]_58791  loss=3.049605 |g|=0.53	lr=1.34e-05 | 16.2%@S49  T=1.20s eta=00:45:01 | 71.7K token/s | 
[Fuyou] head="5" update algorithm=4 t=2.01s
[eval] 
	 Loss@"edu_fineweb1B"=3.139(0.0013) nBranch=1 nToken=4.01M best=3.1406(292) E2T=-0.0386 T=13.4431(0)s x=0
	#3.13933±0.1083 tps=299K(4.01408M) a=[2.96349,3.43328] T=13.4431(sec)
[Section@58800] layer[0-6] tasks=15(nPassBack=0) last_loss=3.17792(-0.0581009) N=(580,49896,49476 5879900)
[epoch_0]_58801  loss=3.086581 |g|=0.565	lr=1.33e-05 | 17.0%@S49  T=4.23s eta=02:37:26 | 69.1K token/s | 
[epoch_0]_58811  loss=3.091333 |g|=0.522	lr=1.33e-05 | 17.8%@S49  T=1.10s eta=00:40:40 | 69.4K token/s | 
[epoch_0]_58821  loss=3.135953 |g|=0.506	lr=1.33e-05 | 18.6%@S49  T=1.07s eta=00:39:29 | 69.8K token/s | 
[epoch_0]_58831  loss=3.047816 |g|=0.509	lr=1.32e-05 | 19.4%@S49  T=1.07s eta=00:39:16 | 70.1K token/s | 
[epoch_0]_58841  loss=3.083661 |g|=0.51	lr=1.32e-05 | 20.3%@S49  T=1.50s eta=00:55:00 | 69.3K token/s | 
[epoch_0]_58851  loss=3.112771 |g|=0.515	lr=1.32e-05 | 21.1%@S49  T=1.06s eta=00:38:27 | 69.7K token/s | 
[epoch_0]_58861  loss=3.048275 |g|=0.493	lr=1.32e-05 | 21.9%@S49  T=1.07s eta=00:38:53 | 70.1K token/s | 
[epoch_0]_58871  loss=3.017057 |g|=0.508	lr=1.31e-05 | 22.7%@S49  T=1.09s eta=00:39:21 | 70.3K token/s | 
[epoch_0]_58881  loss=3.125282 |g|=0.51	lr=1.31e-05 | 23.5%@S49  T=1.12s eta=00:40:08 | 70.5K token/s | 
[epoch_0]_58891  loss=3.094500 |g|=0.51	lr=1.31e-05 | 24.4%@S49  T=1.05s eta=00:37:40 | 70.8K token/s | 
[Fuyou] head="0" update algorithm=4 t=2.07s
[Section@58900] layer[6-12] tasks=15(nPassBack=0) last_loss=3.13541(0.030417) N=(580,49980,49560 5889900)
[epoch_0]_58901  loss=3.087658 |g|=0.526	lr=1.30e-05 | 25.2%@S49  T=1.50s eta=00:53:19 | 70.0K token/s | 
[epoch_0]_58911  loss=3.123594 |g|=0.507	lr=1.30e-05 | 26.0%@S49  T=1.06s eta=00:37:24 | 70.4K token/s | 
[epoch_0]_58921  loss=3.121345 |g|=0.519	lr=1.30e-05 | 26.8%@S49  T=1.06s eta=00:37:16 | 70.7K token/s | 
[epoch_0]_58931  loss=3.018511 |g|=0.492	lr=1.30e-05 | 27.6%@S49  T=1.07s eta=00:37:22 | 71.0K token/s | 
[epoch_0]_58941  loss=2.949898 |g|=0.531	lr=1.29e-05 | 28.5%@S49  T=1.08s eta=00:37:50 | 71.3K token/s | 
[epoch_0]_58951  loss=3.076655 |g|=0.504	lr=1.29e-05 | 29.3%@S49  T=1.12s eta=00:39:00 | 71.4K token/s | 
[epoch_0]_58961  loss=3.106801 |g|=0.515	lr=1.29e-05 | 30.1%@S49  T=1.07s eta=00:37:01 | 71.6K token/s | 
[epoch_0]_58971  loss=3.032741 |g|=0.507	lr=1.28e-05 | 30.9%@S49  T=1.35s eta=00:46:31 | 71.1K token/s | 
[epoch_0]_58981  loss=2.978523 |g|=0.501	lr=1.28e-05 | 31.7%@S49  T=1.07s eta=00:36:40 | 71.3K token/s | 
[epoch_0]_58991  loss=3.141132 |g|=0.514	lr=1.28e-05 | 32.6%@S49  T=1.10s eta=00:37:24 | 71.5K token/s | 
[Fuyou] head="1" update algorithm=4 t=2.04s
[eval] 
	 Loss@"edu_fineweb1B"=3.139(0.00058) nBranch=1 nToken=4.01M best=3.1393(293) E2T=0.038 T=13.4881(0)s x=0
	#3.13875±0.1083 tps=298K(4.01408M) a=[2.96329,3.43249] T=13.4881(sec)
[Section@59000] layer[12-18] tasks=15(nPassBack=0) last_loss=3.10071(0.0629914) N=(580,50064,49644 5899900)
[epoch_0]_59001  loss=3.069280 |g|=0.512	lr=1.28e-05 | 33.4%@S49  T=4.20s eta=02:22:29 | 68.9K token/s | 
[epoch_0]_59011  loss=3.047550 |g|=0.507	lr=1.27e-05 | 34.2%@S49  T=1.14s eta=00:38:27 | 69.0K token/s | 
[epoch_0]_59021  loss=3.098456 |g|=0.518	lr=1.27e-05 | 35.0%@S49  T=1.15s eta=00:38:43 | 69.1K token/s | 
[epoch_0]_59031  loss=3.101268 |g|=0.515	lr=1.27e-05 | 35.8%@S49  T=1.08s eta=00:35:57 | 69.5K token/s | 
[epoch_0]_59041  loss=3.045282 |g|=0.507	lr=1.27e-05 | 36.7%@S49  T=1.11s eta=00:36:57 | 69.7K token/s | 
[epoch_0]_59051  loss=3.133712 |g|=0.547	lr=1.26e-05 | 37.5%@S49  T=1.07s eta=00:35:13 | 70.1K token/s | 
[epoch_0]_59061  loss=3.049356 |g|=0.513	lr=1.26e-05 | 38.3%@S49  T=1.07s eta=00:35:18 | 70.4K token/s | 
[epoch_0]_59071  loss=3.148488 |g|=0.522	lr=1.26e-05 | 39.1%@S49  T=1.11s eta=00:36:19 | 70.5K token/s | 
[epoch_0]_59081  loss=3.139377 |g|=0.537	lr=1.26e-05 | 39.9%@S49  T=1.07s eta=00:34:44 | 70.9K token/s | 
[epoch_0]_59091  loss=3.010139 |g|=0.502	lr=1.25e-05 | 40.7%@S49  T=1.11s eta=00:35:50 | 71.0K token/s | 
[Fuyou] head="2" update algorithm=4 t=2.05s
[Section@59100] layer[18-24] tasks=15(nPassBack=0) last_loss=3.04122(0.0702372) N=(580,50148,49728 5909900)
[epoch_0]_59101  loss=3.181198 |g|=0.516	lr=1.25e-05 | 41.6%@S49  T=1.36s eta=00:43:44 | 70.5K token/s | 
[epoch_0]_59111  loss=3.109845 |g|=0.504	lr=1.25e-05 | 42.4%@S49  T=1.08s eta=00:34:30 | 70.8K token/s | 
[epoch_0]_59121  loss=3.072384 |g|=0.521	lr=1.24e-05 | 43.2%@S49  T=1.20s eta=00:38:12 | 70.6K token/s | 
[epoch_0]_59131  loss=3.100096 |g|=0.526	lr=1.24e-05 | 44.0%@S49  T=1.07s eta=00:33:48 | 71.0K token/s | 
[epoch_0]_59141  loss=3.073466 |g|=0.498	lr=1.24e-05 | 44.8%@S49  T=1.08s eta=00:34:07 | 71.2K token/s | 
[epoch_0]_59151  loss=3.049084 |g|=0.502	lr=1.24e-05 | 45.7%@S49  T=1.08s eta=00:33:59 | 71.4K token/s | 
[epoch_0]_59161  loss=3.035755 |g|=0.492	lr=1.23e-05 | 46.5%@S49  T=1.07s eta=00:33:20 | 71.7K token/s | 
[epoch_0]_59171  loss=3.130378 |g|=0.506	lr=1.23e-05 | 47.3%@S49  T=1.08s eta=00:33:29 | 71.9K token/s | 
[epoch_0]_59181  loss=3.153332 |g|=0.516	lr=1.23e-05 | 48.1%@S49  T=1.12s eta=00:34:40 | 72.0K token/s | 
[epoch_0]_59191  loss=3.131674 |g|=0.51	lr=1.23e-05 | 48.9%@S49  T=1.09s eta=00:33:34 | 72.1K token/s | 
[Fuyou] head="3" update algorithm=4 t=2.06s
[eval] 
	 Loss@"edu_fineweb1B"=3.138(0.00048) nBranch=1 nToken=4.01M best=3.1388(294) E2T=0.0268 T=13.4465(0)s x=0
	#3.13827±0.1084 tps=299K(4.01408M) a=[2.96189,3.43276] T=13.4465(sec)
[Section@59200] layer[24-30] tasks=15(nPassBack=0) last_loss=3.11147(-0.0483727) N=(580,50232,49812 5919900)
[epoch_0]_59201  loss=3.099655 |g|=0.518	lr=1.22e-05 | 49.8%@S49  T=4.23s eta=02:09:24 | 69.5K token/s | 
[epoch_0]_59211  loss=3.052852 |g|=0.508	lr=1.22e-05 | 50.6%@S49  T=1.09s eta=00:33:01 | 69.8K token/s | 
[epoch_0]_59221  loss=3.070071 |g|=0.535	lr=1.22e-05 | 51.4%@S49  T=1.07s eta=00:32:16 | 70.1K token/s | 
[epoch_0]_59231  loss=3.098078 |g|=0.502	lr=1.22e-05 | 52.2%@S49  T=1.10s eta=00:32:55 | 70.4K token/s | 
[epoch_0]_59241  loss=3.111174 |g|=0.491	lr=1.22e-05 | 53.0%@S49  T=1.13s eta=00:33:42 | 70.5K token/s | 
[epoch_0]_59251  loss=3.191049 |g|=0.497	lr=1.21e-05 | 53.9%@S49  T=1.10s eta=00:32:49 | 70.7K token/s | 
[epoch_0]_59261  loss=3.075339 |g|=0.526	lr=1.21e-05 | 54.7%@S49  T=1.07s eta=00:31:43 | 70.9K token/s | 
[epoch_0]_59271  loss=3.119915 |g|=0.523	lr=1.21e-05 | 55.5%@S49  T=1.20s eta=00:35:17 | 70.8K token/s | 
[epoch_0]_59281  loss=3.100311 |g|=0.515	lr=1.21e-05 | 56.3%@S49  T=1.14s eta=00:33:11 | 70.9K token/s | 
[epoch_0]_59291  loss=3.124972 |g|=0.506	lr=1.20e-05 | 57.1%@S49  T=1.07s eta=00:31:10 | 71.1K token/s | 
[Fuyou] head="4" update algorithm=4 t=2.08s
[Section@59300] layer[30-36] tasks=15(nPassBack=0) last_loss=3.1073(0.0400474) N=(580,50316,49896 5929900)
[epoch_0]_59301  loss=3.137507 |g|=0.518	lr=1.20e-05 | 58.0%@S49  T=2.05s eta=00:59:08 | 69.6K token/s | 
[epoch_0]_59311  loss=3.132465 |g|=0.531	lr=1.20e-05 | 58.8%@S49  T=1.08s eta=00:30:54 | 69.9K token/s | 
[epoch_0]_59321  loss=3.030739 |g|=0.527	lr=1.20e-05 | 59.6%@S49  T=1.09s eta=00:31:06 | 70.2K token/s | 
[epoch_0]_59331  loss=3.105091 |g|=0.494	lr=1.19e-05 | 60.4%@S49  T=1.05s eta=00:29:56 | 70.6K token/s | 
[epoch_0]_59341  loss=3.008437 |g|=0.507	lr=1.19e-05 | 61.2%@S49  T=1.07s eta=00:30:13 | 70.9K token/s | 
[epoch_0]_59351  loss=3.048336 |g|=0.526	lr=1.19e-05 | 62.0%@S49  T=1.12s eta=00:31:30 | 71.0K token/s | 
[epoch_0]_59361  loss=3.109772 |g|=0.5	lr=1.19e-05 | 62.9%@S49  T=1.07s eta=00:29:45 | 71.3K token/s | 
[epoch_0]_59371  loss=3.162416 |g|=0.528	lr=1.19e-05 | 63.7%@S49  T=1.07s eta=00:29:38 | 71.5K token/s | 
[epoch_0]_59381  loss=3.129502 |g|=0.495	lr=1.18e-05 | 64.5%@S49  T=1.11s eta=00:30:30 | 71.7K token/s | 
[epoch_0]_59391  loss=3.011738 |g|=0.552	lr=1.18e-05 | 65.3%@S49  T=1.10s eta=00:30:05 | 71.8K token/s | 
[Fuyou] head="5" update algorithm=4 t=2.79s
[eval] 
	 Loss@"edu_fineweb1B"=3.138(0.00045) nBranch=1 nToken=4.01M best=3.1383(295) E2T=0.139 T=13.4188(0)s x=0
	#3.13782±0.1085 tps=299K(4.01408M) a=[2.96127,3.43211] T=13.4188(sec)
[Section@59400] layer[0-6] tasks=15(nPassBack=0) last_loss=2.9991(0.17882) N=(580,50400,49980 5939900)
[epoch_0]_59401  loss=3.102056 |g|=0.529	lr=1.18e-05 | 66.1%@S49  T=4.27s eta=01:56:09 | 69.2K token/s | 
[epoch_0]_59411  loss=3.150046 |g|=0.552	lr=1.18e-05 | 67.0%@S49  T=1.12s eta=00:30:15 | 69.4K token/s | 
[epoch_0]_59421  loss=3.092657 |g|=0.492	lr=1.17e-05 | 67.8%@S49  T=1.12s eta=00:30:00 | 69.6K token/s | 
[epoch_0]_59431  loss=3.031973 |g|=0.527	lr=1.17e-05 | 68.6%@S49  T=1.07s eta=00:28:34 | 69.9K token/s | 
[epoch_0]_59441  loss=3.096421 |g|=0.53	lr=1.17e-05 | 69.4%@S49  T=1.08s eta=00:28:42 | 70.2K token/s | 
[epoch_0]_59451  loss=3.161484 |g|=0.506	lr=1.17e-05 | 70.2%@S49  T=1.26s eta=00:33:18 | 70.0K token/s | 
[epoch_0]_59461  loss=3.063224 |g|=0.512	lr=1.17e-05 | 71.1%@S49  T=1.07s eta=00:28:11 | 70.3K token/s | 
[epoch_0]_59471  loss=3.258021 |g|=0.507	lr=1.16e-05 | 71.9%@S49  T=1.07s eta=00:27:53 | 70.6K token/s | 
[epoch_0]_59481  loss=3.103543 |g|=0.507	lr=1.16e-05 | 72.7%@S49  T=1.11s eta=00:28:43 | 70.8K token/s | 
[epoch_0]_59491  loss=3.128954 |g|=0.51	lr=1.16e-05 | 73.5%@S49  T=1.12s eta=00:28:46 | 70.9K token/s | 
[Fuyou] head="0" update algorithm=4 t=2.08s
[Section@59500] layer[6-12] tasks=15(nPassBack=0) last_loss=3.00202(0.133389) N=(580,50484,50064 5949900)
[epoch_0]_59501  loss=3.076211 |g|=0.531	lr=1.16e-05 | 74.3%@S49  T=1.44s eta=00:36:49 | 70.2K token/s | 
[epoch_0]_59511  loss=3.073943 |g|=0.508	lr=1.16e-05 | 75.2%@S49  T=1.06s eta=00:27:02 | 70.5K token/s | 
[epoch_0]_59521  loss=3.100462 |g|=0.511	lr=1.15e-05 | 76.0%@S49  T=1.09s eta=00:27:33 | 70.7K token/s | 
[epoch_0]_59531  loss=3.131122 |g|=0.5	lr=1.15e-05 | 76.8%@S49  T=1.13s eta=00:28:23 | 70.8K token/s | 
[epoch_0]_59541  loss=3.058035 |g|=0.505	lr=1.15e-05 | 77.6%@S49  T=1.06s eta=00:26:25 | 71.1K token/s | 
[epoch_0]_59551  loss=3.112203 |g|=0.509	lr=1.15e-05 | 78.4%@S49  T=1.08s eta=00:26:42 | 71.4K token/s | 
[epoch_0]_59561  loss=3.131645 |g|=0.503	lr=1.15e-05 | 79.3%@S49  T=1.11s eta=00:27:19 | 71.5K token/s | 
[epoch_0]_59571  loss=3.148662 |g|=0.499	lr=1.14e-05 | 80.1%@S49  T=1.06s eta=00:25:56 | 71.8K token/s | 
[epoch_0]_59581  loss=3.121800 |g|=0.51	lr=1.14e-05 | 80.9%@S49  T=1.17s eta=00:28:20 | 71.7K token/s | 
[epoch_0]_59591  loss=3.154166 |g|=0.51	lr=1.14e-05 | 81.7%@S49  T=1.07s eta=00:25:50 | 71.9K token/s | 
[Fuyou] head="1" update algorithm=4 t=2.06s
[eval] 
	 Loss@"edu_fineweb1B"=3.137(0.00049) nBranch=1 nToken=4.01M best=3.1378(296) E2T=0.0747 T=13.4792(0)s x=0
	#3.13733±0.1083 tps=298K(4.01408M) a=[2.96124,3.43135] T=13.4792(sec)
[Section@59600] layer[12-18] tasks=15(nPassBack=0) last_loss=3.06265(0.0380592) N=(580,50568,50148 5959900)
[epoch_0]_59601  loss=2.970156 |g|=0.513	lr=1.14e-05 | 82.5%@S49  T=4.38s eta=01:44:39 | 69.2K token/s | 
[epoch_0]_59611  loss=3.120443 |g|=0.498	lr=1.14e-05 | 83.3%@S49  T=1.07s eta=00:25:27 | 69.6K token/s | 
[epoch_0]_59621  loss=3.178289 |g|=0.516	lr=1.13e-05 | 84.2%@S49  T=1.08s eta=00:25:28 | 69.9K token/s | 
[epoch_0]_59631  loss=3.147872 |g|=0.525	lr=1.13e-05 | 85.0%@S49  T=1.42s eta=00:33:15 | 69.3K token/s | 
[epoch_0]_59641  loss=3.126482 |g|=0.508	lr=1.13e-05 | 85.8%@S49  T=1.06s eta=00:24:31 | 69.7K token/s | 
[epoch_0]_59651  loss=3.055444 |g|=0.507	lr=1.13e-05 | 86.6%@S49  T=1.09s eta=00:25:03 | 70.0K token/s | 
[epoch_0]_59661  loss=3.050158 |g|=0.512	lr=1.13e-05 | 87.4%@S49  T=1.17s eta=00:26:53 | 70.0K token/s | 
[epoch_0]_59671  loss=3.009594 |g|=0.505	lr=1.12e-05 | 88.3%@S49  T=1.09s eta=00:24:47 | 70.2K token/s | 
[epoch_0]_59681  loss=3.167046 |g|=0.506	lr=1.12e-05 | 89.1%@S49  T=1.06s eta=00:23:56 | 70.6K token/s | 
[epoch_0]_59691  loss=3.122792 |g|=0.507	lr=1.12e-05 | 89.9%@S49  T=1.08s eta=00:24:16 | 70.8K token/s | 
[Fuyou] head="2" update algorithm=4 t=1.99s
[Section@59700] layer[18-24] tasks=15(nPassBack=0) last_loss=3.10638(-0.0651667) N=(580,50652,50232 5969900)
[epoch_0]_59701  loss=3.046604 |g|=0.522	lr=1.12e-05 | 90.7%@S49  T=1.55s eta=00:34:24 | 69.9K token/s | 
[epoch_0]_59711  loss=3.097883 |g|=0.495	lr=1.12e-05 | 91.5%@S49  T=1.09s eta=00:24:03 | 70.2K token/s | 
[epoch_0]_59721  loss=3.113962 |g|=0.53	lr=1.12e-05 | 92.4%@S49  T=1.09s eta=00:23:52 | 70.5K token/s | 
[epoch_0]_59731  loss=3.092219 |g|=0.504	lr=1.11e-05 | 93.2%@S49  T=1.24s eta=00:26:53 | 70.2K token/s | 
[epoch_0]_59741  loss=3.052840 |g|=0.528	lr=1.11e-05 | 94.0%@S49  T=1.07s eta=00:22:58 | 70.6K token/s | 
[epoch_0]_59751  loss=3.166317 |g|=0.516	lr=1.11e-05 | 94.8%@S49  T=1.07s eta=00:22:50 | 70.9K token/s | 
[epoch_0]_59761  loss=3.155191 |g|=0.524	lr=1.11e-05 | 95.6%@S49  T=1.10s eta=00:23:24 | 71.1K token/s | 
[epoch_0]_59771  loss=3.002438 |g|=0.486	lr=1.11e-05 | 96.5%@S49  T=1.10s eta=00:23:09 | 71.2K token/s | 
[epoch_0]_59781  loss=3.069762 |g|=0.502	lr=1.11e-05 | 97.3%@S49  T=1.07s eta=00:22:26 | 71.5K token/s | 
[epoch_0]_59791  loss=3.091914 |g|=0.524	lr=1.10e-05 | 98.1%@S49  T=1.08s eta=00:22:24 | 71.7K token/s | 
[Fuyou] head="3" update algorithm=4 t=2.22s
[eval] 
	 Loss@"edu_fineweb1B"=3.137(0.00037) nBranch=1 nToken=4.01M best=3.1373(297) E2T=0.013 T=13.4365(0)s x=0
	#3.13696±0.1085 tps=299K(4.01408M) a=[2.9608,3.43073] T=13.4365(sec)
[Section@59800] layer[24-30] tasks=15(nPassBack=0) last_loss=3.12393(-0.0124619) N=(580,50736,50316 5979900)
[epoch_0]_59801  loss=3.131745 |g|=0.521	lr=1.10e-05 | 98.9%@S49  T=4.23s eta=01:27:05 | 69.1K token/s | 
[epoch_0]_59811  loss=3.102638 |g|=0.518	lr=1.10e-05 | 99.7%@S49  T=1.09s eta=00:22:14 | 69.4K token/s | 
[epoch_0]_59814  loss=3.112950 |g|=0.53	lr=1.10e-05 | 100.0%@S49  T=1.13s eta=00:22:57 | 69.5K token/s | 
-------- End of shard_49@"./Datasets/edu_fineweb1B/edu_fineweb_train_000806.bin"-------- 
[shard-50]@"./Datasets/edu_fineweb1B/edu_fineweb_train_000807.bin": tokens=100(M) nShardSamples=1220(4882800) 
[epoch_0]_59821  loss=3.133290 |g|=0.516	lr=1.10e-05 | 0.5%@S50  T=1.08s eta=00:21:49 | 69.9K token/s | 
[epoch_0]_59831  loss=3.093491 |g|=0.5	lr=1.10e-05 | 1.4%@S50  T=1.05s eta=00:21:08 | 70.3K token/s | 
[epoch_0]_59841  loss=3.079449 |g|=0.525	lr=1.10e-05 | 2.2%@S50  T=1.08s eta=00:21:31 | 70.5K token/s | 
[epoch_0]_59851  loss=3.097248 |g|=0.51	lr=1.09e-05 | 3.0%@S50  T=1.12s eta=00:22:10 | 70.6K token/s | 
[epoch_0]_59861  loss=3.132114 |g|=0.493	lr=1.09e-05 | 3.8%@S50  T=1.06s eta=00:20:39 | 71.0K token/s | 
[epoch_0]_59871  loss=3.122569 |g|=0.526	lr=1.09e-05 | 4.6%@S50  T=1.07s eta=00:20:40 | 71.3K token/s | 
[epoch_0]_59881  loss=3.028929 |g|=0.499	lr=1.09e-05 | 5.5%@S50  T=1.11s eta=00:21:17 | 71.4K token/s | 
[epoch_0]_59891  loss=3.095405 |g|=0.505	lr=1.09e-05 | 6.3%@S50  T=1.06s eta=00:20:09 | 71.7K token/s | 
[Fuyou] head="4" update algorithm=4 t=2.06s
[Section@59900] layer[30-36] tasks=15(nPassBack=0) last_loss=3.09115(0.0161452) N=(580,50820,50400 5989900)
[epoch_0]_59901  loss=3.120969 |g|=0.496	lr=1.09e-05 | 7.1%@S50  T=1.35s eta=00:25:27 | 71.2K token/s | 
[epoch_0]_59911  loss=3.110421 |g|=0.516	lr=1.08e-05 | 7.9%@S50  T=1.06s eta=00:19:56 | 71.5K token/s | 
[epoch_0]_59921  loss=3.156116 |g|=0.501	lr=1.08e-05 | 8.7%@S50  T=1.05s eta=00:19:33 | 71.8K token/s | 
[epoch_0]_59931  loss=3.172178 |g|=0.488	lr=1.08e-05 | 9.6%@S50  T=1.07s eta=00:19:42 | 72.0K token/s | 
[epoch_0]_59941  loss=3.174326 |g|=0.504	lr=1.08e-05 | 10.4%@S50  T=1.11s eta=00:20:16 | 72.1K token/s | 
[epoch_0]_59951  loss=3.110365 |g|=0.502	lr=1.08e-05 | 11.2%@S50  T=1.07s eta=00:19:20 | 72.3K token/s | 
[epoch_0]_59961  loss=3.111272 |g|=0.494	lr=1.08e-05 | 12.0%@S50  T=1.08s eta=00:19:14 | 72.5K token/s | 
[epoch_0]_59971  loss=3.120673 |g|=0.498	lr=1.08e-05 | 12.8%@S50  T=1.11s eta=00:19:46 | 72.6K token/s | 
[epoch_0]_59981  loss=3.102384 |g|=0.512	lr=1.07e-05 | 13.7%@S50  T=1.08s eta=00:19:01 | 72.7K token/s | 
[epoch_0]_59991  loss=3.075308 |g|=0.484	lr=1.07e-05 | 14.5%@S50  T=1.06s eta=00:18:22 | 73.0K token/s | 
[Fuyou] head="5" update algorithm=4 t=2.05s
[eval] 
	 Loss@"edu_fineweb1B"=3.138(-0.00059) nBranch=1 nToken=4.01M best=3.1373(297) E2T=-0.0456 T=13.4505(0)s x=0
	#3.13755±0.1085 tps=298K(4.01408M) a=[2.96237,3.43296] T=13.4505(sec)
[Section@60000] layer[0-6] tasks=15(nPassBack=0) last_loss=3.18317(-0.184074) N=(580,50904,50484 5999900)
[epoch_0]_60001  loss=3.106781 |g|=0.554	lr=1.07e-05 | 15.3%@S50  T=4.27s eta=01:13:36 | 70.3K token/s | 
[epoch_0]_60011  loss=3.057992 |g|=0.485	lr=1.07e-05 | 16.1%@S50  T=1.08s eta=00:18:30 | 70.5K token/s | 
[epoch_0]_60021  loss=3.128676 |g|=0.496	lr=1.07e-05 | 16.9%@S50  T=1.07s eta=00:18:07 | 70.8K token/s | 
[epoch_0]_60031  loss=3.191123 |g|=0.513	lr=1.07e-05 | 17.8%@S50  T=1.22s eta=00:20:21 | 70.7K token/s | 
[epoch_0]_60041  loss=3.121153 |g|=0.494	lr=1.07e-05 | 18.6%@S50  T=1.06s eta=00:17:32 | 71.0K token/s | 
[epoch_0]_60051  loss=3.161226 |g|=0.504	lr=1.06e-05 | 19.4%@S50  T=1.10s eta=00:17:59 | 71.2K token/s | 
[epoch_0]_60061  loss=3.096810 |g|=0.492	lr=1.06e-05 | 20.2%@S50  T=1.28s eta=00:20:48 | 70.8K token/s | 
[epoch_0]_60071  loss=3.106078 |g|=0.514	lr=1.06e-05 | 21.0%@S50  T=1.06s eta=00:17:05 | 71.1K token/s | 
[epoch_0]_60081  loss=3.093678 |g|=0.482	lr=1.06e-05 | 21.8%@S50  T=1.08s eta=00:17:08 | 71.4K token/s | 
[epoch_0]_60091  loss=3.102424 |g|=0.51	lr=1.06e-05 | 22.7%@S50  T=1.34s eta=00:21:04 | 70.9K token/s | 
[Fuyou] head="0" update algorithm=4 t=2.08s
[Section@60100] layer[6-12] tasks=15(nPassBack=0) last_loss=3.13926(-0.137231) N=(580,50988,50568 6009900)
[epoch_0]_60101  loss=3.088334 |g|=0.496	lr=1.06e-05 | 23.5%@S50  T=1.46s eta=00:22:41 | 70.1K token/s | 
[epoch_0]_60111  loss=3.122360 |g|=0.493	lr=1.06e-05 | 24.3%@S50  T=1.06s eta=00:16:23 | 70.5K token/s | 
[epoch_0]_60121  loss=3.117139 |g|=0.495	lr=1.06e-05 | 25.1%@S50  T=1.08s eta=00:16:26 | 70.7K token/s | 
[epoch_0]_60131  loss=3.092989 |g|=0.498	lr=1.05e-05 | 25.9%@S50  T=1.09s eta=00:16:24 | 71.0K token/s | 
[epoch_0]_60141  loss=3.066100 |g|=0.494	lr=1.05e-05 | 26.8%@S50  T=1.07s eta=00:15:54 | 71.2K token/s | 
[epoch_0]_60151  loss=3.145703 |g|=0.5	lr=1.05e-05 | 27.6%@S50  T=1.08s eta=00:15:55 | 71.5K token/s | 
[epoch_0]_60161  loss=3.099951 |g|=0.508	lr=1.05e-05 | 28.4%@S50  T=1.10s eta=00:16:05 | 71.6K token/s | 
[epoch_0]_60171  loss=3.050995 |g|=0.505	lr=1.05e-05 | 29.2%@S50  T=1.05s eta=00:15:11 | 71.9K token/s | 
[epoch_0]_60181  loss=3.104416 |g|=0.511	lr=1.05e-05 | 30.0%@S50  T=1.08s eta=00:15:20 | 72.1K token/s | 
[epoch_0]_60191  loss=3.077171 |g|=0.506	lr=1.05e-05 | 30.9%@S50  T=1.09s eta=00:15:22 | 72.3K token/s | 
[Fuyou] head="1" update algorithm=4 t=2.23s
[eval] 
	 Loss@"edu_fineweb1B"=3.138(-4.2e-05) nBranch=1 nToken=4.01M best=3.1373(297) E2T=0.0433 T=13.4605(0)s x=0
	#3.13759±0.1084 tps=298K(4.01408M) a=[2.96246,3.43259] T=13.4605(sec)
[Section@60200] layer[12-18] tasks=15(nPassBack=0) last_loss=3.09432(-0.031666) N=(580,51072,50652 6019900)
[epoch_0]_60201  loss=3.068622 |g|=0.54	lr=1.05e-05 | 31.7%@S50  T=4.23s eta=00:58:44 | 69.6K token/s | 
[epoch_0]_60211  loss=3.102287 |g|=0.507	lr=1.05e-05 | 32.5%@S50  T=1.08s eta=00:14:46 | 69.9K token/s | 
[epoch_0]_60221  loss=3.149108 |g|=0.505	lr=1.04e-05 | 33.3%@S50  T=1.07s eta=00:14:27 | 70.3K token/s | 
[epoch_0]_60231  loss=3.102394 |g|=0.49	lr=1.04e-05 | 34.1%@S50  T=1.08s eta=00:14:28 | 70.6K token/s | 
[epoch_0]_60241  loss=3.107265 |g|=0.498	lr=1.04e-05 | 35.0%@S50  T=1.08s eta=00:14:16 | 70.8K token/s | 
[epoch_0]_60251  loss=3.127249 |g|=0.513	lr=1.04e-05 | 35.8%@S50  T=1.12s eta=00:14:34 | 71.0K token/s | 
[epoch_0]_60261  loss=3.044704 |g|=0.488	lr=1.04e-05 | 36.6%@S50  T=1.07s eta=00:13:49 | 71.2K token/s | 
[epoch_0]_60271  loss=3.110891 |g|=0.522	lr=1.04e-05 | 37.4%@S50  T=1.09s eta=00:13:49 | 71.4K token/s | 
[epoch_0]_60281  loss=3.088035 |g|=0.527	lr=1.04e-05 | 38.2%@S50  T=1.14s eta=00:14:16 | 71.5K token/s | 
[epoch_0]_60291  loss=3.096063 |g|=0.494	lr=1.04e-05 | 39.1%@S50  T=1.08s eta=00:13:22 | 71.7K token/s | 
[Fuyou] head="2" update algorithm=4 t=2.04s
[Section@60300] layer[18-24] tasks=15(nPassBack=0) last_loss=3.08549(0.0208907) N=(580,51156,50736 6029900)
[epoch_0]_60301  loss=3.149506 |g|=0.556	lr=1.04e-05 | 39.9%@S50  T=1.67s eta=00:20:25 | 70.6K token/s | 
[epoch_0]_60311  loss=3.111103 |g|=0.517	lr=1.04e-05 | 40.7%@S50  T=1.05s eta=00:12:41 | 70.9K token/s | 
[epoch_0]_60321  loss=3.040581 |g|=0.504	lr=1.03e-05 | 41.5%@S50  T=1.12s eta=00:13:17 | 71.1K token/s | 
[epoch_0]_60331  loss=3.134715 |g|=0.511	lr=1.03e-05 | 42.3%@S50  T=1.06s eta=00:12:28 | 71.4K token/s | 
[epoch_0]_60341  loss=3.053771 |g|=0.527	lr=1.03e-05 | 43.1%@S50  T=1.08s eta=00:12:26 | 71.6K token/s | 
[epoch_0]_60351  loss=3.082401 |g|=0.519	lr=1.03e-05 | 44.0%@S50  T=1.14s eta=00:12:57 | 71.6K token/s | 
[epoch_0]_60361  loss=3.104186 |g|=0.506	lr=1.03e-05 | 44.8%@S50  T=1.08s eta=00:12:05 | 71.8K token/s | 
[epoch_0]_60371  loss=3.096432 |g|=0.513	lr=1.03e-05 | 45.6%@S50  T=1.08s eta=00:11:53 | 72.1K token/s | 
[epoch_0]_60381  loss=3.085783 |g|=0.505	lr=1.03e-05 | 46.4%@S50  T=1.10s eta=00:11:57 | 72.2K token/s | 
[epoch_0]_60391  loss=3.060191 |g|=0.511	lr=1.03e-05 | 47.2%@S50  T=1.10s eta=00:11:48 | 72.3K token/s | 
[Fuyou] head="3" update algorithm=4 t=2.09s
[eval] 
	 Loss@"edu_fineweb1B"=3.138(-0.00012) nBranch=1 nToken=4.01M best=3.1373(297) E2T=0.0385 T=13.4511(0)s x=0
	#3.13771±0.1085 tps=298K(4.01408M) a=[2.96228,3.43327] T=13.4511(sec)
[Section@60400] layer[24-30] tasks=15(nPassBack=0) last_loss=3.09919(0.0247362) N=(580,51240,50820 6039900)
[epoch_0]_60401  loss=3.075018 |g|=0.512	lr=1.03e-05 | 48.1%@S50  T=4.24s eta=00:44:50 | 69.7K token/s | 
[epoch_0]_60411  loss=3.064812 |g|=0.496	lr=1.03e-05 | 48.9%@S50  T=1.09s eta=00:11:20 | 69.9K token/s | 
[epoch_0]_60421  loss=3.182177 |g|=0.503	lr=1.03e-05 | 49.7%@S50  T=1.08s eta=00:11:01 | 70.2K token/s | 
[epoch_0]_60431  loss=3.160977 |g|=0.492	lr=1.02e-05 | 50.5%@S50  T=1.07s eta=00:10:46 | 70.5K token/s | 
[epoch_0]_60441  loss=3.057540 |g|=0.51	lr=1.02e-05 | 51.3%@S50  T=1.13s eta=00:11:11 | 70.6K token/s | 
[epoch_0]_60451  loss=3.120617 |g|=0.524	lr=1.02e-05 | 52.2%@S50  T=1.07s eta=00:10:26 | 70.9K token/s | 
[epoch_0]_60461  loss=3.067510 |g|=0.503	lr=1.02e-05 | 53.0%@S50  T=1.08s eta=00:10:17 | 71.2K token/s | 
[epoch_0]_60471  loss=3.103642 |g|=0.524	lr=1.02e-05 | 53.8%@S50  T=1.12s eta=00:10:33 | 71.3K token/s | 
[epoch_0]_60481  loss=3.066115 |g|=0.502	lr=1.02e-05 | 54.6%@S50  T=1.08s eta=00:09:55 | 71.5K token/s | 
[epoch_0]_60491  loss=3.112216 |g|=0.519	lr=1.02e-05 | 55.4%@S50  T=1.06s eta=00:09:36 | 71.8K token/s | 
[Fuyou] head="4" update algorithm=4 t=2.01s
[Section@60500] layer[30-36] tasks=15(nPassBack=0) last_loss=3.01157(0.079582) N=(580,51324,50904 6049900)
[epoch_0]_60501  loss=3.146923 |g|=0.527	lr=1.02e-05 | 56.3%@S50  T=1.43s eta=00:12:45 | 71.1K token/s | 
[epoch_0]_60511  loss=3.086919 |g|=0.539	lr=1.02e-05 | 57.1%@S50  T=1.06s eta=00:09:13 | 71.4K token/s | 
[epoch_0]_60521  loss=3.126597 |g|=0.504	lr=1.02e-05 | 57.9%@S50  T=1.07s eta=00:09:12 | 71.6K token/s | 
[epoch_0]_60531  loss=3.068822 |g|=0.51	lr=1.02e-05 | 58.7%@S50  T=1.07s eta=00:09:00 | 71.9K token/s | 
[epoch_0]_60541  loss=3.098759 |g|=0.491	lr=1.02e-05 | 59.5%@S50  T=1.12s eta=00:09:11 | 72.0K token/s | 
[epoch_0]_60551  loss=3.112390 |g|=0.51	lr=1.02e-05 | 60.4%@S50  T=1.07s eta=00:08:36 | 72.2K token/s | 
[epoch_0]_60561  loss=3.067107 |g|=0.494	lr=1.02e-05 | 61.2%@S50  T=1.06s eta=00:08:21 | 72.5K token/s | 
[epoch_0]_60571  loss=3.059133 |g|=0.494	lr=1.01e-05 | 62.0%@S50  T=1.10s eta=00:08:28 | 72.6K token/s | 
[epoch_0]_60581  loss=3.080642 |g|=0.502	lr=1.01e-05 | 62.8%@S50  T=1.12s eta=00:08:30 | 72.6K token/s | 
[epoch_0]_60591  loss=3.110334 |g|=0.502	lr=1.01e-05 | 63.6%@S50  T=1.07s eta=00:07:55 | 72.8K token/s | 
[Fuyou] head="5" update algorithm=4 t=2.07s
[eval] 
	 Loss@"edu_fineweb1B"=3.138(0.00012) nBranch=1 nToken=4.01M best=3.1373(297) E2T=0.0555 T=13.4429(0)s x=0
	#3.13759±0.1085 tps=299K(4.01408M) a=[2.96195,3.43178] T=13.4429(sec)
[Section@60600] layer[0-6] tasks=15(nPassBack=0) last_loss=3.08212(0.101049) N=(580,51408,50988 6059900)
[epoch_0]_60601  loss=3.110550 |g|=0.533	lr=1.01e-05 | 64.4%@S50  T=4.21s eta=00:30:28 | 70.1K token/s | 
[epoch_0]_60611  loss=3.195761 |g|=0.5	lr=1.01e-05 | 65.3%@S50  T=1.05s eta=00:07:26 | 70.5K token/s | 
[epoch_0]_60621  loss=3.138767 |g|=0.49	lr=1.01e-05 | 66.1%@S50  T=1.07s eta=00:07:24 | 70.8K token/s | 
[epoch_0]_60631  loss=3.154424 |g|=0.498	lr=1.01e-05 | 66.9%@S50  T=1.06s eta=00:07:08 | 71.1K token/s | 
[epoch_0]_60641  loss=3.126762 |g|=0.486	lr=1.01e-05 | 67.7%@S50  T=1.08s eta=00:07:05 | 71.4K token/s | 
[epoch_0]_60651  loss=3.069459 |g|=0.502	lr=1.01e-05 | 68.5%@S50  T=1.10s eta=00:07:03 | 71.5K token/s | 
[epoch_0]_60661  loss=3.114745 |g|=0.502	lr=1.01e-05 | 69.4%@S50  T=1.11s eta=00:06:56 | 71.6K token/s | 
[epoch_0]_60671  loss=3.102799 |g|=0.496	lr=1.01e-05 | 70.2%@S50  T=1.07s eta=00:06:31 | 71.8K token/s | 
[epoch_0]_60681  loss=3.090974 |g|=0.498	lr=1.01e-05 | 71.0%@S50  T=1.08s eta=00:06:22 | 72.0K token/s | 
[epoch_0]_60691  loss=3.115970 |g|=0.497	lr=1.01e-05 | 71.8%@S50  T=1.13s eta=00:06:30 | 72.1K token/s | 
[Fuyou] head="0" update algorithm=4 t=2.11s
[Section@60700] layer[6-12] tasks=15(nPassBack=0) last_loss=3.07581(0.0634451) N=(580,51492,51072 6069900)
[epoch_0]_60701  loss=3.102385 |g|=0.503	lr=1.01e-05 | 72.6%@S50  T=1.45s eta=00:08:03 | 71.3K token/s | 
[epoch_0]_60711  loss=3.112563 |g|=0.491	lr=1.01e-05 | 73.5%@S50  T=1.07s eta=00:05:47 | 71.5K token/s | 
[epoch_0]_60721  loss=3.058902 |g|=0.511	lr=1.01e-05 | 74.3%@S50  T=1.12s eta=00:05:52 | 71.6K token/s | 
[epoch_0]_60731  loss=3.112797 |g|=0.498	lr=1.01e-05 | 75.1%@S50  T=1.08s eta=00:05:27 | 71.8K token/s | 
[epoch_0]_60741  loss=3.035264 |g|=0.518	lr=1.01e-05 | 75.9%@S50  T=1.08s eta=00:05:16 | 72.0K token/s | 
[epoch_0]_60751  loss=3.139986 |g|=0.508	lr=1.01e-05 | 76.7%@S50  T=1.09s eta=00:05:09 | 72.2K token/s | 
[epoch_0]_60761  loss=3.161437 |g|=0.505	lr=1.01e-05 | 77.6%@S50  T=1.14s eta=00:05:12 | 72.2K token/s | 
[epoch_0]_60771  loss=3.036878 |g|=0.501	lr=1.00e-05 | 78.4%@S50  T=1.07s eta=00:04:43 | 72.4K token/s | 
[epoch_0]_60781  loss=3.112173 |g|=0.524	lr=1.00e-05 | 79.2%@S50  T=1.07s eta=00:04:31 | 72.6K token/s | 
[epoch_0]_60791  loss=3.148616 |g|=0.499	lr=1.00e-05 | 80.0%@S50  T=1.13s eta=00:04:35 | 72.6K token/s | 
[Fuyou] head="1" update algorithm=4 t=2.37s
[eval] 
	 Loss@"edu_fineweb1B"=3.138(5e-05) nBranch=1 nToken=4.01M best=3.1373(297) E2T=0.0733 T=13.4296(0)s x=0
	#3.13754±0.1084 tps=299K(4.01408M) a=[2.96301,3.43273] T=13.4296(sec)
[Section@60800] layer[12-18] tasks=15(nPassBack=0) last_loss=3.06423(0.0300944) N=(580,51576,51156 6079900)
[epoch_0]_60801  loss=3.137873 |g|=0.497	lr=1.00e-05 | 80.8%@S50  T=4.21s eta=00:16:25 | 69.9K token/s | 
[epoch_0]_60811  loss=3.110110 |g|=0.515	lr=1.00e-05 | 81.7%@S50  T=1.08s eta=00:04:02 | 70.2K token/s | 
[epoch_0]_60821  loss=3.163605 |g|=0.523	lr=1.00e-05 | 82.5%@S50  T=1.10s eta=00:03:54 | 70.5K token/s | 
[epoch_0]_60831  loss=3.091427 |g|=0.53	lr=1.00e-05 | 83.3%@S50  T=1.07s eta=00:03:37 | 70.8K token/s | 
[epoch_0]_60841  loss=3.091539 |g|=0.508	lr=1.00e-05 | 84.1%@S50  T=1.08s eta=00:03:29 | 71.0K token/s | 
[epoch_0]_60851  loss=3.105626 |g|=0.515	lr=1.00e-05 | 84.9%@S50  T=1.10s eta=00:03:22 | 71.2K token/s | 
[epoch_0]_60861  loss=3.051508 |g|=0.513	lr=1.00e-05 | 85.7%@S50  T=1.05s eta=00:03:02 | 71.5K token/s | 
[epoch_0]_60871  loss=3.250476 |g|=0.513	lr=1.00e-05 | 86.6%@S50  T=1.08s eta=00:02:56 | 71.8K token/s | 
[epoch_0]_60881  loss=3.127534 |g|=0.509	lr=1.00e-05 | 87.4%@S50  T=1.13s eta=00:02:54 | 71.8K token/s | 
[epoch_0]_60891  loss=3.111076 |g|=0.497	lr=1.00e-05 | 88.2%@S50  T=1.09s eta=00:02:37 | 72.0K token/s | 
[Fuyou] head="2" update algorithm=4 t=2.05s
[Section@60900] layer[18-24] tasks=15(nPassBack=0) last_loss=3.13181(-0.0463133) N=(580,51660,51240 6089900)
[epoch_0]_60901  loss=3.050710 |g|=0.493	lr=1.00e-05 | 89.0%@S50  T=1.34s eta=00:02:59 | 71.4K token/s | 
[epoch_0]_60911  loss=3.080105 |g|=0.501	lr=1.00e-05 | 89.8%@S50  T=1.36s eta=00:02:49 | 70.8K token/s | 
[epoch_0]_60921  loss=3.076399 |g|=0.5	lr=1.00e-05 | 90.7%@S50  T=1.05s eta=00:02:00 | 71.2K token/s | 
[epoch_0]_60931  loss=3.152673 |g|=0.508	lr=1.00e-05 | 91.5%@S50  T=1.12s eta=00:01:56 | 71.3K token/s | 
[epoch_0]_60941  loss=3.087753 |g|=0.501	lr=1.00e-05 | 92.3%@S50  T=1.06s eta=00:01:39 | 71.6K token/s | 
[epoch_0]_60951  loss=3.268345 |g|=0.523	lr=1.00e-05 | 93.1%@S50  T=1.07s eta=00:01:30 | 71.8K token/s | 
[epoch_0]_60961  loss=3.051650 |g|=0.495	lr=1.00e-05 | 93.9%@S50  T=1.11s eta=00:01:21 | 71.9K token/s | 
[epoch_0]_60971  loss=3.124642 |g|=0.516	lr=1.00e-05 | 94.8%@S50  T=1.09s eta=00:01:09 | 72.1K token/s | 
[epoch_0]_60981  loss=3.101457 |g|=0.495	lr=1.00e-05 | 95.6%@S50  T=1.08s eta=58.56s | 72.3K token/s | 
[epoch_0]_60991  loss=3.038525 |g|=0.501	lr=1.00e-05 | 96.4%@S50  T=1.05s eta=46.31s | 72.5K token/s | 
[Fuyou] head="3" update algorithm=4 t=2.07s
[eval] 
	 Loss@"edu_fineweb1B"=3.137(4.6e-05) nBranch=1 nToken=4.01M best=3.1373(297) E2T=0.121 T=13.4738(0)s x=0
	#3.13749±0.1085 tps=298K(4.01408M) a=[2.96262,3.43307] T=13.4738(sec)
[Section@61000] layer[24-30] tasks=15(nPassBack=0) last_loss=3.01648(0.0827088) N=(580,51744,51324 6099900)
[epoch_0]_61001  loss=3.117532 |g|=0.53	lr=1.00e-05 | 97.2%@S50  T=4.23s eta=00:02:23 | 69.9K token/s | 
[epoch_0]_61011  loss=3.102544 |g|=0.506	lr=1.00e-05 | 98.0%@S50  T=1.07s eta=25.59s | 70.2K token/s | 
[epoch_0]_61021  loss=3.100230 |g|=0.5	lr=1.00e-05 | 98.9%@S50  T=1.06s eta=14.89s | 70.6K token/s | 
[epoch_0]_61031  loss=3.138119 |g|=0.512	lr=1.00e-05 | 99.7%@S50  T=1.15s eta=4.60s | 70.6K token/s | 
[epoch_0]_61034  loss=3.081864 |g|=0.515	lr=1.00e-05 | 99.9%@S50  T=1.07s eta=1.07s | 70.9K token/s | 
[epoch_0]_61035  loss=3.124380 |g|=0.492	lr=1.00e-05 | 100.0%@S50  T=1.07s eta=0.0ms | 71.2K token/s | 
[train]: End of all epochs. nEpoch=1 nIter=61035(0) nToken=5000(M)

[train]: Total time=19:44:56

free(): invalid pointer
