********************************************************************
*             Koifish-alpha (2025-09-16 by gcc 11.4.0)             *
*  SPDX-FileCopyrightText: 2023-2025 Yingshi Chen                  *
*  SPDX-License-Identifier: MIT                                    *
*  MAIL: gsp.cys@gmail.com                                         *
********************************************************************

{train::optimizatioin::method} = adamw
{train::batch} = 80
{train::epoch} = 1
{train::learning-rate} = 0.0006
{train::decay} = 0.1
{train::optimizatioin::grad_accumulation} = 1
{train::dump-every} = 10
{train::gpt-every} = -10
{seed} = 42
{threads} = 20
{train::optimizatioin::lars_ratio} = 0
{train::optimizatioin::ZMUV_ratio} = 0
{model::parameter::Layer} = 48
{Head} = 25
{Ffn} = 6400
{Ctx} = 1024
{model::fuyou::branch} = 8
{model::fuyou::crossover} = 0.6
{model::fuyou::mutation} = 0.001
{model::fuyou::social} = 2
{model::fuyou::method} = pso_ga
{model::fuyou::switch} = 100
{checkpoint::out} = ./hy-tmp/checkpoint/GPT2_1558M_
{checkpoint::save-every} = -500
[ARCH] sizeof(token)=4,sizeof(floatX)=2 sizeof(Grad)=2(2)
seed=42
{name} = edu_fineweb1B
{most} = 50
[GlobTokenset] edu_fineweb1B find 5G tokens @"./Datasets/edu_fineweb1B/*train*.bin"(50 files)
{name} = edu_fineweb1B
{eval-every} = 200
{samp} = 0.06
{most} = 1
[GlobTokenset] edu_fineweb1B find 0.1G tokens @"./Datasets/edu_fineweb1B/*val*.bin"(1 files)
DictVAE latent_dim=1600 Dialect=OFF
[shard-1]@"./Datasets/edu_fineweb1B/edu_fineweb_train_000001.bin": tokens=100(M) nShardSamples=1220(97656) 
[shard-1]@"./Datasets/edu_fineweb1B/edu_fineweb_val_000000.bin": tokens=100(M) nShardSamples=1220(97656) 
====== NO WIKI !!! ======
cudaGetDevice: _CUDA_FORCE_MMQ:    no
cudaGetDevice: _CUDA_FORCE_CUBLAS: no
cudaGetDevice: found 1 CUDA devices:
  Device 0: NVIDIA GeForce RTX 4090(23785.4M), compute capability 8.9, VMM: no
+-----------------------+----------------------------------------------------+
	君子不器 - "NVIDIA GeForce RTX 4090" 
	CUDA driver version / runtime version: 12.4 / 12.4
	CUDA capability major/minor version number: 8.9. ECC=1
	
	128 multiprocessors, 128 CUDA cores/MP, 16384 CUDA cores
	GPU max clock rate: 2520 MHz (2.52 GHz)
	Peak bandwidth 1008.1 GByte/s.	Memory clock rate: 10501 MHz (10.50 GHz)
	Memory bus width: 384-bit
	Global memory: 22684 MBytes (23785373696 Bytes)
	Constant memory: 64 KBytes (65536 Bytes)
	Shared memory per block: 48 KBytes (49152 Bytes)
	Shared memory per multiprocessor: 100 KBytes (102400 Bytes)
	L2 cache size: 73728 KBytes (75497472 Bytes)
	Total number of registers available per block: 65536
	Warp size: 32, Max number of threads per block: 1024
	Max number of threads per multiprocessor: 1536
	Max dimension size of a thread block (x,y,z): (1024, 1024, 64)
	Max dimension size of a grid size (x,y,z): (2147483647, 65535, 65535)
+-----------------------+----------------------------------------------------+
GPT2_model::InitModel: init model

LLaMetaInitModel: init model embed=1600 layer=48 ff=6400 tpFFN=5
	 type of FFN=Variation@last_layer
koifish::CLI_params: 
 n_ctx=1024 embd=1600 n_ff=6400 n_head=25 n_head_kv=25 n_layer=48(-1) f_norm_rms_eps=1e-05
 ROPE: type=0 freq_base=10000 freq_scale=1 n_rot=64
 SepQKV: type=1  
[Shuffle]: nSamp=97656 samp_0={69070848:1024} hash=0x553E93901E44DA9E
	model.out.weight =====> model.inp_embd.weight
[RLS]	Init [model.inp_embd,...,model.out.cls][Scheduling] MEM_STRATEGY=PRE_ALLOC_GPU UpdateParam=V1
[RLS]	nGuoke=0(0) Memory of GPU=4615.44M(free=19169.9M)


[Save] @"./hy-tmp/checkpoint/GPT2_1558M_latest.ck" nParams=772 nReloads=672  save_every=-500
	 cudaMalloc=1048.58M@tmpBT4c type=BF16(E8) shape=[80,1024,6400,1] sum=1.0489G
	 cudaMalloc=1048.58M@tmpFF1 type=BF16(E8) shape=[80,1024,6400,1] sum=2.09748G
	 cudaMalloc=160.973M@tmpTernary type=BF16(E8) shape=[1600,50304,1,1] sum=2.25845G
	 cudaMalloc=262.144M@tmpOutL type=BF16(E8) shape=[80,1024,1600,1] sum=2.5206G
	 cudaMalloc=1048.58M@tmpScratch/output type=BF16(E8) shape=[8,65536001,1,1] sum=3.56917G
	 cudaMalloc=262.144M@tmpDelta type=BF16(E8) shape=[80,1024,1600,1] sum=3.83132G
	 cudaMalloc=262.144M@tmpDelta2 type=BF16(E8) shape=[80,1024,1600,1] sum=4.09346G
>>>>>> ST_SERIALIZE save @"./hy-tmp/checkpoint/GPT2_1558M_latest.ck" nInit=0 ......>>>>>> saveto_ofs ......
	 0/773	"position_embd.weight"	 1/773	"model.inp_embd.weight"	 2/773	"model.blk.0.attn_norm.weight"	 3/773	"model.blk.0.attn_norm.bias"	 4/773	"model.blk.0.attn.wq.weight"	 5/773	"model.blk.0.attn.wq.bias"	 6/773	"model.blk.0.attn.wk.weight"	 7/773	"model.blk.0.attn.wk.bias"	 8/773	"model.blk.0.attn.wv.weight"	 9/773	"model.blk.0.attn.wv.bias"	 10/773	"model.blk.0.attn.wo.weight"	 11/773	"model.blk.0.attn.wo.bias"	 12/773	"model.blk.1.attn_norm.weight"	 13/773	"model.blk.0.ffn_norm.weight"	 14/773	"model.blk.0.ffn_norm.bias"	 15/773	"model.blk.0.ffn_down.weight"	 16/773	"model.blk.0.ffn_down.bias"	 17/773	"model.blk.0.ffn_up.weight"	 18/773	"model.blk.0.ffn_up.bias"	 19/773	"model.blk.1.attn_norm.bias"	 20/773	"model.blk.1.attn.wq.weight"	 21/773	"model.blk.1.attn.wq.bias"	 22/773	"model.blk.1.attn.wk.weight"	 23/773	"model.blk.1.attn.wk.bias"	 24/773	"model.blk.1.attn.wv.weight"	 25/773	"model.blk.1.attn.wv.bias"	 26/773	"model.blk.1.attn.wo.weight"	 27/773	"model.blk.1.attn.wo.bias"	 28/773	"model.blk.2.attn_norm.weight"	 29/773	"model.blk.1.ffn_norm.weight"	 30/773	"model.blk.1.ffn_norm.bias"	 31/773	"model.blk.1.ffn_down.weight"	 32/773	"model.blk.1.ffn_down.bias"	 33/773	"model.blk.1.ffn_up.weight"	 34/773	"model.blk.1.ffn_up.bias"	 35/773	"model.blk.2.attn_norm.bias"	 36/773	"model.blk.2.attn.wq.weight"	 37/773	"model.blk.2.attn.wq.bias"	 38/773	"model.blk.2.attn.wk.weight"	 39/773	"model.blk.2.attn.wk.bias"	 40/773	"model.blk.2.attn.wv.weight"	 41/773	"model.blk.2.attn.wv.bias"	 42/773	"model.blk.2.attn.wo.weight"	 43/773	"model.blk.2.attn.wo.bias"	 44/773	"model.blk.2.ffn_norm.weight"	 45/773	"model.blk.2.ffn_norm.bias"	 46/773	"model.blk.2.ffn_down.weight"	 47/773	"model.blk.2.ffn_down.bias"	 48/773	"model.blk.2.ffn_up.weight"	 49/773	"model.blk.2.ffn_up.bias"	 50/773	"model.blk.3.attn_norm.weight"	 51/773	"model.blk.3.attn_norm.bias"	 52/773	"model.blk.3.attn.wq.weight"	 53/773	"model.blk.3.attn.wq.bias"	 54/773	"model.blk.3.attn.wk.weight"	 55/773	"model.blk.3.attn.wk.bias"	 56/773	"model.blk.3.attn.wv.weight"	 57/773	"model.blk.3.attn.wv.bias"	 58/773	"model.blk.3.attn.wo.weight"	 59/773	"model.blk.3.attn.wo.bias"	 60/773	"model.blk.3.ffn_norm.weight"	 61/773	"model.blk.3.ffn_norm.bias"	 62/773	"model.blk.3.ffn_down.weight"	 63/773	"model.blk.3.ffn_down.bias"	 64/773	"model.blk.3.ffn_up.weight"	 65/773	"model.blk.3.ffn_up.bias"	 66/773	"model.blk.4.attn_norm.weight"	 67/773	"model.blk.4.attn_norm.bias"	 68/773	"model.blk.4.attn.wq.weight"	 69/773	"model.blk.4.attn.wq.bias"	 70/773	"model.blk.4.attn.wk.weight"	 71/773	"model.blk.4.attn.wk.bias"	 72/773	"model.blk.4.attn.wv.weight"	 73/773	"model.blk.4.attn.wv.bias"	 74/773	"model.blk.4.attn.wo.weight"	 75/773	"model.blk.4.attn.wo.bias"	 76/773	"model.blk.4.ffn_norm.weight"	 77/773	"model.blk.4.ffn_norm.bias"	 78/773	"model.blk.4.ffn_down.weight"	 79/773	"model.blk.4.ffn_down.bias"	 80/773	"model.blk.4.ffn_up.weight"	 81/773	"model.blk.4.ffn_up.bias"	 82/773	"model.blk.5.attn_norm.weight"	 83/773	"model.blk.5.attn_norm.bias"	 84/773	"model.blk.5.attn.wq.weight"	 85/773	"model.blk.5.attn.wq.bias"	 86/773	"model.blk.5.attn.wk.weight"	 87/773	"model.blk.5.attn.wk.bias"	 88/773	"model.blk.5.attn.wv.weight"	 89/773	"model.blk.5.attn.wv.bias"	 90/773	"model.blk.5.attn.wo.weight"	 91/773	"model.blk.5.attn.wo.bias"	 92/773	"model.blk.5.ffn_norm.weight"	 93/773	"model.blk.5.ffn_norm.bias"	 94/773	"model.blk.5.ffn_down.weight"	 95/773	"model.blk.5.ffn_down.bias"	 96/773	"model.blk.5.ffn_up.weight"	 97/773	"model.blk.5.ffn_up.bias"	 98/773	"model.blk.6.attn_norm.weight"	 99/773	"model.blk.6.attn_norm.bias"	 100/773	"model.blk.6.attn.wq.weight"	 101/773	"model.blk.6.attn.wq.bias"	 102/773	"model.blk.6.attn.wk.weight"	 103/773	"model.blk.6.attn.wk.bias"	 104/773	"model.blk.6.attn.wv.weight"	 105/773	"model.blk.6.attn.wv.bias"	 106/773	"model.blk.6.attn.wo.weight"	 107/773	"model.blk.6.attn.wo.bias"	 108/773	"model.blk.6.ffn_norm.weight"	 109/773	"model.blk.6.ffn_norm.bias"	 110/773	"model.blk.6.ffn_down.weight"	 111/773	"model.blk.6.ffn_down.bias"	 112/773	"model.blk.6.ffn_up.weight"	 113/773	"model.blk.6.ffn_up.bias"	 114/773	"model.blk.7.attn_norm.weight"	 115/773	"model.blk.7.attn_norm.bias"	 116/773	"model.blk.7.attn.wq.weight"	 117/773	"model.blk.7.attn.wq.bias"	 118/773	"model.blk.7.attn.wk.weight"	 119/773	"model.blk.7.attn.wk.bias"	 120/773	"model.blk.7.attn.wv.weight"	 121/773	"model.blk.7.attn.wv.bias"	 122/773	"model.blk.7.attn.wo.weight"	 123/773	"model.blk.7.attn.wo.bias"	 124/773	"model.blk.7.ffn_norm.weight"	 125/773	"model.blk.7.ffn_norm.bias"	 126/773	"model.blk.7.ffn_down.weight"	 127/773	"model.blk.7.ffn_down.bias"	 128/773	"model.blk.7.ffn_up.weight"	 129/773	"model.blk.7.ffn_up.bias"	 130/773	"model.blk.16.attn_norm.weight"	 131/773	"model.blk.16.attn_norm.bias"	 132/773	"model.blk.8.attn_norm.weight"	 133/773	"model.blk.8.attn_norm.bias"	 134/773	"model.blk.8.attn.wq.weight"	 135/773	"model.blk.8.attn.wq.bias"	 136/773	"model.blk.8.attn.wk.weight"	 137/773	"model.blk.8.attn.wk.bias"	 138/773	"model.blk.8.attn.wv.weight"	 139/773	"model.blk.8.attn.wv.bias"	 140/773	"model.blk.8.attn.wo.weight"	 141/773	"model.blk.8.attn.wo.bias"	 142/773	"model.blk.8.ffn_norm.weight"	 143/773	"model.blk.8.ffn_norm.bias"	 144/773	"model.blk.8.ffn_down.weight"	 145/773	"model.blk.8.ffn_down.bias"	 146/773	"model.blk.8.ffn_up.weight"	 147/773	"model.blk.8.ffn_up.bias"	 148/773	"model.blk.9.attn_norm.weight"	 149/773	"model.blk.9.attn_norm.bias"	 150/773	"model.blk.9.attn.wq.weight"	 151/773	"model.blk.9.attn.wq.bias"	 152/773	"model.blk.9.attn.wk.weight"	 153/773	"model.blk.9.attn.wk.bias"	 154/773	"model.blk.9.attn.wv.weight"	 155/773	"model.blk.9.attn.wv.bias"	 156/773	"model.blk.9.attn.wo.weight"	 157/773	"model.blk.9.attn.wo.bias"	 158/773	"model.blk.9.ffn_norm.weight"	 159/773	"model.blk.9.ffn_norm.bias"	 160/773	"model.blk.9.ffn_down.weight"	 161/773	"model.blk.9.ffn_down.bias"	 162/773	"model.blk.9.ffn_up.weight"	 163/773	"model.blk.9.ffn_up.bias"	 164/773	"model.blk.10.attn_norm.weight"	 165/773	"model.blk.10.attn_norm.bias"	 166/773	"model.blk.10.attn.wq.weight"	 167/773	"model.blk.10.attn.wq.bias"	 168/773	"model.blk.10.attn.wk.weight"	 169/773	"model.blk.10.attn.wk.bias"	 170/773	"model.blk.10.attn.wv.weight"	 171/773	"model.blk.10.attn.wv.bias"	 172/773	"model.blk.10.attn.wo.weight"	 173/773	"model.blk.10.attn.wo.bias"	 174/773	"model.blk.10.ffn_norm.weight"	 175/773	"model.blk.10.ffn_norm.bias"	 176/773	"model.blk.10.ffn_down.weight"	 177/773	"model.blk.10.ffn_down.bias"	 178/773	"model.blk.10.ffn_up.weight"	 179/773	"model.blk.10.ffn_up.bias"	 180/773	"model.blk.11.attn_norm.weight"	 181/773	"model.blk.11.attn_norm.bias"	 182/773	"model.blk.11.attn.wq.weight"	 183/773	"model.blk.11.attn.wq.bias"	 184/773	"model.blk.11.attn.wk.weight"	 185/773	"model.blk.11.attn.wk.bias"	 186/773	"model.blk.11.attn.wv.weight"	 187/773	"model.blk.11.attn.wv.bias"	 188/773	"model.blk.11.attn.wo.weight"	 189/773	"model.blk.11.attn.wo.bias"	 190/773	"model.blk.11.ffn_norm.weight"	 191/773	"model.blk.11.ffn_norm.bias"	 192/773	"model.blk.11.ffn_down.weight"	 193/773	"model.blk.11.ffn_down.bias"	 194/773	"model.blk.11.ffn_up.weight"	 195/773	"model.blk.11.ffn_up.bias"	 196/773	"model.blk.12.attn_norm.weight"	 197/773	"model.blk.12.attn_norm.bias"	 198/773	"model.blk.12.attn.wq.weight"	 199/773	"model.blk.12.attn.wq.bias"	 200/773	"model.blk.12.attn.wk.weight"	 201/773	"model.blk.12.attn.wk.bias"	 202/773	"model.blk.12.attn.wv.weight"	 203/773	"model.blk.12.attn.wv.bias"	 204/773	"model.blk.12.attn.wo.weight"	 205/773	"model.blk.12.attn.wo.bias"	 206/773	"model.blk.12.ffn_norm.weight"	 207/773	"model.blk.12.ffn_norm.bias"	 208/773	"model.blk.12.ffn_down.weight"	 209/773	"model.blk.12.ffn_down.bias"	 210/773	"model.blk.12.ffn_up.weight"	 211/773	"model.blk.12.ffn_up.bias"	 212/773	"model.blk.13.attn_norm.weight"	 213/773	"model.blk.13.attn_norm.bias"	 214/773	"model.blk.13.attn.wq.weight"	 215/773	"model.blk.13.attn.wq.bias"	 216/773	"model.blk.13.attn.wk.weight"	 217/773	"model.blk.13.attn.wk.bias"	 218/773	"model.blk.13.attn.wv.weight"	 219/773	"model.blk.13.attn.wv.bias"	 220/773	"model.blk.13.attn.wo.weight"	 221/773	"model.blk.13.attn.wo.bias"	 222/773	"model.blk.13.ffn_norm.weight"	 223/773	"model.blk.13.ffn_norm.bias"	 224/773	"model.blk.13.ffn_down.weight"	 225/773	"model.blk.13.ffn_down.bias"	 226/773	"model.blk.13.ffn_up.weight"	 227/773	"model.blk.13.ffn_up.bias"	 228/773	"model.blk.14.attn_norm.weight"	 229/773	"model.blk.14.attn_norm.bias"	 230/773	"model.blk.14.attn.wq.weight"	 231/773	"model.blk.14.attn.wq.bias"	 232/773	"model.blk.14.attn.wk.weight"	 233/773	"model.blk.14.attn.wk.bias"	 234/773	"model.blk.14.attn.wv.weight"	 235/773	"model.blk.14.attn.wv.bias"	 236/773	"model.blk.14.attn.wo.weight"	 237/773	"model.blk.14.attn.wo.bias"	 238/773	"model.blk.14.ffn_norm.weight"	 239/773	"model.blk.14.ffn_norm.bias"	 240/773	"model.blk.14.ffn_down.weight"	 241/773	"model.blk.14.ffn_down.bias"	 242/773	"model.blk.14.ffn_up.weight"	 243/773	"model.blk.14.ffn_up.bias"	 244/773	"model.blk.15.attn_norm.weight"	 245/773	"model.blk.15.attn_norm.bias"	 246/773	"model.blk.15.attn.wq.weight"	 247/773	"model.blk.15.attn.wq.bias"	 248/773	"model.blk.15.attn.wk.weight"	 249/773	"model.blk.15.attn.wk.bias"	 250/773	"model.blk.15.attn.wv.weight"	 251/773	"model.blk.15.attn.wv.bias"	 252/773	"model.blk.15.attn.wo.weight"	 253/773	"model.blk.15.attn.wo.bias"	 254/773	"model.blk.15.ffn_norm.weight"	 255/773	"model.blk.15.ffn_norm.bias"	 256/773	"model.blk.15.ffn_down.weight"	 257/773	"model.blk.15.ffn_down.bias"	 258/773	"model.blk.15.ffn_up.weight"	 259/773	"model.blk.15.ffn_up.bias"	 260/773	"model.blk.32.attn_norm.weight"	 261/773	"model.blk.16.attn.wq.weight"	 262/773	"model.blk.16.attn.wq.bias"	 263/773	"model.blk.16.attn.wk.weight"	 264/773	"model.blk.16.attn.wk.bias"	 265/773	"model.blk.16.attn.wv.weight"	 266/773	"model.blk.16.attn.wv.bias"	 267/773	"model.blk.16.attn.wo.weight"	 268/773	"model.blk.16.attn.wo.bias"	 269/773	"model.blk.16.ffn_norm.weight"	 270/773	"model.blk.16.ffn_norm.bias"	 271/773	"model.blk.16.ffn_down.weight"	 272/773	"model.blk.16.ffn_down.bias"	 273/773	"model.blk.16.ffn_up.weight"	 274/773	"model.blk.16.ffn_up.bias"	 275/773	"model.blk.17.attn_norm.weight"	 276/773	"model.blk.17.attn_norm.bias"	 277/773	"model.blk.17.attn.wq.weight"	 278/773	"model.blk.17.attn.wq.bias"	 279/773	"model.blk.17.attn.wk.weight"	 280/773	"model.blk.17.attn.wk.bias"	 281/773	"model.blk.17.attn.wv.weight"	 282/773	"model.blk.17.attn.wv.bias"	 283/773	"model.blk.17.attn.wo.weight"	 284/773	"model.blk.17.attn.wo.bias"	 285/773	"model.blk.17.ffn_norm.weight"	 286/773	"model.blk.17.ffn_norm.bias"	 287/773	"model.blk.17.ffn_down.weight"	 288/773	"model.blk.17.ffn_down.bias"	 289/773	"model.blk.17.ffn_up.weight"	 290/773	"model.blk.17.ffn_up.bias"	 291/773	"model.blk.18.attn_norm.weight"	 292/773	"model.blk.18.attn_norm.bias"	 293/773	"model.blk.18.attn.wq.weight"	 294/773	"model.blk.18.attn.wq.bias"	 295/773	"model.blk.18.attn.wk.weight"	 296/773	"model.blk.18.attn.wk.bias"	 297/773	"model.blk.18.attn.wv.weight"	 298/773	"model.blk.18.attn.wv.bias"	 299/773	"model.blk.18.attn.wo.weight"	 300/773	"model.blk.18.attn.wo.bias"	 301/773	"model.blk.18.ffn_norm.weight"	 302/773	"model.blk.18.ffn_norm.bias"	 303/773	"model.blk.18.ffn_down.weight"	 304/773	"model.blk.18.ffn_down.bias"	 305/773	"model.blk.18.ffn_up.weight"	 306/773	"model.blk.18.ffn_up.bias"	 307/773	"model.blk.19.attn_norm.weight"	 308/773	"model.blk.19.attn_norm.bias"	 309/773	"model.blk.19.attn.wq.weight"	 310/773	"model.blk.19.attn.wq.bias"	 311/773	"model.blk.19.attn.wk.weight"	 312/773	"model.blk.19.attn.wk.bias"	 313/773	"model.blk.19.attn.wv.weight"	 314/773	"model.blk.19.attn.wv.bias"	 315/773	"model.blk.19.attn.wo.weight"	 316/773	"model.blk.19.attn.wo.bias"	 317/773	"model.blk.19.ffn_norm.weight"	 318/773	"model.blk.19.ffn_norm.bias"	 319/773	"model.blk.19.ffn_down.weight"	 320/773	"model.blk.19.ffn_down.bias"	 321/773	"model.blk.19.ffn_up.weight"	 322/773	"model.blk.19.ffn_up.bias"	 323/773	"model.blk.20.attn_norm.weight"	 324/773	"model.blk.20.attn_norm.bias"	 325/773	"model.blk.20.attn.wq.weight"	 326/773	"model.blk.20.attn.wq.bias"	 327/773	"model.blk.20.attn.wk.weight"	 328/773	"model.blk.20.attn.wk.bias"	 329/773	"model.blk.20.attn.wv.weight"	 330/773	"model.blk.20.attn.wv.bias"	 331/773	"model.blk.20.attn.wo.weight"	 332/773	"model.blk.20.attn.wo.bias"	 333/773	"model.blk.20.ffn_norm.weight"	 334/773	"model.blk.20.ffn_norm.bias"	 335/773	"model.blk.20.ffn_down.weight"	 336/773	"model.blk.20.ffn_down.bias"	 337/773	"model.blk.20.ffn_up.weight"	 338/773	"model.blk.20.ffn_up.bias"	 339/773	"model.blk.21.attn_norm.weight"	 340/773	"model.blk.21.attn_norm.bias"	 341/773	"model.blk.21.attn.wq.weight"	 342/773	"model.blk.21.attn.wq.bias"	 343/773	"model.blk.21.attn.wk.weight"	 344/773	"model.blk.21.attn.wk.bias"	 345/773	"model.blk.21.attn.wv.weight"	 346/773	"model.blk.21.attn.wv.bias"	 347/773	"model.blk.21.attn.wo.weight"	 348/773	"model.blk.21.attn.wo.bias"	 349/773	"model.blk.43.attn_norm.bias"	 350/773	"model.blk.21.ffn_norm.weight"	 351/773	"model.blk.21.ffn_norm.bias"	 352/773	"model.blk.21.ffn_down.weight"	 353/773	"model.blk.21.ffn_down.bias"	 354/773	"model.blk.21.ffn_up.weight"	 355/773	"model.blk.21.ffn_up.bias"	 356/773	"model.blk.22.attn_norm.weight"	 357/773	"model.blk.22.attn_norm.bias"	 358/773	"model.blk.22.attn.wq.weight"	 359/773	"model.blk.22.attn.wq.bias"	 360/773	"model.blk.22.attn.wk.weight"	 361/773	"model.blk.22.attn.wk.bias"	 362/773	"model.blk.22.attn.wv.weight"	 363/773	"model.blk.22.attn.wv.bias"	 364/773	"model.blk.22.attn.wo.weight"	 365/773	"model.blk.22.attn.wo.bias"	 366/773	"model.blk.22.ffn_norm.weight"	 367/773	"model.blk.22.ffn_norm.bias"	 368/773	"model.blk.22.ffn_down.weight"	 369/773	"model.blk.22.ffn_down.bias"	 370/773	"model.blk.22.ffn_up.weight"	 371/773	"model.blk.22.ffn_up.bias"	 372/773	"model.blk.23.attn_norm.weight"	 373/773	"model.blk.23.attn_norm.bias"	 374/773	"model.blk.23.attn.wq.weight"	 375/773	"model.blk.23.attn.wq.bias"	 376/773	"model.blk.23.attn.wk.weight"	 377/773	"model.blk.23.attn.wk.bias"	 378/773	"model.blk.23.attn.wv.weight"	 379/773	"model.blk.23.attn.wv.bias"	 380/773	"model.blk.23.attn.wo.weight"	 381/773	"model.blk.23.attn.wo.bias"	 382/773	"model.blk.23.ffn_norm.weight"	 383/773	"model.blk.23.ffn_norm.bias"	 384/773	"model.blk.23.ffn_down.weight"	 385/773	"model.blk.23.ffn_down.bias"	 386/773	"model.blk.23.ffn_up.weight"	 387/773	"model.blk.23.ffn_up.bias"	 388/773	"model.blk.24.attn_norm.weight"	 389/773	"model.blk.24.attn_norm.bias"	 390/773	"model.blk.24.attn.wq.weight"	 391/773	"model.blk.24.attn.wq.bias"	 392/773	"model.blk.24.attn.wk.weight"	 393/773	"model.blk.24.attn.wk.bias"	 394/773	"model.blk.24.attn.wv.weight"	 395/773	"model.blk.24.attn.wv.bias"	 396/773	"model.blk.24.attn.wo.weight"	 397/773	"model.blk.24.attn.wo.bias"	 398/773	"model.blk.24.ffn_norm.weight"	 399/773	"model.blk.24.ffn_norm.bias"	 400/773	"model.blk.24.ffn_down.weight"	 401/773	"model.blk.24.ffn_down.bias"	 402/773	"model.blk.24.ffn_up.weight"	 403/773	"model.blk.24.ffn_up.bias"	 404/773	"model.blk.25.attn_norm.weight"	 405/773	"model.blk.25.attn_norm.bias"	 406/773	"model.blk.25.attn.wq.weight"	 407/773	"model.blk.25.attn.wq.bias"	 408/773	"model.blk.25.attn.wk.weight"	 409/773	"model.blk.25.attn.wk.bias"	 410/773	"model.blk.25.attn.wv.weight"	 411/773	"model.blk.25.attn.wv.bias"	 412/773	"model.blk.25.attn.wo.weight"	 413/773	"model.blk.25.attn.wo.bias"	 414/773	"model.blk.25.ffn_norm.weight"	 415/773	"model.blk.25.ffn_norm.bias"	 416/773	"model.blk.25.ffn_down.weight"	 417/773	"model.blk.25.ffn_down.bias"	 418/773	"model.blk.25.ffn_up.weight"	 419/773	"model.blk.25.ffn_up.bias"	 420/773	"model.blk.26.attn_norm.weight"	 421/773	"model.blk.26.attn_norm.bias"	 422/773	"model.blk.26.attn.wq.weight"	 423/773	"model.blk.26.attn.wq.bias"	 424/773	"model.blk.26.attn.wk.weight"	 425/773	"model.blk.26.attn.wk.bias"	 426/773	"model.blk.26.attn.wv.weight"	 427/773	"model.blk.26.attn.wv.bias"	 428/773	"model.blk.26.attn.wo.weight"	 429/773	"model.blk.26.attn.wo.bias"	 430/773	"model.blk.26.ffn_norm.weight"	 431/773	"model.blk.26.ffn_norm.bias"	 432/773	"model.blk.26.ffn_down.weight"	 433/773	"model.blk.26.ffn_down.bias"	 434/773	"model.blk.26.ffn_up.weight"	 435/773	"model.blk.26.ffn_up.bias"	 436/773	"model.blk.27.attn_norm.weight"	 437/773	"model.blk.27.attn_norm.bias"	 438/773	"model.blk.27.attn.wq.weight"	 439/773	"model.blk.27.attn.wq.bias"	 440/773	"model.blk.27.attn.wk.weight"	 441/773	"model.blk.27.attn.wk.bias"	 442/773	"model.blk.27.attn.wv.weight"	 443/773	"model.blk.27.attn.wv.bias"	 444/773	"model.blk.27.attn.wo.weight"	 445/773	"model.blk.27.attn.wo.bias"	 446/773	"model.blk.27.ffn_norm.weight"	 447/773	"model.blk.27.ffn_norm.bias"	 448/773	"model.blk.27.ffn_down.weight"	 449/773	"model.blk.27.ffn_down.bias"	 450/773	"model.blk.27.ffn_up.weight"	 451/773	"model.blk.27.ffn_up.bias"	 452/773	"model.blk.28.attn_norm.weight"	 453/773	"model.blk.28.attn_norm.bias"	 454/773	"model.blk.28.attn.wq.weight"	 455/773	"model.blk.28.attn.wq.bias"	 456/773	"model.blk.28.attn.wk.weight"	 457/773	"model.blk.28.attn.wk.bias"	 458/773	"model.blk.28.attn.wv.weight"	 459/773	"model.blk.28.attn.wv.bias"	 460/773	"model.blk.28.attn.wo.weight"	 461/773	"model.blk.28.attn.wo.bias"	 462/773	"model.blk.28.ffn_norm.weight"	 463/773	"model.blk.28.ffn_norm.bias"	 464/773	"model.blk.28.ffn_down.weight"	 465/773	"model.blk.28.ffn_down.bias"	 466/773	"model.blk.28.ffn_up.weight"	 467/773	"model.blk.28.ffn_up.bias"	 468/773	"model.blk.29.attn_norm.weight"	 469/773	"model.blk.29.attn_norm.bias"	 470/773	"model.blk.29.attn.wq.weight"	 471/773	"model.blk.29.attn.wq.bias"	 472/773	"model.blk.29.attn.wk.weight"	 473/773	"model.blk.29.attn.wk.bias"	 474/773	"model.blk.29.attn.wv.weight"	 475/773	"model.blk.29.attn.wv.bias"	 476/773	"model.blk.29.attn.wo.weight"	 477/773	"model.blk.29.attn.wo.bias"	 478/773	"model.blk.29.ffn_norm.weight"	 479/773	"model.blk.29.ffn_norm.bias"	 480/773	"model.blk.29.ffn_down.weight"	 481/773	"model.blk.29.ffn_down.bias"	 482/773	"model.blk.29.ffn_up.weight"	 483/773	"model.blk.29.ffn_up.bias"	 484/773	"model.blk.30.attn_norm.weight"	 485/773	"model.blk.30.attn_norm.bias"	 486/773	"model.blk.30.attn.wq.weight"	 487/773	"model.blk.30.attn.wq.bias"	 488/773	"model.blk.30.attn.wk.weight"	 489/773	"model.blk.30.attn.wk.bias"	 490/773	"model.blk.30.attn.wv.weight"	 491/773	"model.blk.30.attn.wv.bias"	 492/773	"model.blk.30.attn.wo.weight"	 493/773	"model.blk.30.attn.wo.bias"	 494/773	"model.blk.30.ffn_norm.weight"	 495/773	"model.blk.30.ffn_norm.bias"	 496/773	"model.blk.30.ffn_down.weight"	 497/773	"model.blk.30.ffn_down.bias"	 498/773	"model.blk.30.ffn_up.weight"	 499/773	"model.blk.30.ffn_up.bias"	 500/773	"model.blk.31.attn_norm.weight"	 501/773	"model.blk.31.attn_norm.bias"	 502/773	"model.blk.31.attn.wq.weight"	 503/773	"model.blk.31.attn.wq.bias"	 504/773	"model.blk.31.attn.wk.weight"	 505/773	"model.blk.31.attn.wk.bias"	 506/773	"model.blk.31.attn.wv.weight"	 507/773	"model.blk.31.attn.wv.bias"	 508/773	"model.blk.31.attn.wo.weight"	 509/773	"model.blk.31.attn.wo.bias"	 510/773	"model.blk.31.ffn_norm.weight"	 511/773	"model.blk.31.ffn_norm.bias"	 512/773	"model.blk.31.ffn_down.weight"	 513/773	"model.blk.31.ffn_down.bias"	 514/773	"model.blk.31.ffn_up.weight"	 515/773	"model.blk.31.ffn_up.bias"	 516/773	"model.blk.32.attn_norm.bias"	 517/773	"model.blk.32.attn.wq.weight"	 518/773	"model.blk.32.attn.wq.bias"	 519/773	"model.blk.32.attn.wk.weight"	 520/773	"model.blk.32.attn.wk.bias"	 521/773	"model.blk.32.attn.wv.weight"	 522/773	"model.blk.32.attn.wv.bias"	 523/773	"model.blk.32.attn.wo.weight"	 524/773	"model.blk.32.attn.wo.bias"	 525/773	"model.blk.32.ffn_norm.weight"	 526/773	"model.blk.32.ffn_norm.bias"	 527/773	"model.blk.32.ffn_down.weight"	 528/773	"model.blk.32.ffn_down.bias"	 529/773	"model.blk.32.ffn_up.weight"	 530/773	"model.blk.32.ffn_up.bias"	 531/773	"model.blk.33.attn_norm.weight"	 532/773	"model.blk.33.attn_norm.bias"	 533/773	"model.blk.33.attn.wq.weight"	 534/773	"model.blk.33.attn.wq.bias"	 535/773	"model.blk.33.attn.wk.weight"	 536/773	"model.blk.33.attn.wk.bias"	 537/773	"model.blk.33.attn.wv.weight"	 538/773	"model.blk.33.attn.wv.bias"	 539/773	"model.blk.33.attn.wo.weight"	 540/773	"model.blk.33.attn.wo.bias"	 541/773	"model.blk.33.ffn_norm.weight"	 542/773	"model.blk.33.ffn_norm.bias"	 543/773	"model.blk.33.ffn_down.weight"	 544/773	"model.blk.33.ffn_down.bias"	 545/773	"model.blk.33.ffn_up.weight"	 546/773	"model.blk.33.ffn_up.bias"	 547/773	"model.blk.34.attn_norm.weight"	 548/773	"model.blk.34.attn_norm.bias"	 549/773	"model.blk.34.attn.wq.weight"	 550/773	"model.blk.34.attn.wq.bias"	 551/773	"model.blk.34.attn.wk.weight"	 552/773	"model.blk.34.attn.wk.bias"	 553/773	"model.blk.34.attn.wv.weight"	 554/773	"model.blk.34.attn.wv.bias"	 555/773	"model.blk.34.attn.wo.weight"	 556/773	"model.blk.34.attn.wo.bias"	 557/773	"model.blk.34.ffn_norm.weight"	 558/773	"model.blk.34.ffn_norm.bias"	 559/773	"model.blk.34.ffn_down.weight"	 560/773	"model.blk.34.ffn_down.bias"	 561/773	"model.blk.34.ffn_up.weight"	 562/773	"model.blk.34.ffn_up.bias"	 563/773	"model.blk.35.attn_norm.weight"	 564/773	"model.blk.35.attn_norm.bias"	 565/773	"model.blk.35.attn.wq.weight"	 566/773	"model.blk.35.attn.wq.bias"	 567/773	"model.blk.35.attn.wk.weight"	 568/773	"model.blk.35.attn.wk.bias"	 569/773	"model.blk.35.attn.wv.weight"	 570/773	"model.blk.35.attn.wv.bias"	 571/773	"model.blk.35.attn.wo.weight"	 572/773	"model.blk.35.attn.wo.bias"	 573/773	"model.blk.35.ffn_norm.weight"	 574/773	"model.blk.35.ffn_norm.bias"	 575/773	"model.blk.35.ffn_down.weight"	 576/773	"model.blk.35.ffn_down.bias"	 577/773	"model.blk.35.ffn_up.weight"	 578/773	"model.blk.35.ffn_up.bias"	 579/773	"model.blk.36.attn_norm.weight"	 580/773	"model.blk.36.attn_norm.bias"	 581/773	"model.blk.36.attn.wq.weight"	 582/773	"model.blk.36.attn.wq.bias"	 583/773	"model.blk.36.attn.wk.weight"	 584/773	"model.blk.36.attn.wk.bias"	 585/773	"model.blk.36.attn.wv.weight"	 586/773	"model.blk.36.attn.wv.bias"	 587/773	"model.blk.36.attn.wo.weight"	 588/773	"model.blk.36.attn.wo.bias"	 589/773	"model.blk.36.ffn_norm.weight"	 590/773	"model.blk.36.ffn_norm.bias"	 591/773	"model.blk.36.ffn_down.weight"	 592/773	"model.blk.36.ffn_down.bias"	 593/773	"model.blk.36.ffn_up.weight"	 594/773	"model.blk.36.ffn_up.bias"	 595/773	"model.blk.37.attn_norm.weight"	 596/773	"model.blk.37.attn_norm.bias"	 597/773	"model.blk.37.attn.wq.weight"	 598/773	"model.blk.37.attn.wq.bias"	 599/773	"model.blk.37.attn.wk.weight"	 600/773	"model.blk.37.attn.wk.bias"	 601/773	"model.blk.37.attn.wv.weight"	 602/773	"model.blk.37.attn.wv.bias"	 603/773	"model.blk.37.attn.wo.weight"	 604/773	"model.blk.37.attn.wo.bias"	 605/773	"model.blk.37.ffn_norm.weight"	 606/773	"model.blk.37.ffn_norm.bias"	 607/773	"model.blk.37.ffn_down.weight"	 608/773	"model.blk.37.ffn_down.bias"	 609/773	"model.blk.37.ffn_up.weight"	 610/773	"model.blk.37.ffn_up.bias"	 611/773	"model.blk.38.attn_norm.weight"	 612/773	"model.blk.38.attn_norm.bias"	 613/773	"model.blk.38.attn.wq.weight"	 614/773	"model.blk.38.attn.wq.bias"	 615/773	"model.blk.38.attn.wk.weight"	 616/773	"model.blk.38.attn.wk.bias"	 617/773	"model.blk.38.attn.wv.weight"	 618/773	"model.blk.38.attn.wv.bias"	 619/773	"model.blk.38.attn.wo.weight"	 620/773	"model.blk.38.attn.wo.bias"	 621/773	"model.blk.38.ffn_norm.weight"	 622/773	"model.blk.38.ffn_norm.bias"	 623/773	"model.blk.38.ffn_down.weight"	 624/773	"model.blk.38.ffn_down.bias"	 625/773	"model.blk.38.ffn_up.weight"	 626/773	"model.blk.38.ffn_up.bias"	 627/773	"model.blk.39.attn_norm.weight"	 628/773	"model.blk.39.attn_norm.bias"	 629/773	"model.blk.39.attn.wq.weight"	 630/773	"model.blk.39.attn.wq.bias"	 631/773	"model.blk.39.attn.wk.weight"	 632/773	"model.blk.39.attn.wk.bias"	 633/773	"model.blk.39.attn.wv.weight"	 634/773	"model.blk.39.attn.wv.bias"	 635/773	"model.blk.39.attn.wo.weight"	 636/773	"model.blk.39.attn.wo.bias"	 637/773	"model.blk.39.ffn_norm.weight"	 638/773	"model.blk.39.ffn_norm.bias"	 639/773	"model.blk.39.ffn_down.weight"	 640/773	"model.blk.39.ffn_down.bias"	 641/773	"model.blk.39.ffn_up.weight"	 642/773	"model.blk.39.ffn_up.bias"	 643/773	"model.blk.40.attn_norm.weight"	 644/773	"model.blk.40.attn_norm.bias"	 645/773	"model.blk.40.attn.wq.weight"	 646/773	"model.blk.40.attn.wq.bias"	 647/773	"model.blk.40.attn.wk.weight"	 648/773	"model.blk.40.attn.wk.bias"	 649/773	"model.blk.40.attn.wv.weight"	 650/773	"model.blk.40.attn.wv.bias"	 651/773	"model.blk.40.attn.wo.weight"	 652/773	"model.blk.40.attn.wo.bias"	 653/773	"model.blk.40.ffn_norm.weight"	 654/773	"model.blk.40.ffn_norm.bias"	 655/773	"model.blk.40.ffn_down.weight"	 656/773	"model.blk.40.ffn_down.bias"	 657/773	"model.blk.40.ffn_up.weight"	 658/773	"model.blk.40.ffn_up.bias"	 659/773	"model.blk.41.attn_norm.weight"	 660/773	"model.blk.41.attn_norm.bias"	 661/773	"model.blk.41.attn.wq.weight"	 662/773	"model.blk.41.attn.wq.bias"	 663/773	"model.blk.41.attn.wk.weight"	 664/773	"model.blk.41.attn.wk.bias"	 665/773	"model.blk.41.attn.wv.weight"	 666/773	"model.blk.41.attn.wv.bias"	 667/773	"model.blk.41.attn.wo.weight"	 668/773	"model.blk.41.attn.wo.bias"	 669/773	"model.blk.41.ffn_norm.weight"	 670/773	"model.blk.41.ffn_norm.bias"	 671/773	"model.blk.41.ffn_down.weight"	 672/773	"model.blk.41.ffn_down.bias"	 673/773	"model.blk.41.ffn_up.weight"	 674/773	"model.blk.41.ffn_up.bias"	 675/773	"model.blk.42.attn_norm.weight"	 676/773	"model.blk.42.attn_norm.bias"	 677/773	"model.blk.42.attn.wq.weight"	 678/773	"model.blk.42.attn.wq.bias"	 679/773	"model.blk.42.attn.wk.weight"	 680/773	"model.blk.42.attn.wk.bias"	 681/773	"model.blk.42.attn.wv.weight"	 682/773	"model.blk.42.attn.wv.bias"	 683/773	"model.blk.42.attn.wo.weight"	 684/773	"model.blk.42.attn.wo.bias"	 685/773	"model.blk.43.attn_norm.weight"	 686/773	"model.blk.42.ffn_norm.weight"	 687/773	"model.blk.42.ffn_norm.bias"	 688/773	"model.blk.42.ffn_down.weight"	 689/773	"model.blk.42.ffn_down.bias"	 690/773	"model.blk.42.ffn_up.weight"	 691/773	"model.blk.42.ffn_up.bias"	 692/773	"model.blk.43.attn.wq.weight"	 693/773	"model.blk.43.attn.wq.bias"	 694/773	"model.blk.43.attn.wk.weight"	 695/773	"model.blk.43.attn.wk.bias"	 696/773	"model.blk.43.attn.wv.weight"	 697/773	"model.blk.43.attn.wv.bias"	 698/773	"model.blk.43.attn.wo.weight"	 699/773	"model.blk.43.attn.wo.bias"	 700/773	"model.blk.44.attn_norm.weight"	 701/773	"model.blk.43.ffn_norm.weight"	 702/773	"model.blk.43.ffn_norm.bias"	 703/773	"model.blk.43.ffn_down.weight"	 704/773	"model.blk.43.ffn_down.bias"	 705/773	"model.blk.43.ffn_up.weight"	 706/773	"model.blk.43.ffn_up.bias"	 707/773	"model.blk.44.attn_norm.bias"	 708/773	"model.blk.44.attn.wq.weight"	 709/773	"model.blk.44.attn.wq.bias"	 710/773	"model.blk.44.attn.wk.weight"	 711/773	"model.blk.44.attn.wk.bias"	 712/773	"model.blk.44.attn.wv.weight"	 713/773	"model.blk.44.attn.wv.bias"	 714/773	"model.blk.44.attn.wo.weight"	 715/773	"model.blk.44.attn.wo.bias"	 716/773	"model.blk.44.ffn_norm.weight"	 717/773	"model.blk.44.ffn_norm.bias"	 718/773	"model.blk.44.ffn_down.weight"	 719/773	"model.blk.44.ffn_down.bias"	 720/773	"model.blk.44.ffn_up.weight"	 721/773	"model.blk.44.ffn_up.bias"	 722/773	"model.blk.45.attn_norm.weight"	 723/773	"model.blk.45.attn_norm.bias"	 724/773	"model.blk.45.attn.wq.weight"	 725/773	"model.blk.45.attn.wq.bias"	 726/773	"model.blk.45.attn.wk.weight"	 727/773	"model.blk.45.attn.wk.bias"	 728/773	"model.blk.45.attn.wv.weight"	 729/773	"model.blk.45.attn.wv.bias"	 730/773	"model.blk.45.attn.wo.weight"	 731/773	"model.blk.45.attn.wo.bias"	 732/773	"model.blk.45.ffn_norm.weight"	 733/773	"model.blk.45.ffn_norm.bias"	 734/773	"model.blk.45.ffn_down.weight"	 735/773	"model.blk.45.ffn_down.bias"	 736/773	"model.blk.45.ffn_up.weight"	 737/773	"model.blk.45.ffn_up.bias"	 738/773	"model.blk.46.attn_norm.weight"	 739/773	"model.blk.46.attn_norm.bias"	 740/773	"model.blk.46.attn.wq.weight"	 741/773	"model.blk.46.attn.wq.bias"	 742/773	"model.blk.46.attn.wk.weight"	 743/773	"model.blk.46.attn.wk.bias"	 744/773	"model.blk.46.attn.wv.weight"	 745/773	"model.blk.46.attn.wv.bias"	 746/773	"model.blk.46.attn.wo.weight"	 747/773	"model.blk.46.attn.wo.bias"	 748/773	"model.blk.46.ffn_norm.weight"	 749/773	"model.blk.46.ffn_norm.bias"	 750/773	"model.blk.46.ffn_down.weight"	 751/773	"model.blk.46.ffn_down.bias"	 752/773	"model.blk.46.ffn_up.weight"	 753/773	"model.blk.46.ffn_up.bias"	 754/773	"model.blk.47.attn_norm.weight"	 755/773	"model.blk.47.attn_norm.bias"	 756/773	"model.blk.47.attn.wq.weight"	 757/773	"model.blk.47.attn.wq.bias"	 758/773	"model.blk.47.attn.wk.weight"	 759/773	"model.blk.47.attn.wk.bias"	 760/773	"model.blk.47.attn.wv.weight"	 761/773	"model.blk.47.attn.wv.bias"	 762/773	"model.blk.47.attn.wo.weight"	 763/773	"model.blk.47.attn.wo.bias"	 764/773	"model.blk.47.ffn_norm.weight"	 765/773	"model.blk.47.ffn_norm.bias"	 766/773	"model.blk.47.ffn_down.weight"	 767/773	"model.blk.47.ffn_down.bias"	 768/773	"model.blk.47.ffn_up.weight"	 769/773	"model.blk.47.ffn_up.bias"	 770/773	"model.output_norm.weight"	 771/773	"model.output_norm.bias"	 772/773	"__json__config__">>>>>> saveto_ofs ......sz=9346.2M...>>>>>> saveto_ofs ......OK
>>>>>> ST_SERIALIZE save @"./hy-tmp/checkpoint/GPT2_1558M_latest.ck" nInit=0 sz=0M flag=256 T=13.24s

>>>>>> ST_SERIALIZE load@"./hy-tmp/checkpoint/GPT2_1558M_latest.ck" f=0......

>>>>>> ST_SERIALIZE load@"./hy-tmp/checkpoint/GPT2_1558M_latest.ck" nSerialT=772 iter=0
[RLS_branch] branches=6(48/8)  19@{L0:L8}	 fuyou_0 nParam=128 nReload=112(model.blk.0.attn.wq.weight model.blk.0.attn.wq.bias model.blk.0.attn.wk.weight model.blk.0.attn.wk.bias model.blk.0.attn.wv.weight model.blk.0.attn.wv.bias model.blk.0.attn.wo.weight model.blk.0.attn.wo.bias model.blk.0.ffn_up.weight model.blk.0.ffn_up.bias model.blk.0.ffn_down.weight model.blk.0.ffn_down.bias model.blk.0.ffn_norm.weight model.blk.0.ffn_norm.bias model.blk.1.attn.wq.weight model.blk.1.attn.wq.bias model.blk.1.attn.wk.weight model.blk.1.attn.wk.bias model.blk.1.attn.wv.weight model.blk.1.attn.wv.bias model.blk.1.attn.wo.weight model.blk.1.attn.wo.bias model.blk.1.ffn_up.weight model.blk.1.ffn_up.bias model.blk.1.ffn_down.weight model.blk.1.ffn_down.bias model.blk.1.ffn_norm.weight model.blk.1.ffn_norm.bias model.blk.2.attn.wq.weight model.blk.2.attn.wq.bias model.blk.2.attn.wk.weight model.blk.2.attn.wk.bias model.blk.2.attn.wv.weight model.blk.2.attn.wv.bias model.blk.2.attn.wo.weight model.blk.2.attn.wo.bias model.blk.2.ffn_up.weight model.blk.2.ffn_up.bias model.blk.2.ffn_down.weight model.blk.2.ffn_down.bias model.blk.2.ffn_norm.weight model.blk.2.ffn_norm.bias model.blk.3.attn.wq.weight model.blk.3.attn.wq.bias model.blk.3.attn.wk.weight model.blk.3.attn.wk.bias model.blk.3.attn.wv.weight model.blk.3.attn.wv.bias model.blk.3.attn.wo.weight model.blk.3.attn.wo.bias model.blk.3.ffn_up.weight model.blk.3.ffn_up.bias model.blk.3.ffn_down.weight model.blk.3.ffn_down.bias model.blk.3.ffn_norm.weight model.blk.3.ffn_norm.bias model.blk.4.attn.wq.weight model.blk.4.attn.wq.bias model.blk.4.attn.wk.weight model.blk.4.attn.wk.bias model.blk.4.attn.wv.weight model.blk.4.attn.wv.bias model.blk.4.attn.wo.weight model.blk.4.attn.wo.bias model.blk.4.ffn_up.weight model.blk.4.ffn_up.bias model.blk.4.ffn_down.weight model.blk.4.ffn_down.bias model.blk.4.ffn_norm.weight model.blk.4.ffn_norm.bias model.blk.5.attn.wq.weight model.blk.5.attn.wq.bias model.blk.5.attn.wk.weight model.blk.5.attn.wk.bias model.blk.5.attn.wv.weight model.blk.5.attn.wv.bias model.blk.5.attn.wo.weight model.blk.5.attn.wo.bias model.blk.5.ffn_up.weight model.blk.5.ffn_up.bias model.blk.5.ffn_down.weight model.blk.5.ffn_down.bias model.blk.5.ffn_norm.weight model.blk.5.ffn_norm.bias model.blk.6.attn.wq.weight model.blk.6.attn.wq.bias model.blk.6.attn.wk.weight model.blk.6.attn.wk.bias model.blk.6.attn.wv.weight model.blk.6.attn.wv.bias model.blk.6.attn.wo.weight model.blk.6.attn.wo.bias model.blk.6.ffn_up.weight model.blk.6.ffn_up.bias model.blk.6.ffn_down.weight model.blk.6.ffn_down.bias model.blk.6.ffn_norm.weight model.blk.6.ffn_norm.bias model.blk.7.attn.wq.weight model.blk.7.attn.wq.bias model.blk.7.attn.wk.weight model.blk.7.attn.wk.bias model.blk.7.attn.wv.weight model.blk.7.attn.wv.bias model.blk.7.attn.wo.weight model.blk.7.attn.wo.bias model.blk.7.ffn_up.weight model.blk.7.ffn_up.bias model.blk.7.ffn_down.weight model.blk.7.ffn_down.bias model.blk.7.ffn_norm.weight model.blk.7.ffn_norm.bias )
 19@{L8:L16}	 fuyou_1 nParam=128 nReload=112(model.blk.8.attn.wq.weight model.blk.8.attn.wq.bias model.blk.8.attn.wk.weight model.blk.8.attn.wk.bias model.blk.8.attn.wv.weight model.blk.8.attn.wv.bias model.blk.8.attn.wo.weight model.blk.8.attn.wo.bias model.blk.8.ffn_up.weight model.blk.8.ffn_up.bias model.blk.8.ffn_down.weight model.blk.8.ffn_down.bias model.blk.8.ffn_norm.weight model.blk.8.ffn_norm.bias model.blk.9.attn.wq.weight model.blk.9.attn.wq.bias model.blk.9.attn.wk.weight model.blk.9.attn.wk.bias model.blk.9.attn.wv.weight model.blk.9.attn.wv.bias model.blk.9.attn.wo.weight model.blk.9.attn.wo.bias model.blk.9.ffn_up.weight model.blk.9.ffn_up.bias model.blk.9.ffn_down.weight model.blk.9.ffn_down.bias model.blk.9.ffn_norm.weight model.blk.9.ffn_norm.bias model.blk.10.attn.wq.weight model.blk.10.attn.wq.bias model.blk.10.attn.wk.weight model.blk.10.attn.wk.bias model.blk.10.attn.wv.weight model.blk.10.attn.wv.bias model.blk.10.attn.wo.weight model.blk.10.attn.wo.bias model.blk.10.ffn_up.weight model.blk.10.ffn_up.bias model.blk.10.ffn_down.weight model.blk.10.ffn_down.bias model.blk.10.ffn_norm.weight model.blk.10.ffn_norm.bias model.blk.11.attn.wq.weight model.blk.11.attn.wq.bias model.blk.11.attn.wk.weight model.blk.11.attn.wk.bias model.blk.11.attn.wv.weight model.blk.11.attn.wv.bias model.blk.11.attn.wo.weight model.blk.11.attn.wo.bias model.blk.11.ffn_up.weight model.blk.11.ffn_up.bias model.blk.11.ffn_down.weight model.blk.11.ffn_down.bias model.blk.11.ffn_norm.weight model.blk.11.ffn_norm.bias model.blk.12.attn.wq.weight model.blk.12.attn.wq.bias model.blk.12.attn.wk.weight model.blk.12.attn.wk.bias model.blk.12.attn.wv.weight model.blk.12.attn.wv.bias model.blk.12.attn.wo.weight model.blk.12.attn.wo.bias model.blk.12.ffn_up.weight model.blk.12.ffn_up.bias model.blk.12.ffn_down.weight model.blk.12.ffn_down.bias model.blk.12.ffn_norm.weight model.blk.12.ffn_norm.bias model.blk.13.attn.wq.weight model.blk.13.attn.wq.bias model.blk.13.attn.wk.weight model.blk.13.attn.wk.bias model.blk.13.attn.wv.weight model.blk.13.attn.wv.bias model.blk.13.attn.wo.weight model.blk.13.attn.wo.bias model.blk.13.ffn_up.weight model.blk.13.ffn_up.bias model.blk.13.ffn_down.weight model.blk.13.ffn_down.bias model.blk.13.ffn_norm.weight model.blk.13.ffn_norm.bias model.blk.14.attn.wq.weight model.blk.14.attn.wq.bias model.blk.14.attn.wk.weight model.blk.14.attn.wk.bias model.blk.14.attn.wv.weight model.blk.14.attn.wv.bias model.blk.14.attn.wo.weight model.blk.14.attn.wo.bias model.blk.14.ffn_up.weight model.blk.14.ffn_up.bias model.blk.14.ffn_down.weight model.blk.14.ffn_down.bias model.blk.14.ffn_norm.weight model.blk.14.ffn_norm.bias model.blk.15.attn.wq.weight model.blk.15.attn.wq.bias model.blk.15.attn.wk.weight model.blk.15.attn.wk.bias model.blk.15.attn.wv.weight model.blk.15.attn.wv.bias model.blk.15.attn.wo.weight model.blk.15.attn.wo.bias model.blk.15.ffn_up.weight model.blk.15.ffn_up.bias model.blk.15.ffn_down.weight model.blk.15.ffn_down.bias model.blk.15.ffn_norm.weight model.blk.15.ffn_norm.bias )
 19@{L16:L24}	 fuyou_2 nParam=128 nReload=112(model.blk.16.attn.wq.weight model.blk.16.attn.wq.bias model.blk.16.attn.wk.weight model.blk.16.attn.wk.bias model.blk.16.attn.wv.weight model.blk.16.attn.wv.bias model.blk.16.attn.wo.weight model.blk.16.attn.wo.bias model.blk.16.ffn_up.weight model.blk.16.ffn_up.bias model.blk.16.ffn_down.weight model.blk.16.ffn_down.bias model.blk.16.ffn_norm.weight model.blk.16.ffn_norm.bias model.blk.17.attn.wq.weight model.blk.17.attn.wq.bias model.blk.17.attn.wk.weight model.blk.17.attn.wk.bias model.blk.17.attn.wv.weight model.blk.17.attn.wv.bias model.blk.17.attn.wo.weight model.blk.17.attn.wo.bias model.blk.17.ffn_up.weight model.blk.17.ffn_up.bias model.blk.17.ffn_down.weight model.blk.17.ffn_down.bias model.blk.17.ffn_norm.weight model.blk.17.ffn_norm.bias model.blk.18.attn.wq.weight model.blk.18.attn.wq.bias model.blk.18.attn.wk.weight model.blk.18.attn.wk.bias model.blk.18.attn.wv.weight model.blk.18.attn.wv.bias model.blk.18.attn.wo.weight model.blk.18.attn.wo.bias model.blk.18.ffn_up.weight model.blk.18.ffn_up.bias model.blk.18.ffn_down.weight model.blk.18.ffn_down.bias model.blk.18.ffn_norm.weight model.blk.18.ffn_norm.bias model.blk.19.attn.wq.weight model.blk.19.attn.wq.bias model.blk.19.attn.wk.weight model.blk.19.attn.wk.bias model.blk.19.attn.wv.weight model.blk.19.attn.wv.bias model.blk.19.attn.wo.weight model.blk.19.attn.wo.bias model.blk.19.ffn_up.weight model.blk.19.ffn_up.bias model.blk.19.ffn_down.weight model.blk.19.ffn_down.bias model.blk.19.ffn_norm.weight model.blk.19.ffn_norm.bias model.blk.20.attn.wq.weight model.blk.20.attn.wq.bias model.blk.20.attn.wk.weight model.blk.20.attn.wk.bias model.blk.20.attn.wv.weight model.blk.20.attn.wv.bias model.blk.20.attn.wo.weight model.blk.20.attn.wo.bias model.blk.20.ffn_up.weight model.blk.20.ffn_up.bias model.blk.20.ffn_down.weight model.blk.20.ffn_down.bias model.blk.20.ffn_norm.weight model.blk.20.ffn_norm.bias model.blk.21.attn.wq.weight model.blk.21.attn.wq.bias model.blk.21.attn.wk.weight model.blk.21.attn.wk.bias model.blk.21.attn.wv.weight model.blk.21.attn.wv.bias model.blk.21.attn.wo.weight model.blk.21.attn.wo.bias model.blk.21.ffn_up.weight model.blk.21.ffn_up.bias model.blk.21.ffn_down.weight model.blk.21.ffn_down.bias model.blk.21.ffn_norm.weight model.blk.21.ffn_norm.bias model.blk.22.attn.wq.weight model.blk.22.attn.wq.bias model.blk.22.attn.wk.weight model.blk.22.attn.wk.bias model.blk.22.attn.wv.weight model.blk.22.attn.wv.bias model.blk.22.attn.wo.weight model.blk.22.attn.wo.bias model.blk.22.ffn_up.weight model.blk.22.ffn_up.bias model.blk.22.ffn_down.weight model.blk.22.ffn_down.bias model.blk.22.ffn_norm.weight model.blk.22.ffn_norm.bias model.blk.23.attn.wq.weight model.blk.23.attn.wq.bias model.blk.23.attn.wk.weight model.blk.23.attn.wk.bias model.blk.23.attn.wv.weight model.blk.23.attn.wv.bias model.blk.23.attn.wo.weight model.blk.23.attn.wo.bias model.blk.23.ffn_up.weight model.blk.23.ffn_up.bias model.blk.23.ffn_down.weight model.blk.23.ffn_down.bias model.blk.23.ffn_norm.weight model.blk.23.ffn_norm.bias )
 19@{L24:L32}	 fuyou_3 nParam=128 nReload=112(model.blk.24.attn.wq.weight model.blk.24.attn.wq.bias model.blk.24.attn.wk.weight model.blk.24.attn.wk.bias model.blk.24.attn.wv.weight model.blk.24.attn.wv.bias model.blk.24.attn.wo.weight model.blk.24.attn.wo.bias model.blk.24.ffn_up.weight model.blk.24.ffn_up.bias model.blk.24.ffn_down.weight model.blk.24.ffn_down.bias model.blk.24.ffn_norm.weight model.blk.24.ffn_norm.bias model.blk.25.attn.wq.weight model.blk.25.attn.wq.bias model.blk.25.attn.wk.weight model.blk.25.attn.wk.bias model.blk.25.attn.wv.weight model.blk.25.attn.wv.bias model.blk.25.attn.wo.weight model.blk.25.attn.wo.bias model.blk.25.ffn_up.weight model.blk.25.ffn_up.bias model.blk.25.ffn_down.weight model.blk.25.ffn_down.bias model.blk.25.ffn_norm.weight model.blk.25.ffn_norm.bias model.blk.26.attn.wq.weight model.blk.26.attn.wq.bias model.blk.26.attn.wk.weight model.blk.26.attn.wk.bias model.blk.26.attn.wv.weight model.blk.26.attn.wv.bias model.blk.26.attn.wo.weight model.blk.26.attn.wo.bias model.blk.26.ffn_up.weight model.blk.26.ffn_up.bias model.blk.26.ffn_down.weight model.blk.26.ffn_down.bias model.blk.26.ffn_norm.weight model.blk.26.ffn_norm.bias model.blk.27.attn.wq.weight model.blk.27.attn.wq.bias model.blk.27.attn.wk.weight model.blk.27.attn.wk.bias model.blk.27.attn.wv.weight model.blk.27.attn.wv.bias model.blk.27.attn.wo.weight model.blk.27.attn.wo.bias model.blk.27.ffn_up.weight model.blk.27.ffn_up.bias model.blk.27.ffn_down.weight model.blk.27.ffn_down.bias model.blk.27.ffn_norm.weight model.blk.27.ffn_norm.bias model.blk.28.attn.wq.weight model.blk.28.attn.wq.bias model.blk.28.attn.wk.weight model.blk.28.attn.wk.bias model.blk.28.attn.wv.weight model.blk.28.attn.wv.bias model.blk.28.attn.wo.weight model.blk.28.attn.wo.bias model.blk.28.ffn_up.weight model.blk.28.ffn_up.bias model.blk.28.ffn_down.weight model.blk.28.ffn_down.bias model.blk.28.ffn_norm.weight model.blk.28.ffn_norm.bias model.blk.29.attn.wq.weight model.blk.29.attn.wq.bias model.blk.29.attn.wk.weight model.blk.29.attn.wk.bias model.blk.29.attn.wv.weight model.blk.29.attn.wv.bias model.blk.29.attn.wo.weight model.blk.29.attn.wo.bias model.blk.29.ffn_up.weight model.blk.29.ffn_up.bias model.blk.29.ffn_down.weight model.blk.29.ffn_down.bias model.blk.29.ffn_norm.weight model.blk.29.ffn_norm.bias model.blk.30.attn.wq.weight model.blk.30.attn.wq.bias model.blk.30.attn.wk.weight model.blk.30.attn.wk.bias model.blk.30.attn.wv.weight model.blk.30.attn.wv.bias model.blk.30.attn.wo.weight model.blk.30.attn.wo.bias model.blk.30.ffn_up.weight model.blk.30.ffn_up.bias model.blk.30.ffn_down.weight model.blk.30.ffn_down.bias model.blk.30.ffn_norm.weight model.blk.30.ffn_norm.bias model.blk.31.attn.wq.weight model.blk.31.attn.wq.bias model.blk.31.attn.wk.weight model.blk.31.attn.wk.bias model.blk.31.attn.wv.weight model.blk.31.attn.wv.bias model.blk.31.attn.wo.weight model.blk.31.attn.wo.bias model.blk.31.ffn_up.weight model.blk.31.ffn_up.bias model.blk.31.ffn_down.weight model.blk.31.ffn_down.bias model.blk.31.ffn_norm.weight model.blk.31.ffn_norm.bias )
 19@{L32:L40}	 fuyou_4 nParam=128 nReload=112(model.blk.32.attn.wq.weight model.blk.32.attn.wq.bias model.blk.32.attn.wk.weight model.blk.32.attn.wk.bias model.blk.32.attn.wv.weight model.blk.32.attn.wv.bias model.blk.32.attn.wo.weight model.blk.32.attn.wo.bias model.blk.32.ffn_up.weight model.blk.32.ffn_up.bias model.blk.32.ffn_down.weight model.blk.32.ffn_down.bias model.blk.32.ffn_norm.weight model.blk.32.ffn_norm.bias model.blk.33.attn.wq.weight model.blk.33.attn.wq.bias model.blk.33.attn.wk.weight model.blk.33.attn.wk.bias model.blk.33.attn.wv.weight model.blk.33.attn.wv.bias model.blk.33.attn.wo.weight model.blk.33.attn.wo.bias model.blk.33.ffn_up.weight model.blk.33.ffn_up.bias model.blk.33.ffn_down.weight model.blk.33.ffn_down.bias model.blk.33.ffn_norm.weight model.blk.33.ffn_norm.bias model.blk.34.attn.wq.weight model.blk.34.attn.wq.bias model.blk.34.attn.wk.weight model.blk.34.attn.wk.bias model.blk.34.attn.wv.weight model.blk.34.attn.wv.bias model.blk.34.attn.wo.weight model.blk.34.attn.wo.bias model.blk.34.ffn_up.weight model.blk.34.ffn_up.bias model.blk.34.ffn_down.weight model.blk.34.ffn_down.bias model.blk.34.ffn_norm.weight model.blk.34.ffn_norm.bias model.blk.35.attn.wq.weight model.blk.35.attn.wq.bias model.blk.35.attn.wk.weight model.blk.35.attn.wk.bias model.blk.35.attn.wv.weight model.blk.35.attn.wv.bias model.blk.35.attn.wo.weight model.blk.35.attn.wo.bias model.blk.35.ffn_up.weight model.blk.35.ffn_up.bias model.blk.35.ffn_down.weight model.blk.35.ffn_down.bias model.blk.35.ffn_norm.weight model.blk.35.ffn_norm.bias model.blk.36.attn.wq.weight model.blk.36.attn.wq.bias model.blk.36.attn.wk.weight model.blk.36.attn.wk.bias model.blk.36.attn.wv.weight model.blk.36.attn.wv.bias model.blk.36.attn.wo.weight model.blk.36.attn.wo.bias model.blk.36.ffn_up.weight model.blk.36.ffn_up.bias model.blk.36.ffn_down.weight model.blk.36.ffn_down.bias model.blk.36.ffn_norm.weight model.blk.36.ffn_norm.bias model.blk.37.attn.wq.weight model.blk.37.attn.wq.bias model.blk.37.attn.wk.weight model.blk.37.attn.wk.bias model.blk.37.attn.wv.weight model.blk.37.attn.wv.bias model.blk.37.attn.wo.weight model.blk.37.attn.wo.bias model.blk.37.ffn_up.weight model.blk.37.ffn_up.bias model.blk.37.ffn_down.weight model.blk.37.ffn_down.bias model.blk.37.ffn_norm.weight model.blk.37.ffn_norm.bias model.blk.38.attn.wq.weight model.blk.38.attn.wq.bias model.blk.38.attn.wk.weight model.blk.38.attn.wk.bias model.blk.38.attn.wv.weight model.blk.38.attn.wv.bias model.blk.38.attn.wo.weight model.blk.38.attn.wo.bias model.blk.38.ffn_up.weight model.blk.38.ffn_up.bias model.blk.38.ffn_down.weight model.blk.38.ffn_down.bias model.blk.38.ffn_norm.weight model.blk.38.ffn_norm.bias model.blk.39.attn.wq.weight model.blk.39.attn.wq.bias model.blk.39.attn.wk.weight model.blk.39.attn.wk.bias model.blk.39.attn.wv.weight model.blk.39.attn.wv.bias model.blk.39.attn.wo.weight model.blk.39.attn.wo.bias model.blk.39.ffn_up.weight model.blk.39.ffn_up.bias model.blk.39.ffn_down.weight model.blk.39.ffn_down.bias model.blk.39.ffn_norm.weight model.blk.39.ffn_norm.bias )
 19@{L40:L48}	 fuyou_5 nParam=128 nReload=112(model.blk.40.attn.wq.weight model.blk.40.attn.wq.bias model.blk.40.attn.wk.weight model.blk.40.attn.wk.bias model.blk.40.attn.wv.weight model.blk.40.attn.wv.bias model.blk.40.attn.wo.weight model.blk.40.attn.wo.bias model.blk.40.ffn_up.weight model.blk.40.ffn_up.bias model.blk.40.ffn_down.weight model.blk.40.ffn_down.bias model.blk.40.ffn_norm.weight model.blk.40.ffn_norm.bias model.blk.41.attn.wq.weight model.blk.41.attn.wq.bias model.blk.41.attn.wk.weight model.blk.41.attn.wk.bias model.blk.41.attn.wv.weight model.blk.41.attn.wv.bias model.blk.41.attn.wo.weight model.blk.41.attn.wo.bias model.blk.41.ffn_up.weight model.blk.41.ffn_up.bias model.blk.41.ffn_down.weight model.blk.41.ffn_down.bias model.blk.41.ffn_norm.weight model.blk.41.ffn_norm.bias model.blk.42.attn.wq.weight model.blk.42.attn.wq.bias model.blk.42.attn.wk.weight model.blk.42.attn.wk.bias model.blk.42.attn.wv.weight model.blk.42.attn.wv.bias model.blk.42.attn.wo.weight model.blk.42.attn.wo.bias model.blk.42.ffn_up.weight model.blk.42.ffn_up.bias model.blk.42.ffn_down.weight model.blk.42.ffn_down.bias model.blk.42.ffn_norm.weight model.blk.42.ffn_norm.bias model.blk.43.attn.wq.weight model.blk.43.attn.wq.bias model.blk.43.attn.wk.weight model.blk.43.attn.wk.bias model.blk.43.attn.wv.weight model.blk.43.attn.wv.bias model.blk.43.attn.wo.weight model.blk.43.attn.wo.bias model.blk.43.ffn_up.weight model.blk.43.ffn_up.bias model.blk.43.ffn_down.weight model.blk.43.ffn_down.bias model.blk.43.ffn_norm.weight model.blk.43.ffn_norm.bias model.blk.44.attn.wq.weight model.blk.44.attn.wq.bias model.blk.44.attn.wk.weight model.blk.44.attn.wk.bias model.blk.44.attn.wv.weight model.blk.44.attn.wv.bias model.blk.44.attn.wo.weight model.blk.44.attn.wo.bias model.blk.44.ffn_up.weight model.blk.44.ffn_up.bias model.blk.44.ffn_down.weight model.blk.44.ffn_down.bias model.blk.44.ffn_norm.weight model.blk.44.ffn_norm.bias model.blk.45.attn.wq.weight model.blk.45.attn.wq.bias model.blk.45.attn.wk.weight model.blk.45.attn.wk.bias model.blk.45.attn.wv.weight model.blk.45.attn.wv.bias model.blk.45.attn.wo.weight model.blk.45.attn.wo.bias model.blk.45.ffn_up.weight model.blk.45.ffn_up.bias model.blk.45.ffn_down.weight model.blk.45.ffn_down.bias model.blk.45.ffn_norm.weight model.blk.45.ffn_norm.bias model.blk.46.attn.wq.weight model.blk.46.attn.wq.bias model.blk.46.attn.wk.weight model.blk.46.attn.wk.bias model.blk.46.attn.wv.weight model.blk.46.attn.wv.bias model.blk.46.attn.wo.weight model.blk.46.attn.wo.bias model.blk.46.ffn_up.weight model.blk.46.ffn_up.bias model.blk.46.ffn_down.weight model.blk.46.ffn_down.bias model.blk.46.ffn_norm.weight model.blk.46.ffn_norm.bias model.blk.47.attn.wq.weight model.blk.47.attn.wq.bias model.blk.47.attn.wk.weight model.blk.47.attn.wk.bias model.blk.47.attn.wv.weight model.blk.47.attn.wv.bias model.blk.47.attn.wo.weight model.blk.47.attn.wo.bias model.blk.47.ffn_up.weight model.blk.47.ffn_up.bias model.blk.47.ffn_down.weight model.blk.47.ffn_down.bias model.blk.47.ffn_norm.weight model.blk.47.ffn_norm.bias )

	model.blk.8.attn =====> model.blk.0.attn
	model.blk.8.attn_norm.out =====> model.blk.0.attn_norm.out
	model.blk.8.attn.trans =====> model.blk.0.attn.trans
	model.blk.8.attn.attn =====> model.blk.0.attn.attn
	model.blk.8.attn.wq.out =====> model.blk.0.attn.wq.out
	model.blk.8.attn.wq.weight =====> model.blk.0.attn.wq.weight
	model.blk.8.attn.wq.bias =====> model.blk.0.attn.wq.bias
	model.blk.8.attn.wk.out =====> model.blk.0.attn.wk.out
	model.blk.8.attn.wk.weight =====> model.blk.0.attn.wk.weight
	model.blk.8.attn.wk.bias =====> model.blk.0.attn.wk.bias
	model.blk.8.attn.wv.out =====> model.blk.0.attn.wv.out
	model.blk.8.attn.wv.weight =====> model.blk.0.attn.wv.weight
	model.blk.8.attn.wv.bias =====> model.blk.0.attn.wv.bias
	model.blk.8.attn.wo.out =====> model.blk.0.attn.wo.out
	model.blk.8.attn.wo.weight =====> model.blk.0.attn.wo.weight
	model.blk.8.attn.wo.bias =====> model.blk.0.attn.wo.bias
	model.blk.8.attn_norm.mean =====> model.blk.0.attn_norm.mean
	model.blk.8.attn_norm.rstd =====> model.blk.0.attn_norm.rstd
	model.blk.8.ffn =====> model.blk.0.ffn
	model.blk.8.ffn_norm.out =====> model.blk.0.ffn_norm.out
	model.blk.8.ffn_up.out =====> model.blk.0.ffn_up.out
	model.blk.8.ffn_up.weight =====> model.blk.0.ffn_up.weight
	model.blk.8.ffn_up.bias =====> model.blk.0.ffn_up.bias
	model.blk.8.ffn_down.out =====> model.blk.0.ffn_down.out
	model.blk.8.ffn_down.weight =====> model.blk.0.ffn_down.weight
	model.blk.8.ffn_down.bias =====> model.blk.0.ffn_down.bias
	model.blk.8.ffn_norm.weight =====> model.blk.0.ffn_norm.weight
	model.blk.8.ffn_norm.bias =====> model.blk.0.ffn_norm.bias
	model.blk.8.ffn_norm.mean =====> model.blk.0.ffn_norm.mean
	model.blk.8.ffn_norm.rstd =====> model.blk.0.ffn_norm.rstd
	model.blk.9.attn =====> model.blk.1.attn
	model.blk.9.attn_norm.out =====> model.blk.1.attn_norm.out
	model.blk.9.attn.trans =====> model.blk.1.attn.trans
	model.blk.9.attn.attn =====> model.blk.1.attn.attn
	model.blk.9.attn.wq.out =====> model.blk.1.attn.wq.out
	model.blk.9.attn.wq.weight =====> model.blk.1.attn.wq.weight
	model.blk.9.attn.wq.bias =====> model.blk.1.attn.wq.bias
	model.blk.9.attn.wk.out =====> model.blk.1.attn.wk.out
	model.blk.9.attn.wk.weight =====> model.blk.1.attn.wk.weight
	model.blk.9.attn.wk.bias =====> model.blk.1.attn.wk.bias
	model.blk.9.attn.wv.out =====> model.blk.1.attn.wv.out
	model.blk.9.attn.wv.weight =====> model.blk.1.attn.wv.weight
	model.blk.9.attn.wv.bias =====> model.blk.1.attn.wv.bias
	model.blk.9.attn.wo.out =====> model.blk.1.attn.wo.out
	model.blk.9.attn.wo.weight =====> model.blk.1.attn.wo.weight
	model.blk.9.attn.wo.bias =====> model.blk.1.attn.wo.bias
	model.blk.9.attn_norm.mean =====> model.blk.1.attn_norm.mean
	model.blk.9.attn_norm.rstd =====> model.blk.1.attn_norm.rstd
	model.blk.9.ffn =====> model.blk.1.ffn
	model.blk.9.ffn_norm.out =====> model.blk.1.ffn_norm.out
	model.blk.9.ffn_up.out =====> model.blk.1.ffn_up.out
	model.blk.9.ffn_up.weight =====> model.blk.1.ffn_up.weight
	model.blk.9.ffn_up.bias =====> model.blk.1.ffn_up.bias
	model.blk.9.ffn_down.out =====> model.blk.1.ffn_down.out
	model.blk.9.ffn_down.weight =====> model.blk.1.ffn_down.weight
	model.blk.9.ffn_down.bias =====> model.blk.1.ffn_down.bias
	model.blk.9.ffn_norm.weight =====> model.blk.1.ffn_norm.weight
	model.blk.9.ffn_norm.bias =====> model.blk.1.ffn_norm.bias
	model.blk.9.ffn_norm.mean =====> model.blk.1.ffn_norm.mean
	model.blk.9.ffn_norm.rstd =====> model.blk.1.ffn_norm.rstd
	model.blk.10.attn =====> model.blk.2.attn
	model.blk.10.attn_norm.out =====> model.blk.2.attn_norm.out
	model.blk.10.attn.trans =====> model.blk.2.attn.trans
	model.blk.10.attn.attn =====> model.blk.2.attn.attn
	model.blk.10.attn.wq.out =====> model.blk.2.attn.wq.out
	model.blk.10.attn.wq.weight =====> model.blk.2.attn.wq.weight
	model.blk.10.attn.wq.bias =====> model.blk.2.attn.wq.bias
	model.blk.10.attn.wk.out =====> model.blk.2.attn.wk.out
	model.blk.10.attn.wk.weight =====> model.blk.2.attn.wk.weight
	model.blk.10.attn.wk.bias =====> model.blk.2.attn.wk.bias
	model.blk.10.attn.wv.out =====> model.blk.2.attn.wv.out
	model.blk.10.attn.wv.weight =====> model.blk.2.attn.wv.weight
	model.blk.10.attn.wv.bias =====> model.blk.2.attn.wv.bias
	model.blk.10.attn.wo.out =====> model.blk.2.attn.wo.out
	model.blk.10.attn.wo.weight =====> model.blk.2.attn.wo.weight
	model.blk.10.attn.wo.bias =====> model.blk.2.attn.wo.bias
	model.blk.10.attn_norm.mean =====> model.blk.2.attn_norm.mean
	model.blk.10.attn_norm.rstd =====> model.blk.2.attn_norm.rstd
	model.blk.10.ffn =====> model.blk.2.ffn
	model.blk.10.ffn_norm.out =====> model.blk.2.ffn_norm.out
	model.blk.10.ffn_up.out =====> model.blk.2.ffn_up.out
	model.blk.10.ffn_up.weight =====> model.blk.2.ffn_up.weight
	model.blk.10.ffn_up.bias =====> model.blk.2.ffn_up.bias
	model.blk.10.ffn_down.out =====> model.blk.2.ffn_down.out
	model.blk.10.ffn_down.weight =====> model.blk.2.ffn_down.weight
	model.blk.10.ffn_down.bias =====> model.blk.2.ffn_down.bias
	model.blk.10.ffn_norm.weight =====> model.blk.2.ffn_norm.weight
	model.blk.10.ffn_norm.bias =====> model.blk.2.ffn_norm.bias
	model.blk.10.ffn_norm.mean =====> model.blk.2.ffn_norm.mean
	model.blk.10.ffn_norm.rstd =====> model.blk.2.ffn_norm.rstd
	model.blk.11.attn =====> model.blk.3.attn
	model.blk.11.attn_norm.out =====> model.blk.3.attn_norm.out
	model.blk.11.attn.trans =====> model.blk.3.attn.trans
	model.blk.11.attn.attn =====> model.blk.3.attn.attn
	model.blk.11.attn.wq.out =====> model.blk.3.attn.wq.out
	model.blk.11.attn.wq.weight =====> model.blk.3.attn.wq.weight
	model.blk.11.attn.wq.bias =====> model.blk.3.attn.wq.bias
	model.blk.11.attn.wk.out =====> model.blk.3.attn.wk.out
	model.blk.11.attn.wk.weight =====> model.blk.3.attn.wk.weight
	model.blk.11.attn.wk.bias =====> model.blk.3.attn.wk.bias
	model.blk.11.attn.wv.out =====> model.blk.3.attn.wv.out
	model.blk.11.attn.wv.weight =====> model.blk.3.attn.wv.weight
	model.blk.11.attn.wv.bias =====> model.blk.3.attn.wv.bias
	model.blk.11.attn.wo.out =====> model.blk.3.attn.wo.out
	model.blk.11.attn.wo.weight =====> model.blk.3.attn.wo.weight
	model.blk.11.attn.wo.bias =====> model.blk.3.attn.wo.bias
	model.blk.11.attn_norm.mean =====> model.blk.3.attn_norm.mean
	model.blk.11.attn_norm.rstd =====> model.blk.3.attn_norm.rstd
	model.blk.11.ffn =====> model.blk.3.ffn
	model.blk.11.ffn_norm.out =====> model.blk.3.ffn_norm.out
	model.blk.11.ffn_up.out =====> model.blk.3.ffn_up.out
	model.blk.11.ffn_up.weight =====> model.blk.3.ffn_up.weight
	model.blk.11.ffn_up.bias =====> model.blk.3.ffn_up.bias
	model.blk.11.ffn_down.out =====> model.blk.3.ffn_down.out
	model.blk.11.ffn_down.weight =====> model.blk.3.ffn_down.weight
	model.blk.11.ffn_down.bias =====> model.blk.3.ffn_down.bias
	model.blk.11.ffn_norm.weight =====> model.blk.3.ffn_norm.weight
	model.blk.11.ffn_norm.bias =====> model.blk.3.ffn_norm.bias
	model.blk.11.ffn_norm.mean =====> model.blk.3.ffn_norm.mean
	model.blk.11.ffn_norm.rstd =====> model.blk.3.ffn_norm.rstd
	model.blk.12.attn =====> model.blk.4.attn
	model.blk.12.attn_norm.out =====> model.blk.4.attn_norm.out
	model.blk.12.attn.trans =====> model.blk.4.attn.trans
	model.blk.12.attn.attn =====> model.blk.4.attn.attn
	model.blk.12.attn.wq.out =====> model.blk.4.attn.wq.out
	model.blk.12.attn.wq.weight =====> model.blk.4.attn.wq.weight
	model.blk.12.attn.wq.bias =====> model.blk.4.attn.wq.bias
	model.blk.12.attn.wk.out =====> model.blk.4.attn.wk.out
	model.blk.12.attn.wk.weight =====> model.blk.4.attn.wk.weight
	model.blk.12.attn.wk.bias =====> model.blk.4.attn.wk.bias
	model.blk.12.attn.wv.out =====> model.blk.4.attn.wv.out
	model.blk.12.attn.wv.weight =====> model.blk.4.attn.wv.weight
	model.blk.12.attn.wv.bias =====> model.blk.4.attn.wv.bias
	model.blk.12.attn.wo.out =====> model.blk.4.attn.wo.out
	model.blk.12.attn.wo.weight =====> model.blk.4.attn.wo.weight
	model.blk.12.attn.wo.bias =====> model.blk.4.attn.wo.bias
	model.blk.12.attn_norm.mean =====> model.blk.4.attn_norm.mean
	model.blk.12.attn_norm.rstd =====> model.blk.4.attn_norm.rstd
	model.blk.12.ffn =====> model.blk.4.ffn
	model.blk.12.ffn_norm.out =====> model.blk.4.ffn_norm.out
	model.blk.12.ffn_up.out =====> model.blk.4.ffn_up.out
	model.blk.12.ffn_up.weight =====> model.blk.4.ffn_up.weight
	model.blk.12.ffn_up.bias =====> model.blk.4.ffn_up.bias
	model.blk.12.ffn_down.out =====> model.blk.4.ffn_down.out
	model.blk.12.ffn_down.weight =====> model.blk.4.ffn_down.weight
	model.blk.12.ffn_down.bias =====> model.blk.4.ffn_down.bias
	model.blk.12.ffn_norm.weight =====> model.blk.4.ffn_norm.weight
	model.blk.12.ffn_norm.bias =====> model.blk.4.ffn_norm.bias
	model.blk.12.ffn_norm.mean =====> model.blk.4.ffn_norm.mean
	model.blk.12.ffn_norm.rstd =====> model.blk.4.ffn_norm.rstd
	model.blk.13.attn =====> model.blk.5.attn
	model.blk.13.attn_norm.out =====> model.blk.5.attn_norm.out
	model.blk.13.attn.trans =====> model.blk.5.attn.trans
	model.blk.13.attn.attn =====> model.blk.5.attn.attn
	model.blk.13.attn.wq.out =====> model.blk.5.attn.wq.out
	model.blk.13.attn.wq.weight =====> model.blk.5.attn.wq.weight
	model.blk.13.attn.wq.bias =====> model.blk.5.attn.wq.bias
	model.blk.13.attn.wk.out =====> model.blk.5.attn.wk.out
	model.blk.13.attn.wk.weight =====> model.blk.5.attn.wk.weight
	model.blk.13.attn.wk.bias =====> model.blk.5.attn.wk.bias
	model.blk.13.attn.wv.out =====> model.blk.5.attn.wv.out
	model.blk.13.attn.wv.weight =====> model.blk.5.attn.wv.weight
	model.blk.13.attn.wv.bias =====> model.blk.5.attn.wv.bias
	model.blk.13.attn.wo.out =====> model.blk.5.attn.wo.out
	model.blk.13.attn.wo.weight =====> model.blk.5.attn.wo.weight
	model.blk.13.attn.wo.bias =====> model.blk.5.attn.wo.bias
	model.blk.13.attn_norm.mean =====> model.blk.5.attn_norm.mean
	model.blk.13.attn_norm.rstd =====> model.blk.5.attn_norm.rstd
	model.blk.13.ffn =====> model.blk.5.ffn
	model.blk.13.ffn_norm.out =====> model.blk.5.ffn_norm.out
	model.blk.13.ffn_up.out =====> model.blk.5.ffn_up.out
	model.blk.13.ffn_up.weight =====> model.blk.5.ffn_up.weight
	model.blk.13.ffn_up.bias =====> model.blk.5.ffn_up.bias
	model.blk.13.ffn_down.out =====> model.blk.5.ffn_down.out
	model.blk.13.ffn_down.weight =====> model.blk.5.ffn_down.weight
	model.blk.13.ffn_down.bias =====> model.blk.5.ffn_down.bias
	model.blk.13.ffn_norm.weight =====> model.blk.5.ffn_norm.weight
	model.blk.13.ffn_norm.bias =====> model.blk.5.ffn_norm.bias
	model.blk.13.ffn_norm.mean =====> model.blk.5.ffn_norm.mean
	model.blk.13.ffn_norm.rstd =====> model.blk.5.ffn_norm.rstd
	model.blk.14.attn =====> model.blk.6.attn
	model.blk.14.attn_norm.out =====> model.blk.6.attn_norm.out
	model.blk.14.attn.trans =====> model.blk.6.attn.trans
	model.blk.14.attn.attn =====> model.blk.6.attn.attn
	model.blk.14.attn.wq.out =====> model.blk.6.attn.wq.out
	model.blk.14.attn.wq.weight =====> model.blk.6.attn.wq.weight
	model.blk.14.attn.wq.bias =====> model.blk.6.attn.wq.bias
	model.blk.14.attn.wk.out =====> model.blk.6.attn.wk.out
	model.blk.14.attn.wk.weight =====> model.blk.6.attn.wk.weight
	model.blk.14.attn.wk.bias =====> model.blk.6.attn.wk.bias
	model.blk.14.attn.wv.out =====> model.blk.6.attn.wv.out
	model.blk.14.attn.wv.weight =====> model.blk.6.attn.wv.weight
	model.blk.14.attn.wv.bias =====> model.blk.6.attn.wv.bias
	model.blk.14.attn.wo.out =====> model.blk.6.attn.wo.out
	model.blk.14.attn.wo.weight =====> model.blk.6.attn.wo.weight
	model.blk.14.attn.wo.bias =====> model.blk.6.attn.wo.bias
	model.blk.14.attn_norm.mean =====> model.blk.6.attn_norm.mean
	model.blk.14.attn_norm.rstd =====> model.blk.6.attn_norm.rstd
	model.blk.14.ffn =====> model.blk.6.ffn
	model.blk.14.ffn_norm.out =====> model.blk.6.ffn_norm.out
	model.blk.14.ffn_up.out =====> model.blk.6.ffn_up.out
	model.blk.14.ffn_up.weight =====> model.blk.6.ffn_up.weight
	model.blk.14.ffn_up.bias =====> model.blk.6.ffn_up.bias
	model.blk.14.ffn_down.out =====> model.blk.6.ffn_down.out
	model.blk.14.ffn_down.weight =====> model.blk.6.ffn_down.weight
	model.blk.14.ffn_down.bias =====> model.blk.6.ffn_down.bias
	model.blk.14.ffn_norm.weight =====> model.blk.6.ffn_norm.weight
	model.blk.14.ffn_norm.bias =====> model.blk.6.ffn_norm.bias
	model.blk.14.ffn_norm.mean =====> model.blk.6.ffn_norm.mean
	model.blk.14.ffn_norm.rstd =====> model.blk.6.ffn_norm.rstd
	model.blk.15.attn =====> model.blk.7.attn
	model.blk.15.attn_norm.out =====> model.blk.7.attn_norm.out
	model.blk.15.attn.trans =====> model.blk.7.attn.trans
	model.blk.15.attn.attn =====> model.blk.7.attn.attn
	model.blk.15.attn.wq.out =====> model.blk.7.attn.wq.out
	model.blk.15.attn.wq.weight =====> model.blk.7.attn.wq.weight
	model.blk.15.attn.wq.bias =====> model.blk.7.attn.wq.bias
	model.blk.15.attn.wk.out =====> model.blk.7.attn.wk.out
	model.blk.15.attn.wk.weight =====> model.blk.7.attn.wk.weight
	model.blk.15.attn.wk.bias =====> model.blk.7.attn.wk.bias
	model.blk.15.attn.wv.out =====> model.blk.7.attn.wv.out
	model.blk.15.attn.wv.weight =====> model.blk.7.attn.wv.weight
	model.blk.15.attn.wv.bias =====> model.blk.7.attn.wv.bias
	model.blk.15.attn.wo.out =====> model.blk.7.attn.wo.out
	model.blk.15.attn.wo.weight =====> model.blk.7.attn.wo.weight
	model.blk.15.attn.wo.bias =====> model.blk.7.attn.wo.bias
	model.blk.15.attn_norm.mean =====> model.blk.7.attn_norm.mean
	model.blk.15.attn_norm.rstd =====> model.blk.7.attn_norm.rstd
	model.blk.15.ffn =====> model.blk.7.ffn
	model.blk.15.ffn_norm.out =====> model.blk.7.ffn_norm.out
	model.blk.15.ffn_up.out =====> model.blk.7.ffn_up.out
	model.blk.15.ffn_up.weight =====> model.blk.7.ffn_up.weight
	model.blk.15.ffn_up.bias =====> model.blk.7.ffn_up.bias
	model.blk.15.ffn_down.out =====> model.blk.7.ffn_down.out
	model.blk.15.ffn_down.weight =====> model.blk.7.ffn_down.weight
	model.blk.15.ffn_down.bias =====> model.blk.7.ffn_down.bias
	model.blk.15.ffn_norm.weight =====> model.blk.7.ffn_norm.weight
	model.blk.15.ffn_norm.bias =====> model.blk.7.ffn_norm.bias
	model.blk.15.ffn_norm.mean =====> model.blk.7.ffn_norm.mean
	model.blk.15.ffn_norm.rstd =====> model.blk.7.ffn_norm.rstd
	model.blk.16.attn =====> model.blk.0.attn
	model.blk.16.attn_norm.out =====> model.blk.0.attn_norm.out
	model.blk.16.attn.trans =====> model.blk.0.attn.trans
	model.blk.16.attn.attn =====> model.blk.0.attn.attn
	model.blk.16.attn.wq.out =====> model.blk.0.attn.wq.out
	model.blk.16.attn.wq.weight =====> model.blk.0.attn.wq.weight
	model.blk.16.attn.wq.bias =====> model.blk.0.attn.wq.bias
	model.blk.16.attn.wk.out =====> model.blk.0.attn.wk.out
	model.blk.16.attn.wk.weight =====> model.blk.0.attn.wk.weight
	model.blk.16.attn.wk.bias =====> model.blk.0.attn.wk.bias
	model.blk.16.attn.wv.out =====> model.blk.0.attn.wv.out
	model.blk.16.attn.wv.weight =====> model.blk.0.attn.wv.weight
	model.blk.16.attn.wv.bias =====> model.blk.0.attn.wv.bias
	model.blk.16.attn.wo.out =====> model.blk.0.attn.wo.out
	model.blk.16.attn.wo.weight =====> model.blk.0.attn.wo.weight
	model.blk.16.attn.wo.bias =====> model.blk.0.attn.wo.bias
	model.blk.16.attn_norm.mean =====> model.blk.0.attn_norm.mean
	model.blk.16.attn_norm.rstd =====> model.blk.0.attn_norm.rstd
	model.blk.16.ffn =====> model.blk.0.ffn
	model.blk.16.ffn_norm.out =====> model.blk.0.ffn_norm.out
	model.blk.16.ffn_up.out =====> model.blk.0.ffn_up.out
	model.blk.16.ffn_up.weight =====> model.blk.0.ffn_up.weight
	model.blk.16.ffn_up.bias =====> model.blk.0.ffn_up.bias
	model.blk.16.ffn_down.out =====> model.blk.0.ffn_down.out
	model.blk.16.ffn_down.weight =====> model.blk.0.ffn_down.weight
	model.blk.16.ffn_down.bias =====> model.blk.0.ffn_down.bias
	model.blk.16.ffn_norm.weight =====> model.blk.0.ffn_norm.weight
	model.blk.16.ffn_norm.bias =====> model.blk.0.ffn_norm.bias
	model.blk.16.ffn_norm.mean =====> model.blk.0.ffn_norm.mean
	model.blk.16.ffn_norm.rstd =====> model.blk.0.ffn_norm.rstd
	model.blk.17.attn =====> model.blk.1.attn
	model.blk.17.attn_norm.out =====> model.blk.1.attn_norm.out
	model.blk.17.attn.trans =====> model.blk.1.attn.trans
	model.blk.17.attn.attn =====> model.blk.1.attn.attn
	model.blk.17.attn.wq.out =====> model.blk.1.attn.wq.out
	model.blk.17.attn.wq.weight =====> model.blk.1.attn.wq.weight
	model.blk.17.attn.wq.bias =====> model.blk.1.attn.wq.bias
	model.blk.17.attn.wk.out =====> model.blk.1.attn.wk.out
	model.blk.17.attn.wk.weight =====> model.blk.1.attn.wk.weight
	model.blk.17.attn.wk.bias =====> model.blk.1.attn.wk.bias
	model.blk.17.attn.wv.out =====> model.blk.1.attn.wv.out
	model.blk.17.attn.wv.weight =====> model.blk.1.attn.wv.weight
	model.blk.17.attn.wv.bias =====> model.blk.1.attn.wv.bias
	model.blk.17.attn.wo.out =====> model.blk.1.attn.wo.out
	model.blk.17.attn.wo.weight =====> model.blk.1.attn.wo.weight
	model.blk.17.attn.wo.bias =====> model.blk.1.attn.wo.bias
	model.blk.17.attn_norm.mean =====> model.blk.1.attn_norm.mean
	model.blk.17.attn_norm.rstd =====> model.blk.1.attn_norm.rstd
	model.blk.17.ffn =====> model.blk.1.ffn
	model.blk.17.ffn_norm.out =====> model.blk.1.ffn_norm.out
	model.blk.17.ffn_up.out =====> model.blk.1.ffn_up.out
	model.blk.17.ffn_up.weight =====> model.blk.1.ffn_up.weight
	model.blk.17.ffn_up.bias =====> model.blk.1.ffn_up.bias
	model.blk.17.ffn_down.out =====> model.blk.1.ffn_down.out
	model.blk.17.ffn_down.weight =====> model.blk.1.ffn_down.weight
	model.blk.17.ffn_down.bias =====> model.blk.1.ffn_down.bias
	model.blk.17.ffn_norm.weight =====> model.blk.1.ffn_norm.weight
	model.blk.17.ffn_norm.bias =====> model.blk.1.ffn_norm.bias
	model.blk.17.ffn_norm.mean =====> model.blk.1.ffn_norm.mean
	model.blk.17.ffn_norm.rstd =====> model.blk.1.ffn_norm.rstd
	model.blk.18.attn =====> model.blk.2.attn
	model.blk.18.attn_norm.out =====> model.blk.2.attn_norm.out
	model.blk.18.attn.trans =====> model.blk.2.attn.trans
	model.blk.18.attn.attn =====> model.blk.2.attn.attn
	model.blk.18.attn.wq.out =====> model.blk.2.attn.wq.out
	model.blk.18.attn.wq.weight =====> model.blk.2.attn.wq.weight
	model.blk.18.attn.wq.bias =====> model.blk.2.attn.wq.bias
	model.blk.18.attn.wk.out =====> model.blk.2.attn.wk.out
	model.blk.18.attn.wk.weight =====> model.blk.2.attn.wk.weight
	model.blk.18.attn.wk.bias =====> model.blk.2.attn.wk.bias
	model.blk.18.attn.wv.out =====> model.blk.2.attn.wv.out
	model.blk.18.attn.wv.weight =====> model.blk.2.attn.wv.weight
	model.blk.18.attn.wv.bias =====> model.blk.2.attn.wv.bias
	model.blk.18.attn.wo.out =====> model.blk.2.attn.wo.out
	model.blk.18.attn.wo.weight =====> model.blk.2.attn.wo.weight
	model.blk.18.attn.wo.bias =====> model.blk.2.attn.wo.bias
	model.blk.18.attn_norm.mean =====> model.blk.2.attn_norm.mean
	model.blk.18.attn_norm.rstd =====> model.blk.2.attn_norm.rstd
	model.blk.18.ffn =====> model.blk.2.ffn
	model.blk.18.ffn_norm.out =====> model.blk.2.ffn_norm.out
	model.blk.18.ffn_up.out =====> model.blk.2.ffn_up.out
	model.blk.18.ffn_up.weight =====> model.blk.2.ffn_up.weight
	model.blk.18.ffn_up.bias =====> model.blk.2.ffn_up.bias
	model.blk.18.ffn_down.out =====> model.blk.2.ffn_down.out
	model.blk.18.ffn_down.weight =====> model.blk.2.ffn_down.weight
	model.blk.18.ffn_down.bias =====> model.blk.2.ffn_down.bias
	model.blk.18.ffn_norm.weight =====> model.blk.2.ffn_norm.weight
	model.blk.18.ffn_norm.bias =====> model.blk.2.ffn_norm.bias
	model.blk.18.ffn_norm.mean =====> model.blk.2.ffn_norm.mean
	model.blk.18.ffn_norm.rstd =====> model.blk.2.ffn_norm.rstd
	model.blk.19.attn =====> model.blk.3.attn
	model.blk.19.attn_norm.out =====> model.blk.3.attn_norm.out
	model.blk.19.attn.trans =====> model.blk.3.attn.trans
	model.blk.19.attn.attn =====> model.blk.3.attn.attn
	model.blk.19.attn.wq.out =====> model.blk.3.attn.wq.out
	model.blk.19.attn.wq.weight =====> model.blk.3.attn.wq.weight
	model.blk.19.attn.wq.bias =====> model.blk.3.attn.wq.bias
	model.blk.19.attn.wk.out =====> model.blk.3.attn.wk.out
	model.blk.19.attn.wk.weight =====> model.blk.3.attn.wk.weight
	model.blk.19.attn.wk.bias =====> model.blk.3.attn.wk.bias
	model.blk.19.attn.wv.out =====> model.blk.3.attn.wv.out
	model.blk.19.attn.wv.weight =====> model.blk.3.attn.wv.weight
	model.blk.19.attn.wv.bias =====> model.blk.3.attn.wv.bias
	model.blk.19.attn.wo.out =====> model.blk.3.attn.wo.out
	model.blk.19.attn.wo.weight =====> model.blk.3.attn.wo.weight
	model.blk.19.attn.wo.bias =====> model.blk.3.attn.wo.bias
	model.blk.19.attn_norm.mean =====> model.blk.3.attn_norm.mean
	model.blk.19.attn_norm.rstd =====> model.blk.3.attn_norm.rstd
	model.blk.19.ffn =====> model.blk.3.ffn
	model.blk.19.ffn_norm.out =====> model.blk.3.ffn_norm.out
	model.blk.19.ffn_up.out =====> model.blk.3.ffn_up.out
	model.blk.19.ffn_up.weight =====> model.blk.3.ffn_up.weight
	model.blk.19.ffn_up.bias =====> model.blk.3.ffn_up.bias
	model.blk.19.ffn_down.out =====> model.blk.3.ffn_down.out
	model.blk.19.ffn_down.weight =====> model.blk.3.ffn_down.weight
	model.blk.19.ffn_down.bias =====> model.blk.3.ffn_down.bias
	model.blk.19.ffn_norm.weight =====> model.blk.3.ffn_norm.weight
	model.blk.19.ffn_norm.bias =====> model.blk.3.ffn_norm.bias
	model.blk.19.ffn_norm.mean =====> model.blk.3.ffn_norm.mean
	model.blk.19.ffn_norm.rstd =====> model.blk.3.ffn_norm.rstd
	model.blk.20.attn =====> model.blk.4.attn
	model.blk.20.attn_norm.out =====> model.blk.4.attn_norm.out
	model.blk.20.attn.trans =====> model.blk.4.attn.trans
	model.blk.20.attn.attn =====> model.blk.4.attn.attn
	model.blk.20.attn.wq.out =====> model.blk.4.attn.wq.out
	model.blk.20.attn.wq.weight =====> model.blk.4.attn.wq.weight
	model.blk.20.attn.wq.bias =====> model.blk.4.attn.wq.bias
	model.blk.20.attn.wk.out =====> model.blk.4.attn.wk.out
	model.blk.20.attn.wk.weight =====> model.blk.4.attn.wk.weight
	model.blk.20.attn.wk.bias =====> model.blk.4.attn.wk.bias
	model.blk.20.attn.wv.out =====> model.blk.4.attn.wv.out
	model.blk.20.attn.wv.weight =====> model.blk.4.attn.wv.weight
	model.blk.20.attn.wv.bias =====> model.blk.4.attn.wv.bias
	model.blk.20.attn.wo.out =====> model.blk.4.attn.wo.out
	model.blk.20.attn.wo.weight =====> model.blk.4.attn.wo.weight
	model.blk.20.attn.wo.bias =====> model.blk.4.attn.wo.bias
	model.blk.20.attn_norm.mean =====> model.blk.4.attn_norm.mean
	model.blk.20.attn_norm.rstd =====> model.blk.4.attn_norm.rstd
	model.blk.20.ffn =====> model.blk.4.ffn
	model.blk.20.ffn_norm.out =====> model.blk.4.ffn_norm.out
	model.blk.20.ffn_up.out =====> model.blk.4.ffn_up.out
	model.blk.20.ffn_up.weight =====> model.blk.4.ffn_up.weight
	model.blk.20.ffn_up.bias =====> model.blk.4.ffn_up.bias
	model.blk.20.ffn_down.out =====> model.blk.4.ffn_down.out
	model.blk.20.ffn_down.weight =====> model.blk.4.ffn_down.weight
	model.blk.20.ffn_down.bias =====> model.blk.4.ffn_down.bias
	model.blk.20.ffn_norm.weight =====> model.blk.4.ffn_norm.weight
	model.blk.20.ffn_norm.bias =====> model.blk.4.ffn_norm.bias
	model.blk.20.ffn_norm.mean =====> model.blk.4.ffn_norm.mean
	model.blk.20.ffn_norm.rstd =====> model.blk.4.ffn_norm.rstd
	model.blk.21.attn =====> model.blk.5.attn
	model.blk.21.attn_norm.out =====> model.blk.5.attn_norm.out
	model.blk.21.attn.trans =====> model.blk.5.attn.trans
	model.blk.21.attn.attn =====> model.blk.5.attn.attn
	model.blk.21.attn.wq.out =====> model.blk.5.attn.wq.out
	model.blk.21.attn.wq.weight =====> model.blk.5.attn.wq.weight
	model.blk.21.attn.wq.bias =====> model.blk.5.attn.wq.bias
	model.blk.21.attn.wk.out =====> model.blk.5.attn.wk.out
	model.blk.21.attn.wk.weight =====> model.blk.5.attn.wk.weight
	model.blk.21.attn.wk.bias =====> model.blk.5.attn.wk.bias
	model.blk.21.attn.wv.out =====> model.blk.5.attn.wv.out
	model.blk.21.attn.wv.weight =====> model.blk.5.attn.wv.weight
	model.blk.21.attn.wv.bias =====> model.blk.5.attn.wv.bias
	model.blk.21.attn.wo.out =====> model.blk.5.attn.wo.out
	model.blk.21.attn.wo.weight =====> model.blk.5.attn.wo.weight
	model.blk.21.attn.wo.bias =====> model.blk.5.attn.wo.bias
	model.blk.21.attn_norm.mean =====> model.blk.5.attn_norm.mean
	model.blk.21.attn_norm.rstd =====> model.blk.5.attn_norm.rstd
	model.blk.21.ffn =====> model.blk.5.ffn
	model.blk.21.ffn_norm.out =====> model.blk.5.ffn_norm.out
	model.blk.21.ffn_up.out =====> model.blk.5.ffn_up.out
	model.blk.21.ffn_up.weight =====> model.blk.5.ffn_up.weight
	model.blk.21.ffn_up.bias =====> model.blk.5.ffn_up.bias
	model.blk.21.ffn_down.out =====> model.blk.5.ffn_down.out
	model.blk.21.ffn_down.weight =====> model.blk.5.ffn_down.weight
	model.blk.21.ffn_down.bias =====> model.blk.5.ffn_down.bias
	model.blk.21.ffn_norm.weight =====> model.blk.5.ffn_norm.weight
	model.blk.21.ffn_norm.bias =====> model.blk.5.ffn_norm.bias
	model.blk.21.ffn_norm.mean =====> model.blk.5.ffn_norm.mean
	model.blk.21.ffn_norm.rstd =====> model.blk.5.ffn_norm.rstd
	model.blk.22.attn =====> model.blk.6.attn
	model.blk.22.attn_norm.out =====> model.blk.6.attn_norm.out
	model.blk.22.attn.trans =====> model.blk.6.attn.trans
	model.blk.22.attn.attn =====> model.blk.6.attn.attn
	model.blk.22.attn.wq.out =====> model.blk.6.attn.wq.out
	model.blk.22.attn.wq.weight =====> model.blk.6.attn.wq.weight
	model.blk.22.attn.wq.bias =====> model.blk.6.attn.wq.bias
	model.blk.22.attn.wk.out =====> model.blk.6.attn.wk.out
	model.blk.22.attn.wk.weight =====> model.blk.6.attn.wk.weight
	model.blk.22.attn.wk.bias =====> model.blk.6.attn.wk.bias
	model.blk.22.attn.wv.out =====> model.blk.6.attn.wv.out
	model.blk.22.attn.wv.weight =====> model.blk.6.attn.wv.weight
	model.blk.22.attn.wv.bias =====> model.blk.6.attn.wv.bias
	model.blk.22.attn.wo.out =====> model.blk.6.attn.wo.out
	model.blk.22.attn.wo.weight =====> model.blk.6.attn.wo.weight
	model.blk.22.attn.wo.bias =====> model.blk.6.attn.wo.bias
	model.blk.22.attn_norm.mean =====> model.blk.6.attn_norm.mean
	model.blk.22.attn_norm.rstd =====> model.blk.6.attn_norm.rstd
	model.blk.22.ffn =====> model.blk.6.ffn
	model.blk.22.ffn_norm.out =====> model.blk.6.ffn_norm.out
	model.blk.22.ffn_up.out =====> model.blk.6.ffn_up.out
	model.blk.22.ffn_up.weight =====> model.blk.6.ffn_up.weight
	model.blk.22.ffn_up.bias =====> model.blk.6.ffn_up.bias
	model.blk.22.ffn_down.out =====> model.blk.6.ffn_down.out
	model.blk.22.ffn_down.weight =====> model.blk.6.ffn_down.weight
	model.blk.22.ffn_down.bias =====> model.blk.6.ffn_down.bias
	model.blk.22.ffn_norm.weight =====> model.blk.6.ffn_norm.weight
	model.blk.22.ffn_norm.bias =====> model.blk.6.ffn_norm.bias
	model.blk.22.ffn_norm.mean =====> model.blk.6.ffn_norm.mean
	model.blk.22.ffn_norm.rstd =====> model.blk.6.ffn_norm.rstd
	model.blk.23.attn =====> model.blk.7.attn
	model.blk.23.attn_norm.out =====> model.blk.7.attn_norm.out
	model.blk.23.attn.trans =====> model.blk.7.attn.trans
	model.blk.23.attn.attn =====> model.blk.7.attn.attn
	model.blk.23.attn.wq.out =====> model.blk.7.attn.wq.out
	model.blk.23.attn.wq.weight =====> model.blk.7.attn.wq.weight
	model.blk.23.attn.wq.bias =====> model.blk.7.attn.wq.bias
	model.blk.23.attn.wk.out =====> model.blk.7.attn.wk.out
	model.blk.23.attn.wk.weight =====> model.blk.7.attn.wk.weight
	model.blk.23.attn.wk.bias =====> model.blk.7.attn.wk.bias
	model.blk.23.attn.wv.out =====> model.blk.7.attn.wv.out
	model.blk.23.attn.wv.weight =====> model.blk.7.attn.wv.weight
	model.blk.23.attn.wv.bias =====> model.blk.7.attn.wv.bias
	model.blk.23.attn.wo.out =====> model.blk.7.attn.wo.out
	model.blk.23.attn.wo.weight =====> model.blk.7.attn.wo.weight
	model.blk.23.attn.wo.bias =====> model.blk.7.attn.wo.bias
	model.blk.23.attn_norm.mean =====> model.blk.7.attn_norm.mean
	model.blk.23.attn_norm.rstd =====> model.blk.7.attn_norm.rstd
	model.blk.23.ffn =====> model.blk.7.ffn
	model.blk.23.ffn_norm.out =====> model.blk.7.ffn_norm.out
	model.blk.23.ffn_up.out =====> model.blk.7.ffn_up.out
	model.blk.23.ffn_up.weight =====> model.blk.7.ffn_up.weight
	model.blk.23.ffn_up.bias =====> model.blk.7.ffn_up.bias
	model.blk.23.ffn_down.out =====> model.blk.7.ffn_down.out
	model.blk.23.ffn_down.weight =====> model.blk.7.ffn_down.weight
	model.blk.23.ffn_down.bias =====> model.blk.7.ffn_down.bias
	model.blk.23.ffn_norm.weight =====> model.blk.7.ffn_norm.weight
	model.blk.23.ffn_norm.bias =====> model.blk.7.ffn_norm.bias
	model.blk.23.ffn_norm.mean =====> model.blk.7.ffn_norm.mean
	model.blk.23.ffn_norm.rstd =====> model.blk.7.ffn_norm.rstd
	model.blk.24.attn =====> model.blk.0.attn
	model.blk.24.attn_norm.out =====> model.blk.0.attn_norm.out
	model.blk.24.attn.trans =====> model.blk.0.attn.trans
	model.blk.24.attn.attn =====> model.blk.0.attn.attn
	model.blk.24.attn.wq.out =====> model.blk.0.attn.wq.out
	model.blk.24.attn.wq.weight =====> model.blk.0.attn.wq.weight
	model.blk.24.attn.wq.bias =====> model.blk.0.attn.wq.bias
	model.blk.24.attn.wk.out =====> model.blk.0.attn.wk.out
	model.blk.24.attn.wk.weight =====> model.blk.0.attn.wk.weight
	model.blk.24.attn.wk.bias =====> model.blk.0.attn.wk.bias
	model.blk.24.attn.wv.out =====> model.blk.0.attn.wv.out
	model.blk.24.attn.wv.weight =====> model.blk.0.attn.wv.weight
	model.blk.24.attn.wv.bias =====> model.blk.0.attn.wv.bias
	model.blk.24.attn.wo.out =====> model.blk.0.attn.wo.out
	model.blk.24.attn.wo.weight =====> model.blk.0.attn.wo.weight
	model.blk.24.attn.wo.bias =====> model.blk.0.attn.wo.bias
	model.blk.24.attn_norm.mean =====> model.blk.0.attn_norm.mean
	model.blk.24.attn_norm.rstd =====> model.blk.0.attn_norm.rstd
	model.blk.24.ffn =====> model.blk.0.ffn
	model.blk.24.ffn_norm.out =====> model.blk.0.ffn_norm.out
	model.blk.24.ffn_up.out =====> model.blk.0.ffn_up.out
	model.blk.24.ffn_up.weight =====> model.blk.0.ffn_up.weight
	model.blk.24.ffn_up.bias =====> model.blk.0.ffn_up.bias
	model.blk.24.ffn_down.out =====> model.blk.0.ffn_down.out
	model.blk.24.ffn_down.weight =====> model.blk.0.ffn_down.weight
	model.blk.24.ffn_down.bias =====> model.blk.0.ffn_down.bias
	model.blk.24.ffn_norm.weight =====> model.blk.0.ffn_norm.weight
	model.blk.24.ffn_norm.bias =====> model.blk.0.ffn_norm.bias
	model.blk.24.ffn_norm.mean =====> model.blk.0.ffn_norm.mean
	model.blk.24.ffn_norm.rstd =====> model.blk.0.ffn_norm.rstd
	model.blk.25.attn =====> model.blk.1.attn
	model.blk.25.attn_norm.out =====> model.blk.1.attn_norm.out
	model.blk.25.attn.trans =====> model.blk.1.attn.trans
	model.blk.25.attn.attn =====> model.blk.1.attn.attn
	model.blk.25.attn.wq.out =====> model.blk.1.attn.wq.out
	model.blk.25.attn.wq.weight =====> model.blk.1.attn.wq.weight
	model.blk.25.attn.wq.bias =====> model.blk.1.attn.wq.bias
	model.blk.25.attn.wk.out =====> model.blk.1.attn.wk.out
	model.blk.25.attn.wk.weight =====> model.blk.1.attn.wk.weight
	model.blk.25.attn.wk.bias =====> model.blk.1.attn.wk.bias
	model.blk.25.attn.wv.out =====> model.blk.1.attn.wv.out
	model.blk.25.attn.wv.weight =====> model.blk.1.attn.wv.weight
	model.blk.25.attn.wv.bias =====> model.blk.1.attn.wv.bias
	model.blk.25.attn.wo.out =====> model.blk.1.attn.wo.out
	model.blk.25.attn.wo.weight =====> model.blk.1.attn.wo.weight
	model.blk.25.attn.wo.bias =====> model.blk.1.attn.wo.bias
	model.blk.25.attn_norm.mean =====> model.blk.1.attn_norm.mean
	model.blk.25.attn_norm.rstd =====> model.blk.1.attn_norm.rstd
	model.blk.25.ffn =====> model.blk.1.ffn
	model.blk.25.ffn_norm.out =====> model.blk.1.ffn_norm.out
	model.blk.25.ffn_up.out =====> model.blk.1.ffn_up.out
	model.blk.25.ffn_up.weight =====> model.blk.1.ffn_up.weight
	model.blk.25.ffn_up.bias =====> model.blk.1.ffn_up.bias
	model.blk.25.ffn_down.out =====> model.blk.1.ffn_down.out
	model.blk.25.ffn_down.weight =====> model.blk.1.ffn_down.weight
	model.blk.25.ffn_down.bias =====> model.blk.1.ffn_down.bias
	model.blk.25.ffn_norm.weight =====> model.blk.1.ffn_norm.weight
	model.blk.25.ffn_norm.bias =====> model.blk.1.ffn_norm.bias
	model.blk.25.ffn_norm.mean =====> model.blk.1.ffn_norm.mean
	model.blk.25.ffn_norm.rstd =====> model.blk.1.ffn_norm.rstd
	model.blk.26.attn =====> model.blk.2.attn
	model.blk.26.attn_norm.out =====> model.blk.2.attn_norm.out
	model.blk.26.attn.trans =====> model.blk.2.attn.trans
	model.blk.26.attn.attn =====> model.blk.2.attn.attn
	model.blk.26.attn.wq.out =====> model.blk.2.attn.wq.out
	model.blk.26.attn.wq.weight =====> model.blk.2.attn.wq.weight
	model.blk.26.attn.wq.bias =====> model.blk.2.attn.wq.bias
	model.blk.26.attn.wk.out =====> model.blk.2.attn.wk.out
	model.blk.26.attn.wk.weight =====> model.blk.2.attn.wk.weight
	model.blk.26.attn.wk.bias =====> model.blk.2.attn.wk.bias
	model.blk.26.attn.wv.out =====> model.blk.2.attn.wv.out
	model.blk.26.attn.wv.weight =====> model.blk.2.attn.wv.weight
	model.blk.26.attn.wv.bias =====> model.blk.2.attn.wv.bias
	model.blk.26.attn.wo.out =====> model.blk.2.attn.wo.out
	model.blk.26.attn.wo.weight =====> model.blk.2.attn.wo.weight
	model.blk.26.attn.wo.bias =====> model.blk.2.attn.wo.bias
	model.blk.26.attn_norm.mean =====> model.blk.2.attn_norm.mean
	model.blk.26.attn_norm.rstd =====> model.blk.2.attn_norm.rstd
	model.blk.26.ffn =====> model.blk.2.ffn
	model.blk.26.ffn_norm.out =====> model.blk.2.ffn_norm.out
	model.blk.26.ffn_up.out =====> model.blk.2.ffn_up.out
	model.blk.26.ffn_up.weight =====> model.blk.2.ffn_up.weight
	model.blk.26.ffn_up.bias =====> model.blk.2.ffn_up.bias
	model.blk.26.ffn_down.out =====> model.blk.2.ffn_down.out
	model.blk.26.ffn_down.weight =====> model.blk.2.ffn_down.weight
	model.blk.26.ffn_down.bias =====> model.blk.2.ffn_down.bias
	model.blk.26.ffn_norm.weight =====> model.blk.2.ffn_norm.weight
	model.blk.26.ffn_norm.bias =====> model.blk.2.ffn_norm.bias
	model.blk.26.ffn_norm.mean =====> model.blk.2.ffn_norm.mean
	model.blk.26.ffn_norm.rstd =====> model.blk.2.ffn_norm.rstd
	model.blk.27.attn =====> model.blk.3.attn
	model.blk.27.attn_norm.out =====> model.blk.3.attn_norm.out
	model.blk.27.attn.trans =====> model.blk.3.attn.trans
	model.blk.27.attn.attn =====> model.blk.3.attn.attn
	model.blk.27.attn.wq.out =====> model.blk.3.attn.wq.out
	model.blk.27.attn.wq.weight =====> model.blk.3.attn.wq.weight
	model.blk.27.attn.wq.bias =====> model.blk.3.attn.wq.bias
	model.blk.27.attn.wk.out =====> model.blk.3.attn.wk.out
	model.blk.27.attn.wk.weight =====> model.blk.3.attn.wk.weight
	model.blk.27.attn.wk.bias =====> model.blk.3.attn.wk.bias
	model.blk.27.attn.wv.out =====> model.blk.3.attn.wv.out
	model.blk.27.attn.wv.weight =====> model.blk.3.attn.wv.weight
	model.blk.27.attn.wv.bias =====> model.blk.3.attn.wv.bias
	model.blk.27.attn.wo.out =====> model.blk.3.attn.wo.out
	model.blk.27.attn.wo.weight =====> model.blk.3.attn.wo.weight
	model.blk.27.attn.wo.bias =====> model.blk.3.attn.wo.bias
	model.blk.27.attn_norm.mean =====> model.blk.3.attn_norm.mean
	model.blk.27.attn_norm.rstd =====> model.blk.3.attn_norm.rstd
	model.blk.27.ffn =====> model.blk.3.ffn
	model.blk.27.ffn_norm.out =====> model.blk.3.ffn_norm.out
	model.blk.27.ffn_up.out =====> model.blk.3.ffn_up.out
	model.blk.27.ffn_up.weight =====> model.blk.3.ffn_up.weight
	model.blk.27.ffn_up.bias =====> model.blk.3.ffn_up.bias
	model.blk.27.ffn_down.out =====> model.blk.3.ffn_down.out
	model.blk.27.ffn_down.weight =====> model.blk.3.ffn_down.weight
	model.blk.27.ffn_down.bias =====> model.blk.3.ffn_down.bias
	model.blk.27.ffn_norm.weight =====> model.blk.3.ffn_norm.weight
	model.blk.27.ffn_norm.bias =====> model.blk.3.ffn_norm.bias
	model.blk.27.ffn_norm.mean =====> model.blk.3.ffn_norm.mean
	model.blk.27.ffn_norm.rstd =====> model.blk.3.ffn_norm.rstd
	model.blk.28.attn =====> model.blk.4.attn
	model.blk.28.attn_norm.out =====> model.blk.4.attn_norm.out
	model.blk.28.attn.trans =====> model.blk.4.attn.trans
	model.blk.28.attn.attn =====> model.blk.4.attn.attn
	model.blk.28.attn.wq.out =====> model.blk.4.attn.wq.out
	model.blk.28.attn.wq.weight =====> model.blk.4.attn.wq.weight
	model.blk.28.attn.wq.bias =====> model.blk.4.attn.wq.bias
	model.blk.28.attn.wk.out =====> model.blk.4.attn.wk.out
	model.blk.28.attn.wk.weight =====> model.blk.4.attn.wk.weight
	model.blk.28.attn.wk.bias =====> model.blk.4.attn.wk.bias
	model.blk.28.attn.wv.out =====> model.blk.4.attn.wv.out
	model.blk.28.attn.wv.weight =====> model.blk.4.attn.wv.weight
	model.blk.28.attn.wv.bias =====> model.blk.4.attn.wv.bias
	model.blk.28.attn.wo.out =====> model.blk.4.attn.wo.out
	model.blk.28.attn.wo.weight =====> model.blk.4.attn.wo.weight
	model.blk.28.attn.wo.bias =====> model.blk.4.attn.wo.bias
	model.blk.28.attn_norm.mean =====> model.blk.4.attn_norm.mean
	model.blk.28.attn_norm.rstd =====> model.blk.4.attn_norm.rstd
	model.blk.28.ffn =====> model.blk.4.ffn
	model.blk.28.ffn_norm.out =====> model.blk.4.ffn_norm.out
	model.blk.28.ffn_up.out =====> model.blk.4.ffn_up.out
	model.blk.28.ffn_up.weight =====> model.blk.4.ffn_up.weight
	model.blk.28.ffn_up.bias =====> model.blk.4.ffn_up.bias
	model.blk.28.ffn_down.out =====> model.blk.4.ffn_down.out
	model.blk.28.ffn_down.weight =====> model.blk.4.ffn_down.weight
	model.blk.28.ffn_down.bias =====> model.blk.4.ffn_down.bias
	model.blk.28.ffn_norm.weight =====> model.blk.4.ffn_norm.weight
	model.blk.28.ffn_norm.bias =====> model.blk.4.ffn_norm.bias
	model.blk.28.ffn_norm.mean =====> model.blk.4.ffn_norm.mean
	model.blk.28.ffn_norm.rstd =====> model.blk.4.ffn_norm.rstd
	model.blk.29.attn =====> model.blk.5.attn
	model.blk.29.attn_norm.out =====> model.blk.5.attn_norm.out
	model.blk.29.attn.trans =====> model.blk.5.attn.trans
	model.blk.29.attn.attn =====> model.blk.5.attn.attn
	model.blk.29.attn.wq.out =====> model.blk.5.attn.wq.out
	model.blk.29.attn.wq.weight =====> model.blk.5.attn.wq.weight
	model.blk.29.attn.wq.bias =====> model.blk.5.attn.wq.bias
	model.blk.29.attn.wk.out =====> model.blk.5.attn.wk.out
	model.blk.29.attn.wk.weight =====> model.blk.5.attn.wk.weight
	model.blk.29.attn.wk.bias =====> model.blk.5.attn.wk.bias
	model.blk.29.attn.wv.out =====> model.blk.5.attn.wv.out
	model.blk.29.attn.wv.weight =====> model.blk.5.attn.wv.weight
	model.blk.29.attn.wv.bias =====> model.blk.5.attn.wv.bias
	model.blk.29.attn.wo.out =====> model.blk.5.attn.wo.out
	model.blk.29.attn.wo.weight =====> model.blk.5.attn.wo.weight
	model.blk.29.attn.wo.bias =====> model.blk.5.attn.wo.bias
	model.blk.29.attn_norm.mean =====> model.blk.5.attn_norm.mean
	model.blk.29.attn_norm.rstd =====> model.blk.5.attn_norm.rstd
	model.blk.29.ffn =====> model.blk.5.ffn
	model.blk.29.ffn_norm.out =====> model.blk.5.ffn_norm.out
	model.blk.29.ffn_up.out =====> model.blk.5.ffn_up.out
	model.blk.29.ffn_up.weight =====> model.blk.5.ffn_up.weight
	model.blk.29.ffn_up.bias =====> model.blk.5.ffn_up.bias
	model.blk.29.ffn_down.out =====> model.blk.5.ffn_down.out
	model.blk.29.ffn_down.weight =====> model.blk.5.ffn_down.weight
	model.blk.29.ffn_down.bias =====> model.blk.5.ffn_down.bias
	model.blk.29.ffn_norm.weight =====> model.blk.5.ffn_norm.weight
	model.blk.29.ffn_norm.bias =====> model.blk.5.ffn_norm.bias
	model.blk.29.ffn_norm.mean =====> model.blk.5.ffn_norm.mean
	model.blk.29.ffn_norm.rstd =====> model.blk.5.ffn_norm.rstd
	model.blk.30.attn =====> model.blk.6.attn
	model.blk.30.attn_norm.out =====> model.blk.6.attn_norm.out
	model.blk.30.attn.trans =====> model.blk.6.attn.trans
	model.blk.30.attn.attn =====> model.blk.6.attn.attn
	model.blk.30.attn.wq.out =====> model.blk.6.attn.wq.out
	model.blk.30.attn.wq.weight =====> model.blk.6.attn.wq.weight
	model.blk.30.attn.wq.bias =====> model.blk.6.attn.wq.bias
	model.blk.30.attn.wk.out =====> model.blk.6.attn.wk.out
	model.blk.30.attn.wk.weight =====> model.blk.6.attn.wk.weight
	model.blk.30.attn.wk.bias =====> model.blk.6.attn.wk.bias
	model.blk.30.attn.wv.out =====> model.blk.6.attn.wv.out
	model.blk.30.attn.wv.weight =====> model.blk.6.attn.wv.weight
	model.blk.30.attn.wv.bias =====> model.blk.6.attn.wv.bias
	model.blk.30.attn.wo.out =====> model.blk.6.attn.wo.out
	model.blk.30.attn.wo.weight =====> model.blk.6.attn.wo.weight
	model.blk.30.attn.wo.bias =====> model.blk.6.attn.wo.bias
	model.blk.30.attn_norm.mean =====> model.blk.6.attn_norm.mean
	model.blk.30.attn_norm.rstd =====> model.blk.6.attn_norm.rstd
	model.blk.30.ffn =====> model.blk.6.ffn
	model.blk.30.ffn_norm.out =====> model.blk.6.ffn_norm.out
	model.blk.30.ffn_up.out =====> model.blk.6.ffn_up.out
	model.blk.30.ffn_up.weight =====> model.blk.6.ffn_up.weight
	model.blk.30.ffn_up.bias =====> model.blk.6.ffn_up.bias
	model.blk.30.ffn_down.out =====> model.blk.6.ffn_down.out
	model.blk.30.ffn_down.weight =====> model.blk.6.ffn_down.weight
	model.blk.30.ffn_down.bias =====> model.blk.6.ffn_down.bias
	model.blk.30.ffn_norm.weight =====> model.blk.6.ffn_norm.weight
	model.blk.30.ffn_norm.bias =====> model.blk.6.ffn_norm.bias
	model.blk.30.ffn_norm.mean =====> model.blk.6.ffn_norm.mean
	model.blk.30.ffn_norm.rstd =====> model.blk.6.ffn_norm.rstd
	model.blk.31.attn =====> model.blk.7.attn
	model.blk.31.attn_norm.out =====> model.blk.7.attn_norm.out
	model.blk.31.attn.trans =====> model.blk.7.attn.trans
	model.blk.31.attn.attn =====> model.blk.7.attn.attn
	model.blk.31.attn.wq.out =====> model.blk.7.attn.wq.out
	model.blk.31.attn.wq.weight =====> model.blk.7.attn.wq.weight
	model.blk.31.attn.wq.bias =====> model.blk.7.attn.wq.bias
	model.blk.31.attn.wk.out =====> model.blk.7.attn.wk.out
	model.blk.31.attn.wk.weight =====> model.blk.7.attn.wk.weight
	model.blk.31.attn.wk.bias =====> model.blk.7.attn.wk.bias
	model.blk.31.attn.wv.out =====> model.blk.7.attn.wv.out
	model.blk.31.attn.wv.weight =====> model.blk.7.attn.wv.weight
	model.blk.31.attn.wv.bias =====> model.blk.7.attn.wv.bias
	model.blk.31.attn.wo.out =====> model.blk.7.attn.wo.out
	model.blk.31.attn.wo.weight =====> model.blk.7.attn.wo.weight
	model.blk.31.attn.wo.bias =====> model.blk.7.attn.wo.bias
	model.blk.31.attn_norm.mean =====> model.blk.7.attn_norm.mean
	model.blk.31.attn_norm.rstd =====> model.blk.7.attn_norm.rstd
	model.blk.31.ffn =====> model.blk.7.ffn
	model.blk.31.ffn_norm.out =====> model.blk.7.ffn_norm.out
	model.blk.31.ffn_up.out =====> model.blk.7.ffn_up.out
	model.blk.31.ffn_up.weight =====> model.blk.7.ffn_up.weight
	model.blk.31.ffn_up.bias =====> model.blk.7.ffn_up.bias
	model.blk.31.ffn_down.out =====> model.blk.7.ffn_down.out
	model.blk.31.ffn_down.weight =====> model.blk.7.ffn_down.weight
	model.blk.31.ffn_down.bias =====> model.blk.7.ffn_down.bias
	model.blk.31.ffn_norm.weight =====> model.blk.7.ffn_norm.weight
	model.blk.31.ffn_norm.bias =====> model.blk.7.ffn_norm.bias
	model.blk.31.ffn_norm.mean =====> model.blk.7.ffn_norm.mean
	model.blk.31.ffn_norm.rstd =====> model.blk.7.ffn_norm.rstd
	model.blk.32.attn =====> model.blk.0.attn
	model.blk.32.attn_norm.out =====> model.blk.0.attn_norm.out
	model.blk.32.attn.trans =====> model.blk.0.attn.trans
	model.blk.32.attn.attn =====> model.blk.0.attn.attn
	model.blk.32.attn.wq.out =====> model.blk.0.attn.wq.out
	model.blk.32.attn.wq.weight =====> model.blk.0.attn.wq.weight
	model.blk.32.attn.wq.bias =====> model.blk.0.attn.wq.bias
	model.blk.32.attn.wk.out =====> model.blk.0.attn.wk.out
	model.blk.32.attn.wk.weight =====> model.blk.0.attn.wk.weight
	model.blk.32.attn.wk.bias =====> model.blk.0.attn.wk.bias
	model.blk.32.attn.wv.out =====> model.blk.0.attn.wv.out
	model.blk.32.attn.wv.weight =====> model.blk.0.attn.wv.weight
	model.blk.32.attn.wv.bias =====> model.blk.0.attn.wv.bias
	model.blk.32.attn.wo.out =====> model.blk.0.attn.wo.out
	model.blk.32.attn.wo.weight =====> model.blk.0.attn.wo.weight
	model.blk.32.attn.wo.bias =====> model.blk.0.attn.wo.bias
	model.blk.32.attn_norm.mean =====> model.blk.0.attn_norm.mean
	model.blk.32.attn_norm.rstd =====> model.blk.0.attn_norm.rstd
	model.blk.32.ffn =====> model.blk.0.ffn
	model.blk.32.ffn_norm.out =====> model.blk.0.ffn_norm.out
	model.blk.32.ffn_up.out =====> model.blk.0.ffn_up.out
	model.blk.32.ffn_up.weight =====> model.blk.0.ffn_up.weight
	model.blk.32.ffn_up.bias =====> model.blk.0.ffn_up.bias
	model.blk.32.ffn_down.out =====> model.blk.0.ffn_down.out
	model.blk.32.ffn_down.weight =====> model.blk.0.ffn_down.weight
	model.blk.32.ffn_down.bias =====> model.blk.0.ffn_down.bias
	model.blk.32.ffn_norm.weight =====> model.blk.0.ffn_norm.weight
	model.blk.32.ffn_norm.bias =====> model.blk.0.ffn_norm.bias
	model.blk.32.ffn_norm.mean =====> model.blk.0.ffn_norm.mean
	model.blk.32.ffn_norm.rstd =====> model.blk.0.ffn_norm.rstd
	model.blk.33.attn =====> model.blk.1.attn
	model.blk.33.attn_norm.out =====> model.blk.1.attn_norm.out
	model.blk.33.attn.trans =====> model.blk.1.attn.trans
	model.blk.33.attn.attn =====> model.blk.1.attn.attn
	model.blk.33.attn.wq.out =====> model.blk.1.attn.wq.out
	model.blk.33.attn.wq.weight =====> model.blk.1.attn.wq.weight
	model.blk.33.attn.wq.bias =====> model.blk.1.attn.wq.bias
	model.blk.33.attn.wk.out =====> model.blk.1.attn.wk.out
	model.blk.33.attn.wk.weight =====> model.blk.1.attn.wk.weight
	model.blk.33.attn.wk.bias =====> model.blk.1.attn.wk.bias
	model.blk.33.attn.wv.out =====> model.blk.1.attn.wv.out
	model.blk.33.attn.wv.weight =====> model.blk.1.attn.wv.weight
	model.blk.33.attn.wv.bias =====> model.blk.1.attn.wv.bias
	model.blk.33.attn.wo.out =====> model.blk.1.attn.wo.out
	model.blk.33.attn.wo.weight =====> model.blk.1.attn.wo.weight
	model.blk.33.attn.wo.bias =====> model.blk.1.attn.wo.bias
	model.blk.33.attn_norm.mean =====> model.blk.1.attn_norm.mean
	model.blk.33.attn_norm.rstd =====> model.blk.1.attn_norm.rstd
	model.blk.33.ffn =====> model.blk.1.ffn
	model.blk.33.ffn_norm.out =====> model.blk.1.ffn_norm.out
	model.blk.33.ffn_up.out =====> model.blk.1.ffn_up.out
	model.blk.33.ffn_up.weight =====> model.blk.1.ffn_up.weight
	model.blk.33.ffn_up.bias =====> model.blk.1.ffn_up.bias
	model.blk.33.ffn_down.out =====> model.blk.1.ffn_down.out
	model.blk.33.ffn_down.weight =====> model.blk.1.ffn_down.weight
	model.blk.33.ffn_down.bias =====> model.blk.1.ffn_down.bias
	model.blk.33.ffn_norm.weight =====> model.blk.1.ffn_norm.weight
	model.blk.33.ffn_norm.bias =====> model.blk.1.ffn_norm.bias
	model.blk.33.ffn_norm.mean =====> model.blk.1.ffn_norm.mean
	model.blk.33.ffn_norm.rstd =====> model.blk.1.ffn_norm.rstd
	model.blk.34.attn =====> model.blk.2.attn
	model.blk.34.attn_norm.out =====> model.blk.2.attn_norm.out
	model.blk.34.attn.trans =====> model.blk.2.attn.trans
	model.blk.34.attn.attn =====> model.blk.2.attn.attn
	model.blk.34.attn.wq.out =====> model.blk.2.attn.wq.out
	model.blk.34.attn.wq.weight =====> model.blk.2.attn.wq.weight
	model.blk.34.attn.wq.bias =====> model.blk.2.attn.wq.bias
	model.blk.34.attn.wk.out =====> model.blk.2.attn.wk.out
	model.blk.34.attn.wk.weight =====> model.blk.2.attn.wk.weight
	model.blk.34.attn.wk.bias =====> model.blk.2.attn.wk.bias
	model.blk.34.attn.wv.out =====> model.blk.2.attn.wv.out
	model.blk.34.attn.wv.weight =====> model.blk.2.attn.wv.weight
	model.blk.34.attn.wv.bias =====> model.blk.2.attn.wv.bias
	model.blk.34.attn.wo.out =====> model.blk.2.attn.wo.out
	model.blk.34.attn.wo.weight =====> model.blk.2.attn.wo.weight
	model.blk.34.attn.wo.bias =====> model.blk.2.attn.wo.bias
	model.blk.34.attn_norm.mean =====> model.blk.2.attn_norm.mean
	model.blk.34.attn_norm.rstd =====> model.blk.2.attn_norm.rstd
	model.blk.34.ffn =====> model.blk.2.ffn
	model.blk.34.ffn_norm.out =====> model.blk.2.ffn_norm.out
	model.blk.34.ffn_up.out =====> model.blk.2.ffn_up.out
	model.blk.34.ffn_up.weight =====> model.blk.2.ffn_up.weight
	model.blk.34.ffn_up.bias =====> model.blk.2.ffn_up.bias
	model.blk.34.ffn_down.out =====> model.blk.2.ffn_down.out
	model.blk.34.ffn_down.weight =====> model.blk.2.ffn_down.weight
	model.blk.34.ffn_down.bias =====> model.blk.2.ffn_down.bias
	model.blk.34.ffn_norm.weight =====> model.blk.2.ffn_norm.weight
	model.blk.34.ffn_norm.bias =====> model.blk.2.ffn_norm.bias
	model.blk.34.ffn_norm.mean =====> model.blk.2.ffn_norm.mean
	model.blk.34.ffn_norm.rstd =====> model.blk.2.ffn_norm.rstd
	model.blk.35.attn =====> model.blk.3.attn
	model.blk.35.attn_norm.out =====> model.blk.3.attn_norm.out
	model.blk.35.attn.trans =====> model.blk.3.attn.trans
	model.blk.35.attn.attn =====> model.blk.3.attn.attn
	model.blk.35.attn.wq.out =====> model.blk.3.attn.wq.out
	model.blk.35.attn.wq.weight =====> model.blk.3.attn.wq.weight
	model.blk.35.attn.wq.bias =====> model.blk.3.attn.wq.bias
	model.blk.35.attn.wk.out =====> model.blk.3.attn.wk.out
	model.blk.35.attn.wk.weight =====> model.blk.3.attn.wk.weight
	model.blk.35.attn.wk.bias =====> model.blk.3.attn.wk.bias
	model.blk.35.attn.wv.out =====> model.blk.3.attn.wv.out
	model.blk.35.attn.wv.weight =====> model.blk.3.attn.wv.weight
	model.blk.35.attn.wv.bias =====> model.blk.3.attn.wv.bias
	model.blk.35.attn.wo.out =====> model.blk.3.attn.wo.out
	model.blk.35.attn.wo.weight =====> model.blk.3.attn.wo.weight
	model.blk.35.attn.wo.bias =====> model.blk.3.attn.wo.bias
	model.blk.35.attn_norm.mean =====> model.blk.3.attn_norm.mean
	model.blk.35.attn_norm.rstd =====> model.blk.3.attn_norm.rstd
	model.blk.35.ffn =====> model.blk.3.ffn
	model.blk.35.ffn_norm.out =====> model.blk.3.ffn_norm.out
	model.blk.35.ffn_up.out =====> model.blk.3.ffn_up.out
	model.blk.35.ffn_up.weight =====> model.blk.3.ffn_up.weight
	model.blk.35.ffn_up.bias =====> model.blk.3.ffn_up.bias
	model.blk.35.ffn_down.out =====> model.blk.3.ffn_down.out
	model.blk.35.ffn_down.weight =====> model.blk.3.ffn_down.weight
	model.blk.35.ffn_down.bias =====> model.blk.3.ffn_down.bias
	model.blk.35.ffn_norm.weight =====> model.blk.3.ffn_norm.weight
	model.blk.35.ffn_norm.bias =====> model.blk.3.ffn_norm.bias
	model.blk.35.ffn_norm.mean =====> model.blk.3.ffn_norm.mean
	model.blk.35.ffn_norm.rstd =====> model.blk.3.ffn_norm.rstd
	model.blk.36.attn =====> model.blk.4.attn
	model.blk.36.attn_norm.out =====> model.blk.4.attn_norm.out
	model.blk.36.attn.trans =====> model.blk.4.attn.trans
	model.blk.36.attn.attn =====> model.blk.4.attn.attn
	model.blk.36.attn.wq.out =====> model.blk.4.attn.wq.out
	model.blk.36.attn.wq.weight =====> model.blk.4.attn.wq.weight
	model.blk.36.attn.wq.bias =====> model.blk.4.attn.wq.bias
	model.blk.36.attn.wk.out =====> model.blk.4.attn.wk.out
	model.blk.36.attn.wk.weight =====> model.blk.4.attn.wk.weight
	model.blk.36.attn.wk.bias =====> model.blk.4.attn.wk.bias
	model.blk.36.attn.wv.out =====> model.blk.4.attn.wv.out
	model.blk.36.attn.wv.weight =====> model.blk.4.attn.wv.weight
	model.blk.36.attn.wv.bias =====> model.blk.4.attn.wv.bias
	model.blk.36.attn.wo.out =====> model.blk.4.attn.wo.out
	model.blk.36.attn.wo.weight =====> model.blk.4.attn.wo.weight
	model.blk.36.attn.wo.bias =====> model.blk.4.attn.wo.bias
	model.blk.36.attn_norm.mean =====> model.blk.4.attn_norm.mean
	model.blk.36.attn_norm.rstd =====> model.blk.4.attn_norm.rstd
	model.blk.36.ffn =====> model.blk.4.ffn
	model.blk.36.ffn_norm.out =====> model.blk.4.ffn_norm.out
	model.blk.36.ffn_up.out =====> model.blk.4.ffn_up.out
	model.blk.36.ffn_up.weight =====> model.blk.4.ffn_up.weight
	model.blk.36.ffn_up.bias =====> model.blk.4.ffn_up.bias
	model.blk.36.ffn_down.out =====> model.blk.4.ffn_down.out
	model.blk.36.ffn_down.weight =====> model.blk.4.ffn_down.weight
	model.blk.36.ffn_down.bias =====> model.blk.4.ffn_down.bias
	model.blk.36.ffn_norm.weight =====> model.blk.4.ffn_norm.weight
	model.blk.36.ffn_norm.bias =====> model.blk.4.ffn_norm.bias
	model.blk.36.ffn_norm.mean =====> model.blk.4.ffn_norm.mean
	model.blk.36.ffn_norm.rstd =====> model.blk.4.ffn_norm.rstd
	model.blk.37.attn =====> model.blk.5.attn
	model.blk.37.attn_norm.out =====> model.blk.5.attn_norm.out
	model.blk.37.attn.trans =====> model.blk.5.attn.trans
	model.blk.37.attn.attn =====> model.blk.5.attn.attn
	model.blk.37.attn.wq.out =====> model.blk.5.attn.wq.out
	model.blk.37.attn.wq.weight =====> model.blk.5.attn.wq.weight
	model.blk.37.attn.wq.bias =====> model.blk.5.attn.wq.bias
	model.blk.37.attn.wk.out =====> model.blk.5.attn.wk.out
	model.blk.37.attn.wk.weight =====> model.blk.5.attn.wk.weight
	model.blk.37.attn.wk.bias =====> model.blk.5.attn.wk.bias
	model.blk.37.attn.wv.out =====> model.blk.5.attn.wv.out
	model.blk.37.attn.wv.weight =====> model.blk.5.attn.wv.weight
	model.blk.37.attn.wv.bias =====> model.blk.5.attn.wv.bias
	model.blk.37.attn.wo.out =====> model.blk.5.attn.wo.out
	model.blk.37.attn.wo.weight =====> model.blk.5.attn.wo.weight
	model.blk.37.attn.wo.bias =====> model.blk.5.attn.wo.bias
	model.blk.37.attn_norm.mean =====> model.blk.5.attn_norm.mean
	model.blk.37.attn_norm.rstd =====> model.blk.5.attn_norm.rstd
	model.blk.37.ffn =====> model.blk.5.ffn
	model.blk.37.ffn_norm.out =====> model.blk.5.ffn_norm.out
	model.blk.37.ffn_up.out =====> model.blk.5.ffn_up.out
	model.blk.37.ffn_up.weight =====> model.blk.5.ffn_up.weight
	model.blk.37.ffn_up.bias =====> model.blk.5.ffn_up.bias
	model.blk.37.ffn_down.out =====> model.blk.5.ffn_down.out
	model.blk.37.ffn_down.weight =====> model.blk.5.ffn_down.weight
	model.blk.37.ffn_down.bias =====> model.blk.5.ffn_down.bias
	model.blk.37.ffn_norm.weight =====> model.blk.5.ffn_norm.weight
	model.blk.37.ffn_norm.bias =====> model.blk.5.ffn_norm.bias
	model.blk.37.ffn_norm.mean =====> model.blk.5.ffn_norm.mean
	model.blk.37.ffn_norm.rstd =====> model.blk.5.ffn_norm.rstd
	model.blk.38.attn =====> model.blk.6.attn
	model.blk.38.attn_norm.out =====> model.blk.6.attn_norm.out
	model.blk.38.attn.trans =====> model.blk.6.attn.trans
	model.blk.38.attn.attn =====> model.blk.6.attn.attn
	model.blk.38.attn.wq.out =====> model.blk.6.attn.wq.out
	model.blk.38.attn.wq.weight =====> model.blk.6.attn.wq.weight
	model.blk.38.attn.wq.bias =====> model.blk.6.attn.wq.bias
	model.blk.38.attn.wk.out =====> model.blk.6.attn.wk.out
	model.blk.38.attn.wk.weight =====> model.blk.6.attn.wk.weight
	model.blk.38.attn.wk.bias =====> model.blk.6.attn.wk.bias
	model.blk.38.attn.wv.out =====> model.blk.6.attn.wv.out
	model.blk.38.attn.wv.weight =====> model.blk.6.attn.wv.weight
	model.blk.38.attn.wv.bias =====> model.blk.6.attn.wv.bias
	model.blk.38.attn.wo.out =====> model.blk.6.attn.wo.out
	model.blk.38.attn.wo.weight =====> model.blk.6.attn.wo.weight
	model.blk.38.attn.wo.bias =====> model.blk.6.attn.wo.bias
	model.blk.38.attn_norm.mean =====> model.blk.6.attn_norm.mean
	model.blk.38.attn_norm.rstd =====> model.blk.6.attn_norm.rstd
	model.blk.38.ffn =====> model.blk.6.ffn
	model.blk.38.ffn_norm.out =====> model.blk.6.ffn_norm.out
	model.blk.38.ffn_up.out =====> model.blk.6.ffn_up.out
	model.blk.38.ffn_up.weight =====> model.blk.6.ffn_up.weight
	model.blk.38.ffn_up.bias =====> model.blk.6.ffn_up.bias
	model.blk.38.ffn_down.out =====> model.blk.6.ffn_down.out
	model.blk.38.ffn_down.weight =====> model.blk.6.ffn_down.weight
	model.blk.38.ffn_down.bias =====> model.blk.6.ffn_down.bias
	model.blk.38.ffn_norm.weight =====> model.blk.6.ffn_norm.weight
	model.blk.38.ffn_norm.bias =====> model.blk.6.ffn_norm.bias
	model.blk.38.ffn_norm.mean =====> model.blk.6.ffn_norm.mean
	model.blk.38.ffn_norm.rstd =====> model.blk.6.ffn_norm.rstd
	model.blk.39.attn =====> model.blk.7.attn
	model.blk.39.attn_norm.out =====> model.blk.7.attn_norm.out
	model.blk.39.attn.trans =====> model.blk.7.attn.trans
	model.blk.39.attn.attn =====> model.blk.7.attn.attn
	model.blk.39.attn.wq.out =====> model.blk.7.attn.wq.out
	model.blk.39.attn.wq.weight =====> model.blk.7.attn.wq.weight
	model.blk.39.attn.wq.bias =====> model.blk.7.attn.wq.bias
	model.blk.39.attn.wk.out =====> model.blk.7.attn.wk.out
	model.blk.39.attn.wk.weight =====> model.blk.7.attn.wk.weight
	model.blk.39.attn.wk.bias =====> model.blk.7.attn.wk.bias
	model.blk.39.attn.wv.out =====> model.blk.7.attn.wv.out
	model.blk.39.attn.wv.weight =====> model.blk.7.attn.wv.weight
	model.blk.39.attn.wv.bias =====> model.blk.7.attn.wv.bias
	model.blk.39.attn.wo.out =====> model.blk.7.attn.wo.out
	model.blk.39.attn.wo.weight =====> model.blk.7.attn.wo.weight
	model.blk.39.attn.wo.bias =====> model.blk.7.attn.wo.bias
	model.blk.39.attn_norm.mean =====> model.blk.7.attn_norm.mean
	model.blk.39.attn_norm.rstd =====> model.blk.7.attn_norm.rstd
	model.blk.39.ffn =====> model.blk.7.ffn
	model.blk.39.ffn_norm.out =====> model.blk.7.ffn_norm.out
	model.blk.39.ffn_up.out =====> model.blk.7.ffn_up.out
	model.blk.39.ffn_up.weight =====> model.blk.7.ffn_up.weight
	model.blk.39.ffn_up.bias =====> model.blk.7.ffn_up.bias
	model.blk.39.ffn_down.out =====> model.blk.7.ffn_down.out
	model.blk.39.ffn_down.weight =====> model.blk.7.ffn_down.weight
	model.blk.39.ffn_down.bias =====> model.blk.7.ffn_down.bias
	model.blk.39.ffn_norm.weight =====> model.blk.7.ffn_norm.weight
	model.blk.39.ffn_norm.bias =====> model.blk.7.ffn_norm.bias
	model.blk.39.ffn_norm.mean =====> model.blk.7.ffn_norm.mean
	model.blk.39.ffn_norm.rstd =====> model.blk.7.ffn_norm.rstd
	model.blk.40.attn =====> model.blk.0.attn
	model.blk.40.attn_norm.out =====> model.blk.0.attn_norm.out
	model.blk.40.attn.trans =====> model.blk.0.attn.trans
	model.blk.40.attn.attn =====> model.blk.0.attn.attn
	model.blk.40.attn.wq.out =====> model.blk.0.attn.wq.out
	model.blk.40.attn.wq.weight =====> model.blk.0.attn.wq.weight
	model.blk.40.attn.wq.bias =====> model.blk.0.attn.wq.bias
	model.blk.40.attn.wk.out =====> model.blk.0.attn.wk.out
	model.blk.40.attn.wk.weight =====> model.blk.0.attn.wk.weight
	model.blk.40.attn.wk.bias =====> model.blk.0.attn.wk.bias
	model.blk.40.attn.wv.out =====> model.blk.0.attn.wv.out
	model.blk.40.attn.wv.weight =====> model.blk.0.attn.wv.weight
	model.blk.40.attn.wv.bias =====> model.blk.0.attn.wv.bias
	model.blk.40.attn.wo.out =====> model.blk.0.attn.wo.out
	model.blk.40.attn.wo.weight =====> model.blk.0.attn.wo.weight
	model.blk.40.attn.wo.bias =====> model.blk.0.attn.wo.bias
	model.blk.40.attn_norm.mean =====> model.blk.0.attn_norm.mean
	model.blk.40.attn_norm.rstd =====> model.blk.0.attn_norm.rstd
	model.blk.40.ffn =====> model.blk.0.ffn
	model.blk.40.ffn_norm.out =====> model.blk.0.ffn_norm.out
	model.blk.40.ffn_up.out =====> model.blk.0.ffn_up.out
	model.blk.40.ffn_up.weight =====> model.blk.0.ffn_up.weight
	model.blk.40.ffn_up.bias =====> model.blk.0.ffn_up.bias
	model.blk.40.ffn_down.out =====> model.blk.0.ffn_down.out
	model.blk.40.ffn_down.weight =====> model.blk.0.ffn_down.weight
	model.blk.40.ffn_down.bias =====> model.blk.0.ffn_down.bias
	model.blk.40.ffn_norm.weight =====> model.blk.0.ffn_norm.weight
	model.blk.40.ffn_norm.bias =====> model.blk.0.ffn_norm.bias
	model.blk.40.ffn_norm.mean =====> model.blk.0.ffn_norm.mean
	model.blk.40.ffn_norm.rstd =====> model.blk.0.ffn_norm.rstd
	model.blk.41.attn =====> model.blk.1.attn
	model.blk.41.attn_norm.out =====> model.blk.1.attn_norm.out
	model.blk.41.attn.trans =====> model.blk.1.attn.trans
	model.blk.41.attn.attn =====> model.blk.1.attn.attn
	model.blk.41.attn.wq.out =====> model.blk.1.attn.wq.out
	model.blk.41.attn.wq.weight =====> model.blk.1.attn.wq.weight
	model.blk.41.attn.wq.bias =====> model.blk.1.attn.wq.bias
	model.blk.41.attn.wk.out =====> model.blk.1.attn.wk.out
	model.blk.41.attn.wk.weight =====> model.blk.1.attn.wk.weight
	model.blk.41.attn.wk.bias =====> model.blk.1.attn.wk.bias
	model.blk.41.attn.wv.out =====> model.blk.1.attn.wv.out
	model.blk.41.attn.wv.weight =====> model.blk.1.attn.wv.weight
	model.blk.41.attn.wv.bias =====> model.blk.1.attn.wv.bias
	model.blk.41.attn.wo.out =====> model.blk.1.attn.wo.out
	model.blk.41.attn.wo.weight =====> model.blk.1.attn.wo.weight
	model.blk.41.attn.wo.bias =====> model.blk.1.attn.wo.bias
	model.blk.41.attn_norm.mean =====> model.blk.1.attn_norm.mean
	model.blk.41.attn_norm.rstd =====> model.blk.1.attn_norm.rstd
	model.blk.41.ffn =====> model.blk.1.ffn
	model.blk.41.ffn_norm.out =====> model.blk.1.ffn_norm.out
	model.blk.41.ffn_up.out =====> model.blk.1.ffn_up.out
	model.blk.41.ffn_up.weight =====> model.blk.1.ffn_up.weight
	model.blk.41.ffn_up.bias =====> model.blk.1.ffn_up.bias
	model.blk.41.ffn_down.out =====> model.blk.1.ffn_down.out
	model.blk.41.ffn_down.weight =====> model.blk.1.ffn_down.weight
	model.blk.41.ffn_down.bias =====> model.blk.1.ffn_down.bias
	model.blk.41.ffn_norm.weight =====> model.blk.1.ffn_norm.weight
	model.blk.41.ffn_norm.bias =====> model.blk.1.ffn_norm.bias
	model.blk.41.ffn_norm.mean =====> model.blk.1.ffn_norm.mean
	model.blk.41.ffn_norm.rstd =====> model.blk.1.ffn_norm.rstd
	model.blk.42.attn =====> model.blk.2.attn
	model.blk.42.attn_norm.out =====> model.blk.2.attn_norm.out
	model.blk.42.attn.trans =====> model.blk.2.attn.trans
	model.blk.42.attn.attn =====> model.blk.2.attn.attn
	model.blk.42.attn.wq.out =====> model.blk.2.attn.wq.out
	model.blk.42.attn.wq.weight =====> model.blk.2.attn.wq.weight
	model.blk.42.attn.wq.bias =====> model.blk.2.attn.wq.bias
	model.blk.42.attn.wk.out =====> model.blk.2.attn.wk.out
	model.blk.42.attn.wk.weight =====> model.blk.2.attn.wk.weight
	model.blk.42.attn.wk.bias =====> model.blk.2.attn.wk.bias
	model.blk.42.attn.wv.out =====> model.blk.2.attn.wv.out
	model.blk.42.attn.wv.weight =====> model.blk.2.attn.wv.weight
	model.blk.42.attn.wv.bias =====> model.blk.2.attn.wv.bias
	model.blk.42.attn.wo.out =====> model.blk.2.attn.wo.out
	model.blk.42.attn.wo.weight =====> model.blk.2.attn.wo.weight
	model.blk.42.attn.wo.bias =====> model.blk.2.attn.wo.bias
	model.blk.42.attn_norm.mean =====> model.blk.2.attn_norm.mean
	model.blk.42.attn_norm.rstd =====> model.blk.2.attn_norm.rstd
	model.blk.42.ffn =====> model.blk.2.ffn
	model.blk.42.ffn_norm.out =====> model.blk.2.ffn_norm.out
	model.blk.42.ffn_up.out =====> model.blk.2.ffn_up.out
	model.blk.42.ffn_up.weight =====> model.blk.2.ffn_up.weight
	model.blk.42.ffn_up.bias =====> model.blk.2.ffn_up.bias
	model.blk.42.ffn_down.out =====> model.blk.2.ffn_down.out
	model.blk.42.ffn_down.weight =====> model.blk.2.ffn_down.weight
	model.blk.42.ffn_down.bias =====> model.blk.2.ffn_down.bias
	model.blk.42.ffn_norm.weight =====> model.blk.2.ffn_norm.weight
	model.blk.42.ffn_norm.bias =====> model.blk.2.ffn_norm.bias
	model.blk.42.ffn_norm.mean =====> model.blk.2.ffn_norm.mean
	model.blk.42.ffn_norm.rstd =====> model.blk.2.ffn_norm.rstd
	model.blk.43.attn =====> model.blk.3.attn
	model.blk.43.attn_norm.out =====> model.blk.3.attn_norm.out
	model.blk.43.attn.trans =====> model.blk.3.attn.trans
	model.blk.43.attn.attn =====> model.blk.3.attn.attn
	model.blk.43.attn.wq.out =====> model.blk.3.attn.wq.out
	model.blk.43.attn.wq.weight =====> model.blk.3.attn.wq.weight
	model.blk.43.attn.wq.bias =====> model.blk.3.attn.wq.bias
	model.blk.43.attn.wk.out =====> model.blk.3.attn.wk.out
	model.blk.43.attn.wk.weight =====> model.blk.3.attn.wk.weight
	model.blk.43.attn.wk.bias =====> model.blk.3.attn.wk.bias
	model.blk.43.attn.wv.out =====> model.blk.3.attn.wv.out
	model.blk.43.attn.wv.weight =====> model.blk.3.attn.wv.weight
	model.blk.43.attn.wv.bias =====> model.blk.3.attn.wv.bias
	model.blk.43.attn.wo.out =====> model.blk.3.attn.wo.out
	model.blk.43.attn.wo.weight =====> model.blk.3.attn.wo.weight
	model.blk.43.attn.wo.bias =====> model.blk.3.attn.wo.bias
	model.blk.43.attn_norm.mean =====> model.blk.3.attn_norm.mean
	model.blk.43.attn_norm.rstd =====> model.blk.3.attn_norm.rstd
	model.blk.43.ffn =====> model.blk.3.ffn
	model.blk.43.ffn_norm.out =====> model.blk.3.ffn_norm.out
	model.blk.43.ffn_up.out =====> model.blk.3.ffn_up.out
	model.blk.43.ffn_up.weight =====> model.blk.3.ffn_up.weight
	model.blk.43.ffn_up.bias =====> model.blk.3.ffn_up.bias
	model.blk.43.ffn_down.out =====> model.blk.3.ffn_down.out
	model.blk.43.ffn_down.weight =====> model.blk.3.ffn_down.weight
	model.blk.43.ffn_down.bias =====> model.blk.3.ffn_down.bias
	model.blk.43.ffn_norm.weight =====> model.blk.3.ffn_norm.weight
	model.blk.43.ffn_norm.bias =====> model.blk.3.ffn_norm.bias
	model.blk.43.ffn_norm.mean =====> model.blk.3.ffn_norm.mean
	model.blk.43.ffn_norm.rstd =====> model.blk.3.ffn_norm.rstd
	model.blk.44.attn =====> model.blk.4.attn
	model.blk.44.attn_norm.out =====> model.blk.4.attn_norm.out
	model.blk.44.attn.trans =====> model.blk.4.attn.trans
	model.blk.44.attn.attn =====> model.blk.4.attn.attn
	model.blk.44.attn.wq.out =====> model.blk.4.attn.wq.out
	model.blk.44.attn.wq.weight =====> model.blk.4.attn.wq.weight
	model.blk.44.attn.wq.bias =====> model.blk.4.attn.wq.bias
	model.blk.44.attn.wk.out =====> model.blk.4.attn.wk.out
	model.blk.44.attn.wk.weight =====> model.blk.4.attn.wk.weight
	model.blk.44.attn.wk.bias =====> model.blk.4.attn.wk.bias
	model.blk.44.attn.wv.out =====> model.blk.4.attn.wv.out
	model.blk.44.attn.wv.weight =====> model.blk.4.attn.wv.weight
	model.blk.44.attn.wv.bias =====> model.blk.4.attn.wv.bias
	model.blk.44.attn.wo.out =====> model.blk.4.attn.wo.out
	model.blk.44.attn.wo.weight =====> model.blk.4.attn.wo.weight
	model.blk.44.attn.wo.bias =====> model.blk.4.attn.wo.bias
	model.blk.44.attn_norm.mean =====> model.blk.4.attn_norm.mean
	model.blk.44.attn_norm.rstd =====> model.blk.4.attn_norm.rstd
	model.blk.44.ffn =====> model.blk.4.ffn
	model.blk.44.ffn_norm.out =====> model.blk.4.ffn_norm.out
	model.blk.44.ffn_up.out =====> model.blk.4.ffn_up.out
	model.blk.44.ffn_up.weight =====> model.blk.4.ffn_up.weight
	model.blk.44.ffn_up.bias =====> model.blk.4.ffn_up.bias
	model.blk.44.ffn_down.out =====> model.blk.4.ffn_down.out
	model.blk.44.ffn_down.weight =====> model.blk.4.ffn_down.weight
	model.blk.44.ffn_down.bias =====> model.blk.4.ffn_down.bias
	model.blk.44.ffn_norm.weight =====> model.blk.4.ffn_norm.weight
	model.blk.44.ffn_norm.bias =====> model.blk.4.ffn_norm.bias
	model.blk.44.ffn_norm.mean =====> model.blk.4.ffn_norm.mean
	model.blk.44.ffn_norm.rstd =====> model.blk.4.ffn_norm.rstd
	model.blk.45.attn =====> model.blk.5.attn
	model.blk.45.attn_norm.out =====> model.blk.5.attn_norm.out
	model.blk.45.attn.trans =====> model.blk.5.attn.trans
	model.blk.45.attn.attn =====> model.blk.5.attn.attn
	model.blk.45.attn.wq.out =====> model.blk.5.attn.wq.out
	model.blk.45.attn.wq.weight =====> model.blk.5.attn.wq.weight
	model.blk.45.attn.wq.bias =====> model.blk.5.attn.wq.bias
	model.blk.45.attn.wk.out =====> model.blk.5.attn.wk.out
	model.blk.45.attn.wk.weight =====> model.blk.5.attn.wk.weight
	model.blk.45.attn.wk.bias =====> model.blk.5.attn.wk.bias
	model.blk.45.attn.wv.out =====> model.blk.5.attn.wv.out
	model.blk.45.attn.wv.weight =====> model.blk.5.attn.wv.weight
	model.blk.45.attn.wv.bias =====> model.blk.5.attn.wv.bias
	model.blk.45.attn.wo.out =====> model.blk.5.attn.wo.out
	model.blk.45.attn.wo.weight =====> model.blk.5.attn.wo.weight
	model.blk.45.attn.wo.bias =====> model.blk.5.attn.wo.bias
	model.blk.45.attn_norm.mean =====> model.blk.5.attn_norm.mean
	model.blk.45.attn_norm.rstd =====> model.blk.5.attn_norm.rstd
	model.blk.45.ffn =====> model.blk.5.ffn
	model.blk.45.ffn_norm.out =====> model.blk.5.ffn_norm.out
	model.blk.45.ffn_up.out =====> model.blk.5.ffn_up.out
	model.blk.45.ffn_up.weight =====> model.blk.5.ffn_up.weight
	model.blk.45.ffn_up.bias =====> model.blk.5.ffn_up.bias
	model.blk.45.ffn_down.out =====> model.blk.5.ffn_down.out
	model.blk.45.ffn_down.weight =====> model.blk.5.ffn_down.weight
	model.blk.45.ffn_down.bias =====> model.blk.5.ffn_down.bias
	model.blk.45.ffn_norm.weight =====> model.blk.5.ffn_norm.weight
	model.blk.45.ffn_norm.bias =====> model.blk.5.ffn_norm.bias
	model.blk.45.ffn_norm.mean =====> model.blk.5.ffn_norm.mean
	model.blk.45.ffn_norm.rstd =====> model.blk.5.ffn_norm.rstd
	model.blk.46.attn =====> model.blk.6.attn
	model.blk.46.attn_norm.out =====> model.blk.6.attn_norm.out
	model.blk.46.attn.trans =====> model.blk.6.attn.trans
	model.blk.46.attn.attn =====> model.blk.6.attn.attn
	model.blk.46.attn.wq.out =====> model.blk.6.attn.wq.out
	model.blk.46.attn.wq.weight =====> model.blk.6.attn.wq.weight
	model.blk.46.attn.wq.bias =====> model.blk.6.attn.wq.bias
	model.blk.46.attn.wk.out =====> model.blk.6.attn.wk.out
	model.blk.46.attn.wk.weight =====> model.blk.6.attn.wk.weight
	model.blk.46.attn.wk.bias =====> model.blk.6.attn.wk.bias
	model.blk.46.attn.wv.out =====> model.blk.6.attn.wv.out
	model.blk.46.attn.wv.weight =====> model.blk.6.attn.wv.weight
	model.blk.46.attn.wv.bias =====> model.blk.6.attn.wv.bias
	model.blk.46.attn.wo.out =====> model.blk.6.attn.wo.out
	model.blk.46.attn.wo.weight =====> model.blk.6.attn.wo.weight
	model.blk.46.attn.wo.bias =====> model.blk.6.attn.wo.bias
	model.blk.46.attn_norm.mean =====> model.blk.6.attn_norm.mean
	model.blk.46.attn_norm.rstd =====> model.blk.6.attn_norm.rstd
	model.blk.46.ffn =====> model.blk.6.ffn
	model.blk.46.ffn_norm.out =====> model.blk.6.ffn_norm.out
	model.blk.46.ffn_up.out =====> model.blk.6.ffn_up.out
	model.blk.46.ffn_up.weight =====> model.blk.6.ffn_up.weight
	model.blk.46.ffn_up.bias =====> model.blk.6.ffn_up.bias
	model.blk.46.ffn_down.out =====> model.blk.6.ffn_down.out
	model.blk.46.ffn_down.weight =====> model.blk.6.ffn_down.weight
	model.blk.46.ffn_down.bias =====> model.blk.6.ffn_down.bias
	model.blk.46.ffn_norm.weight =====> model.blk.6.ffn_norm.weight
	model.blk.46.ffn_norm.bias =====> model.blk.6.ffn_norm.bias
	model.blk.46.ffn_norm.mean =====> model.blk.6.ffn_norm.mean
	model.blk.46.ffn_norm.rstd =====> model.blk.6.ffn_norm.rstd
	model.blk.47.attn =====> model.blk.7.attn
	model.blk.47.attn_norm.out =====> model.blk.7.attn_norm.out
	model.blk.47.attn.trans =====> model.blk.7.attn.trans
	model.blk.47.attn.attn =====> model.blk.7.attn.attn
	model.blk.47.attn.wq.out =====> model.blk.7.attn.wq.out
	model.blk.47.attn.wq.weight =====> model.blk.7.attn.wq.weight
	model.blk.47.attn.wq.bias =====> model.blk.7.attn.wq.bias
	model.blk.47.attn.wk.out =====> model.blk.7.attn.wk.out
	model.blk.47.attn.wk.weight =====> model.blk.7.attn.wk.weight
	model.blk.47.attn.wk.bias =====> model.blk.7.attn.wk.bias
	model.blk.47.attn.wv.out =====> model.blk.7.attn.wv.out
	model.blk.47.attn.wv.weight =====> model.blk.7.attn.wv.weight
	model.blk.47.attn.wv.bias =====> model.blk.7.attn.wv.bias
	model.blk.47.attn.wo.out =====> model.blk.7.attn.wo.out
	model.blk.47.attn.wo.weight =====> model.blk.7.attn.wo.weight
	model.blk.47.attn.wo.bias =====> model.blk.7.attn.wo.bias
	model.blk.47.attn_norm.mean =====> model.blk.7.attn_norm.mean
	model.blk.47.attn_norm.rstd =====> model.blk.7.attn_norm.rstd
	model.blk.47.ffn =====> model.blk.7.ffn
	model.blk.47.ffn_norm.out =====> model.blk.7.ffn_norm.out
	model.blk.47.ffn_up.out =====> model.blk.7.ffn_up.out
	model.blk.47.ffn_up.weight =====> model.blk.7.ffn_up.weight
	model.blk.47.ffn_up.bias =====> model.blk.7.ffn_up.bias
	model.blk.47.ffn_down.out =====> model.blk.7.ffn_down.out
	model.blk.47.ffn_down.weight =====> model.blk.7.ffn_down.weight
	model.blk.47.ffn_down.bias =====> model.blk.7.ffn_down.bias
	model.blk.47.ffn_norm.weight =====> model.blk.7.ffn_norm.weight
	model.blk.47.ffn_norm.bias =====> model.blk.7.ffn_norm.bias
	model.blk.47.ffn_norm.mean =====> model.blk.7.ffn_norm.mean
	model.blk.47.ffn_norm.rstd =====> model.blk.7.ffn_norm.rstd
[RLS_branch] 	Guoke=1200(1320) nSection=6 isRefParam=1	
	model.blk.8.attn.wq.weight =====> model.blk.0.attn.wq.weight
	model.blk.8.attn.wq.bias =====> model.blk.0.attn.wq.bias
	model.blk.8.attn.wk.weight =====> model.blk.0.attn.wk.weight
	model.blk.8.attn.wk.bias =====> model.blk.0.attn.wk.bias
	model.blk.8.attn.wv.weight =====> model.blk.0.attn.wv.weight
	model.blk.8.attn.wv.bias =====> model.blk.0.attn.wv.bias
	model.blk.8.attn.wo.weight =====> model.blk.0.attn.wo.weight
	model.blk.8.attn.wo.bias =====> model.blk.0.attn.wo.bias
	model.blk.8.ffn_up.weight =====> model.blk.0.ffn_up.weight
	model.blk.8.ffn_up.bias =====> model.blk.0.ffn_up.bias
	model.blk.8.ffn_down.weight =====> model.blk.0.ffn_down.weight
	model.blk.8.ffn_down.bias =====> model.blk.0.ffn_down.bias
	model.blk.8.ffn_norm.weight =====> model.blk.0.ffn_norm.weight
	model.blk.8.ffn_norm.bias =====> model.blk.0.ffn_norm.bias
	model.blk.9.attn.wq.weight =====> model.blk.1.attn.wq.weight
	model.blk.9.attn.wq.bias =====> model.blk.1.attn.wq.bias
	model.blk.9.attn.wk.weight =====> model.blk.1.attn.wk.weight
	model.blk.9.attn.wk.bias =====> model.blk.1.attn.wk.bias
	model.blk.9.attn.wv.weight =====> model.blk.1.attn.wv.weight
	model.blk.9.attn.wv.bias =====> model.blk.1.attn.wv.bias
	model.blk.9.attn.wo.weight =====> model.blk.1.attn.wo.weight
	model.blk.9.attn.wo.bias =====> model.blk.1.attn.wo.bias
	model.blk.9.ffn_up.weight =====> model.blk.1.ffn_up.weight
	model.blk.9.ffn_up.bias =====> model.blk.1.ffn_up.bias
	model.blk.9.ffn_down.weight =====> model.blk.1.ffn_down.weight
	model.blk.9.ffn_down.bias =====> model.blk.1.ffn_down.bias
	model.blk.9.ffn_norm.weight =====> model.blk.1.ffn_norm.weight
	model.blk.9.ffn_norm.bias =====> model.blk.1.ffn_norm.bias
	model.blk.10.attn.wq.weight =====> model.blk.2.attn.wq.weight
	model.blk.10.attn.wq.bias =====> model.blk.2.attn.wq.bias
	model.blk.10.attn.wk.weight =====> model.blk.2.attn.wk.weight
	model.blk.10.attn.wk.bias =====> model.blk.2.attn.wk.bias
	model.blk.10.attn.wv.weight =====> model.blk.2.attn.wv.weight
	model.blk.10.attn.wv.bias =====> model.blk.2.attn.wv.bias
	model.blk.10.attn.wo.weight =====> model.blk.2.attn.wo.weight
	model.blk.10.attn.wo.bias =====> model.blk.2.attn.wo.bias
	model.blk.10.ffn_up.weight =====> model.blk.2.ffn_up.weight
	model.blk.10.ffn_up.bias =====> model.blk.2.ffn_up.bias
	model.blk.10.ffn_down.weight =====> model.blk.2.ffn_down.weight
	model.blk.10.ffn_down.bias =====> model.blk.2.ffn_down.bias
	model.blk.10.ffn_norm.weight =====> model.blk.2.ffn_norm.weight
	model.blk.10.ffn_norm.bias =====> model.blk.2.ffn_norm.bias
	model.blk.11.attn.wq.weight =====> model.blk.3.attn.wq.weight
	model.blk.11.attn.wq.bias =====> model.blk.3.attn.wq.bias
	model.blk.11.attn.wk.weight =====> model.blk.3.attn.wk.weight
	model.blk.11.attn.wk.bias =====> model.blk.3.attn.wk.bias
	model.blk.11.attn.wv.weight =====> model.blk.3.attn.wv.weight
	model.blk.11.attn.wv.bias =====> model.blk.3.attn.wv.bias
	model.blk.11.attn.wo.weight =====> model.blk.3.attn.wo.weight
	model.blk.11.attn.wo.bias =====> model.blk.3.attn.wo.bias
	model.blk.11.ffn_up.weight =====> model.blk.3.ffn_up.weight
	model.blk.11.ffn_up.bias =====> model.blk.3.ffn_up.bias
	model.blk.11.ffn_down.weight =====> model.blk.3.ffn_down.weight
	model.blk.11.ffn_down.bias =====> model.blk.3.ffn_down.bias
	model.blk.11.ffn_norm.weight =====> model.blk.3.ffn_norm.weight
	model.blk.11.ffn_norm.bias =====> model.blk.3.ffn_norm.bias
	model.blk.12.attn.wq.weight =====> model.blk.4.attn.wq.weight
	model.blk.12.attn.wq.bias =====> model.blk.4.attn.wq.bias
	model.blk.12.attn.wk.weight =====> model.blk.4.attn.wk.weight
	model.blk.12.attn.wk.bias =====> model.blk.4.attn.wk.bias
	model.blk.12.attn.wv.weight =====> model.blk.4.attn.wv.weight
	model.blk.12.attn.wv.bias =====> model.blk.4.attn.wv.bias
	model.blk.12.attn.wo.weight =====> model.blk.4.attn.wo.weight
	model.blk.12.attn.wo.bias =====> model.blk.4.attn.wo.bias
	model.blk.12.ffn_up.weight =====> model.blk.4.ffn_up.weight
	model.blk.12.ffn_up.bias =====> model.blk.4.ffn_up.bias
	model.blk.12.ffn_down.weight =====> model.blk.4.ffn_down.weight
	model.blk.12.ffn_down.bias =====> model.blk.4.ffn_down.bias
	model.blk.12.ffn_norm.weight =====> model.blk.4.ffn_norm.weight
	model.blk.12.ffn_norm.bias =====> model.blk.4.ffn_norm.bias
	model.blk.13.attn.wq.weight =====> model.blk.5.attn.wq.weight
	model.blk.13.attn.wq.bias =====> model.blk.5.attn.wq.bias
	model.blk.13.attn.wk.weight =====> model.blk.5.attn.wk.weight
	model.blk.13.attn.wk.bias =====> model.blk.5.attn.wk.bias
	model.blk.13.attn.wv.weight =====> model.blk.5.attn.wv.weight
	model.blk.13.attn.wv.bias =====> model.blk.5.attn.wv.bias
	model.blk.13.attn.wo.weight =====> model.blk.5.attn.wo.weight
	model.blk.13.attn.wo.bias =====> model.blk.5.attn.wo.bias
	model.blk.13.ffn_up.weight =====> model.blk.5.ffn_up.weight
	model.blk.13.ffn_up.bias =====> model.blk.5.ffn_up.bias
	model.blk.13.ffn_down.weight =====> model.blk.5.ffn_down.weight
	model.blk.13.ffn_down.bias =====> model.blk.5.ffn_down.bias
	model.blk.13.ffn_norm.weight =====> model.blk.5.ffn_norm.weight
	model.blk.13.ffn_norm.bias =====> model.blk.5.ffn_norm.bias
	model.blk.14.attn.wq.weight =====> model.blk.6.attn.wq.weight
	model.blk.14.attn.wq.bias =====> model.blk.6.attn.wq.bias
	model.blk.14.attn.wk.weight =====> model.blk.6.attn.wk.weight
	model.blk.14.attn.wk.bias =====> model.blk.6.attn.wk.bias
	model.blk.14.attn.wv.weight =====> model.blk.6.attn.wv.weight
	model.blk.14.attn.wv.bias =====> model.blk.6.attn.wv.bias
	model.blk.14.attn.wo.weight =====> model.blk.6.attn.wo.weight
	model.blk.14.attn.wo.bias =====> model.blk.6.attn.wo.bias
	model.blk.14.ffn_up.weight =====> model.blk.6.ffn_up.weight
	model.blk.14.ffn_up.bias =====> model.blk.6.ffn_up.bias
	model.blk.14.ffn_down.weight =====> model.blk.6.ffn_down.weight
	model.blk.14.ffn_down.bias =====> model.blk.6.ffn_down.bias
	model.blk.14.ffn_norm.weight =====> model.blk.6.ffn_norm.weight
	model.blk.14.ffn_norm.bias =====> model.blk.6.ffn_norm.bias
	model.blk.15.attn.wq.weight =====> model.blk.7.attn.wq.weight
	model.blk.15.attn.wq.bias =====> model.blk.7.attn.wq.bias
	model.blk.15.attn.wk.weight =====> model.blk.7.attn.wk.weight
	model.blk.15.attn.wk.bias =====> model.blk.7.attn.wk.bias
	model.blk.15.attn.wv.weight =====> model.blk.7.attn.wv.weight
	model.blk.15.attn.wv.bias =====> model.blk.7.attn.wv.bias
	model.blk.15.attn.wo.weight =====> model.blk.7.attn.wo.weight
	model.blk.15.attn.wo.bias =====> model.blk.7.attn.wo.bias
	model.blk.15.ffn_up.weight =====> model.blk.7.ffn_up.weight
	model.blk.15.ffn_up.bias =====> model.blk.7.ffn_up.bias
	model.blk.15.ffn_down.weight =====> model.blk.7.ffn_down.weight
	model.blk.15.ffn_down.bias =====> model.blk.7.ffn_down.bias
	model.blk.15.ffn_norm.weight =====> model.blk.7.ffn_norm.weight
	model.blk.15.ffn_norm.bias =====> model.blk.7.ffn_norm.bias
	model.blk.16.attn.wq.weight =====> model.blk.0.attn.wq.weight
	model.blk.16.attn.wq.bias =====> model.blk.0.attn.wq.bias
	model.blk.16.attn.wk.weight =====> model.blk.0.attn.wk.weight
	model.blk.16.attn.wk.bias =====> model.blk.0.attn.wk.bias
	model.blk.16.attn.wv.weight =====> model.blk.0.attn.wv.weight
	model.blk.16.attn.wv.bias =====> model.blk.0.attn.wv.bias
	model.blk.16.attn.wo.weight =====> model.blk.0.attn.wo.weight
	model.blk.16.attn.wo.bias =====> model.blk.0.attn.wo.bias
	model.blk.16.ffn_up.weight =====> model.blk.0.ffn_up.weight
	model.blk.16.ffn_up.bias =====> model.blk.0.ffn_up.bias
	model.blk.16.ffn_down.weight =====> model.blk.0.ffn_down.weight
	model.blk.16.ffn_down.bias =====> model.blk.0.ffn_down.bias
	model.blk.16.ffn_norm.weight =====> model.blk.0.ffn_norm.weight
	model.blk.16.ffn_norm.bias =====> model.blk.0.ffn_norm.bias
	model.blk.17.attn.wq.weight =====> model.blk.1.attn.wq.weight
	model.blk.17.attn.wq.bias =====> model.blk.1.attn.wq.bias
	model.blk.17.attn.wk.weight =====> model.blk.1.attn.wk.weight
	model.blk.17.attn.wk.bias =====> model.blk.1.attn.wk.bias
	model.blk.17.attn.wv.weight =====> model.blk.1.attn.wv.weight
	model.blk.17.attn.wv.bias =====> model.blk.1.attn.wv.bias
	model.blk.17.attn.wo.weight =====> model.blk.1.attn.wo.weight
	model.blk.17.attn.wo.bias =====> model.blk.1.attn.wo.bias
	model.blk.17.ffn_up.weight =====> model.blk.1.ffn_up.weight
	model.blk.17.ffn_up.bias =====> model.blk.1.ffn_up.bias
	model.blk.17.ffn_down.weight =====> model.blk.1.ffn_down.weight
	model.blk.17.ffn_down.bias =====> model.blk.1.ffn_down.bias
	model.blk.17.ffn_norm.weight =====> model.blk.1.ffn_norm.weight
	model.blk.17.ffn_norm.bias =====> model.blk.1.ffn_norm.bias
	model.blk.18.attn.wq.weight =====> model.blk.2.attn.wq.weight
	model.blk.18.attn.wq.bias =====> model.blk.2.attn.wq.bias
	model.blk.18.attn.wk.weight =====> model.blk.2.attn.wk.weight
	model.blk.18.attn.wk.bias =====> model.blk.2.attn.wk.bias
	model.blk.18.attn.wv.weight =====> model.blk.2.attn.wv.weight
	model.blk.18.attn.wv.bias =====> model.blk.2.attn.wv.bias
	model.blk.18.attn.wo.weight =====> model.blk.2.attn.wo.weight
	model.blk.18.attn.wo.bias =====> model.blk.2.attn.wo.bias
	model.blk.18.ffn_up.weight =====> model.blk.2.ffn_up.weight
	model.blk.18.ffn_up.bias =====> model.blk.2.ffn_up.bias
	model.blk.18.ffn_down.weight =====> model.blk.2.ffn_down.weight
	model.blk.18.ffn_down.bias =====> model.blk.2.ffn_down.bias
	model.blk.18.ffn_norm.weight =====> model.blk.2.ffn_norm.weight
	model.blk.18.ffn_norm.bias =====> model.blk.2.ffn_norm.bias
	model.blk.19.attn.wq.weight =====> model.blk.3.attn.wq.weight
	model.blk.19.attn.wq.bias =====> model.blk.3.attn.wq.bias
	model.blk.19.attn.wk.weight =====> model.blk.3.attn.wk.weight
	model.blk.19.attn.wk.bias =====> model.blk.3.attn.wk.bias
	model.blk.19.attn.wv.weight =====> model.blk.3.attn.wv.weight
	model.blk.19.attn.wv.bias =====> model.blk.3.attn.wv.bias
	model.blk.19.attn.wo.weight =====> model.blk.3.attn.wo.weight
	model.blk.19.attn.wo.bias =====> model.blk.3.attn.wo.bias
	model.blk.19.ffn_up.weight =====> model.blk.3.ffn_up.weight
	model.blk.19.ffn_up.bias =====> model.blk.3.ffn_up.bias
	model.blk.19.ffn_down.weight =====> model.blk.3.ffn_down.weight
	model.blk.19.ffn_down.bias =====> model.blk.3.ffn_down.bias
	model.blk.19.ffn_norm.weight =====> model.blk.3.ffn_norm.weight
	model.blk.19.ffn_norm.bias =====> model.blk.3.ffn_norm.bias
	model.blk.20.attn.wq.weight =====> model.blk.4.attn.wq.weight
	model.blk.20.attn.wq.bias =====> model.blk.4.attn.wq.bias
	model.blk.20.attn.wk.weight =====> model.blk.4.attn.wk.weight
	model.blk.20.attn.wk.bias =====> model.blk.4.attn.wk.bias
	model.blk.20.attn.wv.weight =====> model.blk.4.attn.wv.weight
	model.blk.20.attn.wv.bias =====> model.blk.4.attn.wv.bias
	model.blk.20.attn.wo.weight =====> model.blk.4.attn.wo.weight
	model.blk.20.attn.wo.bias =====> model.blk.4.attn.wo.bias
	model.blk.20.ffn_up.weight =====> model.blk.4.ffn_up.weight
	model.blk.20.ffn_up.bias =====> model.blk.4.ffn_up.bias
	model.blk.20.ffn_down.weight =====> model.blk.4.ffn_down.weight
	model.blk.20.ffn_down.bias =====> model.blk.4.ffn_down.bias
	model.blk.20.ffn_norm.weight =====> model.blk.4.ffn_norm.weight
	model.blk.20.ffn_norm.bias =====> model.blk.4.ffn_norm.bias
	model.blk.21.attn.wq.weight =====> model.blk.5.attn.wq.weight
	model.blk.21.attn.wq.bias =====> model.blk.5.attn.wq.bias
	model.blk.21.attn.wk.weight =====> model.blk.5.attn.wk.weight
	model.blk.21.attn.wk.bias =====> model.blk.5.attn.wk.bias
	model.blk.21.attn.wv.weight =====> model.blk.5.attn.wv.weight
	model.blk.21.attn.wv.bias =====> model.blk.5.attn.wv.bias
	model.blk.21.attn.wo.weight =====> model.blk.5.attn.wo.weight
	model.blk.21.attn.wo.bias =====> model.blk.5.attn.wo.bias
	model.blk.21.ffn_up.weight =====> model.blk.5.ffn_up.weight
	model.blk.21.ffn_up.bias =====> model.blk.5.ffn_up.bias
	model.blk.21.ffn_down.weight =====> model.blk.5.ffn_down.weight
	model.blk.21.ffn_down.bias =====> model.blk.5.ffn_down.bias
	model.blk.21.ffn_norm.weight =====> model.blk.5.ffn_norm.weight
	model.blk.21.ffn_norm.bias =====> model.blk.5.ffn_norm.bias
	model.blk.22.attn.wq.weight =====> model.blk.6.attn.wq.weight
	model.blk.22.attn.wq.bias =====> model.blk.6.attn.wq.bias
	model.blk.22.attn.wk.weight =====> model.blk.6.attn.wk.weight
	model.blk.22.attn.wk.bias =====> model.blk.6.attn.wk.bias
	model.blk.22.attn.wv.weight =====> model.blk.6.attn.wv.weight
	model.blk.22.attn.wv.bias =====> model.blk.6.attn.wv.bias
	model.blk.22.attn.wo.weight =====> model.blk.6.attn.wo.weight
	model.blk.22.attn.wo.bias =====> model.blk.6.attn.wo.bias
	model.blk.22.ffn_up.weight =====> model.blk.6.ffn_up.weight
	model.blk.22.ffn_up.bias =====> model.blk.6.ffn_up.bias
	model.blk.22.ffn_down.weight =====> model.blk.6.ffn_down.weight
	model.blk.22.ffn_down.bias =====> model.blk.6.ffn_down.bias
	model.blk.22.ffn_norm.weight =====> model.blk.6.ffn_norm.weight
	model.blk.22.ffn_norm.bias =====> model.blk.6.ffn_norm.bias
	model.blk.23.attn.wq.weight =====> model.blk.7.attn.wq.weight
	model.blk.23.attn.wq.bias =====> model.blk.7.attn.wq.bias
	model.blk.23.attn.wk.weight =====> model.blk.7.attn.wk.weight
	model.blk.23.attn.wk.bias =====> model.blk.7.attn.wk.bias
	model.blk.23.attn.wv.weight =====> model.blk.7.attn.wv.weight
	model.blk.23.attn.wv.bias =====> model.blk.7.attn.wv.bias
	model.blk.23.attn.wo.weight =====> model.blk.7.attn.wo.weight
	model.blk.23.attn.wo.bias =====> model.blk.7.attn.wo.bias
	model.blk.23.ffn_up.weight =====> model.blk.7.ffn_up.weight
	model.blk.23.ffn_up.bias =====> model.blk.7.ffn_up.bias
	model.blk.23.ffn_down.weight =====> model.blk.7.ffn_down.weight
	model.blk.23.ffn_down.bias =====> model.blk.7.ffn_down.bias
	model.blk.23.ffn_norm.weight =====> model.blk.7.ffn_norm.weight
	model.blk.23.ffn_norm.bias =====> model.blk.7.ffn_norm.bias
	model.blk.24.attn.wq.weight =====> model.blk.0.attn.wq.weight
	model.blk.24.attn.wq.bias =====> model.blk.0.attn.wq.bias
	model.blk.24.attn.wk.weight =====> model.blk.0.attn.wk.weight
	model.blk.24.attn.wk.bias =====> model.blk.0.attn.wk.bias
	model.blk.24.attn.wv.weight =====> model.blk.0.attn.wv.weight
	model.blk.24.attn.wv.bias =====> model.blk.0.attn.wv.bias
	model.blk.24.attn.wo.weight =====> model.blk.0.attn.wo.weight
	model.blk.24.attn.wo.bias =====> model.blk.0.attn.wo.bias
	model.blk.24.ffn_up.weight =====> model.blk.0.ffn_up.weight
	model.blk.24.ffn_up.bias =====> model.blk.0.ffn_up.bias
	model.blk.24.ffn_down.weight =====> model.blk.0.ffn_down.weight
	model.blk.24.ffn_down.bias =====> model.blk.0.ffn_down.bias
	model.blk.24.ffn_norm.weight =====> model.blk.0.ffn_norm.weight
	model.blk.24.ffn_norm.bias =====> model.blk.0.ffn_norm.bias
	model.blk.25.attn.wq.weight =====> model.blk.1.attn.wq.weight
	model.blk.25.attn.wq.bias =====> model.blk.1.attn.wq.bias
	model.blk.25.attn.wk.weight =====> model.blk.1.attn.wk.weight
	model.blk.25.attn.wk.bias =====> model.blk.1.attn.wk.bias
	model.blk.25.attn.wv.weight =====> model.blk.1.attn.wv.weight
	model.blk.25.attn.wv.bias =====> model.blk.1.attn.wv.bias
	model.blk.25.attn.wo.weight =====> model.blk.1.attn.wo.weight
	model.blk.25.attn.wo.bias =====> model.blk.1.attn.wo.bias
	model.blk.25.ffn_up.weight =====> model.blk.1.ffn_up.weight
	model.blk.25.ffn_up.bias =====> model.blk.1.ffn_up.bias
	model.blk.25.ffn_down.weight =====> model.blk.1.ffn_down.weight
	model.blk.25.ffn_down.bias =====> model.blk.1.ffn_down.bias
	model.blk.25.ffn_norm.weight =====> model.blk.1.ffn_norm.weight
	model.blk.25.ffn_norm.bias =====> model.blk.1.ffn_norm.bias
	model.blk.26.attn.wq.weight =====> model.blk.2.attn.wq.weight
	model.blk.26.attn.wq.bias =====> model.blk.2.attn.wq.bias
	model.blk.26.attn.wk.weight =====> model.blk.2.attn.wk.weight
	model.blk.26.attn.wk.bias =====> model.blk.2.attn.wk.bias
	model.blk.26.attn.wv.weight =====> model.blk.2.attn.wv.weight
	model.blk.26.attn.wv.bias =====> model.blk.2.attn.wv.bias
	model.blk.26.attn.wo.weight =====> model.blk.2.attn.wo.weight
	model.blk.26.attn.wo.bias =====> model.blk.2.attn.wo.bias
	model.blk.26.ffn_up.weight =====> model.blk.2.ffn_up.weight
	model.blk.26.ffn_up.bias =====> model.blk.2.ffn_up.bias
	model.blk.26.ffn_down.weight =====> model.blk.2.ffn_down.weight
	model.blk.26.ffn_down.bias =====> model.blk.2.ffn_down.bias
	model.blk.26.ffn_norm.weight =====> model.blk.2.ffn_norm.weight
	model.blk.26.ffn_norm.bias =====> model.blk.2.ffn_norm.bias
	model.blk.27.attn.wq.weight =====> model.blk.3.attn.wq.weight
	model.blk.27.attn.wq.bias =====> model.blk.3.attn.wq.bias
	model.blk.27.attn.wk.weight =====> model.blk.3.attn.wk.weight
	model.blk.27.attn.wk.bias =====> model.blk.3.attn.wk.bias
	model.blk.27.attn.wv.weight =====> model.blk.3.attn.wv.weight
	model.blk.27.attn.wv.bias =====> model.blk.3.attn.wv.bias
	model.blk.27.attn.wo.weight =====> model.blk.3.attn.wo.weight
	model.blk.27.attn.wo.bias =====> model.blk.3.attn.wo.bias
	model.blk.27.ffn_up.weight =====> model.blk.3.ffn_up.weight
	model.blk.27.ffn_up.bias =====> model.blk.3.ffn_up.bias
	model.blk.27.ffn_down.weight =====> model.blk.3.ffn_down.weight
	model.blk.27.ffn_down.bias =====> model.blk.3.ffn_down.bias
	model.blk.27.ffn_norm.weight =====> model.blk.3.ffn_norm.weight
	model.blk.27.ffn_norm.bias =====> model.blk.3.ffn_norm.bias
	model.blk.28.attn.wq.weight =====> model.blk.4.attn.wq.weight
	model.blk.28.attn.wq.bias =====> model.blk.4.attn.wq.bias
	model.blk.28.attn.wk.weight =====> model.blk.4.attn.wk.weight
	model.blk.28.attn.wk.bias =====> model.blk.4.attn.wk.bias
	model.blk.28.attn.wv.weight =====> model.blk.4.attn.wv.weight
	model.blk.28.attn.wv.bias =====> model.blk.4.attn.wv.bias
	model.blk.28.attn.wo.weight =====> model.blk.4.attn.wo.weight
	model.blk.28.attn.wo.bias =====> model.blk.4.attn.wo.bias
	model.blk.28.ffn_up.weight =====> model.blk.4.ffn_up.weight
	model.blk.28.ffn_up.bias =====> model.blk.4.ffn_up.bias
	model.blk.28.ffn_down.weight =====> model.blk.4.ffn_down.weight
	model.blk.28.ffn_down.bias =====> model.blk.4.ffn_down.bias
	model.blk.28.ffn_norm.weight =====> model.blk.4.ffn_norm.weight
	model.blk.28.ffn_norm.bias =====> model.blk.4.ffn_norm.bias
	model.blk.29.attn.wq.weight =====> model.blk.5.attn.wq.weight
	model.blk.29.attn.wq.bias =====> model.blk.5.attn.wq.bias
	model.blk.29.attn.wk.weight =====> model.blk.5.attn.wk.weight
	model.blk.29.attn.wk.bias =====> model.blk.5.attn.wk.bias
	model.blk.29.attn.wv.weight =====> model.blk.5.attn.wv.weight
	model.blk.29.attn.wv.bias =====> model.blk.5.attn.wv.bias
	model.blk.29.attn.wo.weight =====> model.blk.5.attn.wo.weight
	model.blk.29.attn.wo.bias =====> model.blk.5.attn.wo.bias
	model.blk.29.ffn_up.weight =====> model.blk.5.ffn_up.weight
	model.blk.29.ffn_up.bias =====> model.blk.5.ffn_up.bias
	model.blk.29.ffn_down.weight =====> model.blk.5.ffn_down.weight
	model.blk.29.ffn_down.bias =====> model.blk.5.ffn_down.bias
	model.blk.29.ffn_norm.weight =====> model.blk.5.ffn_norm.weight
	model.blk.29.ffn_norm.bias =====> model.blk.5.ffn_norm.bias
	model.blk.30.attn.wq.weight =====> model.blk.6.attn.wq.weight
	model.blk.30.attn.wq.bias =====> model.blk.6.attn.wq.bias
	model.blk.30.attn.wk.weight =====> model.blk.6.attn.wk.weight
	model.blk.30.attn.wk.bias =====> model.blk.6.attn.wk.bias
	model.blk.30.attn.wv.weight =====> model.blk.6.attn.wv.weight
	model.blk.30.attn.wv.bias =====> model.blk.6.attn.wv.bias
	model.blk.30.attn.wo.weight =====> model.blk.6.attn.wo.weight
	model.blk.30.attn.wo.bias =====> model.blk.6.attn.wo.bias
	model.blk.30.ffn_up.weight =====> model.blk.6.ffn_up.weight
	model.blk.30.ffn_up.bias =====> model.blk.6.ffn_up.bias
	model.blk.30.ffn_down.weight =====> model.blk.6.ffn_down.weight
	model.blk.30.ffn_down.bias =====> model.blk.6.ffn_down.bias
	model.blk.30.ffn_norm.weight =====> model.blk.6.ffn_norm.weight
	model.blk.30.ffn_norm.bias =====> model.blk.6.ffn_norm.bias
	model.blk.31.attn.wq.weight =====> model.blk.7.attn.wq.weight
	model.blk.31.attn.wq.bias =====> model.blk.7.attn.wq.bias
	model.blk.31.attn.wk.weight =====> model.blk.7.attn.wk.weight
	model.blk.31.attn.wk.bias =====> model.blk.7.attn.wk.bias
	model.blk.31.attn.wv.weight =====> model.blk.7.attn.wv.weight
	model.blk.31.attn.wv.bias =====> model.blk.7.attn.wv.bias
	model.blk.31.attn.wo.weight =====> model.blk.7.attn.wo.weight
	model.blk.31.attn.wo.bias =====> model.blk.7.attn.wo.bias
	model.blk.31.ffn_up.weight =====> model.blk.7.ffn_up.weight
	model.blk.31.ffn_up.bias =====> model.blk.7.ffn_up.bias
	model.blk.31.ffn_down.weight =====> model.blk.7.ffn_down.weight
	model.blk.31.ffn_down.bias =====> model.blk.7.ffn_down.bias
	model.blk.31.ffn_norm.weight =====> model.blk.7.ffn_norm.weight
	model.blk.31.ffn_norm.bias =====> model.blk.7.ffn_norm.bias
	model.blk.32.attn.wq.weight =====> model.blk.0.attn.wq.weight
	model.blk.32.attn.wq.bias =====> model.blk.0.attn.wq.bias
	model.blk.32.attn.wk.weight =====> model.blk.0.attn.wk.weight
	model.blk.32.attn.wk.bias =====> model.blk.0.attn.wk.bias
	model.blk.32.attn.wv.weight =====> model.blk.0.attn.wv.weight
	model.blk.32.attn.wv.bias =====> model.blk.0.attn.wv.bias
	model.blk.32.attn.wo.weight =====> model.blk.0.attn.wo.weight
	model.blk.32.attn.wo.bias =====> model.blk.0.attn.wo.bias
	model.blk.32.ffn_up.weight =====> model.blk.0.ffn_up.weight
	model.blk.32.ffn_up.bias =====> model.blk.0.ffn_up.bias
	model.blk.32.ffn_down.weight =====> model.blk.0.ffn_down.weight
	model.blk.32.ffn_down.bias =====> model.blk.0.ffn_down.bias
	model.blk.32.ffn_norm.weight =====> model.blk.0.ffn_norm.weight
	model.blk.32.ffn_norm.bias =====> model.blk.0.ffn_norm.bias
	model.blk.33.attn.wq.weight =====> model.blk.1.attn.wq.weight
	model.blk.33.attn.wq.bias =====> model.blk.1.attn.wq.bias
	model.blk.33.attn.wk.weight =====> model.blk.1.attn.wk.weight
	model.blk.33.attn.wk.bias =====> model.blk.1.attn.wk.bias
	model.blk.33.attn.wv.weight =====> model.blk.1.attn.wv.weight
	model.blk.33.attn.wv.bias =====> model.blk.1.attn.wv.bias
	model.blk.33.attn.wo.weight =====> model.blk.1.attn.wo.weight
	model.blk.33.attn.wo.bias =====> model.blk.1.attn.wo.bias
	model.blk.33.ffn_up.weight =====> model.blk.1.ffn_up.weight
	model.blk.33.ffn_up.bias =====> model.blk.1.ffn_up.bias
	model.blk.33.ffn_down.weight =====> model.blk.1.ffn_down.weight
	model.blk.33.ffn_down.bias =====> model.blk.1.ffn_down.bias
	model.blk.33.ffn_norm.weight =====> model.blk.1.ffn_norm.weight
	model.blk.33.ffn_norm.bias =====> model.blk.1.ffn_norm.bias
	model.blk.34.attn.wq.weight =====> model.blk.2.attn.wq.weight
	model.blk.34.attn.wq.bias =====> model.blk.2.attn.wq.bias
	model.blk.34.attn.wk.weight =====> model.blk.2.attn.wk.weight
	model.blk.34.attn.wk.bias =====> model.blk.2.attn.wk.bias
	model.blk.34.attn.wv.weight =====> model.blk.2.attn.wv.weight
	model.blk.34.attn.wv.bias =====> model.blk.2.attn.wv.bias
	model.blk.34.attn.wo.weight =====> model.blk.2.attn.wo.weight
	model.blk.34.attn.wo.bias =====> model.blk.2.attn.wo.bias
	model.blk.34.ffn_up.weight =====> model.blk.2.ffn_up.weight
	model.blk.34.ffn_up.bias =====> model.blk.2.ffn_up.bias
	model.blk.34.ffn_down.weight =====> model.blk.2.ffn_down.weight
	model.blk.34.ffn_down.bias =====> model.blk.2.ffn_down.bias
	model.blk.34.ffn_norm.weight =====> model.blk.2.ffn_norm.weight
	model.blk.34.ffn_norm.bias =====> model.blk.2.ffn_norm.bias
	model.blk.35.attn.wq.weight =====> model.blk.3.attn.wq.weight
	model.blk.35.attn.wq.bias =====> model.blk.3.attn.wq.bias
	model.blk.35.attn.wk.weight =====> model.blk.3.attn.wk.weight
	model.blk.35.attn.wk.bias =====> model.blk.3.attn.wk.bias
	model.blk.35.attn.wv.weight =====> model.blk.3.attn.wv.weight
	model.blk.35.attn.wv.bias =====> model.blk.3.attn.wv.bias
	model.blk.35.attn.wo.weight =====> model.blk.3.attn.wo.weight
	model.blk.35.attn.wo.bias =====> model.blk.3.attn.wo.bias
	model.blk.35.ffn_up.weight =====> model.blk.3.ffn_up.weight
	model.blk.35.ffn_up.bias =====> model.blk.3.ffn_up.bias
	model.blk.35.ffn_down.weight =====> model.blk.3.ffn_down.weight
	model.blk.35.ffn_down.bias =====> model.blk.3.ffn_down.bias
	model.blk.35.ffn_norm.weight =====> model.blk.3.ffn_norm.weight
	model.blk.35.ffn_norm.bias =====> model.blk.3.ffn_norm.bias
	model.blk.36.attn.wq.weight =====> model.blk.4.attn.wq.weight
	model.blk.36.attn.wq.bias =====> model.blk.4.attn.wq.bias
	model.blk.36.attn.wk.weight =====> model.blk.4.attn.wk.weight
	model.blk.36.attn.wk.bias =====> model.blk.4.attn.wk.bias
	model.blk.36.attn.wv.weight =====> model.blk.4.attn.wv.weight
	model.blk.36.attn.wv.bias =====> model.blk.4.attn.wv.bias
	model.blk.36.attn.wo.weight =====> model.blk.4.attn.wo.weight
	model.blk.36.attn.wo.bias =====> model.blk.4.attn.wo.bias
	model.blk.36.ffn_up.weight =====> model.blk.4.ffn_up.weight
	model.blk.36.ffn_up.bias =====> model.blk.4.ffn_up.bias
	model.blk.36.ffn_down.weight =====> model.blk.4.ffn_down.weight
	model.blk.36.ffn_down.bias =====> model.blk.4.ffn_down.bias
	model.blk.36.ffn_norm.weight =====> model.blk.4.ffn_norm.weight
	model.blk.36.ffn_norm.bias =====> model.blk.4.ffn_norm.bias
	model.blk.37.attn.wq.weight =====> model.blk.5.attn.wq.weight
	model.blk.37.attn.wq.bias =====> model.blk.5.attn.wq.bias
	model.blk.37.attn.wk.weight =====> model.blk.5.attn.wk.weight
	model.blk.37.attn.wk.bias =====> model.blk.5.attn.wk.bias
	model.blk.37.attn.wv.weight =====> model.blk.5.attn.wv.weight
	model.blk.37.attn.wv.bias =====> model.blk.5.attn.wv.bias
	model.blk.37.attn.wo.weight =====> model.blk.5.attn.wo.weight
	model.blk.37.attn.wo.bias =====> model.blk.5.attn.wo.bias
	model.blk.37.ffn_up.weight =====> model.blk.5.ffn_up.weight
	model.blk.37.ffn_up.bias =====> model.blk.5.ffn_up.bias
	model.blk.37.ffn_down.weight =====> model.blk.5.ffn_down.weight
	model.blk.37.ffn_down.bias =====> model.blk.5.ffn_down.bias
	model.blk.37.ffn_norm.weight =====> model.blk.5.ffn_norm.weight
	model.blk.37.ffn_norm.bias =====> model.blk.5.ffn_norm.bias
	model.blk.38.attn.wq.weight =====> model.blk.6.attn.wq.weight
	model.blk.38.attn.wq.bias =====> model.blk.6.attn.wq.bias
	model.blk.38.attn.wk.weight =====> model.blk.6.attn.wk.weight
	model.blk.38.attn.wk.bias =====> model.blk.6.attn.wk.bias
	model.blk.38.attn.wv.weight =====> model.blk.6.attn.wv.weight
	model.blk.38.attn.wv.bias =====> model.blk.6.attn.wv.bias
	model.blk.38.attn.wo.weight =====> model.blk.6.attn.wo.weight
	model.blk.38.attn.wo.bias =====> model.blk.6.attn.wo.bias
	model.blk.38.ffn_up.weight =====> model.blk.6.ffn_up.weight
	model.blk.38.ffn_up.bias =====> model.blk.6.ffn_up.bias
	model.blk.38.ffn_down.weight =====> model.blk.6.ffn_down.weight
	model.blk.38.ffn_down.bias =====> model.blk.6.ffn_down.bias
	model.blk.38.ffn_norm.weight =====> model.blk.6.ffn_norm.weight
	model.blk.38.ffn_norm.bias =====> model.blk.6.ffn_norm.bias
	model.blk.39.attn.wq.weight =====> model.blk.7.attn.wq.weight
	model.blk.39.attn.wq.bias =====> model.blk.7.attn.wq.bias
	model.blk.39.attn.wk.weight =====> model.blk.7.attn.wk.weight
	model.blk.39.attn.wk.bias =====> model.blk.7.attn.wk.bias
	model.blk.39.attn.wv.weight =====> model.blk.7.attn.wv.weight
	model.blk.39.attn.wv.bias =====> model.blk.7.attn.wv.bias
	model.blk.39.attn.wo.weight =====> model.blk.7.attn.wo.weight
	model.blk.39.attn.wo.bias =====> model.blk.7.attn.wo.bias
	model.blk.39.ffn_up.weight =====> model.blk.7.ffn_up.weight
	model.blk.39.ffn_up.bias =====> model.blk.7.ffn_up.bias
	model.blk.39.ffn_down.weight =====> model.blk.7.ffn_down.weight
	model.blk.39.ffn_down.bias =====> model.blk.7.ffn_down.bias
	model.blk.39.ffn_norm.weight =====> model.blk.7.ffn_norm.weight
	model.blk.39.ffn_norm.bias =====> model.blk.7.ffn_norm.bias
	model.blk.40.attn.wq.weight =====> model.blk.0.attn.wq.weight
	model.blk.40.attn.wq.bias =====> model.blk.0.attn.wq.bias
	model.blk.40.attn.wk.weight =====> model.blk.0.attn.wk.weight
	model.blk.40.attn.wk.bias =====> model.blk.0.attn.wk.bias
	model.blk.40.attn.wv.weight =====> model.blk.0.attn.wv.weight
	model.blk.40.attn.wv.bias =====> model.blk.0.attn.wv.bias
	model.blk.40.attn.wo.weight =====> model.blk.0.attn.wo.weight
	model.blk.40.attn.wo.bias =====> model.blk.0.attn.wo.bias
	model.blk.40.ffn_up.weight =====> model.blk.0.ffn_up.weight
	model.blk.40.ffn_up.bias =====> model.blk.0.ffn_up.bias
	model.blk.40.ffn_down.weight =====> model.blk.0.ffn_down.weight
	model.blk.40.ffn_down.bias =====> model.blk.0.ffn_down.bias
	model.blk.40.ffn_norm.weight =====> model.blk.0.ffn_norm.weight
	model.blk.40.ffn_norm.bias =====> model.blk.0.ffn_norm.bias
	model.blk.41.attn.wq.weight =====> model.blk.1.attn.wq.weight
	model.blk.41.attn.wq.bias =====> model.blk.1.attn.wq.bias
	model.blk.41.attn.wk.weight =====> model.blk.1.attn.wk.weight
	model.blk.41.attn.wk.bias =====> model.blk.1.attn.wk.bias
	model.blk.41.attn.wv.weight =====> model.blk.1.attn.wv.weight
	model.blk.41.attn.wv.bias =====> model.blk.1.attn.wv.bias
	model.blk.41.attn.wo.weight =====> model.blk.1.attn.wo.weight
	model.blk.41.attn.wo.bias =====> model.blk.1.attn.wo.bias
	model.blk.41.ffn_up.weight =====> model.blk.1.ffn_up.weight
	model.blk.41.ffn_up.bias =====> model.blk.1.ffn_up.bias
	model.blk.41.ffn_down.weight =====> model.blk.1.ffn_down.weight
	model.blk.41.ffn_down.bias =====> model.blk.1.ffn_down.bias
	model.blk.41.ffn_norm.weight =====> model.blk.1.ffn_norm.weight
	model.blk.41.ffn_norm.bias =====> model.blk.1.ffn_norm.bias
	model.blk.42.attn.wq.weight =====> model.blk.2.attn.wq.weight
	model.blk.42.attn.wq.bias =====> model.blk.2.attn.wq.bias
	model.blk.42.attn.wk.weight =====> model.blk.2.attn.wk.weight
	model.blk.42.attn.wk.bias =====> model.blk.2.attn.wk.bias
	model.blk.42.attn.wv.weight =====> model.blk.2.attn.wv.weight
	model.blk.42.attn.wv.bias =====> model.blk.2.attn.wv.bias
	model.blk.42.attn.wo.weight =====> model.blk.2.attn.wo.weight
	model.blk.42.attn.wo.bias =====> model.blk.2.attn.wo.bias
	model.blk.42.ffn_up.weight =====> model.blk.2.ffn_up.weight
	model.blk.42.ffn_up.bias =====> model.blk.2.ffn_up.bias
	model.blk.42.ffn_down.weight =====> model.blk.2.ffn_down.weight
	model.blk.42.ffn_down.bias =====> model.blk.2.ffn_down.bias
	model.blk.42.ffn_norm.weight =====> model.blk.2.ffn_norm.weight
	model.blk.42.ffn_norm.bias =====> model.blk.2.ffn_norm.bias
	model.blk.43.attn.wq.weight =====> model.blk.3.attn.wq.weight
	model.blk.43.attn.wq.bias =====> model.blk.3.attn.wq.bias
	model.blk.43.attn.wk.weight =====> model.blk.3.attn.wk.weight
	model.blk.43.attn.wk.bias =====> model.blk.3.attn.wk.bias
	model.blk.43.attn.wv.weight =====> model.blk.3.attn.wv.weight
	model.blk.43.attn.wv.bias =====> model.blk.3.attn.wv.bias
	model.blk.43.attn.wo.weight =====> model.blk.3.attn.wo.weight
	model.blk.43.attn.wo.bias =====> model.blk.3.attn.wo.bias
	model.blk.43.ffn_up.weight =====> model.blk.3.ffn_up.weight
	model.blk.43.ffn_up.bias =====> model.blk.3.ffn_up.bias
	model.blk.43.ffn_down.weight =====> model.blk.3.ffn_down.weight
	model.blk.43.ffn_down.bias =====> model.blk.3.ffn_down.bias
	model.blk.43.ffn_norm.weight =====> model.blk.3.ffn_norm.weight
	model.blk.43.ffn_norm.bias =====> model.blk.3.ffn_norm.bias
	model.blk.44.attn.wq.weight =====> model.blk.4.attn.wq.weight
	model.blk.44.attn.wq.bias =====> model.blk.4.attn.wq.bias
	model.blk.44.attn.wk.weight =====> model.blk.4.attn.wk.weight
	model.blk.44.attn.wk.bias =====> model.blk.4.attn.wk.bias
	model.blk.44.attn.wv.weight =====> model.blk.4.attn.wv.weight
	model.blk.44.attn.wv.bias =====> model.blk.4.attn.wv.bias
	model.blk.44.attn.wo.weight =====> model.blk.4.attn.wo.weight
	model.blk.44.attn.wo.bias =====> model.blk.4.attn.wo.bias
	model.blk.44.ffn_up.weight =====> model.blk.4.ffn_up.weight
	model.blk.44.ffn_up.bias =====> model.blk.4.ffn_up.bias
	model.blk.44.ffn_down.weight =====> model.blk.4.ffn_down.weight
	model.blk.44.ffn_down.bias =====> model.blk.4.ffn_down.bias
	model.blk.44.ffn_norm.weight =====> model.blk.4.ffn_norm.weight
	model.blk.44.ffn_norm.bias =====> model.blk.4.ffn_norm.bias
	model.blk.45.attn.wq.weight =====> model.blk.5.attn.wq.weight
	model.blk.45.attn.wq.bias =====> model.blk.5.attn.wq.bias
	model.blk.45.attn.wk.weight =====> model.blk.5.attn.wk.weight
	model.blk.45.attn.wk.bias =====> model.blk.5.attn.wk.bias
	model.blk.45.attn.wv.weight =====> model.blk.5.attn.wv.weight
	model.blk.45.attn.wv.bias =====> model.blk.5.attn.wv.bias
	model.blk.45.attn.wo.weight =====> model.blk.5.attn.wo.weight
	model.blk.45.attn.wo.bias =====> model.blk.5.attn.wo.bias
	model.blk.45.ffn_up.weight =====> model.blk.5.ffn_up.weight
	model.blk.45.ffn_up.bias =====> model.blk.5.ffn_up.bias
	model.blk.45.ffn_down.weight =====> model.blk.5.ffn_down.weight
	model.blk.45.ffn_down.bias =====> model.blk.5.ffn_down.bias
	model.blk.45.ffn_norm.weight =====> model.blk.5.ffn_norm.weight
	model.blk.45.ffn_norm.bias =====> model.blk.5.ffn_norm.bias
	model.blk.46.attn.wq.weight =====> model.blk.6.attn.wq.weight
	model.blk.46.attn.wq.bias =====> model.blk.6.attn.wq.bias
	model.blk.46.attn.wk.weight =====> model.blk.6.attn.wk.weight
	model.blk.46.attn.wk.bias =====> model.blk.6.attn.wk.bias
	model.blk.46.attn.wv.weight =====> model.blk.6.attn.wv.weight
	model.blk.46.attn.wv.bias =====> model.blk.6.attn.wv.bias
	model.blk.46.attn.wo.weight =====> model.blk.6.attn.wo.weight
	model.blk.46.attn.wo.bias =====> model.blk.6.attn.wo.bias
	model.blk.46.ffn_up.weight =====> model.blk.6.ffn_up.weight
	model.blk.46.ffn_up.bias =====> model.blk.6.ffn_up.bias
	model.blk.46.ffn_down.weight =====> model.blk.6.ffn_down.weight
	model.blk.46.ffn_down.bias =====> model.blk.6.ffn_down.bias
	model.blk.46.ffn_norm.weight =====> model.blk.6.ffn_norm.weight
	model.blk.46.ffn_norm.bias =====> model.blk.6.ffn_norm.bias
	model.blk.47.attn.wq.weight =====> model.blk.7.attn.wq.weight
	model.blk.47.attn.wq.bias =====> model.blk.7.attn.wq.bias
	model.blk.47.attn.wk.weight =====> model.blk.7.attn.wk.weight
	model.blk.47.attn.wk.bias =====> model.blk.7.attn.wk.bias
	model.blk.47.attn.wv.weight =====> model.blk.7.attn.wv.weight
	model.blk.47.attn.wv.bias =====> model.blk.7.attn.wv.bias
	model.blk.47.attn.wo.weight =====> model.blk.7.attn.wo.weight
	model.blk.47.attn.wo.bias =====> model.blk.7.attn.wo.bias
	model.blk.47.ffn_up.weight =====> model.blk.7.ffn_up.weight
	model.blk.47.ffn_up.bias =====> model.blk.7.ffn_up.bias
	model.blk.47.ffn_down.weight =====> model.blk.7.ffn_down.weight
	model.blk.47.ffn_down.bias =====> model.blk.7.ffn_down.bias
	model.blk.47.ffn_norm.weight =====> model.blk.7.ffn_norm.weight
	model.blk.47.ffn_norm.bias =====> model.blk.7.ffn_norm.bias
[Scheduling] MEM_STRATEGY=PRE_ALLOC_GPU UpdateParam=V1
[RLS]	nGuoke=1200(0) Memory of GPU=19274.5M(free=4510.84M)
[Fuyou] n=6 Explorer=[pso_ga] ensembler="BEST" nSwitch=100 "Only cur fuyou's params in GPU-memor!"

[Section@-1] layer[0-8] tasks=19(nPassBack=0) last_loss=3.40282e+38(0) N=(772,672,112 0)
[RLS] resident={model.inp_embd, model.blk.0.attn, model.blk.0.ffn, model.blk.1.attn, model.blk.1.ffn, model.blk.2.attn, model.blk.2.ffn, model.blk.3.attn, model.blk.3.ffn, model.blk.4.attn, model.blk.4.ffn, model.blk.5.attn, model.blk.5.ffn, model.blk.6.attn, model.blk.6.ffn, model.blk.7.attn, model.blk.7.ffn, model.output_norm, model.out.cls, }
[MEMORY] mGPU=19274.5M(free=4510.84M)
	 cudaMalloc=262.144M@model.inp_embd type=BF16(E8) shape=[80,1024,1600,1] sum=4.35593G
	 cudaMalloc=643.891M@model.inp_embd.weight type=BF16(E8) shape=[50304,1600,1,1]x2 sum=4.99982G
	 cudaMalloc=262.144M@model.blk.0.attn type=BF16(E8) shape=[80,1024,1600,1] sum=5.27507G
	 cudaMalloc=262.144M@model.blk.0.attn_norm.out type=BF16(E8) shape=[80,1024,1600,1] sum=5.53722G
	 cudaMalloc=262.144M@model.blk.0.attn.attn type=BF16(E8) shape=[80,1024,1600,1] sum=5.80755G
	 cudaMalloc=262.144M@model.blk.0.ffn type=BF16(E8) shape=[80,1024,1600,1] sum=6.15235G
	 cudaMalloc=262.144M@model.blk.0.ffn_norm.out type=BF16(E8) shape=[80,1024,1600,1] sum=6.41449G
	 cudaMalloc=262.144M@model.blk.1.attn type=BF16(E8) shape=[80,1024,1600,1] sum=6.84122G
	 cudaMalloc=262.144M@model.blk.1.attn_norm.out type=BF16(E8) shape=[80,1024,1600,1] sum=7.10337G
	 cudaMalloc=262.144M@model.blk.1.attn.attn type=BF16(E8) shape=[80,1024,1600,1] sum=7.3737G
	 cudaMalloc=262.144M@model.blk.1.ffn type=BF16(E8) shape=[80,1024,1600,1] sum=7.7185G
	 cudaMalloc=262.144M@model.blk.1.ffn_norm.out type=BF16(E8) shape=[80,1024,1600,1] sum=7.98064G
	 cudaMalloc=262.144M@model.blk.2.attn type=BF16(E8) shape=[80,1024,1600,1] sum=8.40737G
	 cudaMalloc=262.144M@model.blk.2.attn_norm.out type=BF16(E8) shape=[80,1024,1600,1] sum=8.66952G
	 cudaMalloc=262.144M@model.blk.2.attn.attn type=BF16(E8) shape=[80,1024,1600,1] sum=8.93985G
	 cudaMalloc=262.144M@model.blk.2.ffn type=BF16(E8) shape=[80,1024,1600,1] sum=9.28465G
	 cudaMalloc=262.144M@model.blk.2.ffn_norm.out type=BF16(E8) shape=[80,1024,1600,1] sum=9.54679G
	 cudaMalloc=262.144M@model.blk.3.attn type=BF16(E8) shape=[80,1024,1600,1] sum=9.97352G
	 cudaMalloc=262.144M@model.blk.3.attn_norm.out type=BF16(E8) shape=[80,1024,1600,1] sum=10.2357G
	 cudaMalloc=262.144M@model.blk.3.attn.attn type=BF16(E8) shape=[80,1024,1600,1] sum=10.506G
	 cudaMalloc=262.144M@model.blk.3.ffn type=BF16(E8) shape=[80,1024,1600,1] sum=10.8508G
	 cudaMalloc=262.144M@model.blk.3.ffn_norm.out type=BF16(E8) shape=[80,1024,1600,1] sum=11.1129G
	 cudaMalloc=262.144M@model.blk.4.attn type=BF16(E8) shape=[80,1024,1600,1] sum=11.5397G
	 cudaMalloc=262.144M@model.blk.4.attn_norm.out type=BF16(E8) shape=[80,1024,1600,1] sum=11.8018G
	 cudaMalloc=262.144M@model.blk.4.attn.attn type=BF16(E8) shape=[80,1024,1600,1] sum=12.0722G
	 cudaMalloc=262.144M@model.blk.4.ffn type=BF16(E8) shape=[80,1024,1600,1] sum=12.4169G
	 cudaMalloc=262.144M@model.blk.4.ffn_norm.out type=BF16(E8) shape=[80,1024,1600,1] sum=12.6791G
	 cudaMalloc=262.144M@model.blk.5.attn type=BF16(E8) shape=[80,1024,1600,1] sum=13.1058G
	 cudaMalloc=262.144M@model.blk.5.attn_norm.out type=BF16(E8) shape=[80,1024,1600,1] sum=13.368G
	 cudaMalloc=262.144M@model.blk.5.attn.attn type=BF16(E8) shape=[80,1024,1600,1] sum=13.6383G
	 cudaMalloc=262.144M@model.blk.5.ffn type=BF16(E8) shape=[80,1024,1600,1] sum=13.9831G
	 cudaMalloc=262.144M@model.blk.5.ffn_norm.out type=BF16(E8) shape=[80,1024,1600,1] sum=14.2452G
	 cudaMalloc=262.144M@model.blk.6.attn type=BF16(E8) shape=[80,1024,1600,1] sum=14.672G
	 cudaMalloc=262.144M@model.blk.6.attn_norm.out type=BF16(E8) shape=[80,1024,1600,1] sum=14.9341G
	 cudaMalloc=262.144M@model.blk.6.attn.attn type=BF16(E8) shape=[80,1024,1600,1] sum=15.2044G
	 cudaMalloc=262.144M@model.blk.6.ffn type=BF16(E8) shape=[80,1024,1600,1] sum=15.5492G
	 cudaMalloc=262.144M@model.blk.6.ffn_norm.out type=BF16(E8) shape=[80,1024,1600,1] sum=15.8114G
	 cudaMalloc=262.144M@model.blk.7.attn type=BF16(E8) shape=[80,1024,1600,1] sum=16.2381G
	 cudaMalloc=262.144M@model.blk.7.attn_norm.out type=BF16(E8) shape=[80,1024,1600,1] sum=16.5003G
	 cudaMalloc=262.144M@model.blk.7.attn.attn type=BF16(E8) shape=[80,1024,1600,1] sum=16.7706G
	 cudaMalloc=262.144M@model.blk.7.ffn type=BF16(E8) shape=[80,1024,1600,1] sum=17.1154G
	 cudaMalloc=262.144M@model.blk.7.ffn_norm.out type=BF16(E8) shape=[80,1024,1600,1] sum=17.3775G
	 cudaMalloc=262.144M@model.output_norm type=BF16(E8) shape=[80,1024,1600,1] sum=20.2643G
	 cudaMalloc=824.181M@preLogits type=BF16(E8) shape=[8,1024,50304,1] sum=21.0895G
[TGraph::Prepare4Train] AdamTensor=(194,0.0189%) filter={"output" "norm" }

	[DictVAE]:resi=1 tpNorm=2 opOut="RND_GRAD" nLevel=0

	 {EMBED n=50257 +POS} SYM
{		 QKV E1600 H25 x=1 trans=0 }
		 model.blk.0.ffn {hidden=6400}  
{		 QKV E1600 H25 x=1 trans=0 }
		 model.blk.1.ffn {hidden=6400}  
{		 QKV E1600 H25 x=1 trans=0 }
		 model.blk.2.ffn {hidden=6400}  
{		 QKV E1600 H25 x=1 trans=0 }
		 model.blk.3.ffn {hidden=6400}  
{		 QKV E1600 H25 x=1 trans=0 }
		 model.blk.4.ffn {hidden=6400}  
{		 QKV E1600 H25 x=1 trans=0 }
		 model.blk.5.ffn {hidden=6400}  
{		 QKV E1600 H25 x=1 trans=0 }
		 model.blk.6.ffn {hidden=6400}  
{		 QKV E1600 H25 x=1 trans=0 }
		 model.blk.7.ffn {hidden=6400}  
{		 QKV E1600 H25 x=1 trans=0 }
		 model.blk.8.ffn {hidden=6400}  
{		 QKV E1600 H25 x=1 trans=0 }
		 model.blk.9.ffn {hidden=6400}  
{		 QKV E1600 H25 x=1 trans=0 }
		 model.blk.10.ffn {hidden=6400}  
{		 QKV E1600 H25 x=1 trans=0 }
		 model.blk.11.ffn {hidden=6400}  
{		 QKV E1600 H25 x=1 trans=0 }
		 model.blk.12.ffn {hidden=6400}  
{		 QKV E1600 H25 x=1 trans=0 }
		 model.blk.13.ffn {hidden=6400}  
{		 QKV E1600 H25 x=1 trans=0 }
		 model.blk.14.ffn {hidden=6400}  
{		 QKV E1600 H25 x=1 trans=0 }
		 model.blk.15.ffn {hidden=6400}  
{		 QKV E1600 H25 x=1 trans=0 }
		 model.blk.16.ffn {hidden=6400}  
{		 QKV E1600 H25 x=1 trans=0 }
		 model.blk.17.ffn {hidden=6400}  
{		 QKV E1600 H25 x=1 trans=0 }
		 model.blk.18.ffn {hidden=6400}  
{		 QKV E1600 H25 x=1 trans=0 }
		 model.blk.19.ffn {hidden=6400}  
{		 QKV E1600 H25 x=1 trans=0 }
		 model.blk.20.ffn {hidden=6400}  
{		 QKV E1600 H25 x=1 trans=0 }
		 model.blk.21.ffn {hidden=6400}  
{		 QKV E1600 H25 x=1 trans=0 }
		 model.blk.22.ffn {hidden=6400}  
{		 QKV E1600 H25 x=1 trans=0 }
		 model.blk.23.ffn {hidden=6400}  
{		 QKV E1600 H25 x=1 trans=0 }
		 model.blk.24.ffn {hidden=6400}  
{		 QKV E1600 H25 x=1 trans=0 }
		 model.blk.25.ffn {hidden=6400}  
{		 QKV E1600 H25 x=1 trans=0 }
		 model.blk.26.ffn {hidden=6400}  
{		 QKV E1600 H25 x=1 trans=0 }
		 model.blk.27.ffn {hidden=6400}  
{		 QKV E1600 H25 x=1 trans=0 }
		 model.blk.28.ffn {hidden=6400}  
{		 QKV E1600 H25 x=1 trans=0 }
		 model.blk.29.ffn {hidden=6400}  
{		 QKV E1600 H25 x=1 trans=0 }
		 model.blk.30.ffn {hidden=6400}  
{		 QKV E1600 H25 x=1 trans=0 }
		 model.blk.31.ffn {hidden=6400}  
{		 QKV E1600 H25 x=1 trans=0 }
		 model.blk.32.ffn {hidden=6400}  
{		 QKV E1600 H25 x=1 trans=0 }
		 model.blk.33.ffn {hidden=6400}  
{		 QKV E1600 H25 x=1 trans=0 }
		 model.blk.34.ffn {hidden=6400}  
{		 QKV E1600 H25 x=1 trans=0 }
		 model.blk.35.ffn {hidden=6400}  
{		 QKV E1600 H25 x=1 trans=0 }
		 model.blk.36.ffn {hidden=6400}  
{		 QKV E1600 H25 x=1 trans=0 }
		 model.blk.37.ffn {hidden=6400}  
{		 QKV E1600 H25 x=1 trans=0 }
		 model.blk.38.ffn {hidden=6400}  
{		 QKV E1600 H25 x=1 trans=0 }
		 model.blk.39.ffn {hidden=6400}  
{		 QKV E1600 H25 x=1 trans=0 }
		 model.blk.40.ffn {hidden=6400}  
{		 QKV E1600 H25 x=1 trans=0 }
		 model.blk.41.ffn {hidden=6400}  
{		 QKV E1600 H25 x=1 trans=0 }
		 model.blk.42.ffn {hidden=6400}  
{		 QKV E1600 H25 x=1 trans=0 }
		 model.blk.43.ffn {hidden=6400}  
{		 QKV E1600 H25 x=1 trans=0 }
		 model.blk.44.ffn {hidden=6400}  
{		 QKV E1600 H25 x=1 trans=0 }
		 model.blk.45.ffn {hidden=6400}  
{		 QKV E1600 H25 x=1 trans=0 }
		 model.blk.46.ffn {hidden=6400}  
{		 QKV E1600 H25 x=1 trans=0 }
		 model.blk.47.ffn {hidden=6400}  
	 LayerNormal(+b+mean+rstd) out=model.output_norm
	 OutCLS{dB=8 x=50304} Tyring
  target(ID)=I32 'target' 0.0819M	[ 80  1024  1  1 I32] 
  loss=float 'model.out.cls' 0.0819M	[ 80  1024  1  1 float] 
	LAY=50	
========
 GPT2:    Bias=(normal=1,slp=1) AttOnBC=0
========
koifish::CLI_params: 
 n_ctx=1024 embd=1600 n_ff=6400 n_head=25 n_head_kv=25 n_layer=48(-1) f_norm_rms_eps=1e-05
 ROPE: type=0 freq_base=10000 freq_scale=1 n_rot=64
 SepQKV: type=1  
====== nParams = 1557686400(1557.69M nT=772) ======
Dump: nParams=1557686400 model_size = 0 bytes (0.0 MB)
Dump: n_vocab=50257 t_vocab=50257,n_batch=80,n_ctx=1024,n_embd=1600,n_head=25,n_rot=64,n_ff=6400
Dump: loader=
	 position_embd.weight                 P    szAlloc=13.1072M	[ 1600  1024  1  1 BF16(E8)] 
	 model.inp_embd.weight                P    szAlloc=643.891M	[ 50304  1600  1  1 BF16(E8)] 
	 model.blk.0.attn_norm.weight         P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.0.attn_norm.bias           P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.0.attn.wq.weight           P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.0.attn.wq.bias             P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.0.attn.wk.weight           P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.0.attn.wk.bias             P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.0.attn.wv.weight           P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.0.attn.wv.bias             P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.0.attn.wo.weight           P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.0.attn.wo.bias             P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.1.attn_norm.weight         P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.0.ffn_norm.weight          P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.0.ffn_norm.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.0.ffn_down.weight          P    szAlloc= 81.92M	[ 6400  1600  1  1 BF16(E8)] 
	 model.blk.0.ffn_down.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.0.ffn_up.weight            P    szAlloc= 81.92M	[ 1600  6400  1  1 BF16(E8)] 
	 model.blk.0.ffn_up.bias              P    szAlloc=0.0512M	[ 6400  1  1  1 BF16(E8)] 
	 model.blk.1.attn_norm.bias           P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.1.attn.wq.weight           P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.1.attn.wq.bias             P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.1.attn.wk.weight           P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.1.attn.wk.bias             P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.1.attn.wv.weight           P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.1.attn.wv.bias             P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.1.attn.wo.weight           P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.1.attn.wo.bias             P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.2.attn_norm.weight         P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.1.ffn_norm.weight          P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.1.ffn_norm.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.1.ffn_down.weight          P    szAlloc= 81.92M	[ 6400  1600  1  1 BF16(E8)] 
	 model.blk.1.ffn_down.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.1.ffn_up.weight            P    szAlloc= 81.92M	[ 1600  6400  1  1 BF16(E8)] 
	 model.blk.1.ffn_up.bias              P    szAlloc=0.0512M	[ 6400  1  1  1 BF16(E8)] 
	 model.blk.2.attn_norm.bias           P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.2.attn.wq.weight           P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.2.attn.wq.bias             P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.2.attn.wk.weight           P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.2.attn.wk.bias             P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.2.attn.wv.weight           P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.2.attn.wv.bias             P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.2.attn.wo.weight           P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.2.attn.wo.bias             P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.2.ffn_norm.weight          P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.2.ffn_norm.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.2.ffn_down.weight          P    szAlloc= 81.92M	[ 6400  1600  1  1 BF16(E8)] 
	 model.blk.2.ffn_down.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.2.ffn_up.weight            P    szAlloc= 81.92M	[ 1600  6400  1  1 BF16(E8)] 
	 model.blk.2.ffn_up.bias              P    szAlloc=0.0512M	[ 6400  1  1  1 BF16(E8)] 
	 model.blk.3.attn_norm.weight         P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.3.attn_norm.bias           P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.3.attn.wq.weight           P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.3.attn.wq.bias             P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.3.attn.wk.weight           P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.3.attn.wk.bias             P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.3.attn.wv.weight           P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.3.attn.wv.bias             P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.3.attn.wo.weight           P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.3.attn.wo.bias             P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.3.ffn_norm.weight          P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.3.ffn_norm.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.3.ffn_down.weight          P    szAlloc= 81.92M	[ 6400  1600  1  1 BF16(E8)] 
	 model.blk.3.ffn_down.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.3.ffn_up.weight            P    szAlloc= 81.92M	[ 1600  6400  1  1 BF16(E8)] 
	 model.blk.3.ffn_up.bias              P    szAlloc=0.0512M	[ 6400  1  1  1 BF16(E8)] 
	 model.blk.4.attn_norm.weight         P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.4.attn_norm.bias           P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.4.attn.wq.weight           P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.4.attn.wq.bias             P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.4.attn.wk.weight           P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.4.attn.wk.bias             P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.4.attn.wv.weight           P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.4.attn.wv.bias             P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.4.attn.wo.weight           P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.4.attn.wo.bias             P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.4.ffn_norm.weight          P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.4.ffn_norm.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.4.ffn_down.weight          P    szAlloc= 81.92M	[ 6400  1600  1  1 BF16(E8)] 
	 model.blk.4.ffn_down.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.4.ffn_up.weight            P    szAlloc= 81.92M	[ 1600  6400  1  1 BF16(E8)] 
	 model.blk.4.ffn_up.bias              P    szAlloc=0.0512M	[ 6400  1  1  1 BF16(E8)] 
	 model.blk.5.attn_norm.weight         P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.5.attn_norm.bias           P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.5.attn.wq.weight           P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.5.attn.wq.bias             P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.5.attn.wk.weight           P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.5.attn.wk.bias             P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.5.attn.wv.weight           P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.5.attn.wv.bias             P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.5.attn.wo.weight           P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.5.attn.wo.bias             P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.5.ffn_norm.weight          P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.5.ffn_norm.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.5.ffn_down.weight          P    szAlloc= 81.92M	[ 6400  1600  1  1 BF16(E8)] 
	 model.blk.5.ffn_down.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.5.ffn_up.weight            P    szAlloc= 81.92M	[ 1600  6400  1  1 BF16(E8)] 
	 model.blk.5.ffn_up.bias              P    szAlloc=0.0512M	[ 6400  1  1  1 BF16(E8)] 
	 model.blk.6.attn_norm.weight         P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.6.attn_norm.bias           P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.6.attn.wq.weight           P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.6.attn.wq.bias             P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.6.attn.wk.weight           P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.6.attn.wk.bias             P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.6.attn.wv.weight           P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.6.attn.wv.bias             P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.6.attn.wo.weight           P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.6.attn.wo.bias             P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.6.ffn_norm.weight          P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.6.ffn_norm.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.6.ffn_down.weight          P    szAlloc= 81.92M	[ 6400  1600  1  1 BF16(E8)] 
	 model.blk.6.ffn_down.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.6.ffn_up.weight            P    szAlloc= 81.92M	[ 1600  6400  1  1 BF16(E8)] 
	 model.blk.6.ffn_up.bias              P    szAlloc=0.0512M	[ 6400  1  1  1 BF16(E8)] 
	 model.blk.7.attn_norm.weight         P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.7.attn_norm.bias           P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.7.attn.wq.weight           P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.7.attn.wq.bias             P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.7.attn.wk.weight           P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.7.attn.wk.bias             P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.7.attn.wv.weight           P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.7.attn.wv.bias             P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.7.attn.wo.weight           P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.7.attn.wo.bias             P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.7.ffn_norm.weight          P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.7.ffn_norm.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.7.ffn_down.weight          P    szAlloc= 81.92M	[ 6400  1600  1  1 BF16(E8)] 
	 model.blk.7.ffn_down.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.7.ffn_up.weight            P    szAlloc= 81.92M	[ 1600  6400  1  1 BF16(E8)] 
	 model.blk.7.ffn_up.bias              P    szAlloc=0.0512M	[ 6400  1  1  1 BF16(E8)] 
	 model.blk.16.attn_norm.weight        P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.16.attn_norm.bias          P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.8.attn_norm.weight         P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.8.attn_norm.bias           P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.8.attn.wq.weight           P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.8.attn.wq.bias             P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.8.attn.wk.weight           P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.8.attn.wk.bias             P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.8.attn.wv.weight           P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.8.attn.wv.bias             P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.8.attn.wo.weight           P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.8.attn.wo.bias             P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.8.ffn_norm.weight          P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.8.ffn_norm.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.8.ffn_down.weight          P    szAlloc= 81.92M	[ 6400  1600  1  1 BF16(E8)] 
	 model.blk.8.ffn_down.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.8.ffn_up.weight            P    szAlloc= 81.92M	[ 1600  6400  1  1 BF16(E8)] 
	 model.blk.8.ffn_up.bias              P    szAlloc=0.0512M	[ 6400  1  1  1 BF16(E8)] 
	 model.blk.9.attn_norm.weight         P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.9.attn_norm.bias           P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.9.attn.wq.weight           P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.9.attn.wq.bias             P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.9.attn.wk.weight           P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.9.attn.wk.bias             P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.9.attn.wv.weight           P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.9.attn.wv.bias             P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.9.attn.wo.weight           P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.9.attn.wo.bias             P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.9.ffn_norm.weight          P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.9.ffn_norm.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.9.ffn_down.weight          P    szAlloc= 81.92M	[ 6400  1600  1  1 BF16(E8)] 
	 model.blk.9.ffn_down.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.9.ffn_up.weight            P    szAlloc= 81.92M	[ 1600  6400  1  1 BF16(E8)] 
	 model.blk.9.ffn_up.bias              P    szAlloc=0.0512M	[ 6400  1  1  1 BF16(E8)] 
	 model.blk.10.attn_norm.weight        P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.10.attn_norm.bias          P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.10.attn.wq.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.10.attn.wq.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.10.attn.wk.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.10.attn.wk.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.10.attn.wv.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.10.attn.wv.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.10.attn.wo.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.10.attn.wo.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.10.ffn_norm.weight         P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.10.ffn_norm.bias           P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.10.ffn_down.weight         P    szAlloc= 81.92M	[ 6400  1600  1  1 BF16(E8)] 
	 model.blk.10.ffn_down.bias           P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.10.ffn_up.weight           P    szAlloc= 81.92M	[ 1600  6400  1  1 BF16(E8)] 
	 model.blk.10.ffn_up.bias             P    szAlloc=0.0512M	[ 6400  1  1  1 BF16(E8)] 
	 model.blk.11.attn_norm.weight        P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.11.attn_norm.bias          P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.11.attn.wq.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.11.attn.wq.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.11.attn.wk.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.11.attn.wk.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.11.attn.wv.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.11.attn.wv.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.11.attn.wo.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.11.attn.wo.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.11.ffn_norm.weight         P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.11.ffn_norm.bias           P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.11.ffn_down.weight         P    szAlloc= 81.92M	[ 6400  1600  1  1 BF16(E8)] 
	 model.blk.11.ffn_down.bias           P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.11.ffn_up.weight           P    szAlloc= 81.92M	[ 1600  6400  1  1 BF16(E8)] 
	 model.blk.11.ffn_up.bias             P    szAlloc=0.0512M	[ 6400  1  1  1 BF16(E8)] 
	 model.blk.12.attn_norm.weight        P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.12.attn_norm.bias          P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.12.attn.wq.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.12.attn.wq.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.12.attn.wk.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.12.attn.wk.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.12.attn.wv.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.12.attn.wv.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.12.attn.wo.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.12.attn.wo.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.12.ffn_norm.weight         P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.12.ffn_norm.bias           P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.12.ffn_down.weight         P    szAlloc= 81.92M	[ 6400  1600  1  1 BF16(E8)] 
	 model.blk.12.ffn_down.bias           P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.12.ffn_up.weight           P    szAlloc= 81.92M	[ 1600  6400  1  1 BF16(E8)] 
	 model.blk.12.ffn_up.bias             P    szAlloc=0.0512M	[ 6400  1  1  1 BF16(E8)] 
	 model.blk.13.attn_norm.weight        P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.13.attn_norm.bias          P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.13.attn.wq.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.13.attn.wq.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.13.attn.wk.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.13.attn.wk.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.13.attn.wv.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.13.attn.wv.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.13.attn.wo.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.13.attn.wo.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.13.ffn_norm.weight         P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.13.ffn_norm.bias           P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.13.ffn_down.weight         P    szAlloc= 81.92M	[ 6400  1600  1  1 BF16(E8)] 
	 model.blk.13.ffn_down.bias           P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.13.ffn_up.weight           P    szAlloc= 81.92M	[ 1600  6400  1  1 BF16(E8)] 
	 model.blk.13.ffn_up.bias             P    szAlloc=0.0512M	[ 6400  1  1  1 BF16(E8)] 
	 model.blk.14.attn_norm.weight        P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.14.attn_norm.bias          P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.14.attn.wq.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.14.attn.wq.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.14.attn.wk.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.14.attn.wk.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.14.attn.wv.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.14.attn.wv.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.14.attn.wo.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.14.attn.wo.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.14.ffn_norm.weight         P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.14.ffn_norm.bias           P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.14.ffn_down.weight         P    szAlloc= 81.92M	[ 6400  1600  1  1 BF16(E8)] 
	 model.blk.14.ffn_down.bias           P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.14.ffn_up.weight           P    szAlloc= 81.92M	[ 1600  6400  1  1 BF16(E8)] 
	 model.blk.14.ffn_up.bias             P    szAlloc=0.0512M	[ 6400  1  1  1 BF16(E8)] 
	 model.blk.15.attn_norm.weight        P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.15.attn_norm.bias          P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.15.attn.wq.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.15.attn.wq.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.15.attn.wk.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.15.attn.wk.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.15.attn.wv.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.15.attn.wv.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.15.attn.wo.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.15.attn.wo.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.15.ffn_norm.weight         P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.15.ffn_norm.bias           P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.15.ffn_down.weight         P    szAlloc= 81.92M	[ 6400  1600  1  1 BF16(E8)] 
	 model.blk.15.ffn_down.bias           P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.15.ffn_up.weight           P    szAlloc= 81.92M	[ 1600  6400  1  1 BF16(E8)] 
	 model.blk.15.ffn_up.bias             P    szAlloc=0.0512M	[ 6400  1  1  1 BF16(E8)] 
	 model.blk.32.attn_norm.weight        P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.16.attn.wq.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.16.attn.wq.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.16.attn.wk.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.16.attn.wk.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.16.attn.wv.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.16.attn.wv.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.16.attn.wo.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.16.attn.wo.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.16.ffn_norm.weight         P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.16.ffn_norm.bias           P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.16.ffn_down.weight         P    szAlloc= 81.92M	[ 6400  1600  1  1 BF16(E8)] 
	 model.blk.16.ffn_down.bias           P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.16.ffn_up.weight           P    szAlloc= 81.92M	[ 1600  6400  1  1 BF16(E8)] 
	 model.blk.16.ffn_up.bias             P    szAlloc=0.0512M	[ 6400  1  1  1 BF16(E8)] 
	 model.blk.17.attn_norm.weight        P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.17.attn_norm.bias          P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.17.attn.wq.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.17.attn.wq.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.17.attn.wk.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.17.attn.wk.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.17.attn.wv.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.17.attn.wv.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.17.attn.wo.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.17.attn.wo.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.17.ffn_norm.weight         P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.17.ffn_norm.bias           P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.17.ffn_down.weight         P    szAlloc= 81.92M	[ 6400  1600  1  1 BF16(E8)] 
	 model.blk.17.ffn_down.bias           P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.17.ffn_up.weight           P    szAlloc= 81.92M	[ 1600  6400  1  1 BF16(E8)] 
	 model.blk.17.ffn_up.bias             P    szAlloc=0.0512M	[ 6400  1  1  1 BF16(E8)] 
	 model.blk.18.attn_norm.weight        P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.18.attn_norm.bias          P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.18.attn.wq.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.18.attn.wq.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.18.attn.wk.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.18.attn.wk.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.18.attn.wv.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.18.attn.wv.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.18.attn.wo.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.18.attn.wo.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.18.ffn_norm.weight         P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.18.ffn_norm.bias           P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.18.ffn_down.weight         P    szAlloc= 81.92M	[ 6400  1600  1  1 BF16(E8)] 
	 model.blk.18.ffn_down.bias           P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.18.ffn_up.weight           P    szAlloc= 81.92M	[ 1600  6400  1  1 BF16(E8)] 
	 model.blk.18.ffn_up.bias             P    szAlloc=0.0512M	[ 6400  1  1  1 BF16(E8)] 
	 model.blk.19.attn_norm.weight        P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.19.attn_norm.bias          P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.19.attn.wq.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.19.attn.wq.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.19.attn.wk.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.19.attn.wk.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.19.attn.wv.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.19.attn.wv.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.19.attn.wo.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.19.attn.wo.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.19.ffn_norm.weight         P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.19.ffn_norm.bias           P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.19.ffn_down.weight         P    szAlloc= 81.92M	[ 6400  1600  1  1 BF16(E8)] 
	 model.blk.19.ffn_down.bias           P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.19.ffn_up.weight           P    szAlloc= 81.92M	[ 1600  6400  1  1 BF16(E8)] 
	 model.blk.19.ffn_up.bias             P    szAlloc=0.0512M	[ 6400  1  1  1 BF16(E8)] 
	 model.blk.20.attn_norm.weight        P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.20.attn_norm.bias          P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.20.attn.wq.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.20.attn.wq.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.20.attn.wk.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.20.attn.wk.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.20.attn.wv.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.20.attn.wv.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.20.attn.wo.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.20.attn.wo.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.20.ffn_norm.weight         P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.20.ffn_norm.bias           P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.20.ffn_down.weight         P    szAlloc= 81.92M	[ 6400  1600  1  1 BF16(E8)] 
	 model.blk.20.ffn_down.bias           P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.20.ffn_up.weight           P    szAlloc= 81.92M	[ 1600  6400  1  1 BF16(E8)] 
	 model.blk.20.ffn_up.bias             P    szAlloc=0.0512M	[ 6400  1  1  1 BF16(E8)] 
	 model.blk.21.attn_norm.weight        P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.21.attn_norm.bias          P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.21.attn.wq.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.21.attn.wq.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.21.attn.wk.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.21.attn.wk.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.21.attn.wv.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.21.attn.wv.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.21.attn.wo.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.21.attn.wo.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.43.attn_norm.bias          P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.21.ffn_norm.weight         P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.21.ffn_norm.bias           P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.21.ffn_down.weight         P    szAlloc= 81.92M	[ 6400  1600  1  1 BF16(E8)] 
	 model.blk.21.ffn_down.bias           P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.21.ffn_up.weight           P    szAlloc= 81.92M	[ 1600  6400  1  1 BF16(E8)] 
	 model.blk.21.ffn_up.bias             P    szAlloc=0.0512M	[ 6400  1  1  1 BF16(E8)] 
	 model.blk.22.attn_norm.weight        P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.22.attn_norm.bias          P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.22.attn.wq.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.22.attn.wq.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.22.attn.wk.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.22.attn.wk.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.22.attn.wv.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.22.attn.wv.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.22.attn.wo.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.22.attn.wo.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.22.ffn_norm.weight         P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.22.ffn_norm.bias           P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.22.ffn_down.weight         P    szAlloc= 81.92M	[ 6400  1600  1  1 BF16(E8)] 
	 model.blk.22.ffn_down.bias           P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.22.ffn_up.weight           P    szAlloc= 81.92M	[ 1600  6400  1  1 BF16(E8)] 
	 model.blk.22.ffn_up.bias             P    szAlloc=0.0512M	[ 6400  1  1  1 BF16(E8)] 
	 model.blk.23.attn_norm.weight        P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.23.attn_norm.bias          P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.23.attn.wq.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.23.attn.wq.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.23.attn.wk.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.23.attn.wk.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.23.attn.wv.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.23.attn.wv.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.23.attn.wo.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.23.attn.wo.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.23.ffn_norm.weight         P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.23.ffn_norm.bias           P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.23.ffn_down.weight         P    szAlloc= 81.92M	[ 6400  1600  1  1 BF16(E8)] 
	 model.blk.23.ffn_down.bias           P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.23.ffn_up.weight           P    szAlloc= 81.92M	[ 1600  6400  1  1 BF16(E8)] 
	 model.blk.23.ffn_up.bias             P    szAlloc=0.0512M	[ 6400  1  1  1 BF16(E8)] 
	 model.blk.24.attn_norm.weight        P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.24.attn_norm.bias          P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.24.attn.wq.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.24.attn.wq.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.24.attn.wk.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.24.attn.wk.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.24.attn.wv.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.24.attn.wv.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.24.attn.wo.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.24.attn.wo.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.24.ffn_norm.weight         P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.24.ffn_norm.bias           P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.24.ffn_down.weight         P    szAlloc= 81.92M	[ 6400  1600  1  1 BF16(E8)] 
	 model.blk.24.ffn_down.bias           P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.24.ffn_up.weight           P    szAlloc= 81.92M	[ 1600  6400  1  1 BF16(E8)] 
	 model.blk.24.ffn_up.bias             P    szAlloc=0.0512M	[ 6400  1  1  1 BF16(E8)] 
	 model.blk.25.attn_norm.weight        P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.25.attn_norm.bias          P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.25.attn.wq.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.25.attn.wq.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.25.attn.wk.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.25.attn.wk.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.25.attn.wv.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.25.attn.wv.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.25.attn.wo.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.25.attn.wo.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.25.ffn_norm.weight         P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.25.ffn_norm.bias           P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.25.ffn_down.weight         P    szAlloc= 81.92M	[ 6400  1600  1  1 BF16(E8)] 
	 model.blk.25.ffn_down.bias           P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.25.ffn_up.weight           P    szAlloc= 81.92M	[ 1600  6400  1  1 BF16(E8)] 
	 model.blk.25.ffn_up.bias             P    szAlloc=0.0512M	[ 6400  1  1  1 BF16(E8)] 
	 model.blk.26.attn_norm.weight        P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.26.attn_norm.bias          P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.26.attn.wq.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.26.attn.wq.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.26.attn.wk.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.26.attn.wk.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.26.attn.wv.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.26.attn.wv.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.26.attn.wo.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.26.attn.wo.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.26.ffn_norm.weight         P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.26.ffn_norm.bias           P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.26.ffn_down.weight         P    szAlloc= 81.92M	[ 6400  1600  1  1 BF16(E8)] 
	 model.blk.26.ffn_down.bias           P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.26.ffn_up.weight           P    szAlloc= 81.92M	[ 1600  6400  1  1 BF16(E8)] 
	 model.blk.26.ffn_up.bias             P    szAlloc=0.0512M	[ 6400  1  1  1 BF16(E8)] 
	 model.blk.27.attn_norm.weight        P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.27.attn_norm.bias          P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.27.attn.wq.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.27.attn.wq.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.27.attn.wk.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.27.attn.wk.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.27.attn.wv.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.27.attn.wv.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.27.attn.wo.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.27.attn.wo.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.27.ffn_norm.weight         P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.27.ffn_norm.bias           P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.27.ffn_down.weight         P    szAlloc= 81.92M	[ 6400  1600  1  1 BF16(E8)] 
	 model.blk.27.ffn_down.bias           P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.27.ffn_up.weight           P    szAlloc= 81.92M	[ 1600  6400  1  1 BF16(E8)] 
	 model.blk.27.ffn_up.bias             P    szAlloc=0.0512M	[ 6400  1  1  1 BF16(E8)] 
	 model.blk.28.attn_norm.weight        P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.28.attn_norm.bias          P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.28.attn.wq.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.28.attn.wq.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.28.attn.wk.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.28.attn.wk.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.28.attn.wv.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.28.attn.wv.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.28.attn.wo.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.28.attn.wo.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.28.ffn_norm.weight         P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.28.ffn_norm.bias           P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.28.ffn_down.weight         P    szAlloc= 81.92M	[ 6400  1600  1  1 BF16(E8)] 
	 model.blk.28.ffn_down.bias           P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.28.ffn_up.weight           P    szAlloc= 81.92M	[ 1600  6400  1  1 BF16(E8)] 
	 model.blk.28.ffn_up.bias             P    szAlloc=0.0512M	[ 6400  1  1  1 BF16(E8)] 
	 model.blk.29.attn_norm.weight        P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.29.attn_norm.bias          P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.29.attn.wq.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.29.attn.wq.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.29.attn.wk.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.29.attn.wk.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.29.attn.wv.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.29.attn.wv.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.29.attn.wo.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.29.attn.wo.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.29.ffn_norm.weight         P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.29.ffn_norm.bias           P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.29.ffn_down.weight         P    szAlloc= 81.92M	[ 6400  1600  1  1 BF16(E8)] 
	 model.blk.29.ffn_down.bias           P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.29.ffn_up.weight           P    szAlloc= 81.92M	[ 1600  6400  1  1 BF16(E8)] 
	 model.blk.29.ffn_up.bias             P    szAlloc=0.0512M	[ 6400  1  1  1 BF16(E8)] 
	 model.blk.30.attn_norm.weight        P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.30.attn_norm.bias          P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.30.attn.wq.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.30.attn.wq.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.30.attn.wk.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.30.attn.wk.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.30.attn.wv.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.30.attn.wv.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.30.attn.wo.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.30.attn.wo.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.30.ffn_norm.weight         P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.30.ffn_norm.bias           P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.30.ffn_down.weight         P    szAlloc= 81.92M	[ 6400  1600  1  1 BF16(E8)] 
	 model.blk.30.ffn_down.bias           P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.30.ffn_up.weight           P    szAlloc= 81.92M	[ 1600  6400  1  1 BF16(E8)] 
	 model.blk.30.ffn_up.bias             P    szAlloc=0.0512M	[ 6400  1  1  1 BF16(E8)] 
	 model.blk.31.attn_norm.weight        P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.31.attn_norm.bias          P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.31.attn.wq.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.31.attn.wq.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.31.attn.wk.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.31.attn.wk.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.31.attn.wv.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.31.attn.wv.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.31.attn.wo.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.31.attn.wo.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.31.ffn_norm.weight         P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.31.ffn_norm.bias           P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.31.ffn_down.weight         P    szAlloc= 81.92M	[ 6400  1600  1  1 BF16(E8)] 
	 model.blk.31.ffn_down.bias           P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.31.ffn_up.weight           P    szAlloc= 81.92M	[ 1600  6400  1  1 BF16(E8)] 
	 model.blk.31.ffn_up.bias             P    szAlloc=0.0512M	[ 6400  1  1  1 BF16(E8)] 
	 model.blk.32.attn_norm.bias          P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.32.attn.wq.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.32.attn.wq.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.32.attn.wk.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.32.attn.wk.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.32.attn.wv.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.32.attn.wv.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.32.attn.wo.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.32.attn.wo.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.32.ffn_norm.weight         P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.32.ffn_norm.bias           P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.32.ffn_down.weight         P    szAlloc= 81.92M	[ 6400  1600  1  1 BF16(E8)] 
	 model.blk.32.ffn_down.bias           P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.32.ffn_up.weight           P    szAlloc= 81.92M	[ 1600  6400  1  1 BF16(E8)] 
	 model.blk.32.ffn_up.bias             P    szAlloc=0.0512M	[ 6400  1  1  1 BF16(E8)] 
	 model.blk.33.attn_norm.weight        P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.33.attn_norm.bias          P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.33.attn.wq.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.33.attn.wq.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.33.attn.wk.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.33.attn.wk.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.33.attn.wv.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.33.attn.wv.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.33.attn.wo.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.33.attn.wo.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.33.ffn_norm.weight         P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.33.ffn_norm.bias           P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.33.ffn_down.weight         P    szAlloc= 81.92M	[ 6400  1600  1  1 BF16(E8)] 
	 model.blk.33.ffn_down.bias           P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.33.ffn_up.weight           P    szAlloc= 81.92M	[ 1600  6400  1  1 BF16(E8)] 
	 model.blk.33.ffn_up.bias             P    szAlloc=0.0512M	[ 6400  1  1  1 BF16(E8)] 
	 model.blk.34.attn_norm.weight        P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.34.attn_norm.bias          P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.34.attn.wq.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.34.attn.wq.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.34.attn.wk.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.34.attn.wk.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.34.attn.wv.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.34.attn.wv.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.34.attn.wo.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.34.attn.wo.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.34.ffn_norm.weight         P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.34.ffn_norm.bias           P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.34.ffn_down.weight         P    szAlloc= 81.92M	[ 6400  1600  1  1 BF16(E8)] 
	 model.blk.34.ffn_down.bias           P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.34.ffn_up.weight           P    szAlloc= 81.92M	[ 1600  6400  1  1 BF16(E8)] 
	 model.blk.34.ffn_up.bias             P    szAlloc=0.0512M	[ 6400  1  1  1 BF16(E8)] 
	 model.blk.35.attn_norm.weight        P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.35.attn_norm.bias          P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.35.attn.wq.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.35.attn.wq.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.35.attn.wk.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.35.attn.wk.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.35.attn.wv.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.35.attn.wv.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.35.attn.wo.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.35.attn.wo.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.35.ffn_norm.weight         P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.35.ffn_norm.bias           P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.35.ffn_down.weight         P    szAlloc= 81.92M	[ 6400  1600  1  1 BF16(E8)] 
	 model.blk.35.ffn_down.bias           P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.35.ffn_up.weight           P    szAlloc= 81.92M	[ 1600  6400  1  1 BF16(E8)] 
	 model.blk.35.ffn_up.bias             P    szAlloc=0.0512M	[ 6400  1  1  1 BF16(E8)] 
	 model.blk.36.attn_norm.weight        P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.36.attn_norm.bias          P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.36.attn.wq.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.36.attn.wq.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.36.attn.wk.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.36.attn.wk.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.36.attn.wv.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.36.attn.wv.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.36.attn.wo.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.36.attn.wo.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.36.ffn_norm.weight         P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.36.ffn_norm.bias           P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.36.ffn_down.weight         P    szAlloc= 81.92M	[ 6400  1600  1  1 BF16(E8)] 
	 model.blk.36.ffn_down.bias           P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.36.ffn_up.weight           P    szAlloc= 81.92M	[ 1600  6400  1  1 BF16(E8)] 
	 model.blk.36.ffn_up.bias             P    szAlloc=0.0512M	[ 6400  1  1  1 BF16(E8)] 
	 model.blk.37.attn_norm.weight        P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.37.attn_norm.bias          P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.37.attn.wq.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.37.attn.wq.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.37.attn.wk.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.37.attn.wk.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.37.attn.wv.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.37.attn.wv.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.37.attn.wo.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.37.attn.wo.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.37.ffn_norm.weight         P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.37.ffn_norm.bias           P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.37.ffn_down.weight         P    szAlloc= 81.92M	[ 6400  1600  1  1 BF16(E8)] 
	 model.blk.37.ffn_down.bias           P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.37.ffn_up.weight           P    szAlloc= 81.92M	[ 1600  6400  1  1 BF16(E8)] 
	 model.blk.37.ffn_up.bias             P    szAlloc=0.0512M	[ 6400  1  1  1 BF16(E8)] 
	 model.blk.38.attn_norm.weight        P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.38.attn_norm.bias          P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.38.attn.wq.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.38.attn.wq.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.38.attn.wk.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.38.attn.wk.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.38.attn.wv.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.38.attn.wv.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.38.attn.wo.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.38.attn.wo.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.38.ffn_norm.weight         P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.38.ffn_norm.bias           P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.38.ffn_down.weight         P    szAlloc= 81.92M	[ 6400  1600  1  1 BF16(E8)] 
	 model.blk.38.ffn_down.bias           P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.38.ffn_up.weight           P    szAlloc= 81.92M	[ 1600  6400  1  1 BF16(E8)] 
	 model.blk.38.ffn_up.bias             P    szAlloc=0.0512M	[ 6400  1  1  1 BF16(E8)] 
	 model.blk.39.attn_norm.weight        P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.39.attn_norm.bias          P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.39.attn.wq.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.39.attn.wq.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.39.attn.wk.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.39.attn.wk.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.39.attn.wv.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.39.attn.wv.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.39.attn.wo.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.39.attn.wo.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.39.ffn_norm.weight         P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.39.ffn_norm.bias           P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.39.ffn_down.weight         P    szAlloc= 81.92M	[ 6400  1600  1  1 BF16(E8)] 
	 model.blk.39.ffn_down.bias           P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.39.ffn_up.weight           P    szAlloc= 81.92M	[ 1600  6400  1  1 BF16(E8)] 
	 model.blk.39.ffn_up.bias             P    szAlloc=0.0512M	[ 6400  1  1  1 BF16(E8)] 
	 model.blk.40.attn_norm.weight        P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.40.attn_norm.bias          P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.40.attn.wq.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.40.attn.wq.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.40.attn.wk.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.40.attn.wk.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.40.attn.wv.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.40.attn.wv.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.40.attn.wo.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.40.attn.wo.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.40.ffn_norm.weight         P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.40.ffn_norm.bias           P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.40.ffn_down.weight         P    szAlloc= 81.92M	[ 6400  1600  1  1 BF16(E8)] 
	 model.blk.40.ffn_down.bias           P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.40.ffn_up.weight           P    szAlloc= 81.92M	[ 1600  6400  1  1 BF16(E8)] 
	 model.blk.40.ffn_up.bias             P    szAlloc=0.0512M	[ 6400  1  1  1 BF16(E8)] 
	 model.blk.41.attn_norm.weight        P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.41.attn_norm.bias          P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.41.attn.wq.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.41.attn.wq.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.41.attn.wk.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.41.attn.wk.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.41.attn.wv.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.41.attn.wv.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.41.attn.wo.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.41.attn.wo.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.41.ffn_norm.weight         P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.41.ffn_norm.bias           P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.41.ffn_down.weight         P    szAlloc= 81.92M	[ 6400  1600  1  1 BF16(E8)] 
	 model.blk.41.ffn_down.bias           P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.41.ffn_up.weight           P    szAlloc= 81.92M	[ 1600  6400  1  1 BF16(E8)] 
	 model.blk.41.ffn_up.bias             P    szAlloc=0.0512M	[ 6400  1  1  1 BF16(E8)] 
	 model.blk.42.attn_norm.weight        P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.42.attn_norm.bias          P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.42.attn.wq.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.42.attn.wq.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.42.attn.wk.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.42.attn.wk.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.42.attn.wv.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.42.attn.wv.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.42.attn.wo.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.42.attn.wo.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.43.attn_norm.weight        P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.42.ffn_norm.weight         P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.42.ffn_norm.bias           P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.42.ffn_down.weight         P    szAlloc= 81.92M	[ 6400  1600  1  1 BF16(E8)] 
	 model.blk.42.ffn_down.bias           P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.42.ffn_up.weight           P    szAlloc= 81.92M	[ 1600  6400  1  1 BF16(E8)] 
	 model.blk.42.ffn_up.bias             P    szAlloc=0.0512M	[ 6400  1  1  1 BF16(E8)] 
	 model.blk.43.attn.wq.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.43.attn.wq.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.43.attn.wk.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.43.attn.wk.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.43.attn.wv.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.43.attn.wv.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.43.attn.wo.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.43.attn.wo.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.44.attn_norm.weight        P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.43.ffn_norm.weight         P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.43.ffn_norm.bias           P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.43.ffn_down.weight         P    szAlloc= 81.92M	[ 6400  1600  1  1 BF16(E8)] 
	 model.blk.43.ffn_down.bias           P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.43.ffn_up.weight           P    szAlloc= 81.92M	[ 1600  6400  1  1 BF16(E8)] 
	 model.blk.43.ffn_up.bias             P    szAlloc=0.0512M	[ 6400  1  1  1 BF16(E8)] 
	 model.blk.44.attn_norm.bias          P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.44.attn.wq.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.44.attn.wq.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.44.attn.wk.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.44.attn.wk.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.44.attn.wv.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.44.attn.wv.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.44.attn.wo.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.44.attn.wo.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.44.ffn_norm.weight         P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.44.ffn_norm.bias           P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.44.ffn_down.weight         P    szAlloc= 81.92M	[ 6400  1600  1  1 BF16(E8)] 
	 model.blk.44.ffn_down.bias           P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.44.ffn_up.weight           P    szAlloc= 81.92M	[ 1600  6400  1  1 BF16(E8)] 
	 model.blk.44.ffn_up.bias             P    szAlloc=0.0512M	[ 6400  1  1  1 BF16(E8)] 
	 model.blk.45.attn_norm.weight        P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.45.attn_norm.bias          P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.45.attn.wq.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.45.attn.wq.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.45.attn.wk.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.45.attn.wk.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.45.attn.wv.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.45.attn.wv.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.45.attn.wo.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.45.attn.wo.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.45.ffn_norm.weight         P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.45.ffn_norm.bias           P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.45.ffn_down.weight         P    szAlloc= 81.92M	[ 6400  1600  1  1 BF16(E8)] 
	 model.blk.45.ffn_down.bias           P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.45.ffn_up.weight           P    szAlloc= 81.92M	[ 1600  6400  1  1 BF16(E8)] 
	 model.blk.45.ffn_up.bias             P    szAlloc=0.0512M	[ 6400  1  1  1 BF16(E8)] 
	 model.blk.46.attn_norm.weight        P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.46.attn_norm.bias          P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.46.attn.wq.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.46.attn.wq.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.46.attn.wk.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.46.attn.wk.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.46.attn.wv.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.46.attn.wv.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.46.attn.wo.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.46.attn.wo.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.46.ffn_norm.weight         P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.46.ffn_norm.bias           P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.46.ffn_down.weight         P    szAlloc= 81.92M	[ 6400  1600  1  1 BF16(E8)] 
	 model.blk.46.ffn_down.bias           P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.46.ffn_up.weight           P    szAlloc= 81.92M	[ 1600  6400  1  1 BF16(E8)] 
	 model.blk.46.ffn_up.bias             P    szAlloc=0.0512M	[ 6400  1  1  1 BF16(E8)] 
	 model.blk.47.attn_norm.weight        P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.47.attn_norm.bias          P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.47.attn.wq.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.47.attn.wq.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.47.attn.wk.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.47.attn.wk.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.47.attn.wv.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.47.attn.wv.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.47.attn.wo.weight          P    szAlloc= 20.48M	[ 1600  1600  1  1 BF16(E8)] 
	 model.blk.47.attn.wo.bias            P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.47.ffn_norm.weight         P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.47.ffn_norm.bias           P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.47.ffn_down.weight         P    szAlloc= 81.92M	[ 6400  1600  1  1 BF16(E8)] 
	 model.blk.47.ffn_down.bias           P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.blk.47.ffn_up.weight           P    szAlloc= 81.92M	[ 1600  6400  1  1 BF16(E8)] 
	 model.blk.47.ffn_up.bias             P    szAlloc=0.0512M	[ 6400  1  1  1 BF16(E8)] 
	 model.output_norm.weight             P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 
	 model.output_norm.bias               P    szAlloc=0.0128M	[ 1600  1  1  1 BF16(E8)] 

[NO_QUANT] bit_per_parameter=16 szGama=2 TILEQ=(8,8) pQuant=W_SCALE tensor=0(0%) 
731 mem-blocks 	Total=18.6G activation=11912M weight=3115.4M grad=3115.4M moments=6230.7M temp=4093.1M other=0M
	0	1048.58M  @tmpScratch/output.a 	1.05G
	1	1048.58M  @tmpBT4c.a 	2.1G
	2	1048.58M  @tmpFF1.a 	3.15G
	3	824.181M  @preLogits.a 	3.97G
	4	321.946M  @model.inp_embd.weight.m 	4.29G
	5	262.144M  @model.blk.2.ffn.a 	4.55G
	6	262.144M  @model.blk.4.ffn_norm.out.a 	4.82G
	7	262.144M  @model.blk.4.ffn.a 	5.08G
	8	262.144M  @model.blk.4.attn.attn.a 	5.34G
	9	262.144M  @model.blk.4.attn_norm.out.a 	5.6G
	10	262.144M  @model.blk.4.attn.a 	5.86G
	11	262.144M  @model.blk.3.ffn_norm.out.a 	6.13G
	12	262.144M  @model.blk.3.ffn.a 	6.39G
	13	262.144M  @model.blk.3.attn.attn.a 	6.65G
	14	262.144M  @model.blk.3.attn_norm.out.a 	6.91G
	15	262.144M  @model.blk.3.attn.a 	7.18G
	16	262.144M  @model.blk.2.ffn_norm.out.a 	7.44G
	17	262.144M  @model.blk.5.attn_norm.out.a 	7.7G
	18	262.144M  @model.blk.2.attn.attn.a 	7.96G
	19	262.144M  @model.blk.2.attn_norm.out.a 	8.22G
	20	262.144M  @model.blk.2.attn.a 	8.49G
	21	262.144M  @model.blk.1.ffn_norm.out.a 	8.75G
	22	262.144M  @model.blk.1.ffn.a 	9.01G
	23	262.144M  @model.blk.1.attn.attn.a 	9.27G
	24	262.144M  @model.blk.1.attn_norm.out.a 	9.53G
	25	262.144M  @model.blk.1.attn.a 	9.8G
	26	262.144M  @model.blk.0.ffn_norm.out.a 	10.1G
	27	262.144M  @model.blk.0.ffn.a 	10.3G
	28	262.144M  @model.blk.0.attn_norm.out.a 	10.6G
	29	262.144M  @tmpOutL.a 	10.8G
	30	262.144M  @tmpDelta.a 	11.1G
	31	262.144M  @tmpDelta2.a 	11.4G
	32	262.144M  @model.output_norm.a 	11.6G
	33	262.144M  @model.inp_embd.a 	11.9G
	34	262.144M  @model.blk.7.ffn_norm.out.a 	12.2G
	35	262.144M  @model.blk.7.ffn.a 	12.4G
	36	262.144M  @model.blk.7.attn.attn.a 	12.7G
	37	262.144M  @model.blk.7.attn_norm.out.a 	12.9G
	38	262.144M  @model.blk.7.attn.a 	13.2G
	39	262.144M  @model.blk.0.attn.a 	13.5G
	40	262.144M  @model.blk.5.attn.a 	13.7G
	41	262.144M  @model.blk.6.ffn_norm.out.a 	14G
	42	262.144M  @model.blk.0.attn.attn.a 	14.3G
	43	262.144M  @model.blk.6.ffn.a 	14.5G
	44	262.144M  @model.blk.6.attn.attn.a 	14.8G
	45	262.144M  @model.blk.6.attn_norm.out.a 	15G
	46	262.144M  @model.blk.6.attn.a 	15.3G
	47	262.144M  @model.blk.5.ffn_norm.out.a 	15.6G
	48	262.144M  @model.blk.5.ffn.a 	15.8G
	49	262.144M  @model.blk.5.attn.attn.a 	16.1G
	50	160.973M  @tmpTernary.a 	16.2G
	51	160.973M  @model.inp_embd.weight.g 	16.4G
	52	160.973M  @model.inp_embd.weight.w 	16.6G
	53	 40.96M  @model.blk.7.ffn_up.weight.m 	16.6G
	54	 40.96M  @model.blk.2.ffn_down.weight.m 	16.7G
	55	 40.96M  @model.blk.4.ffn_down.weight.m 	16.7G
	56	 40.96M  @model.blk.2.ffn_up.weight.m 	16.7G
	57	 40.96M  @model.blk.4.ffn_up.weight.m 	16.8G
	58	 40.96M  @model.blk.5.ffn_up.weight.m 	16.8G
	59	 40.96M  @model.blk.5.ffn_down.weight.m 	16.9G
	60	 40.96M  @model.blk.6.ffn_down.weight.m 	16.9G
	61	 40.96M  @model.blk.7.ffn_down.weight.m 	16.9G
	62	 40.96M  @model.blk.3.ffn_down.weight.m 	17G
	63	 40.96M  @model.blk.0.ffn_down.weight.m 	17G
	64	 40.96M  @model.blk.1.ffn_down.weight.m 	17.1G
	65	 40.96M  @model.blk.3.ffn_up.weight.m 	17.1G
	66	 40.96M  @model.blk.0.ffn_up.weight.m 	17.1G
	67	 40.96M  @model.blk.1.ffn_up.weight.m 	17.2G
	68	 40.96M  @model.blk.6.ffn_up.weight.m 	17.2G
	69	 20.48M  @model.blk.5.ffn_up.weight.w 	17.2G
	70	 20.48M  @model.blk.2.ffn_down.weight.g 	17.3G
	71	 20.48M  @model.blk.6.ffn_up.weight.g 	17.3G
	72	 20.48M  @model.blk.2.ffn_down.weight.w 	17.3G
	73	 20.48M  @model.blk.1.ffn_down.weight.g 	17.3G
	74	 20.48M  @model.blk.1.ffn_down.weight.w 	17.3G
	75	 20.48M  @model.blk.2.ffn_up.weight.g 	17.4G
	76	 20.48M  @model.blk.2.ffn_up.weight.w 	17.4G
	77	 20.48M  @model.blk.3.ffn_down.weight.w 	17.4G
	78	 20.48M  @model.blk.5.ffn_up.weight.g 	17.4G
	79	 20.48M  @model.blk.6.ffn_down.weight.w 	17.5G
	80	 20.48M  @model.blk.5.ffn_down.weight.w 	17.5G
	81	 20.48M  @model.blk.5.ffn_down.weight.g 	17.5G
	82	 20.48M  @model.blk.6.ffn_down.weight.g 	17.5G
	83	 20.48M  @model.blk.1.ffn_up.weight.g 	17.5G
	84	 20.48M  @model.blk.1.ffn_up.weight.w 	17.6G
	85	 20.48M  @model.blk.6.ffn_up.weight.w 	17.6G
	86	 20.48M  @model.blk.7.ffn_down.weight.g 	17.6G
	87	 20.48M  @model.blk.4.ffn_down.weight.g 	17.6G
	88	 20.48M  @model.blk.7.ffn_down.weight.w 	17.6G
	89	 20.48M  @model.blk.4.ffn_down.weight.w 	17.7G
	90	 20.48M  @model.blk.4.ffn_up.weight.g 	17.7G
	91	 20.48M  @model.blk.4.ffn_up.weight.w 	17.7G
	92	 20.48M  @model.blk.7.ffn_up.weight.g 	17.7G
	93	 20.48M  @model.blk.0.ffn_up.weight.w 	17.7G
	94	 20.48M  @model.blk.0.ffn_up.weight.g 	17.8G
	95	 20.48M  @model.blk.3.ffn_down.weight.g 	17.8G
	96	 20.48M  @model.blk.7.ffn_up.weight.w 	17.8G
	97	 20.48M  @model.blk.0.ffn_down.weight.g 	17.8G
	98	 20.48M  @model.blk.3.ffn_up.weight.g 	17.8G
	99	 20.48M  @model.blk.3.ffn_up.weight.w 	17.9G
	100	 20.48M  @model.blk.0.ffn_down.weight.w 	17.9G

======== nEopch=1 most_iter=61035
[Scheduling] MEM_STRATEGY=PRE_ALLOC_GPU UpdateParam=V1
[RLS]	nGuoke=1200(0) Memory of GPU=19274.5M(free=4510.84M)
[Fuyou] n=6 Explorer=[pso_ga] ensembler="BEST" nSwitch=100 "Only cur fuyou's params in GPU-memor!"

	Type weight=BF16(E8) activation=BF16(E8)OPT: iter = 0
[Dataset]_"Train" nShard=50(T=5000M) samping=1(1220) EachShard(nSamp=97656,nBatch=1220)
[Dataset]_"Eval" nShard=1(T=100M) samping=0.06(73) EachShard(nSamp=97656,nBatch=1220)
[OPT_Adam]	sRESI=1 s_rounding=0 alloc_w=0 remater[ffn=1 ]
	ADAM lr=0.0006,beta=[0.9,0.95] decay=0.1(dim>=2) clip=0.0208333(alg=1)
	LR policy=Cosine warmup=600@61035
	nParams = 1557686400(1557.69M, nT=772 nG0=0)
	Search@<J_model.Backward>  device=[] 
	 Accumulation=1 AdaptiveSched=0 GRAP=0x7ffd16850c90 rZMUV=0 rLARS=0 
	DECENT=0(ADAMw) SIGN=0 tpFuseCu=1 filter=5

[DEBUG]: gemm=-1 classifier=1
[MEMORY] mGPU=19274.5M(free=4510.84M)
[epoch_0]_1      loss=11.112322 |g|=7.66	lr=2.00e-06 | 0.1%@S1  T=3.70s(data=129.9ms QKV=2.25s FFN=497.8ms) eta=2d 14:47:39 | 22.1K token/s | 
[MEMORY] mGPU=23483.5M(free=301.859M)
[epoch_0]_11     loss=9.463152 |g|=2.84	lr=1.20e-05 | 0.9%@S1  T=1.68s(data=106.4ms QKV=343.8ms FFN=497.7ms) eta=1d 04:31:26 | 23.4K token/s | 
[epoch_0]_21     loss=8.848690 |g|=1.52	lr=2.20e-05 | 1.7%@S1  T=1.68s(data=92.1ms QKV=344.6ms FFN=500.4ms) eta=1d 04:24:43 | 24.7K token/s | 
[epoch_0]_31     loss=8.467572 |g|=1.08	lr=3.20e-05 | 2.5%@S1  T=1.69s(data=80.2ms QKV=347.1ms FFN=502.4ms) eta=1d 04:34:08 | 25.9K token/s | 
[epoch_0]_41     loss=8.021818 |g|=0.98	lr=4.20e-05 | 3.4%@S1  T=1.68s(data=73.2ms QKV=347.8ms FFN=504.3ms) eta=1d 04:32:07 | 27.0K token/s | 
[epoch_0]_51     loss=7.692875 |g|=0.882	lr=5.20e-05 | 4.2%@S1  T=1.69s(data=71.6ms QKV=349.5ms FFN=504.5ms) eta=1d 04:33:51 | 28.1K token/s | 
[epoch_0]_61     loss=7.345158 |g|=1.19	lr=6.20e-05 | 5.0%@S1  T=1.68s(data=65.4ms QKV=348.8ms FFN=506.3ms) eta=1d 04:25:09 | 29.2K token/s | 
[epoch_0]_71     loss=7.211534 |g|=0.657	lr=7.20e-05 | 5.8%@S1  T=1.67s(data=66.4ms QKV=349.7ms FFN=505.7ms) eta=1d 04:19:11 | 30.2K token/s | 
[epoch_0]_81     loss=7.110985 |g|=0.885	lr=8.20e-05 | 6.6%@S1  T=1.69s(data=68.8ms QKV=349.7ms FFN=507.0ms) eta=1d 04:33:09 | 31.1K token/s | 
[epoch_0]_91     loss=7.070553 |g|=0.717	lr=9.20e-05 | 7.5%@S1  T=1.68s(data=62.7ms QKV=350.5ms FFN=506.0ms) eta=1d 04:22:45 | 32.0K token/s | 
[Section@100] layer[8-16] tasks=19(nPassBack=0) last_loss=6.95582(3.40282e+38) N=(772,784,224 13068)
[epoch_0]_101    loss=8.533077 |g|=5.83	lr=1.02e-04 | 8.3%@S1  T=4.13s(data=60.8ms QKV=694.4ms FFN=1.01s) eta=2d 21:52:11 | 31.4K token/s | 
[epoch_0]_111    loss=7.681738 |g|=1.44	lr=1.12e-04 | 9.1%@S1  T=1.66s(data=60.4ms QKV=696.4ms FFN=1.01s) eta=1d 04:08:38 | 32.3K token/s | 
[epoch_0]_121    loss=7.368701 |g|=1.19	lr=1.22e-04 | 9.9%@S1  T=1.66s(data=60.7ms QKV=699.1ms FFN=1.01s) eta=1d 04:09:44 | 33.1K token/s | 
[epoch_0]_131    loss=7.067105 |g|=0.975	lr=1.32e-04 | 10.7%@S1  T=1.67s(data=54.5ms QKV=700.4ms FFN=1.01s) eta=1d 04:14:03 | 33.9K token/s | 
[epoch_0]_141    loss=6.976118 |g|=0.903	lr=1.42e-04 | 11.6%@S1  T=1.68s(data=76.5ms QKV=700.4ms FFN=1.01s) eta=1d 04:22:27 | 34.6K token/s | 
[epoch_0]_151    loss=6.803134 |g|=0.84	lr=1.52e-04 | 12.4%@S1  T=1.67s(data=48.0ms QKV=699.5ms FFN=1.01s) eta=1d 04:13:30 | 35.4K token/s | 
[epoch_0]_161    loss=6.721336 |g|=0.622	lr=1.62e-04 | 13.2%@S1  T=1.68s(data=58.4ms QKV=700.2ms FFN=1.01s) eta=1d 04:27:20 | 36.0K token/s | 
[epoch_0]_171    loss=6.624764 |g|=0.672	lr=1.72e-04 | 14.0%@S1  T=1.66s(data=50.7ms QKV=699.2ms FFN=1.01s) eta=1d 04:06:10 | 36.7K token/s | 
[epoch_0]_181    loss=6.548127 |g|=0.693	lr=1.82e-04 | 14.8%@S1  T=1.71s(data=50.1ms QKV=700.7ms FFN=1.01s) eta=1d 04:55:53 | 37.3K token/s | 
[epoch_0]_191    loss=6.445358 |g|=0.905	lr=1.92e-04 | 15.6%@S1  T=1.67s(data=49.1ms QKV=699.6ms FFN=1.01s) eta=1d 04:13:06 | 37.8K token/s | 
[eval] 
	 Loss@"edu_fineweb1B"=6.565 nFuyou=1 	#6.56471±0.0786 tps=169K(6.30784M) a=[6.36517,6.84657] T=37.3957(sec)
[Section@200] layer[16-24] tasks=19(nPassBack=0) last_loss=6.39994(3.40282e+38) N=(772,896,336 26268)
[epoch_0]_201    loss=7.942790 |g|=2.67	lr=2.02e-04 | 16.5%@S1  T=11.15s(data=57.4ms QKV=1.05s FFN=1.52s) eta=7d 20:23:41 | 36.3K token/s | 
[epoch_0]_211    loss=7.679664 |g|=1.7	lr=2.12e-04 | 17.3%@S1  T=1.66s(data=46.6ms QKV=1.05s FFN=1.52s) eta=1d 04:01:08 | 37.0K token/s | 
[epoch_0]_221    loss=7.173681 |g|=1.08	lr=2.22e-04 | 18.1%@S1  T=1.67s(data=48.9ms QKV=1.05s FFN=1.52s) eta=1d 04:12:06 | 37.6K token/s | 
[epoch_0]_231    loss=6.805258 |g|=1.53	lr=2.32e-04 | 18.9%@S1  T=1.66s(data=48.0ms QKV=1.05s FFN=1.52s) eta=1d 04:01:48 | 38.2K token/s | 
[epoch_0]_241    loss=6.660112 |g|=0.825	lr=2.42e-04 | 19.7%@S1  T=1.66s(data=43.9ms QKV=1.05s FFN=1.52s) eta=1d 03:59:35 | 38.7K token/s | 
[epoch_0]_251    loss=6.580133 |g|=0.649	lr=2.52e-04 | 20.6%@S1  T=1.67s(data=45.0ms QKV=1.05s FFN=1.52s) eta=1d 04:07:50 | 39.3K token/s | 
[epoch_0]_261    loss=6.475121 |g|=0.64	lr=2.62e-04 | 21.4%@S1  T=1.68s(data=59.7ms QKV=1.05s FFN=1.52s) eta=1d 04:17:53 | 39.7K token/s | 
[epoch_0]_271    loss=6.436913 |g|=0.566	lr=2.72e-04 | 22.2%@S1  T=1.66s(data=35.2ms QKV=1.05s FFN=1.52s) eta=1d 04:00:22 | 40.2K token/s | 
[epoch_0]_281    loss=6.453205 |g|=0.646	lr=2.82e-04 | 23.0%@S1  T=1.66s(data=40.4ms QKV=1.05s FFN=1.52s) eta=1d 04:05:53 | 40.7K token/s | 
[epoch_0]_291    loss=6.366806 |g|=0.681	lr=2.92e-04 | 23.8%@S1  T=1.66s(data=37.6ms QKV=1.05s FFN=1.52s) eta=1d 04:04:54 | 41.1K token/s | 
[Section@300] layer[24-32] tasks=19(nPassBack=0) last_loss=6.41032(3.40282e+38) N=(772,1008,448 39468)
[epoch_0]_301    loss=8.122525 |g|=5.49	lr=3.02e-04 | 24.7%@S1  T=3.27s(data=41.9ms QKV=1.40s FFN=2.02s) eta=2d 07:05:36 | 40.3K token/s | 
[epoch_0]_311    loss=7.540678 |g|=2.92	lr=3.12e-04 | 25.5%@S1  T=1.65s(data=38.1ms QKV=1.40s FFN=2.03s) eta=1d 03:46:23 | 40.8K token/s | 
[epoch_0]_321    loss=6.974400 |g|=1.03	lr=3.22e-04 | 26.3%@S1  T=1.67s(data=42.3ms QKV=1.40s FFN=2.03s) eta=1d 04:05:41 | 41.2K token/s | 
[epoch_0]_331    loss=6.664338 |g|=0.944	lr=3.32e-04 | 27.1%@S1  T=1.66s(data=35.8ms QKV=1.40s FFN=2.03s) eta=1d 03:59:50 | 41.6K token/s | 
[epoch_0]_341    loss=6.586419 |g|=0.885	lr=3.42e-04 | 27.9%@S1  T=1.66s(data=33.7ms QKV=1.40s FFN=2.03s) eta=1d 03:57:06 | 42.0K token/s | 
[epoch_0]_351    loss=6.469959 |g|=0.71	lr=3.52e-04 | 28.8%@S1  T=1.66s(data=33.8ms QKV=1.40s FFN=2.03s) eta=1d 03:57:24 | 42.4K token/s | 
[epoch_0]_361    loss=6.398915 |g|=0.58	lr=3.62e-04 | 29.6%@S1  T=1.64s(data=37.0ms QKV=1.40s FFN=2.03s) eta=1d 03:41:58 | 42.7K token/s | 
[epoch_0]_371    loss=6.468574 |g|=0.582	lr=3.72e-04 | 30.4%@S1  T=1.66s(data=33.0ms QKV=1.40s FFN=2.03s) eta=1d 03:57:13 | 43.1K token/s | 
[epoch_0]_381    loss=6.329616 |g|=0.623	lr=3.82e-04 | 31.2%@S1  T=1.66s(data=38.5ms QKV=1.40s FFN=2.03s) eta=1d 04:01:34 | 43.4K token/s | 
[epoch_0]_391    loss=6.291685 |g|=0.703	lr=3.92e-04 | 32.0%@S1  T=1.66s(data=31.0ms QKV=1.40s FFN=2.03s) eta=1d 03:57:44 | 43.7K token/s | 
[eval] 
	 Loss@"edu_fineweb1B"=6.363(0.2) nBranch=1 nToken=6.31M best=6.5647(0) E2T=0.12 T=36.9413(0)s x=0
	#6.3631±0.0762 tps=171K(6.30784M) a=[6.1818,6.64062] T=36.9413(sec)
[Section@400] layer[32-40] tasks=19(nPassBack=0) last_loss=6.24299(3.40282e+38) N=(772,1120,560 52668)
[epoch_0]_401    loss=8.422550 |g|=7.58	lr=4.02e-04 | 32.9%@S1  T=11.09s(data=30.1ms QKV=1.75s FFN=2.53s) eta=7d 18:45:14 | 41.9K token/s | 
[epoch_0]_411    loss=7.630593 |g|=2.07	lr=4.12e-04 | 33.7%@S1  T=1.64s(data=34.1ms QKV=1.75s FFN=2.54s) eta=1d 03:35:35 | 42.3K token/s | 
[epoch_0]_421    loss=6.973986 |g|=0.896	lr=4.22e-04 | 34.5%@S1  T=1.65s(data=32.5ms QKV=1.75s FFN=2.54s) eta=1d 03:46:09 | 42.6K token/s | 
[epoch_0]_431    loss=6.783954 |g|=0.925	lr=4.32e-04 | 35.3%@S1  T=1.65s(data=27.3ms QKV=1.75s FFN=2.54s) eta=1d 03:50:41 | 43.0K token/s | 
[epoch_0]_441    loss=6.528890 |g|=0.727	lr=4.42e-04 | 36.1%@S1  T=1.66s(data=32.6ms QKV=1.75s FFN=2.54s) eta=1d 03:55:23 | 43.3K token/s | 
[epoch_0]_451    loss=6.489204 |g|=0.563	lr=4.52e-04 | 36.9%@S1  T=1.65s(data=30.1ms QKV=1.75s FFN=2.54s) eta=1d 03:47:43 | 43.6K token/s | 
[epoch_0]_461    loss=6.424628 |g|=0.632	lr=4.62e-04 | 37.8%@S1  T=1.66s(data=34.2ms QKV=1.75s FFN=2.54s) eta=1d 03:57:50 | 43.9K token/s | 
[epoch_0]_471    loss=6.359422 |g|=0.613	lr=4.72e-04 | 38.6%@S1  T=1.65s(data=20.8ms QKV=1.75s FFN=2.54s) eta=1d 03:40:51 | 44.2K token/s | 
[epoch_0]_481    loss=6.273743 |g|=0.619	lr=4.82e-04 | 39.4%@S1  T=1.64s(data=24.8ms QKV=1.75s FFN=2.54s) eta=1d 03:40:09 | 44.5K token/s | 
[epoch_0]_491    loss=6.295346 |g|=0.62	lr=4.92e-04 | 40.2%@S1  T=1.66s(data=18.7ms QKV=1.75s FFN=2.54s) eta=1d 03:57:52 | 44.7K token/s | 
[Section@500] layer[40-48] tasks=19(nPassBack=0) last_loss=6.27741(3.40282e+38) N=(772,1232,672 65868)
[epoch_0]_501    loss=8.970860 |g|=8.96	lr=5.02e-04 | 41.0%@S1  T=3.33s(data=24.2ms QKV=2.10s FFN=3.04s) eta=2d 07:57:22 | 43.7K token/s | 
[epoch_0]_511    loss=7.555828 |g|=2.71	lr=5.12e-04 | 41.9%@S1  T=1.64s(data=21.7ms QKV=2.10s FFN=3.04s) eta=1d 03:36:27 | 44.0K token/s | 
[epoch_0]_521    loss=6.959941 |g|=1.12	lr=5.22e-04 | 42.7%@S1  T=1.64s(data=19.2ms QKV=2.10s FFN=3.05s) eta=1d 03:37:29 | 44.3K token/s | 
[epoch_0]_531    loss=6.780500 |g|=0.89	lr=5.32e-04 | 43.5%@S1  T=1.66s(data=27.6ms QKV=2.10s FFN=3.05s) eta=1d 03:50:29 | 44.6K token/s | 
[epoch_0]_541    loss=6.633668 |g|=0.502	lr=5.42e-04 | 44.3%@S1  T=1.65s(data=18.1ms QKV=2.11s FFN=3.05s) eta=1d 03:44:52 | 44.8K token/s | 
[epoch_0]_551    loss=6.501040 |g|=0.525	lr=5.52e-04 | 45.1%@S1  T=1.65s(data=20.6ms QKV=2.10s FFN=3.05s) eta=1d 03:44:08 | 45.1K token/s | 
[epoch_0]_561    loss=6.443844 |g|=0.524	lr=5.62e-04 | 46.0%@S1  T=1.65s(data=20.4ms QKV=2.11s FFN=3.05s) eta=1d 03:43:14 | 45.3K token/s | 
[epoch_0]_571    loss=6.326791 |g|=0.742	lr=5.72e-04 | 46.8%@S1  T=1.64s(data=18.2ms QKV=2.11s FFN=3.05s) eta=1d 03:33:23 | 45.5K token/s | 
[epoch_0]_581    loss=6.262603 |g|=0.556	lr=5.82e-04 | 47.6%@S1  T=1.63s(data=20.4ms QKV=2.11s FFN=3.05s) eta=1d 03:24:13 | 45.8K token/s | 
[epoch_0]_591    loss=6.341547 |g|=0.602	lr=5.92e-04 | 48.4%@S1  T=1.63s(data=17.3ms QKV=2.11s FFN=3.05s) eta=1d 03:21:50 | 46.0K token/s | 
[Fuyou] head="5" update algorithm=4 t=11.88s
[eval] 
	 Loss@"edu_fineweb1B"=6.330(0.033) nBranch=1 nToken=6.31M best=6.3631(1) E2T=0.086 T=36.8175(0)s x=0
	#6.32979±0.0739 tps=171K(6.30784M) a=[6.15433,6.59895] T=36.8175(sec)
[Section@600] layer[0-8] tasks=19(nPassBack=0) last_loss=6.2438(3.40282e+38) N=(772,1344,784 79068)
[epoch_0]_601    loss=6.312537 |g|=0.985	lr=6.00e-04 | 49.2%@S1  T=11.33s(data=23.5ms QKV=2.10s FFN=3.05s) eta=7d 22:11:38 | 44.0K token/s | 
[epoch_0]_611    loss=6.276064 |g|=0.601	lr=6.00e-04 | 50.1%@S1  T=1.65s(data=21.8ms QKV=2.11s FFN=3.05s) eta=1d 03:44:04 | 44.3K token/s | 
[epoch_0]_621    loss=6.183500 |g|=0.856	lr=6.00e-04 | 50.9%@S1  T=1.65s(data=17.4ms QKV=2.11s FFN=3.05s) eta=1d 03:45:12 | 44.6K token/s | 
[epoch_0]_631    loss=6.179949 |g|=0.555	lr=6.00e-04 | 51.7%@S1  T=1.65s(data=22.5ms QKV=2.11s FFN=3.05s) eta=1d 03:39:21 | 44.8K token/s | 
[epoch_0]_641    loss=6.105753 |g|=0.551	lr=6.00e-04 | 52.5%@S1  T=1.65s(data=17.4ms QKV=2.11s FFN=3.05s) eta=1d 03:41:03 | 45.1K token/s | 
[epoch_0]_651    loss=6.179673 |g|=0.43	lr=6.00e-04 | 53.3%@S1  T=1.64s(data=12.0ms QKV=2.11s FFN=3.05s) eta=1d 03:28:33 | 45.3K token/s | 
[epoch_0]_661    loss=6.110866 |g|=0.509	lr=6.00e-04 | 54.2%@S1  T=1.65s(data=18.9ms QKV=2.11s FFN=3.05s) eta=1d 03:39:44 | 45.5K token/s | 
[epoch_0]_671    loss=6.063779 |g|=0.488	lr=6.00e-04 | 55.0%@S1  T=1.64s(data=12.2ms QKV=2.11s FFN=3.05s) eta=1d 03:31:25 | 45.8K token/s | 
[epoch_0]_681    loss=6.041283 |g|=0.471	lr=6.00e-04 | 55.8%@S1  T=1.63s(data=11.6ms QKV=2.11s FFN=3.05s) eta=1d 03:16:38 | 46.0K token/s | 
[epoch_0]_691    loss=5.983490 |g|=0.559	lr=6.00e-04 | 56.6%@S1  T=1.65s(data=19.7ms QKV=2.11s FFN=3.05s) eta=1d 03:37:05 | 46.2K token/s | 
[Fuyou] head="0" update algorithm=4 t=6.25s
[Section@700] layer[8-16] tasks=19(nPassBack=0) last_loss=6.00617(0.949648) N=(772,1456,896 92268)
[epoch_0]_701    loss=6.048582 |g|=0.773	lr=6.00e-04 | 57.4%@S1  T=3.25s(data=16.7ms QKV=2.10s FFN=3.04s) eta=2d 06:31:16 | 45.1K token/s | 
[epoch_0]_711    loss=5.957614 |g|=0.503	lr=6.00e-04 | 58.2%@S1  T=1.64s(data=13.8ms QKV=2.11s FFN=3.05s) eta=1d 03:30:07 | 45.4K token/s | 
[epoch_0]_721    loss=5.992867 |g|=0.498	lr=6.00e-04 | 59.1%@S1  T=1.64s(data=10.3ms QKV=2.11s FFN=3.05s) eta=1d 03:30:47 | 45.6K token/s | 
[epoch_0]_731    loss=5.934167 |g|=0.527	lr=6.00e-04 | 59.9%@S1  T=1.64s(data=10.1ms QKV=2.11s FFN=3.05s) eta=1d 03:30:36 | 45.8K token/s | 
[epoch_0]_741    loss=5.946959 |g|=0.516	lr=6.00e-04 | 60.7%@S1  T=1.65s(data=13.8ms QKV=2.11s FFN=3.05s) eta=1d 03:35:22 | 46.0K token/s | 
[epoch_0]_751    loss=5.889185 |g|=0.582	lr=6.00e-04 | 61.5%@S1  T=1.63s(data=13.6ms QKV=2.11s FFN=3.05s) eta=1d 03:18:48 | 46.2K token/s | 
[epoch_0]_761    loss=5.766405 |g|=0.549	lr=6.00e-04 | 62.3%@S1  T=1.64s(data=10.5ms QKV=2.11s FFN=3.05s) eta=1d 03:31:34 | 46.4K token/s | 
[epoch_0]_771    loss=5.839832 |g|=0.413	lr=6.00e-04 | 63.2%@S1  T=1.64s(data=8.3ms QKV=2.11s FFN=3.05s) eta=1d 03:24:52 | 46.6K token/s | 
[epoch_0]_781    loss=5.751223 |g|=0.518	lr=6.00e-04 | 64.0%@S1  T=1.65s(data=13.0ms QKV=2.11s FFN=3.05s) eta=1d 03:36:40 | 46.7K token/s | 
[epoch_0]_791    loss=5.770848 |g|=0.673	lr=6.00e-04 | 64.8%@S1  T=1.65s(data=6.6ms QKV=2.11s FFN=3.05s) eta=1d 03:33:08 | 46.9K token/s | 
[Fuyou] head="1" update algorithm=4 t=6.81s
[eval] 
	 Loss@"edu_fineweb1B"=5.853(0.48) nBranch=1 nToken=6.31M best=6.3298(2) E2T=0.0623 T=36.8618(0)s x=0
	#5.85272±0.0771 tps=171K(6.30784M) a=[5.69343,6.1277] T=36.8618(sec)
[Section@800] layer[16-24] tasks=19(nPassBack=0) last_loss=5.7904(0.609541) N=(772,1568,1008 105468)
[epoch_0]_801    loss=5.829075 |g|=0.863	lr=6.00e-04 | 65.6%@S1  T=11.39s(data=14.3ms QKV=2.10s FFN=3.04s) eta=7d 22:37:39 | 44.9K token/s | 
[epoch_0]_811    loss=5.629894 |g|=0.53	lr=6.00e-04 | 66.4%@S1  T=1.63s(data=12.2ms QKV=2.11s FFN=3.05s) eta=1d 03:19:28 | 45.2K token/s | 
[epoch_0]_821    loss=5.701972 |g|=0.5	lr=6.00e-04 | 67.3%@S1  T=1.63s(data=9.9ms QKV=2.11s FFN=3.05s) eta=1d 03:14:53 | 45.4K token/s | 
[epoch_0]_831    loss=5.707850 |g|=0.505	lr=6.00e-04 | 68.1%@S1  T=1.65s(data=9.8ms QKV=2.11s FFN=3.05s) eta=1d 03:31:26 | 45.6K token/s | 
[epoch_0]_841    loss=5.694301 |g|=0.408	lr=6.00e-04 | 68.9%@S1  T=1.65s(data=8.7ms QKV=2.11s FFN=3.05s) eta=1d 03:36:41 | 45.8K token/s | 
[epoch_0]_851    loss=5.691642 |g|=0.503	lr=6.00e-04 | 69.7%@S1  T=1.65s(data=9.3ms QKV=2.11s FFN=3.05s) eta=1d 03:31:12 | 46.0K token/s | 
[epoch_0]_861    loss=5.579107 |g|=0.399	lr=6.00e-04 | 70.5%@S1  T=1.64s(data=9.6ms QKV=2.11s FFN=3.05s) eta=1d 03:26:19 | 46.2K token/s | 
[epoch_0]_871    loss=5.621054 |g|=0.42	lr=6.00e-04 | 71.4%@S1  T=1.64s(data=7.9ms QKV=2.11s FFN=3.05s) eta=1d 03:24:04 | 46.4K token/s | 
[epoch_0]_881    loss=5.499460 |g|=0.313	lr=6.00e-04 | 72.2%@S1  T=1.64s(data=9.3ms QKV=2.11s FFN=3.05s) eta=1d 03:20:12 | 46.6K token/s | 
[epoch_0]_891    loss=5.600381 |g|=0.467	lr=6.00e-04 | 73.0%@S1  T=1.63s(data=6.4ms QKV=2.11s FFN=3.05s) eta=1d 03:14:41 | 46.8K token/s | 
[Fuyou] head="2" update algorithm=4 t=9.98s
[Section@900] layer[24-32] tasks=19(nPassBack=0) last_loss=5.50729(0.903035) N=(772,1680,1120 118668)
[epoch_0]_901    loss=5.631349 |g|=1.1	lr=6.00e-04 | 73.8%@S1  T=4.10s(data=8.1ms QKV=2.10s FFN=3.04s) eta=2d 20:30:51 | 45.4K token/s | 
[epoch_0]_911    loss=5.574109 |g|=0.518	lr=6.00e-04 | 74.6%@S1  T=1.63s(data=6.1ms QKV=2.11s FFN=3.05s) eta=1d 03:16:29 | 45.7K token/s | 
[epoch_0]_921    loss=5.537011 |g|=0.418	lr=6.00e-04 | 75.4%@S1  T=1.64s(data=7.8ms QKV=2.11s FFN=3.05s) eta=1d 03:18:23 | 45.9K token/s | 
[epoch_0]_931    loss=5.489906 |g|=0.452	lr=6.00e-04 | 76.3%@S1  T=1.61s(data=7.0ms QKV=2.11s FFN=3.05s) eta=1d 02:56:22 | 46.1K token/s | 
[epoch_0]_941    loss=5.387161 |g|=0.385	lr=6.00e-04 | 77.1%@S1  T=1.63s(data=8.6ms QKV=2.11s FFN=3.05s) eta=1d 03:16:34 | 46.3K token/s | 
[epoch_0]_951    loss=5.395046 |g|=0.483	lr=6.00e-04 | 77.9%@S1  T=1.64s(data=7.0ms QKV=2.11s FFN=3.05s) eta=1d 03:23:51 | 46.5K token/s | 
[epoch_0]_961    loss=5.331252 |g|=0.383	lr=6.00e-04 | 78.7%@S1  T=1.64s(data=7.2ms QKV=2.11s FFN=3.05s) eta=1d 03:20:55 | 46.7K token/s | 
[epoch_0]_971    loss=5.358863 |g|=0.419	lr=6.00e-04 | 79.5%@S1  T=1.64s(data=5.2ms QKV=2.11s FFN=3.05s) eta=1d 03:21:20 | 46.9K token/s | 
[epoch_0]_981    loss=5.311298 |g|=0.486	lr=6.00e-04 | 80.4%@S1  T=1.64s(data=3.4ms QKV=2.11s FFN=3.05s) eta=1d 03:18:05 | 47.0K token/s | 
[epoch_0]_991    loss=5.338401 |g|=0.445	lr=6.00e-04 | 81.2%@S1  T=1.64s(data=3.3ms QKV=2.11s FFN=3.05s) eta=1d 03:16:57 | 47.2K token/s | 
[Fuyou] head="3" update algorithm=4 t=11.65s
[eval] 
	 Loss@"edu_fineweb1B"=5.382(0.47) nBranch=1 nToken=6.31M best=5.8527(3) E2T=0.0471 T=36.7699(0)s x=0
	#5.38164±0.0822 tps=172K(6.30784M) a=[5.21533,5.65693] T=36.7699(sec)
[Section@1000] layer[32-40] tasks=19(nPassBack=0) last_loss=5.33454(0.908451) N=(772,1792,1232 131868)
[epoch_0]_1001   loss=5.375108 |g|=0.922	lr=6.00e-04 | 82.0%@S1  T=11.69s(data=5.1ms QKV=2.10s FFN=3.04s) eta=8d 02:56:38 | 45.2K token/s | 
[epoch_0]_1011   loss=5.370144 |g|=0.455	lr=6.00e-04 | 82.8%@S1  T=1.62s(data=9.0ms QKV=2.10s FFN=3.05s) eta=1d 03:02:26 | 45.4K token/s | 
[epoch_0]_1021   loss=5.273556 |g|=0.413	lr=6.00e-04 | 83.6%@S1  T=1.63s(data=2.0ms QKV=2.11s FFN=3.05s) eta=1d 03:10:59 | 45.7K token/s | 
[epoch_0]_1031   loss=5.184191 |g|=0.478	lr=6.00e-04 | 84.5%@S1  T=1.63s(data=1.9ms QKV=2.11s FFN=3.05s) eta=1d 03:14:54 | 45.9K token/s | 
[epoch_0]_1041   loss=5.275318 |g|=0.531	lr=6.00e-04 | 85.3%@S1  T=1.62s(data=3.4ms QKV=2.11s FFN=3.05s) eta=1d 02:58:59 | 46.1K token/s | 
[epoch_0]_1051   loss=5.224946 |g|=0.389	lr=6.00e-04 | 86.1%@S1  T=1.64s(data=7.2ms QKV=2.11s FFN=3.05s) eta=1d 03:20:07 | 46.3K token/s | 
[epoch_0]_1061   loss=5.165915 |g|=0.441	lr=6.00e-04 | 86.9%@S1  T=1.63s(data=4.2ms QKV=2.11s FFN=3.05s) eta=1d 03:14:05 | 46.5K token/s | 
[epoch_0]_1071   loss=5.068510 |g|=0.411	lr=6.00e-04 | 87.7%@S1  T=1.64s(data=4.7ms QKV=2.11s FFN=3.05s) eta=1d 03:21:40 | 46.7K token/s | 
[epoch_0]_1081   loss=5.104752 |g|=0.453	lr=6.00e-04 | 88.6%@S1  T=1.64s(data=5.4ms QKV=2.11s FFN=3.05s) eta=1d 03:19:14 | 46.8K token/s | 
[epoch_0]_1091   loss=5.182216 |g|=0.42	lr=6.00e-04 | 89.4%@S1  T=1.64s(data=4.0ms QKV=2.11s FFN=3.05s) eta=1d 03:16:02 | 47.0K token/s | 
[Fuyou] head="4" update algorithm=4 t=9.75s
[Section@1100] layer[40-48] tasks=19(nPassBack=0) last_loss=5.12261(1.1548) N=(772,1904,1344 145068)
[epoch_0]_1101   loss=5.196479 |g|=1.11	lr=6.00e-04 | 90.2%@S1  T=4.22s(data=4.8ms QKV=2.10s FFN=3.04s) eta=2d 22:19:37 | 45.6K token/s | 
[epoch_0]_1111   loss=5.136421 |g|=0.559	lr=6.00e-04 | 91.0%@S1  T=1.61s(data=2.9ms QKV=2.10s FFN=3.04s) eta=1d 02:46:37 | 45.9K token/s | 
[epoch_0]_1121   loss=5.123140 |g|=0.43	lr=6.00e-04 | 91.8%@S1  T=1.61s(data=4.1ms QKV=2.10s FFN=3.05s) eta=1d 02:48:46 | 46.1K token/s | 
[epoch_0]_1131   loss=4.994109 |g|=0.453	lr=6.00e-04 | 92.7%@S1  T=1.62s(data=3.4ms QKV=2.10s FFN=3.05s) eta=1d 02:57:08 | 46.4K token/s | 
[epoch_0]_1141   loss=4.983507 |g|=0.412	lr=6.00e-04 | 93.5%@S1  T=1.62s(data=3.7ms QKV=2.10s FFN=3.05s) eta=1d 02:56:39 | 46.6K token/s | 
[epoch_0]_1151   loss=4.964651 |g|=0.48	lr=6.00e-04 | 94.3%@S1  T=1.63s(data=3.1ms QKV=2.11s FFN=3.05s) eta=1d 03:11:32 | 46.7K token/s | 
[epoch_0]_1161   loss=5.018055 |g|=0.445	lr=6.00e-04 | 95.1%@S1  T=1.64s(data=1.9ms QKV=2.11s FFN=3.05s) eta=1d 03:12:34 | 46.9K token/s | 
[epoch_0]_1171   loss=4.990792 |g|=0.402	lr=6.00e-04 | 95.9%@S1  T=1.64s(data=1.6ms QKV=2.11s FFN=3.05s) eta=1d 03:19:41 | 47.1K token/s | 
[epoch_0]_1181   loss=4.929354 |g|=0.386	lr=6.00e-04 | 96.7%@S1  T=1.63s(data=1.8ms QKV=2.10s FFN=3.05s) eta=1d 03:10:49 | 47.2K token/s | 
[epoch_0]_1191   loss=4.968217 |g|=0.418	lr=6.00e-04 | 97.6%@S1  T=1.62s(data=1.8ms QKV=2.10s FFN=3.05s) eta=1d 03:00:38 | 47.4K token/s | 
[Fuyou] head="5" update algorithm=4 t=11.97s
[eval] 
	 Loss@"edu_fineweb1B"=4.996(0.39) nBranch=1 nToken=6.31M best=5.3816(4) E2T=0.102 T=36.7667(0)s x=0
	#4.99623±0.0867 tps=172K(6.30784M) a=[4.80464,5.24723] T=36.7667(sec)
[Section@1200] layer[0-8] tasks=19(nPassBack=0) last_loss=4.8946(1.3492) N=(772,2016,1456 158268)
[epoch_0]_1201   loss=4.908682 |g|=0.892	lr=6.00e-04 | 98.4%@S1  T=11.81s(data=2.0ms QKV=2.10s FFN=3.04s) eta=8d 04:15:37 | 45.3K token/s | 
[epoch_0]_1211   loss=4.884182 |g|=0.442	lr=6.00e-04 | 99.2%@S1  T=1.61s(data=1.8ms QKV=2.10s FFN=3.05s) eta=1d 02:47:45 | 45.6K token/s | 
[epoch_0]_1220   loss=4.902062 |g|=0.438	lr=6.00e-04 | 99.9%@S1  T=1.67s(data=6.9ms QKV=2.11s FFN=3.05s) eta=1d 03:42:00 | 45.8K token/s | 
-------- End of shard_1@"./Datasets/edu_fineweb1B/edu_fineweb_train_000001.bin"-------- 
[shard-2]@"./Datasets/edu_fineweb1B/edu_fineweb_train_000002.bin": tokens=100(M) nShardSamples=1220(195312) 
[epoch_0]_1221   loss=4.903670 |g|=0.468	lr=6.00e-04 | 0.0%@S2  T=2.28s(data=923.1ms QKV=2.10s FFN=3.05s) eta=1d 13:48:27 | 45.3K token/s | 
[epoch_0]_1231   loss=4.904571 |g|=0.431	lr=6.00e-04 | 0.8%@S2  T=1.62s(data=1.2ms QKV=2.10s FFN=3.05s) eta=1d 02:51:59 | 45.6K token/s | 
[epoch_0]_1241   loss=4.843007 |g|=0.459	lr=6.00e-04 | 1.7%@S2  T=1.61s(data=1.3ms QKV=2.10s FFN=3.05s) eta=1d 02:47:13 | 45.8K token/s | 
[epoch_0]_1251   loss=4.851263 |g|=0.471	lr=6.00e-04 | 2.5%@S2  T=1.63s(data=1.4ms QKV=2.10s FFN=3.05s) eta=1d 03:05:56 | 46.1K token/s | 
[epoch_0]_1261   loss=4.748238 |g|=0.423	lr=6.00e-04 | 3.3%@S2  T=1.64s(data=1.4ms QKV=2.10s FFN=3.05s) eta=1d 03:11:31 | 46.2K token/s | 
[epoch_0]_1271   loss=4.806590 |g|=0.471	lr=6.00e-04 | 4.1%@S2  T=1.63s(data=1.6ms QKV=2.10s FFN=3.05s) eta=1d 02:58:42 | 46.5K token/s | 
[epoch_0]_1281   loss=4.763233 |g|=0.495	lr=6.00e-04 | 4.9%@S2  T=1.63s(data=1.5ms QKV=2.10s FFN=3.05s) eta=1d 03:07:27 | 46.6K token/s | 
[epoch_0]_1291   loss=4.724946 |g|=0.438	lr=6.00e-04 | 5.8%@S2  T=1.64s(data=1.5ms QKV=2.10s FFN=3.05s) eta=1d 03:08:45 | 46.8K token/s | 
[Fuyou] head="0" update algorithm=4 t=13.18s
[Section@1300] layer[8-16] tasks=19(nPassBack=0) last_loss=4.81084(1.19533) N=(772,2128,1568 171468)
[epoch_0]_1301   loss=4.814735 |g|=1.02	lr=6.00e-04 | 6.6%@S2  T=4.18s(data=2.1ms QKV=2.10s FFN=3.04s) eta=2d 21:22:30 | 45.5K token/s | 
[epoch_0]_1311   loss=4.751434 |g|=0.526	lr=6.00e-04 | 7.4%@S2  T=1.62s(data=1.6ms QKV=2.10s FFN=3.04s) eta=1d 02:57:01 | 45.7K token/s | 
[epoch_0]_1321   loss=4.775616 |g|=0.459	lr=6.00e-04 | 8.2%@S2  T=1.63s(data=1.7ms QKV=2.10s FFN=3.05s) eta=1d 03:04:45 | 45.9K token/s | 
[epoch_0]_1331   loss=4.602465 |g|=0.482	lr=6.00e-04 | 9.0%@S2  T=1.63s(data=1.3ms QKV=2.10s FFN=3.05s) eta=1d 03:01:11 | 46.1K token/s | 
[epoch_0]_1341   loss=4.637798 |g|=0.431	lr=6.00e-04 | 9.9%@S2  T=1.63s(data=1.3ms QKV=2.10s FFN=3.05s) eta=1d 03:05:10 | 46.3K token/s | 
[epoch_0]_1351   loss=4.627783 |g|=0.464	lr=6.00e-04 | 10.7%@S2  T=1.63s(data=1.3ms QKV=2.10s FFN=3.05s) eta=1d 03:03:01 | 46.5K token/s | 
[epoch_0]_1361   loss=4.598499 |g|=0.447	lr=6.00e-04 | 11.5%@S2  T=1.64s(data=1.5ms QKV=2.11s FFN=3.05s) eta=1d 03:07:31 | 46.7K token/s | 
[epoch_0]_1371   loss=4.578703 |g|=0.457	lr=6.00e-04 | 12.3%@S2  T=1.62s(data=1.6ms QKV=2.10s FFN=3.05s) eta=1d 02:55:48 | 46.9K token/s | 
[epoch_0]_1381   loss=4.672801 |g|=0.489	lr=6.00e-04 | 13.1%@S2  T=1.63s(data=1.6ms QKV=2.10s FFN=3.05s) eta=1d 03:03:14 | 47.1K token/s | 
[epoch_0]_1391   loss=4.576045 |g|=0.556	lr=6.00e-04 | 14.0%@S2  T=1.64s(data=1.5ms QKV=2.11s FFN=3.05s) eta=1d 03:05:21 | 47.2K token/s | 
[Fuyou] head="1" update algorithm=4 t=9.97s
[eval] 
	 Loss@"edu_fineweb1B"=4.659(0.34) nBranch=1 nToken=6.31M best=4.9962(5) E2T=0.0815 T=36.8184(0)s x=0
	#4.65907±0.0900 tps=171K(6.30784M) a=[4.44127,4.89908] T=36.8184(sec)
[Section@1400] layer[16-24] tasks=19(nPassBack=0) last_loss=4.57756(1.21284) N=(772,2240,1680 184668)
[epoch_0]_1401   loss=4.624876 |g|=0.886	lr=6.00e-04 | 14.8%@S2  T=11.96s(data=1.7ms QKV=2.10s FFN=3.04s) eta=8d 06:09:07 | 45.2K token/s | 
[epoch_0]_1411   loss=4.490902 |g|=0.424	lr=6.00e-04 | 15.6%@S2  T=1.61s(data=1.6ms QKV=2.11s FFN=3.04s) eta=1d 02:40:16 | 45.5K token/s | 
[epoch_0]_1421   loss=4.548288 |g|=0.464	lr=6.00e-04 | 16.4%@S2  T=1.62s(data=1.8ms QKV=2.11s FFN=3.05s) eta=1d 02:50:39 | 45.7K token/s | 
[epoch_0]_1431   loss=4.597945 |g|=0.497	lr=6.00e-04 | 17.2%@S2  T=1.62s(data=1.6ms QKV=2.11s FFN=3.05s) eta=1d 02:46:44 | 46.0K token/s | 
[epoch_0]_1441   loss=4.587262 |g|=0.458	lr=6.00e-04 | 18.0%@S2  T=1.62s(data=1.9ms QKV=2.11s FFN=3.05s) eta=1d 02:44:31 | 46.2K token/s | 
[epoch_0]_1451   loss=4.543394 |g|=0.478	lr=6.00e-04 | 18.9%@S2  T=1.64s(data=1.4ms QKV=2.11s FFN=3.05s) eta=1d 03:06:50 | 46.4K token/s | 
[epoch_0]_1461   loss=4.578316 |g|=0.484	lr=6.00e-04 | 19.7%@S2  T=1.64s(data=1.7ms QKV=2.11s FFN=3.05s) eta=1d 03:13:09 | 46.6K token/s | 
[epoch_0]_1471   loss=4.513846 |g|=0.57	lr=6.00e-04 | 20.5%@S2  T=1.63s(data=1.6ms QKV=2.11s FFN=3.05s) eta=1d 03:01:35 | 46.8K token/s | 
[epoch_0]_1481   loss=4.558395 |g|=0.449	lr=6.00e-04 | 21.3%@S2  T=1.63s(data=1.8ms QKV=2.10s FFN=3.05s) eta=1d 03:01:46 | 46.9K token/s | 
[epoch_0]_1491   loss=4.509412 |g|=0.482	lr=6.00e-04 | 22.1%@S2  T=1.63s(data=1.5ms QKV=2.11s FFN=3.05s) eta=1d 02:56:58 | 47.1K token/s | 
[Fuyou] head="2" update algorithm=4 t=10.73s
[Section@1500] layer[24-32] tasks=19(nPassBack=0) last_loss=4.49978(1.00751) N=(772,2352,1792 197868)
[epoch_0]_1501   loss=4.516268 |g|=0.854	lr=6.00e-04 | 23.0%@S2  T=3.86s(data=2.0ms QKV=2.10s FFN=3.04s) eta=2d 15:47:36 | 45.8K token/s | 
[epoch_0]_1511   loss=4.437310 |g|=0.516	lr=6.00e-04 | 23.8%@S2  T=1.61s(data=1.8ms QKV=2.10s FFN=3.04s) eta=1d 02:41:32 | 46.0K token/s | 
[epoch_0]_1521   loss=4.475554 |g|=0.477	lr=6.00e-04 | 24.6%@S2  T=1.64s(data=1.8ms QKV=2.10s FFN=3.05s) eta=1d 03:06:14 | 46.2K token/s | 
[epoch_0]_1531   loss=4.462776 |g|=0.48	lr=6.00e-04 | 25.4%@S2  T=1.64s(data=1.7ms QKV=2.11s FFN=3.05s) eta=1d 03:04:46 | 46.4K token/s | 
[epoch_0]_1541   loss=4.445056 |g|=0.539	lr=6.00e-04 | 26.2%@S2  T=1.64s(data=1.8ms QKV=2.11s FFN=3.05s) eta=1d 03:02:27 | 46.6K token/s | 
[epoch_0]_1551   loss=4.320673 |g|=0.522	lr=6.00e-04 | 27.1%@S2  T=1.63s(data=1.6ms QKV=2.11s FFN=3.05s) eta=1d 02:59:21 | 46.8K token/s | 
[epoch_0]_1561   loss=4.389151 |g|=0.527	lr=6.00e-04 | 27.9%@S2  T=1.64s(data=1.7ms QKV=2.11s FFN=3.05s) eta=1d 03:06:46 | 46.9K token/s | 
[epoch_0]_1571   loss=4.429028 |g|=0.504	lr=6.00e-04 | 28.7%@S2  T=1.64s(data=1.5ms QKV=2.11s FFN=3.05s) eta=1d 03:04:21 | 47.1K token/s | 
[epoch_0]_1581   loss=4.388629 |g|=0.523	lr=6.00e-04 | 29.5%@S2  T=1.64s(data=1.4ms QKV=2.11s FFN=3.05s) eta=1d 03:03:40 | 47.2K token/s | 
[epoch_0]_1591   loss=4.246818 |g|=0.485	lr=6.00e-04 | 30.3%@S2  T=1.63s(data=1.4ms QKV=2.11s FFN=3.05s) eta=1d 02:59:15 | 47.4K token/s | 
[Fuyou] head="3" update algorithm=4 t=11.14s
[eval] 
	 Loss@"edu_fineweb1B"=4.481(0.18) nBranch=1 nToken=6.31M best=4.6591(6) E2T=0.146 T=36.7843(0)s x=0
	#4.48071±0.0938 tps=171K(6.30784M) a=[4.25959,4.72104] T=36.7843(sec)
[Section@1600] layer[32-40] tasks=19(nPassBack=0) last_loss=4.33506(0.999476) N=(772,2464,1904 211068)
[epoch_0]_1601   loss=4.400970 |g|=0.639	lr=6.00e-04 | 31.2%@S2  T=11.99s(data=1.9ms QKV=2.10s FFN=3.04s) eta=8d 05:55:09 | 45.4K token/s | 
[epoch_0]_1611   loss=4.409819 |g|=0.44	lr=6.00e-04 | 32.0%@S2  T=1.62s(data=1.5ms QKV=2.10s FFN=3.05s) eta=1d 02:47:56 | 45.6K token/s | 
[epoch_0]_1621   loss=4.397207 |g|=0.46	lr=6.00e-04 | 32.8%@S2  T=1.62s(data=1.7ms QKV=2.10s FFN=3.05s) eta=1d 02:44:05 | 45.9K token/s | 
[epoch_0]_1631   loss=4.386986 |g|=0.42	lr=6.00e-04 | 33.6%@S2  T=1.64s(data=1.8ms QKV=2.11s FFN=3.05s) eta=1d 03:07:24 | 46.1K token/s | 
[epoch_0]_1641   loss=4.401223 |g|=0.485	lr=6.00e-04 | 34.4%@S2  T=1.62s(data=1.6ms QKV=2.11s FFN=3.05s) eta=1d 02:45:42 | 46.3K token/s | 
[epoch_0]_1651   loss=4.373752 |g|=0.416	lr=6.00e-04 | 35.3%@S2  T=1.63s(data=1.6ms QKV=2.11s FFN=3.05s) eta=1d 02:57:45 | 46.5K token/s | 
[epoch_0]_1661   loss=4.347954 |g|=0.443	lr=6.00e-04 | 36.1%@S2  T=1.64s(data=1.6ms QKV=2.11s FFN=3.05s) eta=1d 03:03:13 | 46.6K token/s | 
[epoch_0]_1671   loss=4.361306 |g|=0.427	lr=6.00e-04 | 36.9%@S2  T=1.64s(data=1.8ms QKV=2.11s FFN=3.05s) eta=1d 03:02:32 | 46.8K token/s | 
[epoch_0]_1681   loss=4.305261 |g|=0.492	lr=6.00e-04 | 37.7%@S2  T=1.63s(data=1.6ms QKV=2.11s FFN=3.05s) eta=1d 02:55:01 | 47.0K token/s | 
[epoch_0]_1691   loss=4.358325 |g|=0.479	lr=6.00e-04 | 38.5%@S2  T=1.64s(data=1.6ms QKV=2.11s FFN=3.05s) eta=1d 02:59:24 | 47.1K token/s | 
[Fuyou] head="4" update algorithm=4 t=12.28s
[Section@1700] layer[40-48] tasks=19(nPassBack=0) last_loss=4.28217(0.840435) N=(772,2576,2016 224268)
[epoch_0]_1701   loss=4.266897 |g|=0.646	lr=6.00e-04 | 39.3%@S2  T=4.09s(data=1.5ms QKV=2.10s FFN=3.04s) eta=2d 19:21:38 | 45.8K token/s | 
[epoch_0]_1711   loss=4.329001 |g|=0.54	lr=6.00e-04 | 40.2%@S2  T=1.63s(data=1.6ms QKV=2.10s FFN=3.04s) eta=1d 02:49:57 | 46.0K token/s | 
[epoch_0]_1721   loss=4.269145 |g|=0.582	lr=5.99e-04 | 41.0%@S2  T=1.63s(data=1.6ms QKV=2.10s FFN=3.05s) eta=1d 02:48:31 | 46.2K token/s | 
[epoch_0]_1731   loss=4.286350 |g|=0.47	lr=5.99e-04 | 41.8%@S2  T=1.63s(data=1.6ms QKV=2.11s FFN=3.05s) eta=1d 02:53:21 | 46.4K token/s | 
[epoch_0]_1741   loss=4.285612 |g|=0.457	lr=5.99e-04 | 42.6%@S2  T=1.64s(data=1.7ms QKV=2.11s FFN=3.05s) eta=1d 03:01:02 | 46.6K token/s | 
[epoch_0]_1751   loss=4.317050 |g|=0.399	lr=5.99e-04 | 43.4%@S2  T=1.63s(data=1.5ms QKV=2.11s FFN=3.05s) eta=1d 02:54:35 | 46.8K token/s | 
[epoch_0]_1761   loss=4.267872 |g|=0.548	lr=5.99e-04 | 44.3%@S2  T=1.64s(data=1.9ms QKV=2.11s FFN=3.05s) eta=1d 02:58:42 | 46.9K token/s | 
[epoch_0]_1771   loss=4.288937 |g|=0.52	lr=5.99e-04 | 45.1%@S2  T=1.63s(data=1.6ms QKV=2.11s FFN=3.05s) eta=1d 02:53:36 | 47.1K token/s | 
[epoch_0]_1781   loss=4.278522 |g|=0.577	lr=5.99e-04 | 45.9%@S2  T=1.64s(data=1.7ms QKV=2.11s FFN=3.05s) eta=1d 02:58:41 | 47.2K token/s | 
[epoch_0]_1791   loss=4.253981 |g|=0.441	lr=5.99e-04 | 46.7%@S2  T=1.64s(data=1.5ms QKV=2.11s FFN=3.05s) eta=1d 02:55:26 | 47.4K token/s | 
[Fuyou] head="5" update algorithm=4 t=11.13s
[eval] 
	 Loss@"edu_fineweb1B"=4.353(0.13) nBranch=1 nToken=6.31M best=4.4807(7) E2T=0.104 T=36.7641(0)s x=0
	#4.35313±0.0955 tps=172K(6.30784M) a=[4.13026,4.58419] T=36.7641(sec)
[Section@1800] layer[0-8] tasks=19(nPassBack=0) last_loss=4.24873(0.645873) N=(772,2688,2128 237468)
[epoch_0]_1801   loss=4.312541 |g|=0.494	lr=5.99e-04 | 47.5%@S2  T=11.90s(data=1.9ms QKV=2.10s FFN=3.04s) eta=8d 03:45:32 | 45.4K token/s | 
[epoch_0]_1811   loss=4.229233 |g|=0.47	lr=5.99e-04 | 48.4%@S2  T=1.62s(data=1.7ms QKV=2.10s FFN=3.05s) eta=1d 02:36:46 | 45.6K token/s | 
[epoch_0]_1821   loss=4.314005 |g|=0.482	lr=5.99e-04 | 49.2%@S2  T=1.64s(data=1.8ms QKV=2.11s FFN=3.05s) eta=1d 02:53:38 | 45.8K token/s | 
[epoch_0]_1831   loss=4.222360 |g|=0.454	lr=5.99e-04 | 50.0%@S2  T=1.63s(data=1.7ms QKV=2.11s FFN=3.05s) eta=1d 02:46:02 | 46.1K token/s | 
[epoch_0]_1841   loss=4.233562 |g|=0.418	lr=5.99e-04 | 50.8%@S2  T=1.63s(data=1.6ms QKV=2.10s FFN=3.05s) eta=1d 02:48:43 | 46.3K token/s | 
[epoch_0]_1851   loss=4.269342 |g|=0.472	lr=5.99e-04 | 51.6%@S2  T=1.62s(data=1.6ms QKV=2.11s FFN=3.05s) eta=1d 02:33:50 | 46.5K token/s | 
[epoch_0]_1861   loss=4.262438 |g|=0.477	lr=5.99e-04 | 52.5%@S2  T=1.62s(data=1.5ms QKV=2.11s FFN=3.05s) eta=1d 02:35:05 | 46.7K token/s | 
[epoch_0]_1871   loss=4.202579 |g|=0.424	lr=5.99e-04 | 53.3%@S2  T=1.64s(data=1.6ms QKV=2.11s FFN=3.05s) eta=1d 02:53:27 | 46.9K token/s | 
[epoch_0]_1881   loss=4.268003 |g|=0.404	lr=5.99e-04 | 54.1%@S2  T=1.64s(data=1.6ms QKV=2.10s FFN=3.05s) eta=1d 02:56:12 | 47.0K token/s | 
[epoch_0]_1891   loss=4.243964 |g|=0.47	lr=5.99e-04 | 54.9%@S2  T=1.65s(data=1.7ms QKV=2.11s FFN=3.05s) eta=1d 03:01:55 | 47.2K token/s | 
[Fuyou] head="0" update algorithm=4 t=10.60s
[Section@1900] layer[8-16] tasks=19(nPassBack=0) last_loss=4.17745(0.633393) N=(772,2800,2240 250668)
[epoch_0]_1901   loss=4.253509 |g|=0.603	lr=5.99e-04 | 55.7%@S2  T=4.03s(data=1.8ms QKV=2.10s FFN=3.04s) eta=2d 18:09:14 | 45.8K token/s | 
[epoch_0]_1911   loss=4.235380 |g|=0.456	lr=5.99e-04 | 56.6%@S2  T=1.62s(data=1.6ms QKV=2.10s FFN=3.04s) eta=1d 02:35:11 | 46.1K token/s | 
[epoch_0]_1921   loss=4.225229 |g|=0.415	lr=5.99e-04 | 57.4%@S2  T=1.64s(data=1.7ms QKV=2.11s FFN=3.04s) eta=1d 02:53:34 | 46.3K token/s | 
[epoch_0]_1931   loss=4.203775 |g|=0.486	lr=5.99e-04 | 58.2%@S2  T=1.62s(data=1.9ms QKV=2.11s FFN=3.05s) eta=1d 02:40:21 | 46.5K token/s | 
[epoch_0]_1941   loss=4.205187 |g|=0.476	lr=5.99e-04 | 59.0%@S2  T=1.65s(data=1.6ms QKV=2.11s FFN=3.05s) eta=1d 03:03:59 | 46.6K token/s | 
[epoch_0]_1951   loss=4.258772 |g|=0.448	lr=5.99e-04 | 59.8%@S2  T=1.64s(data=1.7ms QKV=2.10s FFN=3.05s) eta=1d 02:53:31 | 46.8K token/s | 
[epoch_0]_1961   loss=4.154251 |g|=0.456	lr=5.99e-04 | 60.6%@S2  T=1.66s(data=7.0ms QKV=2.11s FFN=3.05s) eta=1d 03:15:22 | 46.9K token/s | 
[epoch_0]_1971   loss=4.165676 |g|=0.558	lr=5.99e-04 | 61.5%@S2  T=1.65s(data=1.6ms QKV=2.11s FFN=3.05s) eta=1d 02:59:24 | 47.1K token/s | 
[epoch_0]_1981   loss=4.174851 |g|=0.458	lr=5.99e-04 | 62.3%@S2  T=1.65s(data=1.8ms QKV=2.11s FFN=3.05s) eta=1d 03:04:14 | 47.2K token/s | 
[epoch_0]_1991   loss=4.169517 |g|=0.547	lr=5.99e-04 | 63.1%@S2  T=1.64s(data=1.9ms QKV=2.11s FFN=3.05s) eta=1d 02:52:14 | 47.3K token/s | 
[Fuyou] head="1" update algorithm=4 t=8.92s
[eval] 
	 Loss@"edu_fineweb1B"=4.255(0.098) nBranch=1 nToken=6.31M best=4.3531(8) E2T=0.0142 T=36.7649(0)s x=0
	#4.25477±0.0953 tps=172K(6.30784M) a=[4.02563,4.48396] T=36.7649(sec)
[Section@2000] layer[16-24] tasks=19(nPassBack=0) last_loss=4.24053(0.337034) N=(772,2912,2352 263868)
[epoch_0]_2001   loss=4.235850 |g|=0.665	lr=5.99e-04 | 63.9%@S2  T=11.86s(data=1.8ms QKV=2.10s FFN=3.04s) eta=8d 02:26:44 | 45.3K token/s | 
[epoch_0]_2011   loss=4.122676 |g|=0.453	lr=5.99e-04 | 64.7%@S2  T=1.62s(data=1.8ms QKV=2.10s FFN=3.04s) eta=1d 02:35:15 | 45.6K token/s | 
[epoch_0]_2021   loss=4.129835 |g|=0.56	lr=5.99e-04 | 65.6%@S2  T=1.67s(data=1.8ms QKV=2.11s FFN=3.05s) eta=1d 03:20:45 | 45.8K token/s | 
[epoch_0]_2031   loss=4.173173 |g|=0.522	lr=5.99e-04 | 66.4%@S2  T=1.62s(data=1.9ms QKV=2.11s FFN=3.05s) eta=1d 02:37:05 | 46.0K token/s | 
[epoch_0]_2041   loss=4.195983 |g|=0.45	lr=5.99e-04 | 67.2%@S2  T=1.64s(data=1.6ms QKV=2.11s FFN=3.05s) eta=1d 02:52:17 | 46.2K token/s | 
[epoch_0]_2051   loss=4.163640 |g|=0.41	lr=5.99e-04 | 68.0%@S2  T=1.64s(data=1.6ms QKV=2.11s FFN=3.05s) eta=1d 02:55:06 | 46.4K token/s | 
[epoch_0]_2061   loss=4.133211 |g|=0.49	lr=5.99e-04 | 68.8%@S2  T=1.63s(data=1.5ms QKV=2.11s FFN=3.05s) eta=1d 02:44:37 | 46.6K token/s | 
[epoch_0]_2071   loss=4.168108 |g|=0.49	lr=5.99e-04 | 69.7%@S2  T=1.62s(data=1.6ms QKV=2.11s FFN=3.05s) eta=1d 02:30:48 | 46.8K token/s | 
[epoch_0]_2081   loss=4.204166 |g|=0.436	lr=5.99e-04 | 70.5%@S2  T=1.62s(data=1.9ms QKV=2.11s FFN=3.05s) eta=1d 02:33:55 | 46.9K token/s | 
[epoch_0]_2091   loss=4.092406 |g|=0.475	lr=5.99e-04 | 71.3%@S2  T=1.64s(data=1.5ms QKV=2.11s FFN=3.05s) eta=1d 02:49:10 | 47.1K token/s | 
[Fuyou] head="2" update algorithm=4 t=10.91s
[Section@2100] layer[24-32] tasks=19(nPassBack=0) last_loss=4.1577(0.342082) N=(772,3024,2464 277068)
[epoch_0]_2101   loss=4.199941 |g|=0.643	lr=5.99e-04 | 72.1%@S2  T=4.28s(data=2.3ms QKV=2.10s FFN=3.04s) eta=2d 22:06:50 | 45.7K token/s | 
[epoch_0]_2111   loss=4.210218 |g|=0.481	lr=5.99e-04 | 72.9%@S2  T=1.64s(data=1.7ms QKV=2.10s FFN=3.04s) eta=1d 02:47:05 | 45.9K token/s | 
[epoch_0]_2121   loss=4.175221 |g|=0.495	lr=5.99e-04 | 73.8%@S2  T=1.63s(data=1.7ms QKV=2.11s FFN=3.04s) eta=1d 02:41:23 | 46.1K token/s | 
[epoch_0]_2131   loss=4.036080 |g|=0.401	lr=5.99e-04 | 74.6%@S2  T=1.64s(data=1.7ms QKV=2.11s FFN=3.04s) eta=1d 02:53:41 | 46.3K token/s | 
[epoch_0]_2141   loss=4.130101 |g|=0.442	lr=5.99e-04 | 75.4%@S2  T=1.64s(data=1.6ms QKV=2.11s FFN=3.05s) eta=1d 02:52:02 | 46.5K token/s | 
[epoch_0]_2151   loss=4.057078 |g|=0.408	lr=5.99e-04 | 76.2%@S2  T=1.63s(data=1.6ms QKV=2.11s FFN=3.05s) eta=1d 02:35:55 | 46.7K token/s | 
[epoch_0]_2161   loss=4.180006 |g|=0.495	lr=5.99e-04 | 77.0%@S2  T=1.65s(data=1.5ms QKV=2.11s FFN=3.04s) eta=1d 02:54:35 | 46.8K token/s | 
[epoch_0]_2171   loss=4.122108 |g|=0.502	lr=5.99e-04 | 77.8%@S2  T=1.64s(data=1.7ms QKV=2.11s FFN=3.05s) eta=1d 02:53:08 | 47.0K token/s | 
[epoch_0]_2181   loss=4.119967 |g|=0.46	lr=5.99e-04 | 78.7%@S2  T=1.64s(data=1.6ms QKV=2.11s FFN=3.05s) eta=1d 02:44:22 | 47.2K token/s | 
[epoch_0]_2191   loss=4.045261 |g|=0.486	lr=5.99e-04 | 79.5%@S2  T=1.64s(data=1.7ms QKV=2.11s FFN=3.05s) eta=1d 02:49:27 | 47.3K token/s | 
[Fuyou] head="3" update algorithm=4 t=11.17s
[eval] 
	 Loss@"edu_fineweb1B"=4.183(0.072) nBranch=1 nToken=6.31M best=4.2548(9) E2T=0.0663 T=36.7748(0)s x=0
	#4.18296±0.0958 tps=172K(6.30784M) a=[3.95793,4.41262] T=36.7748(sec)
[Section@2200] layer[32-40] tasks=19(nPassBack=0) last_loss=4.11666(0.218399) N=(772,3136,2576 290268)
[epoch_0]_2201   loss=4.077054 |g|=0.565	lr=5.99e-04 | 80.3%@S2  T=11.52s(data=1.8ms QKV=2.10s FFN=3.04s) eta=7d 20:17:31 | 45.3K token/s | 
[epoch_0]_2211   loss=4.118316 |g|=0.511	lr=5.99e-04 | 81.1%@S2  T=1.64s(data=1.8ms QKV=2.10s FFN=3.04s) eta=1d 02:46:05 | 45.5K token/s | 
[epoch_0]_2221   loss=4.061612 |g|=0.479	lr=5.99e-04 | 81.9%@S2  T=1.65s(data=1.6ms QKV=2.10s FFN=3.04s) eta=1d 02:56:11 | 45.7K token/s | 
[epoch_0]_2231   loss=4.079486 |g|=0.496	lr=5.99e-04 | 82.8%@S2  T=1.65s(data=1.6ms QKV=2.11s FFN=3.05s) eta=1d 02:52:27 | 45.9K token/s | 
[epoch_0]_2241   loss=4.108782 |g|=0.441	lr=5.99e-04 | 83.6%@S2  T=1.63s(data=1.8ms QKV=2.10s FFN=3.05s) eta=1d 02:35:17 | 46.1K token/s | 
[epoch_0]_2251   loss=4.075016 |g|=0.407	lr=5.99e-04 | 84.4%@S2  T=1.63s(data=2.1ms QKV=2.11s FFN=3.05s) eta=1d 02:35:26 | 46.4K token/s | 
[epoch_0]_2261   loss=4.113825 |g|=0.545	lr=5.99e-04 | 85.2%@S2  T=1.64s(data=1.9ms QKV=2.11s FFN=3.05s) eta=1d 02:47:38 | 46.5K token/s | 
[epoch_0]_2271   loss=4.054986 |g|=0.469	lr=5.99e-04 | 86.0%@S2  T=1.64s(data=1.6ms QKV=2.11s FFN=3.05s) eta=1d 02:43:52 | 46.7K token/s | 
[epoch_0]_2281   loss=4.042305 |g|=0.456	lr=5.99e-04 | 86.9%@S2  T=1.65s(data=1.6ms QKV=2.11s FFN=3.05s) eta=1d 02:52:42 | 46.9K token/s | 
[epoch_0]_2291   loss=4.072728 |g|=0.464	lr=5.99e-04 | 87.7%@S2  T=1.64s(data=1.6ms QKV=2.11s FFN=3.05s) eta=1d 02:46:23 | 47.0K token/s | 
[Fuyou] head="4" update algorithm=4 t=11.94s
[Section@2300] layer[40-48] tasks=19(nPassBack=0) last_loss=4.10988(0.172295) N=(772,3248,2688 303468)
[epoch_0]_2301   loss=4.045989 |g|=0.594	lr=5.99e-04 | 88.5%@S2  T=3.83s(data=1.6ms QKV=2.10s FFN=3.04s) eta=2d 14:31:32 | 45.7K token/s | 
[epoch_0]_2311   loss=4.143041 |g|=0.503	lr=5.99e-04 | 89.3%@S2  T=1.64s(data=1.7ms QKV=2.10s FFN=3.04s) eta=1d 02:45:08 | 45.9K token/s | 
[epoch_0]_2321   loss=4.054983 |g|=0.478	lr=5.99e-04 | 90.1%@S2  T=1.64s(data=2.1ms QKV=2.11s FFN=3.05s) eta=1d 02:40:31 | 46.1K token/s | 
[epoch_0]_2331   loss=4.067700 |g|=0.402	lr=5.99e-04 | 91.0%@S2  T=1.65s(data=1.6ms QKV=2.11s FFN=3.05s) eta=1d 02:52:28 | 46.3K token/s | 
[epoch_0]_2341   loss=4.115017 |g|=0.582	lr=5.99e-04 | 91.8%@S2  T=1.65s(data=1.7ms QKV=2.11s FFN=3.05s) eta=1d 02:49:20 | 46.5K token/s | 
[epoch_0]_2351   loss=4.093710 |g|=0.436	lr=5.99e-04 | 92.6%@S2  T=1.64s(data=1.7ms QKV=2.11s FFN=3.05s) eta=1d 02:46:40 | 46.7K token/s | 
[epoch_0]_2361   loss=4.026859 |g|=0.407	lr=5.99e-04 | 93.4%@S2  T=1.64s(data=1.6ms QKV=2.11s FFN=3.05s) eta=1d 02:42:25 | 46.8K token/s | 
[epoch_0]_2371   loss=4.013296 |g|=0.437	lr=5.99e-04 | 94.2%@S2  T=1.65s(data=1.6ms QKV=2.11s FFN=3.05s) eta=1d 02:49:08 | 47.0K token/s | 
[epoch_0]_2381   loss=4.043404 |g|=0.463	lr=5.99e-04 | 95.1%@S2  T=1.64s(data=1.7ms QKV=2.11s FFN=3.05s) eta=1d 02:43:18 | 47.1K token/s | 
[epoch_0]_2391   loss=4.130523 |g|=0.486	lr=5.99e-04 | 95.9%@S2  T=1.63s(data=1.8ms QKV=2.11s FFN=3.05s) eta=1d 02:30:47 | 47.3K token/s | 
[Fuyou] head="5" update algorithm=4 t=11.03s
[eval] 
	 Loss@"edu_fineweb1B"=4.117(0.066) nBranch=1 nToken=6.31M best=4.1830(10) E2T=0.0575 T=36.7599(0)s x=0
	#4.11663±0.0966 tps=172K(6.30784M) a=[3.88706,4.34351] T=36.7599(sec)
[Section@2400] layer[0-8] tasks=19(nPassBack=0) last_loss=4.05915(0.189572) N=(772,3360,2800 316668)
[epoch_0]_2401   loss=4.091558 |g|=0.593	lr=5.99e-04 | 96.7%@S2  T=11.99s(data=1.8ms QKV=2.10s FFN=3.04s) eta=8d 03:21:32 | 45.3K token/s | 
[epoch_0]_2411   loss=3.989443 |g|=0.493	lr=5.99e-04 | 97.5%@S2  T=1.63s(data=1.7ms QKV=2.11s FFN=3.05s) eta=1d 02:30:42 | 45.5K token/s | 
[epoch_0]_2421   loss=4.026024 |g|=0.431	lr=5.99e-04 | 98.3%@S2  T=1.64s(data=1.8ms QKV=2.11s FFN=3.05s) eta=1d 02:42:13 | 45.7K token/s | 
[epoch_0]_2431   loss=4.035954 |g|=0.466	lr=5.99e-04 | 99.1%@S2  T=1.64s(data=1.7ms QKV=2.11s FFN=3.05s) eta=1d 02:44:19 | 45.9K token/s | 
[epoch_0]_2441   loss=3.966352 |g|=0.49	lr=5.99e-04 | 100.0%@S2  T=1.64s(data=1.6ms QKV=2.11s FFN=3.05s) eta=1d 02:39:06 | 46.2K token/s | 
-------- End of shard_2@"./Datasets/edu_fineweb1B/edu_fineweb_train_000002.bin"-------- 
[shard-3]@"./Datasets/edu_fineweb1B/edu_fineweb_train_000003.bin": tokens=100(M) nShardSamples=1220(292968) 
[epoch_0]_2451   loss=4.125387 |g|=0.486	lr=5.99e-04 | 0.8%@S3  T=1.64s(data=1.2ms QKV=2.11s FFN=3.05s) eta=1d 02:38:51 | 46.3K token/s | 
[epoch_0]_2461   loss=4.160691 |g|=0.431	lr=5.99e-04 | 1.6%@S3  T=1.64s(data=1.3ms QKV=2.11s FFN=3.05s) eta=1d 02:40:16 | 46.5K token/s | 
[epoch_0]_2471   loss=4.030698 |g|=0.504	lr=5.99e-04 | 2.4%@S3  T=1.62s(data=1.2ms QKV=2.11s FFN=3.05s) eta=1d 02:24:43 | 46.7K token/s | 
[epoch_0]_2481   loss=4.062320 |g|=0.448	lr=5.99e-04 | 3.2%@S3  T=1.64s(data=1.3ms QKV=2.11s FFN=3.05s) eta=1d 02:44:31 | 46.9K token/s | 
[epoch_0]_2491   loss=4.104357 |g|=0.475	lr=5.99e-04 | 4.1%@S3  T=1.65s(data=1.7ms QKV=2.11s FFN=3.05s) eta=1d 02:46:40 | 47.0K token/s | 
[Fuyou] head="0" update algorithm=4 t=10.39s
[Section@2500] layer[8-16] tasks=19(nPassBack=0) last_loss=4.08165(0.0957952) N=(772,3472,2912 329868)
[epoch_0]_2501   loss=4.108588 |g|=0.617	lr=5.99e-04 | 4.9%@S3  T=4.02s(data=2.0ms QKV=2.10s FFN=3.04s) eta=2d 17:23:47 | 45.7K token/s | 
[epoch_0]_2511   loss=4.101618 |g|=0.461	lr=5.99e-04 | 5.7%@S3  T=1.61s(data=1.7ms QKV=2.11s FFN=3.04s) eta=1d 02:11:42 | 45.9K token/s | 
[epoch_0]_2521   loss=4.066116 |g|=0.465	lr=5.99e-04 | 6.5%@S3  T=1.64s(data=1.5ms QKV=2.11s FFN=3.05s) eta=1d 02:40:29 | 46.1K token/s | 
[epoch_0]_2531   loss=4.094961 |g|=0.437	lr=5.99e-04 | 7.3%@S3  T=1.62s(data=1.9ms QKV=2.11s FFN=3.05s) eta=1d 02:22:12 | 46.4K token/s | 
[epoch_0]_2541   loss=4.086997 |g|=0.426	lr=5.98e-04 | 8.2%@S3  T=1.64s(data=1.8ms QKV=2.11s FFN=3.05s) eta=1d 02:39:41 | 46.5K token/s | 
[epoch_0]_2551   loss=4.028947 |g|=0.458	lr=5.98e-04 | 9.0%@S3  T=1.62s(data=1.4ms QKV=2.11s FFN=3.05s) eta=1d 02:23:54 | 46.7K token/s | 
[epoch_0]_2561   loss=4.021070 |g|=0.41	lr=5.98e-04 | 9.8%@S3  T=1.63s(data=1.6ms QKV=2.11s FFN=3.05s) eta=1d 02:27:26 | 46.9K token/s | 
[epoch_0]_2571   loss=4.107687 |g|=0.465	lr=5.98e-04 | 10.6%@S3  T=1.64s(data=1.5ms QKV=2.11s FFN=3.05s) eta=1d 02:42:50 | 47.1K token/s | 
[epoch_0]_2581   loss=4.030687 |g|=0.428	lr=5.98e-04 | 11.4%@S3  T=1.64s(data=1.4ms QKV=2.11s FFN=3.05s) eta=1d 02:38:02 | 47.2K token/s | 
[epoch_0]_2591   loss=3.992494 |g|=0.479	lr=5.98e-04 | 12.3%@S3  T=1.64s(data=2.0ms QKV=2.11s FFN=3.05s) eta=1d 02:33:38 | 47.3K token/s | 
[Fuyou] head="1" update algorithm=4 t=10.20s
[eval] 
	 Loss@"edu_fineweb1B"=4.060(0.057) nBranch=1 nToken=6.31M best=4.1166(11) E2T=0.0465 T=36.7832(0)s x=0
	#4.05991±0.0966 tps=171K(6.30784M) a=[3.83519,4.30195] T=36.7832(sec)
[Section@2600] layer[16-24] tasks=19(nPassBack=0) last_loss=4.0134(0.227129) N=(772,3584,3024 343068)
[epoch_0]_2601   loss=4.023153 |g|=0.613	lr=5.98e-04 | 13.1%@S3  T=11.37s(data=1.7ms QKV=2.11s FFN=3.04s) eta=7d 16:32:28 | 45.3K token/s | 
[epoch_0]_2611   loss=4.029720 |g|=0.464	lr=5.98e-04 | 13.9%@S3  T=1.65s(data=1.6ms QKV=2.11s FFN=3.05s) eta=1d 02:45:52 | 45.6K token/s | 
[epoch_0]_2621   loss=4.152987 |g|=0.474	lr=5.98e-04 | 14.7%@S3  T=1.64s(data=1.7ms QKV=2.11s FFN=3.05s) eta=1d 02:38:31 | 45.8K token/s | 
[epoch_0]_2631   loss=4.067620 |g|=0.455	lr=5.98e-04 | 15.5%@S3  T=1.65s(data=1.7ms QKV=2.11s FFN=3.05s) eta=1d 02:42:58 | 46.0K token/s | 
[epoch_0]_2641   loss=3.999192 |g|=0.522	lr=5.98e-04 | 16.4%@S3  T=1.64s(data=2.0ms QKV=2.11s FFN=3.05s) eta=1d 02:37:39 | 46.2K token/s | 
[epoch_0]_2651   loss=4.031208 |g|=0.423	lr=5.98e-04 | 17.2%@S3  T=1.65s(data=1.8ms QKV=2.11s FFN=3.05s) eta=1d 02:46:01 | 46.3K token/s | 
[epoch_0]_2661   loss=3.967462 |g|=0.481	lr=5.98e-04 | 18.0%@S3  T=1.64s(data=1.7ms QKV=2.11s FFN=3.05s) eta=1d 02:37:49 | 46.5K token/s | 
[epoch_0]_2671   loss=4.013983 |g|=0.447	lr=5.98e-04 | 18.8%@S3  T=1.64s(data=1.5ms QKV=2.11s FFN=3.05s) eta=1d 02:34:23 | 46.7K token/s | 
[epoch_0]_2681   loss=3.982527 |g|=0.397	lr=5.98e-04 | 19.6%@S3  T=1.65s(data=1.7ms QKV=2.11s FFN=3.05s) eta=1d 02:43:35 | 46.8K token/s | 
[epoch_0]_2691   loss=4.022772 |g|=0.41	lr=5.98e-04 | 20.4%@S3  T=1.65s(data=1.5ms QKV=2.11s FFN=3.05s) eta=1d 02:41:52 | 47.0K token/s | 
[Fuyou] head="2" update algorithm=4 t=11.74s
[Section@2700] layer[24-32] tasks=19(nPassBack=0) last_loss=3.99427(0.163433) N=(772,3696,3136 356268)
[epoch_0]_2701   loss=4.039267 |g|=0.633	lr=5.98e-04 | 21.3%@S3  T=4.34s(data=1.9ms QKV=2.10s FFN=3.04s) eta=2d 22:22:04 | 45.6K token/s | 
[epoch_0]_2711   loss=4.003990 |g|=0.427	lr=5.98e-04 | 22.1%@S3  T=1.63s(data=1.9ms QKV=2.11s FFN=3.05s) eta=1d 02:22:10 | 45.8K token/s | 
[epoch_0]_2721   loss=4.064821 |g|=0.438	lr=5.98e-04 | 22.9%@S3  T=1.63s(data=1.8ms QKV=2.11s FFN=3.05s) eta=1d 02:25:12 | 46.0K token/s | 
[epoch_0]_2731   loss=3.978400 |g|=0.394	lr=5.98e-04 | 23.7%@S3  T=1.65s(data=1.8ms QKV=2.11s FFN=3.05s) eta=1d 02:40:03 | 46.2K token/s | 
[epoch_0]_2741   loss=3.993808 |g|=0.417	lr=5.98e-04 | 24.5%@S3  T=1.65s(data=1.7ms QKV=2.11s FFN=3.05s) eta=1d 02:44:46 | 46.4K token/s | 
[epoch_0]_2751   loss=4.024385 |g|=0.448	lr=5.98e-04 | 25.4%@S3  T=1.65s(data=1.7ms QKV=2.11s FFN=3.05s) eta=1d 02:39:34 | 46.6K token/s | 
[epoch_0]_2761   loss=3.993618 |g|=0.46	lr=5.98e-04 | 26.2%@S3  T=1.62s(data=1.8ms QKV=2.11s FFN=3.05s) eta=1d 02:15:20 | 46.8K token/s | 
[epoch_0]_2771   loss=4.007132 |g|=0.497	lr=5.98e-04 | 27.0%@S3  T=1.65s(data=1.4ms QKV=2.11s FFN=3.05s) eta=1d 02:37:38 | 46.9K token/s | 
[epoch_0]_2781   loss=3.957755 |g|=0.522	lr=5.98e-04 | 27.8%@S3  T=1.65s(data=1.4ms QKV=2.11s FFN=3.05s) eta=1d 02:40:18 | 47.0K token/s | 
[epoch_0]_2791   loss=4.010126 |g|=0.425	lr=5.98e-04 | 28.6%@S3  T=1.65s(data=1.4ms QKV=2.11s FFN=3.05s) eta=1d 02:42:31 | 47.2K token/s | 
[Fuyou] head="3" update algorithm=4 t=11.90s
[eval] 
	 Loss@"edu_fineweb1B"=4.016(0.043) nBranch=1 nToken=6.31M best=4.0599(12) E2T=0.0511 T=36.7601(0)s x=0
	#4.01648±0.0973 tps=172K(6.30784M) a=[3.7976,4.24757] T=36.7601(sec)
[Section@2800] layer[32-40] tasks=19(nPassBack=0) last_loss=3.96533(0.151334) N=(772,3808,3248 369468)
[epoch_0]_2801   loss=3.963834 |g|=0.743	lr=5.98e-04 | 29.5%@S3  T=11.84s(data=1.5ms QKV=2.10s FFN=3.04s) eta=7d 23:35:35 | 45.2K token/s | 
[epoch_0]_2811   loss=3.919828 |g|=0.488	lr=5.98e-04 | 30.3%@S3  T=1.64s(data=1.9ms QKV=2.11s FFN=3.05s) eta=1d 02:28:07 | 45.4K token/s | 
[epoch_0]_2821   loss=3.984343 |g|=0.425	lr=5.98e-04 | 31.1%@S3  T=1.64s(data=1.7ms QKV=2.11s FFN=3.05s) eta=1d 02:29:37 | 45.6K token/s | 
[epoch_0]_2831   loss=3.964765 |g|=0.45	lr=5.98e-04 | 31.9%@S3  T=1.64s(data=1.6ms QKV=2.11s FFN=3.05s) eta=1d 02:32:19 | 45.9K token/s | 
[epoch_0]_2841   loss=4.019862 |g|=0.423	lr=5.98e-04 | 32.7%@S3  T=1.65s(data=1.9ms QKV=2.11s FFN=3.05s) eta=1d 02:43:16 | 46.0K token/s | 
[epoch_0]_2851   loss=4.031232 |g|=0.436	lr=5.98e-04 | 33.6%@S3  T=1.65s(data=1.5ms QKV=2.11s FFN=3.05s) eta=1d 02:38:03 | 46.2K token/s | 
[epoch_0]_2861   loss=3.996224 |g|=0.505	lr=5.98e-04 | 34.4%@S3  T=1.65s(data=1.8ms QKV=2.11s FFN=3.05s) eta=1d 02:35:57 | 46.4K token/s | 
[epoch_0]_2871   loss=3.966710 |g|=0.436	lr=5.98e-04 | 35.2%@S3  T=1.66s(data=1.7ms QKV=2.11s FFN=3.05s) eta=1d 02:45:46 | 46.6K token/s | 
[epoch_0]_2881   loss=3.973636 |g|=0.503	lr=5.98e-04 | 36.0%@S3  T=1.64s(data=1.7ms QKV=2.11s FFN=3.05s) eta=1d 02:33:07 | 46.7K token/s | 
[epoch_0]_2891   loss=3.935754 |g|=0.43	lr=5.98e-04 | 36.8%@S3  T=1.65s(data=1.7ms QKV=2.11s FFN=3.05s) eta=1d 02:38:02 | 46.9K token/s | 
[Fuyou] head="4" update algorithm=4 t=11.88s
[Section@2900] layer[40-48] tasks=19(nPassBack=0) last_loss=3.95962(0.150259) N=(772,3920,3360 382668)
[epoch_0]_2901   loss=3.913698 |g|=0.511	lr=5.98e-04 | 37.7%@S3  T=4.27s(data=1.7ms QKV=2.10s FFN=3.04s) eta=2d 20:59:16 | 45.5K token/s | 
[epoch_0]_2911   loss=3.885519 |g|=0.447	lr=5.98e-04 | 38.5%@S3  T=1.64s(data=1.8ms QKV=2.11s FFN=3.05s) eta=1d 02:31:51 | 45.7K token/s | 
[epoch_0]_2921   loss=3.977664 |g|=0.462	lr=5.98e-04 | 39.3%@S3  T=1.62s(data=1.7ms QKV=2.11s FFN=3.05s) eta=1d 02:11:47 | 45.9K token/s | 
[epoch_0]_2931   loss=3.946364 |g|=0.43	lr=5.98e-04 | 40.1%@S3  T=1.66s(data=1.8ms QKV=2.11s FFN=3.05s) eta=1d 02:47:47 | 46.1K token/s | 
[epoch_0]_2941   loss=3.913126 |g|=0.39	lr=5.98e-04 | 40.9%@S3  T=1.65s(data=2.1ms QKV=2.11s FFN=3.05s) eta=1d 02:33:55 | 46.3K token/s | 
[epoch_0]_2951   loss=4.023265 |g|=0.435	lr=5.98e-04 | 41.7%@S3  T=1.65s(data=1.6ms QKV=2.11s FFN=3.05s) eta=1d 02:41:25 | 46.5K token/s | 
[epoch_0]_2961   loss=4.016358 |g|=0.411	lr=5.98e-04 | 42.6%@S3  T=1.63s(data=1.4ms QKV=2.11s FFN=3.05s) eta=1d 02:19:52 | 46.6K token/s | 
[epoch_0]_2971   loss=3.916928 |g|=0.4	lr=5.98e-04 | 43.4%@S3  T=1.65s(data=1.5ms QKV=2.11s FFN=3.05s) eta=1d 02:37:56 | 46.8K token/s | 
[epoch_0]_2981   loss=3.973960 |g|=0.428	lr=5.98e-04 | 44.2%@S3  T=1.66s(data=1.5ms QKV=2.11s FFN=3.05s) eta=1d 02:46:49 | 46.9K token/s | 
[epoch_0]_2991   loss=4.005671 |g|=0.431	lr=5.98e-04 | 45.0%@S3  T=1.65s(data=1.8ms QKV=2.11s FFN=3.05s) eta=1d 02:36:27 | 47.0K token/s | 
[Fuyou] head="5" update algorithm=4 t=12.44s
[eval] 
	 Loss@"edu_fineweb1B"=3.982(0.034) nBranch=1 nToken=6.31M best=4.0165(13) E2T=0.0619 T=36.7554(0)s x=0
	#3.98199±0.0978 tps=172K(6.30784M) a=[3.75561,4.21588] T=36.7554(sec)
[Section@3000] layer[0-8] tasks=19(nPassBack=0) last_loss=3.92012(0.139032) N=(772,4032,3472 395868)
[epoch_0]_3001   loss=4.013878 |g|=0.486	lr=5.98e-04 | 45.8%@S3  T=12.05s(data=2.0ms QKV=2.10s FFN=3.04s) eta=8d 02:18:05 | 45.0K token/s | 
[epoch_0]_3011   loss=3.915838 |g|=0.509	lr=5.98e-04 | 46.7%@S3  T=1.63s(data=2.0ms QKV=2.11s FFN=3.05s) eta=1d 02:12:06 | 45.3K token/s | 
[epoch_0]_3021   loss=3.944363 |g|=0.424	lr=5.98e-04 | 47.5%@S3  T=1.65s(data=1.8ms QKV=2.11s FFN=3.05s) eta=1d 02:31:49 | 45.5K token/s | 
[epoch_0]_3031   loss=3.960993 |g|=0.44	lr=5.98e-04 | 48.3%@S3  T=1.65s(data=1.6ms QKV=2.11s FFN=3.05s) eta=1d 02:34:37 | 45.7K token/s | 
[epoch_0]_3041   loss=3.939862 |g|=0.375	lr=5.98e-04 | 49.1%@S3  T=1.65s(data=1.7ms QKV=2.11s FFN=3.05s) eta=1d 02:36:54 | 45.9K token/s | 
[epoch_0]_3051   loss=3.904907 |g|=0.423	lr=5.98e-04 | 49.9%@S3  T=1.65s(data=1.6ms QKV=2.11s FFN=3.05s) eta=1d 02:36:01 | 46.1K token/s | 
[epoch_0]_3061   loss=3.946776 |g|=0.48	lr=5.98e-04 | 50.8%@S3  T=1.65s(data=1.6ms QKV=2.11s FFN=3.05s) eta=1d 02:34:06 | 46.3K token/s | 
[epoch_0]_3071   loss=3.948980 |g|=0.393	lr=5.98e-04 | 51.6%@S3  T=1.64s(data=1.8ms QKV=2.11s FFN=3.05s) eta=1d 02:28:24 | 46.5K token/s | 
[epoch_0]_3081   loss=3.903913 |g|=0.42	lr=5.98e-04 | 52.4%@S3  T=1.64s(data=1.6ms QKV=2.11s FFN=3.05s) eta=1d 02:28:06 | 46.6K token/s | 
[epoch_0]_3091   loss=3.908192 |g|=0.45	lr=5.98e-04 | 53.2%@S3  T=1.65s(data=1.6ms QKV=2.11s FFN=3.05s) eta=1d 02:36:18 | 46.8K token/s | 
[Fuyou] head="0" update algorithm=4 t=12.47s
[Section@3100] layer[8-16] tasks=19(nPassBack=0) last_loss=3.9232(0.158455) N=(772,4144,3584 409068)
[epoch_0]_3101   loss=3.878858 |g|=0.579	lr=5.97e-04 | 54.0%@S3  T=4.45s(data=2.1ms QKV=2.10s FFN=3.04s) eta=2d 23:34:20 | 45.4K token/s | 
[epoch_0]_3111   loss=3.915992 |g|=0.436	lr=5.97e-04 | 54.9%@S3  T=1.64s(data=2.1ms QKV=2.10s FFN=3.05s) eta=1d 02:21:36 | 45.6K token/s | 
[epoch_0]_3121   loss=3.972919 |g|=0.422	lr=5.97e-04 | 55.7%@S3  T=1.64s(data=2.1ms QKV=2.11s FFN=3.05s) eta=1d 02:20:02 | 45.8K token/s | 
[epoch_0]_3131   loss=3.918857 |g|=0.444	lr=5.97e-04 | 56.5%@S3  T=1.62s(data=1.8ms QKV=2.11s FFN=3.05s) eta=1d 02:04:45 | 46.1K token/s | 
[epoch_0]_3141   loss=3.958025 |g|=0.438	lr=5.97e-04 | 57.3%@S3  T=1.67s(data=1.5ms QKV=2.11s FFN=3.05s) eta=1d 02:48:29 | 46.2K token/s | 
[epoch_0]_3151   loss=3.954159 |g|=0.393	lr=5.97e-04 | 58.1%@S3  T=1.66s(data=2.0ms QKV=2.11s FFN=3.05s) eta=1d 02:38:46 | 46.4K token/s | 
[epoch_0]_3161   loss=3.915381 |g|=0.494	lr=5.97e-04 | 59.0%@S3  T=1.64s(data=1.6ms QKV=2.11s FFN=3.05s) eta=1d 02:25:33 | 46.5K token/s | 
[epoch_0]_3171   loss=3.923170 |g|=0.448	lr=5.97e-04 | 59.8%@S3  T=1.65s(data=1.5ms QKV=2.11s FFN=3.05s) eta=1d 02:28:16 | 46.7K token/s | 
[epoch_0]_3181   loss=3.898759 |g|=0.416	lr=5.97e-04 | 60.6%@S3  T=1.65s(data=1.9ms QKV=2.11s FFN=3.05s) eta=1d 02:29:14 | 46.9K token/s | 
[epoch_0]_3191   loss=3.905362 |g|=0.45	lr=5.97e-04 | 61.4%@S3  T=1.65s(data=1.9ms QKV=2.10s FFN=3.05s) eta=1d 02:31:40 | 47.0K token/s | 
[Fuyou] head="1" update algorithm=4 t=11.34s
[eval] 
	 Loss@"edu_fineweb1B"=3.940(0.042) nBranch=1 nToken=6.31M best=3.9820(14) E2T=-0.0406 T=36.7644(0)s x=0
	#3.93952±0.0981 tps=172K(6.30784M) a=[3.72344,4.18556] T=36.7644(sec)
[Section@3200] layer[16-24] tasks=19(nPassBack=0) last_loss=3.98014(0.0332601) N=(772,4256,3696 422268)
[epoch_0]_3201   loss=3.957447 |g|=0.623	lr=5.97e-04 | 62.2%@S3  T=11.56s(data=1.9ms QKV=2.10s FFN=3.04s) eta=7d 17:44:38 | 45.0K token/s | 
[epoch_0]_3211   loss=3.966656 |g|=0.426	lr=5.97e-04 | 63.0%@S3  T=1.65s(data=1.6ms QKV=2.10s FFN=3.05s) eta=1d 02:28:22 | 45.2K token/s | 
[epoch_0]_3221   loss=3.861372 |g|=0.404	lr=5.97e-04 | 63.9%@S3  T=1.65s(data=1.6ms QKV=2.10s FFN=3.05s) eta=1d 02:29:01 | 45.5K token/s | 
[epoch_0]_3231   loss=3.995450 |g|=0.514	lr=5.97e-04 | 64.7%@S3  T=1.64s(data=1.7ms QKV=2.10s FFN=3.05s) eta=1d 02:22:00 | 45.7K token/s | 
[epoch_0]_3241   loss=3.901900 |g|=0.497	lr=5.97e-04 | 65.5%@S3  T=1.65s(data=1.6ms QKV=2.10s FFN=3.05s) eta=1d 02:24:52 | 45.9K token/s | 
[epoch_0]_3251   loss=3.902806 |g|=0.435	lr=5.97e-04 | 66.3%@S3  T=1.65s(data=1.7ms QKV=2.10s FFN=3.05s) eta=1d 02:27:12 | 46.1K token/s | 
[epoch_0]_3261   loss=3.846163 |g|=0.465	lr=5.97e-04 | 67.1%@S3  T=1.65s(data=1.7ms QKV=2.10s FFN=3.05s) eta=1d 02:24:09 | 46.3K token/s | 
[epoch_0]_3271   loss=3.897470 |g|=0.411	lr=5.97e-04 | 68.0%@S3  T=1.65s(data=1.7ms QKV=2.10s FFN=3.05s) eta=1d 02:24:41 | 46.4K token/s | 
[epoch_0]_3281   loss=3.912105 |g|=0.444	lr=5.97e-04 | 68.8%@S3  T=1.67s(data=1.6ms QKV=2.10s FFN=3.05s) eta=1d 02:45:18 | 46.6K token/s | 
[epoch_0]_3291   loss=3.901204 |g|=0.431	lr=5.97e-04 | 69.6%@S3  T=1.65s(data=1.7ms QKV=2.10s FFN=3.05s) eta=1d 02:26:21 | 46.7K token/s | 
[Fuyou] head="2" update algorithm=4 t=9.23s
[Section@3300] layer[24-32] tasks=19(nPassBack=0) last_loss=3.88671(0.107561) N=(772,4368,3808 435468)
[epoch_0]_3301   loss=3.908956 |g|=0.611	lr=5.97e-04 | 70.4%@S3  T=4.30s(data=1.6ms QKV=2.10s FFN=3.04s) eta=2d 21:01:16 | 45.3K token/s | 
[epoch_0]_3311   loss=3.854469 |g|=0.462	lr=5.97e-04 | 71.2%@S3  T=1.65s(data=1.5ms QKV=2.10s FFN=3.05s) eta=1d 02:23:22 | 45.6K token/s | 
[epoch_0]_3321   loss=3.896654 |g|=0.452	lr=5.97e-04 | 72.1%@S3  T=1.63s(data=1.6ms QKV=2.10s FFN=3.05s) eta=1d 02:07:11 | 45.8K token/s | 
[epoch_0]_3331   loss=3.839066 |g|=0.492	lr=5.97e-04 | 72.9%@S3  T=1.63s(data=1.6ms QKV=2.11s FFN=3.05s) eta=1d 02:08:08 | 46.0K token/s | 
[epoch_0]_3341   loss=3.831707 |g|=0.384	lr=5.97e-04 | 73.7%@S3  T=1.65s(data=1.7ms QKV=2.10s FFN=3.05s) eta=1d 02:24:09 | 46.2K token/s | 
[epoch_0]_3351   loss=3.878120 |g|=0.445	lr=5.97e-04 | 74.5%@S3  T=1.67s(data=1.9ms QKV=2.11s FFN=3.05s) eta=1d 02:46:09 | 46.3K token/s | 
[epoch_0]_3361   loss=3.867651 |g|=0.49	lr=5.97e-04 | 75.3%@S3  T=1.66s(data=1.6ms QKV=2.11s FFN=3.05s) eta=1d 02:33:01 | 46.5K token/s | 
[epoch_0]_3371   loss=3.896167 |g|=0.454	lr=5.97e-04 | 76.2%@S3  T=1.64s(data=1.6ms QKV=2.10s FFN=3.05s) eta=1d 02:14:38 | 46.7K token/s | 
[epoch_0]_3381   loss=3.906595 |g|=0.449	lr=5.97e-04 | 77.0%@S3  T=1.65s(data=1.7ms QKV=2.11s FFN=3.05s) eta=1d 02:26:32 | 46.8K token/s | 
[epoch_0]_3391   loss=3.872763 |g|=0.44	lr=5.97e-04 | 77.8%@S3  T=1.65s(data=1.5ms QKV=2.10s FFN=3.05s) eta=1d 02:23:55 | 47.0K token/s | 
[Fuyou] head="3" update algorithm=4 t=11.31s
[eval] 
	 Loss@"edu_fineweb1B"=3.910(0.03) nBranch=1 nToken=6.31M best=3.9395(15) E2T=0.00449 T=36.7508(0)s x=0
	#3.90962±0.0979 tps=172K(6.30784M) a=[3.69769,4.15587] T=36.7508(sec)
[Section@3400] layer[32-40] tasks=19(nPassBack=0) last_loss=3.90513(0.0601983) N=(772,4480,3920 448668)
[epoch_0]_3401   loss=3.939012 |g|=0.624	lr=5.97e-04 | 78.6%@S3  T=11.90s(data=1.7ms QKV=2.10s FFN=3.04s) eta=7d 22:33:10 | 45.0K token/s | 
[epoch_0]_3411   loss=3.904675 |g|=0.475	lr=5.97e-04 | 79.4%@S3  T=1.65s(data=1.8ms QKV=2.10s FFN=3.05s) eta=1d 02:23:20 | 45.2K token/s | 
[epoch_0]_3421   loss=3.871851 |g|=0.406	lr=5.97e-04 | 80.3%@S3  T=1.64s(data=1.6ms QKV=2.10s FFN=3.05s) eta=1d 02:18:09 | 45.4K token/s | 
[epoch_0]_3431   loss=3.841332 |g|=0.413	lr=5.97e-04 | 81.1%@S3  T=1.63s(data=1.7ms QKV=2.10s FFN=3.05s) eta=1d 02:09:29 | 45.7K token/s | 
[epoch_0]_3441   loss=3.932155 |g|=0.426	lr=5.97e-04 | 81.9%@S3  T=1.66s(data=1.8ms QKV=2.10s FFN=3.05s) eta=1d 02:31:37 | 45.9K token/s | 
[epoch_0]_3451   loss=3.839920 |g|=0.437	lr=5.97e-04 | 82.7%@S3  T=1.64s(data=1.9ms QKV=2.10s FFN=3.05s) eta=1d 02:15:25 | 46.1K token/s | 
[epoch_0]_3461   loss=3.792001 |g|=0.433	lr=5.97e-04 | 83.5%@S3  T=1.65s(data=1.7ms QKV=2.10s FFN=3.05s) eta=1d 02:27:23 | 46.2K token/s | 
[epoch_0]_3471   loss=3.885885 |g|=0.454	lr=5.97e-04 | 84.3%@S3  T=1.65s(data=1.5ms QKV=2.10s FFN=3.05s) eta=1d 02:22:29 | 46.4K token/s | 
[epoch_0]_3481   loss=3.824468 |g|=0.419	lr=5.97e-04 | 85.2%@S3  T=1.65s(data=1.8ms QKV=2.10s FFN=3.05s) eta=1d 02:20:53 | 46.6K token/s | 
[epoch_0]_3491   loss=3.898151 |g|=0.405	lr=5.97e-04 | 86.0%@S3  T=1.66s(data=1.6ms QKV=2.10s FFN=3.05s) eta=1d 02:27:49 | 46.7K token/s | 
[Fuyou] head="4" update algorithm=4 t=12.73s
[Section@3500] layer[40-48] tasks=19(nPassBack=0) last_loss=3.83113(0.128489) N=(772,4592,4032 461868)
[epoch_0]_3501   loss=3.865656 |g|=0.447	lr=5.97e-04 | 86.8%@S3  T=4.36s(data=2.0ms QKV=2.10s FFN=3.04s) eta=2d 21:39:54 | 45.3K token/s | 
[epoch_0]_3511   loss=3.836254 |g|=0.453	lr=5.97e-04 | 87.6%@S3  T=1.64s(data=1.9ms QKV=2.10s FFN=3.05s) eta=1d 02:12:06 | 45.5K token/s | 
[epoch_0]_3521   loss=3.813217 |g|=0.385	lr=5.97e-04 | 88.4%@S3  T=1.66s(data=1.7ms QKV=2.10s FFN=3.05s) eta=1d 02:27:14 | 45.7K token/s | 
[epoch_0]_3531   loss=3.819643 |g|=0.42	lr=5.97e-04 | 89.3%@S3  T=1.62s(data=1.9ms QKV=2.10s FFN=3.05s) eta=1d 01:55:32 | 46.0K token/s | 
[epoch_0]_3541   loss=3.902460 |g|=0.452	lr=5.97e-04 | 90.1%@S3  T=1.63s(data=1.6ms QKV=2.10s FFN=3.05s) eta=1d 02:04:21 | 46.2K token/s | 
[epoch_0]_3551   loss=3.902083 |g|=0.463	lr=5.97e-04 | 90.9%@S3  T=1.65s(data=1.7ms QKV=2.10s FFN=3.05s) eta=1d 02:16:50 | 46.4K token/s | 
[epoch_0]_3561   loss=3.783534 |g|=0.47	lr=5.96e-04 | 91.7%@S3  T=1.62s(data=1.9ms QKV=2.11s FFN=3.05s) eta=1d 01:55:11 | 46.6K token/s | 
[epoch_0]_3571   loss=3.962355 |g|=0.483	lr=5.96e-04 | 92.5%@S3  T=1.62s(data=1.8ms QKV=2.10s FFN=3.05s) eta=1d 01:55:32 | 46.8K token/s | 
[epoch_0]_3581   loss=3.778813 |g|=0.649	lr=5.96e-04 | 93.4%@S3  T=1.65s(data=1.6ms QKV=2.10s FFN=3.05s) eta=1d 02:21:34 | 46.9K token/s | 
[epoch_0]_3591   loss=3.860010 |g|=0.434	lr=5.96e-04 | 94.2%@S3  T=1.65s(data=1.6ms QKV=2.10s FFN=3.05s) eta=1d 02:23:11 | 47.0K token/s | 
[Fuyou] head="5" update algorithm=4 t=11.62s
[eval] 
	 Loss@"edu_fineweb1B"=3.880(0.029) nBranch=1 nToken=6.31M best=3.9096(16) E2T=0.034 T=36.7306(0)s x=0
	#3.88013±0.0974 tps=172K(6.30784M) a=[3.66529,4.12501] T=36.7306(sec)
[Section@3600] layer[0-8] tasks=19(nPassBack=0) last_loss=3.84616(0.0739594) N=(772,4704,4144 475068)
[epoch_0]_3601   loss=3.821247 |g|=0.498	lr=5.96e-04 | 95.0%@S3  T=12.29s(data=1.8ms QKV=2.10s FFN=3.04s) eta=8d 03:59:55 | 45.0K token/s | 
[epoch_0]_3611   loss=3.826514 |g|=0.419	lr=5.96e-04 | 95.8%@S3  T=1.65s(data=2.2ms QKV=2.10s FFN=3.04s) eta=1d 02:18:07 | 45.3K token/s | 
[epoch_0]_3621   loss=3.815426 |g|=0.427	lr=5.96e-04 | 96.6%@S3  T=1.66s(data=1.8ms QKV=2.10s FFN=3.04s) eta=1d 02:26:13 | 45.5K token/s | 
[epoch_0]_3631   loss=3.843751 |g|=0.517	lr=5.96e-04 | 97.5%@S3  T=1.63s(data=1.8ms QKV=2.11s FFN=3.04s) eta=1d 01:59:36 | 45.7K token/s | 
[epoch_0]_3641   loss=3.800793 |g|=0.405	lr=5.96e-04 | 98.3%@S3  T=1.63s(data=1.9ms QKV=2.10s FFN=3.04s) eta=1d 01:55:27 | 45.9K token/s | 
[epoch_0]_3651   loss=3.835544 |g|=0.53	lr=5.96e-04 | 99.1%@S3  T=1.64s(data=1.5ms QKV=2.11s FFN=3.05s) eta=1d 02:05:06 | 46.1K token/s | 
[epoch_0]_3661   loss=3.800512 |g|=0.513	lr=5.96e-04 | 99.9%@S3  T=1.64s(data=1.7ms QKV=2.11s FFN=3.05s) eta=1d 02:12:04 | 46.3K token/s | 
[epoch_0]_3662   loss=3.833114 |g|=0.485	lr=5.96e-04 | 100.0%@S3  T=1.66s(data=2.1ms QKV=2.11s FFN=3.05s) eta=1d 02:24:12 | 46.5K token/s | 
-------- End of shard_3@"./Datasets/edu_fineweb1B/edu_fineweb_train_000003.bin"-------- 
[shard-4]@"./Datasets/edu_fineweb1B/edu_fineweb_train_000004.bin": tokens=100(M) nShardSamples=1220(390624) 
[epoch_0]_3671   loss=3.761628 |g|=0.418	lr=5.96e-04 | 0.7%@S4  T=1.65s(data=1.3ms QKV=2.11s FFN=3.05s) eta=1d 02:16:16 | 46.6K token/s | 
[epoch_0]_3681   loss=3.763453 |g|=0.496	lr=5.96e-04 | 1.5%@S4  T=1.64s(data=1.5ms QKV=2.10s FFN=3.04s) eta=1d 02:08:08 | 46.8K token/s | 
[epoch_0]_3691   loss=3.742181 |g|=0.464	lr=5.96e-04 | 2.4%@S4  T=1.65s(data=1.5ms QKV=2.11s FFN=3.05s) eta=1d 02:16:19 | 47.0K token/s | 
[Fuyou] head="0" update algorithm=4 t=12.01s
[Section@3700] layer[8-16] tasks=19(nPassBack=0) last_loss=3.71272(0.210481) N=(772,4816,4256 488268)
[epoch_0]_3701   loss=3.736940 |g|=0.525	lr=5.96e-04 | 3.2%@S4  T=4.33s(data=1.6ms QKV=2.10s FFN=3.04s) eta=2d 20:58:23 | 45.5K token/s | 
[epoch_0]_3711   loss=3.731794 |g|=0.431	lr=5.96e-04 | 4.0%@S4  T=1.64s(data=1.6ms QKV=2.10s FFN=3.04s) eta=1d 02:07:09 | 45.8K token/s | 
[epoch_0]_3721   loss=3.855704 |g|=0.432	lr=5.96e-04 | 4.8%@S4  T=1.64s(data=1.6ms QKV=2.10s FFN=3.04s) eta=1d 02:09:16 | 46.0K token/s | 
[epoch_0]_3731   loss=3.758574 |g|=0.523	lr=5.96e-04 | 5.6%@S4  T=1.64s(data=1.8ms QKV=2.11s FFN=3.04s) eta=1d 02:08:02 | 46.2K token/s | 
[epoch_0]_3741   loss=3.716206 |g|=0.441	lr=5.96e-04 | 6.5%@S4  T=1.64s(data=1.5ms QKV=2.10s FFN=3.04s) eta=1d 02:05:41 | 46.4K token/s | 
[epoch_0]_3751   loss=3.753465 |g|=0.43	lr=5.96e-04 | 7.3%@S4  T=1.62s(data=2.6ms QKV=2.11s FFN=3.04s) eta=1d 01:49:09 | 46.6K token/s | 
[epoch_0]_3761   loss=3.760994 |g|=0.424	lr=5.96e-04 | 8.1%@S4  T=1.63s(data=2.8ms QKV=2.10s FFN=3.05s) eta=1d 01:53:00 | 46.8K token/s | 
[epoch_0]_3771   loss=3.752246 |g|=0.466	lr=5.96e-04 | 8.9%@S4  T=1.65s(data=1.6ms QKV=2.11s FFN=3.04s) eta=1d 02:14:42 | 46.9K token/s | 
[epoch_0]_3781   loss=3.796496 |g|=0.429	lr=5.96e-04 | 9.7%@S4  T=1.65s(data=1.5ms QKV=2.11s FFN=3.04s) eta=1d 02:10:56 | 47.0K token/s | 
[epoch_0]_3791   loss=3.783960 |g|=0.513	lr=5.96e-04 | 10.6%@S4  T=1.65s(data=1.4ms QKV=2.10s FFN=3.04s) eta=1d 02:17:43 | 47.2K token/s | 
[Fuyou] head="1" update algorithm=4 t=10.80s
[eval] 
	 Loss@"edu_fineweb1B"=3.866(0.014) nBranch=1 nToken=6.31M best=3.8801(17) E2T=0.124 T=36.7488(0)s x=0
	#3.86633±0.0997 tps=172K(6.30784M) a=[3.64758,4.11999] T=36.7488(sec)
[Section@3800] layer[16-24] tasks=19(nPassBack=0) last_loss=3.74203(0.238114) N=(772,4928,4368 501468)
[epoch_0]_3801   loss=3.786365 |g|=0.465	lr=5.96e-04 | 11.4%@S4  T=12.01s(data=1.7ms QKV=2.10s FFN=3.04s) eta=7d 22:55:42 | 45.1K token/s | 
[epoch_0]_3811   loss=3.760610 |g|=0.405	lr=5.96e-04 | 12.2%@S4  T=1.64s(data=1.7ms QKV=2.10s FFN=3.04s) eta=1d 02:05:22 | 45.4K token/s | 
[epoch_0]_3821   loss=3.803762 |g|=0.475	lr=5.96e-04 | 13.0%@S4  T=1.63s(data=1.7ms QKV=2.10s FFN=3.04s) eta=1d 01:56:09 | 45.6K token/s | 
[epoch_0]_3831   loss=3.709019 |g|=0.383	lr=5.96e-04 | 13.8%@S4  T=1.65s(data=1.6ms QKV=2.11s FFN=3.04s) eta=1d 02:16:34 | 45.8K token/s | 
[epoch_0]_3841   loss=3.730318 |g|=0.463	lr=5.96e-04 | 14.7%@S4  T=1.65s(data=2.0ms QKV=2.11s FFN=3.04s) eta=1d 02:13:47 | 46.0K token/s | 
[epoch_0]_3851   loss=3.680617 |g|=0.411	lr=5.96e-04 | 15.5%@S4  T=1.65s(data=1.8ms QKV=2.11s FFN=3.04s) eta=1d 02:15:31 | 46.2K token/s | 
[epoch_0]_3861   loss=3.696855 |g|=0.479	lr=5.96e-04 | 16.3%@S4  T=1.63s(data=1.5ms QKV=2.10s FFN=3.05s) eta=1d 01:52:18 | 46.4K token/s | 
[epoch_0]_3871   loss=3.705118 |g|=0.43	lr=5.96e-04 | 17.1%@S4  T=1.65s(data=1.5ms QKV=2.11s FFN=3.04s) eta=1d 02:08:06 | 46.6K token/s | 
[epoch_0]_3881   loss=3.766190 |g|=0.383	lr=5.96e-04 | 17.9%@S4  T=1.65s(data=1.6ms QKV=2.11s FFN=3.04s) eta=1d 02:08:07 | 46.7K token/s | 
[epoch_0]_3891   loss=3.746345 |g|=0.438	lr=5.96e-04 | 18.8%@S4  T=1.64s(data=1.4ms QKV=2.11s FFN=3.04s) eta=1d 02:05:55 | 46.9K token/s | 
[Fuyou] head="2" update algorithm=4 t=10.75s
[Section@3900] layer[24-32] tasks=19(nPassBack=0) last_loss=3.78993(0.0967715) N=(772,5040,4480 514668)
[epoch_0]_3901   loss=3.812242 |g|=0.511	lr=5.96e-04 | 19.6%@S4  T=4.30s(data=2.1ms QKV=2.10s FFN=3.04s) eta=2d 20:14:19 | 45.5K token/s | 
[epoch_0]_3911   loss=3.768641 |g|=0.426	lr=5.96e-04 | 20.4%@S4  T=1.64s(data=1.5ms QKV=2.10s FFN=3.04s) eta=1d 02:00:45 | 45.7K token/s | 
[epoch_0]_3921   loss=3.707921 |g|=0.433	lr=5.96e-04 | 21.2%@S4  T=1.63s(data=2.1ms QKV=2.10s FFN=3.04s) eta=1d 01:54:35 | 45.9K token/s | 
[epoch_0]_3931   loss=3.755189 |g|=0.389	lr=5.96e-04 | 22.0%@S4  T=1.62s(data=2.6ms QKV=2.11s FFN=3.04s) eta=1d 01:45:02 | 46.2K token/s | 
[epoch_0]_3941   loss=3.767161 |g|=0.543	lr=5.96e-04 | 22.8%@S4  T=1.64s(data=1.7ms QKV=2.11s FFN=3.04s) eta=1d 02:05:10 | 46.3K token/s | 
[epoch_0]_3951   loss=3.802223 |g|=0.466	lr=5.96e-04 | 23.7%@S4  T=1.65s(data=1.7ms QKV=2.11s FFN=3.04s) eta=1d 02:06:46 | 46.5K token/s | 
[epoch_0]_3961   loss=3.727953 |g|=0.459	lr=5.95e-04 | 24.5%@S4  T=1.64s(data=1.7ms QKV=2.11s FFN=3.04s) eta=1d 02:03:45 | 46.7K token/s | 
[epoch_0]_3971   loss=3.749630 |g|=0.418	lr=5.95e-04 | 25.3%@S4  T=1.65s(data=1.4ms QKV=2.11s FFN=3.05s) eta=1d 02:11:21 | 46.8K token/s | 
[epoch_0]_3981   loss=3.689595 |g|=0.443	lr=5.95e-04 | 26.1%@S4  T=1.64s(data=2.0ms QKV=2.10s FFN=3.05s) eta=1d 01:55:47 | 47.0K token/s | 
[epoch_0]_3991   loss=3.794612 |g|=0.412	lr=5.95e-04 | 26.9%@S4  T=1.65s(data=1.4ms QKV=2.11s FFN=3.04s) eta=1d 02:11:53 | 47.1K token/s | 
[Fuyou] head="3" update algorithm=4 t=12.24s
[eval] 
	 Loss@"edu_fineweb1B"=3.851(0.016) nBranch=1 nToken=6.31M best=3.8663(18) E2T=0.0862 T=36.7352(0)s x=0
	#3.85059±0.1010 tps=172K(6.30784M) a=[3.62467,4.1015] T=36.7352(sec)
[Section@4000] layer[32-40] tasks=19(nPassBack=0) last_loss=3.76442(0.140711) N=(772,5152,4592 527868)
[epoch_0]_4001   loss=3.741191 |g|=0.473	lr=5.95e-04 | 27.8%@S4  T=11.78s(data=1.7ms QKV=2.10s FFN=3.04s) eta=7d 18:41:14 | 45.1K token/s | 
[epoch_0]_4011   loss=3.765883 |g|=0.395	lr=5.95e-04 | 28.6%@S4  T=1.63s(data=1.6ms QKV=2.10s FFN=3.04s) eta=1d 01:49:05 | 45.4K token/s | 
[epoch_0]_4021   loss=3.700206 |g|=0.418	lr=5.95e-04 | 29.4%@S4  T=1.65s(data=1.5ms QKV=2.10s FFN=3.04s) eta=1d 02:03:14 | 45.6K token/s | 
[epoch_0]_4031   loss=3.791073 |g|=0.431	lr=5.95e-04 | 30.2%@S4  T=1.65s(data=1.7ms QKV=2.11s FFN=3.04s) eta=1d 02:07:46 | 45.8K token/s | 
[epoch_0]_4041   loss=3.732676 |g|=0.434	lr=5.95e-04 | 31.0%@S4  T=1.65s(data=1.7ms QKV=2.11s FFN=3.04s) eta=1d 02:03:44 | 46.0K token/s | 
[epoch_0]_4051   loss=3.752212 |g|=0.444	lr=5.95e-04 | 31.9%@S4  T=1.65s(data=1.5ms QKV=2.11s FFN=3.04s) eta=1d 02:03:51 | 46.2K token/s | 
[epoch_0]_4061   loss=3.662259 |g|=0.389	lr=5.95e-04 | 32.7%@S4  T=1.65s(data=1.5ms QKV=2.11s FFN=3.04s) eta=1d 02:05:47 | 46.4K token/s | 
[epoch_0]_4071   loss=3.741093 |g|=0.426	lr=5.95e-04 | 33.5%@S4  T=1.65s(data=1.7ms QKV=2.11s FFN=3.04s) eta=1d 02:04:33 | 46.5K token/s | 
[epoch_0]_4081   loss=3.614783 |g|=0.393	lr=5.95e-04 | 34.3%@S4  T=1.63s(data=1.6ms QKV=2.11s FFN=3.04s) eta=1d 01:47:41 | 46.7K token/s | 
[epoch_0]_4091   loss=3.641012 |g|=0.414	lr=5.95e-04 | 35.1%@S4  T=1.65s(data=1.6ms QKV=2.11s FFN=3.04s) eta=1d 02:03:35 | 46.9K token/s | 
[Fuyou] head="4" update algorithm=4 t=12.23s
[Section@4100] layer[40-48] tasks=19(nPassBack=0) last_loss=3.73893(0.092205) N=(772,5264,4704 541068)
[epoch_0]_4101   loss=3.713392 |g|=0.505	lr=5.95e-04 | 36.0%@S4  T=4.15s(data=1.8ms QKV=2.10s FFN=3.04s) eta=2d 17:36:07 | 45.5K token/s | 
[epoch_0]_4111   loss=3.752085 |g|=0.423	lr=5.95e-04 | 36.8%@S4  T=1.64s(data=1.6ms QKV=2.10s FFN=3.04s) eta=1d 01:57:55 | 45.7K token/s | 
[epoch_0]_4121   loss=3.683446 |g|=0.443	lr=5.95e-04 | 37.6%@S4  T=1.64s(data=1.8ms QKV=2.10s FFN=3.04s) eta=1d 01:57:04 | 45.9K token/s | 
[epoch_0]_4131   loss=3.697098 |g|=0.435	lr=5.95e-04 | 38.4%@S4  T=1.65s(data=1.7ms QKV=2.11s FFN=3.04s) eta=1d 02:00:50 | 46.1K token/s | 
[epoch_0]_4141   loss=3.745141 |g|=0.465	lr=5.95e-04 | 39.2%@S4  T=1.65s(data=1.5ms QKV=2.10s FFN=3.04s) eta=1d 02:08:12 | 46.3K token/s | 
[epoch_0]_4151   loss=3.698834 |g|=0.467	lr=5.95e-04 | 40.1%@S4  T=1.65s(data=1.7ms QKV=2.11s FFN=3.04s) eta=1d 02:03:17 | 46.5K token/s | 
[epoch_0]_4161   loss=3.779195 |g|=0.43	lr=5.95e-04 | 40.9%@S4  T=1.64s(data=1.9ms QKV=2.11s FFN=3.04s) eta=1d 01:53:51 | 46.6K token/s | 
[epoch_0]_4171   loss=3.677240 |g|=0.41	lr=5.95e-04 | 41.7%@S4  T=1.67s(data=1.7ms QKV=2.10s FFN=3.05s) eta=1d 02:19:20 | 46.8K token/s | 
[epoch_0]_4181   loss=3.731488 |g|=0.397	lr=5.95e-04 | 42.5%@S4  T=1.64s(data=1.8ms QKV=2.11s FFN=3.04s) eta=1d 01:56:36 | 46.9K token/s | 
[epoch_0]_4191   loss=3.733999 |g|=0.416	lr=5.95e-04 | 43.3%@S4  T=1.66s(data=2.0ms QKV=2.11s FFN=3.05s) eta=1d 02:09:47 | 47.0K token/s | 
[Fuyou] head="5" update algorithm=4 t=10.97s
[eval] 
	 Loss@"edu_fineweb1B"=3.830(0.02) nBranch=1 nToken=6.31M best=3.8506(19) E2T=0.0978 T=36.7444(0)s x=0
	#3.83037±0.1011 tps=172K(6.30784M) a=[3.60347,4.07853] T=36.7444(sec)
[Section@4200] layer[0-8] tasks=19(nPassBack=0) last_loss=3.73254(0.11362) N=(772,5376,4816 554268)
[epoch_0]_4201   loss=3.661685 |g|=0.547	lr=5.95e-04 | 44.1%@S4  T=12.12s(data=2.7ms QKV=2.10s FFN=3.04s) eta=7d 23:17:08 | 45.0K token/s | 
[epoch_0]_4211   loss=3.718203 |g|=0.375	lr=5.95e-04 | 45.0%@S4  T=1.65s(data=1.7ms QKV=2.10s FFN=3.04s) eta=1d 02:03:48 | 45.3K token/s | 
[epoch_0]_4221   loss=3.666757 |g|=0.406	lr=5.95e-04 | 45.8%@S4  T=1.65s(data=2.1ms QKV=2.10s FFN=3.04s) eta=1d 02:07:05 | 45.5K token/s | 
[epoch_0]_4231   loss=3.656865 |g|=0.461	lr=5.95e-04 | 46.6%@S4  T=1.65s(data=1.7ms QKV=2.11s FFN=3.05s) eta=1d 02:03:58 | 45.7K token/s | 
[epoch_0]_4241   loss=3.700160 |g|=0.438	lr=5.95e-04 | 47.4%@S4  T=1.65s(data=1.7ms QKV=2.11s FFN=3.05s) eta=1d 02:04:20 | 45.9K token/s | 
[epoch_0]_4251   loss=3.728279 |g|=0.402	lr=5.95e-04 | 48.2%@S4  T=1.66s(data=1.6ms QKV=2.11s FFN=3.05s) eta=1d 02:09:23 | 46.0K token/s | 
[epoch_0]_4261   loss=3.738408 |g|=0.384	lr=5.95e-04 | 49.1%@S4  T=1.65s(data=1.8ms QKV=2.11s FFN=3.05s) eta=1d 02:02:30 | 46.2K token/s | 
[epoch_0]_4271   loss=3.683475 |g|=0.418	lr=5.95e-04 | 49.9%@S4  T=1.65s(data=1.6ms QKV=2.11s FFN=3.05s) eta=1d 01:57:37 | 46.4K token/s | 
[epoch_0]_4281   loss=3.710181 |g|=0.45	lr=5.95e-04 | 50.7%@S4  T=1.63s(data=1.6ms QKV=2.11s FFN=3.05s) eta=1d 01:44:39 | 46.6K token/s | 
[epoch_0]_4291   loss=3.689122 |g|=0.404	lr=5.95e-04 | 51.5%@S4  T=1.67s(data=1.9ms QKV=2.11s FFN=3.05s) eta=1d 02:16:46 | 46.7K token/s | 
[Fuyou] head="0" update algorithm=4 t=10.95s
[Section@4300] layer[8-16] tasks=19(nPassBack=0) last_loss=3.71797(-0.00525737) N=(772,5488,4928 567468)
[epoch_0]_4301   loss=3.690719 |g|=0.438	lr=5.95e-04 | 52.3%@S4  T=4.27s(data=3.2ms QKV=2.10s FFN=3.04s) eta=2d 19:13:43 | 45.3K token/s | 
[epoch_0]_4311   loss=3.625339 |g|=0.46	lr=5.94e-04 | 53.2%@S4  T=1.63s(data=1.8ms QKV=2.10s FFN=3.04s) eta=1d 01:38:03 | 45.6K token/s | 
[epoch_0]_4321   loss=3.645933 |g|=0.459	lr=5.94e-04 | 54.0%@S4  T=1.65s(data=1.8ms QKV=2.10s FFN=3.04s) eta=1d 01:56:46 | 45.8K token/s | 
[epoch_0]_4331   loss=3.635872 |g|=0.429	lr=5.94e-04 | 54.8%@S4  T=1.65s(data=1.5ms QKV=2.10s FFN=3.04s) eta=1d 01:56:14 | 46.0K token/s | 
[epoch_0]_4341   loss=3.702233 |g|=0.44	lr=5.94e-04 | 55.6%@S4  T=1.64s(data=1.7ms QKV=2.11s FFN=3.05s) eta=1d 01:49:38 | 46.2K token/s | 
[epoch_0]_4351   loss=3.743257 |g|=0.444	lr=5.94e-04 | 56.4%@S4  T=1.66s(data=1.6ms QKV=2.11s FFN=3.05s) eta=1d 02:05:08 | 46.4K token/s | 
[epoch_0]_4361   loss=3.673051 |g|=0.435	lr=5.94e-04 | 57.3%@S4  T=1.63s(data=1.5ms QKV=2.11s FFN=3.05s) eta=1d 01:42:45 | 46.5K token/s | 
[epoch_0]_4371   loss=3.677455 |g|=0.418	lr=5.94e-04 | 58.1%@S4  T=1.66s(data=1.5ms QKV=2.11s FFN=3.05s) eta=1d 02:06:45 | 46.7K token/s | 
[epoch_0]_4381   loss=3.687798 |g|=0.515	lr=5.94e-04 | 58.9%@S4  T=1.65s(data=2.0ms QKV=2.11s FFN=3.05s) eta=1d 02:01:26 | 46.8K token/s | 
[epoch_0]_4391   loss=3.710865 |g|=0.428	lr=5.94e-04 | 59.7%@S4  T=1.64s(data=1.6ms QKV=2.11s FFN=3.05s) eta=1d 01:45:23 | 47.0K token/s | 
[Fuyou] head="1" update algorithm=4 t=9.44s
[eval] 
	 Loss@"edu_fineweb1B"=3.817(0.013) nBranch=1 nToken=6.31M best=3.8304(20) E2T=0.128 T=36.7888(0)s x=0
	#3.81712±0.1018 tps=171K(6.30784M) a=[3.59388,4.08162] T=36.7888(sec)
[Section@4400] layer[16-24] tasks=19(nPassBack=0) last_loss=3.68896(0.053067) N=(772,5600,5040 580668)
[epoch_0]_4401   loss=3.660184 |g|=0.467	lr=5.94e-04 | 60.5%@S4  T=12.08s(data=1.7ms QKV=2.10s FFN=3.04s) eta=7d 22:04:11 | 45.0K token/s | 
[epoch_0]_4411   loss=3.765388 |g|=0.455	lr=5.94e-04 | 61.4%@S4  T=1.65s(data=2.0ms QKV=2.10s FFN=3.05s) eta=1d 01:55:19 | 45.2K token/s | 
[epoch_0]_4421   loss=3.703771 |g|=0.405	lr=5.94e-04 | 62.2%@S4  T=1.63s(data=2.0ms QKV=2.10s FFN=3.05s) eta=1d 01:42:21 | 45.5K token/s | 
[epoch_0]_4431   loss=3.641897 |g|=0.421	lr=5.94e-04 | 63.0%@S4  T=1.64s(data=1.6ms QKV=2.10s FFN=3.05s) eta=1d 01:45:13 | 45.7K token/s | 
[epoch_0]_4441   loss=3.618046 |g|=0.406	lr=5.94e-04 | 63.8%@S4  T=1.63s(data=1.9ms QKV=2.10s FFN=3.05s) eta=1d 01:40:32 | 45.9K token/s | 
[epoch_0]_4451   loss=3.688803 |g|=0.363	lr=5.94e-04 | 64.6%@S4  T=1.66s(data=2.6ms QKV=2.10s FFN=3.05s) eta=1d 02:03:05 | 46.1K token/s | 
[epoch_0]_4461   loss=3.661441 |g|=0.45	lr=5.94e-04 | 65.4%@S4  T=1.66s(data=1.5ms QKV=2.10s FFN=3.05s) eta=1d 02:00:32 | 46.3K token/s | 
[epoch_0]_4471   loss=3.742916 |g|=0.42	lr=5.94e-04 | 66.3%@S4  T=1.65s(data=1.7ms QKV=2.10s FFN=3.05s) eta=1d 01:54:15 | 46.4K token/s | 
[epoch_0]_4481   loss=3.589576 |g|=0.43	lr=5.94e-04 | 67.1%@S4  T=1.66s(data=1.6ms QKV=2.10s FFN=3.05s) eta=1d 02:01:19 | 46.6K token/s | 
[epoch_0]_4491   loss=3.622594 |g|=0.442	lr=5.94e-04 | 67.9%@S4  T=1.65s(data=1.6ms QKV=2.10s FFN=3.05s) eta=1d 01:53:41 | 46.7K token/s | 
[Fuyou] head="2" update algorithm=4 t=8.79s
[Section@4500] layer[24-32] tasks=19(nPassBack=0) last_loss=3.63282(0.157115) N=(772,5712,5152 593868)
[epoch_0]_4501   loss=3.712261 |g|=0.512	lr=5.94e-04 | 68.7%@S4  T=4.33s(data=2.0ms QKV=2.10s FFN=3.04s) eta=2d 19:58:24 | 45.3K token/s | 
[epoch_0]_4511   loss=3.658027 |g|=0.407	lr=5.94e-04 | 69.5%@S4  T=1.67s(data=1.6ms QKV=2.10s FFN=3.04s) eta=1d 02:14:56 | 45.5K token/s | 
[epoch_0]_4521   loss=3.645683 |g|=0.515	lr=5.94e-04 | 70.4%@S4  T=1.66s(data=1.7ms QKV=2.10s FFN=3.05s) eta=1d 02:06:16 | 45.7K token/s | 
[epoch_0]_4531   loss=3.694160 |g|=0.423	lr=5.94e-04 | 71.2%@S4  T=1.65s(data=1.7ms QKV=2.10s FFN=3.05s) eta=1d 01:56:05 | 45.9K token/s | 
[epoch_0]_4541   loss=3.669015 |g|=0.453	lr=5.94e-04 | 72.0%@S4  T=1.66s(data=1.7ms QKV=2.10s FFN=3.05s) eta=1d 01:58:38 | 46.1K token/s | 
[epoch_0]_4551   loss=3.672751 |g|=0.398	lr=5.94e-04 | 72.8%@S4  T=1.66s(data=1.8ms QKV=2.10s FFN=3.05s) eta=1d 02:00:21 | 46.3K token/s | 
[epoch_0]_4561   loss=3.689796 |g|=0.418	lr=5.94e-04 | 73.6%@S4  T=1.65s(data=1.6ms QKV=2.10s FFN=3.05s) eta=1d 01:50:02 | 46.4K token/s | 
[epoch_0]_4571   loss=3.642817 |g|=0.419	lr=5.94e-04 | 74.5%@S4  T=1.65s(data=1.6ms QKV=2.10s FFN=3.05s) eta=1d 01:56:16 | 46.6K token/s | 
[epoch_0]_4581   loss=3.701065 |g|=0.452	lr=5.94e-04 | 75.3%@S4  T=1.64s(data=1.7ms QKV=2.11s FFN=3.05s) eta=1d 01:40:00 | 46.8K token/s | 
[epoch_0]_4591   loss=3.708758 |g|=0.464	lr=5.94e-04 | 76.1%@S4  T=1.64s(data=1.6ms QKV=2.11s FFN=3.05s) eta=1d 01:45:37 | 46.9K token/s | 
[Fuyou] head="3" update algorithm=4 t=10.05s
[eval] 
	 Loss@"edu_fineweb1B"=3.795(0.022) nBranch=1 nToken=6.31M best=3.8171(21) E2T=0.21 T=36.7598(0)s x=0
	#3.79475±0.1019 tps=172K(6.30784M) a=[3.57126,4.04907] T=36.7598(sec)
[Section@4600] layer[32-40] tasks=19(nPassBack=0) last_loss=3.58468(0.179738) N=(772,5824,5264 607068)
[epoch_0]_4601   loss=3.664701 |g|=0.469	lr=5.94e-04 | 76.9%@S4  T=11.72s(data=2.0ms QKV=2.10s FFN=3.04s) eta=7d 15:43:21 | 44.9K token/s | 
[epoch_0]_4611   loss=3.672326 |g|=0.46	lr=5.94e-04 | 77.7%@S4  T=1.65s(data=1.7ms QKV=2.10s FFN=3.05s) eta=1d 01:47:21 | 45.2K token/s | 
[epoch_0]_4621   loss=3.568817 |g|=0.394	lr=5.94e-04 | 78.6%@S4  T=1.65s(data=1.7ms QKV=2.10s FFN=3.05s) eta=1d 01:49:02 | 45.4K token/s | 
[epoch_0]_4631   loss=3.585506 |g|=0.397	lr=5.94e-04 | 79.4%@S4  T=1.65s(data=1.6ms QKV=2.10s FFN=3.05s) eta=1d 01:52:14 | 45.6K token/s | 
[epoch_0]_4641   loss=3.698414 |g|=0.448	lr=5.93e-04 | 80.2%@S4  T=1.66s(data=1.9ms QKV=2.10s FFN=3.05s) eta=1d 01:59:27 | 45.8K token/s | 
[epoch_0]_4651   loss=3.651080 |g|=0.428	lr=5.93e-04 | 81.0%@S4  T=1.66s(data=1.7ms QKV=2.10s FFN=3.05s) eta=1d 02:00:00 | 46.0K token/s | 
[epoch_0]_4661   loss=3.651330 |g|=0.423	lr=5.93e-04 | 81.8%@S4  T=1.65s(data=1.7ms QKV=2.10s FFN=3.05s) eta=1d 01:52:53 | 46.1K token/s | 
[epoch_0]_4671   loss=3.677859 |g|=0.471	lr=5.93e-04 | 82.7%@S4  T=1.65s(data=1.7ms QKV=2.10s FFN=3.05s) eta=1d 01:48:59 | 46.3K token/s | 
[epoch_0]_4681   loss=3.667975 |g|=0.416	lr=5.93e-04 | 83.5%@S4  T=1.66s(data=1.5ms QKV=2.10s FFN=3.05s) eta=1d 01:57:09 | 46.5K token/s | 
[epoch_0]_4691   loss=3.612480 |g|=0.486	lr=5.93e-04 | 84.3%@S4  T=1.65s(data=1.6ms QKV=2.10s FFN=3.05s) eta=1d 01:51:49 | 46.6K token/s | 
[Fuyou] head="4" update algorithm=4 t=12.31s
[Section@4700] layer[40-48] tasks=19(nPassBack=0) last_loss=3.68382(0.0551107) N=(772,5936,5376 620268)
[epoch_0]_4701   loss=3.672483 |g|=0.411	lr=5.93e-04 | 85.1%@S4  T=4.05s(data=1.5ms QKV=2.10s FFN=3.04s) eta=2d 15:20:33 | 45.3K token/s | 
[epoch_0]_4711   loss=3.567381 |g|=0.385	lr=5.93e-04 | 85.9%@S4  T=1.64s(data=1.6ms QKV=2.10s FFN=3.04s) eta=1d 01:40:47 | 45.5K token/s | 
[epoch_0]_4721   loss=3.620972 |g|=0.429	lr=5.93e-04 | 86.7%@S4  T=1.66s(data=1.6ms QKV=2.10s FFN=3.05s) eta=1d 01:59:07 | 45.7K token/s | 
[epoch_0]_4731   loss=3.694121 |g|=0.436	lr=5.93e-04 | 87.6%@S4  T=1.67s(data=1.6ms QKV=2.10s FFN=3.04s) eta=1d 02:05:07 | 45.9K token/s | 
[epoch_0]_4741   loss=3.645490 |g|=0.419	lr=5.93e-04 | 88.4%@S4  T=1.66s(data=1.7ms QKV=2.10s FFN=3.05s) eta=1d 01:56:58 | 46.1K token/s | 
[epoch_0]_4751   loss=3.651192 |g|=0.428	lr=5.93e-04 | 89.2%@S4  T=1.65s(data=1.7ms QKV=2.10s FFN=3.05s) eta=1d 01:51:16 | 46.2K token/s | 
[epoch_0]_4761   loss=3.572643 |g|=0.402	lr=5.93e-04 | 90.0%@S4  T=1.67s(data=1.5ms QKV=2.10s FFN=3.05s) eta=1d 02:05:23 | 46.4K token/s | 
[epoch_0]_4771   loss=3.637975 |g|=0.409	lr=5.93e-04 | 90.8%@S4  T=1.65s(data=1.7ms QKV=2.10s FFN=3.05s) eta=1d 01:47:44 | 46.6K token/s | 
[epoch_0]_4781   loss=3.586895 |g|=0.419	lr=5.93e-04 | 91.7%@S4  T=1.65s(data=1.6ms QKV=2.10s FFN=3.05s) eta=1d 01:49:56 | 46.7K token/s | 
[epoch_0]_4791   loss=3.661809 |g|=0.443	lr=5.93e-04 | 92.5%@S4  T=1.66s(data=1.7ms QKV=2.10s FFN=3.05s) eta=1d 01:51:34 | 46.8K token/s | 
[Fuyou] head="5" update algorithm=4 t=11.13s
[eval] 
	 Loss@"edu_fineweb1B"=3.780(0.015) nBranch=1 nToken=6.31M best=3.7948(22) E2T=0.13 T=36.7353(0)s x=0
	#3.78016±0.1023 tps=172K(6.30784M) a=[3.54623,4.03504] T=36.7353(sec)
[Section@4800] layer[0-8] tasks=19(nPassBack=0) last_loss=3.65061(0.0819294) N=(772,6048,5488 633468)
[epoch_0]_4801   loss=3.689236 |g|=0.408	lr=5.93e-04 | 93.3%@S4  T=11.75s(data=2.1ms QKV=2.10s FFN=3.04s) eta=7d 15:36:19 | 44.8K token/s | 
[epoch_0]_4811   loss=3.700556 |g|=0.401	lr=5.93e-04 | 94.1%@S4  T=1.63s(data=1.6ms QKV=2.10s FFN=3.05s) eta=1d 01:28:58 | 45.1K token/s | 
[epoch_0]_4821   loss=3.689429 |g|=0.413	lr=5.93e-04 | 94.9%@S4  T=1.66s(data=1.6ms QKV=2.10s FFN=3.05s) eta=1d 01:53:37 | 45.3K token/s | 
[epoch_0]_4831   loss=3.636838 |g|=0.456	lr=5.93e-04 | 95.8%@S4  T=1.65s(data=1.6ms QKV=2.11s FFN=3.04s) eta=1d 01:45:43 | 45.5K token/s | 
[epoch_0]_4841   loss=3.642992 |g|=0.448	lr=5.93e-04 | 96.6%@S4  T=1.65s(data=1.6ms QKV=2.10s FFN=3.05s) eta=1d 01:43:31 | 45.8K token/s | 
[epoch_0]_4851   loss=3.635834 |g|=0.409	lr=5.93e-04 | 97.4%@S4  T=1.65s(data=1.6ms QKV=2.11s FFN=3.05s) eta=1d 01:46:09 | 45.9K token/s | 
[epoch_0]_4861   loss=3.652597 |g|=0.469	lr=5.93e-04 | 98.2%@S4  T=1.65s(data=1.7ms QKV=2.10s FFN=3.05s) eta=1d 01:43:20 | 46.1K token/s | 
[epoch_0]_4871   loss=3.540549 |g|=0.433	lr=5.93e-04 | 99.0%@S4  T=1.66s(data=1.8ms QKV=2.11s FFN=3.05s) eta=1d 01:52:04 | 46.3K token/s | 
[epoch_0]_4881   loss=3.633538 |g|=0.398	lr=5.93e-04 | 99.9%@S4  T=1.66s(data=1.6ms QKV=2.11s FFN=3.05s) eta=1d 01:50:59 | 46.5K token/s | 
[epoch_0]_4882   loss=3.642769 |g|=0.404	lr=5.93e-04 | 99.9%@S4  T=1.66s(data=2.0ms QKV=2.11s FFN=3.05s) eta=1d 01:50:48 | 46.6K token/s | 
-------- End of shard_4@"./Datasets/edu_fineweb1B/edu_fineweb_train_000004.bin"-------- 
[shard-5]@"./Datasets/edu_fineweb1B/edu_fineweb_train_000005.bin": tokens=100(M) nShardSamples=1220(488280) 
[epoch_0]_4891   loss=3.703385 |g|=0.408	lr=5.93e-04 | 0.7%@S5  T=1.66s(data=1.4ms QKV=2.11s FFN=3.05s) eta=1d 01:49:12 | 46.7K token/s | 
[Fuyou] head="0" update algorithm=4 t=11.44s
[Section@4900] layer[8-16] tasks=19(nPassBack=0) last_loss=3.73203(-0.0140567) N=(772,6160,5600 646668)
[epoch_0]_4901   loss=3.767508 |g|=0.505	lr=5.93e-04 | 1.5%@S5  T=4.01s(data=2.8ms QKV=2.10s FFN=3.04s) eta=2d 14:31:03 | 45.4K token/s | 
[epoch_0]_4911   loss=3.734636 |g|=0.407	lr=5.93e-04 | 2.3%@S5  T=1.64s(data=1.6ms QKV=2.10s FFN=3.04s) eta=1d 01:30:56 | 45.7K token/s | 
[epoch_0]_4921   loss=3.869455 |g|=0.411	lr=5.93e-04 | 3.1%@S5  T=1.65s(data=1.4ms QKV=2.10s FFN=3.04s) eta=1d 01:47:46 | 45.9K token/s | 
[epoch_0]_4931   loss=3.798023 |g|=0.46	lr=5.93e-04 | 3.9%@S5  T=1.66s(data=1.5ms QKV=2.10s FFN=3.05s) eta=1d 01:53:50 | 46.0K token/s | 
[epoch_0]_4941   loss=3.745098 |g|=0.445	lr=5.92e-04 | 4.8%@S5  T=1.65s(data=1.9ms QKV=2.11s FFN=3.04s) eta=1d 01:40:14 | 46.2K token/s | 
[epoch_0]_4951   loss=3.802062 |g|=0.428	lr=5.92e-04 | 5.6%@S5  T=1.64s(data=1.7ms QKV=2.11s FFN=3.04s) eta=1d 01:36:11 | 46.4K token/s | 
[epoch_0]_4961   loss=3.752842 |g|=0.489	lr=5.92e-04 | 6.4%@S5  T=1.66s(data=1.7ms QKV=2.11s FFN=3.05s) eta=1d 01:47:16 | 46.5K token/s | 
[epoch_0]_4971   loss=3.745539 |g|=0.509	lr=5.92e-04 | 7.2%@S5  T=1.65s(data=1.6ms QKV=2.11s FFN=3.05s) eta=1d 01:46:20 | 46.7K token/s | 
[epoch_0]_4981   loss=3.753712 |g|=0.461	lr=5.92e-04 | 8.0%@S5  T=1.65s(data=1.8ms QKV=2.11s FFN=3.05s) eta=1d 01:41:27 | 46.8K token/s | 
[epoch_0]_4991   loss=3.758211 |g|=0.446	lr=5.92e-04 | 8.9%@S5  T=1.66s(data=1.6ms QKV=2.11s FFN=3.04s) eta=1d 01:49:20 | 47.0K token/s | 
[Fuyou] head="1" update algorithm=4 t=10.85s
[eval] 
	 Loss@"edu_fineweb1B"=3.739(0.041) nBranch=1 nToken=6.31M best=3.7802(23) E2T=-0.0579 T=36.7472(0)s x=0
	#3.73932±0.0995 tps=172K(6.30784M) a=[3.51897,3.99262] T=36.7472(sec)
[Section@5000] layer[16-24] tasks=19(nPassBack=0) last_loss=3.79718(-0.108222) N=(772,6272,5712 659868)
[epoch_0]_5001   loss=3.752718 |g|=0.498	lr=5.92e-04 | 9.7%@S5  T=12.11s(data=1.9ms QKV=2.10s FFN=3.04s) eta=7d 20:29:08 | 45.0K token/s | 
[epoch_0]_5011   loss=3.733146 |g|=0.459	lr=5.92e-04 | 10.5%@S5  T=1.65s(data=1.5ms QKV=2.10s FFN=3.04s) eta=1d 01:37:56 | 45.2K token/s | 
[epoch_0]_5021   loss=3.782757 |g|=0.445	lr=5.92e-04 | 11.3%@S5  T=1.65s(data=1.3ms QKV=2.10s FFN=3.04s) eta=1d 01:38:21 | 45.4K token/s | 
[epoch_0]_5031   loss=3.733372 |g|=0.443	lr=5.92e-04 | 12.1%@S5  T=1.65s(data=1.6ms QKV=2.10s FFN=3.04s) eta=1d 01:38:44 | 45.6K token/s | 
[epoch_0]_5041   loss=3.732701 |g|=0.435	lr=5.92e-04 | 13.0%@S5  T=1.66s(data=2.1ms QKV=2.10s FFN=3.04s) eta=1d 01:50:18 | 45.8K token/s | 
[epoch_0]_5051   loss=3.736704 |g|=0.406	lr=5.92e-04 | 13.8%@S5  T=1.66s(data=1.6ms QKV=2.10s FFN=3.04s) eta=1d 01:45:02 | 46.0K token/s | 
[epoch_0]_5061   loss=3.802445 |g|=0.428	lr=5.92e-04 | 14.6%@S5  T=1.65s(data=1.6ms QKV=2.10s FFN=3.05s) eta=1d 01:39:58 | 46.2K token/s | 
[epoch_0]_5071   loss=3.733429 |g|=0.424	lr=5.92e-04 | 15.4%@S5  T=1.66s(data=1.6ms QKV=2.10s FFN=3.04s) eta=1d 01:50:09 | 46.3K token/s | 
[epoch_0]_5081   loss=3.775230 |g|=0.45	lr=5.92e-04 | 16.2%@S5  T=1.65s(data=1.7ms QKV=2.10s FFN=3.05s) eta=1d 01:39:56 | 46.5K token/s | 
[epoch_0]_5091   loss=3.720882 |g|=0.455	lr=5.92e-04 | 17.1%@S5  T=1.66s(data=1.6ms QKV=2.10s FFN=3.04s) eta=1d 01:51:39 | 46.6K token/s | 
[Fuyou] head="2" update algorithm=4 t=10.79s
[Section@5100] layer[24-32] tasks=19(nPassBack=0) last_loss=3.731(-0.0981777) N=(772,6384,5824 673068)
[epoch_0]_5101   loss=3.698231 |g|=0.446	lr=5.92e-04 | 17.9%@S5  T=4.14s(data=1.7ms QKV=2.10s FFN=3.04s) eta=2d 16:23:38 | 45.3K token/s | 
[epoch_0]_5111   loss=3.810006 |g|=0.44	lr=5.92e-04 | 18.7%@S5  T=1.62s(data=1.4ms QKV=2.10s FFN=3.04s) eta=1d 01:09:41 | 45.6K token/s | 
[epoch_0]_5121   loss=3.765485 |g|=0.517	lr=5.92e-04 | 19.5%@S5  T=1.63s(data=1.6ms QKV=2.10s FFN=3.04s) eta=1d 01:17:57 | 45.8K token/s | 
[epoch_0]_5131   loss=3.749527 |g|=0.434	lr=5.92e-04 | 20.3%@S5  T=1.66s(data=1.6ms QKV=2.10s FFN=3.04s) eta=1d 01:45:43 | 46.0K token/s | 
[epoch_0]_5141   loss=3.742881 |g|=0.46	lr=5.92e-04 | 21.2%@S5  T=1.66s(data=1.7ms QKV=2.10s FFN=3.04s) eta=1d 01:50:05 | 46.1K token/s | 
[epoch_0]_5151   loss=3.767266 |g|=0.412	lr=5.92e-04 | 22.0%@S5  T=1.66s(data=1.8ms QKV=2.10s FFN=3.04s) eta=1d 01:44:18 | 46.3K token/s | 
[epoch_0]_5161   loss=3.738443 |g|=0.411	lr=5.92e-04 | 22.8%@S5  T=1.65s(data=1.7ms QKV=2.10s FFN=3.04s) eta=1d 01:39:23 | 46.5K token/s | 
[epoch_0]_5171   loss=3.799773 |g|=0.387	lr=5.92e-04 | 23.6%@S5  T=1.65s(data=1.8ms QKV=2.10s FFN=3.04s) eta=1d 01:35:35 | 46.6K token/s | 
[epoch_0]_5181   loss=3.686967 |g|=0.406	lr=5.92e-04 | 24.4%@S5  T=1.66s(data=1.6ms QKV=2.10s FFN=3.04s) eta=1d 01:44:04 | 46.8K token/s | 
[epoch_0]_5191   loss=3.745857 |g|=0.466	lr=5.92e-04 | 25.2%@S5  T=1.66s(data=1.5ms QKV=2.10s FFN=3.04s) eta=1d 01:47:58 | 46.9K token/s | 
[Fuyou] head="3" update algorithm=4 t=11.40s
[eval] 
	 Loss@"edu_fineweb1B"=3.721(0.019) nBranch=1 nToken=6.31M best=3.7393(24) E2T=-0.00562 T=36.7413(0)s x=0
	#3.72069±0.0980 tps=172K(6.30784M) a=[3.49728,3.96999] T=36.7413(sec)
[Section@5200] layer[32-40] tasks=19(nPassBack=0) last_loss=3.72631(-0.141628) N=(772,6496,5936 686268)
[epoch_0]_5201   loss=3.721566 |g|=0.488	lr=5.92e-04 | 26.1%@S5  T=11.76s(data=1.7ms QKV=2.10s FFN=3.04s) eta=7d 14:23:05 | 44.9K token/s | 
[epoch_0]_5211   loss=3.784857 |g|=0.458	lr=5.92e-04 | 26.9%@S5  T=1.63s(data=1.4ms QKV=2.10s FFN=3.04s) eta=1d 01:15:34 | 45.2K token/s | 
[epoch_0]_5221   loss=3.710930 |g|=0.45	lr=5.91e-04 | 27.7%@S5  T=1.67s(data=1.6ms QKV=2.10s FFN=3.05s) eta=1d 01:55:36 | 45.4K token/s | 
[epoch_0]_5231   loss=3.755560 |g|=0.461	lr=5.91e-04 | 28.5%@S5  T=1.66s(data=1.9ms QKV=2.10s FFN=3.05s) eta=1d 01:40:09 | 45.6K token/s | 
[epoch_0]_5241   loss=3.767745 |g|=0.432	lr=5.91e-04 | 29.3%@S5  T=1.65s(data=1.4ms QKV=2.10s FFN=3.05s) eta=1d 01:33:07 | 45.8K token/s | 
[epoch_0]_5251   loss=3.746580 |g|=0.439	lr=5.91e-04 | 30.2%@S5  T=1.66s(data=1.8ms QKV=2.10s FFN=3.05s) eta=1d 01:41:08 | 45.9K token/s | 
[epoch_0]_5261   loss=3.704124 |g|=0.39	lr=5.91e-04 | 31.0%@S5  T=1.67s(data=1.8ms QKV=2.10s FFN=3.05s) eta=1d 01:48:47 | 46.1K token/s | 
[epoch_0]_5271   loss=3.677956 |g|=0.438	lr=5.91e-04 | 31.8%@S5  T=1.65s(data=1.5ms QKV=2.10s FFN=3.05s) eta=1d 01:35:59 | 46.3K token/s | 
[epoch_0]_5281   loss=3.751504 |g|=0.453	lr=5.91e-04 | 32.6%@S5  T=1.67s(data=1.4ms QKV=2.10s FFN=3.05s) eta=1d 01:53:43 | 46.4K token/s | 
[epoch_0]_5291   loss=3.713349 |g|=0.392	lr=5.91e-04 | 33.4%@S5  T=1.66s(data=1.5ms QKV=2.10s FFN=3.05s) eta=1d 01:42:39 | 46.6K token/s | 
[Fuyou] head="4" update algorithm=4 t=12.17s
[Section@5300] layer[40-48] tasks=19(nPassBack=0) last_loss=3.76197(-0.0781589) N=(772,6608,6048 699468)
[epoch_0]_5301   loss=3.701612 |g|=0.4	lr=5.91e-04 | 34.3%@S5  T=4.10s(data=1.6ms QKV=2.10s FFN=3.04s) eta=2d 15:30:26 | 45.2K token/s | 
[epoch_0]_5311   loss=3.776819 |g|=0.423	lr=5.91e-04 | 35.1%@S5  T=1.63s(data=1.8ms QKV=2.10s FFN=3.04s) eta=1d 01:16:15 | 45.5K token/s | 
[epoch_0]_5321   loss=3.742295 |g|=0.475	lr=5.91e-04 | 35.9%@S5  T=1.64s(data=1.5ms QKV=2.10s FFN=3.04s) eta=1d 01:27:10 | 45.7K token/s | 
[epoch_0]_5331   loss=3.749293 |g|=0.433	lr=5.91e-04 | 36.7%@S5  T=1.64s(data=1.7ms QKV=2.10s FFN=3.05s) eta=1d 01:20:08 | 45.9K token/s | 
[epoch_0]_5341   loss=3.711322 |g|=0.472	lr=5.91e-04 | 37.5%@S5  T=1.67s(data=1.8ms QKV=2.10s FFN=3.05s) eta=1d 01:49:53 | 46.1K token/s | 
[epoch_0]_5351   loss=3.762874 |g|=0.473	lr=5.91e-04 | 38.4%@S5  T=1.66s(data=1.9ms QKV=2.10s FFN=3.04s) eta=1d 01:36:00 | 46.2K token/s | 
[epoch_0]_5361   loss=3.734367 |g|=0.457	lr=5.91e-04 | 39.2%@S5  T=1.66s(data=1.7ms QKV=2.10s FFN=3.05s) eta=1d 01:38:42 | 46.4K token/s | 
[epoch_0]_5371   loss=3.710668 |g|=0.47	lr=5.91e-04 | 40.0%@S5  T=1.66s(data=1.6ms QKV=2.10s FFN=3.05s) eta=1d 01:41:33 | 46.5K token/s | 
[epoch_0]_5381   loss=3.654197 |g|=0.412	lr=5.91e-04 | 40.8%@S5  T=1.67s(data=1.6ms QKV=2.10s FFN=3.05s) eta=1d 01:47:13 | 46.7K token/s | 
[epoch_0]_5391   loss=3.720028 |g|=0.402	lr=5.91e-04 | 41.6%@S5  T=1.67s(data=1.9ms QKV=2.10s FFN=3.05s) eta=1d 01:44:28 | 46.8K token/s | 
[Fuyou] head="5" update algorithm=4 t=11.97s
[eval] 
	 Loss@"edu_fineweb1B"=3.701(0.02) nBranch=1 nToken=6.31M best=3.7207(25) E2T=-0.0301 T=36.7476(0)s x=0
	#3.701±0.0981 tps=172K(6.30784M) a=[3.48491,3.95068] T=36.7476(sec)
[Section@5400] layer[0-8] tasks=19(nPassBack=0) last_loss=3.73111(-0.0805013) N=(772,6720,6160 712668)
[epoch_0]_5401   loss=3.689049 |g|=0.499	lr=5.91e-04 | 42.5%@S5  T=11.97s(data=1.7ms QKV=2.10s FFN=3.04s) eta=7d 16:56:24 | 44.8K token/s | 
[epoch_0]_5411   loss=3.755333 |g|=0.432	lr=5.91e-04 | 43.3%@S5  T=1.63s(data=1.8ms QKV=2.10s FFN=3.05s) eta=1d 01:10:33 | 45.1K token/s | 
[epoch_0]_5421   loss=3.767988 |g|=0.442	lr=5.91e-04 | 44.1%@S5  T=1.63s(data=1.7ms QKV=2.10s FFN=3.05s) eta=1d 01:10:52 | 45.3K token/s | 
[epoch_0]_5431   loss=3.763683 |g|=0.445	lr=5.91e-04 | 44.9%@S5  T=1.64s(data=1.7ms QKV=2.10s FFN=3.04s) eta=1d 01:17:27 | 45.6K token/s | 
[epoch_0]_5441   loss=3.695905 |g|=0.464	lr=5.91e-04 | 45.7%@S5  T=1.64s(data=1.8ms QKV=2.10s FFN=3.05s) eta=1d 01:23:25 | 45.8K token/s | 
[epoch_0]_5451   loss=3.594664 |g|=0.447	lr=5.91e-04 | 46.5%@S5  T=1.66s(data=1.7ms QKV=2.10s FFN=3.04s) eta=1d 01:41:38 | 46.0K token/s | 
[epoch_0]_5461   loss=3.665666 |g|=0.403	lr=5.91e-04 | 47.4%@S5  T=1.66s(data=1.6ms QKV=2.10s FFN=3.05s) eta=1d 01:41:54 | 46.1K token/s | 
[epoch_0]_5471   loss=3.705809 |g|=0.42	lr=5.91e-04 | 48.2%@S5  T=1.66s(data=1.5ms QKV=2.10s FFN=3.04s) eta=1d 01:39:20 | 46.3K token/s | 
[epoch_0]_5481   loss=3.726248 |g|=0.479	lr=5.90e-04 | 49.0%@S5  T=1.66s(data=1.6ms QKV=2.10s FFN=3.05s) eta=1d 01:39:18 | 46.4K token/s | 
[epoch_0]_5491   loss=3.664832 |g|=0.403	lr=5.90e-04 | 49.8%@S5  T=1.66s(data=1.5ms QKV=2.10s FFN=3.05s) eta=1d 01:34:59 | 46.6K token/s | 
[Fuyou] head="0" update algorithm=4 t=12.04s
[Section@5500] layer[8-16] tasks=19(nPassBack=0) last_loss=3.64528(0.0867538) N=(772,6832,6272 725868)
[epoch_0]_5501   loss=3.709766 |g|=0.481	lr=5.90e-04 | 50.6%@S5  T=4.15s(data=2.0ms QKV=2.10s FFN=3.04s) eta=2d 16:01:52 | 45.2K token/s | 
[epoch_0]_5511   loss=3.711382 |g|=0.498	lr=5.90e-04 | 51.5%@S5  T=1.65s(data=1.7ms QKV=2.10s FFN=3.04s) eta=1d 01:26:33 | 45.5K token/s | 
[epoch_0]_5521   loss=3.682873 |g|=0.424	lr=5.90e-04 | 52.3%@S5  T=1.65s(data=2.0ms QKV=2.10s FFN=3.04s) eta=1d 01:23:00 | 45.7K token/s | 
[epoch_0]_5531   loss=3.714109 |g|=0.397	lr=5.90e-04 | 53.1%@S5  T=1.66s(data=1.6ms QKV=2.10s FFN=3.04s) eta=1d 01:33:30 | 45.9K token/s | 
[epoch_0]_5541   loss=3.674841 |g|=0.421	lr=5.90e-04 | 53.9%@S5  T=1.66s(data=1.7ms QKV=2.10s FFN=3.04s) eta=1d 01:30:56 | 46.0K token/s | 
[epoch_0]_5551   loss=3.681479 |g|=0.42	lr=5.90e-04 | 54.7%@S5  T=1.67s(data=1.5ms QKV=2.10s FFN=3.05s) eta=1d 01:48:39 | 46.2K token/s | 
[epoch_0]_5561   loss=3.707484 |g|=0.452	lr=5.90e-04 | 55.6%@S5  T=1.66s(data=1.5ms QKV=2.10s FFN=3.05s) eta=1d 01:39:09 | 46.3K token/s | 
[epoch_0]_5571   loss=3.695427 |g|=0.394	lr=5.90e-04 | 56.4%@S5  T=1.66s(data=1.7ms QKV=2.10s FFN=3.04s) eta=1d 01:33:40 | 46.5K token/s | 
[epoch_0]_5581   loss=3.697092 |g|=0.403	lr=5.90e-04 | 57.2%@S5  T=1.67s(data=1.6ms QKV=2.10s FFN=3.04s) eta=1d 01:41:30 | 46.6K token/s | 
[epoch_0]_5591   loss=3.682515 |g|=0.419	lr=5.90e-04 | 58.0%@S5  T=1.66s(data=1.6ms QKV=2.10s FFN=3.04s) eta=1d 01:30:54 | 46.8K token/s | 
[Fuyou] head="1" update algorithm=4 t=12.32s
[eval] 
	 Loss@"edu_fineweb1B"=3.686(0.015) nBranch=1 nToken=6.31M best=3.7010(26) E2T=0.0132 T=36.7119(0)s x=0
	#3.68636±0.0986 tps=172K(6.30784M) a=[3.46926,3.93979] T=36.7119(sec)
[Section@5600] layer[16-24] tasks=19(nPassBack=0) last_loss=3.67315(0.124034) N=(772,6944,6384 739068)
[epoch_0]_5601   loss=3.681120 |g|=0.521	lr=5.90e-04 | 58.8%@S5  T=12.16s(data=1.6ms QKV=2.10s FFN=3.04s) eta=7d 19:15:58 | 44.8K token/s | 
[epoch_0]_5611   loss=3.610514 |g|=0.477	lr=5.90e-04 | 59.7%@S5  T=1.65s(data=1.9ms QKV=2.10s FFN=3.04s) eta=1d 01:27:35 | 45.0K token/s | 
[epoch_0]_5621   loss=3.663677 |g|=0.45	lr=5.90e-04 | 60.5%@S5  T=1.66s(data=1.6ms QKV=2.10s FFN=3.04s) eta=1d 01:30:49 | 45.2K token/s | 
[epoch_0]_5631   loss=3.692528 |g|=0.422	lr=5.90e-04 | 61.3%@S5  T=1.63s(data=1.8ms QKV=2.10s FFN=3.05s) eta=1d 01:05:33 | 45.5K token/s | 
[epoch_0]_5641   loss=3.639468 |g|=0.393	lr=5.90e-04 | 62.1%@S5  T=1.65s(data=1.9ms QKV=2.10s FFN=3.04s) eta=1d 01:26:32 | 45.7K token/s | 
[epoch_0]_5651   loss=3.706444 |g|=0.41	lr=5.90e-04 | 62.9%@S5  T=1.63s(data=1.7ms QKV=2.10s FFN=3.04s) eta=1d 01:05:30 | 45.9K token/s | 
[epoch_0]_5661   loss=3.669278 |g|=0.447	lr=5.90e-04 | 63.8%@S5  T=1.63s(data=1.9ms QKV=2.10s FFN=3.05s) eta=1d 01:06:35 | 46.1K token/s | 
[epoch_0]_5671   loss=3.726925 |g|=0.408	lr=5.90e-04 | 64.6%@S5  T=1.64s(data=1.6ms QKV=2.10s FFN=3.05s) eta=1d 01:15:30 | 46.3K token/s | 
[epoch_0]_5681   loss=3.737446 |g|=0.408	lr=5.90e-04 | 65.4%@S5  T=1.63s(data=1.7ms QKV=2.10s FFN=3.04s) eta=1d 01:06:51 | 46.5K token/s | 
[epoch_0]_5691   loss=3.674283 |g|=0.419	lr=5.90e-04 | 66.2%@S5  T=1.63s(data=2.0ms QKV=2.10s FFN=3.04s) eta=1d 01:06:16 | 46.7K token/s | 
[Fuyou] head="2" update algorithm=4 t=12.76s
[Section@5700] layer[24-32] tasks=19(nPassBack=0) last_loss=3.67354(0.0574543) N=(772,7056,6496 752268)
[epoch_0]_5701   loss=3.689000 |g|=0.451	lr=5.90e-04 | 67.0%@S5  T=4.13s(data=1.9ms QKV=2.10s FFN=3.04s) eta=2d 15:30:48 | 45.3K token/s | 
[epoch_0]_5711   loss=3.703953 |g|=0.437	lr=5.90e-04 | 67.8%@S5  T=1.65s(data=1.8ms QKV=2.10s FFN=3.04s) eta=1d 01:24:23 | 45.5K token/s | 
[epoch_0]_5721   loss=3.559980 |g|=0.396	lr=5.90e-04 | 68.7%@S5  T=1.65s(data=1.7ms QKV=2.10s FFN=3.04s) eta=1d 01:18:29 | 45.8K token/s | 
[epoch_0]_5731   loss=3.635840 |g|=0.382	lr=5.89e-04 | 69.5%@S5  T=1.64s(data=1.8ms QKV=2.10s FFN=3.04s) eta=1d 01:10:32 | 46.0K token/s | 
[epoch_0]_5741   loss=3.644517 |g|=0.413	lr=5.89e-04 | 70.3%@S5  T=1.66s(data=1.8ms QKV=2.10s FFN=3.04s) eta=1d 01:32:34 | 46.1K token/s | 
[epoch_0]_5751   loss=3.692062 |g|=0.443	lr=5.89e-04 | 71.1%@S5  T=1.67s(data=1.7ms QKV=2.10s FFN=3.04s) eta=1d 01:40:29 | 46.3K token/s | 
[epoch_0]_5761   loss=3.641860 |g|=0.431	lr=5.89e-04 | 71.9%@S5  T=1.66s(data=1.7ms QKV=2.10s FFN=3.04s) eta=1d 01:28:31 | 46.4K token/s | 
[epoch_0]_5771   loss=3.676254 |g|=0.441	lr=5.89e-04 | 72.8%@S5  T=1.67s(data=1.7ms QKV=2.10s FFN=3.04s) eta=1d 01:34:53 | 46.6K token/s | 
[epoch_0]_5781   loss=3.681257 |g|=0.435	lr=5.89e-04 | 73.6%@S5  T=1.65s(data=1.8ms QKV=2.10s FFN=3.04s) eta=1d 01:19:53 | 46.7K token/s | 
[epoch_0]_5791   loss=3.652864 |g|=0.428	lr=5.89e-04 | 74.4%@S5  T=1.65s(data=1.6ms QKV=2.10s FFN=3.04s) eta=1d 01:16:08 | 46.9K token/s | 
[Fuyou] head="3" update algorithm=4 t=12.44s
[eval] 
	 Loss@"edu_fineweb1B"=3.667(0.019) nBranch=1 nToken=6.31M best=3.6864(27) E2T=-0.0143 T=36.7216(0)s x=0
	#3.66721±0.0971 tps=172K(6.30784M) a=[3.45573,3.92183] T=36.7216(sec)
[Section@5800] layer[32-40] tasks=19(nPassBack=0) last_loss=3.68152(0.044791) N=(772,7168,6608 765468)
[epoch_0]_5801   loss=3.759789 |g|=0.414	lr=5.89e-04 | 75.2%@S5  T=11.94s(data=1.9ms QKV=2.10s FFN=3.04s) eta=7d 15:11:36 | 44.9K token/s | 
[epoch_0]_5811   loss=3.650217 |g|=0.421	lr=5.89e-04 | 76.0%@S5  T=1.66s(data=1.7ms QKV=2.10s FFN=3.04s) eta=1d 01:25:41 | 45.1K token/s | 
[epoch_0]_5821   loss=3.717306 |g|=0.483	lr=5.89e-04 | 76.9%@S5  T=1.65s(data=1.6ms QKV=2.10s FFN=3.04s) eta=1d 01:20:41 | 45.3K token/s | 
[epoch_0]_5831   loss=3.560750 |g|=0.435	lr=5.89e-04 | 77.7%@S5  T=1.65s(data=1.6ms QKV=2.10s FFN=3.04s) eta=1d 01:17:08 | 45.5K token/s | 
[epoch_0]_5841   loss=3.664883 |g|=0.381	lr=5.89e-04 | 78.5%@S5  T=1.66s(data=1.6ms QKV=2.10s FFN=3.04s) eta=1d 01:24:59 | 45.7K token/s | 
[epoch_0]_5851   loss=3.653268 |g|=0.403	lr=5.89e-04 | 79.3%@S5  T=1.66s(data=1.8ms QKV=2.10s FFN=3.04s) eta=1d 01:25:58 | 45.9K token/s | 
[epoch_0]_5861   loss=3.675989 |g|=0.437	lr=5.89e-04 | 80.1%@S5  T=1.67s(data=1.8ms QKV=2.10s FFN=3.04s) eta=1d 01:32:47 | 46.1K token/s | 
[epoch_0]_5871   loss=3.583858 |g|=0.406	lr=5.89e-04 | 81.0%@S5  T=1.66s(data=1.7ms QKV=2.10s FFN=3.04s) eta=1d 01:29:13 | 46.2K token/s | 
[epoch_0]_5881   loss=3.683136 |g|=0.383	lr=5.89e-04 | 81.8%@S5  T=1.66s(data=1.6ms QKV=2.10s FFN=3.04s) eta=1d 01:30:27 | 46.4K token/s | 
[epoch_0]_5891   loss=3.663047 |g|=0.394	lr=5.89e-04 | 82.6%@S5  T=1.67s(data=1.6ms QKV=2.10s FFN=3.04s) eta=1d 01:32:15 | 46.5K token/s | 
[Fuyou] head="4" update algorithm=4 t=12.22s
[Section@5900] layer[40-48] tasks=19(nPassBack=0) last_loss=3.74031(0.0216601) N=(772,7280,6720 778668)
[epoch_0]_5901   loss=3.626273 |g|=0.458	lr=5.89e-04 | 83.4%@S5  T=4.47s(data=3.5ms QKV=2.10s FFN=3.04s) eta=2d 20:24:00 | 45.1K token/s | 
[epoch_0]_5911   loss=3.699662 |g|=0.417	lr=5.89e-04 | 84.2%@S5  T=1.66s(data=1.6ms QKV=2.10s FFN=3.04s) eta=1d 01:23:45 | 45.3K token/s | 
[epoch_0]_5921   loss=3.657105 |g|=0.457	lr=5.89e-04 | 85.1%@S5  T=1.66s(data=2.0ms QKV=2.10s FFN=3.04s) eta=1d 01:22:34 | 45.5K token/s | 
[epoch_0]_5931   loss=3.688112 |g|=0.398	lr=5.89e-04 | 85.9%@S5  T=1.66s(data=1.7ms QKV=2.10s FFN=3.04s) eta=1d 01:23:55 | 45.7K token/s | 
[epoch_0]_5941   loss=3.670794 |g|=0.411	lr=5.89e-04 | 86.7%@S5  T=1.66s(data=1.7ms QKV=2.10s FFN=3.04s) eta=1d 01:24:52 | 45.9K token/s | 
[epoch_0]_5951   loss=3.614311 |g|=0.416	lr=5.89e-04 | 87.5%@S5  T=1.64s(data=1.6ms QKV=2.10s FFN=3.04s) eta=1d 01:08:56 | 46.1K token/s | 
[epoch_0]_5961   loss=3.678229 |g|=0.43	lr=5.89e-04 | 88.3%@S5  T=1.66s(data=1.7ms QKV=2.10s FFN=3.04s) eta=1d 01:24:54 | 46.3K token/s | 
[epoch_0]_5971   loss=3.698196 |g|=0.435	lr=5.88e-04 | 89.1%@S5  T=1.66s(data=1.5ms QKV=2.10s FFN=3.04s) eta=1d 01:25:43 | 46.4K token/s | 
[epoch_0]_5981   loss=3.613939 |g|=0.449	lr=5.88e-04 | 90.0%@S5  T=1.67s(data=1.5ms QKV=2.10s FFN=3.04s) eta=1d 01:29:16 | 46.5K token/s | 
[epoch_0]_5991   loss=3.660078 |g|=0.433	lr=5.88e-04 | 90.8%@S5  T=1.66s(data=1.5ms QKV=2.10s FFN=3.04s) eta=1d 01:22:35 | 46.7K token/s | 
[Fuyou] head="5" update algorithm=4 t=12.82s
[eval] 
	 Loss@"edu_fineweb1B"=3.658(0.0096) nBranch=1 nToken=6.31M best=3.6672(28) E2T=0.0729 T=36.7299(0)s x=0
	#3.65758±0.0976 tps=172K(6.30784M) a=[3.44957,3.91013] T=36.7299(sec)
[Section@6000] layer[0-8] tasks=19(nPassBack=0) last_loss=3.58471(0.146405) N=(772,7392,6832 791868)
[epoch_0]_6001   loss=3.658056 |g|=0.423	lr=5.88e-04 | 91.6%@S5  T=12.41s(data=3.9ms QKV=2.10s FFN=3.04s) eta=7d 21:44:42 | 44.7K token/s | 
[epoch_0]_6011   loss=3.675951 |g|=0.411	lr=5.88e-04 | 92.4%@S5  T=1.64s(data=1.6ms QKV=2.10s FFN=3.04s) eta=1d 01:02:35 | 45.0K token/s | 
[epoch_0]_6021   loss=3.662175 |g|=0.412	lr=5.88e-04 | 93.2%@S5  T=1.65s(data=1.8ms QKV=2.10s FFN=3.04s) eta=1d 01:16:04 | 45.2K token/s | 
[epoch_0]_6031   loss=3.642453 |g|=0.416	lr=5.88e-04 | 94.1%@S5  T=1.66s(data=1.6ms QKV=2.10s FFN=3.04s) eta=1d 01:19:11 | 45.4K token/s | 
[epoch_0]_6041   loss=3.639992 |g|=0.405	lr=5.88e-04 | 94.9%@S5  T=1.66s(data=1.5ms QKV=2.10s FFN=3.04s) eta=1d 01:23:32 | 45.6K token/s | 
[epoch_0]_6051   loss=3.703570 |g|=0.391	lr=5.88e-04 | 95.7%@S5  T=1.66s(data=1.5ms QKV=2.10s FFN=3.04s) eta=1d 01:19:56 | 45.8K token/s | 
[epoch_0]_6061   loss=3.702032 |g|=0.481	lr=5.88e-04 | 96.5%@S5  T=1.67s(data=2.0ms QKV=2.10s FFN=3.04s) eta=1d 01:30:23 | 45.9K token/s | 
[epoch_0]_6071   loss=3.668246 |g|=0.394	lr=5.88e-04 | 97.3%@S5  T=1.67s(data=1.9ms QKV=2.10s FFN=3.04s) eta=1d 01:33:32 | 46.1K token/s | 
[epoch_0]_6081   loss=3.614637 |g|=0.398	lr=5.88e-04 | 98.2%@S5  T=1.68s(data=1.9ms QKV=2.10s FFN=3.04s) eta=1d 01:35:11 | 46.2K token/s | 
[epoch_0]_6091   loss=3.681026 |g|=0.454	lr=5.88e-04 | 99.0%@S5  T=1.65s(data=1.6ms QKV=2.10s FFN=3.04s) eta=1d 01:10:16 | 46.4K token/s | 
[Fuyou] head="0" update algorithm=4 t=12.87s
[Section@6100] layer[8-16] tasks=19(nPassBack=0) last_loss=3.63139(0.0138905) N=(772,7504,6944 805068)
[epoch_0]_6101   loss=3.636359 |g|=0.426	lr=5.88e-04 | 99.8%@S5  T=4.43s(data=1.6ms QKV=2.10s FFN=3.03s) eta=2d 19:40:15 | 45.0K token/s | 
[epoch_0]_6103   loss=3.719512 |g|=0.411	lr=5.88e-04 | 100.0%@S5  T=1.91s(data=1.6ms QKV=2.10s FFN=3.04s) eta=1d 05:08:42 | 44.9K token/s | 
-------- End of shard_5@"./Datasets/edu_fineweb1B/edu_fineweb_train_000005.bin"-------- 
[shard-6]@"./Datasets/edu_fineweb1B/edu_fineweb_train_000006.bin": tokens=100(M) nShardSamples=1220(585936) 
[epoch_0]_6111   loss=3.653028 |g|=0.412	lr=5.88e-04 | 0.6%@S6  T=1.63s(data=1.2ms QKV=2.10s FFN=3.04s) eta=1d 00:53:23 | 45.2K token/s | 
[epoch_0]_6121   loss=3.668560 |g|=0.472	lr=5.88e-04 | 1.4%@S6  T=1.65s(data=1.2ms QKV=2.10s FFN=3.04s) eta=1d 01:11:50 | 45.4K token/s | 
[epoch_0]_6131   loss=3.679852 |g|=0.415	lr=5.88e-04 | 2.3%@S6  T=1.66s(data=1.2ms QKV=2.10s FFN=3.04s) eta=1d 01:21:48 | 45.6K token/s | 
[epoch_0]_6141   loss=3.674180 |g|=0.405	lr=5.88e-04 | 3.1%@S6  T=1.66s(data=1.3ms QKV=2.10s FFN=3.04s) eta=1d 01:14:36 | 45.8K token/s | 
[epoch_0]_6151   loss=3.706110 |g|=0.421	lr=5.88e-04 | 3.9%@S6  T=1.64s(data=1.5ms QKV=2.10s FFN=3.04s) eta=1d 00:56:20 | 46.0K token/s | 
[epoch_0]_6161   loss=3.635879 |g|=0.448	lr=5.88e-04 | 4.7%@S6  T=1.65s(data=1.4ms QKV=2.10s FFN=3.04s) eta=1d 01:06:15 | 46.2K token/s | 
[epoch_0]_6171   loss=3.613398 |g|=0.43	lr=5.88e-04 | 5.5%@S6  T=1.66s(data=1.9ms QKV=2.10s FFN=3.04s) eta=1d 01:16:54 | 46.3K token/s | 
[epoch_0]_6181   loss=3.639681 |g|=0.416	lr=5.88e-04 | 6.3%@S6  T=1.66s(data=1.8ms QKV=2.10s FFN=3.04s) eta=1d 01:20:29 | 46.5K token/s | 
[epoch_0]_6191   loss=3.651829 |g|=0.432	lr=5.88e-04 | 7.2%@S6  T=1.67s(data=1.6ms QKV=2.10s FFN=3.04s) eta=1d 01:22:01 | 46.6K token/s | 
[Fuyou] head="1" update algorithm=4 t=12.34s
[eval] 
	 Loss@"edu_fineweb1B"=3.654(0.0033) nBranch=1 nToken=6.31M best=3.6576(29) E2T=0.0296 T=36.7377(0)s x=0
	#3.65426±0.0983 tps=172K(6.30784M) a=[3.44426,3.90084] T=36.7377(sec)
[Section@6200] layer[16-24] tasks=19(nPassBack=0) last_loss=3.62468(0.0484622) N=(772,7616,7056 818268)
[epoch_0]_6201   loss=3.561430 |g|=0.484	lr=5.88e-04 | 8.0%@S6  T=11.85s(data=1.6ms QKV=2.10s FFN=3.04s) eta=7d 12:26:31 | 44.6K token/s | 
[epoch_0]_6211   loss=3.557675 |g|=0.491	lr=5.87e-04 | 8.8%@S6  T=1.66s(data=1.6ms QKV=2.10s FFN=3.04s) eta=1d 01:16:05 | 44.9K token/s | 
[epoch_0]_6221   loss=3.568022 |g|=0.436	lr=5.87e-04 | 9.6%@S6  T=1.66s(data=1.9ms QKV=2.10s FFN=3.04s) eta=1d 01:17:04 | 45.1K token/s | 
[epoch_0]_6231   loss=3.685145 |g|=0.424	lr=5.87e-04 | 10.4%@S6  T=1.67s(data=1.5ms QKV=2.10s FFN=3.04s) eta=1d 01:23:34 | 45.3K token/s | 
[epoch_0]_6241   loss=3.638347 |g|=0.405	lr=5.87e-04 | 11.3%@S6  T=1.64s(data=1.3ms QKV=2.10s FFN=3.04s) eta=1d 00:59:31 | 45.5K token/s | 
[epoch_0]_6251   loss=3.626257 |g|=0.416	lr=5.87e-04 | 12.1%@S6  T=1.64s(data=1.7ms QKV=2.10s FFN=3.04s) eta=1d 00:56:39 | 45.7K token/s | 
[epoch_0]_6261   loss=3.621320 |g|=0.431	lr=5.87e-04 | 12.9%@S6  T=1.66s(data=1.7ms QKV=2.10s FFN=3.04s) eta=1d 01:16:53 | 45.9K token/s | 
[epoch_0]_6271   loss=3.624397 |g|=0.4	lr=5.87e-04 | 13.7%@S6  T=1.64s(data=1.7ms QKV=2.10s FFN=3.04s) eta=1d 00:56:10 | 46.1K token/s | 
[epoch_0]_6281   loss=3.645441 |g|=0.393	lr=5.87e-04 | 14.5%@S6  T=1.64s(data=1.5ms QKV=2.10s FFN=3.04s) eta=1d 00:53:47 | 46.3K token/s | 
[epoch_0]_6291   loss=3.675444 |g|=0.429	lr=5.87e-04 | 15.4%@S6  T=1.66s(data=1.6ms QKV=2.10s FFN=3.04s) eta=1d 01:16:06 | 46.5K token/s | 
[Fuyou] head="2" update algorithm=4 t=10.56s
[Section@6300] layer[24-32] tasks=19(nPassBack=0) last_loss=3.55748(0.116061) N=(772,7728,7168 831468)
[epoch_0]_6301   loss=3.611799 |g|=0.431	lr=5.87e-04 | 16.2%@S6  T=3.87s(data=2.3ms QKV=2.10s FFN=3.04s) eta=2d 10:46:03 | 45.2K token/s | 
[epoch_0]_6311   loss=3.610269 |g|=0.495	lr=5.87e-04 | 17.0%@S6  T=1.65s(data=1.7ms QKV=2.10s FFN=3.04s) eta=1d 01:09:03 | 45.4K token/s | 
[epoch_0]_6321   loss=3.652281 |g|=0.398	lr=5.87e-04 | 17.8%@S6  T=1.66s(data=2.1ms QKV=2.10s FFN=3.04s) eta=1d 01:13:03 | 45.6K token/s | 
[epoch_0]_6331   loss=3.607785 |g|=0.417	lr=5.87e-04 | 18.6%@S6  T=1.65s(data=1.5ms QKV=2.10s FFN=3.04s) eta=1d 01:02:02 | 45.8K token/s | 
[epoch_0]_6341   loss=3.666851 |g|=0.454	lr=5.87e-04 | 19.5%@S6  T=1.67s(data=1.6ms QKV=2.10s FFN=3.04s) eta=1d 01:18:44 | 46.0K token/s | 
[epoch_0]_6351   loss=3.633292 |g|=0.405	lr=5.87e-04 | 20.3%@S6  T=1.67s(data=1.5ms QKV=2.10s FFN=3.04s) eta=1d 01:18:35 | 46.2K token/s | 
[epoch_0]_6361   loss=3.605233 |g|=0.429	lr=5.87e-04 | 21.1%@S6  T=1.67s(data=1.8ms QKV=2.10s FFN=3.04s) eta=1d 01:18:21 | 46.3K token/s | 
[epoch_0]_6371   loss=3.568394 |g|=0.408	lr=5.87e-04 | 21.9%@S6  T=1.67s(data=1.5ms QKV=2.10s FFN=3.04s) eta=1d 01:17:56 | 46.4K token/s | 
[epoch_0]_6381   loss=3.598474 |g|=0.413	lr=5.87e-04 | 22.7%@S6  T=1.66s(data=2.0ms QKV=2.10s FFN=3.04s) eta=1d 01:11:47 | 46.6K token/s | 
[epoch_0]_6391   loss=3.635395 |g|=0.408	lr=5.87e-04 | 23.6%@S6  T=1.64s(data=1.7ms QKV=2.10s FFN=3.04s) eta=1d 00:56:58 | 46.8K token/s | 
[Fuyou] head="3" update algorithm=4 t=10.77s
[eval] 
	 Loss@"edu_fineweb1B"=3.650(0.0042) nBranch=1 nToken=6.31M best=3.6543(30) E2T=-0.00523 T=36.7582(0)s x=0
	#3.65002±0.0990 tps=172K(6.30784M) a=[3.44009,3.91348] T=36.7582(sec)
[Section@6400] layer[32-40] tasks=19(nPassBack=0) last_loss=3.65525(0.0262747) N=(772,7840,7280 844668)
[epoch_0]_6401   loss=3.588330 |g|=0.434	lr=5.87e-04 | 24.4%@S6  T=11.49s(data=1.8ms QKV=2.10s FFN=3.04s) eta=7d 06:18:53 | 44.8K token/s | 
[epoch_0]_6411   loss=3.499520 |g|=0.417	lr=5.87e-04 | 25.2%@S6  T=1.66s(data=1.6ms QKV=2.10s FFN=3.04s) eta=1d 01:13:58 | 45.0K token/s | 
[epoch_0]_6421   loss=3.578246 |g|=0.46	lr=5.87e-04 | 26.0%@S6  T=1.67s(data=1.7ms QKV=2.10s FFN=3.04s) eta=1d 01:18:25 | 45.2K token/s | 
[epoch_0]_6431   loss=3.645967 |g|=0.429	lr=5.86e-04 | 26.8%@S6  T=1.67s(data=1.5ms QKV=2.10s FFN=3.04s) eta=1d 01:20:26 | 45.4K token/s | 
[epoch_0]_6441   loss=3.613017 |g|=0.42	lr=5.86e-04 | 27.6%@S6  T=1.68s(data=1.6ms QKV=2.10s FFN=3.04s) eta=1d 01:27:27 | 45.6K token/s | 
[epoch_0]_6451   loss=3.579672 |g|=0.453	lr=5.86e-04 | 28.5%@S6  T=1.66s(data=1.7ms QKV=2.10s FFN=3.04s) eta=1d 01:09:55 | 45.8K token/s | 
[epoch_0]_6461   loss=3.577819 |g|=0.399	lr=5.86e-04 | 29.3%@S6  T=1.66s(data=1.4ms QKV=2.10s FFN=3.04s) eta=1d 01:08:52 | 45.9K token/s | 
[epoch_0]_6471   loss=3.591742 |g|=0.37	lr=5.86e-04 | 30.1%@S6  T=1.66s(data=1.7ms QKV=2.10s FFN=3.04s) eta=1d 01:08:44 | 46.1K token/s | 
[epoch_0]_6481   loss=3.593432 |g|=0.424	lr=5.86e-04 | 30.9%@S6  T=1.67s(data=1.6ms QKV=2.10s FFN=3.04s) eta=1d 01:14:20 | 46.3K token/s | 
[epoch_0]_6491   loss=3.576452 |g|=0.435	lr=5.86e-04 | 31.7%@S6  T=1.66s(data=1.4ms QKV=2.10s FFN=3.04s) eta=1d 01:11:34 | 46.4K token/s | 
[Fuyou] head="4" update algorithm=4 t=9.66s
[Section@6500] layer[40-48] tasks=19(nPassBack=0) last_loss=3.57176(0.16855) N=(772,7952,7392 857868)
[epoch_0]_6501   loss=3.642154 |g|=0.396	lr=5.86e-04 | 32.6%@S6  T=4.35s(data=1.8ms QKV=2.10s FFN=3.04s) eta=2d 17:54:43 | 45.0K token/s | 
[epoch_0]_6511   loss=3.572470 |g|=0.394	lr=5.86e-04 | 33.4%@S6  T=1.63s(data=1.6ms QKV=2.10s FFN=3.04s) eta=1d 00:41:55 | 45.3K token/s | 
[epoch_0]_6521   loss=3.582051 |g|=0.394	lr=5.86e-04 | 34.2%@S6  T=1.67s(data=1.8ms QKV=2.10s FFN=3.04s) eta=1d 01:15:21 | 45.5K token/s | 
[epoch_0]_6531   loss=3.647409 |g|=0.407	lr=5.86e-04 | 35.0%@S6  T=1.67s(data=1.9ms QKV=2.10s FFN=3.04s) eta=1d 01:19:49 | 45.7K token/s | 
[epoch_0]_6541   loss=3.663801 |g|=0.436	lr=5.86e-04 | 35.8%@S6  T=1.67s(data=1.6ms QKV=2.10s FFN=3.04s) eta=1d 01:12:38 | 45.8K token/s | 
[epoch_0]_6551   loss=3.598099 |g|=0.409	lr=5.86e-04 | 36.7%@S6  T=1.66s(data=1.6ms QKV=2.10s FFN=3.04s) eta=1d 01:11:00 | 46.0K token/s | 
[epoch_0]_6561   loss=3.580134 |g|=0.405	lr=5.86e-04 | 37.5%@S6  T=1.66s(data=1.7ms QKV=2.10s FFN=3.04s) eta=1d 01:09:16 | 46.2K token/s | 
[epoch_0]_6571   loss=3.570960 |g|=0.478	lr=5.86e-04 | 38.3%@S6  T=1.65s(data=1.6ms QKV=2.10s FFN=3.04s) eta=1d 01:00:37 | 46.3K token/s | 
[epoch_0]_6581   loss=3.620723 |g|=0.395	lr=5.86e-04 | 39.1%@S6  T=1.64s(data=1.5ms QKV=2.10s FFN=3.04s) eta=1d 00:48:50 | 46.5K token/s | 
[epoch_0]_6591   loss=3.597614 |g|=0.434	lr=5.86e-04 | 39.9%@S6  T=1.64s(data=1.6ms QKV=2.10s FFN=3.04s) eta=1d 00:43:57 | 46.7K token/s | 
[Fuyou] head="5" update algorithm=4 t=9.29s
[eval] 
	 Loss@"edu_fineweb1B"=3.645(0.0054) nBranch=1 nToken=6.31M best=3.6500(31) E2T=0.0967 T=36.7405(0)s x=0
	#3.64459±0.1005 tps=172K(6.30784M) a=[3.42833,3.90758] T=36.7405(sec)
[Section@6600] layer[0-8] tasks=19(nPassBack=0) last_loss=3.54786(0.0368469) N=(772,8064,7504 871068)
[epoch_0]_6601   loss=3.540638 |g|=0.398	lr=5.86e-04 | 40.8%@S6  T=11.30s(data=1.8ms QKV=2.10s FFN=3.04s) eta=7d 02:55:42 | 44.7K token/s | 
[epoch_0]_6611   loss=3.637566 |g|=0.397	lr=5.86e-04 | 41.6%@S6  T=1.64s(data=1.6ms QKV=2.10s FFN=3.04s) eta=1d 00:45:59 | 45.0K token/s | 
[epoch_0]_6621   loss=3.501010 |g|=0.366	lr=5.86e-04 | 42.4%@S6  T=1.65s(data=1.7ms QKV=2.10s FFN=3.04s) eta=1d 00:53:48 | 45.2K token/s | 
[epoch_0]_6631   loss=3.616052 |g|=0.412	lr=5.86e-04 | 43.2%@S6  T=1.71s(data=8.3ms QKV=2.10s FFN=3.04s) eta=1d 01:49:24 | 45.4K token/s | 
[epoch_0]_6641   loss=3.640603 |g|=0.418	lr=5.85e-04 | 44.0%@S6  T=1.67s(data=2.0ms QKV=2.10s FFN=3.04s) eta=1d 01:16:08 | 45.5K token/s | 
[epoch_0]_6651   loss=3.506462 |g|=0.397	lr=5.85e-04 | 44.9%@S6  T=1.66s(data=1.6ms QKV=2.10s FFN=3.04s) eta=1d 01:01:40 | 45.7K token/s | 
[epoch_0]_6661   loss=3.533983 |g|=0.402	lr=5.85e-04 | 45.7%@S6  T=1.65s(data=2.0ms QKV=2.10s FFN=3.04s) eta=1d 00:57:27 | 45.9K token/s | 
[epoch_0]_6671   loss=3.623282 |g|=0.432	lr=5.85e-04 | 46.5%@S6  T=1.68s(data=1.8ms QKV=2.10s FFN=3.04s) eta=1d 01:22:52 | 46.1K token/s | 
[epoch_0]_6681   loss=3.545881 |g|=0.458	lr=5.85e-04 | 47.3%@S6  T=1.67s(data=1.8ms QKV=2.10s FFN=3.04s) eta=1d 01:13:32 | 46.2K token/s | 
[epoch_0]_6691   loss=3.541282 |g|=0.415	lr=5.85e-04 | 48.1%@S6  T=1.67s(data=1.5ms QKV=2.10s FFN=3.04s) eta=1d 01:10:04 | 46.4K token/s | 
[Fuyou] head="0" update algorithm=4 t=9.48s
[Section@6700] layer[8-16] tasks=19(nPassBack=0) last_loss=3.55782(0.0735657) N=(772,8176,7616 884268)
[epoch_0]_6701   loss=3.510751 |g|=0.426	lr=5.85e-04 | 48.9%@S6  T=4.40s(data=1.6ms QKV=2.10s FFN=3.04s) eta=2d 18:24:57 | 45.0K token/s | 
[epoch_0]_6711   loss=3.580435 |g|=0.415	lr=5.85e-04 | 49.8%@S6  T=1.67s(data=1.5ms QKV=2.10s FFN=3.04s) eta=1d 01:07:44 | 45.2K token/s | 
[epoch_0]_6721   loss=3.661030 |g|=0.411	lr=5.85e-04 | 50.6%@S6  T=1.66s(data=1.8ms QKV=2.10s FFN=3.04s) eta=1d 01:02:03 | 45.4K token/s | 
[epoch_0]_6731   loss=3.575724 |g|=0.425	lr=5.85e-04 | 51.4%@S6  T=1.68s(data=1.6ms QKV=2.10s FFN=3.04s) eta=1d 01:18:25 | 45.6K token/s | 
[epoch_0]_6741   loss=3.583761 |g|=0.413	lr=5.85e-04 | 52.2%@S6  T=1.66s(data=1.5ms QKV=2.10s FFN=3.04s) eta=1d 01:06:26 | 45.7K token/s | 
[epoch_0]_6751   loss=3.615396 |g|=0.426	lr=5.85e-04 | 53.0%@S6  T=1.66s(data=1.6ms QKV=2.10s FFN=3.04s) eta=1d 01:02:50 | 45.9K token/s | 
[epoch_0]_6761   loss=3.607121 |g|=0.421	lr=5.85e-04 | 53.9%@S6  T=1.66s(data=1.6ms QKV=2.10s FFN=3.04s) eta=1d 00:59:41 | 46.1K token/s | 
[epoch_0]_6771   loss=3.615184 |g|=0.417	lr=5.85e-04 | 54.7%@S6  T=1.66s(data=1.6ms QKV=2.10s FFN=3.04s) eta=1d 01:02:02 | 46.3K token/s | 
[epoch_0]_6781   loss=3.540473 |g|=0.408	lr=5.85e-04 | 55.5%@S6  T=1.67s(data=1.7ms QKV=2.10s FFN=3.04s) eta=1d 01:08:35 | 46.4K token/s | 
[epoch_0]_6791   loss=3.564641 |g|=0.437	lr=5.85e-04 | 56.3%@S6  T=1.66s(data=1.8ms QKV=2.10s FFN=3.04s) eta=1d 01:01:05 | 46.6K token/s | 
[Fuyou] head="1" update algorithm=4 t=9.28s
[eval] 
	 Loss@"edu_fineweb1B"=3.634(0.011) nBranch=1 nToken=6.31M best=3.6446(32) E2T=0.0424 T=36.7507(0)s x=0
	#3.63371±0.0998 tps=172K(6.30784M) a=[3.4138,3.89182] T=36.7507(sec)
[Section@6800] layer[16-24] tasks=19(nPassBack=0) last_loss=3.59131(0.0333769) N=(772,8288,7728 897468)
[epoch_0]_6801   loss=3.611076 |g|=0.46	lr=5.85e-04 | 57.1%@S6  T=11.31s(data=1.5ms QKV=2.10s FFN=3.04s) eta=7d 02:21:19 | 44.6K token/s | 
[epoch_0]_6811   loss=3.600986 |g|=0.425	lr=5.85e-04 | 58.0%@S6  T=1.66s(data=1.6ms QKV=2.10s FFN=3.04s) eta=1d 01:02:35 | 44.8K token/s | 
[epoch_0]_6821   loss=3.519639 |g|=0.416	lr=5.85e-04 | 58.8%@S6  T=1.68s(data=1.9ms QKV=2.10s FFN=3.04s) eta=1d 01:19:13 | 45.0K token/s | 
[epoch_0]_6831   loss=3.609079 |g|=0.41	lr=5.85e-04 | 59.6%@S6  T=1.66s(data=1.7ms QKV=2.10s FFN=3.04s) eta=1d 01:02:04 | 45.2K token/s | 
[epoch_0]_6841   loss=3.613290 |g|=0.451	lr=5.85e-04 | 60.4%@S6  T=1.66s(data=1.6ms QKV=2.10s FFN=3.04s) eta=1d 01:01:50 | 45.4K token/s | 
[epoch_0]_6851   loss=3.604465 |g|=0.408	lr=5.84e-04 | 61.2%@S6  T=1.68s(data=1.5ms QKV=2.10s FFN=3.04s) eta=1d 01:13:50 | 45.6K token/s | 
[epoch_0]_6861   loss=3.617758 |g|=0.47	lr=5.84e-04 | 62.1%@S6  T=1.67s(data=1.7ms QKV=2.10s FFN=3.04s) eta=1d 01:06:28 | 45.8K token/s | 
[epoch_0]_6871   loss=3.554182 |g|=0.422	lr=5.84e-04 | 62.9%@S6  T=1.66s(data=1.7ms QKV=2.10s FFN=3.04s) eta=1d 01:01:55 | 46.0K token/s | 
[epoch_0]_6881   loss=3.525617 |g|=0.432	lr=5.84e-04 | 63.7%@S6  T=1.66s(data=1.8ms QKV=2.10s FFN=3.04s) eta=1d 01:02:16 | 46.1K token/s | 
[epoch_0]_6891   loss=3.624127 |g|=0.442	lr=5.84e-04 | 64.5%@S6  T=1.68s(data=1.7ms QKV=2.10s FFN=3.04s) eta=1d 01:11:41 | 46.3K token/s | 
[Fuyou] head="2" update algorithm=4 t=9.97s
[Section@6900] layer[24-32] tasks=19(nPassBack=0) last_loss=3.58293(-0.0254512) N=(772,8400,7840 910668)
[epoch_0]_6901   loss=3.560115 |g|=0.362	lr=5.84e-04 | 65.3%@S6  T=3.87s(data=1.8ms QKV=2.10s FFN=3.04s) eta=2d 10:10:16 | 45.0K token/s | 
[epoch_0]_6911   loss=3.608347 |g|=0.411	lr=5.84e-04 | 66.2%@S6  T=1.65s(data=1.9ms QKV=2.10s FFN=3.04s) eta=1d 00:47:30 | 45.2K token/s | 
[epoch_0]_6921   loss=3.609465 |g|=0.571	lr=5.84e-04 | 67.0%@S6  T=1.65s(data=1.8ms QKV=2.10s FFN=3.04s) eta=1d 00:45:24 | 45.5K token/s | 
[epoch_0]_6931   loss=3.557342 |g|=0.407	lr=5.84e-04 | 67.8%@S6  T=1.68s(data=1.6ms QKV=2.10s FFN=3.04s) eta=1d 01:11:53 | 45.6K token/s | 
[epoch_0]_6941   loss=3.511054 |g|=0.406	lr=5.84e-04 | 68.6%@S6  T=1.67s(data=1.6ms QKV=2.10s FFN=3.04s) eta=1d 01:05:20 | 45.8K token/s | 
[epoch_0]_6951   loss=3.548743 |g|=0.399	lr=5.84e-04 | 69.4%@S6  T=1.67s(data=1.6ms QKV=2.10s FFN=3.04s) eta=1d 01:03:47 | 46.0K token/s | 
[epoch_0]_6961   loss=3.529890 |g|=0.463	lr=5.84e-04 | 70.2%@S6  T=1.67s(data=1.6ms QKV=2.10s FFN=3.04s) eta=1d 01:01:20 | 46.1K token/s | 
[epoch_0]_6971   loss=3.551231 |g|=0.409	lr=5.84e-04 | 71.1%@S6  T=1.67s(data=1.7ms QKV=2.10s FFN=3.04s) eta=1d 01:00:54 | 46.3K token/s | 
[epoch_0]_6981   loss=3.598527 |g|=0.379	lr=5.84e-04 | 71.9%@S6  T=1.66s(data=1.5ms QKV=2.10s FFN=3.04s) eta=1d 00:55:46 | 46.4K token/s | 
[epoch_0]_6991   loss=3.550965 |g|=0.414	lr=5.84e-04 | 72.7%@S6  T=1.66s(data=1.6ms QKV=2.10s FFN=3.04s) eta=1d 00:56:01 | 46.6K token/s | 
[Fuyou] head="3" update algorithm=4 t=10.08s
[eval] 
	 Loss@"edu_fineweb1B"=3.630(0.004) nBranch=1 nToken=6.31M best=3.6337(33) E2T=0.0304 T=36.7506(0)s x=0
	#3.62967±0.0992 tps=172K(6.30784M) a=[3.41857,3.88805] T=36.7506(sec)
[Section@7000] layer[32-40] tasks=19(nPassBack=0) last_loss=3.59922(0.0560229) N=(772,8512,7952 923868)
[epoch_0]_7001   loss=3.580168 |g|=0.42	lr=5.84e-04 | 73.5%@S6  T=11.42s(data=1.8ms QKV=2.10s FFN=3.04s) eta=7d 03:25:40 | 44.6K token/s | 
[epoch_0]_7011   loss=3.558873 |g|=0.415	lr=5.84e-04 | 74.3%@S6  T=1.65s(data=1.8ms QKV=2.10s FFN=3.04s) eta=1d 00:41:21 | 44.9K token/s | 
[epoch_0]_7021   loss=3.567834 |g|=0.404	lr=5.84e-04 | 75.2%@S6  T=1.67s(data=1.7ms QKV=2.10s FFN=3.04s) eta=1d 01:00:44 | 45.1K token/s | 
[epoch_0]_7031   loss=3.644174 |g|=0.39	lr=5.84e-04 | 76.0%@S6  T=1.67s(data=1.5ms QKV=2.10s FFN=3.04s) eta=1d 01:03:24 | 45.3K token/s | 
[epoch_0]_7041   loss=3.600014 |g|=0.467	lr=5.84e-04 | 76.8%@S6  T=1.66s(data=1.5ms QKV=2.10s FFN=3.04s) eta=1d 00:55:04 | 45.5K token/s | 
[epoch_0]_7051   loss=3.574575 |g|=0.405	lr=5.83e-04 | 77.6%@S6  T=1.67s(data=1.7ms QKV=2.10s FFN=3.04s) eta=1d 01:03:13 | 45.7K token/s | 
[epoch_0]_7061   loss=3.521025 |g|=0.415	lr=5.83e-04 | 78.4%@S6  T=1.68s(data=1.6ms QKV=2.10s FFN=3.04s) eta=1d 01:12:39 | 45.8K token/s | 
[epoch_0]_7071   loss=3.677896 |g|=0.42	lr=5.83e-04 | 79.3%@S6  T=1.66s(data=1.8ms QKV=2.11s FFN=3.04s) eta=1d 00:54:41 | 46.0K token/s | 
[epoch_0]_7081   loss=3.670179 |g|=0.44	lr=5.83e-04 | 80.1%@S6  T=1.70s(data=1.6ms QKV=2.10s FFN=3.04s) eta=1d 01:31:37 | 46.1K token/s | 
[epoch_0]_7091   loss=3.571249 |g|=0.383	lr=5.83e-04 | 80.9%@S6  T=1.66s(data=1.6ms QKV=2.10s FFN=3.04s) eta=1d 00:48:37 | 46.3K token/s | 
[Fuyou] head="4" update algorithm=4 t=10.16s
[Section@7100] layer[40-48] tasks=19(nPassBack=0) last_loss=3.55402(0.01774) N=(772,8624,8064 937068)
[epoch_0]_7101   loss=3.510255 |g|=0.42	lr=5.83e-04 | 81.7%@S6  T=4.48s(data=1.7ms QKV=2.10s FFN=3.04s) eta=2d 19:02:41 | 44.9K token/s | 
[epoch_0]_7111   loss=3.557774 |g|=0.472	lr=5.83e-04 | 82.5%@S6  T=1.68s(data=2.0ms QKV=2.10s FFN=3.04s) eta=1d 01:07:14 | 45.1K token/s | 
[epoch_0]_7121   loss=3.563490 |g|=0.413	lr=5.83e-04 | 83.4%@S6  T=1.67s(data=1.6ms QKV=2.10s FFN=3.04s) eta=1d 01:00:26 | 45.3K token/s | 
[epoch_0]_7131   loss=3.545053 |g|=0.416	lr=5.83e-04 | 84.2%@S6  T=1.65s(data=1.9ms QKV=2.10s FFN=3.04s) eta=1d 00:39:34 | 45.5K token/s | 
[epoch_0]_7141   loss=3.541879 |g|=0.444	lr=5.83e-04 | 85.0%@S6  T=1.68s(data=1.8ms QKV=2.10s FFN=3.04s) eta=1d 01:05:44 | 45.7K token/s | 
[epoch_0]_7151   loss=3.488567 |g|=0.451	lr=5.83e-04 | 85.8%@S6  T=1.67s(data=1.8ms QKV=2.10s FFN=3.04s) eta=1d 01:02:33 | 45.8K token/s | 
[epoch_0]_7161   loss=3.534668 |g|=0.387	lr=5.83e-04 | 86.6%@S6  T=1.68s(data=1.5ms QKV=2.10s FFN=3.04s) eta=1d 01:04:27 | 46.0K token/s | 
[epoch_0]_7171   loss=3.609529 |g|=0.429	lr=5.83e-04 | 87.5%@S6  T=1.66s(data=1.5ms QKV=2.10s FFN=3.04s) eta=1d 00:52:04 | 46.1K token/s | 
[epoch_0]_7181   loss=3.540809 |g|=0.43	lr=5.83e-04 | 88.3%@S6  T=1.67s(data=1.9ms QKV=2.10s FFN=3.04s) eta=1d 01:01:52 | 46.3K token/s | 
[epoch_0]_7191   loss=3.590615 |g|=0.426	lr=5.83e-04 | 89.1%@S6  T=1.67s(data=1.6ms QKV=2.10s FFN=3.04s) eta=1d 01:01:55 | 46.4K token/s | 
[Fuyou] head="5" update algorithm=4 t=11.78s
[eval] 
	 Loss@"edu_fineweb1B"=3.620(0.0099) nBranch=1 nToken=6.31M best=3.6297(34) E2T=0.0101 T=36.7047(0)s x=0
	#3.61975±0.1002 tps=172K(6.30784M) a=[3.40257,3.88736] T=36.7047(sec)
[Section@7200] layer[0-8] tasks=19(nPassBack=0) last_loss=3.60965(-0.0617878) N=(772,8736,8176 950268)
[epoch_0]_7201   loss=3.525733 |g|=0.393	lr=5.83e-04 | 89.9%@S6  T=11.38s(data=1.8ms QKV=2.10s FFN=3.04s) eta=7d 02:14:11 | 44.5K token/s | 
[epoch_0]_7211   loss=3.512321 |g|=0.432	lr=5.83e-04 | 90.7%@S6  T=1.66s(data=1.6ms QKV=2.10s FFN=3.04s) eta=1d 00:52:35 | 44.7K token/s | 
[epoch_0]_7221   loss=3.554337 |g|=0.454	lr=5.83e-04 | 91.5%@S6  T=1.66s(data=1.6ms QKV=2.10s FFN=3.04s) eta=1d 00:50:42 | 44.9K token/s | 
[epoch_0]_7231   loss=3.528513 |g|=0.43	lr=5.83e-04 | 92.4%@S6  T=1.66s(data=1.6ms QKV=2.10s FFN=3.04s) eta=1d 00:48:55 | 45.1K token/s | 
[epoch_0]_7241   loss=3.540638 |g|=0.416	lr=5.82e-04 | 93.2%@S6  T=1.65s(data=1.6ms QKV=2.10s FFN=3.04s) eta=1d 00:43:36 | 45.4K token/s | 
[epoch_0]_7251   loss=3.578981 |g|=0.396	lr=5.82e-04 | 94.0%@S6  T=1.67s(data=1.6ms QKV=2.10s FFN=3.04s) eta=1d 00:56:24 | 45.5K token/s | 
[epoch_0]_7261   loss=3.625345 |g|=0.388	lr=5.82e-04 | 94.8%@S6  T=1.67s(data=1.6ms QKV=2.10s FFN=3.04s) eta=1d 00:57:20 | 45.7K token/s | 
[epoch_0]_7271   loss=3.523461 |g|=0.413	lr=5.82e-04 | 95.6%@S6  T=1.67s(data=1.6ms QKV=2.10s FFN=3.04s) eta=1d 00:56:31 | 45.9K token/s | 
[epoch_0]_7281   loss=3.572927 |g|=0.411	lr=5.82e-04 | 96.5%@S6  T=1.69s(data=1.7ms QKV=2.10s FFN=3.04s) eta=1d 01:10:23 | 46.0K token/s | 
[epoch_0]_7291   loss=3.487686 |g|=0.477	lr=5.82e-04 | 97.3%@S6  T=1.66s(data=1.8ms QKV=2.10s FFN=3.04s) eta=1d 00:49:52 | 46.2K token/s | 
[Fuyou] head="0" update algorithm=4 t=8.13s
[Section@7300] layer[8-16] tasks=19(nPassBack=0) last_loss=3.52116(0.0366588) N=(772,8848,8288 963468)
[epoch_0]_7301   loss=3.595853 |g|=0.397	lr=5.82e-04 | 98.1%@S6  T=4.12s(data=1.7ms QKV=2.10s FFN=3.04s) eta=2d 13:29:03 | 44.9K token/s | 
[epoch_0]_7311   loss=3.539670 |g|=0.411	lr=5.82e-04 | 98.9%@S6  T=1.64s(data=1.7ms QKV=2.10s FFN=3.04s) eta=1d 00:29:31 | 45.1K token/s | 
[epoch_0]_7321   loss=3.564616 |g|=0.416	lr=5.82e-04 | 99.7%@S6  T=1.64s(data=1.7ms QKV=2.10s FFN=3.04s) eta=1d 00:29:08 | 45.4K token/s | 
[epoch_0]_7324   loss=3.569139 |g|=0.399	lr=5.82e-04 | 100.0%@S6  T=1.64s(data=1.5ms QKV=2.10s FFN=3.04s) eta=1d 00:28:07 | 45.6K token/s | 
-------- End of shard_6@"./Datasets/edu_fineweb1B/edu_fineweb_train_000006.bin"-------- 
[shard-7]@"./Datasets/edu_fineweb1B/edu_fineweb_train_000007.bin": tokens=100(M) nShardSamples=1220(683592) 
[epoch_0]_7331   loss=3.526737 |g|=0.408	lr=5.82e-04 | 0.6%@S7  T=1.64s(data=1.2ms QKV=2.10s FFN=3.04s) eta=1d 00:26:18 | 45.8K token/s | 
[epoch_0]_7341   loss=3.574958 |g|=0.409	lr=5.82e-04 | 1.4%@S7  T=1.65s(data=1.2ms QKV=2.10s FFN=3.04s) eta=1d 00:32:11 | 46.0K token/s | 
[epoch_0]_7351   loss=3.587679 |g|=0.387	lr=5.82e-04 | 2.2%@S7  T=1.66s(data=1.5ms QKV=2.10s FFN=3.04s) eta=1d 00:41:20 | 46.2K token/s | 
[epoch_0]_7361   loss=3.591035 |g|=0.396	lr=5.82e-04 | 3.0%@S7  T=1.67s(data=1.6ms QKV=2.10s FFN=3.05s) eta=1d 00:50:08 | 46.3K token/s | 
[epoch_0]_7371   loss=3.471093 |g|=0.385	lr=5.82e-04 | 3.8%@S7  T=1.68s(data=1.8ms QKV=2.10s FFN=3.04s) eta=1d 00:59:55 | 46.5K token/s | 
[epoch_0]_7381   loss=3.635015 |g|=0.389	lr=5.82e-04 | 4.7%@S7  T=1.66s(data=1.6ms QKV=2.10s FFN=3.04s) eta=1d 00:45:16 | 46.6K token/s | 
[epoch_0]_7391   loss=3.554372 |g|=0.398	lr=5.82e-04 | 5.5%@S7  T=1.66s(data=1.5ms QKV=2.10s FFN=3.04s) eta=1d 00:45:04 | 46.7K token/s | 
[Fuyou] head="1" update algorithm=4 t=9.76s
[eval] 
	 Loss@"edu_fineweb1B"=3.599(0.02) nBranch=1 nToken=6.31M best=3.6197(35) E2T=-0.0185 T=36.7167(0)s x=0
	#3.59944±0.0996 tps=172K(6.30784M) a=[3.38707,3.85449] T=36.7167(sec)
[Section@7400] layer[16-24] tasks=19(nPassBack=0) last_loss=3.61792(-0.0266175) N=(772,8960,8400 976668)
[epoch_0]_7401   loss=3.566884 |g|=0.439	lr=5.82e-04 | 6.3%@S7  T=11.84s(data=1.9ms QKV=2.10s FFN=3.04s) eta=7d 08:26:00 | 44.7K token/s | 
[epoch_0]_7411   loss=3.541450 |g|=0.387	lr=5.82e-04 | 7.1%@S7  T=1.67s(data=1.7ms QKV=2.10s FFN=3.04s) eta=1d 00:50:17 | 45.0K token/s | 
[epoch_0]_7421   loss=3.569033 |g|=0.429	lr=5.82e-04 | 7.9%@S7  T=1.66s(data=1.9ms QKV=2.10s FFN=3.04s) eta=1d 00:39:25 | 45.2K token/s | 
[epoch_0]_7431   loss=3.543363 |g|=0.426	lr=5.81e-04 | 8.8%@S7  T=1.67s(data=1.7ms QKV=2.10s FFN=3.04s) eta=1d 00:54:30 | 45.4K token/s | 
[epoch_0]_7441   loss=3.496086 |g|=0.391	lr=5.81e-04 | 9.6%@S7  T=1.67s(data=1.7ms QKV=2.10s FFN=3.04s) eta=1d 00:51:52 | 45.6K token/s | 
[epoch_0]_7451   loss=3.516327 |g|=0.448	lr=5.81e-04 | 10.4%@S7  T=1.67s(data=1.6ms QKV=2.10s FFN=3.04s) eta=1d 00:52:50 | 45.7K token/s | 
[epoch_0]_7461   loss=3.487195 |g|=0.442	lr=5.81e-04 | 11.2%@S7  T=1.68s(data=1.4ms QKV=2.10s FFN=3.04s) eta=1d 01:00:56 | 45.9K token/s | 
[epoch_0]_7471   loss=3.479906 |g|=0.395	lr=5.81e-04 | 12.0%@S7  T=1.66s(data=1.8ms QKV=2.10s FFN=3.04s) eta=1d 00:45:04 | 46.1K token/s | 
[epoch_0]_7481   loss=3.529330 |g|=0.405	lr=5.81e-04 | 12.8%@S7  T=1.67s(data=1.7ms QKV=2.10s FFN=3.04s) eta=1d 00:53:21 | 46.2K token/s | 
[epoch_0]_7491   loss=3.517253 |g|=0.422	lr=5.81e-04 | 13.7%@S7  T=1.66s(data=1.9ms QKV=2.10s FFN=3.04s) eta=1d 00:42:37 | 46.4K token/s | 
[Fuyou] head="2" update algorithm=4 t=9.55s
[Section@7500] layer[24-32] tasks=19(nPassBack=0) last_loss=3.54053(0.0424039) N=(772,9072,8512 989868)
[epoch_0]_7501   loss=3.593215 |g|=0.426	lr=5.81e-04 | 14.5%@S7  T=3.88s(data=1.7ms QKV=2.10s FFN=3.04s) eta=2d 09:37:52 | 45.1K token/s | 
[epoch_0]_7511   loss=3.595736 |g|=0.411	lr=5.81e-04 | 15.3%@S7  T=1.67s(data=1.6ms QKV=2.10s FFN=3.04s) eta=1d 00:46:14 | 45.3K token/s | 
[epoch_0]_7521   loss=3.570410 |g|=0.416	lr=5.81e-04 | 16.1%@S7  T=1.69s(data=2.0ms QKV=2.10s FFN=3.04s) eta=1d 01:10:58 | 45.5K token/s | 
[epoch_0]_7531   loss=3.599042 |g|=0.39	lr=5.81e-04 | 16.9%@S7  T=1.64s(data=3.5ms QKV=2.10s FFN=3.04s) eta=1d 00:26:11 | 45.7K token/s | 
[epoch_0]_7541   loss=3.554133 |g|=0.397	lr=5.81e-04 | 17.8%@S7  T=1.66s(data=1.7ms QKV=2.10s FFN=3.04s) eta=1d 00:42:01 | 45.9K token/s | 
[epoch_0]_7551   loss=3.603642 |g|=0.418	lr=5.81e-04 | 18.6%@S7  T=1.67s(data=1.8ms QKV=2.10s FFN=3.04s) eta=1d 00:51:29 | 46.0K token/s | 
[epoch_0]_7561   loss=3.559199 |g|=0.392	lr=5.81e-04 | 19.4%@S7  T=1.66s(data=1.7ms QKV=2.10s FFN=3.04s) eta=1d 00:40:12 | 46.2K token/s | 
[epoch_0]_7571   loss=3.576735 |g|=0.417	lr=5.81e-04 | 20.2%@S7  T=1.69s(data=1.5ms QKV=2.10s FFN=3.04s) eta=1d 01:03:27 | 46.3K token/s | 
[epoch_0]_7581   loss=3.530244 |g|=0.41	lr=5.81e-04 | 21.0%@S7  T=1.67s(data=1.9ms QKV=2.10s FFN=3.04s) eta=1d 00:51:36 | 46.4K token/s | 
[epoch_0]_7591   loss=3.484308 |g|=0.39	lr=5.81e-04 | 21.9%@S7  T=1.67s(data=1.4ms QKV=2.10s FFN=3.04s) eta=1d 00:46:40 | 46.6K token/s | 
[Fuyou] head="3" update algorithm=4 t=10.36s
[eval] 
	 Loss@"edu_fineweb1B"=3.584(0.015) nBranch=1 nToken=6.31M best=3.5994(36) E2T=0.103 T=36.7462(0)s x=0
	#3.58437±0.0995 tps=172K(6.30784M) a=[3.37272,3.8389] T=36.7462(sec)
[Section@7600] layer[32-40] tasks=19(nPassBack=0) last_loss=3.48106(0.118161) N=(772,9184,8624 1003068)
[epoch_0]_7601   loss=3.535435 |g|=0.423	lr=5.81e-04 | 22.7%@S7  T=11.78s(data=1.9ms QKV=2.10s FFN=3.04s) eta=7d 06:53:55 | 44.6K token/s | 
[epoch_0]_7611   loss=3.568641 |g|=0.406	lr=5.80e-04 | 23.5%@S7  T=1.66s(data=1.7ms QKV=2.10s FFN=3.04s) eta=1d 00:34:43 | 44.8K token/s | 
[epoch_0]_7621   loss=3.582483 |g|=0.388	lr=5.80e-04 | 24.3%@S7  T=1.67s(data=2.2ms QKV=2.10s FFN=3.04s) eta=1d 00:43:01 | 45.0K token/s | 
[epoch_0]_7631   loss=3.493272 |g|=0.419	lr=5.80e-04 | 25.1%@S7  T=1.65s(data=1.9ms QKV=2.10s FFN=3.04s) eta=1d 00:28:26 | 45.3K token/s | 
[epoch_0]_7641   loss=3.651188 |g|=0.467	lr=5.80e-04 | 26.0%@S7  T=1.67s(data=1.5ms QKV=2.10s FFN=3.04s) eta=1d 00:43:49 | 45.5K token/s | 
[epoch_0]_7651   loss=3.534319 |g|=0.453	lr=5.80e-04 | 26.8%@S7  T=1.67s(data=1.4ms QKV=2.10s FFN=3.04s) eta=1d 00:44:14 | 45.6K token/s | 
[epoch_0]_7661   loss=3.610811 |g|=0.387	lr=5.80e-04 | 27.6%@S7  T=1.66s(data=1.5ms QKV=2.10s FFN=3.04s) eta=1d 00:39:00 | 45.8K token/s | 
[epoch_0]_7671   loss=3.586681 |g|=0.386	lr=5.80e-04 | 28.4%@S7  T=1.67s(data=1.8ms QKV=2.10s FFN=3.04s) eta=1d 00:46:04 | 46.0K token/s | 
[epoch_0]_7681   loss=3.494930 |g|=0.445	lr=5.80e-04 | 29.2%@S7  T=1.68s(data=1.5ms QKV=2.10s FFN=3.04s) eta=1d 00:55:31 | 46.1K token/s | 
[epoch_0]_7691   loss=3.572947 |g|=0.432	lr=5.80e-04 | 30.0%@S7  T=1.67s(data=1.5ms QKV=2.10s FFN=3.04s) eta=1d 00:48:36 | 46.3K token/s | 
[Fuyou] head="4" update algorithm=4 t=11.35s
[Section@7700] layer[40-48] tasks=19(nPassBack=0) last_loss=3.57359(-0.0195665) N=(772,9296,8736 1016268)
[epoch_0]_7701   loss=3.563300 |g|=0.427	lr=5.80e-04 | 30.9%@S7  T=3.87s(data=1.6ms QKV=2.10s FFN=3.04s) eta=2d 09:17:33 | 45.0K token/s | 
[epoch_0]_7711   loss=3.561902 |g|=0.466	lr=5.80e-04 | 31.7%@S7  T=1.67s(data=1.5ms QKV=2.10s FFN=3.04s) eta=1d 00:42:58 | 45.2K token/s | 
[epoch_0]_7721   loss=3.547277 |g|=0.392	lr=5.80e-04 | 32.5%@S7  T=1.69s(data=1.6ms QKV=2.10s FFN=3.04s) eta=1d 01:04:40 | 45.4K token/s | 
[epoch_0]_7731   loss=3.492421 |g|=0.426	lr=5.80e-04 | 33.3%@S7  T=1.67s(data=1.6ms QKV=2.10s FFN=3.04s) eta=1d 00:44:37 | 45.6K token/s | 
[epoch_0]_7741   loss=3.571130 |g|=0.401	lr=5.80e-04 | 34.1%@S7  T=1.67s(data=1.6ms QKV=2.10s FFN=3.04s) eta=1d 00:43:16 | 45.7K token/s | 
[epoch_0]_7751   loss=3.570288 |g|=0.449	lr=5.80e-04 | 35.0%@S7  T=1.66s(data=1.7ms QKV=2.10s FFN=3.04s) eta=1d 00:30:52 | 45.9K token/s | 
[epoch_0]_7761   loss=3.489315 |g|=0.394	lr=5.80e-04 | 35.8%@S7  T=1.65s(data=1.6ms QKV=2.10s FFN=3.04s) eta=1d 00:23:38 | 46.1K token/s | 
[epoch_0]_7771   loss=3.565050 |g|=0.45	lr=5.80e-04 | 36.6%@S7  T=1.67s(data=1.7ms QKV=2.10s FFN=3.04s) eta=1d 00:39:01 | 46.3K token/s | 
[epoch_0]_7781   loss=3.541872 |g|=0.43	lr=5.80e-04 | 37.4%@S7  T=1.67s(data=1.6ms QKV=2.10s FFN=3.04s) eta=1d 00:40:42 | 46.4K token/s | 
[epoch_0]_7791   loss=3.582961 |g|=0.405	lr=5.79e-04 | 38.2%@S7  T=1.68s(data=1.6ms QKV=2.10s FFN=3.04s) eta=1d 00:52:01 | 46.5K token/s | 
[Fuyou] head="5" update algorithm=4 t=11.28s
[eval] 
	 Loss@"edu_fineweb1B"=3.573(0.011) nBranch=1 nToken=6.31M best=3.5844(37) E2T=0.0276 T=36.7078(0)s x=0
	#3.57305±0.0996 tps=172K(6.30784M) a=[3.36411,3.8353] T=36.7078(sec)
[Section@7800] layer[0-8] tasks=19(nPassBack=0) last_loss=3.54546(0.0641875) N=(772,9408,8848 1029468)
[epoch_0]_7801   loss=3.497238 |g|=0.394	lr=5.79e-04 | 39.1%@S7  T=12.07s(data=1.9ms QKV=2.10s FFN=3.04s) eta=7d 10:31:28 | 44.5K token/s | 
[epoch_0]_7811   loss=3.452813 |g|=0.432	lr=5.79e-04 | 39.9%@S7  T=1.66s(data=1.9ms QKV=2.10s FFN=3.05s) eta=1d 00:35:01 | 44.8K token/s | 
[epoch_0]_7821   loss=3.699668 |g|=0.405	lr=5.79e-04 | 40.7%@S7  T=1.65s(data=1.9ms QKV=2.10s FFN=3.04s) eta=1d 00:19:03 | 45.0K token/s | 
[epoch_0]_7831   loss=3.578411 |g|=0.394	lr=5.79e-04 | 41.5%@S7  T=1.66s(data=1.6ms QKV=2.10s FFN=3.04s) eta=1d 00:33:19 | 45.2K token/s | 
[epoch_0]_7841   loss=3.589991 |g|=0.425	lr=5.79e-04 | 42.3%@S7  T=1.66s(data=1.5ms QKV=2.10s FFN=3.04s) eta=1d 00:27:30 | 45.4K token/s | 
[epoch_0]_7851   loss=3.574971 |g|=0.428	lr=5.79e-04 | 43.2%@S7  T=1.66s(data=1.6ms QKV=2.10s FFN=3.04s) eta=1d 00:32:17 | 45.6K token/s | 
[epoch_0]_7861   loss=3.549080 |g|=0.401	lr=5.79e-04 | 44.0%@S7  T=1.65s(data=1.6ms QKV=2.10s FFN=3.04s) eta=1d 00:21:01 | 45.8K token/s | 
[epoch_0]_7871   loss=3.492882 |g|=0.419	lr=5.79e-04 | 44.8%@S7  T=1.68s(data=1.6ms QKV=2.10s FFN=3.04s) eta=1d 00:47:34 | 46.0K token/s | 
[epoch_0]_7881   loss=3.474204 |g|=0.454	lr=5.79e-04 | 45.6%@S7  T=1.65s(data=1.5ms QKV=2.10s FFN=3.04s) eta=1d 00:24:34 | 46.2K token/s | 
[epoch_0]_7891   loss=3.536932 |g|=0.409	lr=5.79e-04 | 46.4%@S7  T=1.67s(data=1.5ms QKV=2.10s FFN=3.04s) eta=1d 00:36:10 | 46.3K token/s | 
[Fuyou] head="0" update algorithm=4 t=9.14s
[Section@7900] layer[8-16] tasks=19(nPassBack=0) last_loss=3.54965(-0.0284879) N=(772,9520,8960 1042668)
[epoch_0]_7901   loss=3.491806 |g|=0.373	lr=5.79e-04 | 47.3%@S7  T=4.13s(data=2.0ms QKV=2.10s FFN=3.04s) eta=2d 12:53:14 | 45.0K token/s | 
[epoch_0]_7911   loss=3.523438 |g|=0.422	lr=5.79e-04 | 48.1%@S7  T=1.69s(data=1.7ms QKV=2.10s FFN=3.04s) eta=1d 00:53:21 | 45.2K token/s | 
[epoch_0]_7921   loss=3.505196 |g|=0.381	lr=5.79e-04 | 48.9%@S7  T=1.67s(data=1.6ms QKV=2.10s FFN=3.04s) eta=1d 00:37:41 | 45.4K token/s | 
[epoch_0]_7931   loss=3.483782 |g|=0.386	lr=5.79e-04 | 49.7%@S7  T=1.67s(data=1.6ms QKV=2.10s FFN=3.04s) eta=1d 00:42:26 | 45.5K token/s | 
[epoch_0]_7941   loss=3.589028 |g|=0.432	lr=5.79e-04 | 50.5%@S7  T=1.68s(data=1.5ms QKV=2.10s FFN=3.04s) eta=1d 00:44:39 | 45.7K token/s | 
[epoch_0]_7951   loss=3.493728 |g|=0.449	lr=5.79e-04 | 51.3%@S7  T=1.66s(data=1.7ms QKV=2.10s FFN=3.04s) eta=1d 00:28:04 | 45.9K token/s | 
[epoch_0]_7961   loss=3.595390 |g|=0.429	lr=5.79e-04 | 52.2%@S7  T=1.68s(data=1.6ms QKV=2.10s FFN=3.04s) eta=1d 00:41:39 | 46.0K token/s | 
[epoch_0]_7971   loss=3.622835 |g|=0.421	lr=5.78e-04 | 53.0%@S7  T=1.67s(data=1.5ms QKV=2.10s FFN=3.04s) eta=1d 00:38:27 | 46.2K token/s | 
[epoch_0]_7981   loss=3.498153 |g|=0.402	lr=5.78e-04 | 53.8%@S7  T=1.65s(data=1.5ms QKV=2.10s FFN=3.04s) eta=1d 00:21:07 | 46.4K token/s | 
[epoch_0]_7991   loss=3.469729 |g|=0.417	lr=5.78e-04 | 54.6%@S7  T=1.66s(data=1.5ms QKV=2.10s FFN=3.04s) eta=1d 00:29:54 | 46.5K token/s | 
[Fuyou] head="1" update algorithm=4 t=8.51s
[eval] 
	 Loss@"edu_fineweb1B"=3.564(0.0089) nBranch=1 nToken=6.31M best=3.5731(38) E2T=0.0615 T=36.78(0)s x=0
	#3.56413±0.1005 tps=172K(6.30784M) a=[3.35092,3.82552] T=36.78(sec)
[Section@8000] layer[16-24] tasks=19(nPassBack=0) last_loss=3.50268(0.115248) N=(772,9632,9072 1055868)
[epoch_0]_8001   loss=3.527164 |g|=0.441	lr=5.78e-04 | 55.4%@S7  T=11.32s(data=2.0ms QKV=2.10s FFN=3.04s) eta=6d 22:45:15 | 44.5K token/s | 
[epoch_0]_8011   loss=3.472024 |g|=0.421	lr=5.78e-04 | 56.3%@S7  T=1.66s(data=1.9ms QKV=2.10s FFN=3.04s) eta=1d 00:24:14 | 44.8K token/s | 
[epoch_0]_8021   loss=3.460576 |g|=0.408	lr=5.78e-04 | 57.1%@S7  T=1.68s(data=1.6ms QKV=2.10s FFN=3.04s) eta=1d 00:42:12 | 45.0K token/s | 
[epoch_0]_8031   loss=3.568852 |g|=0.498	lr=5.78e-04 | 57.9%@S7  T=1.65s(data=1.9ms QKV=2.10s FFN=3.04s) eta=1d 00:16:04 | 45.2K token/s | 
[epoch_0]_8041   loss=3.556397 |g|=0.467	lr=5.78e-04 | 58.7%@S7  T=1.66s(data=1.6ms QKV=2.10s FFN=3.04s) eta=1d 00:26:29 | 45.4K token/s | 
[epoch_0]_8051   loss=3.580794 |g|=0.384	lr=5.78e-04 | 59.5%@S7  T=1.64s(data=1.9ms QKV=2.10s FFN=3.04s) eta=1d 00:11:47 | 45.7K token/s | 
[epoch_0]_8061   loss=3.510168 |g|=0.407	lr=5.78e-04 | 60.4%@S7  T=1.67s(data=1.6ms QKV=2.10s FFN=3.04s) eta=1d 00:31:48 | 45.8K token/s | 
[epoch_0]_8071   loss=3.491109 |g|=0.439	lr=5.78e-04 | 61.2%@S7  T=1.67s(data=1.5ms QKV=2.10s FFN=3.04s) eta=1d 00:37:27 | 46.0K token/s | 
[epoch_0]_8081   loss=3.496144 |g|=0.402	lr=5.78e-04 | 62.0%@S7  T=1.67s(data=1.5ms QKV=2.10s FFN=3.04s) eta=1d 00:32:33 | 46.1K token/s | 
[epoch_0]_8091   loss=3.516147 |g|=0.417	lr=5.78e-04 | 62.8%@S7  T=1.68s(data=1.7ms QKV=2.10s FFN=3.04s) eta=1d 00:46:22 | 46.3K token/s | 
[Fuyou] head="2" update algorithm=4 t=10.26s
[Section@8100] layer[24-32] tasks=19(nPassBack=0) last_loss=3.53033(0.0101993) N=(772,9744,9184 1069068)
[epoch_0]_8101   loss=3.470883 |g|=0.363	lr=5.78e-04 | 63.6%@S7  T=4.08s(data=1.8ms QKV=2.10s FFN=3.04s) eta=2d 12:03:54 | 45.0K token/s | 
[epoch_0]_8111   loss=3.531162 |g|=0.445	lr=5.78e-04 | 64.5%@S7  T=1.66s(data=1.9ms QKV=2.10s FFN=3.04s) eta=1d 00:24:54 | 45.2K token/s | 
[epoch_0]_8121   loss=3.556302 |g|=0.436	lr=5.78e-04 | 65.3%@S7  T=1.70s(data=2.1ms QKV=2.10s FFN=3.04s) eta=1d 01:02:09 | 45.3K token/s | 
[epoch_0]_8131   loss=3.574730 |g|=0.426	lr=5.78e-04 | 66.1%@S7  T=1.66s(data=1.6ms QKV=2.10s FFN=3.04s) eta=1d 00:26:14 | 45.5K token/s | 
[epoch_0]_8141   loss=3.404478 |g|=0.41	lr=5.77e-04 | 66.9%@S7  T=1.67s(data=1.6ms QKV=2.10s FFN=3.04s) eta=1d 00:34:28 | 45.7K token/s | 
[epoch_0]_8151   loss=3.532035 |g|=0.467	lr=5.77e-04 | 67.7%@S7  T=1.67s(data=1.6ms QKV=2.10s FFN=3.04s) eta=1d 00:32:12 | 45.9K token/s | 
[epoch_0]_8161   loss=3.516225 |g|=0.474	lr=5.77e-04 | 68.6%@S7  T=1.67s(data=1.5ms QKV=2.10s FFN=3.04s) eta=1d 00:31:58 | 46.0K token/s | 
[epoch_0]_8171   loss=3.597404 |g|=0.388	lr=5.77e-04 | 69.4%@S7  T=1.68s(data=1.7ms QKV=2.10s FFN=3.04s) eta=1d 00:37:50 | 46.2K token/s | 
[epoch_0]_8181   loss=3.522027 |g|=0.438	lr=5.77e-04 | 70.2%@S7  T=1.67s(data=1.9ms QKV=2.10s FFN=3.04s) eta=1d 00:32:11 | 46.3K token/s | 
[epoch_0]_8191   loss=3.505991 |g|=0.423	lr=5.77e-04 | 71.0%@S7  T=1.68s(data=2.1ms QKV=2.10s FFN=3.04s) eta=1d 00:40:28 | 46.4K token/s | 
[Fuyou] head="3" update algorithm=4 t=10.87s
[eval] 
	 Loss@"edu_fineweb1B"=3.554(0.0099) nBranch=1 nToken=6.31M best=3.5641(39) E2T=-0.00302 T=36.7101(0)s x=0
	#3.55423±0.0997 tps=172K(6.30784M) a=[3.33886,3.81514] T=36.7101(sec)
[Section@8200] layer[32-40] tasks=19(nPassBack=0) last_loss=3.55725(-0.0761895) N=(772,9856,9296 1082268)
[epoch_0]_8201   loss=3.523397 |g|=0.419	lr=5.77e-04 | 71.8%@S7  T=11.48s(data=2.0ms QKV=2.10s FFN=3.04s) eta=7d 00:27:44 | 44.5K token/s | 
[epoch_0]_8211   loss=3.554628 |g|=0.365	lr=5.77e-04 | 72.6%@S7  T=1.67s(data=1.7ms QKV=2.10s FFN=3.04s) eta=1d 00:27:52 | 44.7K token/s | 
[epoch_0]_8221   loss=3.510603 |g|=0.39	lr=5.77e-04 | 73.5%@S7  T=1.67s(data=1.9ms QKV=2.10s FFN=3.04s) eta=1d 00:26:51 | 44.9K token/s | 
[epoch_0]_8231   loss=3.573627 |g|=0.412	lr=5.77e-04 | 74.3%@S7  T=1.67s(data=1.7ms QKV=2.10s FFN=3.04s) eta=1d 00:29:36 | 45.1K token/s | 
[epoch_0]_8241   loss=3.564260 |g|=0.416	lr=5.77e-04 | 75.1%@S7  T=1.67s(data=1.8ms QKV=2.10s FFN=3.04s) eta=1d 00:30:01 | 45.3K token/s | 
[epoch_0]_8251   loss=3.490532 |g|=0.444	lr=5.77e-04 | 75.9%@S7  T=1.67s(data=2.0ms QKV=2.10s FFN=3.04s) eta=1d 00:26:58 | 45.5K token/s | 
[epoch_0]_8261   loss=3.484537 |g|=0.392	lr=5.77e-04 | 76.7%@S7  T=1.68s(data=1.7ms QKV=2.10s FFN=3.04s) eta=1d 00:33:36 | 45.7K token/s | 
[epoch_0]_8271   loss=3.457648 |g|=0.409	lr=5.77e-04 | 77.6%@S7  T=1.68s(data=1.5ms QKV=2.10s FFN=3.04s) eta=1d 00:38:31 | 45.8K token/s | 
[epoch_0]_8281   loss=3.570530 |g|=0.441	lr=5.77e-04 | 78.4%@S7  T=1.67s(data=1.5ms QKV=2.10s FFN=3.04s) eta=1d 00:30:22 | 46.0K token/s | 
[epoch_0]_8291   loss=3.558147 |g|=0.408	lr=5.77e-04 | 79.2%@S7  T=1.67s(data=1.5ms QKV=2.10s FFN=3.04s) eta=1d 00:30:08 | 46.1K token/s | 
[Fuyou] head="4" update algorithm=4 t=10.44s
[Section@8300] layer[40-48] tasks=19(nPassBack=0) last_loss=3.47511(0.098484) N=(772,9968,9408 1095468)
[epoch_0]_8301   loss=3.515626 |g|=0.395	lr=5.77e-04 | 80.0%@S7  T=4.31s(data=1.7ms QKV=2.10s FFN=3.04s) eta=2d 15:08:08 | 44.8K token/s | 
[epoch_0]_8311   loss=3.543936 |g|=0.391	lr=5.76e-04 | 80.8%@S7  T=1.67s(data=1.5ms QKV=2.10s FFN=3.04s) eta=1d 00:23:39 | 45.0K token/s | 
[epoch_0]_8321   loss=3.489148 |g|=0.444	lr=5.76e-04 | 81.7%@S7  T=1.68s(data=1.8ms QKV=2.10s FFN=3.04s) eta=1d 00:33:14 | 45.2K token/s | 
[epoch_0]_8331   loss=3.515925 |g|=0.436	lr=5.76e-04 | 82.5%@S7  T=1.65s(data=2.0ms QKV=2.10s FFN=3.04s) eta=1d 00:06:45 | 45.4K token/s | 
[epoch_0]_8341   loss=3.463091 |g|=0.404	lr=5.76e-04 | 83.3%@S7  T=1.67s(data=1.7ms QKV=2.10s FFN=3.04s) eta=1d 00:24:51 | 45.6K token/s | 
[epoch_0]_8351   loss=3.448945 |g|=0.386	lr=5.76e-04 | 84.1%@S7  T=1.68s(data=1.6ms QKV=2.10s FFN=3.04s) eta=1d 00:36:06 | 45.8K token/s | 
[epoch_0]_8361   loss=3.476548 |g|=0.406	lr=5.76e-04 | 84.9%@S7  T=1.67s(data=1.6ms QKV=2.10s FFN=3.04s) eta=1d 00:26:32 | 45.9K token/s | 
[epoch_0]_8371   loss=3.484963 |g|=0.41	lr=5.76e-04 | 85.8%@S7  T=1.68s(data=1.5ms QKV=2.10s FFN=3.04s) eta=1d 00:36:44 | 46.1K token/s | 
[epoch_0]_8381   loss=3.445427 |g|=0.408	lr=5.76e-04 | 86.6%@S7  T=1.68s(data=1.6ms QKV=2.10s FFN=3.04s) eta=1d 00:31:17 | 46.2K token/s | 
[epoch_0]_8391   loss=3.436002 |g|=0.409	lr=5.76e-04 | 87.4%@S7  T=1.67s(data=1.5ms QKV=2.10s FFN=3.04s) eta=1d 00:27:07 | 46.3K token/s | 
[Fuyou] head="5" update algorithm=4 t=11.09s
[eval] 
	 Loss@"edu_fineweb1B"=3.548(0.0061) nBranch=1 nToken=6.31M best=3.5542(40) E2T=0.0336 T=36.7018(0)s x=0
	#3.5481±0.1008 tps=172K(6.30784M) a=[3.33198,3.81737] T=36.7018(sec)
[Section@8400] layer[0-8] tasks=19(nPassBack=0) last_loss=3.51447(0.0309963) N=(772,10080,9520 1108668)
[epoch_0]_8401   loss=3.504303 |g|=0.485	lr=5.76e-04 | 88.2%@S7  T=11.45s(data=2.2ms QKV=2.10s FFN=3.04s) eta=6d 23:22:26 | 44.4K token/s | 
[epoch_0]_8411   loss=3.542745 |g|=0.403	lr=5.76e-04 | 89.0%@S7  T=1.68s(data=1.7ms QKV=2.10s FFN=3.04s) eta=1d 00:34:33 | 44.6K token/s | 
[epoch_0]_8421   loss=3.464653 |g|=0.407	lr=5.76e-04 | 89.9%@S7  T=1.65s(data=1.6ms QKV=2.10s FFN=3.04s) eta=1d 00:04:19 | 44.9K token/s | 
[epoch_0]_8431   loss=3.602444 |g|=0.41	lr=5.76e-04 | 90.7%@S7  T=1.67s(data=2.0ms QKV=2.10s FFN=3.04s) eta=1d 00:24:59 | 45.1K token/s | 
[epoch_0]_8441   loss=3.483792 |g|=0.422	lr=5.76e-04 | 91.5%@S7  T=1.68s(data=1.7ms QKV=2.10s FFN=3.04s) eta=1d 00:34:32 | 45.2K token/s | 
[epoch_0]_8451   loss=3.514786 |g|=0.38	lr=5.76e-04 | 92.3%@S7  T=1.68s(data=1.6ms QKV=2.10s FFN=3.04s) eta=1d 00:30:51 | 45.4K token/s | 
[epoch_0]_8461   loss=3.488492 |g|=0.453	lr=5.76e-04 | 93.1%@S7  T=1.68s(data=2.3ms QKV=2.10s FFN=3.04s) eta=1d 00:31:35 | 45.6K token/s | 
[epoch_0]_8471   loss=3.503751 |g|=0.44	lr=5.75e-04 | 93.9%@S7  T=1.65s(data=1.5ms QKV=2.10s FFN=3.04s) eta=1d 00:05:31 | 45.8K token/s | 
[epoch_0]_8481   loss=3.515792 |g|=0.389	lr=5.75e-04 | 94.8%@S7  T=1.65s(data=1.6ms QKV=2.10s FFN=3.04s) eta=1d 00:06:05 | 46.0K token/s | 
[epoch_0]_8491   loss=3.505370 |g|=0.383	lr=5.75e-04 | 95.6%@S7  T=1.69s(data=1.5ms QKV=2.10s FFN=3.04s) eta=1d 00:38:51 | 46.1K token/s | 
[Fuyou] head="0" update algorithm=4 t=6.23s
[Section@8500] layer[8-16] tasks=19(nPassBack=0) last_loss=3.44181(0.107835) N=(772,10192,9632 1121868)
[epoch_0]_8501   loss=3.517910 |g|=0.377	lr=5.75e-04 | 96.4%@S7  T=4.13s(data=1.7ms QKV=2.10s FFN=3.03s) eta=2d 12:19:09 | 44.8K token/s | 
[epoch_0]_8511   loss=3.492678 |g|=0.423	lr=5.75e-04 | 97.2%@S7  T=1.65s(data=2.2ms QKV=2.10s FFN=3.04s) eta=1d 00:01:58 | 45.0K token/s | 
[epoch_0]_8521   loss=3.511056 |g|=0.481	lr=5.75e-04 | 98.0%@S7  T=1.68s(data=1.8ms QKV=2.10s FFN=3.04s) eta=1d 00:27:13 | 45.2K token/s | 
[epoch_0]_8531   loss=3.541211 |g|=0.477	lr=5.75e-04 | 98.9%@S7  T=1.67s(data=1.6ms QKV=2.10s FFN=3.04s) eta=1d 00:22:20 | 45.4K token/s | 
[epoch_0]_8541   loss=3.593596 |g|=0.407	lr=5.75e-04 | 99.7%@S7  T=1.67s(data=1.7ms QKV=2.10s FFN=3.04s) eta=1d 00:22:30 | 45.6K token/s | 
[epoch_0]_8544   loss=3.465715 |g|=0.419	lr=5.75e-04 | 99.9%@S7  T=1.67s(data=1.7ms QKV=2.10s FFN=3.04s) eta=1d 00:21:58 | 45.8K token/s | 
-------- End of shard_7@"./Datasets/edu_fineweb1B/edu_fineweb_train_000007.bin"-------- 
[shard-8]@"./Datasets/edu_fineweb1B/edu_fineweb_train_000008.bin": tokens=100(M) nShardSamples=1220(781248) 
[epoch_0]_8551   loss=3.555371 |g|=0.429	lr=5.75e-04 | 0.5%@S8  T=1.67s(data=1.5ms QKV=2.10s FFN=3.04s) eta=1d 00:24:31 | 45.9K token/s | 
[epoch_0]_8561   loss=3.605929 |g|=0.393	lr=5.75e-04 | 1.3%@S8  T=1.67s(data=1.3ms QKV=2.10s FFN=3.04s) eta=1d 00:21:17 | 46.1K token/s | 
[epoch_0]_8571   loss=3.504824 |g|=0.421	lr=5.75e-04 | 2.1%@S8  T=1.67s(data=1.2ms QKV=2.10s FFN=3.04s) eta=1d 00:19:59 | 46.2K token/s | 
[epoch_0]_8581   loss=3.547659 |g|=0.414	lr=5.75e-04 | 3.0%@S8  T=1.67s(data=1.4ms QKV=2.10s FFN=3.04s) eta=1d 00:21:43 | 46.4K token/s | 
[epoch_0]_8591   loss=3.517797 |g|=0.422	lr=5.75e-04 | 3.8%@S8  T=1.67s(data=1.4ms QKV=2.10s FFN=3.04s) eta=1d 00:15:43 | 46.5K token/s | 
[Fuyou] head="1" update algorithm=4 t=9.73s
[eval] 
	 Loss@"edu_fineweb1B"=3.540(0.008) nBranch=1 nToken=6.31M best=3.5481(41) E2T=-0.00175 T=36.7236(0)s x=0
	#3.54014±0.1002 tps=172K(6.30784M) a=[3.32929,3.80514] T=36.7236(sec)
[Section@8600] layer[16-24] tasks=19(nPassBack=0) last_loss=3.54189(-0.0392122) N=(772,10304,9744 1135068)
[epoch_0]_8601   loss=3.601969 |g|=0.416	lr=5.75e-04 | 4.6%@S8  T=11.28s(data=1.5ms QKV=2.10s FFN=3.04s) eta=6d 20:19:30 | 44.6K token/s | 
[epoch_0]_8611   loss=3.491831 |g|=0.411	lr=5.75e-04 | 5.4%@S8  T=1.64s(data=1.7ms QKV=2.10s FFN=3.04s) eta=23:52:57 | 44.8K token/s | 
[epoch_0]_8621   loss=3.519559 |g|=0.416	lr=5.75e-04 | 6.2%@S8  T=1.66s(data=1.5ms QKV=2.10s FFN=3.04s) eta=1d 00:11:39 | 45.0K token/s | 
[epoch_0]_8631   loss=3.557666 |g|=0.366	lr=5.74e-04 | 7.1%@S8  T=1.67s(data=1.7ms QKV=2.10s FFN=3.04s) eta=1d 00:22:15 | 45.2K token/s | 
[epoch_0]_8641   loss=3.584184 |g|=0.419	lr=5.74e-04 | 7.9%@S8  T=1.67s(data=1.9ms QKV=2.10s FFN=3.04s) eta=1d 00:22:10 | 45.4K token/s | 
[epoch_0]_8651   loss=3.565210 |g|=0.404	lr=5.74e-04 | 8.7%@S8  T=1.66s(data=2.1ms QKV=2.10s FFN=3.04s) eta=1d 00:07:26 | 45.6K token/s | 
[epoch_0]_8661   loss=3.515426 |g|=0.462	lr=5.74e-04 | 9.5%@S8  T=1.69s(data=1.5ms QKV=2.10s FFN=3.04s) eta=1d 00:31:36 | 45.8K token/s | 
[epoch_0]_8671   loss=3.627126 |g|=0.408	lr=5.74e-04 | 10.3%@S8  T=1.68s(data=1.7ms QKV=2.10s FFN=3.04s) eta=1d 00:27:41 | 45.9K token/s | 
[epoch_0]_8681   loss=3.584229 |g|=0.443	lr=5.74e-04 | 11.2%@S8  T=1.67s(data=1.6ms QKV=2.10s FFN=3.04s) eta=1d 00:19:47 | 46.1K token/s | 
[epoch_0]_8691   loss=3.620252 |g|=0.405	lr=5.74e-04 | 12.0%@S8  T=1.70s(data=1.6ms QKV=2.10s FFN=3.04s) eta=1d 00:41:11 | 46.2K token/s | 
[Fuyou] head="2" update algorithm=4 t=9.07s
[Section@8700] layer[24-32] tasks=19(nPassBack=0) last_loss=3.56815(-0.0378215) N=(772,10416,9856 1148268)
[epoch_0]_8701   loss=3.552173 |g|=0.397	lr=5.74e-04 | 12.8%@S8  T=4.19s(data=2.1ms QKV=2.10s FFN=3.03s) eta=2d 12:57:52 | 44.8K token/s | 
[epoch_0]_8711   loss=3.566778 |g|=0.42	lr=5.74e-04 | 13.6%@S8  T=1.64s(data=1.9ms QKV=2.10s FFN=3.04s) eta=23:50:09 | 45.1K token/s | 
[epoch_0]_8721   loss=3.597840 |g|=0.434	lr=5.74e-04 | 14.4%@S8  T=1.64s(data=1.6ms QKV=2.10s FFN=3.04s) eta=23:50:35 | 45.3K token/s | 
[epoch_0]_8731   loss=3.596987 |g|=0.4	lr=5.74e-04 | 15.2%@S8  T=1.64s(data=1.9ms QKV=2.10s FFN=3.04s) eta=23:51:52 | 45.6K token/s | 
[epoch_0]_8741   loss=3.509685 |g|=0.387	lr=5.74e-04 | 16.1%@S8  T=1.64s(data=1.8ms QKV=2.10s FFN=3.04s) eta=23:50:45 | 45.8K token/s | 
[epoch_0]_8751   loss=3.577429 |g|=0.401	lr=5.74e-04 | 16.9%@S8  T=1.70s(data=1.6ms QKV=2.10s FFN=3.04s) eta=1d 00:42:31 | 45.9K token/s | 
[epoch_0]_8761   loss=3.485436 |g|=0.396	lr=5.74e-04 | 17.7%@S8  T=1.65s(data=1.9ms QKV=2.10s FFN=3.04s) eta=23:59:26 | 46.1K token/s | 
[epoch_0]_8771   loss=3.542066 |g|=0.4	lr=5.74e-04 | 18.5%@S8  T=1.68s(data=1.6ms QKV=2.10s FFN=3.04s) eta=1d 00:21:40 | 46.2K token/s | 
[epoch_0]_8781   loss=3.524679 |g|=0.401	lr=5.74e-04 | 19.3%@S8  T=1.65s(data=1.7ms QKV=2.10s FFN=3.04s) eta=23:58:25 | 46.4K token/s | 
[epoch_0]_8791   loss=3.488801 |g|=0.46	lr=5.73e-04 | 20.2%@S8  T=1.65s(data=1.8ms QKV=2.10s FFN=3.04s) eta=23:59:52 | 46.6K token/s | 
[Fuyou] head="3" update algorithm=4 t=9.41s
[eval] 
	 Loss@"edu_fineweb1B"=3.535(0.0054) nBranch=1 nToken=6.31M best=3.5401(42) E2T=-0.0357 T=36.7095(0)s x=0
	#3.53471±0.1002 tps=172K(6.30784M) a=[3.32595,3.80653] T=36.7095(sec)
[Section@8800] layer[32-40] tasks=19(nPassBack=0) last_loss=3.57037(-0.0131218) N=(772,10528,9968 1161468)
[epoch_0]_8801   loss=3.516943 |g|=0.378	lr=5.73e-04 | 21.0%@S8  T=11.25s(data=1.6ms QKV=2.10s FFN=3.04s) eta=6d 19:11:14 | 44.6K token/s | 
[epoch_0]_8811   loss=3.526463 |g|=0.41	lr=5.73e-04 | 21.8%@S8  T=1.65s(data=1.6ms QKV=2.10s FFN=3.04s) eta=23:55:58 | 44.8K token/s | 
[epoch_0]_8821   loss=3.527081 |g|=0.401	lr=5.73e-04 | 22.6%@S8  T=1.68s(data=2.4ms QKV=2.10s FFN=3.04s) eta=1d 00:26:01 | 45.0K token/s | 
[epoch_0]_8831   loss=3.564033 |g|=0.416	lr=5.73e-04 | 23.4%@S8  T=1.67s(data=1.7ms QKV=2.10s FFN=3.04s) eta=1d 00:16:41 | 45.2K token/s | 
[epoch_0]_8841   loss=3.506708 |g|=0.426	lr=5.73e-04 | 24.3%@S8  T=1.67s(data=1.7ms QKV=2.10s FFN=3.04s) eta=1d 00:09:03 | 45.4K token/s | 
[epoch_0]_8851   loss=3.585576 |g|=0.424	lr=5.73e-04 | 25.1%@S8  T=1.65s(data=1.9ms QKV=2.10s FFN=3.04s) eta=23:51:55 | 45.6K token/s | 
[epoch_0]_8861   loss=3.581837 |g|=0.422	lr=5.73e-04 | 25.9%@S8  T=1.65s(data=1.7ms QKV=2.10s FFN=3.04s) eta=23:50:54 | 45.8K token/s | 
[epoch_0]_8871   loss=3.505278 |g|=0.393	lr=5.73e-04 | 26.7%@S8  T=1.67s(data=1.5ms QKV=2.10s FFN=3.04s) eta=1d 00:16:13 | 46.0K token/s | 
[epoch_0]_8881   loss=3.532247 |g|=0.383	lr=5.73e-04 | 27.5%@S8  T=1.64s(data=1.7ms QKV=2.10s FFN=3.04s) eta=23:49:44 | 46.2K token/s | 
[epoch_0]_8891   loss=3.524681 |g|=0.421	lr=5.73e-04 | 28.4%@S8  T=1.65s(data=2.1ms QKV=2.10s FFN=3.04s) eta=23:50:10 | 46.4K token/s | 
[Fuyou] head="4" update algorithm=4 t=10.44s
[Section@8900] layer[40-48] tasks=19(nPassBack=0) last_loss=3.54379(-0.0686855) N=(772,10640,10080 1174668)
[epoch_0]_8901   loss=3.559092 |g|=0.425	lr=5.73e-04 | 29.2%@S8  T=4.01s(data=1.5ms QKV=2.10s FFN=3.03s) eta=2d 10:01:25 | 45.1K token/s | 
[epoch_0]_8911   loss=3.514171 |g|=0.411	lr=5.73e-04 | 30.0%@S8  T=1.64s(data=1.8ms QKV=2.10s FFN=3.04s) eta=23:44:26 | 45.3K token/s | 
[epoch_0]_8921   loss=3.560546 |g|=0.418	lr=5.73e-04 | 30.8%@S8  T=1.64s(data=1.7ms QKV=2.10s FFN=3.04s) eta=23:45:30 | 45.5K token/s | 
[epoch_0]_8931   loss=3.559622 |g|=0.454	lr=5.73e-04 | 31.6%@S8  T=1.65s(data=1.5ms QKV=2.10s FFN=3.04s) eta=23:53:29 | 45.8K token/s | 
[epoch_0]_8941   loss=3.453813 |g|=0.41	lr=5.73e-04 | 32.4%@S8  T=1.64s(data=1.6ms QKV=2.10s FFN=3.04s) eta=23:45:18 | 46.0K token/s | 
[epoch_0]_8951   loss=3.480639 |g|=0.413	lr=5.72e-04 | 33.3%@S8  T=1.65s(data=1.6ms QKV=2.10s FFN=3.04s) eta=23:48:54 | 46.1K token/s | 
[epoch_0]_8961   loss=3.577052 |g|=0.415	lr=5.72e-04 | 34.1%@S8  T=1.66s(data=1.9ms QKV=2.10s FFN=3.04s) eta=1d 00:01:19 | 46.3K token/s | 
[epoch_0]_8971   loss=3.517233 |g|=0.428	lr=5.72e-04 | 34.9%@S8  T=1.65s(data=2.1ms QKV=2.10s FFN=3.04s) eta=23:51:23 | 46.5K token/s | 
[epoch_0]_8981   loss=3.560538 |g|=0.397	lr=5.72e-04 | 35.7%@S8  T=1.67s(data=1.9ms QKV=2.10s FFN=3.04s) eta=1d 00:07:49 | 46.6K token/s | 
[epoch_0]_8991   loss=3.560937 |g|=0.394	lr=5.72e-04 | 36.5%@S8  T=1.65s(data=1.9ms QKV=2.10s FFN=3.04s) eta=23:48:24 | 46.8K token/s | 
[Fuyou] head="5" update algorithm=4 t=10.92s
[eval] 
	 Loss@"edu_fineweb1B"=3.532(0.0027) nBranch=1 nToken=6.31M best=3.5347(43) E2T=0.0441 T=36.706(0)s x=0
	#3.53205±0.1002 tps=172K(6.30784M) a=[3.33188,3.80351] T=36.706(sec)
[Section@9000] layer[0-8] tasks=19(nPassBack=0) last_loss=3.48791(0.0265565) N=(772,10752,10192 1187868)
[epoch_0]_9001   loss=3.547402 |g|=0.405	lr=5.72e-04 | 37.4%@S8  T=11.63s(data=1.5ms QKV=2.10s FFN=3.04s) eta=7d 00:06:17 | 44.8K token/s | 
[epoch_0]_9011   loss=3.538059 |g|=0.426	lr=5.72e-04 | 38.2%@S8  T=1.64s(data=1.7ms QKV=2.10s FFN=3.04s) eta=23:44:40 | 45.0K token/s | 
[epoch_0]_9021   loss=3.418710 |g|=0.418	lr=5.72e-04 | 39.0%@S8  T=1.64s(data=1.6ms QKV=2.10s FFN=3.04s) eta=23:45:08 | 45.3K token/s | 
[epoch_0]_9031   loss=3.605114 |g|=0.383	lr=5.72e-04 | 39.8%@S8  T=1.67s(data=1.9ms QKV=2.10s FFN=3.04s) eta=1d 00:07:59 | 45.5K token/s | 
[epoch_0]_9041   loss=3.576124 |g|=0.452	lr=5.72e-04 | 40.6%@S8  T=1.67s(data=1.6ms QKV=2.10s FFN=3.04s) eta=1d 00:06:26 | 45.6K token/s | 
[epoch_0]_9051   loss=3.599801 |g|=0.417	lr=5.72e-04 | 41.5%@S8  T=1.64s(data=2.0ms QKV=2.10s FFN=3.04s) eta=23:44:18 | 45.9K token/s | 
[epoch_0]_9061   loss=3.524263 |g|=0.39	lr=5.72e-04 | 42.3%@S8  T=1.65s(data=1.8ms QKV=2.10s FFN=3.04s) eta=23:47:43 | 46.0K token/s | 
[epoch_0]_9071   loss=3.563469 |g|=0.399	lr=5.72e-04 | 43.1%@S8  T=1.67s(data=1.6ms QKV=2.10s FFN=3.04s) eta=1d 00:06:30 | 46.2K token/s | 
[epoch_0]_9081   loss=3.569952 |g|=0.401	lr=5.72e-04 | 43.9%@S8  T=1.66s(data=1.6ms QKV=2.10s FFN=3.04s) eta=1d 25 | 46.3K token/s | 
[epoch_0]_9091   loss=3.502243 |g|=0.407	lr=5.72e-04 | 44.7%@S8  T=1.65s(data=1.8ms QKV=2.10s FFN=3.04s) eta=23:44:17 | 46.5K token/s | 
[Fuyou] head="0" update algorithm=4 t=7.03s
[Section@9100] layer[8-16] tasks=19(nPassBack=0) last_loss=3.52415(-0.0823343) N=(772,10864,10304 1201068)
[epoch_0]_9101   loss=3.544574 |g|=0.398	lr=5.71e-04 | 45.6%@S8  T=3.92s(data=1.8ms QKV=2.10s FFN=3.03s) eta=2d 08:35:12 | 45.2K token/s | 
[epoch_0]_9111   loss=3.545882 |g|=0.409	lr=5.71e-04 | 46.4%@S8  T=1.66s(data=1.6ms QKV=2.10s FFN=3.04s) eta=23:58:45 | 45.4K token/s | 
[epoch_0]_9121   loss=3.506504 |g|=0.402	lr=5.71e-04 | 47.2%@S8  T=1.65s(data=1.8ms QKV=2.10s FFN=3.04s) eta=23:45:27 | 45.7K token/s | 
[epoch_0]_9131   loss=3.492410 |g|=0.409	lr=5.71e-04 | 48.0%@S8  T=1.64s(data=1.6ms QKV=2.10s FFN=3.04s) eta=23:37:16 | 45.9K token/s | 
[epoch_0]_9141   loss=3.535117 |g|=0.43	lr=5.71e-04 | 48.8%@S8  T=1.66s(data=1.6ms QKV=2.10s FFN=3.04s) eta=23:58:14 | 46.0K token/s | 
[epoch_0]_9151   loss=3.484031 |g|=0.401	lr=5.71e-04 | 49.7%@S8  T=1.65s(data=1.5ms QKV=2.10s FFN=3.04s) eta=23:44:45 | 46.2K token/s | 
[epoch_0]_9161   loss=3.547323 |g|=0.42	lr=5.71e-04 | 50.5%@S8  T=1.65s(data=1.5ms QKV=2.10s FFN=3.04s) eta=23:45:38 | 46.4K token/s | 
[epoch_0]_9171   loss=3.492239 |g|=0.375	lr=5.71e-04 | 51.3%@S8  T=1.65s(data=1.6ms QKV=2.10s FFN=3.04s) eta=23:46:17 | 46.6K token/s | 
[epoch_0]_9181   loss=3.485401 |g|=0.392	lr=5.71e-04 | 52.1%@S8  T=1.67s(data=1.7ms QKV=2.10s FFN=3.04s) eta=1d 00:01:45 | 46.7K token/s | 
[epoch_0]_9191   loss=3.533409 |g|=0.406	lr=5.71e-04 | 52.9%@S8  T=1.65s(data=1.7ms QKV=2.10s FFN=3.04s) eta=23:44:46 | 46.8K token/s | 
[Fuyou] head="1" update algorithm=4 t=9.52s
[eval] 
	 Loss@"edu_fineweb1B"=3.525(0.0075) nBranch=1 nToken=6.31M best=3.5321(44) E2T=0.0118 T=36.7405(0)s x=0
	#3.52457±0.0997 tps=172K(6.30784M) a=[3.32065,3.79735] T=36.7405(sec)
[Section@9200] layer[16-24] tasks=19(nPassBack=0) last_loss=3.51274(0.0291533) N=(772,10976,10416 1214268)
[epoch_0]_9201   loss=3.539356 |g|=0.462	lr=5.71e-04 | 53.7%@S8  T=11.54s(data=2.7ms QKV=2.10s FFN=3.04s) eta=6d 22:10:49 | 44.8K token/s | 
[epoch_0]_9211   loss=3.481971 |g|=0.395	lr=5.71e-04 | 54.6%@S8  T=1.64s(data=1.9ms QKV=2.10s FFN=3.04s) eta=23:38:57 | 45.1K token/s | 
[epoch_0]_9221   loss=3.568367 |g|=0.442	lr=5.71e-04 | 55.4%@S8  T=1.68s(data=1.6ms QKV=2.10s FFN=3.04s) eta=1d 00:10:59 | 45.3K token/s | 
[epoch_0]_9231   loss=3.462729 |g|=0.431	lr=5.71e-04 | 56.2%@S8  T=1.68s(data=1.6ms QKV=2.10s FFN=3.04s) eta=1d 00:10:56 | 45.5K token/s | 
[epoch_0]_9241   loss=3.527453 |g|=0.399	lr=5.71e-04 | 57.0%@S8  T=1.67s(data=1.8ms QKV=2.10s FFN=3.04s) eta=1d 00:02:14 | 45.6K token/s | 
[epoch_0]_9251   loss=3.535703 |g|=0.391	lr=5.70e-04 | 57.8%@S8  T=1.67s(data=1.7ms QKV=2.10s FFN=3.04s) eta=23:59:56 | 45.8K token/s | 
[epoch_0]_9261   loss=3.479198 |g|=0.42	lr=5.70e-04 | 58.7%@S8  T=1.68s(data=1.6ms QKV=2.10s FFN=3.04s) eta=1d 00:06:47 | 46.0K token/s | 
[epoch_0]_9271   loss=3.477506 |g|=0.384	lr=5.70e-04 | 59.5%@S8  T=1.68s(data=1.5ms QKV=2.10s FFN=3.04s) eta=1d 00:07:28 | 46.1K token/s | 
[epoch_0]_9281   loss=3.571831 |g|=0.39	lr=5.70e-04 | 60.3%@S8  T=1.65s(data=1.5ms QKV=2.10s FFN=3.04s) eta=23:40:55 | 46.3K token/s | 
[epoch_0]_9291   loss=3.568332 |g|=0.418	lr=5.70e-04 | 61.1%@S8  T=1.67s(data=1.7ms QKV=2.10s FFN=3.04s) eta=1d 49 | 46.4K token/s | 
[Fuyou] head="2" update algorithm=4 t=10.49s
[Section@9300] layer[24-32] tasks=19(nPassBack=0) last_loss=3.48568(0.0824668) N=(772,11088,10528 1227468)
[epoch_0]_9301   loss=3.443848 |g|=0.429	lr=5.70e-04 | 61.9%@S8  T=4.16s(data=3.3ms QKV=2.10s FFN=3.04s) eta=2d 11:47:53 | 45.1K token/s | 
[epoch_0]_9311   loss=3.556448 |g|=0.435	lr=5.70e-04 | 62.8%@S8  T=1.64s(data=1.9ms QKV=2.10s FFN=3.04s) eta=23:30:41 | 45.3K token/s | 
[epoch_0]_9321   loss=3.506453 |g|=0.389	lr=5.70e-04 | 63.6%@S8  T=1.64s(data=1.6ms QKV=2.10s FFN=3.04s) eta=23:31:50 | 45.6K token/s | 
[epoch_0]_9331   loss=3.526617 |g|=0.401	lr=5.70e-04 | 64.4%@S8  T=1.67s(data=1.6ms QKV=2.10s FFN=3.04s) eta=1d 00:02:54 | 45.7K token/s | 
[epoch_0]_9341   loss=3.539294 |g|=0.384	lr=5.70e-04 | 65.2%@S8  T=1.66s(data=1.6ms QKV=2.10s FFN=3.04s) eta=23:47:21 | 45.9K token/s | 
[epoch_0]_9351   loss=3.585354 |g|=0.386	lr=5.70e-04 | 66.0%@S8  T=1.66s(data=1.5ms QKV=2.10s FFN=3.04s) eta=23:47:54 | 46.1K token/s | 
[epoch_0]_9361   loss=3.535195 |g|=0.379	lr=5.70e-04 | 66.9%@S8  T=1.68s(data=1.5ms QKV=2.10s FFN=3.04s) eta=1d 00:04:43 | 46.2K token/s | 
[epoch_0]_9371   loss=3.472569 |g|=0.38	lr=5.70e-04 | 67.7%@S8  T=1.67s(data=1.6ms QKV=2.10s FFN=3.04s) eta=23:55:53 | 46.4K token/s | 
[epoch_0]_9381   loss=3.534351 |g|=0.402	lr=5.70e-04 | 68.5%@S8  T=1.65s(data=1.6ms QKV=2.10s FFN=3.04s) eta=23:40:25 | 46.5K token/s | 
[epoch_0]_9391   loss=3.508520 |g|=0.393	lr=5.70e-04 | 69.3%@S8  T=1.65s(data=1.5ms QKV=2.10s FFN=3.04s) eta=23:44:09 | 46.7K token/s | 
[Fuyou] head="3" update algorithm=4 t=12.00s
[eval] 
	 Loss@"edu_fineweb1B"=3.519(0.0057) nBranch=1 nToken=6.31M best=3.5246(45) E2T=-0.0333 T=36.7414(0)s x=0
	#3.51886±0.1002 tps=172K(6.30784M) a=[3.31976,3.78804] T=36.7414(sec)
[Section@9400] layer[32-40] tasks=19(nPassBack=0) last_loss=3.55217(0.0182073) N=(772,11200,10640 1240668)
[epoch_0]_9401   loss=3.436064 |g|=0.41	lr=5.69e-04 | 70.1%@S8  T=11.62s(data=1.9ms QKV=2.10s FFN=3.04s) eta=6d 22:43:24 | 44.7K token/s | 
[epoch_0]_9411   loss=3.543766 |g|=0.428	lr=5.69e-04 | 71.0%@S8  T=1.65s(data=1.9ms QKV=2.10s FFN=3.04s) eta=23:37:09 | 45.0K token/s | 
[epoch_0]_9421   loss=3.543417 |g|=0.443	lr=5.69e-04 | 71.8%@S8  T=1.68s(data=1.6ms QKV=2.10s FFN=3.04s) eta=1d 00:05:17 | 45.1K token/s | 
[epoch_0]_9431   loss=3.503743 |g|=0.441	lr=5.69e-04 | 72.6%@S8  T=1.64s(data=1.8ms QKV=2.10s FFN=3.04s) eta=23:34:08 | 45.4K token/s | 
[epoch_0]_9441   loss=3.491665 |g|=0.417	lr=5.69e-04 | 73.4%@S8  T=1.66s(data=1.6ms QKV=2.10s FFN=3.04s) eta=23:48:18 | 45.6K token/s | 
[epoch_0]_9451   loss=3.566597 |g|=0.406	lr=5.69e-04 | 74.2%@S8  T=1.68s(data=1.6ms QKV=2.10s FFN=3.04s) eta=1d 00:05:52 | 45.7K token/s | 
[epoch_0]_9461   loss=3.566375 |g|=0.422	lr=5.69e-04 | 75.0%@S8  T=1.68s(data=1.8ms QKV=2.10s FFN=3.04s) eta=1d 00:02:54 | 45.9K token/s | 
[epoch_0]_9471   loss=3.479535 |g|=0.399	lr=5.69e-04 | 75.9%@S8  T=1.68s(data=1.6ms QKV=2.10s FFN=3.04s) eta=1d 00:05:56 | 46.0K token/s | 
[epoch_0]_9481   loss=3.432039 |g|=0.36	lr=5.69e-04 | 76.7%@S8  T=1.69s(data=1.5ms QKV=2.10s FFN=3.04s) eta=1d 00:08:48 | 46.2K token/s | 
[epoch_0]_9491   loss=3.552077 |g|=0.394	lr=5.69e-04 | 77.5%@S8  T=1.66s(data=1.7ms QKV=2.10s FFN=3.04s) eta=23:43:45 | 46.3K token/s | 
[Fuyou] head="4" update algorithm=4 t=11.78s
[Section@9500] layer[40-48] tasks=19(nPassBack=0) last_loss=3.48321(0.0605834) N=(772,11312,10752 1253868)
[epoch_0]_9501   loss=3.560464 |g|=0.396	lr=5.69e-04 | 78.3%@S8  T=4.07s(data=1.7ms QKV=2.10s FFN=3.04s) eta=2d 10:13:02 | 45.0K token/s | 
[epoch_0]_9511   loss=3.474239 |g|=0.413	lr=5.69e-04 | 79.1%@S8  T=1.64s(data=2.0ms QKV=2.10s FFN=3.04s) eta=23:30:27 | 45.3K token/s | 
[epoch_0]_9521   loss=3.555226 |g|=0.442	lr=5.69e-04 | 80.0%@S8  T=1.68s(data=1.6ms QKV=2.10s FFN=3.04s) eta=1d 00:03:15 | 45.4K token/s | 
[epoch_0]_9531   loss=3.478816 |g|=0.407	lr=5.69e-04 | 80.8%@S8  T=1.67s(data=1.5ms QKV=2.10s FFN=3.04s) eta=23:57:33 | 45.6K token/s | 
[epoch_0]_9541   loss=3.533074 |g|=0.457	lr=5.68e-04 | 81.6%@S8  T=1.69s(data=1.6ms QKV=2.10s FFN=3.04s) eta=1d 00:10:16 | 45.7K token/s | 
[epoch_0]_9551   loss=3.515389 |g|=0.393	lr=5.68e-04 | 82.4%@S8  T=1.65s(data=1.9ms QKV=2.10s FFN=3.04s) eta=23:35:31 | 45.9K token/s | 
[epoch_0]_9561   loss=3.493128 |g|=0.364	lr=5.68e-04 | 83.2%@S8  T=1.69s(data=1.6ms QKV=2.10s FFN=3.04s) eta=1d 00:11:53 | 46.1K token/s | 
[epoch_0]_9571   loss=3.529566 |g|=0.411	lr=5.68e-04 | 84.1%@S8  T=1.68s(data=1.6ms QKV=2.10s FFN=3.04s) eta=23:57:48 | 46.2K token/s | 
[epoch_0]_9581   loss=3.509832 |g|=0.382	lr=5.68e-04 | 84.9%@S8  T=1.67s(data=1.9ms QKV=2.10s FFN=3.04s) eta=23:50:57 | 46.4K token/s | 
[epoch_0]_9591   loss=3.530048 |g|=0.425	lr=5.68e-04 | 85.7%@S8  T=1.67s(data=1.6ms QKV=2.10s FFN=3.04s) eta=23:51:55 | 46.5K token/s | 
[Fuyou] head="5" update algorithm=4 t=10.32s
[eval] 
	 Loss@"edu_fineweb1B"=3.515(0.0036) nBranch=1 nToken=6.31M best=3.5189(46) E2T=-0.0518 T=36.7049(0)s x=0
	#3.51528±0.0997 tps=172K(6.30784M) a=[3.31247,3.78372] T=36.7049(sec)
[Section@9600] layer[0-8] tasks=19(nPassBack=0) last_loss=3.56704(-0.0791297) N=(772,11424,10864 1267068)
[epoch_0]_9601   loss=3.609146 |g|=0.444	lr=5.68e-04 | 86.5%@S8  T=11.88s(data=2.3ms QKV=2.10s FFN=3.04s) eta=7d 01:41:01 | 44.5K token/s | 
[epoch_0]_9611   loss=3.391284 |g|=0.421	lr=5.68e-04 | 87.3%@S8  T=1.69s(data=1.8ms QKV=2.10s FFN=3.05s) eta=1d 00:06:51 | 44.7K token/s | 
[epoch_0]_9621   loss=3.409942 |g|=0.396	lr=5.68e-04 | 88.2%@S8  T=1.68s(data=1.8ms QKV=2.10s FFN=3.05s) eta=23:56:33 | 44.9K token/s | 
[epoch_0]_9631   loss=3.479154 |g|=0.384	lr=5.68e-04 | 89.0%@S8  T=1.65s(data=2.0ms QKV=2.10s FFN=3.05s) eta=23:36:29 | 45.1K token/s | 
[epoch_0]_9641   loss=3.510426 |g|=0.444	lr=5.68e-04 | 89.8%@S8  T=1.66s(data=1.5ms QKV=2.10s FFN=3.05s) eta=23:39:43 | 45.4K token/s | 
[epoch_0]_9651   loss=3.411623 |g|=0.396	lr=5.68e-04 | 90.6%@S8  T=1.69s(data=1.5ms QKV=2.10s FFN=3.05s) eta=1d 00:05:55 | 45.5K token/s | 
[epoch_0]_9661   loss=3.504161 |g|=0.417	lr=5.68e-04 | 91.4%@S8  T=1.67s(data=1.9ms QKV=2.10s FFN=3.05s) eta=23:51:53 | 45.7K token/s | 
[epoch_0]_9671   loss=3.507365 |g|=0.428	lr=5.68e-04 | 92.3%@S8  T=1.67s(data=1.8ms QKV=2.10s FFN=3.05s) eta=23:46:42 | 45.9K token/s | 
[epoch_0]_9681   loss=3.494060 |g|=0.41	lr=5.68e-04 | 93.1%@S8  T=1.67s(data=1.5ms QKV=2.10s FFN=3.05s) eta=23:46:33 | 46.0K token/s | 
[epoch_0]_9691   loss=3.555060 |g|=0.407	lr=5.67e-04 | 93.9%@S8  T=1.65s(data=1.8ms QKV=2.10s FFN=3.05s) eta=23:34:03 | 46.2K token/s | 
[Fuyou] head="0" update algorithm=4 t=8.01s
[Section@9700] layer[8-16] tasks=19(nPassBack=0) last_loss=3.50301(0.0211358) N=(772,11536,10976 1280268)
[epoch_0]_9701   loss=3.423082 |g|=0.393	lr=5.67e-04 | 94.7%@S8  T=3.98s(data=2.0ms QKV=2.09s FFN=3.04s) eta=2d 08:47:30 | 44.9K token/s | 
[epoch_0]_9711   loss=3.486226 |g|=0.391	lr=5.67e-04 | 95.5%@S8  T=1.65s(data=1.6ms QKV=2.10s FFN=3.05s) eta=23:30:36 | 45.2K token/s | 
[epoch_0]_9721   loss=3.442565 |g|=0.387	lr=5.67e-04 | 96.3%@S8  T=1.66s(data=1.6ms QKV=2.10s FFN=3.05s) eta=23:38:24 | 45.4K token/s | 
[epoch_0]_9731   loss=3.479229 |g|=0.427	lr=5.67e-04 | 97.2%@S8  T=1.69s(data=1.6ms QKV=2.10s FFN=3.05s) eta=1d 48 | 45.5K token/s | 
[epoch_0]_9741   loss=3.476667 |g|=0.412	lr=5.67e-04 | 98.0%@S8  T=1.66s(data=2.1ms QKV=2.10s FFN=3.05s) eta=23:37:17 | 45.7K token/s | 
[epoch_0]_9751   loss=3.435257 |g|=0.435	lr=5.67e-04 | 98.8%@S8  T=1.66s(data=1.6ms QKV=2.10s FFN=3.05s) eta=23:35:25 | 45.9K token/s | 
[epoch_0]_9761   loss=3.427686 |g|=0.409	lr=5.67e-04 | 99.6%@S8  T=1.65s(data=1.8ms QKV=2.10s FFN=3.05s) eta=23:33:10 | 46.1K token/s | 
[epoch_0]_9765   loss=3.434420 |g|=0.388	lr=5.67e-04 | 100.0%@S8  T=1.66s(data=1.6ms QKV=2.10s FFN=3.05s) eta=23:36:01 | 46.3K token/s | 
-------- End of shard_8@"./Datasets/edu_fineweb1B/edu_fineweb_train_000008.bin"-------- 
[shard-9]@"./Datasets/edu_fineweb1B/edu_fineweb_train_000009.bin": tokens=100(M) nShardSamples=1220(878904) 
[epoch_0]_9771   loss=3.469990 |g|=0.395	lr=5.67e-04 | 0.4%@S9  T=1.66s(data=1.2ms QKV=2.10s FFN=3.05s) eta=23:38:29 | 46.4K token/s | 
[epoch_0]_9781   loss=3.435652 |g|=0.425	lr=5.67e-04 | 1.3%@S9  T=1.66s(data=1.2ms QKV=2.10s FFN=3.05s) eta=23:41:49 | 46.6K token/s | 
[epoch_0]_9791   loss=3.408615 |g|=0.399	lr=5.67e-04 | 2.1%@S9  T=1.66s(data=1.9ms QKV=2.10s FFN=3.05s) eta=23:36:35 | 46.7K token/s | 
[Fuyou] head="1" update algorithm=4 t=10.11s
[eval] 
	 Loss@"edu_fineweb1B"=3.517(-0.0018) nBranch=1 nToken=6.31M best=3.5153(47) E2T=0.0648 T=36.7071(0)s x=0
	#3.51703±0.0992 tps=172K(6.30784M) a=[3.31339,3.78781] T=36.7071(sec)
[Section@9800] layer[16-24] tasks=19(nPassBack=0) last_loss=3.45227(0.0604632) N=(772,11648,11088 1293468)
[epoch_0]_9801   loss=3.405596 |g|=0.378	lr=5.67e-04 | 2.9%@S9  T=11.50s(data=1.7ms QKV=2.10s FFN=3.04s) eta=6d 19:43:04 | 44.7K token/s | 
[epoch_0]_9811   loss=3.461940 |g|=0.397	lr=5.67e-04 | 3.7%@S9  T=1.65s(data=1.8ms QKV=2.10s FFN=3.05s) eta=23:25:28 | 45.0K token/s | 
[epoch_0]_9821   loss=3.379033 |g|=0.394	lr=5.67e-04 | 4.5%@S9  T=1.65s(data=1.9ms QKV=2.10s FFN=3.05s) eta=23:31:14 | 45.2K token/s | 
[epoch_0]_9831   loss=3.455554 |g|=0.475	lr=5.66e-04 | 5.4%@S9  T=1.67s(data=1.6ms QKV=2.10s FFN=3.05s) eta=23:48:13 | 45.4K token/s | 
[epoch_0]_9841   loss=3.422787 |g|=0.386	lr=5.66e-04 | 6.2%@S9  T=1.65s(data=1.8ms QKV=2.10s FFN=3.05s) eta=23:25:13 | 45.6K token/s | 
[epoch_0]_9851   loss=3.432660 |g|=0.38	lr=5.66e-04 | 7.0%@S9  T=1.64s(data=1.8ms QKV=2.10s FFN=3.05s) eta=23:20:30 | 45.8K token/s | 
[epoch_0]_9861   loss=3.405217 |g|=0.404	lr=5.66e-04 | 7.8%@S9  T=1.67s(data=1.8ms QKV=2.10s FFN=3.05s) eta=23:45:21 | 46.0K token/s | 
[epoch_0]_9871   loss=3.351610 |g|=0.385	lr=5.66e-04 | 8.6%@S9  T=1.67s(data=2.1ms QKV=2.10s FFN=3.05s) eta=23:45:25 | 46.1K token/s | 
[epoch_0]_9881   loss=3.447415 |g|=0.399	lr=5.66e-04 | 9.5%@S9  T=1.69s(data=1.4ms QKV=2.10s FFN=3.05s) eta=23:59:10 | 46.3K token/s | 
[epoch_0]_9891   loss=3.456975 |g|=0.421	lr=5.66e-04 | 10.3%@S9  T=1.70s(data=1.8ms QKV=2.10s FFN=3.05s) eta=1d 00:06:20 | 46.4K token/s | 
[Fuyou] head="2" update algorithm=4 t=10.91s
[Section@9900] layer[24-32] tasks=19(nPassBack=0) last_loss=3.39072(0.0949628) N=(772,11760,11200 1306668)
[epoch_0]_9901   loss=3.443159 |g|=0.384	lr=5.66e-04 | 11.1%@S9  T=4.34s(data=1.5ms QKV=2.09s FFN=3.04s) eta=2d 13:39:56 | 45.0K token/s | 
[epoch_0]_9911   loss=3.393472 |g|=0.393	lr=5.66e-04 | 11.9%@S9  T=1.66s(data=1.6ms QKV=2.10s FFN=3.04s) eta=23:36:57 | 45.2K token/s | 
[epoch_0]_9921   loss=3.526328 |g|=0.436	lr=5.66e-04 | 12.7%@S9  T=1.65s(data=1.6ms QKV=2.10s FFN=3.05s) eta=23:29:50 | 45.4K token/s | 
[epoch_0]_9931   loss=3.475358 |g|=0.381	lr=5.66e-04 | 13.6%@S9  T=1.67s(data=1.6ms QKV=2.10s FFN=3.05s) eta=23:43:02 | 45.6K token/s | 
[epoch_0]_9941   loss=3.428112 |g|=0.461	lr=5.66e-04 | 14.4%@S9  T=1.68s(data=1.4ms QKV=2.10s FFN=3.05s) eta=23:49:27 | 45.8K token/s | 
[epoch_0]_9951   loss=3.420367 |g|=0.405	lr=5.66e-04 | 15.2%@S9  T=1.68s(data=1.7ms QKV=2.10s FFN=3.05s) eta=23:47:18 | 45.9K token/s | 
[epoch_0]_9961   loss=3.459422 |g|=0.419	lr=5.66e-04 | 16.0%@S9  T=1.68s(data=1.8ms QKV=2.10s FFN=3.05s) eta=23:45:48 | 46.1K token/s | 
[epoch_0]_9971   loss=3.427414 |g|=0.367	lr=5.65e-04 | 16.8%@S9  T=1.67s(data=1.6ms QKV=2.10s FFN=3.05s) eta=23:43:49 | 46.2K token/s | 
[epoch_0]_9981   loss=3.368397 |g|=0.458	lr=5.65e-04 | 17.6%@S9  T=1.68s(data=1.9ms QKV=2.10s FFN=3.05s) eta=23:53:32 | 46.3K token/s | 
[epoch_0]_9991   loss=3.400534 |g|=0.394	lr=5.65e-04 | 18.5%@S9  T=1.65s(data=1.4ms QKV=2.10s FFN=3.05s) eta=23:20:27 | 46.5K token/s | 
[Fuyou] head="3" update algorithm=4 t=11.03s
[eval] 
	 Loss@"edu_fineweb1B"=3.519(-0.0016) nBranch=1 nToken=6.31M best=3.5153(47) E2T=0.0986 T=36.7085(0)s x=0
	#3.51862±0.1002 tps=172K(6.30784M) a=[3.30952,3.79057] T=36.7085(sec)
[Section@10000] layer[32-40] tasks=19(nPassBack=0) last_loss=3.42003(0.132134) N=(772,11872,11312 1319868)
[epoch_0]_10001  loss=3.494230 |g|=0.388	lr=5.65e-04 | 19.3%@S9  T=12.01s(data=1.7ms QKV=2.10s FFN=3.04s) eta=7d 02:13:28 | 44.5K token/s | 
[epoch_0]_10011  loss=3.415826 |g|=0.424	lr=5.65e-04 | 20.1%@S9  T=1.65s(data=1.7ms QKV=2.10s FFN=3.04s) eta=23:20:36 | 44.8K token/s | 
[epoch_0]_10021  loss=3.506320 |g|=0.407	lr=5.65e-04 | 20.9%@S9  T=1.69s(data=1.6ms QKV=2.10s FFN=3.04s) eta=23:59:26 | 45.0K token/s | 
[epoch_0]_10031  loss=3.451377 |g|=0.421	lr=5.65e-04 | 21.7%@S9  T=1.68s(data=1.6ms QKV=2.10s FFN=3.05s) eta=23:50:21 | 45.1K token/s | 
[epoch_0]_10041  loss=3.414018 |g|=0.407	lr=5.65e-04 | 22.6%@S9  T=1.64s(data=1.7ms QKV=2.10s FFN=3.05s) eta=23:17:55 | 45.4K token/s | 
[epoch_0]_10051  loss=3.382583 |g|=0.414	lr=5.65e-04 | 23.4%@S9  T=1.67s(data=1.8ms QKV=2.10s FFN=3.05s) eta=23:39:07 | 45.6K token/s | 
[epoch_0]_10061  loss=3.484316 |g|=0.453	lr=5.65e-04 | 24.2%@S9  T=1.67s(data=2.1ms QKV=2.10s FFN=3.05s) eta=23:42:36 | 45.7K token/s | 
[epoch_0]_10071  loss=3.430375 |g|=0.382	lr=5.65e-04 | 25.0%@S9  T=1.68s(data=1.5ms QKV=2.10s FFN=3.05s) eta=23:49:23 | 45.9K token/s | 
[epoch_0]_10081  loss=3.413432 |g|=0.394	lr=5.65e-04 | 25.8%@S9  T=1.65s(data=1.5ms QKV=2.10s FFN=3.05s) eta=23:20:00 | 46.1K token/s | 
[epoch_0]_10091  loss=3.487316 |g|=0.379	lr=5.65e-04 | 26.7%@S9  T=1.69s(data=1.5ms QKV=2.10s FFN=3.05s) eta=23:51:22 | 46.2K token/s | 
[Fuyou] head="4" update algorithm=4 t=12.64s
[Section@10100] layer[40-48] tasks=19(nPassBack=0) last_loss=3.38451(0.0986953) N=(772,11984,11424 1333068)
[epoch_0]_10101  loss=3.420438 |g|=0.39	lr=5.65e-04 | 27.5%@S9  T=4.22s(data=3.1ms QKV=2.10s FFN=3.03s) eta=2d 11:41:01 | 44.9K token/s | 
[epoch_0]_10111  loss=3.455465 |g|=0.397	lr=5.64e-04 | 28.3%@S9  T=1.65s(data=1.7ms QKV=2.10s FFN=3.04s) eta=23:22:11 | 45.1K token/s | 
[epoch_0]_10121  loss=3.434117 |g|=0.396	lr=5.64e-04 | 29.1%@S9  T=1.68s(data=1.7ms QKV=2.10s FFN=3.04s) eta=23:42:27 | 45.3K token/s | 
[epoch_0]_10131  loss=3.447631 |g|=0.406	lr=5.64e-04 | 29.9%@S9  T=1.68s(data=1.8ms QKV=2.10s FFN=3.04s) eta=23:46:01 | 45.5K token/s | 
[epoch_0]_10141  loss=3.482003 |g|=0.419	lr=5.64e-04 | 30.8%@S9  T=1.67s(data=1.5ms QKV=2.10s FFN=3.04s) eta=23:40:45 | 45.6K token/s | 
[epoch_0]_10151  loss=3.400726 |g|=0.399	lr=5.64e-04 | 31.6%@S9  T=1.65s(data=2.0ms QKV=2.10s FFN=3.04s) eta=23:18:22 | 45.8K token/s | 
[epoch_0]_10161  loss=3.443101 |g|=0.409	lr=5.64e-04 | 32.4%@S9  T=1.65s(data=1.7ms QKV=2.10s FFN=3.04s) eta=23:18:22 | 46.0K token/s | 
[epoch_0]_10171  loss=3.357799 |g|=0.382	lr=5.64e-04 | 33.2%@S9  T=1.67s(data=1.8ms QKV=2.10s FFN=3.04s) eta=23:32:45 | 46.2K token/s | 
[epoch_0]_10181  loss=3.387619 |g|=0.401	lr=5.64e-04 | 34.0%@S9  T=1.67s(data=1.6ms QKV=2.10s FFN=3.04s) eta=23:31:47 | 46.3K token/s | 
[epoch_0]_10191  loss=3.463095 |g|=0.409	lr=5.64e-04 | 34.8%@S9  T=1.65s(data=1.8ms QKV=2.10s FFN=3.04s) eta=23:20:23 | 46.5K token/s | 
[Fuyou] head="5" update algorithm=4 t=12.35s
[eval] 
	 Loss@"edu_fineweb1B"=3.519(-0.00086) nBranch=1 nToken=6.31M best=3.5153(47) E2T=0.081 T=36.6944(0)s x=0
	#3.51949±0.1002 tps=172K(6.30784M) a=[3.3172,3.78896] T=36.6944(sec)
[Section@10200] layer[0-8] tasks=19(nPassBack=0) last_loss=3.43846(0.128579) N=(772,12096,11536 1346268)
[epoch_0]_10201  loss=3.416373 |g|=0.372	lr=5.64e-04 | 35.7%@S9  T=12.38s(data=2.1ms QKV=2.10s FFN=3.04s) eta=7d 06:46:22 | 44.5K token/s | 
[epoch_0]_10211  loss=3.510240 |g|=0.377	lr=5.64e-04 | 36.5%@S9  T=1.65s(data=1.9ms QKV=2.10s FFN=3.04s) eta=23:18:28 | 44.8K token/s | 
[epoch_0]_10221  loss=3.458830 |g|=0.385	lr=5.64e-04 | 37.3%@S9  T=1.68s(data=1.9ms QKV=2.10s FFN=3.04s) eta=23:39:36 | 45.0K token/s | 
[epoch_0]_10231  loss=3.398152 |g|=0.378	lr=5.64e-04 | 38.1%@S9  T=1.65s(data=1.9ms QKV=2.10s FFN=3.04s) eta=23:18:16 | 45.2K token/s | 
[epoch_0]_10241  loss=3.357361 |g|=0.4	lr=5.63e-04 | 38.9%@S9  T=1.68s(data=1.9ms QKV=2.10s FFN=3.04s) eta=23:44:48 | 45.4K token/s | 
[epoch_0]_10251  loss=3.452804 |g|=0.38	lr=5.63e-04 | 39.8%@S9  T=1.71s(data=1.7ms QKV=2.10s FFN=3.04s) eta=1d 00:11:01 | 45.5K token/s | 
[epoch_0]_10261  loss=3.440191 |g|=0.388	lr=5.63e-04 | 40.6%@S9  T=1.68s(data=1.6ms QKV=2.10s FFN=3.04s) eta=23:44:32 | 45.6K token/s | 
[epoch_0]_10271  loss=3.411619 |g|=0.395	lr=5.63e-04 | 41.4%@S9  T=1.67s(data=1.6ms QKV=2.10s FFN=3.04s) eta=23:36:24 | 45.8K token/s | 
[epoch_0]_10281  loss=3.359169 |g|=0.403	lr=5.63e-04 | 42.2%@S9  T=1.68s(data=1.8ms QKV=2.10s FFN=3.04s) eta=23:42:18 | 46.0K token/s | 
[epoch_0]_10291  loss=3.364147 |g|=0.406	lr=5.63e-04 | 43.0%@S9  T=1.66s(data=1.9ms QKV=2.10s FFN=3.04s) eta=23:23:00 | 46.1K token/s | 
[Fuyou] head="0" update algorithm=4 t=11.76s
[Section@10300] layer[8-16] tasks=19(nPassBack=0) last_loss=3.41087(0.0921388) N=(772,12208,11648 1359468)
[epoch_0]_10301  loss=3.429220 |g|=0.438	lr=5.63e-04 | 43.9%@S9  T=4.51s(data=1.6ms QKV=2.10s FFN=3.03s) eta=2d 15:30:54 | 44.7K token/s | 
[epoch_0]_10311  loss=3.417025 |g|=0.385	lr=5.63e-04 | 44.7%@S9  T=1.68s(data=2.7ms QKV=2.10s FFN=3.04s) eta=23:44:13 | 44.9K token/s | 
[epoch_0]_10321  loss=3.439024 |g|=0.375	lr=5.63e-04 | 45.5%@S9  T=1.68s(data=1.7ms QKV=2.10s FFN=3.04s) eta=23:42:37 | 45.1K token/s | 
[epoch_0]_10331  loss=3.391040 |g|=0.442	lr=5.63e-04 | 46.3%@S9  T=1.68s(data=1.8ms QKV=2.10s FFN=3.04s) eta=23:38:05 | 45.3K token/s | 
[epoch_0]_10341  loss=3.418933 |g|=0.436	lr=5.63e-04 | 47.1%@S9  T=1.70s(data=1.9ms QKV=2.10s FFN=3.04s) eta=23:53:15 | 45.4K token/s | 
[epoch_0]_10351  loss=3.431580 |g|=0.438	lr=5.63e-04 | 48.0%@S9  T=1.69s(data=1.7ms QKV=2.10s FFN=3.04s) eta=23:46:16 | 45.6K token/s | 
[epoch_0]_10361  loss=3.440378 |g|=0.373	lr=5.63e-04 | 48.8%@S9  T=1.69s(data=1.7ms QKV=2.10s FFN=3.04s) eta=23:46:49 | 45.7K token/s | 
[epoch_0]_10371  loss=3.402114 |g|=0.382	lr=5.63e-04 | 49.6%@S9  T=1.69s(data=1.6ms QKV=2.10s FFN=3.04s) eta=23:44:43 | 45.9K token/s | 
[epoch_0]_10381  loss=3.466961 |g|=0.427	lr=5.62e-04 | 50.4%@S9  T=1.69s(data=1.6ms QKV=2.10s FFN=3.04s) eta=23:46:53 | 46.0K token/s | 
[epoch_0]_10391  loss=3.406356 |g|=0.418	lr=5.62e-04 | 51.2%@S9  T=1.70s(data=2.3ms QKV=2.10s FFN=3.05s) eta=23:51:20 | 46.1K token/s | 
[Fuyou] head="1" update algorithm=4 t=11.74s
[eval] 
	 Loss@"edu_fineweb1B"=3.519(0.00073) nBranch=1 nToken=6.31M best=3.5153(47) E2T=0.073 T=36.762(0)s x=0
	#3.51876±0.1009 tps=172K(6.30784M) a=[3.31102,3.79328] T=36.762(sec)
[Section@10400] layer[16-24] tasks=19(nPassBack=0) last_loss=3.4458(0.00646853) N=(772,12320,11760 1372668)
[epoch_0]_10401  loss=3.377966 |g|=0.388	lr=5.62e-04 | 52.1%@S9  T=12.05s(data=5.3ms QKV=2.10s FFN=3.04s) eta=7d 01:28:20 | 44.2K token/s | 
[epoch_0]_10411  loss=3.402058 |g|=0.393	lr=5.62e-04 | 52.9%@S9  T=1.70s(data=2.0ms QKV=2.10s FFN=3.04s) eta=23:53:05 | 44.4K token/s | 
[epoch_0]_10421  loss=3.351327 |g|=0.386	lr=5.62e-04 | 53.7%@S9  T=1.71s(data=1.6ms QKV=2.10s FFN=3.04s) eta=23:59:24 | 44.5K token/s | 
[epoch_0]_10431  loss=3.354233 |g|=0.439	lr=5.62e-04 | 54.5%@S9  T=1.69s(data=1.6ms QKV=2.10s FFN=3.04s) eta=23:41:41 | 44.7K token/s | 
[epoch_0]_10441  loss=3.422873 |g|=0.427	lr=5.62e-04 | 55.3%@S9  T=1.68s(data=1.6ms QKV=2.10s FFN=3.04s) eta=23:33:31 | 45.0K token/s | 
[epoch_0]_10451  loss=3.405507 |g|=0.375	lr=5.62e-04 | 56.1%@S9  T=1.69s(data=2.9ms QKV=2.10s FFN=3.04s) eta=23:41:38 | 45.1K token/s | 
[epoch_0]_10461  loss=3.469635 |g|=0.432	lr=5.62e-04 | 57.0%@S9  T=1.67s(data=1.8ms QKV=2.10s FFN=3.04s) eta=23:28:46 | 45.3K token/s | 
[epoch_0]_10471  loss=3.440585 |g|=0.397	lr=5.62e-04 | 57.8%@S9  T=1.70s(data=1.7ms QKV=2.10s FFN=3.04s) eta=23:52:09 | 45.5K token/s | 
[epoch_0]_10481  loss=3.466775 |g|=0.367	lr=5.62e-04 | 58.6%@S9  T=1.69s(data=2.0ms QKV=2.10s FFN=3.04s) eta=23:47:07 | 45.6K token/s | 
[epoch_0]_10491  loss=3.442000 |g|=0.457	lr=5.62e-04 | 59.4%@S9  T=1.67s(data=2.1ms QKV=2.10s FFN=3.04s) eta=23:22:48 | 45.8K token/s | 
[Fuyou] head="2" update algorithm=4 t=10.83s
[Section@10500] layer[24-32] tasks=19(nPassBack=0) last_loss=3.38326(0.00746512) N=(772,12432,11872 1385868)
[epoch_0]_10501  loss=3.378773 |g|=0.369	lr=5.62e-04 | 60.2%@S9  T=4.62s(data=2.1ms QKV=2.10s FFN=3.04s) eta=2d 16:48:20 | 44.4K token/s | 
[epoch_0]_10511  loss=3.403537 |g|=0.398	lr=5.61e-04 | 61.1%@S9  T=1.69s(data=1.7ms QKV=2.10s FFN=3.04s) eta=23:39:41 | 44.6K token/s | 
[epoch_0]_10521  loss=3.453209 |g|=0.391	lr=5.61e-04 | 61.9%@S9  T=1.68s(data=1.7ms QKV=2.10s FFN=3.04s) eta=23:30:30 | 44.8K token/s | 
[epoch_0]_10531  loss=3.337847 |g|=0.381	lr=5.61e-04 | 62.7%@S9  T=1.65s(data=1.5ms QKV=2.10s FFN=3.04s) eta=23:08:20 | 45.1K token/s | 
[epoch_0]_10541  loss=3.465949 |g|=0.399	lr=5.61e-04 | 63.5%@S9  T=1.68s(data=1.8ms QKV=2.10s FFN=3.04s) eta=23:36:12 | 45.2K token/s | 
[epoch_0]_10551  loss=3.433185 |g|=0.406	lr=5.61e-04 | 64.3%@S9  T=1.68s(data=1.6ms QKV=2.10s FFN=3.04s) eta=23:32:14 | 45.4K token/s | 
[epoch_0]_10561  loss=3.395841 |g|=0.418	lr=5.61e-04 | 65.2%@S9  T=1.69s(data=1.7ms QKV=2.10s FFN=3.04s) eta=23:38:53 | 45.6K token/s | 
[epoch_0]_10571  loss=3.401999 |g|=0.432	lr=5.61e-04 | 66.0%@S9  T=1.65s(data=1.6ms QKV=2.10s FFN=3.04s) eta=23:08:21 | 45.8K token/s | 
[epoch_0]_10581  loss=3.397786 |g|=0.423	lr=5.61e-04 | 66.8%@S9  T=1.67s(data=1.9ms QKV=2.10s FFN=3.04s) eta=23:20:16 | 46.0K token/s | 
[epoch_0]_10591  loss=3.359375 |g|=0.435	lr=5.61e-04 | 67.6%@S9  T=1.69s(data=1.8ms QKV=2.10s FFN=3.04s) eta=23:41:35 | 46.1K token/s | 
[Fuyou] head="3" update algorithm=4 t=12.33s
[eval] 
	 Loss@"edu_fineweb1B"=3.514(0.0046) nBranch=1 nToken=6.31M best=3.5188(51) E2T=0.208 T=36.767(0)s x=0
	#3.51416±0.1005 tps=172K(6.30784M) a=[3.31032,3.78552] T=36.767(sec)
[Section@10600] layer[32-40] tasks=19(nPassBack=0) last_loss=3.30574(0.114292) N=(772,12544,11984 1399068)
[epoch_0]_10601  loss=3.311445 |g|=0.364	lr=5.61e-04 | 68.4%@S9  T=12.02s(data=2.1ms QKV=2.10s FFN=3.04s) eta=7d 00:19:57 | 44.1K token/s | 
[epoch_0]_10611  loss=3.411693 |g|=0.382	lr=5.61e-04 | 69.3%@S9  T=1.68s(data=1.6ms QKV=2.10s FFN=3.04s) eta=23:29:54 | 44.3K token/s | 
[epoch_0]_10621  loss=3.441366 |g|=0.371	lr=5.61e-04 | 70.1%@S9  T=1.70s(data=1.8ms QKV=2.10s FFN=3.04s) eta=23:47:40 | 44.5K token/s | 
[epoch_0]_10631  loss=3.384938 |g|=0.459	lr=5.61e-04 | 70.9%@S9  T=1.68s(data=1.7ms QKV=2.10s FFN=3.04s) eta=23:28:45 | 44.8K token/s | 
[epoch_0]_10641  loss=3.437441 |g|=0.403	lr=5.60e-04 | 71.7%@S9  T=1.68s(data=1.9ms QKV=2.10s FFN=3.04s) eta=23:28:20 | 45.0K token/s | 
[epoch_0]_10651  loss=3.416020 |g|=0.418	lr=5.60e-04 | 72.5%@S9  T=1.70s(data=1.7ms QKV=2.10s FFN=3.04s) eta=23:45:30 | 45.1K token/s | 
[epoch_0]_10661  loss=3.396761 |g|=0.39	lr=5.60e-04 | 73.4%@S9  T=1.70s(data=1.6ms QKV=2.10s FFN=3.04s) eta=23:51:25 | 45.3K token/s | 
[epoch_0]_10671  loss=3.421124 |g|=0.378	lr=5.60e-04 | 74.2%@S9  T=1.70s(data=1.6ms QKV=2.10s FFN=3.04s) eta=23:44:22 | 45.4K token/s | 
[epoch_0]_10681  loss=3.405956 |g|=0.398	lr=5.60e-04 | 75.0%@S9  T=1.69s(data=1.7ms QKV=2.10s FFN=3.04s) eta=23:39:47 | 45.6K token/s | 
[epoch_0]_10691  loss=3.444751 |g|=0.416	lr=5.60e-04 | 75.8%@S9  T=1.68s(data=1.9ms QKV=2.10s FFN=3.04s) eta=23:33:46 | 45.7K token/s | 
[Fuyou] head="4" update algorithm=4 t=12.41s
[Section@10700] layer[40-48] tasks=19(nPassBack=0) last_loss=3.42641(-0.0418999) N=(772,12656,12096 1412268)
[epoch_0]_10701  loss=3.330385 |g|=0.365	lr=5.60e-04 | 76.6%@S9  T=4.24s(data=1.7ms QKV=2.10s FFN=3.04s) eta=2d 11:14:37 | 44.4K token/s | 
[epoch_0]_10711  loss=3.404020 |g|=0.432	lr=5.60e-04 | 77.4%@S9  T=1.69s(data=1.8ms QKV=2.10s FFN=3.04s) eta=23:34:33 | 44.6K token/s | 
[epoch_0]_10721  loss=3.379233 |g|=0.459	lr=5.60e-04 | 78.3%@S9  T=1.71s(data=1.7ms QKV=2.10s FFN=3.04s) eta=23:50:40 | 44.8K token/s | 
[epoch_0]_10731  loss=3.372763 |g|=0.412	lr=5.60e-04 | 79.1%@S9  T=1.70s(data=1.8ms QKV=2.10s FFN=3.04s) eta=23:46:20 | 45.0K token/s | 
[epoch_0]_10741  loss=3.411130 |g|=0.385	lr=5.60e-04 | 79.9%@S9  T=1.71s(data=1.8ms QKV=2.10s FFN=3.05s) eta=23:50:25 | 45.1K token/s | 
[epoch_0]_10751  loss=3.443370 |g|=0.401	lr=5.60e-04 | 80.7%@S9  T=1.68s(data=1.8ms QKV=2.10s FFN=3.04s) eta=23:25:13 | 45.3K token/s | 
[epoch_0]_10761  loss=3.322757 |g|=0.4	lr=5.60e-04 | 81.5%@S9  T=1.71s(data=1.6ms QKV=2.10s FFN=3.04s) eta=23:49:45 | 45.4K token/s | 
[epoch_0]_10771  loss=3.347357 |g|=0.431	lr=5.59e-04 | 82.4%@S9  T=1.69s(data=1.8ms QKV=2.10s FFN=3.05s) eta=23:37:19 | 45.6K token/s | 
[epoch_0]_10781  loss=3.359372 |g|=0.45	lr=5.59e-04 | 83.2%@S9  T=1.67s(data=1.7ms QKV=2.10s FFN=3.04s) eta=23:15:24 | 45.8K token/s | 
[epoch_0]_10791  loss=3.371795 |g|=0.41	lr=5.59e-04 | 84.0%@S9  T=1.70s(data=1.8ms QKV=2.10s FFN=3.05s) eta=23:43:15 | 45.9K token/s | 
[Fuyou] head="5" update algorithm=4 t=11.30s
[eval] 
	 Loss@"edu_fineweb1B"=3.511(0.0028) nBranch=1 nToken=6.31M best=3.5142(52) E2T=0.139 T=36.772(0)s x=0
	#3.51132±0.1014 tps=172K(6.30784M) a=[3.30195,3.79004] T=36.772(sec)
[Section@10800] layer[0-8] tasks=19(nPassBack=0) last_loss=3.37214(0.0663249) N=(772,12768,12208 1425468)
[epoch_0]_10801  loss=3.375504 |g|=0.398	lr=5.59e-04 | 84.8%@S9  T=12.22s(data=1.7ms QKV=2.10s FFN=3.04s) eta=7d 02:30:36 | 43.9K token/s | 
[epoch_0]_10811  loss=3.446275 |g|=0.376	lr=5.59e-04 | 85.6%@S9  T=1.69s(data=2.1ms QKV=2.10s FFN=3.04s) eta=23:31:59 | 44.2K token/s | 
[epoch_0]_10821  loss=3.440299 |g|=0.395	lr=5.59e-04 | 86.5%@S9  T=1.70s(data=1.9ms QKV=2.10s FFN=3.04s) eta=23:38:53 | 44.4K token/s | 
[epoch_0]_10831  loss=3.381093 |g|=0.403	lr=5.59e-04 | 87.3%@S9  T=1.67s(data=1.7ms QKV=2.10s FFN=3.04s) eta=23:15:55 | 44.6K token/s | 
[epoch_0]_10841  loss=3.425920 |g|=0.388	lr=5.59e-04 | 88.1%@S9  T=1.68s(data=1.8ms QKV=2.10s FFN=3.05s) eta=23:29:26 | 44.8K token/s | 
[epoch_0]_10851  loss=3.368296 |g|=0.376	lr=5.59e-04 | 88.9%@S9  T=1.65s(data=2.0ms QKV=2.10s FFN=3.05s) eta=23:00:52 | 45.0K token/s | 
[epoch_0]_10861  loss=3.455648 |g|=0.402	lr=5.59e-04 | 89.7%@S9  T=1.67s(data=1.9ms QKV=2.10s FFN=3.05s) eta=23:13:09 | 45.2K token/s | 
[epoch_0]_10871  loss=3.467140 |g|=0.415	lr=5.59e-04 | 90.6%@S9  T=1.70s(data=1.9ms QKV=2.10s FFN=3.05s) eta=23:40:11 | 45.4K token/s | 
[epoch_0]_10881  loss=3.368304 |g|=0.373	lr=5.59e-04 | 91.4%@S9  T=1.66s(data=1.8ms QKV=2.10s FFN=3.05s) eta=23:05:29 | 45.6K token/s | 
[epoch_0]_10891  loss=3.427453 |g|=0.408	lr=5.59e-04 | 92.2%@S9  T=1.66s(data=1.9ms QKV=2.10s FFN=3.05s) eta=23:07:47 | 45.8K token/s | 
[Fuyou] head="0" update algorithm=4 t=11.81s
[Section@10900] layer[8-16] tasks=19(nPassBack=0) last_loss=3.43443(-0.0235579) N=(772,12880,12320 1438668)
[epoch_0]_10901  loss=3.400486 |g|=0.401	lr=5.58e-04 | 93.0%@S9  T=4.53s(data=1.9ms QKV=2.10s FFN=3.04s) eta=2d 15:06:42 | 44.4K token/s | 
[epoch_0]_10911  loss=3.452226 |g|=0.388	lr=5.58e-04 | 93.8%@S9  T=1.69s(data=1.7ms QKV=2.10s FFN=3.04s) eta=23:27:41 | 44.6K token/s | 
[epoch_0]_10921  loss=3.385679 |g|=0.439	lr=5.58e-04 | 94.7%@S9  T=1.70s(data=2.1ms QKV=2.11s FFN=3.04s) eta=23:35:53 | 44.8K token/s | 
[epoch_0]_10931  loss=3.429699 |g|=0.403	lr=5.58e-04 | 95.5%@S9  T=1.70s(data=1.7ms QKV=2.10s FFN=3.05s) eta=23:36:07 | 45.0K token/s | 
[epoch_0]_10941  loss=3.380025 |g|=0.424	lr=5.58e-04 | 96.3%@S9  T=1.70s(data=1.6ms QKV=2.10s FFN=3.04s) eta=23:38:31 | 45.1K token/s | 
[epoch_0]_10951  loss=3.365072 |g|=0.393	lr=5.58e-04 | 97.1%@S9  T=1.70s(data=1.6ms QKV=2.10s FFN=3.05s) eta=23:37:51 | 45.3K token/s | 
[epoch_0]_10961  loss=3.401683 |g|=0.449	lr=5.58e-04 | 97.9%@S9  T=1.69s(data=1.6ms QKV=2.11s FFN=3.05s) eta=23:32:47 | 45.4K token/s | 
[epoch_0]_10971  loss=3.449955 |g|=0.396	lr=5.58e-04 | 98.7%@S9  T=1.66s(data=1.8ms QKV=2.10s FFN=3.05s) eta=23:02:35 | 45.6K token/s | 
[epoch_0]_10981  loss=3.379521 |g|=0.399	lr=5.58e-04 | 99.6%@S9  T=1.65s(data=1.7ms QKV=2.11s FFN=3.05s) eta=22:57:38 | 45.8K token/s | 
[epoch_0]_10986  loss=3.301902 |g|=0.376	lr=5.58e-04 | 100.0%@S9  T=1.70s(data=1.6ms QKV=2.10s FFN=3.05s) eta=23:35:24 | 46.0K token/s | 
-------- End of shard_9@"./Datasets/edu_fineweb1B/edu_fineweb_train_000009.bin"-------- 
[shard-10]@"./Datasets/edu_fineweb1B/edu_fineweb_train_000010.bin": tokens=100(M) nShardSamples=1220(976560) 
[epoch_0]_10991  loss=3.528162 |g|=0.404	lr=5.58e-04 | 0.4%@S10  T=1.71s(data=1.5ms QKV=2.10s FFN=3.05s) eta=23:47:09 | 46.1K token/s | 
[Fuyou] head="1" update algorithm=4 t=11.23s
[eval] 
	 Loss@"edu_fineweb1B"=3.504(0.0074) nBranch=1 nToken=6.31M best=3.5113(53) E2T=-0.0551 T=36.7714(0)s x=0
	#3.50393±0.1001 tps=172K(6.30784M) a=[3.29098,3.7761] T=36.7714(sec)
[Section@11000] layer[16-24] tasks=19(nPassBack=0) last_loss=3.55907(-0.113267) N=(772,12992,12432 1451868)
[epoch_0]_11001  loss=3.592581 |g|=0.393	lr=5.58e-04 | 1.2%@S10  T=12.06s(data=1.6ms QKV=2.10s FFN=3.04s) eta=6d 23:32:54 | 44.1K token/s | 
[epoch_0]_11011  loss=3.504799 |g|=0.407	lr=5.58e-04 | 2.0%@S10  T=1.69s(data=1.4ms QKV=2.10s FFN=3.04s) eta=23:26:38 | 44.3K token/s | 
[epoch_0]_11021  loss=3.498649 |g|=0.47	lr=5.57e-04 | 2.8%@S10  T=1.69s(data=1.8ms QKV=2.10s FFN=3.04s) eta=23:30:18 | 44.5K token/s | 
[epoch_0]_11031  loss=3.573857 |g|=0.424	lr=5.57e-04 | 3.7%@S10  T=1.67s(data=1.8ms QKV=2.10s FFN=3.04s) eta=23:09:13 | 44.8K token/s | 
[epoch_0]_11041  loss=3.465381 |g|=0.396	lr=5.57e-04 | 4.5%@S10  T=1.72s(data=1.6ms QKV=2.10s FFN=3.05s) eta=23:53:32 | 44.9K token/s | 
[epoch_0]_11051  loss=3.610988 |g|=0.421	lr=5.57e-04 | 5.3%@S10  T=1.71s(data=1.7ms QKV=2.10s FFN=3.04s) eta=23:42:55 | 45.1K token/s | 
[epoch_0]_11061  loss=3.503243 |g|=0.413	lr=5.57e-04 | 6.1%@S10  T=1.69s(data=1.7ms QKV=2.10s FFN=3.05s) eta=23:27:58 | 45.2K token/s | 
[epoch_0]_11071  loss=3.493851 |g|=0.391	lr=5.57e-04 | 6.9%@S10  T=1.69s(data=1.9ms QKV=2.10s FFN=3.04s) eta=23:29:57 | 45.4K token/s | 
[epoch_0]_11081  loss=3.448802 |g|=0.399	lr=5.57e-04 | 7.8%@S10  T=1.69s(data=1.7ms QKV=2.10s FFN=3.04s) eta=23:29:21 | 45.5K token/s | 
[epoch_0]_11091  loss=3.493427 |g|=0.384	lr=5.57e-04 | 8.6%@S10  T=1.69s(data=1.8ms QKV=2.10s FFN=3.05s) eta=23:28:10 | 45.7K token/s | 
[Fuyou] head="2" update algorithm=4 t=10.15s
[Section@11100] layer[24-32] tasks=19(nPassBack=0) last_loss=3.49048(-0.107225) N=(772,13104,12544 1465068)
[epoch_0]_11101  loss=3.484590 |g|=0.387	lr=5.57e-04 | 9.4%@S10  T=4.18s(data=1.5ms QKV=2.10s FFN=3.04s) eta=2d 10:02:02 | 44.4K token/s | 
[epoch_0]_11111  loss=3.548156 |g|=0.416	lr=5.57e-04 | 10.2%@S10  T=1.70s(data=1.7ms QKV=2.10s FFN=3.04s) eta=23:33:23 | 44.6K token/s | 
[epoch_0]_11121  loss=3.521931 |g|=0.408	lr=5.57e-04 | 11.0%@S10  T=1.70s(data=1.9ms QKV=2.10s FFN=3.04s) eta=23:30:30 | 44.8K token/s | 
[epoch_0]_11131  loss=3.496059 |g|=0.393	lr=5.57e-04 | 11.9%@S10  T=1.70s(data=1.8ms QKV=2.10s FFN=3.04s) eta=23:33:10 | 44.9K token/s | 
[epoch_0]_11141  loss=3.429345 |g|=0.386	lr=5.57e-04 | 12.7%@S10  T=1.69s(data=1.7ms QKV=2.10s FFN=3.04s) eta=23:23:37 | 45.1K token/s | 
[epoch_0]_11151  loss=3.505970 |g|=0.422	lr=5.56e-04 | 13.5%@S10  T=1.68s(data=1.6ms QKV=2.10s FFN=3.04s) eta=23:16:38 | 45.3K token/s | 
[epoch_0]_11161  loss=3.510675 |g|=0.418	lr=5.56e-04 | 14.3%@S10  T=1.69s(data=1.3ms QKV=2.10s FFN=3.04s) eta=23:28:14 | 45.4K token/s | 
[epoch_0]_11171  loss=3.541066 |g|=0.414	lr=5.56e-04 | 15.1%@S10  T=1.68s(data=1.3ms QKV=2.10s FFN=3.04s) eta=23:19:27 | 45.6K token/s | 
[epoch_0]_11181  loss=3.488455 |g|=0.41	lr=5.56e-04 | 16.0%@S10  T=1.69s(data=1.6ms QKV=2.10s FFN=3.04s) eta=23:23:25 | 45.7K token/s | 
[epoch_0]_11191  loss=3.562551 |g|=0.389	lr=5.56e-04 | 16.8%@S10  T=1.71s(data=1.8ms QKV=2.10s FFN=3.04s) eta=23:39:12 | 45.9K token/s | 
[Fuyou] head="3" update algorithm=4 t=10.52s
[eval] 
	 Loss@"edu_fineweb1B"=3.480(0.024) nBranch=1 nToken=6.31M best=3.5039(54) E2T=0.0196 T=36.7399(0)s x=0
	#3.48003±0.0988 tps=172K(6.30784M) a=[3.27912,3.75545] T=36.7399(sec)
[Section@11200] layer[32-40] tasks=19(nPassBack=0) last_loss=3.46043(-0.154689) N=(772,13216,12656 1478268)
[epoch_0]_11201  loss=3.446776 |g|=0.409	lr=5.56e-04 | 17.6%@S10  T=11.57s(data=1.9ms QKV=2.10s FFN=3.04s) eta=6d 16:06:25 | 43.9K token/s | 
[epoch_0]_11211  loss=3.517341 |g|=0.385	lr=5.56e-04 | 18.4%@S10  T=1.67s(data=1.5ms QKV=2.10s FFN=3.04s) eta=23:04:05 | 44.2K token/s | 
[epoch_0]_11221  loss=3.493871 |g|=0.425	lr=5.56e-04 | 19.2%@S10  T=1.71s(data=2.0ms QKV=2.10s FFN=3.04s) eta=23:38:50 | 44.4K token/s | 
[epoch_0]_11231  loss=3.561734 |g|=0.39	lr=5.56e-04 | 20.0%@S10  T=1.71s(data=1.6ms QKV=2.10s FFN=3.04s) eta=23:39:00 | 44.5K token/s | 
[epoch_0]_11241  loss=3.528685 |g|=0.399	lr=5.56e-04 | 20.9%@S10  T=1.72s(data=1.7ms QKV=2.10s FFN=3.04s) eta=23:47:50 | 44.7K token/s | 
[epoch_0]_11251  loss=3.525748 |g|=0.402	lr=5.56e-04 | 21.7%@S10  T=1.69s(data=1.6ms QKV=2.10s FFN=3.04s) eta=23:23:56 | 44.9K token/s | 
[epoch_0]_11261  loss=3.432407 |g|=0.404	lr=5.56e-04 | 22.5%@S10  T=1.68s(data=1.5ms QKV=2.10s FFN=3.04s) eta=23:14:37 | 45.1K token/s | 
[epoch_0]_11271  loss=3.447393 |g|=0.4	lr=5.55e-04 | 23.3%@S10  T=1.67s(data=1.8ms QKV=2.10s FFN=3.04s) eta=23:07:38 | 45.3K token/s | 
[epoch_0]_11281  loss=3.422453 |g|=0.411	lr=5.55e-04 | 24.1%@S10  T=1.70s(data=1.6ms QKV=2.10s FFN=3.04s) eta=23:33:29 | 45.4K token/s | 
[epoch_0]_11291  loss=3.433632 |g|=0.399	lr=5.55e-04 | 25.0%@S10  T=1.69s(data=1.5ms QKV=2.10s FFN=3.04s) eta=23:18:13 | 45.6K token/s | 
[Fuyou] head="4" update algorithm=4 t=10.47s
[Section@11300] layer[40-48] tasks=19(nPassBack=0) last_loss=3.50491(-0.0784967) N=(772,13328,12768 1491468)
[epoch_0]_11301  loss=3.431804 |g|=0.44	lr=5.55e-04 | 25.8%@S10  T=3.88s(data=1.6ms QKV=2.10s FFN=3.04s) eta=2d 05:36:57 | 44.3K token/s | 
[epoch_0]_11311  loss=3.457654 |g|=0.421	lr=5.55e-04 | 26.6%@S10  T=1.69s(data=1.6ms QKV=2.10s FFN=3.04s) eta=23:19:39 | 44.6K token/s | 
[epoch_0]_11321  loss=3.520514 |g|=0.405	lr=5.55e-04 | 27.4%@S10  T=1.70s(data=1.5ms QKV=2.10s FFN=3.04s) eta=23:26:47 | 44.7K token/s | 
[epoch_0]_11331  loss=3.541641 |g|=0.447	lr=5.55e-04 | 28.2%@S10  T=1.70s(data=1.7ms QKV=2.10s FFN=3.04s) eta=23:25:02 | 44.9K token/s | 
[epoch_0]_11341  loss=3.502988 |g|=0.405	lr=5.55e-04 | 29.1%@S10  T=1.71s(data=1.6ms QKV=2.10s FFN=3.04s) eta=23:32:42 | 45.1K token/s | 
[epoch_0]_11351  loss=3.501456 |g|=0.419	lr=5.55e-04 | 29.9%@S10  T=1.71s(data=1.7ms QKV=2.10s FFN=3.04s) eta=23:32:12 | 45.2K token/s | 
[epoch_0]_11361  loss=3.488761 |g|=0.426	lr=5.55e-04 | 30.7%@S10  T=1.69s(data=1.7ms QKV=2.10s FFN=3.04s) eta=23:21:56 | 45.4K token/s | 
[epoch_0]_11371  loss=3.464098 |g|=0.388	lr=5.55e-04 | 31.5%@S10  T=1.67s(data=1.5ms QKV=2.10s FFN=3.04s) eta=23:02:36 | 45.6K token/s | 
[epoch_0]_11381  loss=3.495311 |g|=0.423	lr=5.55e-04 | 32.3%@S10  T=1.70s(data=1.6ms QKV=2.10s FFN=3.04s) eta=23:29:43 | 45.7K token/s | 
[epoch_0]_11391  loss=3.546525 |g|=0.364	lr=5.54e-04 | 33.2%@S10  T=1.69s(data=1.5ms QKV=2.10s FFN=3.04s) eta=23:18:17 | 45.8K token/s | 
[Fuyou] head="5" update algorithm=4 t=10.49s
[eval] 
	 Loss@"edu_fineweb1B"=3.473(0.0074) nBranch=1 nToken=6.31M best=3.4800(55) E2T=-0.0709 T=36.7769(0)s x=0
	#3.47266±0.0985 tps=172K(6.30784M) a=[3.27526,3.73933] T=36.7769(sec)
[Section@11400] layer[0-8] tasks=19(nPassBack=0) last_loss=3.54361(-0.171469) N=(772,13440,12880 1504668)
[epoch_0]_11401  loss=3.533065 |g|=0.366	lr=5.54e-04 | 34.0%@S10  T=11.70s(data=1.8ms QKV=2.10s FFN=3.04s) eta=6d 17:19:23 | 43.9K token/s | 
[epoch_0]_11411  loss=3.458219 |g|=0.377	lr=5.54e-04 | 34.8%@S10  T=1.70s(data=1.7ms QKV=2.10s FFN=3.04s) eta=23:24:20 | 44.1K token/s | 
[epoch_0]_11421  loss=3.514592 |g|=0.423	lr=5.54e-04 | 35.6%@S10  T=1.71s(data=1.7ms QKV=2.10s FFN=3.04s) eta=23:33:41 | 44.3K token/s | 
[epoch_0]_11431  loss=3.497891 |g|=0.39	lr=5.54e-04 | 36.4%@S10  T=1.70s(data=2.1ms QKV=2.10s FFN=3.04s) eta=23:21:31 | 44.5K token/s | 
[epoch_0]_11441  loss=3.489223 |g|=0.398	lr=5.54e-04 | 37.3%@S10  T=1.66s(data=1.6ms QKV=2.10s FFN=3.04s) eta=22:53:33 | 44.7K token/s | 
[epoch_0]_11451  loss=3.518115 |g|=0.397	lr=5.54e-04 | 38.1%@S10  T=1.65s(data=1.6ms QKV=2.10s FFN=3.04s) eta=22:47:35 | 45.0K token/s | 
[epoch_0]_11461  loss=3.552775 |g|=0.391	lr=5.54e-04 | 38.9%@S10  T=1.69s(data=1.6ms QKV=2.10s FFN=3.04s) eta=23:17:56 | 45.1K token/s | 
[epoch_0]_11471  loss=3.397779 |g|=0.393	lr=5.54e-04 | 39.7%@S10  T=1.69s(data=1.6ms QKV=2.10s FFN=3.04s) eta=23:12:45 | 45.3K token/s | 
[epoch_0]_11481  loss=3.472749 |g|=0.441	lr=5.54e-04 | 40.5%@S10  T=1.69s(data=1.6ms QKV=2.10s FFN=3.04s) eta=23:15:12 | 45.5K token/s | 
[epoch_0]_11491  loss=3.495022 |g|=0.372	lr=5.54e-04 | 41.3%@S10  T=1.68s(data=1.5ms QKV=2.10s FFN=3.04s) eta=23:03:52 | 45.6K token/s | 
[Fuyou] head="0" update algorithm=4 t=8.81s
[Section@11500] layer[8-16] tasks=19(nPassBack=0) last_loss=3.42397(0.0104589) N=(772,13552,12992 1517868)
[epoch_0]_11501  loss=3.442343 |g|=0.367	lr=5.54e-04 | 42.2%@S10  T=4.26s(data=1.7ms QKV=2.10s FFN=3.04s) eta=2d 10:39:36 | 44.3K token/s | 
[epoch_0]_11511  loss=3.506160 |g|=0.429	lr=5.53e-04 | 43.0%@S10  T=1.69s(data=1.7ms QKV=2.10s FFN=3.04s) eta=23:18:41 | 44.5K token/s | 
[epoch_0]_11521  loss=3.493380 |g|=0.408	lr=5.53e-04 | 43.8%@S10  T=1.70s(data=1.5ms QKV=2.10s FFN=3.04s) eta=23:18:51 | 44.7K token/s | 
[epoch_0]_11531  loss=3.433665 |g|=0.391	lr=5.53e-04 | 44.6%@S10  T=1.69s(data=1.8ms QKV=2.10s FFN=3.04s) eta=23:16:41 | 44.9K token/s | 
[epoch_0]_11541  loss=3.523143 |g|=0.449	lr=5.53e-04 | 45.4%@S10  T=1.70s(data=1.6ms QKV=2.10s FFN=3.04s) eta=23:20:41 | 45.1K token/s | 
[epoch_0]_11551  loss=3.567140 |g|=0.397	lr=5.53e-04 | 46.3%@S10  T=1.72s(data=1.7ms QKV=2.10s FFN=3.04s) eta=23:35:04 | 45.2K token/s | 
[epoch_0]_11561  loss=3.545780 |g|=0.393	lr=5.53e-04 | 47.1%@S10  T=1.69s(data=1.7ms QKV=2.10s FFN=3.04s) eta=23:13:36 | 45.4K token/s | 
[epoch_0]_11571  loss=3.453684 |g|=0.391	lr=5.53e-04 | 47.9%@S10  T=1.67s(data=2.1ms QKV=2.10s FFN=3.04s) eta=22:55:41 | 45.6K token/s | 
[epoch_0]_11581  loss=3.469490 |g|=0.397	lr=5.53e-04 | 48.7%@S10  T=1.69s(data=1.8ms QKV=2.10s FFN=3.04s) eta=23:13:08 | 45.7K token/s | 
[epoch_0]_11591  loss=3.503358 |g|=0.421	lr=5.53e-04 | 49.5%@S10  T=1.70s(data=1.5ms QKV=2.10s FFN=3.04s) eta=23:19:13 | 45.8K token/s | 
[Fuyou] head="1" update algorithm=4 t=8.93s
[eval] 
	 Loss@"edu_fineweb1B"=3.463(0.0098) nBranch=1 nToken=6.31M best=3.4727(56) E2T=-0.0383 T=36.7631(0)s x=0
	#3.4629±0.0990 tps=172K(6.30784M) a=[3.26388,3.7302] T=36.7631(sec)
[Section@11600] layer[16-24] tasks=19(nPassBack=0) last_loss=3.50124(0.0578356) N=(772,13664,13104 1531068)
[epoch_0]_11601  loss=3.445966 |g|=0.343	lr=5.53e-04 | 50.4%@S10  T=11.48s(data=2.0ms QKV=2.10s FFN=3.04s) eta=6d 13:35:08 | 43.9K token/s | 
[epoch_0]_11611  loss=3.465433 |g|=0.397	lr=5.53e-04 | 51.2%@S10  T=1.70s(data=1.9ms QKV=2.10s FFN=3.04s) eta=23:23:57 | 44.1K token/s | 
[epoch_0]_11621  loss=3.450144 |g|=0.363	lr=5.53e-04 | 52.0%@S10  T=1.69s(data=1.7ms QKV=2.10s FFN=3.04s) eta=23:15:13 | 44.3K token/s | 
[epoch_0]_11631  loss=3.427724 |g|=0.404	lr=5.52e-04 | 52.8%@S10  T=1.69s(data=2.0ms QKV=2.10s FFN=3.04s) eta=23:14:53 | 44.5K token/s | 
[epoch_0]_11641  loss=3.540405 |g|=0.424	lr=5.52e-04 | 53.6%@S10  T=1.70s(data=1.9ms QKV=2.10s FFN=3.04s) eta=23:15:31 | 44.7K token/s | 
[epoch_0]_11651  loss=3.457180 |g|=0.408	lr=5.52e-04 | 54.5%@S10  T=1.67s(data=1.6ms QKV=2.10s FFN=3.04s) eta=22:54:59 | 44.9K token/s | 
[epoch_0]_11661  loss=3.457420 |g|=0.399	lr=5.52e-04 | 55.3%@S10  T=1.69s(data=1.5ms QKV=2.10s FFN=3.04s) eta=23:10:51 | 45.1K token/s | 
[epoch_0]_11671  loss=3.546887 |g|=0.384	lr=5.52e-04 | 56.1%@S10  T=1.67s(data=2.0ms QKV=2.10s FFN=3.04s) eta=22:56:23 | 45.3K token/s | 
[epoch_0]_11681  loss=3.506266 |g|=0.407	lr=5.52e-04 | 56.9%@S10  T=1.71s(data=1.6ms QKV=2.10s FFN=3.04s) eta=23:30:19 | 45.4K token/s | 
[epoch_0]_11691  loss=3.548104 |g|=0.406	lr=5.52e-04 | 57.7%@S10  T=1.69s(data=1.6ms QKV=2.10s FFN=3.04s) eta=23:07:33 | 45.6K token/s | 
[Fuyou] head="2" update algorithm=4 t=10.95s
[Section@11700] layer[24-32] tasks=19(nPassBack=0) last_loss=3.49143(-0.000945091) N=(772,13776,13216 1544268)
[epoch_0]_11701  loss=3.451032 |g|=0.385	lr=5.52e-04 | 58.5%@S10  T=4.30s(data=2.1ms QKV=2.10s FFN=3.04s) eta=2d 10:51:52 | 44.2K token/s | 
[epoch_0]_11711  loss=3.504561 |g|=0.399	lr=5.52e-04 | 59.4%@S10  T=1.71s(data=1.9ms QKV=2.10s FFN=3.04s) eta=23:24:38 | 44.4K token/s | 
[epoch_0]_11721  loss=3.442326 |g|=0.416	lr=5.52e-04 | 60.2%@S10  T=1.71s(data=1.5ms QKV=2.10s FFN=3.04s) eta=23:26:18 | 44.6K token/s | 
[epoch_0]_11731  loss=3.516154 |g|=0.407	lr=5.52e-04 | 61.0%@S10  T=1.70s(data=1.6ms QKV=2.10s FFN=3.04s) eta=23:17:46 | 44.8K token/s | 
[epoch_0]_11741  loss=3.501233 |g|=0.383	lr=5.52e-04 | 61.8%@S10  T=1.71s(data=1.7ms QKV=2.10s FFN=3.04s) eta=23:20:58 | 44.9K token/s | 
[epoch_0]_11751  loss=3.461900 |g|=0.431	lr=5.51e-04 | 62.6%@S10  T=1.69s(data=2.1ms QKV=2.10s FFN=3.04s) eta=23:10:41 | 45.1K token/s | 
[epoch_0]_11761  loss=3.524028 |g|=0.414	lr=5.51e-04 | 63.5%@S10  T=1.69s(data=1.6ms QKV=2.10s FFN=3.04s) eta=23:06:36 | 45.3K token/s | 
[epoch_0]_11771  loss=3.510696 |g|=0.43	lr=5.51e-04 | 64.3%@S10  T=1.70s(data=2.3ms QKV=2.10s FFN=3.04s) eta=23:12:12 | 45.4K token/s | 
[epoch_0]_11781  loss=3.516671 |g|=0.445	lr=5.51e-04 | 65.1%@S10  T=1.68s(data=1.7ms QKV=2.10s FFN=3.04s) eta=23:00:28 | 45.6K token/s | 
[epoch_0]_11791  loss=3.524228 |g|=0.39	lr=5.51e-04 | 65.9%@S10  T=1.72s(data=1.6ms QKV=2.10s FFN=3.04s) eta=23:32:59 | 45.7K token/s | 
[Fuyou] head="3" update algorithm=4 t=11.02s
[eval] 
	 Loss@"edu_fineweb1B"=3.456(0.0068) nBranch=1 nToken=6.31M best=3.4629(57) E2T=-0.0301 T=36.7518(0)s x=0
	#3.45606±0.0988 tps=172K(6.30784M) a=[3.25407,3.72761] T=36.7518(sec)
[Section@11800] layer[32-40] tasks=19(nPassBack=0) last_loss=3.48616(-0.0257325) N=(772,13888,13328 1557468)
[epoch_0]_11801  loss=3.475626 |g|=0.38	lr=5.51e-04 | 66.7%@S10  T=11.32s(data=2.1ms QKV=2.10s FFN=3.04s) eta=6d 10:47:00 | 43.8K token/s | 
[epoch_0]_11811  loss=3.488361 |g|=0.392	lr=5.51e-04 | 67.6%@S10  T=1.69s(data=1.9ms QKV=2.10s FFN=3.04s) eta=23:09:52 | 44.0K token/s | 
[epoch_0]_11821  loss=3.410046 |g|=0.405	lr=5.51e-04 | 68.4%@S10  T=1.70s(data=1.7ms QKV=2.10s FFN=3.04s) eta=23:16:33 | 44.2K token/s | 
[epoch_0]_11831  loss=3.482247 |g|=0.4	lr=5.51e-04 | 69.2%@S10  T=1.69s(data=1.5ms QKV=2.10s FFN=3.04s) eta=23:03:43 | 44.4K token/s | 
[epoch_0]_11841  loss=3.445557 |g|=0.377	lr=5.51e-04 | 70.0%@S10  T=1.70s(data=1.7ms QKV=2.10s FFN=3.04s) eta=23:15:55 | 44.6K token/s | 
[epoch_0]_11851  loss=3.437656 |g|=0.402	lr=5.51e-04 | 70.8%@S10  T=1.73s(data=1.7ms QKV=2.11s FFN=3.04s) eta=23:34:15 | 44.8K token/s | 
[epoch_0]_11861  loss=3.528236 |g|=0.393	lr=5.51e-04 | 71.7%@S10  T=1.71s(data=6.4ms QKV=2.11s FFN=3.05s) eta=23:24:20 | 44.9K token/s | 
[epoch_0]_11871  loss=3.546831 |g|=0.425	lr=5.50e-04 | 72.5%@S10  T=1.71s(data=1.8ms QKV=2.10s FFN=3.04s) eta=23:21:22 | 45.1K token/s | 
[epoch_0]_11881  loss=3.458730 |g|=0.417	lr=5.50e-04 | 73.3%@S10  T=1.71s(data=1.6ms QKV=2.10s FFN=3.04s) eta=23:22:07 | 45.2K token/s | 
[epoch_0]_11891  loss=3.529695 |g|=0.383	lr=5.50e-04 | 74.1%@S10  T=1.72s(data=1.8ms QKV=2.10s FFN=3.04s) eta=23:28:44 | 45.3K token/s | 
[Fuyou] head="4" update algorithm=4 t=9.97s
[Section@11900] layer[40-48] tasks=19(nPassBack=0) last_loss=3.35879(0.146121) N=(772,14000,13440 1570668)
[epoch_0]_11901  loss=3.453171 |g|=0.361	lr=5.50e-04 | 74.9%@S10  T=3.94s(data=1.6ms QKV=2.10s FFN=3.04s) eta=2d 05:45:57 | 44.1K token/s | 
[epoch_0]_11911  loss=3.488816 |g|=0.398	lr=5.50e-04 | 75.8%@S10  T=1.71s(data=1.6ms QKV=2.10s FFN=3.04s) eta=23:17:51 | 44.3K token/s | 
[epoch_0]_11921  loss=3.506647 |g|=0.427	lr=5.50e-04 | 76.6%@S10  T=1.70s(data=1.5ms QKV=2.11s FFN=3.04s) eta=23:09:23 | 44.5K token/s | 
[epoch_0]_11931  loss=3.470696 |g|=0.377	lr=5.50e-04 | 77.4%@S10  T=1.70s(data=1.5ms QKV=2.10s FFN=3.04s) eta=23:13:44 | 44.7K token/s | 
[epoch_0]_11941  loss=3.482372 |g|=0.401	lr=5.50e-04 | 78.2%@S10  T=1.70s(data=1.5ms QKV=2.10s FFN=3.04s) eta=23:15:05 | 44.8K token/s | 
[epoch_0]_11951  loss=3.563942 |g|=0.4	lr=5.50e-04 | 79.0%@S10  T=1.71s(data=1.7ms QKV=2.10s FFN=3.04s) eta=23:15:16 | 45.0K token/s | 
[epoch_0]_11961  loss=3.477946 |g|=0.45	lr=5.50e-04 | 79.8%@S10  T=1.80s(data=1.5ms QKV=2.11s FFN=3.04s) eta=1d 00:28:37 | 45.0K token/s | 
[epoch_0]_11971  loss=3.525587 |g|=0.408	lr=5.50e-04 | 80.7%@S10  T=1.74s(data=1.6ms QKV=2.10s FFN=3.04s) eta=23:39:35 | 45.1K token/s | 
[epoch_0]_11981  loss=3.489949 |g|=0.39	lr=5.50e-04 | 81.5%@S10  T=1.69s(data=1.7ms QKV=2.10s FFN=3.04s) eta=23:05:04 | 45.3K token/s | 
[epoch_0]_11991  loss=3.429044 |g|=0.396	lr=5.49e-04 | 82.3%@S10  T=1.70s(data=1.7ms QKV=2.11s FFN=3.04s) eta=23:13:19 | 45.4K token/s | 
[Fuyou] head="5" update algorithm=4 t=9.84s
[eval] 
	 Loss@"edu_fineweb1B"=3.452(0.0041) nBranch=1 nToken=6.31M best=3.4561(58) E2T=-0.0955 T=36.7558(0)s x=0
	#3.45197±0.0985 tps=172K(6.30784M) a=[3.25911,3.72145] T=36.7558(sec)
[Section@12000] layer[0-8] tasks=19(nPassBack=0) last_loss=3.54749(-0.00388265) N=(772,14112,13552 1583868)
[epoch_0]_12001  loss=3.431633 |g|=0.353	lr=5.49e-04 | 83.1%@S10  T=12.01s(data=1.6ms QKV=2.10s FFN=3.04s) eta=6d 19:33:27 | 43.5K token/s | 
[epoch_0]_12011  loss=3.426891 |g|=0.392	lr=5.49e-04 | 83.9%@S10  T=1.71s(data=1.7ms QKV=2.10s FFN=3.04s) eta=23:14:23 | 43.7K token/s | 
[epoch_0]_12021  loss=3.436264 |g|=0.421	lr=5.49e-04 | 84.8%@S10  T=1.70s(data=1.6ms QKV=2.10s FFN=3.04s) eta=23:05:16 | 44.0K token/s | 
[epoch_0]_12031  loss=3.471290 |g|=0.391	lr=5.49e-04 | 85.6%@S10  T=1.70s(data=1.7ms QKV=2.10s FFN=3.04s) eta=23:10:45 | 44.2K token/s | 
[epoch_0]_12041  loss=3.542347 |g|=0.407	lr=5.49e-04 | 86.4%@S10  T=1.67s(data=1.6ms QKV=2.11s FFN=3.04s) eta=22:47:23 | 44.4K token/s | 
[epoch_0]_12051  loss=3.440891 |g|=0.444	lr=5.49e-04 | 87.2%@S10  T=1.72s(data=1.5ms QKV=2.10s FFN=3.04s) eta=23:21:18 | 44.6K token/s | 
[epoch_0]_12061  loss=3.502042 |g|=0.422	lr=5.49e-04 | 88.0%@S10  T=1.69s(data=1.6ms QKV=2.10s FFN=3.04s) eta=22:57:17 | 44.8K token/s | 
[epoch_0]_12071  loss=3.523694 |g|=0.394	lr=5.49e-04 | 88.9%@S10  T=1.73s(data=1.7ms QKV=2.10s FFN=3.04s) eta=23:29:35 | 44.9K token/s | 
[epoch_0]_12081  loss=3.432725 |g|=0.389	lr=5.49e-04 | 89.7%@S10  T=1.71s(data=1.6ms QKV=2.10s FFN=3.04s) eta=23:18:41 | 45.0K token/s | 
[epoch_0]_12091  loss=3.434595 |g|=0.399	lr=5.49e-04 | 90.5%@S10  T=1.72s(data=1.5ms QKV=2.11s FFN=3.04s) eta=23:19:37 | 45.2K token/s | 
[Fuyou] head="0" update algorithm=4 t=11.01s
[Section@12100] layer[8-16] tasks=19(nPassBack=0) last_loss=3.44323(-0.0192616) N=(772,14224,13664 1597068)
[epoch_0]_12101  loss=3.479837 |g|=0.383	lr=5.48e-04 | 91.3%@S10  T=3.96s(data=1.8ms QKV=2.10s FFN=3.04s) eta=2d 05:45:46 | 44.0K token/s | 
[epoch_0]_12111  loss=3.500024 |g|=0.418	lr=5.48e-04 | 92.1%@S10  T=1.74s(data=1.6ms QKV=2.10s FFN=3.04s) eta=23:35:30 | 44.1K token/s | 
[epoch_0]_12121  loss=3.433648 |g|=0.362	lr=5.48e-04 | 93.0%@S10  T=1.69s(data=1.8ms QKV=2.10s FFN=3.04s) eta=23:00:57 | 44.3K token/s | 
[epoch_0]_12131  loss=3.425040 |g|=0.405	lr=5.48e-04 | 93.8%@S10  T=1.71s(data=1.6ms QKV=2.10s FFN=3.04s) eta=23:11:42 | 44.5K token/s | 
[epoch_0]_12141  loss=3.519190 |g|=0.415	lr=5.48e-04 | 94.6%@S10  T=1.68s(data=1.7ms QKV=2.10s FFN=3.04s) eta=22:47:07 | 44.7K token/s | 
[epoch_0]_12151  loss=3.449170 |g|=0.42	lr=5.48e-04 | 95.4%@S10  T=1.73s(data=1.7ms QKV=2.10s FFN=3.04s) eta=23:26:34 | 44.9K token/s | 
[epoch_0]_12161  loss=3.502025 |g|=0.409	lr=5.48e-04 | 96.2%@S10  T=1.71s(data=1.5ms QKV=2.10s FFN=3.04s) eta=23:15:36 | 45.0K token/s | 
[epoch_0]_12171  loss=3.496977 |g|=0.379	lr=5.48e-04 | 97.1%@S10  T=1.73s(data=1.7ms QKV=2.10s FFN=3.04s) eta=23:28:58 | 45.1K token/s | 
[epoch_0]_12181  loss=3.434043 |g|=0.415	lr=5.48e-04 | 97.9%@S10  T=1.71s(data=1.5ms QKV=2.10s FFN=3.04s) eta=23:08:38 | 45.3K token/s | 
[epoch_0]_12191  loss=3.465118 |g|=0.395	lr=5.48e-04 | 98.7%@S10  T=1.67s(data=1.8ms QKV=2.10s FFN=3.04s) eta=22:37:33 | 45.5K token/s | 
[Fuyou] head="1" update algorithm=4 t=8.57s
[eval] 
	 Loss@"edu_fineweb1B"=3.447(0.005) nBranch=1 nToken=6.31M best=3.4520(59) E2T=-0.0557 T=36.7586(0)s x=0
	#3.44694±0.0983 tps=172K(6.30784M) a=[3.24775,3.71653] T=36.7586(sec)
[Section@12200] layer[16-24] tasks=19(nPassBack=0) last_loss=3.50266(-0.00142121) N=(772,14336,13776 1610268)
[epoch_0]_12201  loss=3.439591 |g|=0.393	lr=5.48e-04 | 99.5%@S10  T=12.11s(data=2.0ms QKV=2.10s FFN=3.04s) eta=6d 20:18:40 | 43.5K token/s | 
[epoch_0]_12206  loss=3.416884 |g|=0.384	lr=5.48e-04 | 99.9%@S10  T=1.71s(data=1.7ms QKV=2.10s FFN=3.04s) eta=23:13:59 | 43.7K token/s | 
[epoch_0]_12207  loss=3.493185 |g|=0.462	lr=5.48e-04 | 100.0%@S10  T=1.70s(data=1.6ms QKV=2.10s FFN=3.04s) eta=23:03:56 | 44.0K token/s | 
-------- End of shard_10@"./Datasets/edu_fineweb1B/edu_fineweb_train_000010.bin"-------- 
[shard-11]@"./Datasets/edu_fineweb1B/edu_fineweb_train_000465.bin": tokens=100(M) nShardSamples=1220(1074216) 
[epoch_0]_12211  loss=3.450828 |g|=0.407	lr=5.48e-04 | 0.3%@S11  T=1.68s(data=1.2ms QKV=2.10s FFN=3.04s) eta=22:45:27 | 44.2K token/s | 
[epoch_0]_12221  loss=3.453043 |g|=0.402	lr=5.47e-04 | 1.1%@S11  T=1.69s(data=1.2ms QKV=2.10s FFN=3.04s) eta=22:57:31 | 44.4K token/s | 
[epoch_0]_12231  loss=3.481252 |g|=0.393	lr=5.47e-04 | 2.0%@S11  T=1.70s(data=1.3ms QKV=2.10s FFN=3.04s) eta=23:03:40 | 44.6K token/s | 
[epoch_0]_12241  loss=3.418456 |g|=0.388	lr=5.47e-04 | 2.8%@S11  T=1.69s(data=1.5ms QKV=2.10s FFN=3.04s) eta=22:51:00 | 44.8K token/s | 
[epoch_0]_12251  loss=3.533571 |g|=0.44	lr=5.47e-04 | 3.6%@S11  T=1.70s(data=1.4ms QKV=2.10s FFN=3.04s) eta=23:00:56 | 45.0K token/s | 
[epoch_0]_12261  loss=3.448022 |g|=0.427	lr=5.47e-04 | 4.4%@S11  T=1.70s(data=1.3ms QKV=2.10s FFN=3.04s) eta=23:03:23 | 45.1K token/s | 
[epoch_0]_12271  loss=3.454516 |g|=0.374	lr=5.47e-04 | 5.2%@S11  T=1.67s(data=1.2ms QKV=2.10s FFN=3.04s) eta=22:38:39 | 45.3K token/s | 
[epoch_0]_12281  loss=3.364532 |g|=0.345	lr=5.47e-04 | 6.1%@S11  T=1.68s(data=1.2ms QKV=2.10s FFN=3.04s) eta=22:48:48 | 45.5K token/s | 
[epoch_0]_12291  loss=3.442780 |g|=0.404	lr=5.47e-04 | 6.9%@S11  T=1.70s(data=1.3ms QKV=2.10s FFN=3.04s) eta=23:02:57 | 45.6K token/s | 
[Fuyou] head="2" update algorithm=4 t=11.61s
[Section@12300] layer[24-32] tasks=19(nPassBack=0) last_loss=3.50252(-0.0110953) N=(772,14448,13888 1623468)
[epoch_0]_12301  loss=3.483397 |g|=0.432	lr=5.47e-04 | 7.7%@S11  T=3.96s(data=1.4ms QKV=2.10s FFN=3.04s) eta=2d 05:39:34 | 44.4K token/s | 
[epoch_0]_12311  loss=3.491795 |g|=0.423	lr=5.47e-04 | 8.5%@S11  T=1.69s(data=1.8ms QKV=2.10s FFN=3.04s) eta=22:51:30 | 44.6K token/s | 
[epoch_0]_12321  loss=3.476677 |g|=0.419	lr=5.47e-04 | 9.3%@S11  T=1.70s(data=1.5ms QKV=2.10s FFN=3.04s) eta=22:57:24 | 44.8K token/s | 
[epoch_0]_12331  loss=3.417694 |g|=0.383	lr=5.46e-04 | 10.2%@S11  T=1.70s(data=1.5ms QKV=2.10s FFN=3.05s) eta=22:57:58 | 44.9K token/s | 
[epoch_0]_12341  loss=3.448157 |g|=0.461	lr=5.46e-04 | 11.0%@S11  T=1.70s(data=1.4ms QKV=2.10s FFN=3.05s) eta=22:56:29 | 45.1K token/s | 
[epoch_0]_12351  loss=3.476206 |g|=0.442	lr=5.46e-04 | 11.8%@S11  T=1.70s(data=1.5ms QKV=2.10s FFN=3.05s) eta=22:57:16 | 45.3K token/s | 
[epoch_0]_12361  loss=3.435354 |g|=0.413	lr=5.46e-04 | 12.6%@S11  T=1.70s(data=1.8ms QKV=2.10s FFN=3.05s) eta=23:01:07 | 45.4K token/s | 
[epoch_0]_12371  loss=3.472644 |g|=0.429	lr=5.46e-04 | 13.4%@S11  T=1.69s(data=1.5ms QKV=2.10s FFN=3.05s) eta=22:52:25 | 45.6K token/s | 
[epoch_0]_12381  loss=3.512705 |g|=0.416	lr=5.46e-04 | 14.3%@S11  T=1.69s(data=1.4ms QKV=2.10s FFN=3.05s) eta=22:47:40 | 45.7K token/s | 
[epoch_0]_12391  loss=3.466504 |g|=0.415	lr=5.46e-04 | 15.1%@S11  T=1.67s(data=1.5ms QKV=2.10s FFN=3.05s) eta=22:36:48 | 45.9K token/s | 
[Fuyou] head="3" update algorithm=4 t=11.71s
[eval] 
	 Loss@"edu_fineweb1B"=3.452(-0.0055) nBranch=1 nToken=6.31M best=3.4520(59) E2T=-0.0726 T=36.7223(0)s x=0
	#3.45242±0.0986 tps=172K(6.30784M) a=[3.2555,3.72343] T=36.7223(sec)
[Section@12400] layer[32-40] tasks=19(nPassBack=0) last_loss=3.52497(-0.0388136) N=(772,14560,14000 1636668)
[epoch_0]_12401  loss=3.480390 |g|=0.382	lr=5.46e-04 | 15.9%@S11  T=11.59s(data=1.6ms QKV=2.10s FFN=3.04s) eta=6d 12:31:33 | 43.9K token/s | 
[epoch_0]_12411  loss=3.569671 |g|=0.413	lr=5.46e-04 | 16.7%@S11  T=1.70s(data=1.9ms QKV=2.10s FFN=3.04s) eta=22:57:16 | 44.1K token/s | 
[epoch_0]_12421  loss=3.459446 |g|=0.424	lr=5.46e-04 | 17.5%@S11  T=1.69s(data=1.8ms QKV=2.10s FFN=3.05s) eta=22:53:02 | 44.4K token/s | 
[epoch_0]_12431  loss=3.497975 |g|=0.376	lr=5.46e-04 | 18.4%@S11  T=1.72s(data=1.7ms QKV=2.10s FFN=3.05s) eta=23:13:49 | 44.5K token/s | 
[epoch_0]_12441  loss=3.471193 |g|=0.393	lr=5.45e-04 | 19.2%@S11  T=1.73s(data=1.8ms QKV=2.10s FFN=3.05s) eta=23:21:07 | 44.7K token/s | 
[epoch_0]_12451  loss=3.446536 |g|=0.406	lr=5.45e-04 | 20.0%@S11  T=1.71s(data=1.6ms QKV=2.10s FFN=3.05s) eta=23:03:45 | 44.8K token/s | 
[epoch_0]_12461  loss=3.487451 |g|=0.372	lr=5.45e-04 | 20.8%@S11  T=1.73s(data=1.6ms QKV=2.10s FFN=3.05s) eta=23:20:26 | 45.0K token/s | 
[epoch_0]_12471  loss=3.393684 |g|=0.387	lr=5.45e-04 | 21.6%@S11  T=1.70s(data=1.9ms QKV=2.10s FFN=3.05s) eta=22:55:41 | 45.1K token/s | 
[epoch_0]_12481  loss=3.452595 |g|=0.367	lr=5.45e-04 | 22.4%@S11  T=1.67s(data=1.7ms QKV=2.10s FFN=3.05s) eta=22:29:31 | 45.3K token/s | 
[epoch_0]_12491  loss=3.418463 |g|=0.409	lr=5.45e-04 | 23.3%@S11  T=1.67s(data=1.7ms QKV=2.10s FFN=3.05s) eta=22:30:30 | 45.5K token/s | 
[Fuyou] head="4" update algorithm=4 t=11.03s
[Section@12500] layer[40-48] tasks=19(nPassBack=0) last_loss=3.46004(-0.101252) N=(772,14672,14112 1649868)
[epoch_0]_12501  loss=3.487205 |g|=0.35	lr=5.45e-04 | 24.1%@S11  T=3.95s(data=1.7ms QKV=2.10s FFN=3.04s) eta=2d 05:19:04 | 44.3K token/s | 
[epoch_0]_12511  loss=3.379424 |g|=0.366	lr=5.45e-04 | 24.9%@S11  T=1.68s(data=1.5ms QKV=2.10s FFN=3.04s) eta=22:40:58 | 44.5K token/s | 
[epoch_0]_12521  loss=3.487402 |g|=0.392	lr=5.45e-04 | 25.7%@S11  T=1.69s(data=1.7ms QKV=2.10s FFN=3.04s) eta=22:46:02 | 44.7K token/s | 
[epoch_0]_12531  loss=3.448110 |g|=0.385	lr=5.45e-04 | 26.5%@S11  T=1.70s(data=1.5ms QKV=2.10s FFN=3.05s) eta=22:54:31 | 44.9K token/s | 
[epoch_0]_12541  loss=3.485119 |g|=0.411	lr=5.45e-04 | 27.4%@S11  T=1.69s(data=1.7ms QKV=2.10s FFN=3.05s) eta=22:47:55 | 45.0K token/s | 
[epoch_0]_12551  loss=3.400950 |g|=0.381	lr=5.45e-04 | 28.2%@S11  T=1.70s(data=1.7ms QKV=2.10s FFN=3.04s) eta=22:52:08 | 45.2K token/s | 
[epoch_0]_12561  loss=3.449366 |g|=0.377	lr=5.44e-04 | 29.0%@S11  T=1.70s(data=1.5ms QKV=2.10s FFN=3.05s) eta=22:56:23 | 45.3K token/s | 
[epoch_0]_12571  loss=3.497569 |g|=0.412	lr=5.44e-04 | 29.8%@S11  T=1.69s(data=1.4ms QKV=2.10s FFN=3.05s) eta=22:47:46 | 45.5K token/s | 
[epoch_0]_12581  loss=3.413493 |g|=0.427	lr=5.44e-04 | 30.6%@S11  T=1.71s(data=1.7ms QKV=2.10s FFN=3.05s) eta=22:58:31 | 45.6K token/s | 
[epoch_0]_12591  loss=3.526146 |g|=0.451	lr=5.44e-04 | 31.5%@S11  T=1.72s(data=1.5ms QKV=2.10s FFN=3.05s) eta=23:07:33 | 45.7K token/s | 
[Fuyou] head="5" update algorithm=4 t=9.66s
[eval] 
	 Loss@"edu_fineweb1B"=3.454(-0.0017) nBranch=1 nToken=6.31M best=3.4520(59) E2T=-0.00306 T=36.7783(0)s x=0
	#3.45412±0.0983 tps=172K(6.30784M) a=[3.26,3.72434] T=36.7783(sec)
[Section@12600] layer[0-8] tasks=19(nPassBack=0) last_loss=3.45717(0.0903141) N=(772,14784,14224 1663068)
[epoch_0]_12601  loss=3.394829 |g|=0.421	lr=5.44e-04 | 32.3%@S11  T=12.17s(data=1.8ms QKV=2.10s FFN=3.04s) eta=6d 19:40:19 | 43.8K token/s | 
[epoch_0]_12611  loss=3.426204 |g|=0.394	lr=5.44e-04 | 33.1%@S11  T=1.70s(data=1.7ms QKV=2.10s FFN=3.05s) eta=22:54:05 | 44.0K token/s | 
[epoch_0]_12621  loss=3.441684 |g|=0.407	lr=5.44e-04 | 33.9%@S11  T=1.70s(data=2.1ms QKV=2.10s FFN=3.05s) eta=22:50:46 | 44.2K token/s | 
[epoch_0]_12631  loss=3.468439 |g|=0.393	lr=5.44e-04 | 34.7%@S11  T=1.70s(data=1.7ms QKV=2.10s FFN=3.05s) eta=22:51:51 | 44.4K token/s | 
[epoch_0]_12641  loss=3.481357 |g|=0.389	lr=5.44e-04 | 35.6%@S11  T=1.71s(data=1.6ms QKV=2.10s FFN=3.04s) eta=22:55:32 | 44.6K token/s | 
[epoch_0]_12651  loss=3.347459 |g|=0.409	lr=5.44e-04 | 36.4%@S11  T=1.69s(data=1.6ms QKV=2.10s FFN=3.05s) eta=22:44:43 | 44.8K token/s | 
[epoch_0]_12661  loss=3.383795 |g|=0.368	lr=5.44e-04 | 37.2%@S11  T=1.71s(data=1.7ms QKV=2.10s FFN=3.05s) eta=22:58:10 | 44.9K token/s | 
[epoch_0]_12671  loss=3.434162 |g|=0.398	lr=5.43e-04 | 38.0%@S11  T=1.69s(data=1.6ms QKV=2.10s FFN=3.05s) eta=22:45:38 | 45.1K token/s | 
[epoch_0]_12681  loss=3.405065 |g|=0.407	lr=5.43e-04 | 38.8%@S11  T=1.70s(data=1.5ms QKV=2.10s FFN=3.05s) eta=22:46:33 | 45.3K token/s | 
[epoch_0]_12691  loss=3.394570 |g|=0.412	lr=5.43e-04 | 39.7%@S11  T=1.69s(data=1.5ms QKV=2.10s FFN=3.05s) eta=22:40:42 | 45.4K token/s | 
[Fuyou] head="0" update algorithm=4 t=10.11s
[Section@12700] layer[8-16] tasks=19(nPassBack=0) last_loss=3.42101(0.0222206) N=(772,14896,14336 1676268)
[epoch_0]_12701  loss=3.479765 |g|=0.376	lr=5.43e-04 | 40.5%@S11  T=4.13s(data=2.3ms QKV=2.10s FFN=3.04s) eta=2d 07:30:49 | 44.1K token/s | 
[epoch_0]_12711  loss=3.461780 |g|=0.42	lr=5.43e-04 | 41.3%@S11  T=1.65s(data=1.7ms QKV=2.10s FFN=3.04s) eta=22:08:56 | 44.4K token/s | 
[epoch_0]_12721  loss=3.501926 |g|=0.427	lr=5.43e-04 | 42.1%@S11  T=1.70s(data=2.0ms QKV=2.10s FFN=3.05s) eta=22:46:35 | 44.6K token/s | 
[epoch_0]_12731  loss=3.388326 |g|=0.42	lr=5.43e-04 | 42.9%@S11  T=1.70s(data=1.6ms QKV=2.10s FFN=3.04s) eta=22:51:26 | 44.8K token/s | 
[epoch_0]_12741  loss=3.467379 |g|=0.409	lr=5.43e-04 | 43.7%@S11  T=1.72s(data=1.6ms QKV=2.10s FFN=3.05s) eta=23:00:28 | 44.9K token/s | 
[epoch_0]_12751  loss=3.386035 |g|=0.415	lr=5.43e-04 | 44.6%@S11  T=1.70s(data=1.5ms QKV=2.10s FFN=3.05s) eta=22:51:51 | 45.1K token/s | 
[epoch_0]_12761  loss=3.435040 |g|=0.408	lr=5.43e-04 | 45.4%@S11  T=1.67s(data=1.8ms QKV=2.10s FFN=3.05s) eta=22:27:34 | 45.3K token/s | 
[epoch_0]_12771  loss=3.366215 |g|=0.418	lr=5.43e-04 | 46.2%@S11  T=1.67s(data=2.0ms QKV=2.10s FFN=3.05s) eta=22:22:57 | 45.5K token/s | 
[epoch_0]_12781  loss=3.466304 |g|=0.353	lr=5.42e-04 | 47.0%@S11  T=1.71s(data=1.7ms QKV=2.10s FFN=3.05s) eta=22:51:52 | 45.6K token/s | 
[epoch_0]_12791  loss=3.395878 |g|=0.437	lr=5.42e-04 | 47.8%@S11  T=1.67s(data=1.8ms QKV=2.10s FFN=3.05s) eta=22:22:18 | 45.8K token/s | 
[Fuyou] head="1" update algorithm=4 t=10.89s
[eval] 
	 Loss@"edu_fineweb1B"=3.451(0.0026) nBranch=1 nToken=6.31M best=3.4541(62) E2T=-0.00319 T=36.7382(0)s x=0
	#3.45149±0.0976 tps=172K(6.30784M) a=[3.25165,3.71815] T=36.7382(sec)
[Section@12800] layer[16-24] tasks=19(nPassBack=0) last_loss=3.45468(0.0479782) N=(772,15008,14448 1689468)
[epoch_0]_12801  loss=3.443785 |g|=0.367	lr=5.42e-04 | 48.7%@S11  T=11.56s(data=2.5ms QKV=2.10s FFN=3.04s) eta=6d 10:54:54 | 43.8K token/s | 
[epoch_0]_12811  loss=3.440168 |g|=0.421	lr=5.42e-04 | 49.5%@S11  T=1.70s(data=1.8ms QKV=2.10s FFN=3.04s) eta=22:48:35 | 44.1K token/s | 
[epoch_0]_12821  loss=3.426467 |g|=0.386	lr=5.42e-04 | 50.3%@S11  T=1.72s(data=1.7ms QKV=2.10s FFN=3.05s) eta=23:02:53 | 44.2K token/s | 
[epoch_0]_12831  loss=3.330567 |g|=0.392	lr=5.42e-04 | 51.1%@S11  T=1.72s(data=1.7ms QKV=2.10s FFN=3.05s) eta=23:04:02 | 44.4K token/s | 
[epoch_0]_12841  loss=3.426825 |g|=0.391	lr=5.42e-04 | 51.9%@S11  T=1.72s(data=1.5ms QKV=2.10s FFN=3.05s) eta=23:00:20 | 44.6K token/s | 
[epoch_0]_12851  loss=3.412624 |g|=0.416	lr=5.42e-04 | 52.8%@S11  T=1.70s(data=1.7ms QKV=2.10s FFN=3.04s) eta=22:47:37 | 44.7K token/s | 
[epoch_0]_12861  loss=3.472792 |g|=0.423	lr=5.42e-04 | 53.6%@S11  T=1.72s(data=1.7ms QKV=2.10s FFN=3.05s) eta=23:02:37 | 44.9K token/s | 
[epoch_0]_12871  loss=3.450978 |g|=0.393	lr=5.42e-04 | 54.4%@S11  T=1.70s(data=1.5ms QKV=2.10s FFN=3.05s) eta=22:40:54 | 45.0K token/s | 
[epoch_0]_12881  loss=3.387170 |g|=0.398	lr=5.42e-04 | 55.2%@S11  T=1.70s(data=1.5ms QKV=2.10s FFN=3.05s) eta=22:41:09 | 45.2K token/s | 
[epoch_0]_12891  loss=3.445362 |g|=0.393	lr=5.41e-04 | 56.0%@S11  T=1.72s(data=1.7ms QKV=2.10s FFN=3.04s) eta=23:01:48 | 45.3K token/s | 
[Fuyou] head="2" update algorithm=4 t=9.98s
[Section@12900] layer[24-32] tasks=19(nPassBack=0) last_loss=3.46398(0.038543) N=(772,15120,14560 1702668)
[epoch_0]_12901  loss=3.448663 |g|=0.407	lr=5.41e-04 | 56.9%@S11  T=4.25s(data=1.7ms QKV=2.10s FFN=3.04s) eta=2d 08:52:30 | 44.0K token/s | 
[epoch_0]_12911  loss=3.359249 |g|=0.43	lr=5.41e-04 | 57.7%@S11  T=1.65s(data=1.7ms QKV=2.10s FFN=3.04s) eta=22:07:13 | 44.3K token/s | 
[epoch_0]_12921  loss=3.423652 |g|=0.398	lr=5.41e-04 | 58.5%@S11  T=1.69s(data=1.7ms QKV=2.10s FFN=3.04s) eta=22:32:32 | 44.5K token/s | 
[epoch_0]_12931  loss=3.458757 |g|=0.399	lr=5.41e-04 | 59.3%@S11  T=1.68s(data=1.7ms QKV=2.10s FFN=3.04s) eta=22:28:31 | 44.7K token/s | 
[epoch_0]_12941  loss=3.485081 |g|=0.414	lr=5.41e-04 | 60.1%@S11  T=1.69s(data=1.5ms QKV=2.10s FFN=3.05s) eta=22:35:17 | 44.9K token/s | 
[epoch_0]_12951  loss=3.427090 |g|=0.442	lr=5.41e-04 | 60.9%@S11  T=1.71s(data=1.5ms QKV=2.10s FFN=3.04s) eta=22:53:41 | 45.1K token/s | 
[epoch_0]_12961  loss=3.333298 |g|=0.425	lr=5.41e-04 | 61.8%@S11  T=1.69s(data=1.5ms QKV=2.10s FFN=3.05s) eta=22:33:51 | 45.2K token/s | 
[epoch_0]_12971  loss=3.427202 |g|=0.433	lr=5.41e-04 | 62.6%@S11  T=1.72s(data=1.7ms QKV=2.10s FFN=3.04s) eta=22:54:03 | 45.4K token/s | 
[epoch_0]_12981  loss=3.368009 |g|=0.425	lr=5.41e-04 | 63.4%@S11  T=1.69s(data=1.8ms QKV=2.10s FFN=3.04s) eta=22:36:28 | 45.5K token/s | 
[epoch_0]_12991  loss=3.488414 |g|=0.405	lr=5.40e-04 | 64.2%@S11  T=1.72s(data=1.6ms QKV=2.10s FFN=3.04s) eta=22:54:54 | 45.6K token/s | 
[Fuyou] head="3" update algorithm=4 t=9.40s
[eval] 
	 Loss@"edu_fineweb1B"=3.448(0.0035) nBranch=1 nToken=6.31M best=3.4515(63) E2T=-0.118 T=36.7282(0)s x=0
	#3.44801±0.0990 tps=172K(6.30784M) a=[3.25167,3.71535] T=36.7282(sec)
[Section@13000] layer[32-40] tasks=19(nPassBack=0) last_loss=3.56555(-0.0405724) N=(772,15232,14672 1715868)
[epoch_0]_13001  loss=3.446103 |g|=0.372	lr=5.40e-04 | 65.0%@S11  T=11.36s(data=1.6ms QKV=2.10s FFN=3.04s) eta=6d 07:35:21 | 43.7K token/s | 
[epoch_0]_13011  loss=3.398899 |g|=0.422	lr=5.40e-04 | 65.9%@S11  T=1.69s(data=1.6ms QKV=2.10s FFN=3.04s) eta=22:34:54 | 43.9K token/s | 
[epoch_0]_13021  loss=3.468667 |g|=0.392	lr=5.40e-04 | 66.7%@S11  T=1.67s(data=1.6ms QKV=2.10s FFN=3.04s) eta=22:18:34 | 44.2K token/s | 
[epoch_0]_13031  loss=3.432722 |g|=0.363	lr=5.40e-04 | 67.5%@S11  T=1.68s(data=1.6ms QKV=2.10s FFN=3.04s) eta=22:20:08 | 44.4K token/s | 
[epoch_0]_13041  loss=3.380787 |g|=0.402	lr=5.40e-04 | 68.3%@S11  T=1.71s(data=1.7ms QKV=2.10s FFN=3.04s) eta=22:51:02 | 44.6K token/s | 
[epoch_0]_13051  loss=3.412502 |g|=0.399	lr=5.40e-04 | 69.1%@S11  T=1.68s(data=1.6ms QKV=2.10s FFN=3.05s) eta=22:25:22 | 44.8K token/s | 
[epoch_0]_13061  loss=3.498261 |g|=0.423	lr=5.40e-04 | 70.0%@S11  T=1.71s(data=1.8ms QKV=2.10s FFN=3.05s) eta=22:45:50 | 44.9K token/s | 
[epoch_0]_13071  loss=3.496105 |g|=0.408	lr=5.40e-04 | 70.8%@S11  T=1.69s(data=1.8ms QKV=2.10s FFN=3.04s) eta=22:33:31 | 45.1K token/s | 
[epoch_0]_13081  loss=3.492136 |g|=0.391	lr=5.40e-04 | 71.6%@S11  T=1.69s(data=1.5ms QKV=2.10s FFN=3.04s) eta=22:32:40 | 45.3K token/s | 
[epoch_0]_13091  loss=3.409962 |g|=0.364	lr=5.40e-04 | 72.4%@S11  T=1.69s(data=1.5ms QKV=2.10s FFN=3.05s) eta=22:29:28 | 45.4K token/s | 
[Fuyou] head="4" update algorithm=4 t=11.10s
[Section@13100] layer[40-48] tasks=19(nPassBack=0) last_loss=3.43309(0.0269501) N=(772,15344,14784 1729068)
[epoch_0]_13101  loss=3.391809 |g|=0.377	lr=5.39e-04 | 73.2%@S11  T=4.35s(data=1.7ms QKV=2.10s FFN=3.04s) eta=2d 09:54:20 | 44.1K token/s | 
[epoch_0]_13111  loss=3.454163 |g|=0.432	lr=5.39e-04 | 74.1%@S11  T=1.66s(data=1.7ms QKV=2.10s FFN=3.04s) eta=22:06:00 | 44.4K token/s | 
[epoch_0]_13121  loss=3.420619 |g|=0.4	lr=5.39e-04 | 74.9%@S11  T=1.69s(data=1.8ms QKV=2.10s FFN=3.04s) eta=22:27:56 | 44.6K token/s | 
[epoch_0]_13131  loss=3.371003 |g|=0.391	lr=5.39e-04 | 75.7%@S11  T=1.66s(data=1.7ms QKV=2.10s FFN=3.04s) eta=22:08:30 | 44.8K token/s | 
[epoch_0]_13141  loss=3.443180 |g|=0.432	lr=5.39e-04 | 76.5%@S11  T=1.70s(data=1.7ms QKV=2.10s FFN=3.04s) eta=22:38:58 | 45.0K token/s | 
[epoch_0]_13151  loss=3.404645 |g|=0.379	lr=5.39e-04 | 77.3%@S11  T=1.68s(data=1.7ms QKV=2.10s FFN=3.05s) eta=22:16:58 | 45.2K token/s | 
[epoch_0]_13161  loss=3.472719 |g|=0.431	lr=5.39e-04 | 78.2%@S11  T=1.69s(data=1.5ms QKV=2.10s FFN=3.05s) eta=22:31:46 | 45.3K token/s | 
[epoch_0]_13171  loss=3.372305 |g|=0.412	lr=5.39e-04 | 79.0%@S11  T=1.70s(data=1.6ms QKV=2.10s FFN=3.04s) eta=22:34:24 | 45.5K token/s | 
[epoch_0]_13181  loss=3.445359 |g|=0.402	lr=5.39e-04 | 79.8%@S11  T=1.71s(data=1.7ms QKV=2.10s FFN=3.05s) eta=22:42:18 | 45.6K token/s | 
[epoch_0]_13191  loss=3.413382 |g|=0.397	lr=5.39e-04 | 80.6%@S11  T=1.69s(data=1.5ms QKV=2.10s FFN=3.05s) eta=22:28:24 | 45.7K token/s | 
[Fuyou] head="5" update algorithm=4 t=10.98s
[eval] 
	 Loss@"edu_fineweb1B"=3.448(-0.0001) nBranch=1 nToken=6.31M best=3.4480(64) E2T=0.051 T=36.7078(0)s x=0
	#3.44811±0.0988 tps=172K(6.30784M) a=[3.24693,3.72062] T=36.7078(sec)
[Section@13200] layer[0-8] tasks=19(nPassBack=0) last_loss=3.39713(0.0600433) N=(772,15456,14896 1742268)
[epoch_0]_13201  loss=3.381732 |g|=0.386	lr=5.39e-04 | 81.4%@S11  T=11.52s(data=1.9ms QKV=2.10s FFN=3.04s) eta=6d 09:05:30 | 43.8K token/s | 
[epoch_0]_13211  loss=3.456696 |g|=0.378	lr=5.38e-04 | 82.2%@S11  T=1.67s(data=1.7ms QKV=2.10s FFN=3.04s) eta=22:07:41 | 44.1K token/s | 
[epoch_0]_13221  loss=3.404567 |g|=0.387	lr=5.38e-04 | 83.1%@S11  T=1.72s(data=2.2ms QKV=2.10s FFN=3.04s) eta=22:49:10 | 44.3K token/s | 
[epoch_0]_13231  loss=3.464366 |g|=0.387	lr=5.38e-04 | 83.9%@S11  T=1.70s(data=1.7ms QKV=2.10s FFN=3.04s) eta=22:35:08 | 44.5K token/s | 
[epoch_0]_13241  loss=3.378456 |g|=0.421	lr=5.38e-04 | 84.7%@S11  T=1.69s(data=1.7ms QKV=2.10s FFN=3.04s) eta=22:28:27 | 44.7K token/s | 
[epoch_0]_13251  loss=3.524777 |g|=0.415	lr=5.38e-04 | 85.5%@S11  T=1.71s(data=1.8ms QKV=2.10s FFN=3.04s) eta=22:39:55 | 44.8K token/s | 
[epoch_0]_13261  loss=3.406433 |g|=0.396	lr=5.38e-04 | 86.3%@S11  T=1.70s(data=1.7ms QKV=2.10s FFN=3.04s) eta=22:32:59 | 45.0K token/s | 
[epoch_0]_13271  loss=3.474072 |g|=0.391	lr=5.38e-04 | 87.2%@S11  T=1.69s(data=1.7ms QKV=2.10s FFN=3.04s) eta=22:26:26 | 45.2K token/s | 
[epoch_0]_13281  loss=3.394357 |g|=0.424	lr=5.38e-04 | 88.0%@S11  T=1.71s(data=1.5ms QKV=2.10s FFN=3.04s) eta=22:41:40 | 45.3K token/s | 
[epoch_0]_13291  loss=3.431785 |g|=0.405	lr=5.38e-04 | 88.8%@S11  T=1.70s(data=1.6ms QKV=2.10s FFN=3.04s) eta=22:35:11 | 45.4K token/s | 
[Fuyou] head="0" update algorithm=4 t=8.20s
[Section@13300] layer[8-16] tasks=19(nPassBack=0) last_loss=3.39688(0.024138) N=(772,15568,15008 1755468)
[epoch_0]_13301  loss=3.446074 |g|=0.378	lr=5.38e-04 | 89.6%@S11  T=4.20s(data=1.9ms QKV=2.10s FFN=3.04s) eta=2d 07:38:24 | 44.1K token/s | 
[epoch_0]_13311  loss=3.386536 |g|=0.415	lr=5.37e-04 | 90.4%@S11  T=1.71s(data=1.8ms QKV=2.10s FFN=3.04s) eta=22:41:34 | 44.3K token/s | 
[epoch_0]_13321  loss=3.439686 |g|=0.404	lr=5.37e-04 | 91.3%@S11  T=1.71s(data=1.6ms QKV=2.10s FFN=3.04s) eta=22:36:06 | 44.5K token/s | 
[epoch_0]_13331  loss=3.401386 |g|=0.402	lr=5.37e-04 | 92.1%@S11  T=1.71s(data=1.7ms QKV=2.10s FFN=3.04s) eta=22:38:28 | 44.7K token/s | 
[epoch_0]_13341  loss=3.467990 |g|=0.383	lr=5.37e-04 | 92.9%@S11  T=1.70s(data=1.7ms QKV=2.10s FFN=3.04s) eta=22:34:25 | 44.9K token/s | 
[epoch_0]_13351  loss=3.391613 |g|=0.395	lr=5.37e-04 | 93.7%@S11  T=1.71s(data=1.5ms QKV=2.10s FFN=3.04s) eta=22:36:45 | 45.0K token/s | 
[epoch_0]_13361  loss=3.345333 |g|=0.397	lr=5.37e-04 | 94.5%@S11  T=1.70s(data=1.8ms QKV=2.10s FFN=3.04s) eta=22:27:03 | 45.2K token/s | 
[epoch_0]_13371  loss=3.403044 |g|=0.425	lr=5.37e-04 | 95.4%@S11  T=1.69s(data=1.8ms QKV=2.10s FFN=3.04s) eta=22:21:58 | 45.3K token/s | 
[epoch_0]_13381  loss=3.417584 |g|=0.407	lr=5.37e-04 | 96.2%@S11  T=1.70s(data=1.6ms QKV=2.10s FFN=3.04s) eta=22:31:22 | 45.5K token/s | 
[epoch_0]_13391  loss=3.461061 |g|=0.409	lr=5.37e-04 | 97.0%@S11  T=1.67s(data=1.8ms QKV=2.10s FFN=3.04s) eta=22:02:36 | 45.7K token/s | 
[Fuyou] head="1" update algorithm=4 t=8.27s
[eval] 
	 Loss@"edu_fineweb1B"=3.445(0.0028) nBranch=1 nToken=6.31M best=3.4481(65) E2T=-0.00257 T=36.7581(0)s x=0
	#3.44536±0.0980 tps=172K(6.30784M) a=[3.25151,3.7183] T=36.7581(sec)
[Section@13400] layer[16-24] tasks=19(nPassBack=0) last_loss=3.44793(0.00674653) N=(772,15680,15120 1768668)
[epoch_0]_13401  loss=3.327767 |g|=0.362	lr=5.37e-04 | 97.8%@S11  T=11.31s(data=1.9ms QKV=2.10s FFN=3.04s) eta=6d 05:42:15 | 43.7K token/s | 
[epoch_0]_13411  loss=3.379387 |g|=0.392	lr=5.37e-04 | 98.6%@S11  T=1.68s(data=1.8ms QKV=2.10s FFN=3.04s) eta=22:09:32 | 44.0K token/s | 
[epoch_0]_13421  loss=3.418229 |g|=0.403	lr=5.36e-04 | 99.5%@S11  T=1.70s(data=1.7ms QKV=2.10s FFN=3.04s) eta=22:28:01 | 44.2K token/s | 
[epoch_0]_13427  loss=3.456318 |g|=0.39	lr=5.36e-04 | 99.9%@S11  T=1.69s(data=1.6ms QKV=2.10s FFN=3.04s) eta=22:17:33 | 44.4K token/s | 
-------- End of shard_11@"./Datasets/edu_fineweb1B/edu_fineweb_train_000465.bin"-------- 
[shard-12]@"./Datasets/edu_fineweb1B/edu_fineweb_train_000466.bin": tokens=100(M) nShardSamples=1220(1171872) 
[epoch_0]_13431  loss=3.487386 |g|=0.383	lr=5.36e-04 | 0.3%@S12  T=1.70s(data=1.4ms QKV=2.10s FFN=3.04s) eta=22:32:40 | 44.6K token/s | 
[epoch_0]_13441  loss=3.490444 |g|=0.409	lr=5.36e-04 | 1.1%@S12  T=1.70s(data=1.6ms QKV=2.10s FFN=3.04s) eta=22:26:36 | 44.8K token/s | 
[epoch_0]_13451  loss=3.436910 |g|=0.387	lr=5.36e-04 | 1.9%@S12  T=1.69s(data=1.2ms QKV=2.10s FFN=3.04s) eta=22:18:00 | 45.0K token/s | 
[epoch_0]_13461  loss=3.447389 |g|=0.404	lr=5.36e-04 | 2.7%@S12  T=1.71s(data=2.7ms QKV=2.10s FFN=3.04s) eta=22:33:05 | 45.1K token/s | 
[epoch_0]_13471  loss=3.501832 |g|=0.428	lr=5.36e-04 | 3.5%@S12  T=1.69s(data=1.4ms QKV=2.10s FFN=3.04s) eta=22:16:23 | 45.3K token/s | 
[epoch_0]_13481  loss=3.506288 |g|=0.431	lr=5.36e-04 | 4.4%@S12  T=1.69s(data=1.5ms QKV=2.10s FFN=3.04s) eta=22:19:55 | 45.5K token/s | 
[epoch_0]_13491  loss=3.513918 |g|=0.395	lr=5.36e-04 | 5.2%@S12  T=1.71s(data=1.2ms QKV=2.10s FFN=3.04s) eta=22:34:51 | 45.6K token/s | 
[Fuyou] head="2" update algorithm=4 t=9.57s
[Section@13500] layer[24-32] tasks=19(nPassBack=0) last_loss=3.48783(-0.0238554) N=(772,15792,15232 1781868)
[epoch_0]_13501  loss=3.476095 |g|=0.362	lr=5.36e-04 | 6.0%@S12  T=4.34s(data=2.2ms QKV=2.10s FFN=3.04s) eta=2d 09:20:04 | 44.3K token/s | 
[epoch_0]_13511  loss=3.496563 |g|=0.419	lr=5.36e-04 | 6.8%@S12  T=1.68s(data=1.7ms QKV=2.10s FFN=3.04s) eta=22:08:07 | 44.5K token/s | 
[epoch_0]_13521  loss=3.461181 |g|=0.418	lr=5.35e-04 | 7.6%@S12  T=1.69s(data=1.5ms QKV=2.10s FFN=3.04s) eta=22:20:54 | 44.7K token/s | 
[epoch_0]_13531  loss=3.425883 |g|=0.446	lr=5.35e-04 | 8.5%@S12  T=1.68s(data=1.3ms QKV=2.10s FFN=3.04s) eta=22:08:34 | 44.9K token/s | 
[epoch_0]_13541  loss=3.502182 |g|=0.396	lr=5.35e-04 | 9.3%@S12  T=1.69s(data=1.3ms QKV=2.10s FFN=3.04s) eta=22:19:03 | 45.1K token/s | 
[epoch_0]_13551  loss=3.458670 |g|=0.379	lr=5.35e-04 | 10.1%@S12  T=1.69s(data=1.4ms QKV=2.10s FFN=3.04s) eta=22:20:24 | 45.2K token/s | 
[epoch_0]_13561  loss=3.440535 |g|=0.433	lr=5.35e-04 | 10.9%@S12  T=1.71s(data=1.4ms QKV=2.10s FFN=3.04s) eta=22:32:06 | 45.4K token/s | 
[epoch_0]_13571  loss=3.455877 |g|=0.402	lr=5.35e-04 | 11.7%@S12  T=1.71s(data=1.6ms QKV=2.10s FFN=3.04s) eta=22:34:17 | 45.5K token/s | 
[epoch_0]_13581  loss=3.430957 |g|=0.421	lr=5.35e-04 | 12.6%@S12  T=1.70s(data=1.6ms QKV=2.10s FFN=3.04s) eta=22:20:46 | 45.6K token/s | 
[epoch_0]_13591  loss=3.424093 |g|=0.415	lr=5.35e-04 | 13.4%@S12  T=1.67s(data=1.5ms QKV=2.10s FFN=3.04s) eta=22:04:15 | 45.8K token/s | 
[Fuyou] head="3" update algorithm=4 t=10.74s
[eval] 
	 Loss@"edu_fineweb1B"=3.432(0.013) nBranch=1 nToken=6.31M best=3.4454(66) E2T=-0.0679 T=36.7502(0)s x=0
	#3.43192±0.0981 tps=172K(6.30784M) a=[3.23436,3.69482] T=36.7502(sec)
[Section@13600] layer[32-40] tasks=19(nPassBack=0) last_loss=3.49983(0.0657215) N=(772,15904,15344 1795068)
[epoch_0]_13601  loss=3.468290 |g|=0.37	lr=5.35e-04 | 14.2%@S12  T=11.41s(data=1.8ms QKV=2.10s FFN=3.04s) eta=6d 06:22:39 | 43.9K token/s | 
[epoch_0]_13611  loss=3.389785 |g|=0.72	lr=5.35e-04 | 15.0%@S12  T=1.69s(data=1.7ms QKV=2.10s FFN=3.04s) eta=22:19:32 | 44.1K token/s | 
[epoch_0]_13621  loss=3.471797 |g|=0.437	lr=5.35e-04 | 15.8%@S12  T=1.72s(data=1.7ms QKV=2.10s FFN=3.04s) eta=22:37:15 | 44.3K token/s | 
[epoch_0]_13631  loss=3.466291 |g|=0.416	lr=5.34e-04 | 16.7%@S12  T=1.71s(data=1.6ms QKV=2.10s FFN=3.04s) eta=22:32:46 | 44.4K token/s | 
[epoch_0]_13641  loss=3.490641 |g|=0.416	lr=5.34e-04 | 17.5%@S12  T=1.69s(data=1.7ms QKV=2.10s FFN=3.04s) eta=22:16:04 | 44.6K token/s | 
[epoch_0]_13651  loss=3.458816 |g|=0.431	lr=5.34e-04 | 18.3%@S12  T=1.71s(data=1.5ms QKV=2.10s FFN=3.04s) eta=22:28:33 | 44.8K token/s | 
[epoch_0]_13661  loss=3.460234 |g|=0.415	lr=5.34e-04 | 19.1%@S12  T=1.72s(data=1.6ms QKV=2.10s FFN=3.04s) eta=22:37:02 | 45.0K token/s | 
[epoch_0]_13671  loss=3.438583 |g|=0.4	lr=5.34e-04 | 19.9%@S12  T=1.72s(data=1.6ms QKV=2.10s FFN=3.04s) eta=22:41:04 | 45.1K token/s | 
[epoch_0]_13681  loss=3.417074 |g|=0.397	lr=5.34e-04 | 20.8%@S12  T=1.71s(data=1.7ms QKV=2.10s FFN=3.04s) eta=22:31:02 | 45.2K token/s | 
[epoch_0]_13691  loss=3.477957 |g|=0.426	lr=5.34e-04 | 21.6%@S12  T=1.70s(data=1.6ms QKV=2.10s FFN=3.04s) eta=22:20:46 | 45.4K token/s | 
[Fuyou] head="4" update algorithm=4 t=9.94s
[Section@13700] layer[40-48] tasks=19(nPassBack=0) last_loss=3.45676(-0.0236681) N=(772,16016,15456 1808268)
[epoch_0]_13701  loss=3.450742 |g|=0.399	lr=5.34e-04 | 22.4%@S12  T=4.36s(data=1.9ms QKV=2.10s FFN=3.04s) eta=2d 09:17:35 | 44.0K token/s | 
[epoch_0]_13711  loss=3.434173 |g|=0.381	lr=5.34e-04 | 23.2%@S12  T=1.67s(data=1.6ms QKV=2.10s FFN=3.04s) eta=21:55:54 | 44.3K token/s | 
[epoch_0]_13721  loss=3.473248 |g|=0.399	lr=5.34e-04 | 24.0%@S12  T=1.70s(data=1.6ms QKV=2.10s FFN=3.04s) eta=22:16:37 | 44.5K token/s | 
[epoch_0]_13731  loss=3.423177 |g|=0.397	lr=5.33e-04 | 24.8%@S12  T=1.71s(data=1.3ms QKV=2.10s FFN=3.04s) eta=22:26:16 | 44.7K token/s | 
[epoch_0]_13741  loss=3.397716 |g|=0.379	lr=5.33e-04 | 25.7%@S12  T=1.69s(data=1.8ms QKV=2.10s FFN=3.04s) eta=22:14:04 | 44.9K token/s | 
[epoch_0]_13751  loss=3.361202 |g|=0.404	lr=5.33e-04 | 26.5%@S12  T=1.68s(data=1.5ms QKV=2.10s FFN=3.04s) eta=22:07:27 | 45.0K token/s | 
[epoch_0]_13761  loss=3.467860 |g|=0.398	lr=5.33e-04 | 27.3%@S12  T=1.70s(data=1.9ms QKV=2.10s FFN=3.04s) eta=22:18:49 | 45.2K token/s | 
[epoch_0]_13771  loss=3.458604 |g|=0.415	lr=5.33e-04 | 28.1%@S12  T=1.70s(data=1.5ms QKV=2.10s FFN=3.04s) eta=22:20:09 | 45.4K token/s | 
[epoch_0]_13781  loss=3.416760 |g|=0.433	lr=5.33e-04 | 28.9%@S12  T=1.72s(data=1.4ms QKV=2.10s FFN=3.04s) eta=22:36:18 | 45.5K token/s | 
[epoch_0]_13791  loss=3.469145 |g|=0.382	lr=5.33e-04 | 29.8%@S12  T=1.70s(data=1.7ms QKV=2.10s FFN=3.04s) eta=22:17:04 | 45.6K token/s | 
[Fuyou] head="5" update algorithm=4 t=11.58s
[eval] 
	 Loss@"edu_fineweb1B"=3.426(0.0061) nBranch=1 nToken=6.31M best=3.4319(67) E2T=-0.053 T=36.7354(0)s x=0
	#3.42583±0.0982 tps=172K(6.30784M) a=[3.22818,3.68693] T=36.7354(sec)
[Section@13800] layer[0-8] tasks=19(nPassBack=0) last_loss=3.47883(-0.0816994) N=(772,16128,15568 1821468)
[epoch_0]_13801  loss=3.395206 |g|=0.371	lr=5.33e-04 | 30.6%@S12  T=11.94s(data=1.5ms QKV=2.10s FFN=3.04s) eta=6d 12:38:30 | 43.7K token/s | 
[epoch_0]_13811  loss=3.475507 |g|=0.392	lr=5.33e-04 | 31.4%@S12  T=1.70s(data=1.6ms QKV=2.10s FFN=3.04s) eta=22:14:11 | 43.9K token/s | 
[epoch_0]_13821  loss=3.432385 |g|=0.403	lr=5.33e-04 | 32.2%@S12  T=1.69s(data=1.8ms QKV=2.10s FFN=3.04s) eta=22:11:40 | 44.1K token/s | 
[epoch_0]_13831  loss=3.364489 |g|=0.388	lr=5.32e-04 | 33.0%@S12  T=1.71s(data=1.7ms QKV=2.10s FFN=3.04s) eta=22:28:13 | 44.3K token/s | 
[epoch_0]_13841  loss=3.427997 |g|=0.391	lr=5.32e-04 | 33.9%@S12  T=1.70s(data=1.6ms QKV=2.10s FFN=3.04s) eta=22:16:31 | 44.5K token/s | 
[epoch_0]_13851  loss=3.429669 |g|=0.4	lr=5.32e-04 | 34.7%@S12  T=1.70s(data=1.6ms QKV=2.10s FFN=3.04s) eta=22:14:21 | 44.7K token/s | 
[epoch_0]_13861  loss=3.446753 |g|=0.412	lr=5.32e-04 | 35.5%@S12  T=1.71s(data=1.5ms QKV=2.10s FFN=3.04s) eta=22:22:20 | 44.9K token/s | 
[epoch_0]_13871  loss=3.445207 |g|=0.389	lr=5.32e-04 | 36.3%@S12  T=1.70s(data=1.6ms QKV=2.10s FFN=3.04s) eta=22:18:19 | 45.0K token/s | 
[epoch_0]_13881  loss=3.418866 |g|=0.38	lr=5.32e-04 | 37.1%@S12  T=1.71s(data=1.6ms QKV=2.10s FFN=3.04s) eta=22:27:42 | 45.2K token/s | 
[epoch_0]_13891  loss=3.392952 |g|=0.384	lr=5.32e-04 | 38.0%@S12  T=1.71s(data=1.5ms QKV=2.10s FFN=3.04s) eta=22:21:03 | 45.3K token/s | 
[Fuyou] head="0" update algorithm=4 t=11.52s
[Section@13900] layer[8-16] tasks=19(nPassBack=0) last_loss=3.52092(-0.124045) N=(772,16240,15680 1834668)
[epoch_0]_13901  loss=3.445980 |g|=0.374	lr=5.32e-04 | 38.8%@S12  T=3.91s(data=1.5ms QKV=2.10s FFN=3.04s) eta=2d 03:11:22 | 44.1K token/s | 
[epoch_0]_13911  loss=3.399378 |g|=0.394	lr=5.32e-04 | 39.6%@S12  T=1.67s(data=1.6ms QKV=2.10s FFN=3.04s) eta=21:54:05 | 44.3K token/s | 
[epoch_0]_13921  loss=3.399267 |g|=0.396	lr=5.32e-04 | 40.4%@S12  T=1.71s(data=1.5ms QKV=2.10s FFN=3.04s) eta=22:25:23 | 44.5K token/s | 
[epoch_0]_13931  loss=3.503985 |g|=0.4	lr=5.31e-04 | 41.2%@S12  T=1.70s(data=1.6ms QKV=2.10s FFN=3.04s) eta=22:11:07 | 44.7K token/s | 
[epoch_0]_13941  loss=3.455300 |g|=0.395	lr=5.31e-04 | 42.1%@S12  T=1.70s(data=1.5ms QKV=2.10s FFN=3.04s) eta=22:10:48 | 44.9K token/s | 
[epoch_0]_13951  loss=3.449124 |g|=0.385	lr=5.31e-04 | 42.9%@S12  T=1.69s(data=1.7ms QKV=2.10s FFN=3.04s) eta=22:07:12 | 45.0K token/s | 
[epoch_0]_13961  loss=3.393831 |g|=0.4	lr=5.31e-04 | 43.7%@S12  T=1.73s(data=1.6ms QKV=2.10s FFN=3.04s) eta=22:38:10 | 45.2K token/s | 
[epoch_0]_13971  loss=3.452346 |g|=0.415	lr=5.31e-04 | 44.5%@S12  T=1.71s(data=1.6ms QKV=2.10s FFN=3.04s) eta=22:18:44 | 45.3K token/s | 
[epoch_0]_13981  loss=3.438084 |g|=0.413	lr=5.31e-04 | 45.3%@S12  T=1.70s(data=1.5ms QKV=2.10s FFN=3.04s) eta=22:11:44 | 45.5K token/s | 
[epoch_0]_13991  loss=3.415612 |g|=0.391	lr=5.31e-04 | 46.1%@S12  T=1.72s(data=1.6ms QKV=2.10s FFN=3.04s) eta=22:25:35 | 45.6K token/s | 
[Fuyou] head="1" update algorithm=4 t=7.53s
[eval] 
	 Loss@"edu_fineweb1B"=3.422(0.0039) nBranch=1 nToken=6.31M best=3.4258(68) E2T=-0.0693 T=36.7644(0)s x=0
	#3.42189±0.0989 tps=172K(6.30784M) a=[3.22086,3.68567] T=36.7644(sec)
[Section@14000] layer[16-24] tasks=19(nPassBack=0) last_loss=3.49116(-0.0432262) N=(772,16352,15792 1847868)
[epoch_0]_14001  loss=3.384535 |g|=0.365	lr=5.31e-04 | 47.0%@S12  T=11.91s(data=1.9ms QKV=2.10s FFN=3.04s) eta=6d 11:39:11 | 43.6K token/s | 
[epoch_0]_14011  loss=3.443206 |g|=0.447	lr=5.31e-04 | 47.8%@S12  T=1.69s(data=1.6ms QKV=2.10s FFN=3.04s) eta=22:06:24 | 43.9K token/s | 
[epoch_0]_14021  loss=3.524040 |g|=0.385	lr=5.31e-04 | 48.6%@S12  T=1.69s(data=1.6ms QKV=2.10s FFN=3.04s) eta=22:05:29 | 44.1K token/s | 
[epoch_0]_14031  loss=3.435750 |g|=0.419	lr=5.31e-04 | 49.4%@S12  T=1.69s(data=1.6ms QKV=2.10s FFN=3.04s) eta=22:07:13 | 44.3K token/s | 
[epoch_0]_14041  loss=3.400980 |g|=0.445	lr=5.30e-04 | 50.2%@S12  T=1.70s(data=1.6ms QKV=2.10s FFN=3.04s) eta=22:11:55 | 44.5K token/s | 
[epoch_0]_14051  loss=3.387229 |g|=0.399	lr=5.30e-04 | 51.1%@S12  T=1.70s(data=1.7ms QKV=2.10s FFN=3.04s) eta=22:08:37 | 44.7K token/s | 
[epoch_0]_14061  loss=3.432301 |g|=0.434	lr=5.30e-04 | 51.9%@S12  T=1.71s(data=1.5ms QKV=2.10s FFN=3.04s) eta=22:16:53 | 44.9K token/s | 
[epoch_0]_14071  loss=3.439020 |g|=0.431	lr=5.30e-04 | 52.7%@S12  T=1.71s(data=1.6ms QKV=2.10s FFN=3.04s) eta=22:21:38 | 45.0K token/s | 
[epoch_0]_14081  loss=3.451681 |g|=0.384	lr=5.30e-04 | 53.5%@S12  T=1.70s(data=1.6ms QKV=2.10s FFN=3.04s) eta=22:08:33 | 45.2K token/s | 
[epoch_0]_14091  loss=3.462910 |g|=0.422	lr=5.30e-04 | 54.3%@S12  T=1.71s(data=1.6ms QKV=2.10s FFN=3.04s) eta=22:14:43 | 45.3K token/s | 
[Fuyou] head="2" update algorithm=4 t=9.22s
[Section@14100] layer[24-32] tasks=19(nPassBack=0) last_loss=3.43773(0.0501041) N=(772,16464,15904 1861068)
[epoch_0]_14101  loss=3.424976 |g|=0.376	lr=5.30e-04 | 55.2%@S12  T=3.55s(data=3.7ms QKV=2.10s FFN=3.04s) eta=1d 22:20:33 | 44.2K token/s | 
[epoch_0]_14111  loss=3.399637 |g|=0.392	lr=5.30e-04 | 56.0%@S12  T=1.71s(data=1.8ms QKV=2.10s FFN=3.04s) eta=22:15:25 | 44.4K token/s | 
[epoch_0]_14121  loss=3.383728 |g|=0.393	lr=5.30e-04 | 56.8%@S12  T=1.71s(data=1.6ms QKV=2.10s FFN=3.04s) eta=22:19:56 | 44.6K token/s | 
[epoch_0]_14131  loss=3.401772 |g|=0.381	lr=5.30e-04 | 57.6%@S12  T=1.70s(data=2.1ms QKV=2.10s FFN=3.04s) eta=22:09:57 | 44.7K token/s | 
[epoch_0]_14141  loss=3.446247 |g|=0.399	lr=5.29e-04 | 58.4%@S12  T=1.67s(data=1.6ms QKV=2.10s FFN=3.04s) eta=21:45:19 | 45.0K token/s | 
[epoch_0]_14151  loss=3.405120 |g|=0.4	lr=5.29e-04 | 59.3%@S12  T=1.70s(data=1.6ms QKV=2.10s FFN=3.04s) eta=22:11:51 | 45.1K token/s | 
[epoch_0]_14161  loss=3.381233 |g|=0.399	lr=5.29e-04 | 60.1%@S12  T=1.71s(data=1.7ms QKV=2.10s FFN=3.04s) eta=22:12:25 | 45.3K token/s | 
[epoch_0]_14171  loss=3.425570 |g|=0.391	lr=5.29e-04 | 60.9%@S12  T=1.70s(data=1.8ms QKV=2.10s FFN=3.04s) eta=22:05:56 | 45.4K token/s | 
[epoch_0]_14181  loss=3.490000 |g|=0.394	lr=5.29e-04 | 61.7%@S12  T=1.71s(data=1.5ms QKV=2.10s FFN=3.04s) eta=22:15:24 | 45.5K token/s | 
[epoch_0]_14191  loss=3.399695 |g|=0.416	lr=5.29e-04 | 62.5%@S12  T=1.72s(data=1.5ms QKV=2.10s FFN=3.04s) eta=22:20:01 | 45.6K token/s | 
[Fuyou] head="3" update algorithm=4 t=11.63s
[eval] 
	 Loss@"edu_fineweb1B"=3.419(0.0027) nBranch=1 nToken=6.31M best=3.4219(69) E2T=0.00442 T=36.7148(0)s x=0
	#3.41914±0.0984 tps=172K(6.30784M) a=[3.21605,3.67747] T=36.7148(sec)
[Section@14200] layer[32-40] tasks=19(nPassBack=0) last_loss=3.41472(0.0851061) N=(772,16576,16016 1874268)
[epoch_0]_14201  loss=3.489510 |g|=0.374	lr=5.29e-04 | 63.3%@S12  T=12.04s(data=1.8ms QKV=2.10s FFN=3.04s) eta=6d 12:38:02 | 43.7K token/s | 
[epoch_0]_14211  loss=3.419838 |g|=0.387	lr=5.29e-04 | 64.2%@S12  T=1.70s(data=1.6ms QKV=2.10s FFN=3.04s) eta=22:06:38 | 43.9K token/s | 
[epoch_0]_14221  loss=3.521099 |g|=0.39	lr=5.29e-04 | 65.0%@S12  T=1.70s(data=1.6ms QKV=2.10s FFN=3.04s) eta=22:03:51 | 44.1K token/s | 
[epoch_0]_14231  loss=3.470090 |g|=0.387	lr=5.29e-04 | 65.8%@S12  T=1.71s(data=1.7ms QKV=2.10s FFN=3.04s) eta=22:14:31 | 44.3K token/s | 
[epoch_0]_14241  loss=3.510376 |g|=0.385	lr=5.28e-04 | 66.6%@S12  T=1.70s(data=2.1ms QKV=2.10s FFN=3.04s) eta=22:04:43 | 44.5K token/s | 
[epoch_0]_14251  loss=3.386559 |g|=0.426	lr=5.28e-04 | 67.4%@S12  T=1.70s(data=1.6ms QKV=2.10s FFN=3.04s) eta=22:03:35 | 44.7K token/s | 
[epoch_0]_14261  loss=3.374840 |g|=0.41	lr=5.28e-04 | 68.3%@S12  T=1.70s(data=1.7ms QKV=2.10s FFN=3.04s) eta=22:04:22 | 44.9K token/s | 
[epoch_0]_14271  loss=3.447824 |g|=0.429	lr=5.28e-04 | 69.1%@S12  T=1.68s(data=1.6ms QKV=2.10s FFN=3.04s) eta=21:51:54 | 45.1K token/s | 
[epoch_0]_14281  loss=3.430451 |g|=0.415	lr=5.28e-04 | 69.9%@S12  T=1.70s(data=1.6ms QKV=2.10s FFN=3.04s) eta=22:04:48 | 45.2K token/s | 
[epoch_0]_14291  loss=3.398436 |g|=0.414	lr=5.28e-04 | 70.7%@S12  T=1.70s(data=1.8ms QKV=2.10s FFN=3.04s) eta=22:06:24 | 45.4K token/s | 
[Fuyou] head="4" update algorithm=4 t=11.72s
[Section@14300] layer[40-48] tasks=19(nPassBack=0) last_loss=3.3859(0.0708551) N=(772,16688,16128 1887468)
[epoch_0]_14301  loss=3.429353 |g|=0.398	lr=5.28e-04 | 71.5%@S12  T=3.82s(data=1.6ms QKV=2.10s FFN=3.03s) eta=2d 01:33:39 | 44.2K token/s | 
[epoch_0]_14311  loss=3.462801 |g|=0.412	lr=5.28e-04 | 72.4%@S12  T=1.70s(data=1.6ms QKV=2.10s FFN=3.04s) eta=22:02:19 | 44.4K token/s | 
[epoch_0]_14321  loss=3.366593 |g|=0.382	lr=5.28e-04 | 73.2%@S12  T=1.70s(data=1.8ms QKV=2.10s FFN=3.04s) eta=22:07:22 | 44.6K token/s | 
[epoch_0]_14331  loss=3.329714 |g|=0.389	lr=5.28e-04 | 74.0%@S12  T=1.72s(data=1.7ms QKV=2.10s FFN=3.04s) eta=22:15:41 | 44.7K token/s | 
[epoch_0]_14341  loss=3.395136 |g|=0.362	lr=5.27e-04 | 74.8%@S12  T=1.72s(data=1.7ms QKV=2.10s FFN=3.04s) eta=22:18:02 | 44.9K token/s | 
[epoch_0]_14351  loss=3.400341 |g|=0.389	lr=5.27e-04 | 75.6%@S12  T=1.70s(data=1.5ms QKV=2.10s FFN=3.04s) eta=22:01:37 | 45.0K token/s | 
[epoch_0]_14361  loss=3.448288 |g|=0.4	lr=5.27e-04 | 76.5%@S12  T=1.72s(data=1.7ms QKV=2.10s FFN=3.04s) eta=22:19:23 | 45.2K token/s | 
[epoch_0]_14371  loss=3.476183 |g|=0.389	lr=5.27e-04 | 77.3%@S12  T=1.70s(data=1.6ms QKV=2.10s FFN=3.04s) eta=22:01:58 | 45.3K token/s | 
[epoch_0]_14381  loss=3.373318 |g|=0.411	lr=5.27e-04 | 78.1%@S12  T=1.70s(data=2.1ms QKV=2.10s FFN=3.04s) eta=22:02:46 | 45.5K token/s | 
[epoch_0]_14391  loss=3.476723 |g|=0.426	lr=5.27e-04 | 78.9%@S12  T=1.71s(data=2.0ms QKV=2.10s FFN=3.04s) eta=22:08:00 | 45.6K token/s | 
[Fuyou] head="5" update algorithm=4 t=11.16s
[eval] 
	 Loss@"edu_fineweb1B"=3.414(0.0056) nBranch=1 nToken=6.31M best=3.4191(70) E2T=-0.0447 T=36.6992(0)s x=0
	#3.41353±0.0977 tps=172K(6.30784M) a=[3.21507,3.67026] T=36.6992(sec)
[Section@14400] layer[0-8] tasks=19(nPassBack=0) last_loss=3.45824(0.0205896) N=(772,16800,16240 1900668)
[epoch_0]_14401  loss=3.352909 |g|=0.372	lr=5.27e-04 | 79.7%@S12  T=12.19s(data=1.8ms QKV=2.10s FFN=3.04s) eta=6d 13:53:53 | 43.6K token/s | 
[epoch_0]_14411  loss=3.359889 |g|=0.389	lr=5.27e-04 | 80.6%@S12  T=1.70s(data=1.7ms QKV=2.10s FFN=3.04s) eta=22:03:56 | 43.9K token/s | 
[epoch_0]_14421  loss=3.448397 |g|=0.429	lr=5.27e-04 | 81.4%@S12  T=1.71s(data=1.8ms QKV=2.10s FFN=3.04s) eta=22:10:58 | 44.1K token/s | 
[epoch_0]_14431  loss=3.406329 |g|=0.395	lr=5.26e-04 | 82.2%@S12  T=1.68s(data=2.2ms QKV=2.10s FFN=3.04s) eta=21:43:31 | 44.3K token/s | 
[epoch_0]_14441  loss=3.477103 |g|=0.418	lr=5.26e-04 | 83.0%@S12  T=1.72s(data=1.6ms QKV=2.10s FFN=3.04s) eta=22:13:51 | 44.5K token/s | 
[epoch_0]_14451  loss=3.419542 |g|=0.401	lr=5.26e-04 | 83.8%@S12  T=1.69s(data=1.9ms QKV=2.10s FFN=3.04s) eta=21:55:33 | 44.7K token/s | 
[epoch_0]_14461  loss=3.414246 |g|=0.427	lr=5.26e-04 | 84.6%@S12  T=1.70s(data=1.6ms QKV=2.10s FFN=3.04s) eta=21:56:39 | 44.8K token/s | 
[epoch_0]_14471  loss=3.442807 |g|=0.398	lr=5.26e-04 | 85.5%@S12  T=1.71s(data=1.6ms QKV=2.10s FFN=3.04s) eta=22:08:52 | 45.0K token/s | 
[epoch_0]_14481  loss=3.432590 |g|=0.378	lr=5.26e-04 | 86.3%@S12  T=1.70s(data=1.7ms QKV=2.10s FFN=3.04s) eta=21:56:11 | 45.2K token/s | 
[epoch_0]_14491  loss=3.297222 |g|=0.407	lr=5.26e-04 | 87.1%@S12  T=1.70s(data=1.7ms QKV=2.10s FFN=3.04s) eta=21:55:45 | 45.3K token/s | 
[Fuyou] head="0" update algorithm=4 t=11.44s
[Section@14500] layer[8-16] tasks=19(nPassBack=0) last_loss=3.45395(0.0669668) N=(772,16912,16352 1913868)
[epoch_0]_14501  loss=3.413143 |g|=0.383	lr=5.26e-04 | 87.9%@S12  T=4.35s(data=1.9ms QKV=2.10s FFN=3.03s) eta=2d 08:12:09 | 44.0K token/s | 
[epoch_0]_14511  loss=3.349205 |g|=0.371	lr=5.26e-04 | 88.7%@S12  T=1.69s(data=1.6ms QKV=2.10s FFN=3.04s) eta=21:53:11 | 44.2K token/s | 
[epoch_0]_14521  loss=3.355150 |g|=0.377	lr=5.26e-04 | 89.6%@S12  T=1.71s(data=1.8ms QKV=2.10s FFN=3.04s) eta=22:07:17 | 44.4K token/s | 
[epoch_0]_14531  loss=3.438374 |g|=0.416	lr=5.25e-04 | 90.4%@S12  T=1.70s(data=1.6ms QKV=2.10s FFN=3.04s) eta=21:55:44 | 44.6K token/s | 
[epoch_0]_14541  loss=3.516734 |g|=0.407	lr=5.25e-04 | 91.2%@S12  T=1.72s(data=1.5ms QKV=2.10s FFN=3.04s) eta=22:15:34 | 44.7K token/s | 
[epoch_0]_14551  loss=3.365925 |g|=0.416	lr=5.25e-04 | 92.0%@S12  T=1.68s(data=2.3ms QKV=2.10s FFN=3.04s) eta=21:39:42 | 44.9K token/s | 
[epoch_0]_14561  loss=3.420938 |g|=0.435	lr=5.25e-04 | 92.8%@S12  T=1.70s(data=1.6ms QKV=2.10s FFN=3.04s) eta=21:58:31 | 45.1K token/s | 
[epoch_0]_14571  loss=3.504003 |g|=0.424	lr=5.25e-04 | 93.7%@S12  T=1.68s(data=1.9ms QKV=2.10s FFN=3.04s) eta=21:37:51 | 45.3K token/s | 
[epoch_0]_14581  loss=3.360915 |g|=0.403	lr=5.25e-04 | 94.5%@S12  T=1.69s(data=1.9ms QKV=2.10s FFN=3.04s) eta=21:50:16 | 45.4K token/s | 
[epoch_0]_14591  loss=3.381802 |g|=0.414	lr=5.25e-04 | 95.3%@S12  T=1.72s(data=1.5ms QKV=2.10s FFN=3.04s) eta=22:10:21 | 45.6K token/s | 
[Fuyou] head="1" update algorithm=4 t=9.00s
[eval] 
	 Loss@"edu_fineweb1B"=3.411(0.0027) nBranch=1 nToken=6.31M best=3.4135(71) E2T=-0.0351 T=36.7308(0)s x=0
	#3.41087±0.0979 tps=172K(6.30784M) a=[3.21388,3.66824] T=36.7308(sec)
[Section@14600] layer[16-24] tasks=19(nPassBack=0) last_loss=3.44594(0.0452173) N=(772,17024,16464 1927068)
[epoch_0]_14601  loss=3.435321 |g|=0.37	lr=5.25e-04 | 96.1%@S12  T=11.99s(data=1.6ms QKV=2.10s FFN=3.03s) eta=6d 10:38:45 | 43.6K token/s | 
[epoch_0]_14611  loss=3.444638 |g|=0.428	lr=5.25e-04 | 96.9%@S12  T=1.69s(data=1.6ms QKV=2.10s FFN=3.04s) eta=21:49:56 | 43.9K token/s | 
[epoch_0]_14621  loss=3.448923 |g|=0.397	lr=5.25e-04 | 97.8%@S12  T=1.71s(data=1.6ms QKV=2.10s FFN=3.04s) eta=22:02:44 | 44.1K token/s | 
[epoch_0]_14631  loss=3.405082 |g|=0.408	lr=5.24e-04 | 98.6%@S12  T=1.70s(data=1.7ms QKV=2.10s FFN=3.04s) eta=21:57:41 | 44.3K token/s | 
[epoch_0]_14641  loss=3.498013 |g|=0.393	lr=5.24e-04 | 99.4%@S12  T=1.71s(data=1.8ms QKV=2.10s FFN=3.04s) eta=22:01:39 | 44.4K token/s | 
[epoch_0]_14648  loss=3.378858 |g|=0.43	lr=5.24e-04 | 100.0%@S12  T=1.71s(data=1.5ms QKV=2.10s FFN=3.04s) eta=21:58:54 | 44.6K token/s | 
-------- End of shard_12@"./Datasets/edu_fineweb1B/edu_fineweb_train_000466.bin"-------- 
[shard-13]@"./Datasets/edu_fineweb1B/edu_fineweb_train_000467.bin": tokens=100(M) nShardSamples=1220(1269528) 
[epoch_0]_14651  loss=3.448992 |g|=0.386	lr=5.24e-04 | 0.2%@S13  T=1.72s(data=1.2ms QKV=2.10s FFN=3.04s) eta=22:08:42 | 44.8K token/s | 
[epoch_0]_14661  loss=3.461353 |g|=0.389	lr=5.24e-04 | 1.0%@S13  T=1.72s(data=1.5ms QKV=2.10s FFN=3.04s) eta=22:08:30 | 44.9K token/s | 
[epoch_0]_14671  loss=3.461195 |g|=0.382	lr=5.24e-04 | 1.9%@S13  T=1.70s(data=1.4ms QKV=2.10s FFN=3.04s) eta=21:53:39 | 45.1K token/s | 
[epoch_0]_14681  loss=3.402808 |g|=0.414	lr=5.24e-04 | 2.7%@S13  T=1.72s(data=1.5ms QKV=2.10s FFN=3.04s) eta=22:08:57 | 45.2K token/s | 
[epoch_0]_14691  loss=3.444303 |g|=0.411	lr=5.24e-04 | 3.5%@S13  T=1.70s(data=1.8ms QKV=2.10s FFN=3.04s) eta=21:53:00 | 45.4K token/s | 
[Fuyou] head="2" update algorithm=4 t=10.68s
[Section@14700] layer[24-32] tasks=19(nPassBack=0) last_loss=3.4494(-0.0116708) N=(772,17136,16576 1940268)
[epoch_0]_14701  loss=3.504861 |g|=0.386	lr=5.24e-04 | 4.3%@S13  T=4.24s(data=1.7ms QKV=2.10s FFN=3.03s) eta=2d 06:33:50 | 44.1K token/s | 
[epoch_0]_14711  loss=3.408082 |g|=0.387	lr=5.24e-04 | 5.1%@S13  T=1.70s(data=1.5ms QKV=2.11s FFN=3.04s) eta=21:52:29 | 44.3K token/s | 
[epoch_0]_14721  loss=3.437186 |g|=0.382	lr=5.24e-04 | 5.9%@S13  T=1.72s(data=1.6ms QKV=2.10s FFN=3.04s) eta=22:06:32 | 44.4K token/s | 
[epoch_0]_14731  loss=3.436419 |g|=0.463	lr=5.23e-04 | 6.8%@S13  T=1.70s(data=1.6ms QKV=2.10s FFN=3.04s) eta=21:50:58 | 44.6K token/s | 
[epoch_0]_14741  loss=3.341862 |g|=0.405	lr=5.23e-04 | 7.6%@S13  T=1.71s(data=1.6ms QKV=2.10s FFN=3.04s) eta=21:56:51 | 44.8K token/s | 
[epoch_0]_14751  loss=3.486117 |g|=0.408	lr=5.23e-04 | 8.4%@S13  T=1.71s(data=1.3ms QKV=2.10s FFN=3.04s) eta=21:55:21 | 45.0K token/s | 
[epoch_0]_14761  loss=3.358220 |g|=0.374	lr=5.23e-04 | 9.2%@S13  T=1.71s(data=1.3ms QKV=2.10s FFN=3.04s) eta=21:55:07 | 45.1K token/s | 
[epoch_0]_14771  loss=3.395969 |g|=0.383	lr=5.23e-04 | 10.0%@S13  T=1.71s(data=1.4ms QKV=2.10s FFN=3.04s) eta=21:59:54 | 45.2K token/s | 
[epoch_0]_14781  loss=3.456341 |g|=0.405	lr=5.23e-04 | 10.9%@S13  T=1.71s(data=1.3ms QKV=2.10s FFN=3.04s) eta=21:56:31 | 45.4K token/s | 
[epoch_0]_14791  loss=3.387377 |g|=0.415	lr=5.23e-04 | 11.7%@S13  T=1.71s(data=1.6ms QKV=2.10s FFN=3.04s) eta=22:00:04 | 45.5K token/s | 
[Fuyou] head="3" update algorithm=4 t=10.98s
[eval] 
	 Loss@"edu_fineweb1B"=3.413(-0.0017) nBranch=1 nToken=6.31M best=3.4109(72) E2T=-0.0326 T=36.716(0)s x=0
	#3.41261±0.0979 tps=172K(6.30784M) a=[3.21092,3.67591] T=36.716(sec)
[Section@14800] layer[32-40] tasks=19(nPassBack=0) last_loss=3.44519(-0.0304725) N=(772,17248,16688 1953468)
[epoch_0]_14801  loss=3.461243 |g|=0.392	lr=5.23e-04 | 12.5%@S13  T=11.62s(data=1.6ms QKV=2.10s FFN=3.04s) eta=6d 05:11:34 | 43.6K token/s | 
[epoch_0]_14811  loss=3.414412 |g|=0.468	lr=5.23e-04 | 13.3%@S13  T=1.72s(data=2.1ms QKV=2.10s FFN=3.04s) eta=22:03:53 | 43.8K token/s | 
[epoch_0]_14821  loss=3.351284 |g|=0.385	lr=5.22e-04 | 14.1%@S13  T=1.70s(data=1.7ms QKV=2.10s FFN=3.04s) eta=21:52:46 | 44.0K token/s | 
[epoch_0]_14831  loss=3.416346 |g|=0.408	lr=5.22e-04 | 15.0%@S13  T=1.72s(data=1.4ms QKV=2.10s FFN=3.04s) eta=22:02:37 | 44.2K token/s | 
[epoch_0]_14841  loss=3.435553 |g|=0.371	lr=5.22e-04 | 15.8%@S13  T=1.67s(data=1.8ms QKV=2.10s FFN=3.04s) eta=21:23:25 | 44.4K token/s | 
[epoch_0]_14851  loss=3.445590 |g|=0.426	lr=5.22e-04 | 16.6%@S13  T=1.70s(data=1.8ms QKV=2.10s FFN=3.04s) eta=21:49:41 | 44.6K token/s | 
[epoch_0]_14861  loss=3.393918 |g|=0.398	lr=5.22e-04 | 17.4%@S13  T=1.68s(data=1.7ms QKV=2.10s FFN=3.04s) eta=21:30:36 | 44.8K token/s | 
[epoch_0]_14871  loss=3.400805 |g|=0.406	lr=5.22e-04 | 18.2%@S13  T=1.72s(data=1.7ms QKV=2.10s FFN=3.04s) eta=22:03:40 | 45.0K token/s | 
[epoch_0]_14881  loss=3.380798 |g|=0.38	lr=5.22e-04 | 19.1%@S13  T=1.72s(data=1.6ms QKV=2.10s FFN=3.04s) eta=22:04:19 | 45.1K token/s | 
[epoch_0]_14891  loss=3.417573 |g|=0.373	lr=5.22e-04 | 19.9%@S13  T=1.70s(data=1.5ms QKV=2.10s FFN=3.04s) eta=21:48:23 | 45.3K token/s | 
[Fuyou] head="4" update algorithm=4 t=11.90s
[Section@14900] layer[40-48] tasks=19(nPassBack=0) last_loss=3.36677(0.0191355) N=(772,17360,16800 1966668)
[epoch_0]_14901  loss=3.421566 |g|=0.362	lr=5.22e-04 | 20.7%@S13  T=4.10s(data=1.9ms QKV=2.10s FFN=3.03s) eta=2d 04:33:02 | 44.0K token/s | 
[epoch_0]_14911  loss=3.471375 |g|=0.396	lr=5.22e-04 | 21.5%@S13  T=1.70s(data=1.8ms QKV=2.10s FFN=3.04s) eta=21:49:53 | 44.2K token/s | 
[epoch_0]_14921  loss=3.409739 |g|=0.383	lr=5.21e-04 | 22.3%@S13  T=1.70s(data=1.7ms QKV=2.10s FFN=3.04s) eta=21:48:39 | 44.4K token/s | 
[epoch_0]_14931  loss=3.444913 |g|=0.395	lr=5.21e-04 | 23.2%@S13  T=1.70s(data=1.8ms QKV=2.10s FFN=3.04s) eta=21:49:44 | 44.6K token/s | 
[epoch_0]_14941  loss=3.415923 |g|=0.421	lr=5.21e-04 | 24.0%@S13  T=1.70s(data=1.5ms QKV=2.10s FFN=3.04s) eta=21:49:20 | 44.7K token/s | 
[epoch_0]_14951  loss=3.494366 |g|=0.418	lr=5.21e-04 | 24.8%@S13  T=1.73s(data=1.4ms QKV=2.10s FFN=3.04s) eta=22:06:58 | 44.9K token/s | 
[epoch_0]_14961  loss=3.315826 |g|=0.375	lr=5.21e-04 | 25.6%@S13  T=1.70s(data=1.7ms QKV=2.10s FFN=3.04s) eta=21:46:00 | 45.0K token/s | 
[epoch_0]_14971  loss=3.473161 |g|=0.394	lr=5.21e-04 | 26.4%@S13  T=1.66s(data=1.6ms QKV=2.10s FFN=3.04s) eta=21:17:27 | 45.3K token/s | 
[epoch_0]_14981  loss=3.384214 |g|=0.408	lr=5.21e-04 | 27.2%@S13  T=1.71s(data=1.4ms QKV=2.10s FFN=3.04s) eta=21:51:59 | 45.4K token/s | 
[epoch_0]_14991  loss=3.401952 |g|=0.398	lr=5.21e-04 | 28.1%@S13  T=1.70s(data=1.8ms QKV=2.10s FFN=3.04s) eta=21:41:27 | 45.5K token/s | 
[Fuyou] head="5" update algorithm=4 t=11.25s
[eval] 
	 Loss@"edu_fineweb1B"=3.412(0.0011) nBranch=1 nToken=6.31M best=3.4109(72) E2T=-0.0193 T=36.7275(0)s x=0
	#3.41151±0.0983 tps=172K(6.30784M) a=[3.21198,3.6801] T=36.7275(sec)
[Section@15000] layer[0-8] tasks=19(nPassBack=0) last_loss=3.43076(0.0274758) N=(772,17472,16912 1979868)
[epoch_0]_15001  loss=3.396873 |g|=0.415	lr=5.21e-04 | 28.9%@S13  T=12.29s(data=1.6ms QKV=2.10s FFN=3.04s) eta=6d 13:07:07 | 43.6K token/s | 
[epoch_0]_15011  loss=3.388792 |g|=0.401	lr=5.20e-04 | 29.7%@S13  T=1.71s(data=1.6ms QKV=2.10s FFN=3.04s) eta=21:48:28 | 43.8K token/s | 
[epoch_0]_15021  loss=3.378711 |g|=0.367	lr=5.20e-04 | 30.5%@S13  T=1.71s(data=1.5ms QKV=2.10s FFN=3.04s) eta=21:49:36 | 44.0K token/s | 
[epoch_0]_15031  loss=3.377969 |g|=0.388	lr=5.20e-04 | 31.3%@S13  T=1.70s(data=1.7ms QKV=2.10s FFN=3.04s) eta=21:43:47 | 44.2K token/s | 
[epoch_0]_15041  loss=3.393043 |g|=0.391	lr=5.20e-04 | 32.2%@S13  T=1.70s(data=1.8ms QKV=2.10s FFN=3.04s) eta=21:42:24 | 44.4K token/s | 
[epoch_0]_15051  loss=3.338488 |g|=0.376	lr=5.20e-04 | 33.0%@S13  T=1.70s(data=1.8ms QKV=2.10s FFN=3.04s) eta=21:41:31 | 44.6K token/s | 
[epoch_0]_15061  loss=3.447483 |g|=0.401	lr=5.20e-04 | 33.8%@S13  T=1.71s(data=1.5ms QKV=2.10s FFN=3.04s) eta=21:47:44 | 44.8K token/s | 
[epoch_0]_15071  loss=3.449004 |g|=0.412	lr=5.20e-04 | 34.6%@S13  T=1.71s(data=1.6ms QKV=2.10s FFN=3.04s) eta=21:48:45 | 44.9K token/s | 
[epoch_0]_15081  loss=3.357438 |g|=0.424	lr=5.20e-04 | 35.4%@S13  T=1.70s(data=1.6ms QKV=2.10s FFN=3.04s) eta=21:44:59 | 45.1K token/s | 
[epoch_0]_15091  loss=3.455942 |g|=0.432	lr=5.20e-04 | 36.3%@S13  T=1.72s(data=1.6ms QKV=2.10s FFN=3.04s) eta=21:56:06 | 45.2K token/s | 
[Fuyou] head="0" update algorithm=4 t=11.15s
[Section@15100] layer[8-16] tasks=19(nPassBack=0) last_loss=3.4939(-0.0399473) N=(772,17584,17024 1993068)
[epoch_0]_15101  loss=3.344763 |g|=0.359	lr=5.20e-04 | 37.1%@S13  T=4.06s(data=1.8ms QKV=2.10s FFN=3.03s) eta=2d 03:47:21 | 44.0K token/s | 
[epoch_0]_15111  loss=3.367764 |g|=0.371	lr=5.19e-04 | 37.9%@S13  T=1.69s(data=1.6ms QKV=2.10s FFN=3.04s) eta=21:37:00 | 44.2K token/s | 
[epoch_0]_15121  loss=3.394353 |g|=0.364	lr=5.19e-04 | 38.7%@S13  T=1.70s(data=1.7ms QKV=2.10s FFN=3.04s) eta=21:42:21 | 44.4K token/s | 
[epoch_0]_15131  loss=3.391770 |g|=0.404	lr=5.19e-04 | 39.5%@S13  T=1.71s(data=1.5ms QKV=2.10s FFN=3.04s) eta=21:45:04 | 44.6K token/s | 
[epoch_0]_15141  loss=3.404438 |g|=0.39	lr=5.19e-04 | 40.4%@S13  T=1.70s(data=1.7ms QKV=2.10s FFN=3.04s) eta=21:36:33 | 44.8K token/s | 
[epoch_0]_15151  loss=3.415531 |g|=0.417	lr=5.19e-04 | 41.2%@S13  T=1.72s(data=1.5ms QKV=2.10s FFN=3.04s) eta=21:53:07 | 44.9K token/s | 
[epoch_0]_15161  loss=3.530836 |g|=0.421	lr=5.19e-04 | 42.0%@S13  T=1.67s(data=1.4ms QKV=2.10s FFN=3.04s) eta=21:19:56 | 45.1K token/s | 
[epoch_0]_15171  loss=3.365639 |g|=0.373	lr=5.19e-04 | 42.8%@S13  T=1.70s(data=1.5ms QKV=2.10s FFN=3.04s) eta=21:39:14 | 45.3K token/s | 
[epoch_0]_15181  loss=3.388302 |g|=0.422	lr=5.19e-04 | 43.6%@S13  T=1.72s(data=1.5ms QKV=2.10s FFN=3.04s) eta=21:57:49 | 45.4K token/s | 
[epoch_0]_15191  loss=3.433701 |g|=0.43	lr=5.19e-04 | 44.5%@S13  T=1.69s(data=1.5ms QKV=2.10s FFN=3.04s) eta=21:30:52 | 45.5K token/s | 
[Fuyou] head="1" update algorithm=4 t=7.63s
[eval] 
	 Loss@"edu_fineweb1B"=3.410(0.0014) nBranch=1 nToken=6.31M best=3.4115(74) E2T=-0.0458 T=36.7289(0)s x=0
	#3.41015±0.0969 tps=172K(6.30784M) a=[3.21373,3.66756] T=36.7289(sec)
[Section@15200] layer[16-24] tasks=19(nPassBack=0) last_loss=3.45594(-0.00999808) N=(772,17696,17136 2006268)
[epoch_0]_15201  loss=3.448048 |g|=0.43	lr=5.18e-04 | 45.3%@S13  T=12.02s(data=3.0ms QKV=2.10s FFN=3.04s) eta=6d 09:03:55 | 43.6K token/s | 
[epoch_0]_15211  loss=3.414498 |g|=0.396	lr=5.18e-04 | 46.1%@S13  T=1.70s(data=1.6ms QKV=2.10s FFN=3.04s) eta=21:39:40 | 43.8K token/s | 
[epoch_0]_15221  loss=3.400282 |g|=0.387	lr=5.18e-04 | 46.9%@S13  T=1.71s(data=1.6ms QKV=2.10s FFN=3.04s) eta=21:46:38 | 44.0K token/s | 
[epoch_0]_15231  loss=3.358407 |g|=0.391	lr=5.18e-04 | 47.7%@S13  T=1.72s(data=1.6ms QKV=2.10s FFN=3.04s) eta=21:52:13 | 44.2K token/s | 
[epoch_0]_15241  loss=3.377912 |g|=0.382	lr=5.18e-04 | 48.5%@S13  T=1.71s(data=1.6ms QKV=2.10s FFN=3.04s) eta=21:45:25 | 44.4K token/s | 
[epoch_0]_15251  loss=3.467748 |g|=0.425	lr=5.18e-04 | 49.4%@S13  T=1.71s(data=1.6ms QKV=2.10s FFN=3.04s) eta=21:44:06 | 44.6K token/s | 
[epoch_0]_15261  loss=3.436723 |g|=0.372	lr=5.18e-04 | 50.2%@S13  T=1.72s(data=1.5ms QKV=2.10s FFN=3.04s) eta=21:53:21 | 44.7K token/s | 
[epoch_0]_15271  loss=3.393826 |g|=0.384	lr=5.18e-04 | 51.0%@S13  T=1.68s(data=1.5ms QKV=2.10s FFN=3.04s) eta=21:24:32 | 44.9K token/s | 
[epoch_0]_15281  loss=3.376707 |g|=0.378	lr=5.18e-04 | 51.8%@S13  T=1.68s(data=1.5ms QKV=2.10s FFN=3.04s) eta=21:22:44 | 45.1K token/s | 
[epoch_0]_15291  loss=3.398355 |g|=0.409	lr=5.18e-04 | 52.6%@S13  T=1.72s(data=1.5ms QKV=2.10s FFN=3.04s) eta=21:49:24 | 45.2K token/s | 
[Fuyou] head="2" update algorithm=4 t=8.89s
[Section@15300] layer[24-32] tasks=19(nPassBack=0) last_loss=3.45208(-0.00267696) N=(772,17808,17248 2019468)
[epoch_0]_15301  loss=3.430145 |g|=0.393	lr=5.17e-04 | 53.5%@S13  T=3.61s(data=1.5ms QKV=2.10s FFN=3.04s) eta=1d 21:50:20 | 44.1K token/s | 
[epoch_0]_15311  loss=3.365641 |g|=0.399	lr=5.17e-04 | 54.3%@S13  T=1.68s(data=1.5ms QKV=2.10s FFN=3.04s) eta=21:20:00 | 44.3K token/s | 
[epoch_0]_15321  loss=3.362204 |g|=0.367	lr=5.17e-04 | 55.1%@S13  T=1.71s(data=1.8ms QKV=2.10s FFN=3.04s) eta=21:46:14 | 44.5K token/s | 
[epoch_0]_15331  loss=3.407482 |g|=0.413	lr=5.17e-04 | 55.9%@S13  T=1.77s(data=2.0ms QKV=2.10s FFN=3.04s) eta=22:26:13 | 44.6K token/s | 
[epoch_0]_15341  loss=3.413790 |g|=0.408	lr=5.17e-04 | 56.7%@S13  T=1.70s(data=1.7ms QKV=2.10s FFN=3.04s) eta=21:35:43 | 44.8K token/s | 
[epoch_0]_15351  loss=3.384084 |g|=0.382	lr=5.17e-04 | 57.6%@S13  T=1.71s(data=1.6ms QKV=2.10s FFN=3.04s) eta=21:39:38 | 44.9K token/s | 
[epoch_0]_15361  loss=3.460658 |g|=0.397	lr=5.17e-04 | 58.4%@S13  T=1.71s(data=1.5ms QKV=2.10s FFN=3.04s) eta=21:40:26 | 45.1K token/s | 
[epoch_0]_15371  loss=3.383083 |g|=0.395	lr=5.17e-04 | 59.2%@S13  T=1.71s(data=1.7ms QKV=2.10s FFN=3.04s) eta=21:42:20 | 45.2K token/s | 
[epoch_0]_15381  loss=3.303839 |g|=0.397	lr=5.17e-04 | 60.0%@S13  T=1.72s(data=1.5ms QKV=2.10s FFN=3.04s) eta=21:50:44 | 45.3K token/s | 
[epoch_0]_15391  loss=3.449760 |g|=0.384	lr=5.16e-04 | 60.8%@S13  T=1.71s(data=1.6ms QKV=2.10s FFN=3.04s) eta=21:44:31 | 45.5K token/s | 
[Fuyou] head="3" update algorithm=4 t=10.06s
[eval] 
	 Loss@"edu_fineweb1B"=3.409(0.00092) nBranch=1 nToken=6.31M best=3.4102(75) E2T=0.0167 T=36.7268(0)s x=0
	#3.40923±0.0987 tps=172K(6.30784M) a=[3.21411,3.67466] T=36.7268(sec)
[Section@15400] layer[32-40] tasks=19(nPassBack=0) last_loss=3.39258(0.0526125) N=(772,17920,17360 2032668)
[epoch_0]_15401  loss=3.408578 |g|=0.382	lr=5.16e-04 | 61.7%@S13  T=12.06s(data=1.9ms QKV=2.10s FFN=3.04s) eta=6d 08:55:47 | 43.5K token/s | 
[epoch_0]_15411  loss=3.448514 |g|=0.419	lr=5.16e-04 | 62.5%@S13  T=1.71s(data=1.6ms QKV=2.10s FFN=3.04s) eta=21:41:52 | 43.8K token/s | 
[epoch_0]_15421  loss=3.440978 |g|=0.423	lr=5.16e-04 | 63.3%@S13  T=1.71s(data=1.5ms QKV=2.10s FFN=3.04s) eta=21:41:23 | 44.0K token/s | 
[epoch_0]_15431  loss=3.394284 |g|=0.383	lr=5.16e-04 | 64.1%@S13  T=1.72s(data=1.7ms QKV=2.10s FFN=3.04s) eta=21:47:30 | 44.1K token/s | 
[epoch_0]_15441  loss=3.362473 |g|=0.401	lr=5.16e-04 | 64.9%@S13  T=1.71s(data=1.7ms QKV=2.10s FFN=3.04s) eta=21:37:45 | 44.3K token/s | 
[epoch_0]_15451  loss=3.368358 |g|=0.402	lr=5.16e-04 | 65.8%@S13  T=1.71s(data=1.7ms QKV=2.10s FFN=3.04s) eta=21:40:32 | 44.5K token/s | 
[epoch_0]_15461  loss=3.419741 |g|=0.399	lr=5.16e-04 | 66.6%@S13  T=1.69s(data=1.5ms QKV=2.10s FFN=3.04s) eta=21:25:20 | 44.7K token/s | 
[epoch_0]_15471  loss=3.356371 |g|=0.388	lr=5.16e-04 | 67.4%@S13  T=1.72s(data=1.5ms QKV=2.10s FFN=3.04s) eta=21:46:44 | 44.8K token/s | 
[epoch_0]_15481  loss=3.447436 |g|=0.393	lr=5.15e-04 | 68.2%@S13  T=1.70s(data=1.5ms QKV=2.10s FFN=3.04s) eta=21:31:07 | 45.0K token/s | 
[epoch_0]_15491  loss=3.462811 |g|=0.419	lr=5.15e-04 | 69.0%@S13  T=1.70s(data=1.7ms QKV=2.10s FFN=3.04s) eta=21:29:24 | 45.2K token/s | 
[Fuyou] head="4" update algorithm=4 t=10.38s
[Section@15500] layer[40-48] tasks=19(nPassBack=0) last_loss=3.37174(-0.0049758) N=(772,18032,17472 2045868)
[epoch_0]_15501  loss=3.431782 |g|=0.348	lr=5.15e-04 | 69.8%@S13  T=3.66s(data=1.9ms QKV=2.10s FFN=3.03s) eta=1d 22:20:40 | 44.0K token/s | 
[epoch_0]_15511  loss=3.360245 |g|=0.402	lr=5.15e-04 | 70.7%@S13  T=1.70s(data=1.6ms QKV=2.10s FFN=3.04s) eta=21:29:46 | 44.2K token/s | 
[epoch_0]_15521  loss=3.411101 |g|=0.408	lr=5.15e-04 | 71.5%@S13  T=1.71s(data=1.6ms QKV=2.10s FFN=3.04s) eta=21:36:51 | 44.4K token/s | 
[epoch_0]_15531  loss=3.403490 |g|=0.366	lr=5.15e-04 | 72.3%@S13  T=1.71s(data=1.7ms QKV=2.10s FFN=3.04s) eta=21:35:20 | 44.6K token/s | 
[epoch_0]_15541  loss=3.362935 |g|=0.39	lr=5.15e-04 | 73.1%@S13  T=1.68s(data=1.7ms QKV=2.10s FFN=3.04s) eta=21:10:47 | 44.8K token/s | 
[epoch_0]_15551  loss=3.335229 |g|=0.383	lr=5.15e-04 | 73.9%@S13  T=1.70s(data=1.7ms QKV=2.10s FFN=3.04s) eta=21:28:47 | 45.0K token/s | 
[epoch_0]_15561  loss=3.351796 |g|=0.414	lr=5.15e-04 | 74.8%@S13  T=1.70s(data=1.7ms QKV=2.10s FFN=3.04s) eta=21:27:11 | 45.1K token/s | 
[epoch_0]_15571  loss=3.356633 |g|=0.407	lr=5.15e-04 | 75.6%@S13  T=1.68s(data=1.7ms QKV=2.10s FFN=3.04s) eta=21:11:33 | 45.3K token/s | 
[epoch_0]_15581  loss=3.390544 |g|=0.371	lr=5.14e-04 | 76.4%@S13  T=1.67s(data=1.6ms QKV=2.10s FFN=3.04s) eta=21:08:18 | 45.5K token/s | 
[epoch_0]_15591  loss=3.413927 |g|=0.437	lr=5.14e-04 | 77.2%@S13  T=1.67s(data=1.7ms QKV=2.10s FFN=3.04s) eta=21:08:13 | 45.7K token/s | 
[Fuyou] head="5" update algorithm=4 t=8.73s
[eval] 
	 Loss@"edu_fineweb1B"=3.407(0.0027) nBranch=1 nToken=6.31M best=3.4092(76) E2T=0.0126 T=36.7376(0)s x=0
	#3.40651±0.0983 tps=172K(6.30784M) a=[3.21027,3.6765] T=36.7376(sec)
[Section@15600] layer[0-8] tasks=19(nPassBack=0) last_loss=3.39392(0.0368462) N=(772,18144,17584 2059068)
[epoch_0]_15601  loss=3.387883 |g|=0.372	lr=5.14e-04 | 78.0%@S13  T=12.05s(data=1.8ms QKV=2.10s FFN=3.04s) eta=6d 08:02:33 | 43.7K token/s | 
[epoch_0]_15611  loss=3.391403 |g|=0.405	lr=5.14e-04 | 78.9%@S13  T=1.70s(data=1.7ms QKV=2.10s FFN=3.04s) eta=21:29:59 | 44.0K token/s | 
[epoch_0]_15621  loss=3.287288 |g|=0.414	lr=5.14e-04 | 79.7%@S13  T=1.73s(data=1.7ms QKV=2.10s FFN=3.04s) eta=21:50:42 | 44.1K token/s | 
[epoch_0]_15631  loss=3.355818 |g|=0.409	lr=5.14e-04 | 80.5%@S13  T=1.70s(data=1.7ms QKV=2.10s FFN=3.04s) eta=21:25:39 | 44.3K token/s | 
[epoch_0]_15641  loss=3.423066 |g|=0.412	lr=5.14e-04 | 81.3%@S13  T=1.71s(data=1.6ms QKV=2.10s FFN=3.04s) eta=21:36:27 | 44.5K token/s | 
[epoch_0]_15651  loss=3.335504 |g|=0.395	lr=5.14e-04 | 82.1%@S13  T=1.71s(data=1.6ms QKV=2.10s FFN=3.04s) eta=21:32:49 | 44.7K token/s | 
[epoch_0]_15661  loss=3.403152 |g|=0.418	lr=5.14e-04 | 83.0%@S13  T=1.72s(data=1.6ms QKV=2.10s FFN=3.04s) eta=21:37:37 | 44.8K token/s | 
[epoch_0]_15671  loss=3.355241 |g|=0.407	lr=5.13e-04 | 83.8%@S13  T=1.70s(data=1.6ms QKV=2.10s FFN=3.04s) eta=21:23:57 | 45.0K token/s | 
[epoch_0]_15681  loss=3.331201 |g|=0.373	lr=5.13e-04 | 84.6%@S13  T=1.72s(data=1.9ms QKV=2.10s FFN=3.04s) eta=21:40:37 | 45.1K token/s | 
[epoch_0]_15691  loss=3.345280 |g|=0.372	lr=5.13e-04 | 85.4%@S13  T=1.72s(data=1.5ms QKV=2.10s FFN=3.04s) eta=21:38:35 | 45.3K token/s | 
[Fuyou] head="0" update algorithm=4 t=11.10s
[Section@15700] layer[8-16] tasks=19(nPassBack=0) last_loss=3.30999(0.18391) N=(772,18256,17696 2072268)
[epoch_0]_15701  loss=3.370446 |g|=0.363	lr=5.13e-04 | 86.2%@S13  T=4.09s(data=1.8ms QKV=2.10s FFN=3.03s) eta=2d 03:30:23 | 44.0K token/s | 
[epoch_0]_15711  loss=3.372308 |g|=0.373	lr=5.13e-04 | 87.0%@S13  T=1.70s(data=1.6ms QKV=2.10s FFN=3.04s) eta=21:21:59 | 44.2K token/s | 
[epoch_0]_15721  loss=3.377776 |g|=0.37	lr=5.13e-04 | 87.9%@S13  T=1.68s(data=1.6ms QKV=2.10s FFN=3.04s) eta=21:05:11 | 44.4K token/s | 
[epoch_0]_15731  loss=3.409124 |g|=0.4	lr=5.13e-04 | 88.7%@S13  T=1.69s(data=1.7ms QKV=2.10s FFN=3.04s) eta=21:19:41 | 44.6K token/s | 
[epoch_0]_15741  loss=3.346864 |g|=0.376	lr=5.13e-04 | 89.5%@S13  T=1.71s(data=1.7ms QKV=2.10s FFN=3.04s) eta=21:29:22 | 44.8K token/s | 
[epoch_0]_15751  loss=3.385722 |g|=0.379	lr=5.13e-04 | 90.3%@S13  T=1.71s(data=1.6ms QKV=2.10s FFN=3.04s) eta=21:28:05 | 45.0K token/s | 
[epoch_0]_15761  loss=3.356663 |g|=0.384	lr=5.12e-04 | 91.1%@S13  T=1.70s(data=1.8ms QKV=2.10s FFN=3.04s) eta=21:20:14 | 45.1K token/s | 
[epoch_0]_15771  loss=3.296666 |g|=0.407	lr=5.12e-04 | 92.0%@S13  T=1.71s(data=1.7ms QKV=2.10s FFN=3.04s) eta=21:33:16 | 45.3K token/s | 
[epoch_0]_15781  loss=3.411097 |g|=0.391	lr=5.12e-04 | 92.8%@S13  T=1.73s(data=1.6ms QKV=2.11s FFN=3.04s) eta=21:45:19 | 45.4K token/s | 
[epoch_0]_15791  loss=3.407269 |g|=0.357	lr=5.12e-04 | 93.6%@S13  T=1.71s(data=1.5ms QKV=2.10s FFN=3.04s) eta=21:28:22 | 45.5K token/s | 
[Fuyou] head="1" update algorithm=4 t=8.34s
[eval] 
	 Loss@"edu_fineweb1B"=3.405(0.0017) nBranch=1 nToken=6.31M best=3.4065(77) E2T=-0.0201 T=36.747(0)s x=0
	#3.40481±0.0983 tps=172K(6.30784M) a=[3.2093,3.67253] T=36.747(sec)
[Section@15800] layer[16-24] tasks=19(nPassBack=0) last_loss=3.42487(0.0310707) N=(772,18368,17808 2085468)
[epoch_0]_15801  loss=3.388885 |g|=0.362	lr=5.12e-04 | 94.4%@S13  T=11.93s(data=1.6ms QKV=2.10s FFN=3.04s) eta=6d 05:50:46 | 43.6K token/s | 
[epoch_0]_15811  loss=3.358209 |g|=0.383	lr=5.12e-04 | 95.2%@S13  T=1.72s(data=1.9ms QKV=2.10s FFN=3.04s) eta=21:34:27 | 43.8K token/s | 
[epoch_0]_15821  loss=3.420342 |g|=0.397	lr=5.12e-04 | 96.1%@S13  T=1.68s(data=1.7ms QKV=2.10s FFN=3.04s) eta=21:05:11 | 44.0K token/s | 
[epoch_0]_15831  loss=3.364628 |g|=0.417	lr=5.12e-04 | 96.9%@S13  T=1.71s(data=2.1ms QKV=2.10s FFN=3.04s) eta=21:30:16 | 44.2K token/s | 
[epoch_0]_15841  loss=3.361062 |g|=0.362	lr=5.12e-04 | 97.7%@S13  T=1.72s(data=1.6ms QKV=2.10s FFN=3.04s) eta=21:38:09 | 44.4K token/s | 
[epoch_0]_15851  loss=3.375598 |g|=0.394	lr=5.11e-04 | 98.5%@S13  T=1.72s(data=1.6ms QKV=2.10s FFN=3.04s) eta=21:32:14 | 44.5K token/s | 
[epoch_0]_15861  loss=3.355266 |g|=0.376	lr=5.11e-04 | 99.3%@S13  T=1.68s(data=3.3ms QKV=2.11s FFN=3.04s) eta=21:08:23 | 44.7K token/s | 
[epoch_0]_15869  loss=3.381729 |g|=0.382	lr=5.11e-04 | 100.0%@S13  T=1.72s(data=1.6ms QKV=2.10s FFN=3.04s) eta=21:33:05 | 44.9K token/s | 
-------- End of shard_13@"./Datasets/edu_fineweb1B/edu_fineweb_train_000467.bin"-------- 
[shard-14]@"./Datasets/edu_fineweb1B/edu_fineweb_train_000468.bin": tokens=100(M) nShardSamples=1220(1367184) 
[epoch_0]_15871  loss=3.417808 |g|=0.385	lr=5.11e-04 | 0.2%@S14  T=1.90s(data=1.4ms QKV=2.10s FFN=3.04s) eta=23:52:19 | 44.8K token/s | 
[epoch_0]_15881  loss=3.406068 |g|=0.393	lr=5.11e-04 | 1.0%@S14  T=1.73s(data=2.0ms QKV=2.10s FFN=3.04s) eta=21:42:42 | 44.9K token/s | 
[epoch_0]_15891  loss=3.486176 |g|=0.368	lr=5.11e-04 | 1.8%@S14  T=1.71s(data=1.2ms QKV=2.11s FFN=3.04s) eta=21:25:17 | 45.1K token/s | 
[Fuyou] head="2" update algorithm=4 t=10.89s
[Section@15900] layer[24-32] tasks=19(nPassBack=0) last_loss=3.48337(-0.0312881) N=(772,18480,17920 2098668)
[epoch_0]_15901  loss=3.456442 |g|=0.388	lr=5.11e-04 | 2.6%@S14  T=4.26s(data=1.2ms QKV=2.10s FFN=3.03s) eta=2d 05:22:25 | 43.8K token/s | 
[epoch_0]_15911  loss=3.471433 |g|=0.404	lr=5.11e-04 | 3.4%@S14  T=1.69s(data=1.4ms QKV=2.10s FFN=3.04s) eta=21:13:32 | 44.0K token/s | 
[epoch_0]_15921  loss=3.377401 |g|=0.396	lr=5.11e-04 | 4.3%@S14  T=1.67s(data=1.5ms QKV=2.10s FFN=3.04s) eta=20:55:12 | 44.3K token/s | 
[epoch_0]_15931  loss=3.355016 |g|=0.382	lr=5.11e-04 | 5.1%@S14  T=1.70s(data=1.7ms QKV=2.10s FFN=3.04s) eta=21:21:32 | 44.5K token/s | 
[epoch_0]_15941  loss=3.435743 |g|=0.389	lr=5.10e-04 | 5.9%@S14  T=1.70s(data=1.7ms QKV=2.10s FFN=3.04s) eta=21:20:05 | 44.6K token/s | 
[epoch_0]_15951  loss=3.399644 |g|=0.388	lr=5.10e-04 | 6.7%@S14  T=1.68s(data=1.7ms QKV=2.10s FFN=3.04s) eta=21:04:58 | 44.8K token/s | 
[epoch_0]_15961  loss=3.340110 |g|=0.382	lr=5.10e-04 | 7.5%@S14  T=1.67s(data=1.6ms QKV=2.10s FFN=3.04s) eta=20:53:06 | 45.1K token/s | 
[epoch_0]_15971  loss=3.437737 |g|=0.415	lr=5.10e-04 | 8.3%@S14  T=1.71s(data=1.3ms QKV=2.10s FFN=3.04s) eta=21:23:59 | 45.2K token/s | 
[epoch_0]_15981  loss=3.355302 |g|=0.389	lr=5.10e-04 | 9.2%@S14  T=1.71s(data=1.4ms QKV=2.11s FFN=3.04s) eta=21:22:39 | 45.3K token/s | 
[epoch_0]_15991  loss=3.362177 |g|=0.387	lr=5.10e-04 | 10.0%@S14  T=1.70s(data=1.7ms QKV=2.11s FFN=3.04s) eta=21:13:49 | 45.5K token/s | 
[Fuyou] head="3" update algorithm=4 t=11.27s
[eval] 
	 Loss@"edu_fineweb1B"=3.398(0.0064) nBranch=1 nToken=6.31M best=3.4048(78) E2T=0.0585 T=36.746(0)s x=0
	#3.39845±0.0976 tps=172K(6.30784M) a=[3.20484,3.66417] T=36.746(sec)
[Section@16000] layer[32-40] tasks=19(nPassBack=0) last_loss=3.33999(0.0525897) N=(772,18592,18032 2111868)
[epoch_0]_16001  loss=3.456322 |g|=0.405	lr=5.10e-04 | 10.8%@S14  T=11.83s(data=2.2ms QKV=2.10s FFN=3.03s) eta=6d 04:01:32 | 43.6K token/s | 
[epoch_0]_16011  loss=3.388239 |g|=0.399	lr=5.10e-04 | 11.6%@S14  T=1.72s(data=2.1ms QKV=2.10s FFN=3.04s) eta=21:31:30 | 43.8K token/s | 
[epoch_0]_16021  loss=3.384240 |g|=0.382	lr=5.10e-04 | 12.4%@S14  T=1.68s(data=1.8ms QKV=2.10s FFN=3.04s) eta=20:58:16 | 44.0K token/s | 
[epoch_0]_16031  loss=3.371682 |g|=0.421	lr=5.09e-04 | 13.3%@S14  T=1.69s(data=2.0ms QKV=2.11s FFN=3.04s) eta=21:07:53 | 44.2K token/s | 
[epoch_0]_16041  loss=3.421912 |g|=0.391	lr=5.09e-04 | 14.1%@S14  T=1.68s(data=1.8ms QKV=2.11s FFN=3.04s) eta=20:57:09 | 44.5K token/s | 
[epoch_0]_16051  loss=3.374154 |g|=0.427	lr=5.09e-04 | 14.9%@S14  T=1.72s(data=1.4ms QKV=2.10s FFN=3.04s) eta=21:26:15 | 44.6K token/s | 
[epoch_0]_16061  loss=3.402079 |g|=0.386	lr=5.09e-04 | 15.7%@S14  T=1.74s(data=1.6ms QKV=2.10s FFN=3.04s) eta=21:44:58 | 44.8K token/s | 
[epoch_0]_16071  loss=3.462903 |g|=0.391	lr=5.09e-04 | 16.5%@S14  T=1.74s(data=1.6ms QKV=2.10s FFN=3.04s) eta=21:46:09 | 44.9K token/s | 
[epoch_0]_16081  loss=3.339397 |g|=0.363	lr=5.09e-04 | 17.4%@S14  T=1.69s(data=1.9ms QKV=2.10s FFN=3.04s) eta=21:02:42 | 45.1K token/s | 
[epoch_0]_16091  loss=3.411725 |g|=0.421	lr=5.09e-04 | 18.2%@S14  T=1.81s(data=1.7ms QKV=2.10s FFN=3.04s) eta=22:33:26 | 45.1K token/s | 
[Fuyou] head="4" update algorithm=4 t=11.46s
[Section@16100] layer[40-48] tasks=19(nPassBack=0) last_loss=3.46174(-0.0899949) N=(772,18704,18144 2125068)
[epoch_0]_16101  loss=3.399690 |g|=0.362	lr=5.09e-04 | 19.0%@S14  T=4.10s(data=1.7ms QKV=2.10s FFN=3.03s) eta=2d 03:12:27 | 43.8K token/s | 
[epoch_0]_16111  loss=3.376967 |g|=0.414	lr=5.09e-04 | 19.8%@S14  T=1.69s(data=2.1ms QKV=2.10s FFN=3.04s) eta=21:02:17 | 44.1K token/s | 
[epoch_0]_16121  loss=3.410165 |g|=0.425	lr=5.08e-04 | 20.6%@S14  T=1.76s(data=2.0ms QKV=2.10s FFN=3.04s) eta=21:56:16 | 44.2K token/s | 
[epoch_0]_16131  loss=3.419812 |g|=0.422	lr=5.08e-04 | 21.5%@S14  T=1.74s(data=2.0ms QKV=2.10s FFN=3.04s) eta=21:45:37 | 44.3K token/s | 
[epoch_0]_16141  loss=3.338516 |g|=0.427	lr=5.08e-04 | 22.3%@S14  T=1.69s(data=1.6ms QKV=2.10s FFN=3.04s) eta=21:06:32 | 44.5K token/s | 
[epoch_0]_16151  loss=3.423728 |g|=0.402	lr=5.08e-04 | 23.1%@S14  T=1.73s(data=1.8ms QKV=2.10s FFN=3.04s) eta=21:33:28 | 44.7K token/s | 
[epoch_0]_16161  loss=3.437123 |g|=0.403	lr=5.08e-04 | 23.9%@S14  T=1.72s(data=1.8ms QKV=2.10s FFN=3.04s) eta=21:22:44 | 44.8K token/s | 
[epoch_0]_16171  loss=3.406898 |g|=0.418	lr=5.08e-04 | 24.7%@S14  T=1.74s(data=1.5ms QKV=2.10s FFN=3.04s) eta=21:43:23 | 44.9K token/s | 
[epoch_0]_16181  loss=3.443065 |g|=0.405	lr=5.08e-04 | 25.6%@S14  T=1.72s(data=1.9ms QKV=2.10s FFN=3.04s) eta=21:23:39 | 45.1K token/s | 
[epoch_0]_16191  loss=3.396787 |g|=0.415	lr=5.08e-04 | 26.4%@S14  T=1.73s(data=1.7ms QKV=2.10s FFN=3.04s) eta=21:30:34 | 45.2K token/s | 
[Fuyou] head="5" update algorithm=4 t=12.13s
[eval] 
	 Loss@"edu_fineweb1B"=3.392(0.0066) nBranch=1 nToken=6.31M best=3.3984(79) E2T=0.00154 T=36.7199(0)s x=0
	#3.39187±0.0977 tps=172K(6.30784M) a=[3.19805,3.65955] T=36.7199(sec)
[Section@16200] layer[0-8] tasks=19(nPassBack=0) last_loss=3.39034(0.00357962) N=(772,18816,18256 2138268)
[epoch_0]_16201  loss=3.378331 |g|=0.37	lr=5.08e-04 | 27.2%@S14  T=12.33s(data=1.8ms QKV=2.10s FFN=3.03s) eta=6d 09:35:59 | 43.3K token/s | 
[epoch_0]_16211  loss=3.495206 |g|=0.406	lr=5.07e-04 | 28.0%@S14  T=1.73s(data=1.8ms QKV=2.10s FFN=3.04s) eta=21:33:47 | 43.5K token/s | 
[epoch_0]_16221  loss=3.380566 |g|=0.431	lr=5.07e-04 | 28.8%@S14  T=1.67s(data=1.8ms QKV=2.10s FFN=3.04s) eta=20:44:50 | 43.7K token/s | 
[epoch_0]_16231  loss=3.427586 |g|=0.384	lr=5.07e-04 | 29.6%@S14  T=1.72s(data=1.9ms QKV=2.10s FFN=3.04s) eta=21:22:13 | 43.9K token/s | 
[epoch_0]_16241  loss=3.429785 |g|=0.396	lr=5.07e-04 | 30.5%@S14  T=1.72s(data=1.6ms QKV=2.10s FFN=3.04s) eta=21:22:21 | 44.1K token/s | 
[epoch_0]_16251  loss=3.318879 |g|=0.424	lr=5.07e-04 | 31.3%@S14  T=1.72s(data=1.9ms QKV=2.10s FFN=3.04s) eta=21:25:05 | 44.3K token/s | 
[epoch_0]_16261  loss=3.376251 |g|=0.393	lr=5.07e-04 | 32.1%@S14  T=1.72s(data=1.7ms QKV=2.10s FFN=3.04s) eta=21:22:45 | 44.5K token/s | 
[epoch_0]_16271  loss=3.450941 |g|=0.396	lr=5.07e-04 | 32.9%@S14  T=1.72s(data=1.7ms QKV=2.10s FFN=3.04s) eta=21:23:47 | 44.6K token/s | 
[epoch_0]_16281  loss=3.446733 |g|=0.403	lr=5.07e-04 | 33.7%@S14  T=1.72s(data=1.6ms QKV=2.10s FFN=3.04s) eta=21:24:14 | 44.8K token/s | 
[epoch_0]_16291  loss=3.429294 |g|=0.413	lr=5.07e-04 | 34.6%@S14  T=1.73s(data=1.7ms QKV=2.10s FFN=3.04s) eta=21:33:34 | 44.9K token/s | 
[Fuyou] head="0" update algorithm=4 t=11.17s
[Section@16300] layer[8-16] tasks=19(nPassBack=0) last_loss=3.38305(-0.0730557) N=(772,18928,18368 2151468)
[epoch_0]_16301  loss=3.393380 |g|=0.366	lr=5.06e-04 | 35.4%@S14  T=4.25s(data=1.9ms QKV=2.10s FFN=3.03s) eta=2d 04:51:34 | 43.6K token/s | 
[epoch_0]_16311  loss=3.407351 |g|=0.395	lr=5.06e-04 | 36.2%@S14  T=1.72s(data=1.7ms QKV=2.10s FFN=3.04s) eta=21:20:23 | 43.8K token/s | 
[epoch_0]_16321  loss=3.339704 |g|=0.378	lr=5.06e-04 | 37.0%@S14  T=1.72s(data=1.6ms QKV=2.10s FFN=3.04s) eta=21:24:42 | 44.0K token/s | 
[epoch_0]_16331  loss=3.379842 |g|=0.387	lr=5.06e-04 | 37.8%@S14  T=1.72s(data=2.3ms QKV=2.10s FFN=3.04s) eta=21:19:46 | 44.2K token/s | 
[epoch_0]_16341  loss=3.440946 |g|=0.393	lr=5.06e-04 | 38.7%@S14  T=1.71s(data=1.7ms QKV=2.10s FFN=3.04s) eta=21:16:46 | 44.4K token/s | 
[epoch_0]_16351  loss=3.491369 |g|=0.379	lr=5.06e-04 | 39.5%@S14  T=1.73s(data=1.7ms QKV=2.10s FFN=3.04s) eta=21:25:58 | 44.5K token/s | 
[epoch_0]_16361  loss=3.453592 |g|=0.408	lr=5.06e-04 | 40.3%@S14  T=1.73s(data=1.8ms QKV=2.10s FFN=3.04s) eta=21:28:11 | 44.7K token/s | 
[epoch_0]_16371  loss=3.430721 |g|=0.428	lr=5.06e-04 | 41.1%@S14  T=1.73s(data=1.6ms QKV=2.10s FFN=3.04s) eta=21:29:09 | 44.8K token/s | 
[epoch_0]_16381  loss=3.408209 |g|=0.392	lr=5.06e-04 | 41.9%@S14  T=1.71s(data=1.7ms QKV=2.10s FFN=3.04s) eta=21:14:41 | 44.9K token/s | 
[epoch_0]_16391  loss=3.375132 |g|=0.407	lr=5.05e-04 | 42.8%@S14  T=1.72s(data=1.5ms QKV=2.10s FFN=3.04s) eta=21:21:37 | 45.1K token/s | 
[Fuyou] head="1" update algorithm=4 t=8.63s
[eval] 
	 Loss@"edu_fineweb1B"=3.389(0.0025) nBranch=1 nToken=6.31M best=3.3919(80) E2T=0.0172 T=36.757(0)s x=0
	#3.38939±0.0980 tps=172K(6.30784M) a=[3.18627,3.65995] T=36.757(sec)
[Section@16400] layer[16-24] tasks=19(nPassBack=0) last_loss=3.37223(0.052635) N=(772,19040,18480 2164668)
[epoch_0]_16401  loss=3.419576 |g|=0.364	lr=5.05e-04 | 43.6%@S14  T=11.63s(data=2.2ms QKV=2.10s FFN=3.04s) eta=6d 00:11:47 | 43.2K token/s | 
[epoch_0]_16411  loss=3.386738 |g|=0.429	lr=5.05e-04 | 44.4%@S14  T=1.71s(data=2.0ms QKV=2.10s FFN=3.04s) eta=21:13:52 | 43.4K token/s | 
[epoch_0]_16421  loss=3.339893 |g|=0.41	lr=5.05e-04 | 45.2%@S14  T=1.72s(data=1.6ms QKV=2.10s FFN=3.04s) eta=21:19:53 | 43.6K token/s | 
[epoch_0]_16431  loss=3.374758 |g|=0.415	lr=5.05e-04 | 46.0%@S14  T=1.72s(data=1.6ms QKV=2.10s FFN=3.04s) eta=21:21:31 | 43.8K token/s | 
[epoch_0]_16441  loss=3.353020 |g|=0.41	lr=5.05e-04 | 46.9%@S14  T=1.71s(data=1.7ms QKV=2.10s FFN=3.04s) eta=21:12:36 | 44.0K token/s | 
[epoch_0]_16451  loss=3.444988 |g|=0.403	lr=5.05e-04 | 47.7%@S14  T=1.75s(data=1.7ms QKV=2.10s FFN=3.04s) eta=21:41:10 | 44.2K token/s | 
[epoch_0]_16461  loss=3.406071 |g|=0.398	lr=5.05e-04 | 48.5%@S14  T=1.72s(data=1.5ms QKV=2.10s FFN=3.04s) eta=21:15:11 | 44.3K token/s | 
[epoch_0]_16471  loss=3.391774 |g|=0.379	lr=5.05e-04 | 49.3%@S14  T=1.73s(data=1.6ms QKV=2.10s FFN=3.04s) eta=21:27:51 | 44.5K token/s | 
[epoch_0]_16481  loss=3.343483 |g|=0.399	lr=5.04e-04 | 50.1%@S14  T=1.73s(data=1.6ms QKV=2.10s FFN=3.04s) eta=21:23:17 | 44.6K token/s | 
[epoch_0]_16491  loss=3.426656 |g|=0.422	lr=5.04e-04 | 50.9%@S14  T=1.73s(data=1.7ms QKV=2.10s FFN=3.04s) eta=21:24:53 | 44.8K token/s | 
[Fuyou] head="2" update algorithm=4 t=10.44s
[Section@16500] layer[24-32] tasks=19(nPassBack=0) last_loss=3.42244(0.060925) N=(772,19152,18592 2177868)
[epoch_0]_16501  loss=3.377998 |g|=0.369	lr=5.04e-04 | 51.8%@S14  T=4.57s(data=2.0ms QKV=2.10s FFN=3.03s) eta=2d 08:31:27 | 43.4K token/s | 
[epoch_0]_16511  loss=3.405640 |g|=0.381	lr=5.04e-04 | 52.6%@S14  T=1.70s(data=1.7ms QKV=2.10s FFN=3.04s) eta=21:00:26 | 43.7K token/s | 
[epoch_0]_16521  loss=3.362983 |g|=0.412	lr=5.04e-04 | 53.4%@S14  T=1.73s(data=1.7ms QKV=2.10s FFN=3.04s) eta=21:26:34 | 43.8K token/s | 
[epoch_0]_16531  loss=3.346209 |g|=0.396	lr=5.04e-04 | 54.2%@S14  T=1.76s(data=1.5ms QKV=2.10s FFN=3.04s) eta=21:41:55 | 44.0K token/s | 
[epoch_0]_16541  loss=3.348544 |g|=0.37	lr=5.04e-04 | 55.0%@S14  T=1.75s(data=1.7ms QKV=2.10s FFN=3.04s) eta=21:41:00 | 44.1K token/s | 
[epoch_0]_16551  loss=3.461263 |g|=0.404	lr=5.04e-04 | 55.9%@S14  T=1.73s(data=1.7ms QKV=2.10s FFN=3.04s) eta=21:21:13 | 44.3K token/s | 
[epoch_0]_16561  loss=3.493133 |g|=0.401	lr=5.04e-04 | 56.7%@S14  T=1.73s(data=1.7ms QKV=2.10s FFN=3.04s) eta=21:26:02 | 44.4K token/s | 
[epoch_0]_16571  loss=3.381674 |g|=0.4	lr=5.03e-04 | 57.5%@S14  T=1.72s(data=1.7ms QKV=2.10s FFN=3.04s) eta=21:12:56 | 44.6K token/s | 
[epoch_0]_16581  loss=3.435868 |g|=0.365	lr=5.03e-04 | 58.3%@S14  T=1.72s(data=1.7ms QKV=2.10s FFN=3.04s) eta=21:17:34 | 44.7K token/s | 
[epoch_0]_16591  loss=3.392420 |g|=0.38	lr=5.03e-04 | 59.1%@S14  T=1.72s(data=2.0ms QKV=2.10s FFN=3.04s) eta=21:15:16 | 44.9K token/s | 
[Fuyou] head="3" update algorithm=4 t=11.37s
[eval] 
	 Loss@"edu_fineweb1B"=3.387(0.0023) nBranch=1 nToken=6.31M best=3.3894(81) E2T=0.0105 T=36.6987(0)s x=0
	#3.38705±0.0975 tps=172K(6.30784M) a=[3.19296,3.65478] T=36.6987(sec)
[Section@16600] layer[32-40] tasks=19(nPassBack=0) last_loss=3.37651(-0.0365241) N=(772,19264,18704 2191068)
[epoch_0]_16601  loss=3.334321 |g|=0.346	lr=5.03e-04 | 60.0%@S14  T=11.62s(data=1.9ms QKV=2.10s FFN=3.04s) eta=5d 23:23:47 | 43.0K token/s | 
[epoch_0]_16611  loss=3.398185 |g|=0.402	lr=5.03e-04 | 60.8%@S14  T=1.67s(data=1.6ms QKV=2.10s FFN=3.04s) eta=20:38:41 | 43.3K token/s | 
[epoch_0]_16621  loss=3.414614 |g|=0.414	lr=5.03e-04 | 61.6%@S14  T=1.70s(data=1.7ms QKV=2.10s FFN=3.04s) eta=20:59:10 | 43.5K token/s | 
[epoch_0]_16631  loss=3.471971 |g|=0.383	lr=5.03e-04 | 62.4%@S14  T=1.72s(data=1.7ms QKV=2.10s FFN=3.04s) eta=21:13:52 | 43.7K token/s | 
[epoch_0]_16641  loss=3.362051 |g|=0.373	lr=5.03e-04 | 63.2%@S14  T=1.68s(data=1.8ms QKV=2.10s FFN=3.04s) eta=20:39:38 | 44.0K token/s | 
[epoch_0]_16651  loss=3.414262 |g|=0.391	lr=5.02e-04 | 64.1%@S14  T=1.74s(data=1.7ms QKV=2.10s FFN=3.04s) eta=21:30:48 | 44.1K token/s | 
[epoch_0]_16661  loss=3.333962 |g|=0.384	lr=5.02e-04 | 64.9%@S14  T=1.69s(data=1.6ms QKV=2.10s FFN=3.04s) eta=20:48:10 | 44.4K token/s | 
[epoch_0]_16671  loss=3.341208 |g|=0.39	lr=5.02e-04 | 65.7%@S14  T=1.72s(data=1.7ms QKV=2.10s FFN=3.04s) eta=21:09:07 | 44.5K token/s | 
[epoch_0]_16681  loss=3.431041 |g|=0.384	lr=5.02e-04 | 66.5%@S14  T=1.73s(data=1.7ms QKV=2.10s FFN=3.04s) eta=21:17:34 | 44.7K token/s | 
[epoch_0]_16691  loss=3.356060 |g|=0.381	lr=5.02e-04 | 67.3%@S14  T=1.73s(data=1.6ms QKV=2.10s FFN=3.04s) eta=21:19:47 | 44.8K token/s | 
[Fuyou] head="4" update algorithm=4 t=11.98s
[Section@16700] layer[40-48] tasks=19(nPassBack=0) last_loss=3.41435(0.0473888) N=(772,19376,18816 2204268)
[epoch_0]_16701  loss=3.355673 |g|=0.439	lr=5.02e-04 | 68.2%@S14  T=3.93s(data=2.1ms QKV=2.10s FFN=3.03s) eta=2d 00:23:21 | 43.6K token/s | 
[epoch_0]_16711  loss=3.356821 |g|=0.387	lr=5.02e-04 | 69.0%@S14  T=1.71s(data=1.7ms QKV=2.10s FFN=3.04s) eta=21:06:40 | 43.8K token/s | 
[epoch_0]_16721  loss=3.389153 |g|=0.405	lr=5.02e-04 | 69.8%@S14  T=1.72s(data=2.4ms QKV=2.10s FFN=3.04s) eta=21:13:07 | 44.0K token/s | 
[epoch_0]_16731  loss=3.353867 |g|=0.381	lr=5.02e-04 | 70.6%@S14  T=1.73s(data=1.6ms QKV=2.10s FFN=3.04s) eta=21:15:47 | 44.2K token/s | 
[epoch_0]_16741  loss=3.410360 |g|=0.413	lr=5.01e-04 | 71.4%@S14  T=1.68s(data=1.8ms QKV=2.10s FFN=3.04s) eta=20:43:52 | 44.4K token/s | 
[epoch_0]_16751  loss=3.400617 |g|=0.391	lr=5.01e-04 | 72.2%@S14  T=1.67s(data=1.8ms QKV=2.10s FFN=3.04s) eta=20:33:28 | 44.6K token/s | 
[epoch_0]_16761  loss=3.393077 |g|=0.413	lr=5.01e-04 | 73.1%@S14  T=1.73s(data=1.7ms QKV=2.10s FFN=3.04s) eta=21:17:22 | 44.8K token/s | 
[epoch_0]_16771  loss=3.381827 |g|=0.387	lr=5.01e-04 | 73.9%@S14  T=1.70s(data=1.6ms QKV=2.10s FFN=3.04s) eta=20:54:10 | 44.9K token/s | 
[epoch_0]_16781  loss=3.439506 |g|=0.39	lr=5.01e-04 | 74.7%@S14  T=1.73s(data=1.7ms QKV=2.10s FFN=3.04s) eta=21:17:55 | 45.0K token/s | 
[epoch_0]_16791  loss=3.359333 |g|=0.394	lr=5.01e-04 | 75.5%@S14  T=1.74s(data=1.5ms QKV=2.10s FFN=3.04s) eta=21:21:21 | 45.2K token/s | 
[Fuyou] head="5" update algorithm=4 t=10.54s
[eval] 
	 Loss@"edu_fineweb1B"=3.385(0.0018) nBranch=1 nToken=6.31M best=3.3871(82) E2T=0.0161 T=36.7412(0)s x=0
	#3.38528±0.0979 tps=172K(6.30784M) a=[3.19343,3.65142] T=36.7412(sec)
[Section@16800] layer[0-8] tasks=19(nPassBack=0) last_loss=3.36918(0.0211606) N=(772,19488,18928 2217468)
[epoch_0]_16801  loss=3.441185 |g|=0.362	lr=5.01e-04 | 76.3%@S14  T=12.14s(data=2.1ms QKV=2.10s FFN=3.04s) eta=6d 05:11:11 | 43.2K token/s | 
[epoch_0]_16811  loss=3.381046 |g|=0.378	lr=5.01e-04 | 77.2%@S14  T=1.69s(data=1.6ms QKV=2.10s FFN=3.04s) eta=20:42:14 | 43.5K token/s | 
[epoch_0]_16821  loss=3.420069 |g|=0.403	lr=5.01e-04 | 78.0%@S14  T=1.69s(data=1.9ms QKV=2.10s FFN=3.04s) eta=20:47:34 | 43.7K token/s | 
[epoch_0]_16831  loss=3.368382 |g|=0.404	lr=5.00e-04 | 78.8%@S14  T=1.71s(data=1.7ms QKV=2.10s FFN=3.04s) eta=21:00:09 | 44.0K token/s | 
[epoch_0]_16841  loss=3.378562 |g|=0.367	lr=5.00e-04 | 79.6%@S14  T=1.69s(data=1.9ms QKV=2.10s FFN=3.04s) eta=20:45:17 | 44.2K token/s | 
[epoch_0]_16851  loss=3.456979 |g|=0.406	lr=5.00e-04 | 80.4%@S14  T=1.73s(data=1.7ms QKV=2.10s FFN=3.04s) eta=21:14:28 | 44.3K token/s | 
[epoch_0]_16861  loss=3.438256 |g|=0.436	lr=5.00e-04 | 81.3%@S14  T=1.76s(data=1.9ms QKV=2.10s FFN=3.04s) eta=21:36:25 | 44.4K token/s | 
[epoch_0]_16871  loss=3.396739 |g|=0.396	lr=5.00e-04 | 82.1%@S14  T=1.73s(data=1.6ms QKV=2.10s FFN=3.04s) eta=21:10:08 | 44.6K token/s | 
[epoch_0]_16881  loss=3.451895 |g|=0.394	lr=5.00e-04 | 82.9%@S14  T=1.68s(data=1.6ms QKV=2.10s FFN=3.04s) eta=20:38:16 | 44.8K token/s | 
[epoch_0]_16891  loss=3.289190 |g|=0.389	lr=5.00e-04 | 83.7%@S14  T=1.71s(data=1.6ms QKV=2.10s FFN=3.04s) eta=20:58:09 | 45.0K token/s | 
[Fuyou] head="0" update algorithm=4 t=8.92s
[Section@16900] layer[8-16] tasks=19(nPassBack=0) last_loss=3.38017(0.00287938) N=(772,19600,19040 2230668)
[epoch_0]_16901  loss=3.343876 |g|=0.377	lr=5.00e-04 | 84.5%@S14  T=3.99s(data=1.7ms QKV=2.10s FFN=3.03s) eta=2d 00:53:37 | 43.7K token/s | 
[epoch_0]_16911  loss=3.316715 |g|=0.4	lr=4.99e-04 | 85.4%@S14  T=1.70s(data=1.7ms QKV=2.10s FFN=3.04s) eta=20:48:42 | 44.0K token/s | 
[epoch_0]_16921  loss=3.383772 |g|=0.415	lr=4.99e-04 | 86.2%@S14  T=1.68s(data=1.9ms QKV=2.10s FFN=3.04s) eta=20:36:02 | 44.2K token/s | 
[epoch_0]_16931  loss=3.321347 |g|=0.377	lr=4.99e-04 | 87.0%@S14  T=1.68s(data=1.6ms QKV=2.10s FFN=3.04s) eta=20:35:41 | 44.4K token/s | 
[epoch_0]_16941  loss=3.314894 |g|=0.413	lr=4.99e-04 | 87.8%@S14  T=1.68s(data=1.6ms QKV=2.10s FFN=3.04s) eta=20:36:54 | 44.6K token/s | 
[epoch_0]_16951  loss=3.402533 |g|=0.382	lr=4.99e-04 | 88.6%@S14  T=1.70s(data=1.6ms QKV=2.10s FFN=3.04s) eta=20:49:00 | 44.8K token/s | 
[epoch_0]_16961  loss=3.371214 |g|=0.386	lr=4.99e-04 | 89.4%@S14  T=1.71s(data=2.1ms QKV=2.10s FFN=3.04s) eta=20:55:43 | 45.0K token/s | 
[epoch_0]_16971  loss=3.402912 |g|=0.387	lr=4.99e-04 | 90.3%@S14  T=1.73s(data=1.7ms QKV=2.10s FFN=3.04s) eta=21:08:05 | 45.1K token/s | 
[epoch_0]_16981  loss=3.368622 |g|=0.421	lr=4.99e-04 | 91.1%@S14  T=1.75s(data=1.6ms QKV=2.10s FFN=3.04s) eta=21:26:33 | 45.2K token/s | 
[epoch_0]_16991  loss=3.423314 |g|=0.386	lr=4.99e-04 | 91.9%@S14  T=1.69s(data=1.8ms QKV=2.10s FFN=3.04s) eta=20:38:29 | 45.3K token/s | 
[Fuyou] head="1" update algorithm=4 t=10.76s
[eval] 
	 Loss@"edu_fineweb1B"=3.382(0.0037) nBranch=1 nToken=6.31M best=3.3853(83) E2T=0.0118 T=36.7477(0)s x=0
	#3.38163±0.0975 tps=172K(6.30784M) a=[3.18975,3.64961] T=36.7477(sec)
[Section@17000] layer[16-24] tasks=19(nPassBack=0) last_loss=3.36986(0.00237489) N=(772,19712,19152 2243868)
[epoch_0]_17001  loss=3.404067 |g|=0.407	lr=4.98e-04 | 92.7%@S14  T=12.24s(data=2.0ms QKV=2.10s FFN=3.04s) eta=6d 05:44:22 | 43.4K token/s | 
[epoch_0]_17011  loss=3.369856 |g|=0.403	lr=4.98e-04 | 93.5%@S14  T=1.73s(data=2.0ms QKV=2.10s FFN=3.04s) eta=21:06:38 | 43.6K token/s | 
[epoch_0]_17021  loss=3.367157 |g|=0.462	lr=4.98e-04 | 94.4%@S14  T=1.70s(data=2.1ms QKV=2.10s FFN=3.04s) eta=20:47:28 | 43.8K token/s | 
[epoch_0]_17031  loss=3.372746 |g|=0.423	lr=4.98e-04 | 95.2%@S14  T=1.73s(data=1.9ms QKV=2.10s FFN=3.04s) eta=21:10:21 | 44.0K token/s | 
[epoch_0]_17041  loss=3.292334 |g|=0.418	lr=4.98e-04 | 96.0%@S14  T=1.73s(data=1.6ms QKV=2.10s FFN=3.04s) eta=21:11:51 | 44.2K token/s | 
[epoch_0]_17051  loss=3.339221 |g|=0.399	lr=4.98e-04 | 96.8%@S14  T=1.69s(data=1.5ms QKV=2.10s FFN=3.04s) eta=20:39:54 | 44.4K token/s | 
[epoch_0]_17061  loss=3.407288 |g|=0.387	lr=4.98e-04 | 97.6%@S14  T=1.69s(data=1.5ms QKV=2.10s FFN=3.04s) eta=20:36:48 | 44.6K token/s | 
[epoch_0]_17071  loss=3.329796 |g|=0.392	lr=4.98e-04 | 98.5%@S14  T=1.67s(data=1.4ms QKV=2.10s FFN=3.04s) eta=20:24:37 | 44.8K token/s | 
[epoch_0]_17081  loss=3.338557 |g|=0.37	lr=4.98e-04 | 99.3%@S14  T=1.69s(data=1.8ms QKV=2.10s FFN=3.04s) eta=20:37:31 | 45.0K token/s | 
[epoch_0]_17089  loss=3.361606 |g|=0.397	lr=4.97e-04 | 99.9%@S14  T=1.68s(data=2.0ms QKV=2.10s FFN=3.05s) eta=20:30:23 | 45.2K token/s | 
-------- End of shard_14@"./Datasets/edu_fineweb1B/edu_fineweb_train_000468.bin"-------- 
[shard-15]@"./Datasets/edu_fineweb1B/edu_fineweb_train_000469.bin": tokens=100(M) nShardSamples=1220(1464840) 
[epoch_0]_17091  loss=3.380438 |g|=0.393	lr=4.97e-04 | 0.1%@S15  T=1.91s(data=1.5ms QKV=2.10s FFN=3.04s) eta=23:22:26 | 45.1K token/s | 
[Fuyou] head="2" update algorithm=4 t=11.11s
[Section@17100] layer[24-32] tasks=19(nPassBack=0) last_loss=3.37284(0.0495977) N=(772,19824,19264 2257068)
[epoch_0]_17101  loss=3.364534 |g|=0.387	lr=4.97e-04 | 0.9%@S15  T=4.36s(data=1.4ms QKV=2.10s FFN=3.04s) eta=2d 05:13:06 | 43.8K token/s | 
[epoch_0]_17111  loss=3.409995 |g|=0.39	lr=4.97e-04 | 1.7%@S15  T=1.69s(data=6.1ms QKV=2.10s FFN=3.04s) eta=20:40:26 | 44.0K token/s | 
[epoch_0]_17121  loss=3.475829 |g|=0.403	lr=4.97e-04 | 2.6%@S15  T=1.69s(data=1.5ms QKV=2.10s FFN=3.04s) eta=20:38:42 | 44.2K token/s | 
[epoch_0]_17131  loss=3.368906 |g|=0.403	lr=4.97e-04 | 3.4%@S15  T=1.69s(data=1.6ms QKV=2.10s FFN=3.04s) eta=20:38:43 | 44.4K token/s | 
[epoch_0]_17141  loss=3.242100 |g|=0.367	lr=4.97e-04 | 4.2%@S15  T=1.69s(data=1.8ms QKV=2.11s FFN=3.04s) eta=20:36:35 | 44.6K token/s | 
[epoch_0]_17151  loss=3.338007 |g|=0.397	lr=4.97e-04 | 5.0%@S15  T=1.69s(data=1.9ms QKV=2.10s FFN=3.04s) eta=20:34:00 | 44.8K token/s | 
[epoch_0]_17161  loss=3.336931 |g|=0.392	lr=4.97e-04 | 5.8%@S15  T=1.72s(data=1.8ms QKV=2.10s FFN=3.04s) eta=21:00:27 | 44.9K token/s | 
[epoch_0]_17171  loss=3.394800 |g|=0.423	lr=4.96e-04 | 6.7%@S15  T=1.73s(data=1.6ms QKV=2.10s FFN=3.04s) eta=21:04:09 | 45.1K token/s | 
[epoch_0]_17181  loss=3.334219 |g|=0.433	lr=4.96e-04 | 7.5%@S15  T=1.72s(data=1.8ms QKV=2.10s FFN=3.04s) eta=20:59:51 | 45.2K token/s | 
[epoch_0]_17191  loss=3.346377 |g|=0.407	lr=4.96e-04 | 8.3%@S15  T=1.72s(data=1.3ms QKV=2.10s FFN=3.04s) eta=20:59:55 | 45.3K token/s | 
[Fuyou] head="3" update algorithm=4 t=11.21s
[eval] 
	 Loss@"edu_fineweb1B"=3.380(0.002) nBranch=1 nToken=6.31M best=3.3816(84) E2T=-0.0194 T=36.7413(0)s x=0
	#3.37959±0.0976 tps=172K(6.30784M) a=[3.18215,3.64484] T=36.7413(sec)
[Section@17200] layer[32-40] tasks=19(nPassBack=0) last_loss=3.399(-0.0224898) N=(772,19936,19376 2270268)
[epoch_0]_17201  loss=3.368178 |g|=0.397	lr=4.96e-04 | 9.1%@S15  T=11.62s(data=1.6ms QKV=2.10s FFN=3.04s) eta=5d 21:28:38 | 43.4K token/s | 
[epoch_0]_17211  loss=3.378626 |g|=0.395	lr=4.96e-04 | 9.9%@S15  T=1.72s(data=1.4ms QKV=2.10s FFN=3.04s) eta=20:54:25 | 43.6K token/s | 
[epoch_0]_17221  loss=3.326329 |g|=0.377	lr=4.96e-04 | 10.7%@S15  T=1.66s(data=1.3ms QKV=2.10s FFN=3.04s) eta=20:14:42 | 43.9K token/s | 
[epoch_0]_17231  loss=3.303385 |g|=0.402	lr=4.96e-04 | 11.6%@S15  T=1.67s(data=1.5ms QKV=2.10s FFN=3.04s) eta=20:21:36 | 44.1K token/s | 
[epoch_0]_17241  loss=3.369368 |g|=0.373	lr=4.96e-04 | 12.4%@S15  T=1.69s(data=1.5ms QKV=2.10s FFN=3.04s) eta=20:35:56 | 44.4K token/s | 
[epoch_0]_17251  loss=3.462032 |g|=0.405	lr=4.96e-04 | 13.2%@S15  T=1.71s(data=1.6ms QKV=2.10s FFN=3.05s) eta=20:46:21 | 44.5K token/s | 
[epoch_0]_17261  loss=3.356908 |g|=0.365	lr=4.95e-04 | 14.0%@S15  T=1.71s(data=1.6ms QKV=2.10s FFN=3.04s) eta=20:49:51 | 44.7K token/s | 
[epoch_0]_17271  loss=3.377922 |g|=0.399	lr=4.95e-04 | 14.8%@S15  T=1.72s(data=1.4ms QKV=2.10s FFN=3.04s) eta=20:51:52 | 44.9K token/s | 
[epoch_0]_17281  loss=3.352340 |g|=0.387	lr=4.95e-04 | 15.7%@S15  T=1.67s(data=1.7ms QKV=2.10s FFN=3.04s) eta=20:19:32 | 45.1K token/s | 
[epoch_0]_17291  loss=3.333516 |g|=0.428	lr=4.95e-04 | 16.5%@S15  T=1.72s(data=1.6ms QKV=2.10s FFN=3.04s) eta=20:53:03 | 45.2K token/s | 
[Fuyou] head="4" update algorithm=4 t=11.80s
[Section@17300] layer[40-48] tasks=19(nPassBack=0) last_loss=3.399(0.0153494) N=(772,20048,19488 2283468)
[epoch_0]_17301  loss=3.348801 |g|=0.353	lr=4.95e-04 | 17.3%@S15  T=4.16s(data=2.4ms QKV=2.10s FFN=3.04s) eta=2d 02:35:42 | 43.9K token/s | 
[epoch_0]_17311  loss=3.300285 |g|=0.419	lr=4.95e-04 | 18.1%@S15  T=1.69s(data=1.7ms QKV=2.10s FFN=3.04s) eta=20:28:34 | 44.1K token/s | 
[epoch_0]_17321  loss=3.301833 |g|=0.383	lr=4.95e-04 | 18.9%@S15  T=1.71s(data=1.6ms QKV=2.10s FFN=3.04s) eta=20:45:15 | 44.3K token/s | 
[epoch_0]_17331  loss=3.351722 |g|=0.39	lr=4.95e-04 | 19.8%@S15  T=1.67s(data=1.8ms QKV=2.10s FFN=3.04s) eta=20:16:50 | 44.6K token/s | 
[epoch_0]_17341  loss=3.307522 |g|=0.407	lr=4.94e-04 | 20.6%@S15  T=1.74s(data=1.7ms QKV=2.10s FFN=3.04s) eta=21:06:42 | 44.7K token/s | 
[epoch_0]_17351  loss=3.390742 |g|=0.42	lr=4.94e-04 | 21.4%@S15  T=1.68s(data=2.6ms QKV=2.10s FFN=3.04s) eta=20:20:19 | 44.9K token/s | 
[epoch_0]_17361  loss=3.349010 |g|=0.396	lr=4.94e-04 | 22.2%@S15  T=1.73s(data=1.7ms QKV=2.10s FFN=3.04s) eta=21:00:57 | 45.0K token/s | 
[epoch_0]_17371  loss=3.401372 |g|=0.372	lr=4.94e-04 | 23.0%@S15  T=1.72s(data=1.6ms QKV=2.10s FFN=3.04s) eta=20:48:31 | 45.2K token/s | 
[epoch_0]_17381  loss=3.358017 |g|=0.391	lr=4.94e-04 | 23.9%@S15  T=1.73s(data=1.8ms QKV=2.10s FFN=3.04s) eta=20:57:50 | 45.3K token/s | 
[epoch_0]_17391  loss=3.426010 |g|=0.415	lr=4.94e-04 | 24.7%@S15  T=1.74s(data=1.6ms QKV=2.11s FFN=3.04s) eta=21:04:40 | 45.4K token/s | 
[Fuyou] head="5" update algorithm=4 t=10.87s
[eval] 
	 Loss@"edu_fineweb1B"=3.377(0.0025) nBranch=1 nToken=6.31M best=3.3796(85) E2T=0.0687 T=36.7381(0)s x=0
	#3.37709±0.0974 tps=172K(6.30784M) a=[3.18298,3.64097] T=36.7381(sec)
[Section@17400] layer[0-8] tasks=19(nPassBack=0) last_loss=3.30843(0.060751) N=(772,20160,19600 2296668)
[epoch_0]_17401  loss=3.348191 |g|=0.372	lr=4.94e-04 | 25.5%@S15  T=12.14s(data=1.6ms QKV=2.10s FFN=3.04s) eta=6d 03:09:18 | 43.4K token/s | 
[epoch_0]_17411  loss=3.382676 |g|=0.422	lr=4.94e-04 | 26.3%@S15  T=1.72s(data=1.5ms QKV=2.10s FFN=3.04s) eta=20:48:32 | 43.6K token/s | 
[epoch_0]_17421  loss=3.360447 |g|=0.369	lr=4.94e-04 | 27.1%@S15  T=1.75s(data=1.8ms QKV=2.10s FFN=3.04s) eta=21:10:22 | 43.8K token/s | 
[epoch_0]_17431  loss=3.369927 |g|=0.354	lr=4.93e-04 | 28.0%@S15  T=1.68s(data=1.8ms QKV=2.10s FFN=3.04s) eta=20:24:05 | 44.1K token/s | 
[epoch_0]_17441  loss=3.374324 |g|=0.383	lr=4.93e-04 | 28.8%@S15  T=1.68s(data=1.8ms QKV=2.10s FFN=3.04s) eta=20:22:30 | 44.3K token/s | 
[epoch_0]_17451  loss=3.306298 |g|=0.394	lr=4.93e-04 | 29.6%@S15  T=1.71s(data=1.5ms QKV=2.10s FFN=3.04s) eta=20:39:10 | 44.5K token/s | 
[epoch_0]_17461  loss=3.400254 |g|=0.376	lr=4.93e-04 | 30.4%@S15  T=1.68s(data=1.8ms QKV=2.10s FFN=3.04s) eta=20:17:33 | 44.7K token/s | 
[epoch_0]_17471  loss=3.289893 |g|=0.417	lr=4.93e-04 | 31.2%@S15  T=1.69s(data=1.6ms QKV=2.10s FFN=3.04s) eta=20:29:44 | 44.9K token/s | 
[epoch_0]_17481  loss=3.332850 |g|=0.398	lr=4.93e-04 | 32.0%@S15  T=1.73s(data=1.4ms QKV=2.10s FFN=3.04s) eta=20:52:37 | 45.0K token/s | 
[epoch_0]_17491  loss=3.401115 |g|=0.41	lr=4.93e-04 | 32.9%@S15  T=1.69s(data=1.7ms QKV=2.10s FFN=3.04s) eta=20:24:09 | 45.2K token/s | 
[Fuyou] head="0" update algorithm=4 t=9.59s
[Section@17500] layer[8-16] tasks=19(nPassBack=0) last_loss=3.3583(0.0218678) N=(772,20272,19712 2309868)
[epoch_0]_17501  loss=3.409586 |g|=0.377	lr=4.93e-04 | 33.7%@S15  T=3.99s(data=1.8ms QKV=2.10s FFN=3.04s) eta=2d 00:11:25 | 44.0K token/s | 
[epoch_0]_17511  loss=3.316095 |g|=0.408	lr=4.92e-04 | 34.5%@S15  T=1.68s(data=1.8ms QKV=2.10s FFN=3.04s) eta=20:15:31 | 44.2K token/s | 
[epoch_0]_17521  loss=3.284009 |g|=0.38	lr=4.92e-04 | 35.3%@S15  T=1.67s(data=1.8ms QKV=2.10s FFN=3.04s) eta=20:13:05 | 44.4K token/s | 
[epoch_0]_17531  loss=3.371680 |g|=0.381	lr=4.92e-04 | 36.1%@S15  T=1.68s(data=1.6ms QKV=2.10s FFN=3.04s) eta=20:15:29 | 44.7K token/s | 
[epoch_0]_17541  loss=3.358241 |g|=0.408	lr=4.92e-04 | 37.0%@S15  T=1.72s(data=1.8ms QKV=2.10s FFN=3.04s) eta=20:46:23 | 44.8K token/s | 
[epoch_0]_17551  loss=3.359544 |g|=0.359	lr=4.92e-04 | 37.8%@S15  T=1.71s(data=1.7ms QKV=2.10s FFN=3.04s) eta=20:38:56 | 45.0K token/s | 
[epoch_0]_17561  loss=3.404759 |g|=0.38	lr=4.92e-04 | 38.6%@S15  T=1.69s(data=1.9ms QKV=2.10s FFN=3.04s) eta=20:27:22 | 45.1K token/s | 
[epoch_0]_17571  loss=3.353093 |g|=0.4	lr=4.92e-04 | 39.4%@S15  T=1.74s(data=1.5ms QKV=2.10s FFN=3.04s) eta=21:03:19 | 45.2K token/s | 
[epoch_0]_17581  loss=3.357359 |g|=0.383	lr=4.92e-04 | 40.2%@S15  T=1.70s(data=1.9ms QKV=2.10s FFN=3.04s) eta=20:32:58 | 45.4K token/s | 
[epoch_0]_17591  loss=3.357527 |g|=0.396	lr=4.91e-04 | 41.1%@S15  T=1.69s(data=1.9ms QKV=2.10s FFN=3.04s) eta=20:21:33 | 45.5K token/s | 
[Fuyou] head="1" update algorithm=4 t=10.17s
[eval] 
	 Loss@"edu_fineweb1B"=3.374(0.0031) nBranch=1 nToken=6.31M best=3.3771(86) E2T=0.0117 T=36.7667(0)s x=0
	#3.37396±0.0974 tps=172K(6.30784M) a=[3.17902,3.63965] T=36.7667(sec)
[Section@17600] layer[16-24] tasks=19(nPassBack=0) last_loss=3.3623(0.00756311) N=(772,20384,19824 2323068)
[epoch_0]_17601  loss=3.308929 |g|=0.41	lr=4.91e-04 | 41.9%@S15  T=11.66s(data=1.8ms QKV=2.10s FFN=3.04s) eta=5d 20:38:10 | 43.6K token/s | 
[epoch_0]_17611  loss=3.372913 |g|=0.37	lr=4.91e-04 | 42.7%@S15  T=1.72s(data=1.6ms QKV=2.10s FFN=3.04s) eta=20:46:35 | 43.8K token/s | 
[epoch_0]_17621  loss=3.347125 |g|=0.405	lr=4.91e-04 | 43.5%@S15  T=1.74s(data=1.5ms QKV=2.10s FFN=3.04s) eta=20:56:40 | 44.0K token/s | 
[epoch_0]_17631  loss=3.382954 |g|=0.416	lr=4.91e-04 | 44.3%@S15  T=1.77s(data=1.6ms QKV=2.10s FFN=3.04s) eta=21:18:16 | 44.1K token/s | 
[epoch_0]_17641  loss=3.322799 |g|=0.395	lr=4.91e-04 | 45.2%@S15  T=1.72s(data=1.6ms QKV=2.10s FFN=3.04s) eta=20:43:22 | 44.3K token/s | 
[epoch_0]_17651  loss=3.323735 |g|=0.393	lr=4.91e-04 | 46.0%@S15  T=1.73s(data=1.7ms QKV=2.10s FFN=3.04s) eta=20:50:44 | 44.4K token/s | 
[epoch_0]_17661  loss=3.419232 |g|=0.39	lr=4.91e-04 | 46.8%@S15  T=1.72s(data=1.6ms QKV=2.10s FFN=3.04s) eta=20:44:02 | 44.6K token/s | 
[epoch_0]_17671  loss=3.363363 |g|=0.391	lr=4.91e-04 | 47.6%@S15  T=1.73s(data=1.7ms QKV=2.10s FFN=3.04s) eta=20:53:33 | 44.7K token/s | 
[epoch_0]_17681  loss=3.366549 |g|=0.406	lr=4.90e-04 | 48.4%@S15  T=1.72s(data=1.6ms QKV=2.10s FFN=3.04s) eta=20:44:20 | 44.9K token/s | 
[epoch_0]_17691  loss=3.343272 |g|=0.404	lr=4.90e-04 | 49.3%@S15  T=1.72s(data=1.5ms QKV=2.10s FFN=3.04s) eta=20:41:12 | 45.0K token/s | 
[Fuyou] head="2" update algorithm=4 t=9.46s
[Section@17700] layer[24-32] tasks=19(nPassBack=0) last_loss=3.36954(0.00330591) N=(772,20496,19936 2336268)
[epoch_0]_17701  loss=3.279156 |g|=0.401	lr=4.90e-04 | 50.1%@S15  T=4.45s(data=1.7ms QKV=2.10s FFN=3.04s) eta=2d 05:35:57 | 43.7K token/s | 
[epoch_0]_17711  loss=3.380553 |g|=0.387	lr=4.90e-04 | 50.9%@S15  T=1.70s(data=1.7ms QKV=2.10s FFN=3.04s) eta=20:25:45 | 43.9K token/s | 
[epoch_0]_17721  loss=3.274074 |g|=0.393	lr=4.90e-04 | 51.7%@S15  T=1.68s(data=1.6ms QKV=2.10s FFN=3.04s) eta=20:12:58 | 44.1K token/s | 
[epoch_0]_17731  loss=3.385267 |g|=0.398	lr=4.90e-04 | 52.5%@S15  T=1.69s(data=1.9ms QKV=2.10s FFN=3.04s) eta=20:22:09 | 44.4K token/s | 
[epoch_0]_17741  loss=3.362558 |g|=0.409	lr=4.90e-04 | 53.3%@S15  T=1.73s(data=1.6ms QKV=2.10s FFN=3.04s) eta=20:46:21 | 44.5K token/s | 
[epoch_0]_17751  loss=3.275238 |g|=0.393	lr=4.90e-04 | 54.2%@S15  T=1.72s(data=1.5ms QKV=2.10s FFN=3.04s) eta=20:41:37 | 44.7K token/s | 
[epoch_0]_17761  loss=3.395530 |g|=0.408	lr=4.89e-04 | 55.0%@S15  T=1.72s(data=1.5ms QKV=2.10s FFN=3.04s) eta=20:42:42 | 44.8K token/s | 
[epoch_0]_17771  loss=3.407197 |g|=0.385	lr=4.89e-04 | 55.8%@S15  T=1.73s(data=1.9ms QKV=2.10s FFN=3.04s) eta=20:46:00 | 44.9K token/s | 
[epoch_0]_17781  loss=3.371091 |g|=0.427	lr=4.89e-04 | 56.6%@S15  T=1.72s(data=2.1ms QKV=2.10s FFN=3.04s) eta=20:41:32 | 45.1K token/s | 
[epoch_0]_17791  loss=3.396389 |g|=0.398	lr=4.89e-04 | 57.4%@S15  T=1.73s(data=1.6ms QKV=2.10s FFN=3.04s) eta=20:44:09 | 45.2K token/s | 
[Fuyou] head="3" update algorithm=4 t=11.05s
[eval] 
	 Loss@"edu_fineweb1B"=3.371(0.0034) nBranch=1 nToken=6.31M best=3.3740(87) E2T=0.0199 T=36.7443(0)s x=0
	#3.37051±0.0965 tps=172K(6.30784M) a=[3.17641,3.63418] T=36.7443(sec)
[Section@17800] layer[32-40] tasks=19(nPassBack=0) last_loss=3.3506(0.0484064) N=(772,20608,20048 2349468)
[epoch_0]_17801  loss=3.301301 |g|=0.402	lr=4.89e-04 | 58.3%@S15  T=11.67s(data=2.0ms QKV=2.10s FFN=3.04s) eta=5d 20:11:50 | 43.3K token/s | 
[epoch_0]_17811  loss=3.415943 |g|=0.447	lr=4.89e-04 | 59.1%@S15  T=1.74s(data=1.8ms QKV=2.10s FFN=3.04s) eta=20:53:06 | 43.5K token/s | 
[epoch_0]_17821  loss=3.405694 |g|=0.412	lr=4.89e-04 | 59.9%@S15  T=1.73s(data=1.9ms QKV=2.10s FFN=3.04s) eta=20:43:17 | 43.7K token/s | 
[epoch_0]_17831  loss=3.347641 |g|=0.395	lr=4.89e-04 | 60.7%@S15  T=1.74s(data=1.5ms QKV=2.10s FFN=3.04s) eta=20:55:53 | 43.8K token/s | 
[epoch_0]_17841  loss=3.349808 |g|=0.446	lr=4.88e-04 | 61.5%@S15  T=1.72s(data=1.7ms QKV=2.10s FFN=3.04s) eta=20:40:09 | 44.0K token/s | 
[epoch_0]_17851  loss=3.348647 |g|=0.408	lr=4.88e-04 | 62.4%@S15  T=1.74s(data=1.6ms QKV=2.10s FFN=3.04s) eta=20:53:21 | 44.2K token/s | 
[epoch_0]_17861  loss=3.315245 |g|=0.384	lr=4.88e-04 | 63.2%@S15  T=1.73s(data=1.7ms QKV=2.10s FFN=3.04s) eta=20:43:07 | 44.3K token/s | 
[epoch_0]_17871  loss=3.338741 |g|=0.366	lr=4.88e-04 | 64.0%@S15  T=1.75s(data=1.7ms QKV=2.10s FFN=3.04s) eta=20:57:49 | 44.5K token/s | 
[epoch_0]_17881  loss=3.290871 |g|=0.392	lr=4.88e-04 | 64.8%@S15  T=1.73s(data=1.8ms QKV=2.10s FFN=3.04s) eta=20:45:58 | 44.6K token/s | 
[epoch_0]_17891  loss=3.329376 |g|=0.379	lr=4.88e-04 | 65.6%@S15  T=1.76s(data=1.6ms QKV=2.10s FFN=3.04s) eta=21:02:49 | 44.7K token/s | 
[Fuyou] head="4" update algorithm=4 t=12.19s
[Section@17900] layer[40-48] tasks=19(nPassBack=0) last_loss=3.38209(0.0169153) N=(772,20720,20160 2362668)
[epoch_0]_17901  loss=3.338466 |g|=0.384	lr=4.88e-04 | 66.5%@S15  T=4.22s(data=1.9ms QKV=2.10s FFN=3.04s) eta=2d 02:32:09 | 43.4K token/s | 
[epoch_0]_17911  loss=3.366165 |g|=0.387	lr=4.88e-04 | 67.3%@S15  T=1.71s(data=1.6ms QKV=2.10s FFN=3.04s) eta=20:31:10 | 43.7K token/s | 
[epoch_0]_17921  loss=3.346720 |g|=0.377	lr=4.88e-04 | 68.1%@S15  T=1.70s(data=1.6ms QKV=2.10s FFN=3.04s) eta=20:24:17 | 43.9K token/s | 
[epoch_0]_17931  loss=3.373152 |g|=0.372	lr=4.87e-04 | 68.9%@S15  T=1.74s(data=1.8ms QKV=2.10s FFN=3.04s) eta=20:51:31 | 44.0K token/s | 
[epoch_0]_17941  loss=3.324306 |g|=0.431	lr=4.87e-04 | 69.7%@S15  T=1.74s(data=1.6ms QKV=2.10s FFN=3.04s) eta=20:47:42 | 44.2K token/s | 
[epoch_0]_17951  loss=3.329311 |g|=0.386	lr=4.87e-04 | 70.6%@S15  T=1.72s(data=1.7ms QKV=2.10s FFN=3.04s) eta=20:33:43 | 44.4K token/s | 
[epoch_0]_17961  loss=3.410361 |g|=0.408	lr=4.87e-04 | 71.4%@S15  T=1.73s(data=1.8ms QKV=2.10s FFN=3.04s) eta=20:40:47 | 44.5K token/s | 
[epoch_0]_17971  loss=3.404060 |g|=0.388	lr=4.87e-04 | 72.2%@S15  T=1.74s(data=1.5ms QKV=2.10s FFN=3.04s) eta=20:45:20 | 44.7K token/s | 
[epoch_0]_17981  loss=3.287041 |g|=0.399	lr=4.87e-04 | 73.0%@S15  T=1.72s(data=1.7ms QKV=2.10s FFN=3.04s) eta=20:33:23 | 44.8K token/s | 
[epoch_0]_17991  loss=3.357269 |g|=0.384	lr=4.87e-04 | 73.8%@S15  T=1.77s(data=6.3ms QKV=2.10s FFN=3.04s) eta=21:07:42 | 44.9K token/s | 
[Fuyou] head="5" update algorithm=4 t=11.18s
[eval] 
	 Loss@"edu_fineweb1B"=3.370(4.5e-05) nBranch=1 nToken=6.31M best=3.3705(88) E2T=-0.000551 T=36.7531(0)s x=0
	#3.37047±0.0969 tps=172K(6.30784M) a=[3.18028,3.63337] T=36.7531(sec)
[Section@18000] layer[0-8] tasks=19(nPassBack=0) last_loss=3.37102(-0.0625939) N=(772,20832,20272 2375868)
[epoch_0]_18001  loss=3.318744 |g|=0.353	lr=4.87e-04 | 74.6%@S15  T=12.32s(data=2.0ms QKV=2.10s FFN=3.04s) eta=6d 03:15:36 | 43.0K token/s | 
[epoch_0]_18011  loss=3.342407 |g|=0.389	lr=4.86e-04 | 75.5%@S15  T=1.70s(data=1.7ms QKV=2.10s FFN=3.04s) eta=20:17:37 | 43.2K token/s | 
[epoch_0]_18021  loss=3.310325 |g|=0.376	lr=4.86e-04 | 76.3%@S15  T=1.68s(data=1.8ms QKV=2.10s FFN=3.04s) eta=20:01:39 | 43.5K token/s | 
[epoch_0]_18031  loss=3.334843 |g|=0.376	lr=4.86e-04 | 77.1%@S15  T=1.72s(data=1.8ms QKV=2.10s FFN=3.04s) eta=20:31:38 | 43.7K token/s | 
[epoch_0]_18041  loss=3.414807 |g|=0.401	lr=4.86e-04 | 77.9%@S15  T=1.74s(data=1.7ms QKV=2.10s FFN=3.04s) eta=20:44:12 | 43.9K token/s | 
[epoch_0]_18051  loss=3.440015 |g|=0.391	lr=4.86e-04 | 78.7%@S15  T=1.73s(data=1.8ms QKV=2.10s FFN=3.04s) eta=20:38:04 | 44.1K token/s | 
[epoch_0]_18061  loss=3.389893 |g|=0.409	lr=4.86e-04 | 79.6%@S15  T=1.72s(data=1.8ms QKV=2.10s FFN=3.04s) eta=20:28:41 | 44.3K token/s | 
[epoch_0]_18071  loss=3.391005 |g|=0.368	lr=4.86e-04 | 80.4%@S15  T=1.70s(data=1.6ms QKV=2.10s FFN=3.04s) eta=20:14:46 | 44.5K token/s | 
[epoch_0]_18081  loss=3.358510 |g|=0.393	lr=4.86e-04 | 81.2%@S15  T=1.73s(data=1.9ms QKV=2.10s FFN=3.04s) eta=20:41:46 | 44.6K token/s | 
[epoch_0]_18091  loss=3.370143 |g|=0.377	lr=4.85e-04 | 82.0%@S15  T=1.73s(data=1.6ms QKV=2.10s FFN=3.04s) eta=20:41:34 | 44.7K token/s | 
[Fuyou] head="0" update algorithm=4 t=10.00s
[Section@18100] layer[8-16] tasks=19(nPassBack=0) last_loss=3.38602(-0.0277166) N=(772,20944,20384 2389068)
[epoch_0]_18101  loss=3.333560 |g|=0.354	lr=4.85e-04 | 82.8%@S15  T=4.11s(data=1.7ms QKV=2.10s FFN=3.04s) eta=2d 00:57:25 | 43.5K token/s | 
[epoch_0]_18111  loss=3.310523 |g|=0.396	lr=4.85e-04 | 83.7%@S15  T=1.72s(data=1.6ms QKV=2.10s FFN=3.04s) eta=20:27:21 | 43.7K token/s | 
[epoch_0]_18121  loss=3.355016 |g|=0.391	lr=4.85e-04 | 84.5%@S15  T=1.72s(data=1.6ms QKV=2.10s FFN=3.04s) eta=20:31:04 | 43.9K token/s | 
[epoch_0]_18131  loss=3.326326 |g|=0.42	lr=4.85e-04 | 85.3%@S15  T=1.68s(data=1.9ms QKV=2.10s FFN=3.04s) eta=20:03:22 | 44.1K token/s | 
[epoch_0]_18141  loss=3.325571 |g|=0.374	lr=4.85e-04 | 86.1%@S15  T=1.73s(data=1.5ms QKV=2.10s FFN=3.04s) eta=20:35:26 | 44.3K token/s | 
[epoch_0]_18151  loss=3.384956 |g|=0.407	lr=4.85e-04 | 86.9%@S15  T=1.74s(data=1.6ms QKV=2.11s FFN=3.04s) eta=20:43:04 | 44.4K token/s | 
[epoch_0]_18161  loss=3.317731 |g|=0.386	lr=4.85e-04 | 87.8%@S15  T=1.72s(data=1.7ms QKV=2.10s FFN=3.04s) eta=20:28:56 | 44.6K token/s | 
[epoch_0]_18171  loss=3.346420 |g|=0.38	lr=4.84e-04 | 88.6%@S15  T=1.72s(data=1.5ms QKV=2.10s FFN=3.04s) eta=20:28:39 | 44.7K token/s | 
[epoch_0]_18181  loss=3.325413 |g|=0.379	lr=4.84e-04 | 89.4%@S15  T=1.77s(data=1.9ms QKV=2.10s FFN=3.04s) eta=21:04:10 | 44.8K token/s | 
[epoch_0]_18191  loss=3.341136 |g|=0.394	lr=4.84e-04 | 90.2%@S15  T=1.72s(data=1.7ms QKV=2.10s FFN=3.04s) eta=20:29:13 | 45.0K token/s | 
[Fuyou] head="1" update algorithm=4 t=9.33s
[eval] 
	 Loss@"edu_fineweb1B"=3.369(0.0016) nBranch=1 nToken=6.31M best=3.3705(89) E2T=0.00904 T=36.7576(0)s x=0
	#3.36888±0.0966 tps=172K(6.30784M) a=[3.18032,3.62922] T=36.7576(sec)
[Section@18200] layer[16-24] tasks=19(nPassBack=0) last_loss=3.35984(0.00245333) N=(772,21056,20496 2402268)
[epoch_0]_18201  loss=3.346098 |g|=0.357	lr=4.84e-04 | 91.0%@S15  T=11.63s(data=1.7ms QKV=2.10s FFN=3.04s) eta=5d 18:21:03 | 43.1K token/s | 
[epoch_0]_18211  loss=3.333068 |g|=0.375	lr=4.84e-04 | 91.8%@S15  T=1.69s(data=1.7ms QKV=2.10s FFN=3.04s) eta=20:06:20 | 43.3K token/s | 
[epoch_0]_18221  loss=3.355064 |g|=0.374	lr=4.84e-04 | 92.7%@S15  T=1.78s(data=6.4ms QKV=2.10s FFN=3.04s) eta=21:09:47 | 43.5K token/s | 
[epoch_0]_18231  loss=3.329913 |g|=0.365	lr=4.84e-04 | 93.5%@S15  T=1.76s(data=1.8ms QKV=2.11s FFN=3.04s) eta=20:56:29 | 43.6K token/s | 
[epoch_0]_18241  loss=3.337061 |g|=0.407	lr=4.84e-04 | 94.3%@S15  T=1.73s(data=1.7ms QKV=2.10s FFN=3.04s) eta=20:30:41 | 43.8K token/s | 
[epoch_0]_18251  loss=3.275872 |g|=0.41	lr=4.84e-04 | 95.1%@S15  T=1.74s(data=1.8ms QKV=2.10s FFN=3.04s) eta=20:37:10 | 44.0K token/s | 
[epoch_0]_18261  loss=3.346732 |g|=0.428	lr=4.83e-04 | 95.9%@S15  T=1.71s(data=1.5ms QKV=2.10s FFN=3.04s) eta=20:19:14 | 44.2K token/s | 
[epoch_0]_18271  loss=3.332725 |g|=0.367	lr=4.83e-04 | 96.8%@S15  T=1.76s(data=2.1ms QKV=2.10s FFN=3.04s) eta=20:57:30 | 44.3K token/s | 
[epoch_0]_18281  loss=3.259631 |g|=0.385	lr=4.83e-04 | 97.6%@S15  T=1.74s(data=1.6ms QKV=2.10s FFN=3.04s) eta=20:37:28 | 44.4K token/s | 
[epoch_0]_18291  loss=3.321700 |g|=0.388	lr=4.83e-04 | 98.4%@S15  T=1.77s(data=1.7ms QKV=2.10s FFN=3.04s) eta=21:00:49 | 44.5K token/s | 
[Fuyou] head="2" update algorithm=4 t=11.25s
[Section@18300] layer[24-32] tasks=19(nPassBack=0) last_loss=3.34423(0.0253031) N=(772,21168,20608 2415468)
[epoch_0]_18301  loss=3.389605 |g|=0.388	lr=4.83e-04 | 99.2%@S15  T=4.49s(data=1.9ms QKV=2.10s FFN=3.03s) eta=2d 05:14:27 | 43.2K token/s | 
[epoch_0]_18310  loss=3.372106 |g|=0.393	lr=4.83e-04 | 100.0%@S15  T=1.73s(data=1.7ms QKV=2.10s FFN=3.04s) eta=20:35:04 | 43.4K token/s | 
-------- End of shard_15@"./Datasets/edu_fineweb1B/edu_fineweb_train_000469.bin"-------- 
[shard-16]@"./Datasets/edu_fineweb1B/edu_fineweb_train_000470.bin": tokens=100(M) nShardSamples=1220(1562496) 
[epoch_0]_18311  loss=3.337447 |g|=0.405	lr=4.83e-04 | 0.0%@S16  T=2.31s(data=875.9ms QKV=2.10s FFN=3.04s) eta=1d 03:23:34 | 43.0K token/s | 
[epoch_0]_18321  loss=3.298859 |g|=0.4	lr=4.83e-04 | 0.9%@S16  T=1.68s(data=1.2ms QKV=2.10s FFN=3.04s) eta=19:57:46 | 43.3K token/s | 
[epoch_0]_18331  loss=3.358983 |g|=0.388	lr=4.83e-04 | 1.7%@S16  T=1.69s(data=1.3ms QKV=2.10s FFN=3.04s) eta=20:04:57 | 43.6K token/s | 
[epoch_0]_18341  loss=3.411918 |g|=0.464	lr=4.82e-04 | 2.5%@S16  T=1.69s(data=1.3ms QKV=2.10s FFN=3.04s) eta=20:02:50 | 43.8K token/s | 
[epoch_0]_18351  loss=3.333075 |g|=0.383	lr=4.82e-04 | 3.3%@S16  T=1.74s(data=1.2ms QKV=2.10s FFN=3.04s) eta=20:37:30 | 44.0K token/s | 
[epoch_0]_18361  loss=3.357585 |g|=0.431	lr=4.82e-04 | 4.1%@S16  T=1.70s(data=1.2ms QKV=2.10s FFN=3.04s) eta=20:11:10 | 44.2K token/s | 
[epoch_0]_18371  loss=3.387332 |g|=0.414	lr=4.82e-04 | 5.0%@S16  T=1.71s(data=1.2ms QKV=2.10s FFN=3.04s) eta=20:18:39 | 44.4K token/s | 
[epoch_0]_18381  loss=3.428689 |g|=0.39	lr=4.82e-04 | 5.8%@S16  T=1.72s(data=1.3ms QKV=2.10s FFN=3.04s) eta=20:26:16 | 44.5K token/s | 
[epoch_0]_18391  loss=3.377717 |g|=0.376	lr=4.82e-04 | 6.6%@S16  T=1.74s(data=1.5ms QKV=2.10s FFN=3.04s) eta=20:33:34 | 44.6K token/s | 
[Fuyou] head="3" update algorithm=4 t=11.40s
[eval] 
	 Loss@"edu_fineweb1B"=3.365(0.0039) nBranch=1 nToken=6.31M best=3.3689(90) E2T=-0.0209 T=36.7373(0)s x=0
	#3.36498±0.0969 tps=172K(6.30784M) a=[3.17696,3.63212] T=36.7373(sec)
[Section@18400] layer[32-40] tasks=19(nPassBack=0) last_loss=3.38587(-0.0352714) N=(772,21280,20720 2428668)
[epoch_0]_18401  loss=3.389286 |g|=0.363	lr=4.82e-04 | 7.4%@S16  T=12.06s(data=6.8ms QKV=2.10s FFN=3.04s) eta=5d 22:48:37 | 42.8K token/s | 
[epoch_0]_18411  loss=3.410801 |g|=0.399	lr=4.82e-04 | 8.2%@S16  T=1.70s(data=1.6ms QKV=2.10s FFN=3.04s) eta=20:08:32 | 43.0K token/s | 
[epoch_0]_18421  loss=3.415099 |g|=0.428	lr=4.81e-04 | 9.1%@S16  T=1.71s(data=1.5ms QKV=2.10s FFN=3.04s) eta=20:11:33 | 43.3K token/s | 
[epoch_0]_18431  loss=3.396814 |g|=0.372	lr=4.81e-04 | 9.9%@S16  T=1.71s(data=1.4ms QKV=2.10s FFN=3.04s) eta=20:12:30 | 43.5K token/s | 
[epoch_0]_18441  loss=3.392176 |g|=0.394	lr=4.81e-04 | 10.7%@S16  T=1.68s(data=1.6ms QKV=2.10s FFN=3.04s) eta=19:53:58 | 43.8K token/s | 
[epoch_0]_18451  loss=3.372075 |g|=0.388	lr=4.81e-04 | 11.5%@S16  T=1.72s(data=1.4ms QKV=2.10s FFN=3.04s) eta=20:23:03 | 44.0K token/s | 
[epoch_0]_18461  loss=3.379746 |g|=0.38	lr=4.81e-04 | 12.3%@S16  T=1.71s(data=1.7ms QKV=2.10s FFN=3.04s) eta=20:16:18 | 44.2K token/s | 
[epoch_0]_18471  loss=3.371235 |g|=0.369	lr=4.81e-04 | 13.1%@S16  T=1.70s(data=1.6ms QKV=2.10s FFN=3.04s) eta=20:07:40 | 44.3K token/s | 
[epoch_0]_18481  loss=3.404409 |g|=0.38	lr=4.81e-04 | 14.0%@S16  T=1.69s(data=1.6ms QKV=2.10s FFN=3.04s) eta=19:58:18 | 44.6K token/s | 
[epoch_0]_18491  loss=3.412856 |g|=0.394	lr=4.81e-04 | 14.8%@S16  T=1.72s(data=1.3ms QKV=2.10s FFN=3.04s) eta=20:18:44 | 44.7K token/s | 
[Fuyou] head="4" update algorithm=4 t=12.74s
[Section@18500] layer[40-48] tasks=19(nPassBack=0) last_loss=3.32124(0.0608499) N=(772,21392,20832 2441868)
[epoch_0]_18501  loss=3.374417 |g|=0.375	lr=4.80e-04 | 15.6%@S16  T=3.93s(data=1.5ms QKV=2.10s FFN=3.04s) eta=1d 22:25:37 | 43.5K token/s | 
[epoch_0]_18511  loss=3.318181 |g|=0.414	lr=4.80e-04 | 16.4%@S16  T=1.70s(data=1.9ms QKV=2.10s FFN=3.04s) eta=20:02:11 | 43.8K token/s | 
[epoch_0]_18521  loss=3.349302 |g|=0.381	lr=4.80e-04 | 17.2%@S16  T=1.71s(data=1.6ms QKV=2.10s FFN=3.04s) eta=20:11:51 | 44.0K token/s | 
[epoch_0]_18531  loss=3.399060 |g|=0.399	lr=4.80e-04 | 18.1%@S16  T=1.73s(data=1.8ms QKV=2.10s FFN=3.04s) eta=20:28:49 | 44.1K token/s | 
[epoch_0]_18541  loss=3.389652 |g|=0.445	lr=4.80e-04 | 18.9%@S16  T=1.74s(data=1.6ms QKV=2.10s FFN=3.04s) eta=20:32:30 | 44.3K token/s | 
[epoch_0]_18551  loss=3.351742 |g|=0.421	lr=4.80e-04 | 19.7%@S16  T=1.71s(data=1.6ms QKV=2.10s FFN=3.04s) eta=20:07:24 | 44.5K token/s | 
[epoch_0]_18561  loss=3.380343 |g|=0.409	lr=4.80e-04 | 20.5%@S16  T=1.69s(data=1.5ms QKV=2.10s FFN=3.04s) eta=19:58:19 | 44.7K token/s | 
[epoch_0]_18571  loss=3.370451 |g|=0.402	lr=4.80e-04 | 21.3%@S16  T=1.71s(data=1.6ms QKV=2.10s FFN=3.04s) eta=20:13:02 | 44.8K token/s | 
[epoch_0]_18581  loss=3.296278 |g|=0.416	lr=4.79e-04 | 22.2%@S16  T=1.72s(data=1.6ms QKV=2.10s FFN=3.04s) eta=20:15:41 | 45.0K token/s | 
[epoch_0]_18591  loss=3.396215 |g|=0.387	lr=4.79e-04 | 23.0%@S16  T=1.73s(data=1.5ms QKV=2.10s FFN=3.04s) eta=20:22:46 | 45.1K token/s | 
[Fuyou] head="5" update algorithm=4 t=10.08s
[eval] 
	 Loss@"edu_fineweb1B"=3.364(0.0011) nBranch=1 nToken=6.31M best=3.3650(91) E2T=-0.000734 T=36.7679(0)s x=0
	#3.3639±0.0969 tps=172K(6.30784M) a=[3.17424,3.63182] T=36.7679(sec)
[Section@18600] layer[0-8] tasks=19(nPassBack=0) last_loss=3.36464(0.00638318) N=(772,21504,20944 2455068)
[epoch_0]_18601  loss=3.353286 |g|=0.374	lr=4.79e-04 | 23.8%@S16  T=12.03s(data=2.4ms QKV=2.10s FFN=3.04s) eta=5d 21:51:05 | 43.2K token/s | 
[epoch_0]_18611  loss=3.380486 |g|=0.392	lr=4.79e-04 | 24.6%@S16  T=1.72s(data=1.6ms QKV=2.10s FFN=3.04s) eta=20:18:14 | 43.4K token/s | 
[epoch_0]_18621  loss=3.304224 |g|=0.438	lr=4.79e-04 | 25.4%@S16  T=1.71s(data=2.4ms QKV=2.10s FFN=3.04s) eta=20:08:23 | 43.6K token/s | 
[epoch_0]_18631  loss=3.364623 |g|=0.393	lr=4.79e-04 | 26.3%@S16  T=1.70s(data=1.5ms QKV=2.10s FFN=3.04s) eta=19:59:26 | 43.8K token/s | 
[epoch_0]_18641  loss=3.385053 |g|=0.376	lr=4.79e-04 | 27.1%@S16  T=1.68s(data=1.7ms QKV=2.10s FFN=3.04s) eta=19:43:38 | 44.1K token/s | 
[epoch_0]_18651  loss=3.245005 |g|=0.394	lr=4.79e-04 | 27.9%@S16  T=1.69s(data=1.5ms QKV=2.10s FFN=3.04s) eta=19:51:31 | 44.3K token/s | 
[epoch_0]_18661  loss=3.373013 |g|=0.387	lr=4.78e-04 | 28.7%@S16  T=1.68s(data=1.5ms QKV=2.10s FFN=3.04s) eta=19:49:10 | 44.5K token/s | 
[epoch_0]_18671  loss=3.386713 |g|=0.386	lr=4.78e-04 | 29.5%@S16  T=1.69s(data=1.8ms QKV=2.10s FFN=3.04s) eta=19:56:07 | 44.7K token/s | 
[epoch_0]_18681  loss=3.363692 |g|=0.405	lr=4.78e-04 | 30.4%@S16  T=1.70s(data=1.8ms QKV=2.10s FFN=3.04s) eta=20:01:18 | 44.9K token/s | 
[epoch_0]_18691  loss=3.355038 |g|=0.375	lr=4.78e-04 | 31.2%@S16  T=1.70s(data=1.6ms QKV=2.10s FFN=3.04s) eta=20:01:22 | 45.1K token/s | 
[Fuyou] head="0" update algorithm=4 t=9.65s
[Section@18700] layer[8-16] tasks=19(nPassBack=0) last_loss=3.34254(0.0434742) N=(772,21616,21056 2468268)
[epoch_0]_18701  loss=3.372011 |g|=0.376	lr=4.78e-04 | 32.0%@S16  T=4.70s(data=2.9ms QKV=2.10s FFN=3.04s) eta=2d 07:15:55 | 43.7K token/s | 
[epoch_0]_18711  loss=3.353244 |g|=0.371	lr=4.78e-04 | 32.8%@S16  T=1.71s(data=2.9ms QKV=2.10s FFN=3.04s) eta=20:05:28 | 43.9K token/s | 
[epoch_0]_18721  loss=3.309720 |g|=0.389	lr=4.78e-04 | 33.6%@S16  T=1.72s(data=1.5ms QKV=2.10s FFN=3.04s) eta=20:11:31 | 44.1K token/s | 
[epoch_0]_18731  loss=3.394682 |g|=0.383	lr=4.78e-04 | 34.4%@S16  T=1.70s(data=1.8ms QKV=2.10s FFN=3.04s) eta=19:56:34 | 44.3K token/s | 
[epoch_0]_18741  loss=3.390103 |g|=0.396	lr=4.77e-04 | 35.3%@S16  T=1.70s(data=1.6ms QKV=2.10s FFN=3.04s) eta=19:59:54 | 44.5K token/s | 
[epoch_0]_18751  loss=3.352651 |g|=0.39	lr=4.77e-04 | 36.1%@S16  T=1.74s(data=1.8ms QKV=2.10s FFN=3.04s) eta=20:24:45 | 44.6K token/s | 
[epoch_0]_18761  loss=3.306957 |g|=0.39	lr=4.77e-04 | 36.9%@S16  T=1.71s(data=2.1ms QKV=2.10s FFN=3.04s) eta=20:02:47 | 44.8K token/s | 
[epoch_0]_18771  loss=3.268725 |g|=0.398	lr=4.77e-04 | 37.7%@S16  T=1.73s(data=1.7ms QKV=2.10s FFN=3.04s) eta=20:16:58 | 44.9K token/s | 
[epoch_0]_18781  loss=3.272060 |g|=0.392	lr=4.77e-04 | 38.5%@S16  T=1.72s(data=1.7ms QKV=2.10s FFN=3.04s) eta=20:09:56 | 45.1K token/s | 
[epoch_0]_18791  loss=3.265510 |g|=0.373	lr=4.77e-04 | 39.4%@S16  T=1.73s(data=1.5ms QKV=2.10s FFN=3.04s) eta=20:14:58 | 45.2K token/s | 
[Fuyou] head="1" update algorithm=4 t=10.65s
[eval] 
	 Loss@"edu_fineweb1B"=3.362(0.0023) nBranch=1 nToken=6.31M best=3.3639(92) E2T=-0.0218 T=36.7316(0)s x=0
	#3.36163±0.0983 tps=172K(6.30784M) a=[3.16632,3.63122] T=36.7316(sec)
[Section@18800] layer[16-24] tasks=19(nPassBack=0) last_loss=3.38342(-0.0235765) N=(772,21728,21168 2481468)
[epoch_0]_18801  loss=3.395543 |g|=0.373	lr=4.77e-04 | 40.2%@S16  T=11.95s(data=1.9ms QKV=2.10s FFN=3.04s) eta=5d 20:12:02 | 43.3K token/s | 
[epoch_0]_18811  loss=3.282807 |g|=0.383	lr=4.77e-04 | 41.0%@S16  T=1.74s(data=1.9ms QKV=2.10s FFN=3.04s) eta=20:23:35 | 43.5K token/s | 
[epoch_0]_18821  loss=3.366132 |g|=0.442	lr=4.76e-04 | 41.8%@S16  T=1.73s(data=1.7ms QKV=2.10s FFN=3.04s) eta=20:19:55 | 43.6K token/s | 
[epoch_0]_18831  loss=3.341184 |g|=0.381	lr=4.76e-04 | 42.6%@S16  T=1.75s(data=1.7ms QKV=2.10s FFN=3.04s) eta=20:30:02 | 43.8K token/s | 
[epoch_0]_18841  loss=3.367256 |g|=0.383	lr=4.76e-04 | 43.5%@S16  T=1.72s(data=1.7ms QKV=2.10s FFN=3.04s) eta=20:12:26 | 44.0K token/s | 
[epoch_0]_18851  loss=3.363322 |g|=0.386	lr=4.76e-04 | 44.3%@S16  T=1.72s(data=1.8ms QKV=2.10s FFN=3.04s) eta=20:11:23 | 44.2K token/s | 
[epoch_0]_18861  loss=3.408667 |g|=0.414	lr=4.76e-04 | 45.1%@S16  T=1.73s(data=1.5ms QKV=2.10s FFN=3.04s) eta=20:15:30 | 44.3K token/s | 
[epoch_0]_18871  loss=3.347356 |g|=0.399	lr=4.76e-04 | 45.9%@S16  T=1.69s(data=1.6ms QKV=2.10s FFN=3.04s) eta=19:48:49 | 44.5K token/s | 
[epoch_0]_18881  loss=3.380526 |g|=0.408	lr=4.76e-04 | 46.7%@S16  T=1.68s(data=2.2ms QKV=2.10s FFN=3.04s) eta=19:43:14 | 44.7K token/s | 
[epoch_0]_18891  loss=3.363666 |g|=0.416	lr=4.76e-04 | 47.6%@S16  T=1.70s(data=1.5ms QKV=2.10s FFN=3.04s) eta=19:51:56 | 44.9K token/s | 
[Fuyou] head="2" update algorithm=4 t=11.12s
[Section@18900] layer[24-32] tasks=19(nPassBack=0) last_loss=3.3935(-0.049264) N=(772,21840,21280 2494668)
[epoch_0]_18901  loss=3.433958 |g|=0.407	lr=4.75e-04 | 48.4%@S16  T=4.21s(data=1.9ms QKV=2.09s FFN=3.04s) eta=2d 01:13:43 | 43.6K token/s | 
[epoch_0]_18911  loss=3.382127 |g|=0.39	lr=4.75e-04 | 49.2%@S16  T=1.69s(data=1.5ms QKV=2.10s FFN=3.04s) eta=19:46:54 | 43.9K token/s | 
[epoch_0]_18921  loss=3.383324 |g|=0.397	lr=4.75e-04 | 50.0%@S16  T=1.76s(data=1.6ms QKV=2.10s FFN=3.04s) eta=20:37:58 | 44.0K token/s | 
[epoch_0]_18931  loss=3.317699 |g|=0.393	lr=4.75e-04 | 50.8%@S16  T=1.70s(data=1.7ms QKV=2.10s FFN=3.04s) eta=19:49:27 | 44.2K token/s | 
[epoch_0]_18941  loss=3.284091 |g|=0.405	lr=4.75e-04 | 51.7%@S16  T=1.71s(data=1.9ms QKV=2.10s FFN=3.04s) eta=19:57:22 | 44.4K token/s | 
[epoch_0]_18951  loss=3.313402 |g|=0.375	lr=4.75e-04 | 52.5%@S16  T=1.73s(data=1.8ms QKV=2.10s FFN=3.05s) eta=20:16:48 | 44.6K token/s | 
[epoch_0]_18961  loss=3.296020 |g|=0.408	lr=4.75e-04 | 53.3%@S16  T=1.74s(data=1.7ms QKV=2.10s FFN=3.04s) eta=20:17:30 | 44.7K token/s | 
[epoch_0]_18971  loss=3.323978 |g|=0.456	lr=4.75e-04 | 54.1%@S16  T=1.69s(data=1.9ms QKV=2.10s FFN=3.04s) eta=19:43:55 | 44.9K token/s | 
[epoch_0]_18981  loss=3.334930 |g|=0.421	lr=4.74e-04 | 54.9%@S16  T=1.70s(data=1.7ms QKV=2.10s FFN=3.04s) eta=19:50:41 | 45.0K token/s | 
[epoch_0]_18991  loss=3.391560 |g|=0.387	lr=4.74e-04 | 55.7%@S16  T=1.69s(data=1.5ms QKV=2.10s FFN=3.04s) eta=19:47:02 | 45.2K token/s | 
[Fuyou] head="3" update algorithm=4 t=11.94s
[eval] 
	 Loss@"edu_fineweb1B"=3.360(0.0021) nBranch=1 nToken=6.31M best=3.3616(93) E2T=-0.0145 T=36.7224(0)s x=0
	#3.35955±0.0974 tps=172K(6.30784M) a=[3.17026,3.62963] T=36.7224(sec)
[Section@19000] layer[32-40] tasks=19(nPassBack=0) last_loss=3.37402(0.0118477) N=(772,21952,21392 2507868)
[epoch_0]_19001  loss=3.277534 |g|=0.398	lr=4.74e-04 | 56.6%@S16  T=11.99s(data=2.6ms QKV=2.10s FFN=3.04s) eta=5d 19:56:20 | 43.3K token/s | 
[epoch_0]_19011  loss=3.363917 |g|=0.397	lr=4.74e-04 | 57.4%@S16  T=1.73s(data=1.8ms QKV=2.10s FFN=3.04s) eta=20:10:34 | 43.5K token/s | 
[epoch_0]_19021  loss=3.376501 |g|=0.391	lr=4.74e-04 | 58.2%@S16  T=1.74s(data=1.7ms QKV=2.10s FFN=3.04s) eta=20:20:21 | 43.7K token/s | 
[epoch_0]_19031  loss=3.380824 |g|=0.377	lr=4.74e-04 | 59.0%@S16  T=1.69s(data=1.9ms QKV=2.10s FFN=3.04s) eta=19:43:16 | 43.9K token/s | 
[epoch_0]_19041  loss=3.354963 |g|=0.385	lr=4.74e-04 | 59.8%@S16  T=1.69s(data=2.2ms QKV=2.10s FFN=3.04s) eta=19:39:27 | 44.1K token/s | 
[epoch_0]_19051  loss=3.368572 |g|=0.381	lr=4.74e-04 | 60.7%@S16  T=1.70s(data=1.9ms QKV=2.10s FFN=3.04s) eta=19:50:16 | 44.3K token/s | 
[epoch_0]_19061  loss=3.399717 |g|=0.418	lr=4.73e-04 | 61.5%@S16  T=1.70s(data=1.8ms QKV=2.10s FFN=3.04s) eta=19:48:00 | 44.5K token/s | 
[epoch_0]_19071  loss=3.315075 |g|=0.396	lr=4.73e-04 | 62.3%@S16  T=1.73s(data=1.6ms QKV=2.10s FFN=3.04s) eta=20:08:59 | 44.7K token/s | 
[epoch_0]_19081  loss=3.345045 |g|=0.382	lr=4.73e-04 | 63.1%@S16  T=1.74s(data=1.7ms QKV=2.10s FFN=3.04s) eta=20:18:36 | 44.8K token/s | 
[epoch_0]_19091  loss=3.381796 |g|=0.385	lr=4.73e-04 | 63.9%@S16  T=1.69s(data=1.9ms QKV=2.10s FFN=3.04s) eta=19:44:07 | 45.0K token/s | 
[Fuyou] head="4" update algorithm=4 t=11.94s
[Section@19100] layer[40-48] tasks=19(nPassBack=0) last_loss=3.33229(-0.0110579) N=(772,22064,21504 2521068)
[epoch_0]_19101  loss=3.338172 |g|=0.375	lr=4.73e-04 | 64.8%@S16  T=3.87s(data=1.8ms QKV=2.09s FFN=3.04s) eta=1d 21:07:31 | 43.8K token/s | 
[epoch_0]_19111  loss=3.270267 |g|=0.418	lr=4.73e-04 | 65.6%@S16  T=1.72s(data=1.7ms QKV=2.10s FFN=3.04s) eta=19:58:25 | 44.0K token/s | 
[epoch_0]_19121  loss=3.355443 |g|=0.412	lr=4.73e-04 | 66.4%@S16  T=1.73s(data=1.6ms QKV=2.10s FFN=3.04s) eta=20:06:33 | 44.2K token/s | 
[epoch_0]_19131  loss=3.342479 |g|=0.406	lr=4.73e-04 | 67.2%@S16  T=1.75s(data=2.0ms QKV=2.10s FFN=3.04s) eta=20:19:11 | 44.3K token/s | 
[epoch_0]_19141  loss=3.402182 |g|=0.398	lr=4.72e-04 | 68.0%@S16  T=1.72s(data=1.6ms QKV=2.10s FFN=3.04s) eta=20:01:41 | 44.5K token/s | 
[epoch_0]_19151  loss=3.340232 |g|=0.396	lr=4.72e-04 | 68.9%@S16  T=1.73s(data=1.6ms QKV=2.10s FFN=3.04s) eta=20:07:38 | 44.6K token/s | 
[epoch_0]_19161  loss=3.391365 |g|=0.406	lr=4.72e-04 | 69.7%@S16  T=1.74s(data=1.7ms QKV=2.10s FFN=3.04s) eta=20:14:15 | 44.7K token/s | 
[epoch_0]_19171  loss=3.293279 |g|=0.364	lr=4.72e-04 | 70.5%@S16  T=1.73s(data=1.7ms QKV=2.10s FFN=3.04s) eta=20:04:01 | 44.9K token/s | 
[epoch_0]_19181  loss=3.325314 |g|=0.423	lr=4.72e-04 | 71.3%@S16  T=1.74s(data=1.8ms QKV=2.10s FFN=3.04s) eta=20:12:25 | 45.0K token/s | 
[epoch_0]_19191  loss=3.393797 |g|=0.382	lr=4.72e-04 | 72.1%@S16  T=1.74s(data=1.8ms QKV=2.10s FFN=3.04s) eta=20:14:11 | 45.1K token/s | 
[Fuyou] head="5" update algorithm=4 t=10.65s
[eval] 
	 Loss@"edu_fineweb1B"=3.358(0.0016) nBranch=1 nToken=6.31M best=3.3595(94) E2T=0.0232 T=36.7301(0)s x=0
	#3.3579±0.0971 tps=172K(6.30784M) a=[3.1663,3.62807] T=36.7301(sec)
[Section@19200] layer[0-8] tasks=19(nPassBack=0) last_loss=3.33466(0.0299811) N=(772,22176,21616 2534268)
[epoch_0]_19201  loss=3.339328 |g|=0.379	lr=4.72e-04 | 73.0%@S16  T=12.08s(data=2.2ms QKV=2.10s FFN=3.04s) eta=5d 20:19:47 | 43.2K token/s | 
[epoch_0]_19211  loss=3.336285 |g|=0.405	lr=4.72e-04 | 73.8%@S16  T=1.73s(data=1.7ms QKV=2.10s FFN=3.04s) eta=20:05:24 | 43.4K token/s | 
[epoch_0]_19221  loss=3.357409 |g|=0.385	lr=4.71e-04 | 74.6%@S16  T=1.74s(data=1.6ms QKV=2.10s FFN=3.04s) eta=20:15:29 | 43.6K token/s | 
[epoch_0]_19231  loss=3.373259 |g|=0.398	lr=4.71e-04 | 75.4%@S16  T=1.70s(data=1.6ms QKV=2.10s FFN=3.04s) eta=19:45:38 | 43.8K token/s | 
[epoch_0]_19241  loss=3.396146 |g|=0.375	lr=4.71e-04 | 76.2%@S16  T=1.73s(data=1.5ms QKV=2.10s FFN=3.04s) eta=20:07:18 | 44.0K token/s | 
[epoch_0]_19251  loss=3.370776 |g|=0.409	lr=4.71e-04 | 77.0%@S16  T=1.73s(data=1.9ms QKV=2.10s FFN=3.04s) eta=20:02:44 | 44.1K token/s | 
[epoch_0]_19261  loss=3.349309 |g|=0.404	lr=4.71e-04 | 77.9%@S16  T=1.74s(data=1.6ms QKV=2.10s FFN=3.04s) eta=20:11:20 | 44.3K token/s | 
[epoch_0]_19271  loss=3.350082 |g|=0.397	lr=4.71e-04 | 78.7%@S16  T=1.71s(data=1.7ms QKV=2.10s FFN=3.04s) eta=19:52:38 | 44.5K token/s | 
[epoch_0]_19281  loss=3.306963 |g|=0.418	lr=4.71e-04 | 79.5%@S16  T=1.69s(data=1.5ms QKV=2.10s FFN=3.04s) eta=19:37:42 | 44.7K token/s | 
[epoch_0]_19291  loss=3.404305 |g|=0.402	lr=4.70e-04 | 80.3%@S16  T=1.69s(data=2.0ms QKV=2.10s FFN=3.04s) eta=19:38:54 | 44.8K token/s | 
[Fuyou] head="0" update algorithm=4 t=9.47s
[Section@19300] layer[8-16] tasks=19(nPassBack=0) last_loss=3.31071(0.0318296) N=(772,22288,21728 2547468)
[epoch_0]_19301  loss=3.408355 |g|=0.356	lr=4.70e-04 | 81.1%@S16  T=4.32s(data=1.8ms QKV=2.10s FFN=3.03s) eta=2d 02:05:35 | 43.5K token/s | 
[epoch_0]_19311  loss=3.246696 |g|=0.382	lr=4.70e-04 | 82.0%@S16  T=1.69s(data=1.6ms QKV=2.10s FFN=3.04s) eta=19:36:35 | 43.8K token/s | 
[epoch_0]_19321  loss=3.332018 |g|=0.375	lr=4.70e-04 | 82.8%@S16  T=1.73s(data=1.6ms QKV=2.10s FFN=3.04s) eta=20:01:28 | 44.0K token/s | 
[epoch_0]_19331  loss=3.371531 |g|=0.399	lr=4.70e-04 | 83.6%@S16  T=1.72s(data=1.7ms QKV=2.10s FFN=3.04s) eta=19:54:59 | 44.2K token/s | 
[epoch_0]_19341  loss=3.389530 |g|=0.405	lr=4.70e-04 | 84.4%@S16  T=1.69s(data=1.7ms QKV=2.10s FFN=3.04s) eta=19:35:26 | 44.4K token/s | 
[epoch_0]_19351  loss=3.357306 |g|=0.384	lr=4.70e-04 | 85.2%@S16  T=1.69s(data=2.0ms QKV=2.10s FFN=3.04s) eta=19:36:07 | 44.6K token/s | 
[epoch_0]_19361  loss=3.314862 |g|=0.38	lr=4.70e-04 | 86.1%@S16  T=1.69s(data=2.0ms QKV=2.10s FFN=3.04s) eta=19:35:53 | 44.8K token/s | 
[epoch_0]_19371  loss=3.364590 |g|=0.394	lr=4.69e-04 | 86.9%@S16  T=1.71s(data=2.0ms QKV=2.10s FFN=3.04s) eta=19:44:54 | 44.9K token/s | 
[epoch_0]_19381  loss=3.361677 |g|=0.387	lr=4.69e-04 | 87.7%@S16  T=1.72s(data=1.5ms QKV=2.10s FFN=3.04s) eta=19:56:44 | 45.1K token/s | 
[epoch_0]_19391  loss=3.342721 |g|=0.391	lr=4.69e-04 | 88.5%@S16  T=1.71s(data=1.8ms QKV=2.10s FFN=3.04s) eta=19:47:36 | 45.2K token/s | 
[Fuyou] head="1" update algorithm=4 t=9.06s
[eval] 
	 Loss@"edu_fineweb1B"=3.357(0.00088) nBranch=1 nToken=6.31M best=3.3579(95) E2T=0.058 T=36.7862(0)s x=0
	#3.35703±0.0972 tps=171K(6.30784M) a=[3.16407,3.63035] T=36.7862(sec)
[Section@19400] layer[16-24] tasks=19(nPassBack=0) last_loss=3.29901(0.0844061) N=(772,22400,21840 2560668)
[epoch_0]_19401  loss=3.283258 |g|=0.366	lr=4.69e-04 | 89.3%@S16  T=12.11s(data=1.9ms QKV=2.10s FFN=3.04s) eta=5d 20:05:42 | 43.3K token/s | 
[epoch_0]_19411  loss=3.384573 |g|=0.422	lr=4.69e-04 | 90.2%@S16  T=1.69s(data=1.7ms QKV=2.10s FFN=3.04s) eta=19:32:49 | 43.5K token/s | 
[epoch_0]_19421  loss=3.283236 |g|=0.389	lr=4.69e-04 | 91.0%@S16  T=1.71s(data=1.8ms QKV=2.10s FFN=3.04s) eta=19:48:19 | 43.7K token/s | 
[epoch_0]_19431  loss=3.251727 |g|=0.393	lr=4.69e-04 | 91.8%@S16  T=1.68s(data=1.8ms QKV=2.10s FFN=3.04s) eta=19:27:23 | 44.0K token/s | 
[epoch_0]_19441  loss=3.340662 |g|=0.409	lr=4.69e-04 | 92.6%@S16  T=1.70s(data=1.6ms QKV=2.10s FFN=3.04s) eta=19:41:49 | 44.2K token/s | 
[epoch_0]_19451  loss=3.272884 |g|=0.392	lr=4.68e-04 | 93.4%@S16  T=1.74s(data=1.8ms QKV=2.10s FFN=3.04s) eta=20:04:41 | 44.3K token/s | 
[epoch_0]_19461  loss=3.363684 |g|=0.384	lr=4.68e-04 | 94.3%@S16  T=1.74s(data=1.8ms QKV=2.10s FFN=3.04s) eta=20:03:06 | 44.5K token/s | 
[epoch_0]_19471  loss=3.450838 |g|=0.424	lr=4.68e-04 | 95.1%@S16  T=1.74s(data=2.0ms QKV=2.10s FFN=3.04s) eta=20:04:00 | 44.6K token/s | 
[epoch_0]_19481  loss=3.374023 |g|=0.398	lr=4.68e-04 | 95.9%@S16  T=1.76s(data=1.6ms QKV=2.10s FFN=3.04s) eta=20:15:29 | 44.7K token/s | 
[epoch_0]_19491  loss=3.281177 |g|=0.394	lr=4.68e-04 | 96.7%@S16  T=1.74s(data=1.6ms QKV=2.10s FFN=3.04s) eta=20:04:40 | 44.8K token/s | 
[Fuyou] head="2" update algorithm=4 t=11.86s
[Section@19500] layer[24-32] tasks=19(nPassBack=0) last_loss=3.36884(0.0246618) N=(772,22512,21952 2573868)
[epoch_0]_19501  loss=3.362300 |g|=0.373	lr=4.68e-04 | 97.5%@S16  T=4.06s(data=1.7ms QKV=2.10s FFN=3.03s) eta=1d 22:48:51 | 43.6K token/s | 
[epoch_0]_19511  loss=3.320110 |g|=0.376	lr=4.68e-04 | 98.3%@S16  T=1.73s(data=1.6ms QKV=2.10s FFN=3.04s) eta=19:55:14 | 43.8K token/s | 
[epoch_0]_19521  loss=3.319731 |g|=0.379	lr=4.68e-04 | 99.2%@S16  T=1.73s(data=1.6ms QKV=2.10s FFN=3.04s) eta=19:57:58 | 44.0K token/s | 
[epoch_0]_19531  loss=3.360252 |g|=0.381	lr=4.67e-04 | 100.0%@S16  T=1.75s(data=2.0ms QKV=2.10s FFN=3.04s) eta=20:12:08 | 44.1K token/s | 
-------- End of shard_16@"./Datasets/edu_fineweb1B/edu_fineweb_train_000470.bin"-------- 
[shard-17]@"./Datasets/edu_fineweb1B/edu_fineweb_train_000471.bin": tokens=100(M) nShardSamples=1220(1660152) 
[epoch_0]_19541  loss=3.353171 |g|=0.382	lr=4.67e-04 | 0.8%@S17  T=1.73s(data=1.2ms QKV=2.10s FFN=3.04s) eta=19:55:08 | 44.3K token/s | 
[epoch_0]_19551  loss=3.310107 |g|=0.407	lr=4.67e-04 | 1.6%@S17  T=1.72s(data=1.4ms QKV=2.10s FFN=3.04s) eta=19:47:03 | 44.4K token/s | 
[epoch_0]_19561  loss=3.372041 |g|=0.409	lr=4.67e-04 | 2.4%@S17  T=1.72s(data=1.3ms QKV=2.10s FFN=3.04s) eta=19:50:18 | 44.6K token/s | 
[epoch_0]_19571  loss=3.311911 |g|=0.374	lr=4.67e-04 | 3.3%@S17  T=1.73s(data=1.4ms QKV=2.10s FFN=3.04s) eta=19:52:32 | 44.7K token/s | 
[epoch_0]_19581  loss=3.334385 |g|=0.385	lr=4.67e-04 | 4.1%@S17  T=1.74s(data=1.3ms QKV=2.10s FFN=3.04s) eta=19:58:57 | 44.9K token/s | 
[epoch_0]_19591  loss=3.338456 |g|=0.411	lr=4.67e-04 | 4.9%@S17  T=1.70s(data=1.3ms QKV=2.10s FFN=3.04s) eta=19:33:34 | 45.0K token/s | 
[Fuyou] head="3" update algorithm=4 t=11.31s
[eval] 
	 Loss@"edu_fineweb1B"=3.351(0.0058) nBranch=1 nToken=6.31M best=3.3570(96) E2T=-0.0466 T=36.7366(0)s x=0
	#3.35118±0.0969 tps=172K(6.30784M) a=[3.16283,3.62252] T=36.7366(sec)
[Section@19600] layer[32-40] tasks=19(nPassBack=0) last_loss=3.39775(-0.0237334) N=(772,22624,22064 2587068)
[epoch_0]_19601  loss=3.381317 |g|=0.367	lr=4.67e-04 | 5.7%@S17  T=11.98s(data=1.9ms QKV=2.10s FFN=3.04s) eta=5d 17:55:06 | 43.1K token/s | 
[epoch_0]_19611  loss=3.297351 |g|=0.39	lr=4.66e-04 | 6.5%@S17  T=1.73s(data=1.5ms QKV=2.10s FFN=3.04s) eta=19:52:12 | 43.3K token/s | 
[epoch_0]_19621  loss=3.358851 |g|=0.38	lr=4.66e-04 | 7.4%@S17  T=1.75s(data=1.7ms QKV=2.10s FFN=3.04s) eta=20:05:45 | 43.5K token/s | 
[epoch_0]_19631  loss=3.354916 |g|=0.389	lr=4.66e-04 | 8.2%@S17  T=1.76s(data=6.8ms QKV=2.10s FFN=3.04s) eta=20:16:13 | 43.7K token/s | 
[epoch_0]_19641  loss=3.337529 |g|=0.382	lr=4.66e-04 | 9.0%@S17  T=1.72s(data=1.3ms QKV=2.10s FFN=3.04s) eta=19:44:43 | 43.9K token/s | 
[epoch_0]_19651  loss=3.316680 |g|=0.371	lr=4.66e-04 | 9.8%@S17  T=1.70s(data=1.3ms QKV=2.10s FFN=3.04s) eta=19:34:25 | 44.1K token/s | 
[epoch_0]_19661  loss=3.343930 |g|=0.388	lr=4.66e-04 | 10.6%@S17  T=1.73s(data=1.4ms QKV=2.10s FFN=3.04s) eta=19:53:09 | 44.2K token/s | 
[epoch_0]_19671  loss=3.245629 |g|=0.384	lr=4.66e-04 | 11.5%@S17  T=1.74s(data=1.4ms QKV=2.10s FFN=3.04s) eta=19:59:39 | 44.4K token/s | 
[epoch_0]_19681  loss=3.414071 |g|=0.375	lr=4.65e-04 | 12.3%@S17  T=1.74s(data=1.6ms QKV=2.10s FFN=3.04s) eta=19:58:30 | 44.5K token/s | 
[epoch_0]_19691  loss=3.377374 |g|=0.397	lr=4.65e-04 | 13.1%@S17  T=1.73s(data=1.6ms QKV=2.10s FFN=3.04s) eta=19:54:09 | 44.7K token/s | 
[Fuyou] head="4" update algorithm=4 t=11.10s
[Section@19700] layer[40-48] tasks=19(nPassBack=0) last_loss=3.35641(-0.0241117) N=(772,22736,22176 2600268)
[epoch_0]_19701  loss=3.414723 |g|=0.388	lr=4.65e-04 | 13.9%@S17  T=3.75s(data=1.7ms QKV=2.10s FFN=3.03s) eta=1d 19:02:48 | 43.5K token/s | 
[epoch_0]_19711  loss=3.336910 |g|=0.404	lr=4.65e-04 | 14.7%@S17  T=1.75s(data=1.6ms QKV=2.10s FFN=3.04s) eta=20:02:05 | 43.7K token/s | 
[epoch_0]_19721  loss=3.352203 |g|=0.408	lr=4.65e-04 | 15.5%@S17  T=1.72s(data=1.6ms QKV=2.10s FFN=3.04s) eta=19:41:41 | 43.9K token/s | 
[epoch_0]_19731  loss=3.335186 |g|=0.385	lr=4.65e-04 | 16.4%@S17  T=1.75s(data=3.2ms QKV=2.10s FFN=3.04s) eta=20:04:05 | 44.0K token/s | 
[epoch_0]_19741  loss=3.242134 |g|=0.386	lr=4.65e-04 | 17.2%@S17  T=1.72s(data=1.8ms QKV=2.10s FFN=3.04s) eta=19:41:14 | 44.2K token/s | 
[epoch_0]_19751  loss=3.339002 |g|=0.391	lr=4.65e-04 | 18.0%@S17  T=1.74s(data=1.7ms QKV=2.10s FFN=3.04s) eta=19:54:28 | 44.4K token/s | 
[epoch_0]_19761  loss=3.307679 |g|=0.379	lr=4.64e-04 | 18.8%@S17  T=1.70s(data=2.3ms QKV=2.10s FFN=3.04s) eta=19:32:23 | 44.6K token/s | 
[epoch_0]_19771  loss=3.339576 |g|=0.409	lr=4.64e-04 | 19.6%@S17  T=1.72s(data=2.8ms QKV=2.10s FFN=3.04s) eta=19:45:14 | 44.7K token/s | 
[epoch_0]_19781  loss=3.284438 |g|=0.367	lr=4.64e-04 | 20.5%@S17  T=1.73s(data=3.0ms QKV=2.10s FFN=3.04s) eta=19:47:24 | 44.8K token/s | 
[epoch_0]_19791  loss=3.374355 |g|=0.364	lr=4.64e-04 | 21.3%@S17  T=1.70s(data=3.6ms QKV=2.10s FFN=3.04s) eta=19:25:36 | 45.0K token/s | 
[Fuyou] head="5" update algorithm=4 t=10.66s
[eval] 
	 Loss@"edu_fineweb1B"=3.347(0.0041) nBranch=1 nToken=6.31M best=3.3512(97) E2T=-0.0378 T=36.7363(0)s x=0
	#3.34712±0.0975 tps=172K(6.30784M) a=[3.15715,3.61733] T=36.7363(sec)
[Section@19800] layer[0-8] tasks=19(nPassBack=0) last_loss=3.38488(-0.0502188) N=(772,22848,22288 2613468)
[epoch_0]_19801  loss=3.338125 |g|=0.39	lr=4.64e-04 | 22.1%@S17  T=12.26s(data=1.7ms QKV=2.10s FFN=3.04s) eta=5d 20:23:13 | 43.1K token/s | 
[epoch_0]_19811  loss=3.371222 |g|=0.4	lr=4.64e-04 | 22.9%@S17  T=1.71s(data=2.1ms QKV=2.10s FFN=3.04s) eta=19:35:42 | 43.3K token/s | 
[epoch_0]_19821  loss=3.341700 |g|=0.382	lr=4.64e-04 | 23.7%@S17  T=1.70s(data=1.6ms QKV=2.10s FFN=3.04s) eta=19:29:37 | 43.6K token/s | 
[epoch_0]_19831  loss=3.391459 |g|=0.416	lr=4.64e-04 | 24.6%@S17  T=1.73s(data=1.9ms QKV=2.10s FFN=3.04s) eta=19:49:05 | 43.8K token/s | 
[epoch_0]_19841  loss=3.361510 |g|=0.403	lr=4.63e-04 | 25.4%@S17  T=1.80s(data=1.5ms QKV=2.10s FFN=3.04s) eta=20:39:04 | 43.8K token/s | 
[epoch_0]_19851  loss=3.334078 |g|=0.403	lr=4.63e-04 | 26.2%@S17  T=1.71s(data=1.5ms QKV=2.10s FFN=3.04s) eta=19:36:59 | 44.0K token/s | 
[epoch_0]_19861  loss=3.295479 |g|=0.388	lr=4.63e-04 | 27.0%@S17  T=1.75s(data=1.4ms QKV=2.10s FFN=3.04s) eta=19:57:31 | 44.2K token/s | 
[epoch_0]_19871  loss=3.390248 |g|=0.425	lr=4.63e-04 | 27.8%@S17  T=1.74s(data=1.4ms QKV=2.10s FFN=3.04s) eta=19:53:28 | 44.3K token/s | 
[epoch_0]_19881  loss=3.328130 |g|=0.41	lr=4.63e-04 | 28.7%@S17  T=1.70s(data=1.9ms QKV=2.10s FFN=3.04s) eta=19:29:10 | 44.5K token/s | 
[epoch_0]_19891  loss=3.364926 |g|=0.394	lr=4.63e-04 | 29.5%@S17  T=1.72s(data=1.3ms QKV=2.10s FFN=3.04s) eta=19:39:49 | 44.7K token/s | 
[Fuyou] head="0" update algorithm=4 t=11.32s
[Section@19900] layer[8-16] tasks=19(nPassBack=0) last_loss=3.35372(-0.0430036) N=(772,22960,22400 2626668)
[epoch_0]_19901  loss=3.372047 |g|=0.372	lr=4.63e-04 | 30.3%@S17  T=4.18s(data=1.9ms QKV=2.10s FFN=3.04s) eta=1d 23:44:57 | 43.4K token/s | 
[epoch_0]_19911  loss=3.238674 |g|=0.398	lr=4.63e-04 | 31.1%@S17  T=1.70s(data=1.9ms QKV=2.10s FFN=3.04s) eta=19:24:02 | 43.7K token/s | 
[epoch_0]_19921  loss=3.329858 |g|=0.371	lr=4.62e-04 | 31.9%@S17  T=1.72s(data=1.9ms QKV=2.10s FFN=3.04s) eta=19:39:58 | 43.9K token/s | 
[epoch_0]_19931  loss=3.344758 |g|=0.412	lr=4.62e-04 | 32.8%@S17  T=1.73s(data=1.6ms QKV=2.10s FFN=3.04s) eta=19:44:37 | 44.0K token/s | 
[epoch_0]_19941  loss=3.341643 |g|=0.401	lr=4.62e-04 | 33.6%@S17  T=1.69s(data=2.0ms QKV=2.10s FFN=3.04s) eta=19:16:07 | 44.3K token/s | 
[epoch_0]_19951  loss=3.342479 |g|=0.408	lr=4.62e-04 | 34.4%@S17  T=1.74s(data=1.6ms QKV=2.10s FFN=3.04s) eta=19:48:24 | 44.4K token/s | 
[epoch_0]_19961  loss=3.302764 |g|=0.393	lr=4.62e-04 | 35.2%@S17  T=1.68s(data=2.5ms QKV=2.10s FFN=3.04s) eta=19:11:55 | 44.6K token/s | 
[epoch_0]_19971  loss=3.352352 |g|=0.401	lr=4.62e-04 | 36.0%@S17  T=1.74s(data=1.6ms QKV=2.10s FFN=3.04s) eta=19:51:35 | 44.7K token/s | 
[epoch_0]_19981  loss=3.456698 |g|=0.408	lr=4.62e-04 | 36.8%@S17  T=1.77s(data=3.0ms QKV=2.10s FFN=3.04s) eta=20:13:45 | 44.8K token/s | 
[epoch_0]_19991  loss=3.377588 |g|=0.391	lr=4.61e-04 | 37.7%@S17  T=1.73s(data=1.5ms QKV=2.10s FFN=3.04s) eta=19:41:52 | 44.9K token/s | 
[Fuyou] head="1" update algorithm=4 t=11.58s
[eval] 
	 Loss@"edu_fineweb1B"=3.343(0.0043) nBranch=1 nToken=6.31M best=3.3471(98) E2T=0.0104 T=36.7333(0)s x=0
	#3.34286±0.0971 tps=172K(6.30784M) a=[3.15127,3.61129] T=36.7333(sec)
[Section@20000] layer[16-24] tasks=19(nPassBack=0) last_loss=3.33244(-0.0334315) N=(772,23072,22512 2639868)
[epoch_0]_20001  loss=3.245562 |g|=0.359	lr=4.61e-04 | 38.5%@S17  T=11.94s(data=1.8ms QKV=2.10s FFN=3.04s) eta=5d 16:03:33 | 43.0K token/s | 
[epoch_0]_20011  loss=3.319670 |g|=0.411	lr=4.61e-04 | 39.3%@S17  T=1.73s(data=1.5ms QKV=2.10s FFN=3.04s) eta=19:43:25 | 43.3K token/s | 
[epoch_0]_20021  loss=3.358437 |g|=0.411	lr=4.61e-04 | 40.1%@S17  T=1.73s(data=1.6ms QKV=2.10s FFN=3.04s) eta=19:44:05 | 43.5K token/s | 
[epoch_0]_20031  loss=3.339382 |g|=0.374	lr=4.61e-04 | 40.9%@S17  T=1.74s(data=1.8ms QKV=2.10s FFN=3.04s) eta=19:48:09 | 43.6K token/s | 
[epoch_0]_20041  loss=3.334339 |g|=0.382	lr=4.61e-04 | 41.8%@S17  T=1.72s(data=1.8ms QKV=2.10s FFN=3.04s) eta=19:34:28 | 43.8K token/s | 
[epoch_0]_20051  loss=3.368137 |g|=0.385	lr=4.61e-04 | 42.6%@S17  T=1.70s(data=1.5ms QKV=2.10s FFN=3.04s) eta=19:23:39 | 44.1K token/s | 
[epoch_0]_20061  loss=3.314623 |g|=0.4	lr=4.61e-04 | 43.4%@S17  T=1.74s(data=1.5ms QKV=2.10s FFN=3.04s) eta=19:47:16 | 44.2K token/s | 
[epoch_0]_20071  loss=3.395311 |g|=0.386	lr=4.60e-04 | 44.2%@S17  T=1.73s(data=1.5ms QKV=2.10s FFN=3.04s) eta=19:41:32 | 44.4K token/s | 
[epoch_0]_20081  loss=3.274300 |g|=0.396	lr=4.60e-04 | 45.0%@S17  T=1.73s(data=1.6ms QKV=2.10s FFN=3.04s) eta=19:42:15 | 44.5K token/s | 
[epoch_0]_20091  loss=3.302289 |g|=0.398	lr=4.60e-04 | 45.9%@S17  T=1.73s(data=1.5ms QKV=2.10s FFN=3.04s) eta=19:37:29 | 44.7K token/s | 
[Fuyou] head="2" update algorithm=4 t=10.12s
[Section@20100] layer[24-32] tasks=19(nPassBack=0) last_loss=3.34433(0.0245118) N=(772,23184,22624 2653068)
[epoch_0]_20101  loss=3.311280 |g|=0.364	lr=4.60e-04 | 46.7%@S17  T=4.09s(data=1.5ms QKV=2.10s FFN=3.03s) eta=1d 22:30:14 | 43.4K token/s | 
[epoch_0]_20111  loss=3.330550 |g|=0.391	lr=4.60e-04 | 47.5%@S17  T=1.72s(data=1.7ms QKV=2.10s FFN=3.04s) eta=19:32:41 | 43.6K token/s | 
[epoch_0]_20121  loss=3.278673 |g|=0.399	lr=4.60e-04 | 48.3%@S17  T=1.71s(data=2.0ms QKV=2.10s FFN=3.04s) eta=19:26:11 | 43.8K token/s | 
[epoch_0]_20131  loss=3.298351 |g|=0.399	lr=4.60e-04 | 49.1%@S17  T=1.76s(data=6.5ms QKV=2.10s FFN=3.04s) eta=20:02:39 | 44.0K token/s | 
[epoch_0]_20141  loss=3.297910 |g|=0.414	lr=4.60e-04 | 50.0%@S17  T=1.73s(data=1.6ms QKV=2.10s FFN=3.04s) eta=19:37:43 | 44.1K token/s | 
[epoch_0]_20151  loss=3.329811 |g|=0.372	lr=4.59e-04 | 50.8%@S17  T=1.73s(data=1.8ms QKV=2.10s FFN=3.04s) eta=19:39:45 | 44.3K token/s | 
[epoch_0]_20161  loss=3.304766 |g|=0.408	lr=4.59e-04 | 51.6%@S17  T=1.75s(data=1.6ms QKV=2.10s FFN=3.04s) eta=19:50:57 | 44.4K token/s | 
[epoch_0]_20171  loss=3.348705 |g|=0.409	lr=4.59e-04 | 52.4%@S17  T=1.73s(data=2.0ms QKV=2.10s FFN=3.04s) eta=19:37:01 | 44.6K token/s | 
[epoch_0]_20181  loss=3.317198 |g|=0.419	lr=4.59e-04 | 53.2%@S17  T=1.73s(data=1.5ms QKV=2.10s FFN=3.04s) eta=19:35:29 | 44.7K token/s | 
[epoch_0]_20191  loss=3.379074 |g|=0.375	lr=4.59e-04 | 54.1%@S17  T=1.70s(data=1.6ms QKV=2.10s FFN=3.04s) eta=19:14:18 | 44.9K token/s | 
[Fuyou] head="3" update algorithm=4 t=10.24s
[eval] 
	 Loss@"edu_fineweb1B"=3.340(0.0027) nBranch=1 nToken=6.31M best=3.3429(99) E2T=0.0399 T=36.7423(0)s x=0
	#3.34018±0.0971 tps=172K(6.30784M) a=[3.15092,3.61106] T=36.7423(sec)
[Section@20200] layer[32-40] tasks=19(nPassBack=0) last_loss=3.30026(0.0974984) N=(772,23296,22736 2666268)
[epoch_0]_20201  loss=3.330501 |g|=0.394	lr=4.59e-04 | 54.9%@S17  T=11.59s(data=1.6ms QKV=2.10s FFN=3.04s) eta=5d 11:27:10 | 43.0K token/s | 
[epoch_0]_20211  loss=3.312678 |g|=0.388	lr=4.59e-04 | 55.7%@S17  T=1.69s(data=1.9ms QKV=2.10s FFN=3.04s) eta=19:07:33 | 43.3K token/s | 
[epoch_0]_20221  loss=3.348694 |g|=0.385	lr=4.58e-04 | 56.5%@S17  T=1.73s(data=1.6ms QKV=2.10s FFN=3.04s) eta=19:33:50 | 43.5K token/s | 
[epoch_0]_20231  loss=3.293091 |g|=0.412	lr=4.58e-04 | 57.3%@S17  T=1.71s(data=1.9ms QKV=2.10s FFN=3.04s) eta=19:19:36 | 43.7K token/s | 
[epoch_0]_20241  loss=3.353873 |g|=0.359	lr=4.58e-04 | 58.1%@S17  T=1.71s(data=1.7ms QKV=2.10s FFN=3.04s) eta=19:19:34 | 43.9K token/s | 
[epoch_0]_20251  loss=3.295385 |g|=0.403	lr=4.58e-04 | 59.0%@S17  T=1.75s(data=2.0ms QKV=2.10s FFN=3.04s) eta=19:50:42 | 44.1K token/s | 
[epoch_0]_20261  loss=3.402477 |g|=0.382	lr=4.58e-04 | 59.8%@S17  T=1.74s(data=1.7ms QKV=2.10s FFN=3.04s) eta=19:39:08 | 44.2K token/s | 
[epoch_0]_20271  loss=3.366927 |g|=0.388	lr=4.58e-04 | 60.6%@S17  T=1.72s(data=1.8ms QKV=2.10s FFN=3.04s) eta=19:31:52 | 44.4K token/s | 
[epoch_0]_20281  loss=3.417343 |g|=0.398	lr=4.58e-04 | 61.4%@S17  T=1.73s(data=1.6ms QKV=2.10s FFN=3.04s) eta=19:33:52 | 44.6K token/s | 
[epoch_0]_20291  loss=3.341729 |g|=0.391	lr=4.58e-04 | 62.2%@S17  T=1.77s(data=1.7ms QKV=2.10s FFN=3.04s) eta=20:02:02 | 44.6K token/s | 
[Fuyou] head="4" update algorithm=4 t=10.63s
[Section@20300] layer[40-48] tasks=19(nPassBack=0) last_loss=3.35427(0.00213671) N=(772,23408,22848 2679468)
[epoch_0]_20301  loss=3.305864 |g|=0.38	lr=4.57e-04 | 63.1%@S17  T=4.40s(data=8.4ms QKV=2.10s FFN=3.04s) eta=2d 01:48:23 | 43.3K token/s | 
[epoch_0]_20311  loss=3.340101 |g|=0.417	lr=4.57e-04 | 63.9%@S17  T=1.73s(data=1.7ms QKV=2.10s FFN=3.04s) eta=19:35:03 | 43.5K token/s | 
[epoch_0]_20321  loss=3.340717 |g|=0.389	lr=4.57e-04 | 64.7%@S17  T=1.74s(data=1.8ms QKV=2.10s FFN=3.04s) eta=19:40:35 | 43.7K token/s | 
[epoch_0]_20331  loss=3.327913 |g|=0.399	lr=4.57e-04 | 65.5%@S17  T=1.74s(data=1.6ms QKV=2.10s FFN=3.04s) eta=19:40:45 | 43.9K token/s | 
[epoch_0]_20341  loss=3.349309 |g|=0.386	lr=4.57e-04 | 66.3%@S17  T=1.75s(data=2.3ms QKV=2.10s FFN=3.04s) eta=19:49:31 | 44.0K token/s | 
[epoch_0]_20351  loss=3.310792 |g|=0.384	lr=4.57e-04 | 67.2%@S17  T=1.73s(data=1.6ms QKV=2.10s FFN=3.04s) eta=19:34:25 | 44.2K token/s | 
[epoch_0]_20361  loss=3.318950 |g|=0.391	lr=4.57e-04 | 68.0%@S17  T=1.73s(data=1.9ms QKV=2.10s FFN=3.04s) eta=19:32:04 | 44.3K token/s | 
[epoch_0]_20371  loss=3.321223 |g|=0.409	lr=4.56e-04 | 68.8%@S17  T=1.73s(data=1.5ms QKV=2.10s FFN=3.04s) eta=19:29:14 | 44.5K token/s | 
[epoch_0]_20381  loss=3.274771 |g|=0.368	lr=4.56e-04 | 69.6%@S17  T=1.75s(data=1.7ms QKV=2.10s FFN=3.04s) eta=19:43:31 | 44.6K token/s | 
[epoch_0]_20391  loss=3.289182 |g|=0.446	lr=4.56e-04 | 70.4%@S17  T=1.75s(data=1.5ms QKV=2.10s FFN=3.04s) eta=19:46:35 | 44.7K token/s | 
[Fuyou] head="5" update algorithm=4 t=12.40s
[eval] 
	 Loss@"edu_fineweb1B"=3.339(0.00084) nBranch=1 nToken=6.31M best=3.3402(100) E2T=-0.0147 T=36.7132(0)s x=0
	#3.33934±0.0973 tps=172K(6.30784M) a=[3.15393,3.60859] T=36.7132(sec)
[Section@20400] layer[0-8] tasks=19(nPassBack=0) last_loss=3.35406(0.0308142) N=(772,23520,22960 2692668)
[epoch_0]_20401  loss=3.343116 |g|=0.377	lr=4.56e-04 | 71.3%@S17  T=11.85s(data=2.2ms QKV=2.10s FFN=3.04s) eta=5d 13:44:48 | 42.8K token/s | 
[epoch_0]_20411  loss=3.340531 |g|=0.396	lr=4.56e-04 | 72.1%@S17  T=1.74s(data=1.9ms QKV=2.10s FFN=3.04s) eta=19:37:33 | 43.1K token/s | 
[epoch_0]_20421  loss=3.355623 |g|=0.388	lr=4.56e-04 | 72.9%@S17  T=1.71s(data=1.6ms QKV=2.10s FFN=3.04s) eta=19:16:24 | 43.3K token/s | 
[epoch_0]_20431  loss=3.329342 |g|=0.388	lr=4.56e-04 | 73.7%@S17  T=1.72s(data=1.7ms QKV=2.10s FFN=3.04s) eta=19:20:50 | 43.5K token/s | 
[epoch_0]_20441  loss=3.358296 |g|=0.4	lr=4.56e-04 | 74.5%@S17  T=1.75s(data=1.6ms QKV=2.10s FFN=3.04s) eta=19:45:27 | 43.7K token/s | 
[epoch_0]_20451  loss=3.308572 |g|=0.387	lr=4.55e-04 | 75.4%@S17  T=1.74s(data=1.7ms QKV=2.10s FFN=3.04s) eta=19:37:44 | 43.9K token/s | 
[epoch_0]_20461  loss=3.252234 |g|=0.385	lr=4.55e-04 | 76.2%@S17  T=1.71s(data=1.9ms QKV=2.10s FFN=3.04s) eta=19:13:39 | 44.1K token/s | 
[epoch_0]_20471  loss=3.408930 |g|=0.417	lr=4.55e-04 | 77.0%@S17  T=1.71s(data=1.8ms QKV=2.10s FFN=3.04s) eta=19:18:21 | 44.2K token/s | 
[epoch_0]_20481  loss=3.330914 |g|=0.395	lr=4.55e-04 | 77.8%@S17  T=1.73s(data=1.6ms QKV=2.10s FFN=3.04s) eta=19:29:29 | 44.4K token/s | 
[epoch_0]_20491  loss=3.291549 |g|=0.394	lr=4.55e-04 | 78.6%@S17  T=1.76s(data=1.5ms QKV=2.10s FFN=3.04s) eta=19:46:52 | 44.5K token/s | 
[Fuyou] head="0" update algorithm=4 t=12.46s
[Section@20500] layer[8-16] tasks=19(nPassBack=0) last_loss=3.32737(0.0263453) N=(772,23632,23072 2705868)
[epoch_0]_20501  loss=3.276336 |g|=0.364	lr=4.55e-04 | 79.4%@S17  T=4.30s(data=1.9ms QKV=2.10s FFN=3.03s) eta=2d 00:23:43 | 43.2K token/s | 
[epoch_0]_20511  loss=3.256732 |g|=0.393	lr=4.55e-04 | 80.3%@S17  T=1.69s(data=2.0ms QKV=2.10s FFN=3.04s) eta=19:03:01 | 43.5K token/s | 
[epoch_0]_20521  loss=3.352385 |g|=0.413	lr=4.54e-04 | 81.1%@S17  T=1.74s(data=1.8ms QKV=2.10s FFN=3.04s) eta=19:37:17 | 43.7K token/s | 
[epoch_0]_20531  loss=3.257002 |g|=0.388	lr=4.54e-04 | 81.9%@S17  T=1.73s(data=1.7ms QKV=2.10s FFN=3.04s) eta=19:30:08 | 43.9K token/s | 
[epoch_0]_20541  loss=3.274519 |g|=0.401	lr=4.54e-04 | 82.7%@S17  T=1.74s(data=1.8ms QKV=2.10s FFN=3.04s) eta=19:35:42 | 44.0K token/s | 
[epoch_0]_20551  loss=3.341936 |g|=0.39	lr=4.54e-04 | 83.5%@S17  T=1.71s(data=1.6ms QKV=2.10s FFN=3.04s) eta=19:13:27 | 44.2K token/s | 
[epoch_0]_20561  loss=3.255979 |g|=0.395	lr=4.54e-04 | 84.4%@S17  T=1.75s(data=1.6ms QKV=2.10s FFN=3.04s) eta=19:40:58 | 44.3K token/s | 
[epoch_0]_20571  loss=3.317513 |g|=0.388	lr=4.54e-04 | 85.2%@S17  T=1.73s(data=1.8ms QKV=2.10s FFN=3.04s) eta=19:26:21 | 44.5K token/s | 
[epoch_0]_20581  loss=3.353554 |g|=0.388	lr=4.54e-04 | 86.0%@S17  T=1.69s(data=1.8ms QKV=2.10s FFN=3.04s) eta=19:01:07 | 44.7K token/s | 
[epoch_0]_20591  loss=3.314449 |g|=0.392	lr=4.54e-04 | 86.8%@S17  T=1.69s(data=1.8ms QKV=2.10s FFN=3.04s) eta=18:56:55 | 44.9K token/s | 
[Fuyou] head="1" update algorithm=4 t=8.32s
[eval] 
	 Loss@"edu_fineweb1B"=3.336(0.0029) nBranch=1 nToken=6.31M best=3.3393(101) E2T=0.0387 T=36.7606(0)s x=0
	#3.33647±0.0978 tps=172K(6.30784M) a=[3.1432,3.60961] T=36.7606(sec)
[Section@20600] layer[16-24] tasks=19(nPassBack=0) last_loss=3.2978(0.034646) N=(772,23744,23184 2719068)
[epoch_0]_20601  loss=3.334851 |g|=0.378	lr=4.53e-04 | 87.6%@S17  T=11.74s(data=2.1ms QKV=2.10s FFN=3.04s) eta=5d 11:52:30 | 43.0K token/s | 
[epoch_0]_20611  loss=3.363483 |g|=0.366	lr=4.53e-04 | 88.5%@S17  T=1.69s(data=1.9ms QKV=2.10s FFN=3.04s) eta=18:58:36 | 43.3K token/s | 
[epoch_0]_20621  loss=3.340997 |g|=0.396	lr=4.53e-04 | 89.3%@S17  T=1.68s(data=1.8ms QKV=2.10s FFN=3.04s) eta=18:53:53 | 43.5K token/s | 
[epoch_0]_20631  loss=3.234561 |g|=0.384	lr=4.53e-04 | 90.1%@S17  T=1.73s(data=1.8ms QKV=2.10s FFN=3.04s) eta=19:27:17 | 43.7K token/s | 
[epoch_0]_20641  loss=3.364675 |g|=0.41	lr=4.53e-04 | 90.9%@S17  T=1.69s(data=1.8ms QKV=2.10s FFN=3.04s) eta=18:59:51 | 43.9K token/s | 
[epoch_0]_20651  loss=3.358772 |g|=0.38	lr=4.53e-04 | 91.7%@S17  T=1.70s(data=1.9ms QKV=2.10s FFN=3.04s) eta=19:05:31 | 44.2K token/s | 
[epoch_0]_20661  loss=3.321118 |g|=0.385	lr=4.53e-04 | 92.6%@S17  T=1.76s(data=1.7ms QKV=2.10s FFN=3.04s) eta=19:42:06 | 44.3K token/s | 
[epoch_0]_20671  loss=3.296847 |g|=0.389	lr=4.52e-04 | 93.4%@S17  T=1.74s(data=1.5ms QKV=2.10s FFN=3.04s) eta=19:29:44 | 44.4K token/s | 
[epoch_0]_20681  loss=3.275515 |g|=0.366	lr=4.52e-04 | 94.2%@S17  T=1.74s(data=1.5ms QKV=2.10s FFN=3.04s) eta=19:29:40 | 44.6K token/s | 
[epoch_0]_20691  loss=3.331794 |g|=0.393	lr=4.52e-04 | 95.0%@S17  T=1.78s(data=1.9ms QKV=2.10s FFN=3.04s) eta=19:55:26 | 44.6K token/s | 
[Fuyou] head="2" update algorithm=4 t=8.01s
[Section@20700] layer[24-32] tasks=19(nPassBack=0) last_loss=3.4017(-0.0573728) N=(772,23856,23296 2732268)
[epoch_0]_20701  loss=3.312043 |g|=0.356	lr=4.52e-04 | 95.8%@S17  T=3.65s(data=1.7ms QKV=2.10s FFN=3.03s) eta=1d 16:54:54 | 43.5K token/s | 
[epoch_0]_20711  loss=3.337494 |g|=0.393	lr=4.52e-04 | 96.7%@S17  T=1.70s(data=1.7ms QKV=2.11s FFN=3.04s) eta=19:00:42 | 43.8K token/s | 
[epoch_0]_20721  loss=3.347729 |g|=0.388	lr=4.52e-04 | 97.5%@S17  T=1.72s(data=1.6ms QKV=2.10s FFN=3.04s) eta=19:15:52 | 44.0K token/s | 
[epoch_0]_20731  loss=3.399831 |g|=0.39	lr=4.52e-04 | 98.3%@S17  T=1.73s(data=1.7ms QKV=2.10s FFN=3.04s) eta=19:20:00 | 44.1K token/s | 
[epoch_0]_20741  loss=3.352943 |g|=0.442	lr=4.52e-04 | 99.1%@S17  T=1.74s(data=1.5ms QKV=2.10s FFN=3.04s) eta=19:31:02 | 44.3K token/s | 
[epoch_0]_20751  loss=3.270001 |g|=0.402	lr=4.51e-04 | 99.9%@S17  T=1.74s(data=1.5ms QKV=2.10s FFN=3.04s) eta=19:27:17 | 44.4K token/s | 
-------- End of shard_17@"./Datasets/edu_fineweb1B/edu_fineweb_train_000471.bin"-------- 
[shard-18]@"./Datasets/edu_fineweb1B/edu_fineweb_train_000472.bin": tokens=100(M) nShardSamples=1220(1757808) 
[epoch_0]_20761  loss=3.375267 |g|=0.43	lr=4.51e-04 | 0.7%@S18  T=1.71s(data=1.2ms QKV=2.10s FFN=3.04s) eta=19:10:28 | 44.6K token/s | 
[epoch_0]_20771  loss=3.308683 |g|=0.399	lr=4.51e-04 | 1.6%@S18  T=1.73s(data=1.3ms QKV=2.10s FFN=3.04s) eta=19:19:41 | 44.7K token/s | 
[epoch_0]_20781  loss=3.398963 |g|=0.401	lr=4.51e-04 | 2.4%@S18  T=1.76s(data=1.7ms QKV=2.10s FFN=3.04s) eta=19:41:29 | 44.8K token/s | 
[epoch_0]_20791  loss=3.338960 |g|=0.394	lr=4.51e-04 | 3.2%@S18  T=1.70s(data=1.6ms QKV=2.10s FFN=3.04s) eta=19:02:40 | 45.0K token/s | 
[Fuyou] head="3" update algorithm=4 t=10.13s
[eval] 
	 Loss@"edu_fineweb1B"=3.336(0.00084) nBranch=1 nToken=6.31M best=3.3365(102) E2T=-0.0257 T=36.7227(0)s x=0
	#3.33563±0.0975 tps=172K(6.30784M) a=[3.14009,3.60556] T=36.7227(sec)
[Section@20800] layer[32-40] tasks=19(nPassBack=0) last_loss=3.36136(-0.0611088) N=(772,23968,23408 2745468)
[epoch_0]_20801  loss=3.303583 |g|=0.381	lr=4.51e-04 | 4.0%@S18  T=11.89s(data=1.7ms QKV=2.10s FFN=3.04s) eta=5d 12:55:18 | 43.1K token/s | 
[epoch_0]_20811  loss=3.338741 |g|=0.37	lr=4.51e-04 | 4.8%@S18  T=1.76s(data=6.6ms QKV=2.10s FFN=3.04s) eta=19:36:50 | 43.3K token/s | 
[epoch_0]_20821  loss=3.369827 |g|=0.409	lr=4.50e-04 | 5.7%@S18  T=1.72s(data=1.9ms QKV=2.10s FFN=3.04s) eta=19:12:33 | 43.5K token/s | 
[epoch_0]_20831  loss=3.329600 |g|=0.413	lr=4.50e-04 | 6.5%@S18  T=1.74s(data=1.7ms QKV=2.10s FFN=3.04s) eta=19:24:05 | 43.7K token/s | 
[epoch_0]_20841  loss=3.314947 |g|=0.404	lr=4.50e-04 | 7.3%@S18  T=1.75s(data=1.9ms QKV=2.10s FFN=3.04s) eta=19:34:59 | 43.8K token/s | 
[epoch_0]_20851  loss=3.320193 |g|=0.383	lr=4.50e-04 | 8.1%@S18  T=1.74s(data=1.6ms QKV=2.10s FFN=3.04s) eta=19:25:08 | 44.0K token/s | 
[epoch_0]_20861  loss=3.429481 |g|=0.406	lr=4.50e-04 | 8.9%@S18  T=1.70s(data=1.7ms QKV=2.10s FFN=3.04s) eta=19:00:52 | 44.2K token/s | 
[epoch_0]_20871  loss=3.343119 |g|=0.368	lr=4.50e-04 | 9.8%@S18  T=1.73s(data=1.5ms QKV=2.10s FFN=3.04s) eta=19:17:56 | 44.3K token/s | 
[epoch_0]_20881  loss=3.366155 |g|=0.383	lr=4.50e-04 | 10.6%@S18  T=1.73s(data=1.3ms QKV=2.10s FFN=3.04s) eta=19:18:30 | 44.5K token/s | 
[epoch_0]_20891  loss=3.342024 |g|=0.374	lr=4.50e-04 | 11.4%@S18  T=1.71s(data=1.4ms QKV=2.10s FFN=3.04s) eta=19:05:34 | 44.7K token/s | 
[Fuyou] head="4" update algorithm=4 t=11.63s
[Section@20900] layer[40-48] tasks=19(nPassBack=0) last_loss=3.32952(0.0247483) N=(772,24080,23520 2758668)
[epoch_0]_20901  loss=3.310340 |g|=0.391	lr=4.49e-04 | 12.2%@S18  T=3.79s(data=1.7ms QKV=2.10s FFN=3.03s) eta=1d 18:14:13 | 43.5K token/s | 
[epoch_0]_20911  loss=3.273530 |g|=0.424	lr=4.49e-04 | 13.0%@S18  T=1.70s(data=1.9ms QKV=2.10s FFN=3.04s) eta=18:56:00 | 43.7K token/s | 
[epoch_0]_20921  loss=3.285081 |g|=0.396	lr=4.49e-04 | 13.9%@S18  T=1.72s(data=1.6ms QKV=2.10s FFN=3.04s) eta=19:09:58 | 43.9K token/s | 
[epoch_0]_20931  loss=3.379705 |g|=0.382	lr=4.49e-04 | 14.7%@S18  T=1.76s(data=1.8ms QKV=2.10s FFN=3.04s) eta=19:35:19 | 44.1K token/s | 
[epoch_0]_20941  loss=3.352443 |g|=0.38	lr=4.49e-04 | 15.5%@S18  T=1.72s(data=1.7ms QKV=2.10s FFN=3.04s) eta=19:10:17 | 44.2K token/s | 
[epoch_0]_20951  loss=3.288255 |g|=0.385	lr=4.49e-04 | 16.3%@S18  T=1.74s(data=1.5ms QKV=2.10s FFN=3.04s) eta=19:25:04 | 44.4K token/s | 
[epoch_0]_20961  loss=3.348751 |g|=0.418	lr=4.49e-04 | 17.1%@S18  T=1.74s(data=1.8ms QKV=2.10s FFN=3.04s) eta=19:25:09 | 44.5K token/s | 
[epoch_0]_20971  loss=3.406084 |g|=0.386	lr=4.48e-04 | 17.9%@S18  T=1.71s(data=1.4ms QKV=2.10s FFN=3.04s) eta=18:59:33 | 44.7K token/s | 
[epoch_0]_20981  loss=3.326042 |g|=0.373	lr=4.48e-04 | 18.8%@S18  T=1.70s(data=1.4ms QKV=2.10s FFN=3.04s) eta=18:54:45 | 44.9K token/s | 
[epoch_0]_20991  loss=3.330310 |g|=0.403	lr=4.48e-04 | 19.6%@S18  T=1.71s(data=1.7ms QKV=2.10s FFN=3.04s) eta=19:00:13 | 45.0K token/s | 
[Fuyou] head="5" update algorithm=4 t=10.99s
[eval] 
	 Loss@"edu_fineweb1B"=3.335(0.00026) nBranch=1 nToken=6.31M best=3.3356(103) E2T=-0.0379 T=36.7204(0)s x=0
	#3.33538±0.0971 tps=172K(6.30784M) a=[3.14164,3.60021] T=36.7204(sec)
[Section@21000] layer[0-8] tasks=19(nPassBack=0) last_loss=3.37326(-0.0191977) N=(772,24192,23632 2771868)
[epoch_0]_21001  loss=3.330892 |g|=0.374	lr=4.48e-04 | 20.4%@S18  T=12.18s(data=2.0ms QKV=2.10s FFN=3.03s) eta=5d 15:28:47 | 43.1K token/s | 
[epoch_0]_21011  loss=3.341508 |g|=0.402	lr=4.48e-04 | 21.2%@S18  T=1.73s(data=1.6ms QKV=2.10s FFN=3.04s) eta=19:13:53 | 43.3K token/s | 
[epoch_0]_21021  loss=3.275924 |g|=0.393	lr=4.48e-04 | 22.0%@S18  T=1.75s(data=1.5ms QKV=2.10s FFN=3.04s) eta=19:25:23 | 43.5K token/s | 
[epoch_0]_21031  loss=3.342278 |g|=0.405	lr=4.48e-04 | 22.9%@S18  T=1.70s(data=1.7ms QKV=2.10s FFN=3.04s) eta=18:56:00 | 43.7K token/s | 
[epoch_0]_21041  loss=3.367455 |g|=0.402	lr=4.48e-04 | 23.7%@S18  T=1.74s(data=1.6ms QKV=2.10s FFN=3.04s) eta=19:20:11 | 43.9K token/s | 
[epoch_0]_21051  loss=3.330660 |g|=0.408	lr=4.47e-04 | 24.5%@S18  T=1.75s(data=1.5ms QKV=2.10s FFN=3.04s) eta=19:28:33 | 44.0K token/s | 
[epoch_0]_21061  loss=3.387851 |g|=0.405	lr=4.47e-04 | 25.3%@S18  T=1.71s(data=1.5ms QKV=2.10s FFN=3.04s) eta=19:01:41 | 44.2K token/s | 
[epoch_0]_21071  loss=3.335436 |g|=0.41	lr=4.47e-04 | 26.1%@S18  T=1.76s(data=1.6ms QKV=2.10s FFN=3.04s) eta=19:29:46 | 44.3K token/s | 
[epoch_0]_21081  loss=3.346193 |g|=0.397	lr=4.47e-04 | 27.0%@S18  T=1.75s(data=1.7ms QKV=2.10s FFN=3.04s) eta=19:25:27 | 44.5K token/s | 
[epoch_0]_21091  loss=3.356882 |g|=0.397	lr=4.47e-04 | 27.8%@S18  T=1.76s(data=1.5ms QKV=2.10s FFN=3.04s) eta=19:29:34 | 44.6K token/s | 
[Fuyou] head="0" update algorithm=4 t=10.48s
[Section@21100] layer[8-16] tasks=19(nPassBack=0) last_loss=3.37394(-0.0465698) N=(772,24304,23744 2785068)
[epoch_0]_21101  loss=3.356396 |g|=0.413	lr=4.47e-04 | 28.6%@S18  T=4.21s(data=1.6ms QKV=2.10s FFN=3.03s) eta=1d 22:41:52 | 43.3K token/s | 
[epoch_0]_21111  loss=3.316787 |g|=0.386	lr=4.47e-04 | 29.4%@S18  T=1.71s(data=1.6ms QKV=2.10s FFN=3.04s) eta=18:55:01 | 43.5K token/s | 
[epoch_0]_21121  loss=3.374872 |g|=0.409	lr=4.46e-04 | 30.2%@S18  T=1.71s(data=1.8ms QKV=2.10s FFN=3.04s) eta=18:58:48 | 43.8K token/s | 
[epoch_0]_21131  loss=3.300550 |g|=0.4	lr=4.46e-04 | 31.1%@S18  T=1.76s(data=2.0ms QKV=2.10s FFN=3.04s) eta=19:30:01 | 43.9K token/s | 
[epoch_0]_21141  loss=3.274508 |g|=0.385	lr=4.46e-04 | 31.9%@S18  T=1.74s(data=1.6ms QKV=2.10s FFN=3.04s) eta=19:18:44 | 44.1K token/s | 
[epoch_0]_21151  loss=3.322306 |g|=0.364	lr=4.46e-04 | 32.7%@S18  T=1.75s(data=1.6ms QKV=2.10s FFN=3.04s) eta=19:25:17 | 44.2K token/s | 
[epoch_0]_21161  loss=3.335741 |g|=0.425	lr=4.46e-04 | 33.5%@S18  T=1.78s(data=1.6ms QKV=2.10s FFN=3.04s) eta=19:40:25 | 44.3K token/s | 
[epoch_0]_21171  loss=3.310216 |g|=0.444	lr=4.46e-04 | 34.3%@S18  T=1.75s(data=1.8ms QKV=2.10s FFN=3.04s) eta=19:21:30 | 44.4K token/s | 
[epoch_0]_21181  loss=3.319532 |g|=0.404	lr=4.46e-04 | 35.2%@S18  T=1.73s(data=1.6ms QKV=2.10s FFN=3.04s) eta=19:07:25 | 44.6K token/s | 
[epoch_0]_21191  loss=3.321300 |g|=0.37	lr=4.45e-04 | 36.0%@S18  T=1.74s(data=1.6ms QKV=2.10s FFN=3.04s) eta=19:18:22 | 44.7K token/s | 
[Fuyou] head="1" update algorithm=4 t=9.18s
[eval] 
	 Loss@"edu_fineweb1B"=3.335(0.00043) nBranch=1 nToken=6.31M best=3.3354(104) E2T=-0.0422 T=36.7399(0)s x=0
	#3.33494±0.0974 tps=172K(6.30784M) a=[3.13864,3.60664] T=36.7399(sec)
[Section@21200] layer[16-24] tasks=19(nPassBack=0) last_loss=3.37712(-0.0793247) N=(772,24416,23856 2798268)
[epoch_0]_21201  loss=3.308516 |g|=0.376	lr=4.45e-04 | 36.8%@S18  T=11.92s(data=2.1ms QKV=2.10s FFN=3.04s) eta=5d 11:53:17 | 42.8K token/s | 
[epoch_0]_21211  loss=3.331420 |g|=0.38	lr=4.45e-04 | 37.6%@S18  T=1.75s(data=2.0ms QKV=2.10s FFN=3.04s) eta=19:21:53 | 43.0K token/s | 
[epoch_0]_21221  loss=3.295911 |g|=0.389	lr=4.45e-04 | 38.4%@S18  T=1.75s(data=1.8ms QKV=2.11s FFN=3.04s) eta=19:20:13 | 43.2K token/s | 
[epoch_0]_21231  loss=3.305800 |g|=0.376	lr=4.45e-04 | 39.2%@S18  T=1.78s(data=1.5ms QKV=2.10s FFN=3.04s) eta=19:37:33 | 43.3K token/s | 
[epoch_0]_21241  loss=3.343444 |g|=0.39	lr=4.45e-04 | 40.1%@S18  T=1.75s(data=1.9ms QKV=2.10s FFN=3.04s) eta=19:22:03 | 43.5K token/s | 
[epoch_0]_21251  loss=3.294668 |g|=0.38	lr=4.45e-04 | 40.9%@S18  T=1.75s(data=1.6ms QKV=2.10s FFN=3.04s) eta=19:17:13 | 43.7K token/s | 
[epoch_0]_21261  loss=3.321427 |g|=0.411	lr=4.45e-04 | 41.7%@S18  T=1.72s(data=1.8ms QKV=2.10s FFN=3.04s) eta=18:58:03 | 43.9K token/s | 
[epoch_0]_21271  loss=3.343065 |g|=0.428	lr=4.44e-04 | 42.5%@S18  T=1.75s(data=1.4ms QKV=2.10s FFN=3.04s) eta=19:18:34 | 44.0K token/s | 
[epoch_0]_21281  loss=3.295033 |g|=0.422	lr=4.44e-04 | 43.3%@S18  T=1.76s(data=1.5ms QKV=2.10s FFN=3.04s) eta=19:26:58 | 44.2K token/s | 
[epoch_0]_21291  loss=3.307467 |g|=0.4	lr=4.44e-04 | 44.2%@S18  T=1.75s(data=1.9ms QKV=2.10s FFN=3.04s) eta=19:16:56 | 44.3K token/s | 
[Fuyou] head="2" update algorithm=4 t=8.52s
[Section@21300] layer[24-32] tasks=19(nPassBack=0) last_loss=3.37591(0.0257874) N=(772,24528,23968 2811468)
[epoch_0]_21301  loss=3.337711 |g|=0.378	lr=4.44e-04 | 45.0%@S18  T=4.38s(data=1.8ms QKV=2.10s FFN=3.03s) eta=2d 00:22:31 | 43.0K token/s | 
[epoch_0]_21311  loss=3.339429 |g|=0.398	lr=4.44e-04 | 45.8%@S18  T=1.74s(data=1.7ms QKV=2.10s FFN=3.04s) eta=19:10:21 | 43.2K token/s | 
[epoch_0]_21321  loss=3.343024 |g|=0.4	lr=4.44e-04 | 46.6%@S18  T=1.75s(data=1.6ms QKV=2.10s FFN=3.04s) eta=19:16:47 | 43.4K token/s | 
[epoch_0]_21331  loss=3.331707 |g|=0.387	lr=4.44e-04 | 47.4%@S18  T=1.73s(data=1.6ms QKV=2.10s FFN=3.04s) eta=19:07:00 | 43.6K token/s | 
[epoch_0]_21341  loss=3.291524 |g|=0.371	lr=4.43e-04 | 48.3%@S18  T=1.76s(data=1.6ms QKV=2.10s FFN=3.04s) eta=19:26:51 | 43.7K token/s | 
[epoch_0]_21351  loss=3.241831 |g|=0.39	lr=4.43e-04 | 49.1%@S18  T=1.74s(data=1.7ms QKV=2.10s FFN=3.04s) eta=19:11:44 | 43.9K token/s | 
[epoch_0]_21361  loss=3.330041 |g|=0.403	lr=4.43e-04 | 49.9%@S18  T=1.76s(data=1.7ms QKV=2.10s FFN=3.04s) eta=19:23:25 | 44.0K token/s | 
[epoch_0]_21371  loss=3.303065 |g|=0.414	lr=4.43e-04 | 50.7%@S18  T=1.71s(data=1.6ms QKV=2.10s FFN=3.04s) eta=18:50:11 | 44.2K token/s | 
[epoch_0]_21381  loss=3.340842 |g|=0.38	lr=4.43e-04 | 51.5%@S18  T=1.73s(data=1.7ms QKV=2.10s FFN=3.04s) eta=19:01:23 | 44.4K token/s | 
[epoch_0]_21391  loss=3.329083 |g|=0.398	lr=4.43e-04 | 52.4%@S18  T=1.75s(data=1.5ms QKV=2.10s FFN=3.04s) eta=19:15:43 | 44.5K token/s | 
[Fuyou] head="3" update algorithm=4 t=11.10s
[eval] 
	 Loss@"edu_fineweb1B"=3.335(0.00042) nBranch=1 nToken=6.31M best=3.3349(105) E2T=-0.0355 T=36.7324(0)s x=0
	#3.33452±0.0972 tps=172K(6.30784M) a=[3.13814,3.60651] T=36.7324(sec)
[Section@21400] layer[32-40] tasks=19(nPassBack=0) last_loss=3.37001(-0.00864244) N=(772,24640,24080 2824668)
[epoch_0]_21401  loss=3.275442 |g|=0.362	lr=4.43e-04 | 53.2%@S18  T=11.67s(data=2.5ms QKV=2.10s FFN=3.04s) eta=5d 08:27:40 | 42.6K token/s | 
[epoch_0]_21411  loss=3.352865 |g|=0.385	lr=4.43e-04 | 54.0%@S18  T=1.69s(data=1.9ms QKV=2.10s FFN=3.04s) eta=18:37:30 | 42.9K token/s | 
[epoch_0]_21421  loss=3.346692 |g|=0.408	lr=4.42e-04 | 54.8%@S18  T=1.75s(data=1.6ms QKV=2.10s FFN=3.04s) eta=19:16:13 | 43.1K token/s | 
[epoch_0]_21431  loss=3.285549 |g|=0.419	lr=4.42e-04 | 55.6%@S18  T=1.71s(data=1.8ms QKV=2.10s FFN=3.04s) eta=18:46:33 | 43.4K token/s | 
[epoch_0]_21441  loss=3.285817 |g|=0.392	lr=4.42e-04 | 56.5%@S18  T=1.75s(data=2.0ms QKV=2.10s FFN=3.04s) eta=19:12:45 | 43.5K token/s | 
[epoch_0]_21451  loss=3.251569 |g|=0.385	lr=4.42e-04 | 57.3%@S18  T=1.75s(data=1.5ms QKV=2.10s FFN=3.04s) eta=19:12:41 | 43.7K token/s | 
[epoch_0]_21461  loss=3.343310 |g|=0.378	lr=4.42e-04 | 58.1%@S18  T=1.74s(data=1.7ms QKV=2.11s FFN=3.04s) eta=19:10:36 | 43.9K token/s | 
[epoch_0]_21471  loss=3.313398 |g|=0.399	lr=4.42e-04 | 58.9%@S18  T=1.74s(data=1.7ms QKV=2.11s FFN=3.04s) eta=19:05:24 | 44.0K token/s | 
[epoch_0]_21481  loss=3.352628 |g|=0.376	lr=4.42e-04 | 59.7%@S18  T=1.81s(data=1.6ms QKV=2.10s FFN=3.04s) eta=19:51:10 | 44.1K token/s | 
[epoch_0]_21491  loss=3.339779 |g|=0.417	lr=4.41e-04 | 60.5%@S18  T=1.74s(data=1.6ms QKV=2.10s FFN=3.04s) eta=19:08:51 | 44.2K token/s | 
[Fuyou] head="4" update algorithm=4 t=11.43s
[Section@21500] layer[40-48] tasks=19(nPassBack=0) last_loss=3.28577(0.0437541) N=(772,24752,24192 2837868)
[epoch_0]_21501  loss=3.260976 |g|=0.39	lr=4.41e-04 | 61.4%@S18  T=4.17s(data=1.6ms QKV=2.10s FFN=3.03s) eta=1d 21:47:49 | 43.0K token/s | 
[epoch_0]_21511  loss=3.278131 |g|=0.378	lr=4.41e-04 | 62.2%@S18  T=1.76s(data=1.6ms QKV=2.10s FFN=3.04s) eta=19:20:28 | 43.2K token/s | 
[epoch_0]_21521  loss=3.310211 |g|=0.395	lr=4.41e-04 | 63.0%@S18  T=1.75s(data=1.7ms QKV=2.10s FFN=3.04s) eta=19:13:30 | 43.4K token/s | 
[epoch_0]_21531  loss=3.338695 |g|=0.405	lr=4.41e-04 | 63.8%@S18  T=1.76s(data=1.6ms QKV=2.10s FFN=3.04s) eta=19:21:19 | 43.5K token/s | 
[epoch_0]_21541  loss=3.371853 |g|=0.38	lr=4.41e-04 | 64.6%@S18  T=1.77s(data=1.6ms QKV=2.10s FFN=3.04s) eta=19:25:22 | 43.7K token/s | 
[epoch_0]_21551  loss=3.372558 |g|=0.414	lr=4.41e-04 | 65.5%@S18  T=1.75s(data=1.5ms QKV=2.10s FFN=3.04s) eta=19:08:27 | 43.8K token/s | 
[epoch_0]_21561  loss=3.313659 |g|=0.374	lr=4.40e-04 | 66.3%@S18  T=1.77s(data=1.8ms QKV=2.10s FFN=3.04s) eta=19:22:11 | 44.0K token/s | 
[epoch_0]_21571  loss=3.334562 |g|=0.38	lr=4.40e-04 | 67.1%@S18  T=1.76s(data=2.4ms QKV=2.11s FFN=3.04s) eta=19:19:30 | 44.1K token/s | 
[epoch_0]_21581  loss=3.318691 |g|=0.402	lr=4.40e-04 | 67.9%@S18  T=1.74s(data=1.7ms QKV=2.10s FFN=3.04s) eta=19:04:37 | 44.2K token/s | 
[epoch_0]_21591  loss=3.321348 |g|=0.393	lr=4.40e-04 | 68.7%@S18  T=1.73s(data=1.7ms QKV=2.10s FFN=3.04s) eta=18:58:33 | 44.4K token/s | 
[Fuyou] head="5" update algorithm=4 t=11.96s
[eval] 
	 Loss@"edu_fineweb1B"=3.333(0.0011) nBranch=1 nToken=6.31M best=3.3345(106) E2T=-0.0677 T=36.7242(0)s x=0
	#3.33341±0.0981 tps=172K(6.30784M) a=[3.14468,3.60339] T=36.7242(sec)
[Section@21600] layer[0-8] tasks=19(nPassBack=0) last_loss=3.40111(-0.027849) N=(772,24864,24304 2851068)
[epoch_0]_21601  loss=3.292708 |g|=0.377	lr=4.40e-04 | 69.6%@S18  T=11.90s(data=1.9ms QKV=2.10s FFN=3.04s) eta=5d 10:22:16 | 42.5K token/s | 
[epoch_0]_21611  loss=3.314734 |g|=0.388	lr=4.40e-04 | 70.4%@S18  T=1.76s(data=1.7ms QKV=2.10s FFN=3.04s) eta=19:18:23 | 42.7K token/s | 
[epoch_0]_21621  loss=3.325673 |g|=0.372	lr=4.40e-04 | 71.2%@S18  T=1.75s(data=2.0ms QKV=2.10s FFN=3.04s) eta=19:11:45 | 42.9K token/s | 
[epoch_0]_21631  loss=3.349104 |g|=0.427	lr=4.40e-04 | 72.0%@S18  T=1.73s(data=1.8ms QKV=2.10s FFN=3.04s) eta=18:58:31 | 43.1K token/s | 
[epoch_0]_21641  loss=3.345290 |g|=0.399	lr=4.39e-04 | 72.8%@S18  T=1.75s(data=1.8ms QKV=2.10s FFN=3.04s) eta=19:07:52 | 43.3K token/s | 
[epoch_0]_21651  loss=3.378800 |g|=0.369	lr=4.39e-04 | 73.7%@S18  T=1.74s(data=1.7ms QKV=2.10s FFN=3.04s) eta=19:00:15 | 43.5K token/s | 
[epoch_0]_21661  loss=3.305155 |g|=0.388	lr=4.39e-04 | 74.5%@S18  T=1.74s(data=1.7ms QKV=2.10s FFN=3.04s) eta=19:00:43 | 43.7K token/s | 
[epoch_0]_21671  loss=3.377408 |g|=0.391	lr=4.39e-04 | 75.3%@S18  T=1.76s(data=1.7ms QKV=2.10s FFN=3.04s) eta=19:12:48 | 43.8K token/s | 
[epoch_0]_21681  loss=3.291073 |g|=0.403	lr=4.39e-04 | 76.1%@S18  T=1.77s(data=2.0ms QKV=2.10s FFN=3.04s) eta=19:18:04 | 44.0K token/s | 
[epoch_0]_21691  loss=3.359217 |g|=0.4	lr=4.39e-04 | 76.9%@S18  T=1.74s(data=1.5ms QKV=2.10s FFN=3.04s) eta=19:03:16 | 44.1K token/s | 
[Fuyou] head="0" update algorithm=4 t=12.04s
[Section@21700] layer[8-16] tasks=19(nPassBack=0) last_loss=3.27791(0.0960286) N=(772,24976,24416 2864268)
[epoch_0]_21701  loss=3.358230 |g|=0.392	lr=4.39e-04 | 77.8%@S18  T=4.47s(data=2.0ms QKV=2.10s FFN=3.04s) eta=2d 00:48:51 | 42.8K token/s | 
[epoch_0]_21711  loss=3.298304 |g|=0.398	lr=4.38e-04 | 78.6%@S18  T=1.73s(data=1.8ms QKV=2.10s FFN=3.04s) eta=18:50:54 | 43.1K token/s | 
[epoch_0]_21721  loss=3.335968 |g|=0.411	lr=4.38e-04 | 79.4%@S18  T=1.74s(data=1.6ms QKV=2.10s FFN=3.04s) eta=19:03:19 | 43.2K token/s | 
[epoch_0]_21731  loss=3.356919 |g|=0.381	lr=4.38e-04 | 80.2%@S18  T=1.71s(data=1.7ms QKV=2.10s FFN=3.04s) eta=18:37:46 | 43.5K token/s | 
[epoch_0]_21741  loss=3.348213 |g|=0.4	lr=4.38e-04 | 81.0%@S18  T=1.74s(data=1.6ms QKV=2.10s FFN=3.04s) eta=18:58:45 | 43.7K token/s | 
[epoch_0]_21751  loss=3.321139 |g|=0.373	lr=4.38e-04 | 81.8%@S18  T=1.74s(data=1.8ms QKV=2.10s FFN=3.04s) eta=19:01:26 | 43.8K token/s | 
[epoch_0]_21761  loss=3.291988 |g|=0.384	lr=4.38e-04 | 82.7%@S18  T=1.75s(data=2.1ms QKV=2.10s FFN=3.04s) eta=19:02:34 | 44.0K token/s | 
[epoch_0]_21771  loss=3.296458 |g|=0.417	lr=4.38e-04 | 83.5%@S18  T=1.74s(data=1.6ms QKV=2.10s FFN=3.04s) eta=18:59:21 | 44.1K token/s | 
[epoch_0]_21781  loss=3.364969 |g|=0.408	lr=4.37e-04 | 84.3%@S18  T=1.73s(data=1.8ms QKV=2.10s FFN=3.04s) eta=18:53:16 | 44.3K token/s | 
[epoch_0]_21791  loss=3.378659 |g|=0.392	lr=4.37e-04 | 85.1%@S18  T=1.74s(data=1.6ms QKV=2.11s FFN=3.04s) eta=18:59:00 | 44.4K token/s | 
[Fuyou] head="1" update algorithm=4 t=9.85s
[eval] 
	 Loss@"edu_fineweb1B"=3.331(0.0019) nBranch=1 nToken=6.31M best=3.3334(107) E2T=0.0239 T=36.7072(0)s x=0
	#3.33146±0.0981 tps=172K(6.30784M) a=[3.13944,3.59945] T=36.7072(sec)
[Section@21800] layer[16-24] tasks=19(nPassBack=0) last_loss=3.30759(0.0695367) N=(772,25088,24528 2877468)
[epoch_0]_21801  loss=3.325858 |g|=0.37	lr=4.37e-04 | 85.9%@S18  T=11.97s(data=1.6ms QKV=2.10s FFN=3.04s) eta=5d 10:27:38 | 42.6K token/s | 
[epoch_0]_21811  loss=3.369007 |g|=0.422	lr=4.37e-04 | 86.8%@S18  T=1.71s(data=1.9ms QKV=2.10s FFN=3.04s) eta=18:35:12 | 42.8K token/s | 
[epoch_0]_21821  loss=3.309107 |g|=0.393	lr=4.37e-04 | 87.6%@S18  T=1.71s(data=1.9ms QKV=2.10s FFN=3.04s) eta=18:37:43 | 43.1K token/s | 
[epoch_0]_21831  loss=3.261948 |g|=0.402	lr=4.37e-04 | 88.4%@S18  T=1.75s(data=1.6ms QKV=2.10s FFN=3.04s) eta=19:03:35 | 43.3K token/s | 
[epoch_0]_21841  loss=3.353382 |g|=0.385	lr=4.37e-04 | 89.2%@S18  T=1.75s(data=1.6ms QKV=2.10s FFN=3.04s) eta=19:01:20 | 43.4K token/s | 
[epoch_0]_21851  loss=3.352583 |g|=0.414	lr=4.36e-04 | 90.0%@S18  T=1.75s(data=1.6ms QKV=2.10s FFN=3.04s) eta=19:00:44 | 43.6K token/s | 
[epoch_0]_21861  loss=3.280622 |g|=0.39	lr=4.36e-04 | 90.9%@S18  T=1.72s(data=1.7ms QKV=2.10s FFN=3.04s) eta=18:46:08 | 43.8K token/s | 
[epoch_0]_21871  loss=3.324890 |g|=0.372	lr=4.36e-04 | 91.7%@S18  T=1.75s(data=1.8ms QKV=2.10s FFN=3.04s) eta=18:59:27 | 44.0K token/s | 
[epoch_0]_21881  loss=3.416319 |g|=0.402	lr=4.36e-04 | 92.5%@S18  T=1.76s(data=1.6ms QKV=2.10s FFN=3.04s) eta=19:08:45 | 44.1K token/s | 
[epoch_0]_21891  loss=3.338141 |g|=0.408	lr=4.36e-04 | 93.3%@S18  T=1.76s(data=1.6ms QKV=2.10s FFN=3.04s) eta=19:09:46 | 44.2K token/s | 
[Fuyou] head="2" update algorithm=4 t=8.87s
[Section@21900] layer[24-32] tasks=19(nPassBack=0) last_loss=3.27295(0.102965) N=(772,25200,24640 2890668)
[epoch_0]_21901  loss=3.301667 |g|=0.351	lr=4.36e-04 | 94.1%@S18  T=4.17s(data=1.8ms QKV=2.10s FFN=3.03s) eta=1d 21:20:12 | 43.0K token/s | 
[epoch_0]_21911  loss=3.304771 |g|=0.403	lr=4.36e-04 | 95.0%@S18  T=1.74s(data=1.8ms QKV=2.10s FFN=3.04s) eta=18:55:39 | 43.2K token/s | 
[epoch_0]_21921  loss=3.272551 |g|=0.385	lr=4.36e-04 | 95.8%@S18  T=1.76s(data=1.7ms QKV=2.10s FFN=3.04s) eta=19:04:40 | 43.4K token/s | 
[epoch_0]_21931  loss=3.268588 |g|=0.441	lr=4.35e-04 | 96.6%@S18  T=1.76s(data=1.8ms QKV=2.10s FFN=3.04s) eta=19:06:31 | 43.5K token/s | 
[epoch_0]_21941  loss=3.325516 |g|=0.402	lr=4.35e-04 | 97.4%@S18  T=1.74s(data=1.6ms QKV=2.11s FFN=3.04s) eta=18:55:48 | 43.7K token/s | 
[epoch_0]_21951  loss=3.301933 |g|=0.422	lr=4.35e-04 | 98.2%@S18  T=1.75s(data=1.8ms QKV=2.10s FFN=3.04s) eta=18:58:14 | 43.9K token/s | 
[epoch_0]_21961  loss=3.408873 |g|=0.399	lr=4.35e-04 | 99.1%@S18  T=1.75s(data=1.5ms QKV=2.10s FFN=3.04s) eta=18:57:51 | 44.0K token/s | 
[epoch_0]_21971  loss=3.337391 |g|=0.383	lr=4.35e-04 | 99.9%@S18  T=1.76s(data=1.7ms QKV=2.10s FFN=3.04s) eta=19:06:35 | 44.1K token/s | 
[epoch_0]_21972  loss=3.295013 |g|=0.381	lr=4.35e-04 | 100.0%@S18  T=1.76s(data=1.5ms QKV=2.10s FFN=3.04s) eta=19:09:01 | 44.2K token/s | 
-------- End of shard_18@"./Datasets/edu_fineweb1B/edu_fineweb_train_000472.bin"-------- 
[shard-19]@"./Datasets/edu_fineweb1B/edu_fineweb_train_000473.bin": tokens=100(M) nShardSamples=1220(1855464) 
[epoch_0]_21981  loss=3.322372 |g|=0.381	lr=4.35e-04 | 0.7%@S19  T=1.74s(data=1.2ms QKV=2.10s FFN=3.04s) eta=18:54:46 | 44.4K token/s | 
[epoch_0]_21991  loss=3.333034 |g|=0.382	lr=4.35e-04 | 1.5%@S19  T=1.74s(data=1.4ms QKV=2.10s FFN=3.04s) eta=18:52:51 | 44.5K token/s | 
[Fuyou] head="3" update algorithm=4 t=11.36s
[eval] 
	 Loss@"edu_fineweb1B"=3.327(0.0047) nBranch=1 nToken=6.31M best=3.3315(108) E2T=0.0324 T=36.7098(0)s x=0
	#3.32675±0.0971 tps=172K(6.30784M) a=[3.13601,3.59212] T=36.7098(sec)
[Section@22000] layer[32-40] tasks=19(nPassBack=0) last_loss=3.2943(0.075702) N=(772,25312,24752 2903868)
[epoch_0]_22001  loss=3.294303 |g|=0.396	lr=4.34e-04 | 2.3%@S19  T=11.65s(data=1.8ms QKV=2.10s FFN=3.04s) eta=5d 06:17:25 | 42.6K token/s | 
[epoch_0]_22011  loss=3.307057 |g|=0.422	lr=4.34e-04 | 3.1%@S19  T=1.74s(data=1.7ms QKV=2.10s FFN=3.04s) eta=18:54:31 | 42.9K token/s | 
[epoch_0]_22021  loss=3.297940 |g|=0.425	lr=4.34e-04 | 4.0%@S19  T=1.71s(data=2.2ms QKV=2.10s FFN=3.04s) eta=18:34:14 | 43.1K token/s | 
[epoch_0]_22031  loss=3.374416 |g|=0.409	lr=4.34e-04 | 4.8%@S19  T=1.74s(data=1.6ms QKV=2.10s FFN=3.04s) eta=18:48:37 | 43.3K token/s | 
[epoch_0]_22041  loss=3.396945 |g|=0.389	lr=4.34e-04 | 5.6%@S19  T=1.74s(data=1.7ms QKV=2.10s FFN=3.04s) eta=18:49:02 | 43.5K token/s | 
[epoch_0]_22051  loss=3.320991 |g|=0.369	lr=4.34e-04 | 6.4%@S19  T=1.73s(data=1.5ms QKV=2.10s FFN=3.04s) eta=18:41:17 | 43.7K token/s | 
[epoch_0]_22061  loss=3.326198 |g|=0.412	lr=4.34e-04 | 7.2%@S19  T=1.71s(data=1.6ms QKV=2.10s FFN=3.04s) eta=18:33:48 | 43.9K token/s | 
[epoch_0]_22071  loss=3.343421 |g|=0.411	lr=4.33e-04 | 8.1%@S19  T=1.71s(data=1.6ms QKV=2.10s FFN=3.04s) eta=18:29:38 | 44.1K token/s | 
[epoch_0]_22081  loss=3.271289 |g|=0.395	lr=4.33e-04 | 8.9%@S19  T=1.73s(data=1.6ms QKV=2.10s FFN=3.04s) eta=18:45:06 | 44.3K token/s | 
[epoch_0]_22091  loss=3.355806 |g|=0.373	lr=4.33e-04 | 9.7%@S19  T=1.74s(data=1.9ms QKV=2.10s FFN=3.04s) eta=18:48:10 | 44.4K token/s | 
[Fuyou] head="4" update algorithm=4 t=11.42s
[Section@22100] layer[40-48] tasks=19(nPassBack=0) last_loss=3.30572(-0.0199537) N=(772,25424,24864 2917068)
[epoch_0]_22101  loss=3.290056 |g|=0.364	lr=4.33e-04 | 10.5%@S19  T=4.02s(data=1.6ms QKV=2.10s FFN=3.03s) eta=1d 19:25:56 | 43.2K token/s | 
[epoch_0]_22111  loss=3.313397 |g|=0.412	lr=4.33e-04 | 11.3%@S19  T=1.76s(data=1.5ms QKV=2.10s FFN=3.04s) eta=19:00:58 | 43.4K token/s | 
[epoch_0]_22121  loss=3.335760 |g|=0.392	lr=4.33e-04 | 12.2%@S19  T=1.73s(data=1.7ms QKV=2.10s FFN=3.04s) eta=18:41:22 | 43.6K token/s | 
[epoch_0]_22131  loss=3.342721 |g|=0.408	lr=4.33e-04 | 13.0%@S19  T=1.73s(data=1.6ms QKV=2.10s FFN=3.04s) eta=18:40:12 | 43.8K token/s | 
[epoch_0]_22141  loss=3.235573 |g|=0.401	lr=4.32e-04 | 13.8%@S19  T=1.74s(data=1.6ms QKV=2.10s FFN=3.04s) eta=18:48:51 | 43.9K token/s | 
[epoch_0]_22151  loss=3.375310 |g|=0.397	lr=4.32e-04 | 14.6%@S19  T=1.77s(data=1.7ms QKV=2.10s FFN=3.04s) eta=19:05:11 | 44.1K token/s | 
[epoch_0]_22161  loss=3.370668 |g|=0.396	lr=4.32e-04 | 15.4%@S19  T=1.75s(data=1.7ms QKV=2.10s FFN=3.04s) eta=18:54:23 | 44.2K token/s | 
[epoch_0]_22171  loss=3.417349 |g|=0.414	lr=4.32e-04 | 16.3%@S19  T=1.75s(data=1.5ms QKV=2.10s FFN=3.04s) eta=18:56:15 | 44.3K token/s | 
[epoch_0]_22181  loss=3.364476 |g|=0.395	lr=4.32e-04 | 17.1%@S19  T=1.74s(data=1.5ms QKV=2.10s FFN=3.04s) eta=18:47:33 | 44.5K token/s | 
[epoch_0]_22191  loss=3.267908 |g|=0.375	lr=4.32e-04 | 17.9%@S19  T=1.76s(data=1.5ms QKV=2.10s FFN=3.04s) eta=18:58:36 | 44.6K token/s | 
[Fuyou] head="5" update algorithm=4 t=9.32s
[eval] 
	 Loss@"edu_fineweb1B"=3.320(0.0071) nBranch=1 nToken=6.31M best=3.3268(109) E2T=0.0528 T=36.7259(0)s x=0
	#3.3197±0.0973 tps=172K(6.30784M) a=[3.1291,3.58753] T=36.7259(sec)
[Section@22200] layer[0-8] tasks=19(nPassBack=0) last_loss=3.26687(0.134233) N=(772,25536,24976 2930268)
[epoch_0]_22201  loss=3.370127 |g|=0.38	lr=4.32e-04 | 18.7%@S19  T=11.80s(data=1.3ms QKV=2.10s FFN=3.04s) eta=5d 07:14:53 | 42.7K token/s | 
[epoch_0]_22211  loss=3.294188 |g|=0.383	lr=4.31e-04 | 19.5%@S19  T=1.75s(data=1.7ms QKV=2.10s FFN=3.04s) eta=18:49:45 | 42.9K token/s | 
[epoch_0]_22221  loss=3.348660 |g|=0.4	lr=4.31e-04 | 20.4%@S19  T=1.75s(data=1.5ms QKV=2.10s FFN=3.04s) eta=18:53:02 | 43.1K token/s | 
[epoch_0]_22231  loss=3.171602 |g|=0.373	lr=4.31e-04 | 21.2%@S19  T=1.76s(data=1.7ms QKV=2.10s FFN=3.04s) eta=19:00:19 | 43.3K token/s | 
[epoch_0]_22241  loss=3.277397 |g|=0.394	lr=4.31e-04 | 22.0%@S19  T=1.73s(data=1.7ms QKV=2.10s FFN=3.04s) eta=18:39:12 | 43.5K token/s | 
[epoch_0]_22251  loss=3.325418 |g|=0.402	lr=4.31e-04 | 22.8%@S19  T=1.74s(data=1.7ms QKV=2.10s FFN=3.04s) eta=18:42:04 | 43.6K token/s | 
[epoch_0]_22261  loss=3.236870 |g|=0.393	lr=4.31e-04 | 23.6%@S19  T=1.74s(data=1.7ms QKV=2.10s FFN=3.04s) eta=18:46:04 | 43.8K token/s | 
[epoch_0]_22271  loss=3.248616 |g|=0.381	lr=4.31e-04 | 24.4%@S19  T=1.74s(data=1.6ms QKV=2.10s FFN=3.04s) eta=18:46:31 | 44.0K token/s | 
[epoch_0]_22281  loss=3.257251 |g|=0.381	lr=4.31e-04 | 25.3%@S19  T=1.73s(data=1.4ms QKV=2.10s FFN=3.04s) eta=18:37:49 | 44.1K token/s | 
[epoch_0]_22291  loss=3.255530 |g|=0.399	lr=4.30e-04 | 26.1%@S19  T=1.75s(data=1.5ms QKV=2.10s FFN=3.04s) eta=18:47:30 | 44.3K token/s | 
[Fuyou] head="0" update algorithm=4 t=10.15s
[Section@22300] layer[8-16] tasks=19(nPassBack=0) last_loss=3.37399(-0.096081) N=(772,25648,25088 2943468)
[epoch_0]_22301  loss=3.355935 |g|=0.384	lr=4.30e-04 | 26.9%@S19  T=4.41s(data=1.8ms QKV=2.10s FFN=3.03s) eta=1d 23:28:41 | 43.0K token/s | 
[epoch_0]_22311  loss=3.290728 |g|=0.381	lr=4.30e-04 | 27.7%@S19  T=1.73s(data=1.5ms QKV=2.10s FFN=3.04s) eta=18:33:50 | 43.2K token/s | 
[epoch_0]_22321  loss=3.294065 |g|=0.409	lr=4.30e-04 | 28.5%@S19  T=1.70s(data=1.7ms QKV=2.10s FFN=3.04s) eta=18:17:30 | 43.5K token/s | 
[epoch_0]_22331  loss=3.316026 |g|=0.396	lr=4.30e-04 | 29.4%@S19  T=1.69s(data=1.4ms QKV=2.10s FFN=3.04s) eta=18:08:42 | 43.7K token/s | 
[epoch_0]_22341  loss=3.252601 |g|=0.407	lr=4.30e-04 | 30.2%@S19  T=1.70s(data=1.5ms QKV=2.10s FFN=3.04s) eta=18:13:27 | 43.9K token/s | 
[epoch_0]_22351  loss=3.331877 |g|=0.406	lr=4.30e-04 | 31.0%@S19  T=1.71s(data=1.6ms QKV=2.10s FFN=3.04s) eta=18:20:47 | 44.1K token/s | 
[epoch_0]_22361  loss=3.245868 |g|=0.381	lr=4.29e-04 | 31.8%@S19  T=1.71s(data=1.4ms QKV=2.10s FFN=3.04s) eta=18:21:52 | 44.3K token/s | 
[epoch_0]_22371  loss=3.333871 |g|=0.411	lr=4.29e-04 | 32.6%@S19  T=1.73s(data=1.5ms QKV=2.10s FFN=3.04s) eta=18:37:14 | 44.5K token/s | 
[epoch_0]_22381  loss=3.278829 |g|=0.389	lr=4.29e-04 | 33.5%@S19  T=1.73s(data=1.5ms QKV=2.10s FFN=3.04s) eta=18:32:10 | 44.6K token/s | 
[epoch_0]_22391  loss=3.312794 |g|=0.403	lr=4.29e-04 | 34.3%@S19  T=1.70s(data=1.6ms QKV=2.10s FFN=3.04s) eta=18:17:46 | 44.8K token/s | 
[Fuyou] head="1" update algorithm=4 t=9.84s
[eval] 
	 Loss@"edu_fineweb1B"=3.315(0.0046) nBranch=1 nToken=6.31M best=3.3197(110) E2T=0.0278 T=36.7366(0)s x=0
	#3.31508±0.0975 tps=172K(6.30784M) a=[3.12224,3.58218] T=36.7366(sec)
[Section@22400] layer[16-24] tasks=19(nPassBack=0) last_loss=3.28728(0.020308) N=(772,25760,25200 2956668)
[epoch_0]_22401  loss=3.306729 |g|=0.389	lr=4.29e-04 | 35.1%@S19  T=11.70s(data=2.2ms QKV=2.10s FFN=3.04s) eta=5d 05:34:55 | 42.9K token/s | 
[epoch_0]_22411  loss=3.334682 |g|=0.44	lr=4.29e-04 | 35.9%@S19  T=1.74s(data=1.7ms QKV=2.10s FFN=3.04s) eta=18:39:09 | 43.1K token/s | 
[epoch_0]_22421  loss=3.273371 |g|=0.36	lr=4.29e-04 | 36.7%@S19  T=1.76s(data=1.7ms QKV=2.10s FFN=3.04s) eta=18:49:43 | 43.3K token/s | 
[epoch_0]_22431  loss=3.364720 |g|=0.404	lr=4.28e-04 | 37.6%@S19  T=1.75s(data=1.8ms QKV=2.10s FFN=3.04s) eta=18:44:33 | 43.5K token/s | 
[epoch_0]_22441  loss=3.314695 |g|=0.4	lr=4.28e-04 | 38.4%@S19  T=1.75s(data=1.8ms QKV=2.10s FFN=3.04s) eta=18:46:40 | 43.6K token/s | 
[epoch_0]_22451  loss=3.225460 |g|=0.38	lr=4.28e-04 | 39.2%@S19  T=1.76s(data=1.5ms QKV=2.10s FFN=3.04s) eta=18:49:52 | 43.8K token/s | 
[epoch_0]_22461  loss=3.338457 |g|=0.395	lr=4.28e-04 | 40.0%@S19  T=1.77s(data=1.6ms QKV=2.10s FFN=3.04s) eta=18:57:31 | 43.9K token/s | 
[epoch_0]_22471  loss=3.235763 |g|=0.392	lr=4.28e-04 | 40.8%@S19  T=1.70s(data=1.6ms QKV=2.10s FFN=3.04s) eta=18:10:22 | 44.1K token/s | 
[epoch_0]_22481  loss=3.292037 |g|=0.402	lr=4.28e-04 | 41.6%@S19  T=1.72s(data=1.5ms QKV=2.10s FFN=3.04s) eta=18:27:45 | 44.3K token/s | 
[epoch_0]_22491  loss=3.311884 |g|=0.379	lr=4.28e-04 | 42.5%@S19  T=1.79s(data=1.8ms QKV=2.10s FFN=3.04s) eta=19:11:21 | 44.4K token/s | 
[Fuyou] head="2" update algorithm=4 t=9.68s
[Section@22500] layer[24-32] tasks=19(nPassBack=0) last_loss=3.26735(0.00559735) N=(772,25872,25312 2969868)
[epoch_0]_22501  loss=3.240261 |g|=0.346	lr=4.27e-04 | 43.3%@S19  T=4.35s(data=2.1ms QKV=2.10s FFN=3.03s) eta=1d 22:30:49 | 43.1K token/s | 
[epoch_0]_22511  loss=3.304913 |g|=0.373	lr=4.27e-04 | 44.1%@S19  T=1.74s(data=1.9ms QKV=2.10s FFN=3.04s) eta=18:33:59 | 43.3K token/s | 
[epoch_0]_22521  loss=3.223492 |g|=0.39	lr=4.27e-04 | 44.9%@S19  T=1.74s(data=1.6ms QKV=2.10s FFN=3.04s) eta=18:35:26 | 43.5K token/s | 
[epoch_0]_22531  loss=3.277638 |g|=0.412	lr=4.27e-04 | 45.7%@S19  T=1.74s(data=1.7ms QKV=2.10s FFN=3.04s) eta=18:33:54 | 43.7K token/s | 
[epoch_0]_22541  loss=3.332623 |g|=0.405	lr=4.27e-04 | 46.6%@S19  T=1.71s(data=1.9ms QKV=2.10s FFN=3.04s) eta=18:19:08 | 43.9K token/s | 
[epoch_0]_22551  loss=3.259671 |g|=0.385	lr=4.27e-04 | 47.4%@S19  T=1.74s(data=2.0ms QKV=2.10s FFN=3.04s) eta=18:35:18 | 44.0K token/s | 
[epoch_0]_22561  loss=3.324714 |g|=0.381	lr=4.27e-04 | 48.2%@S19  T=1.75s(data=1.5ms QKV=2.10s FFN=3.04s) eta=18:39:26 | 44.2K token/s | 
[epoch_0]_22571  loss=3.224038 |g|=0.433	lr=4.26e-04 | 49.0%@S19  T=1.74s(data=1.7ms QKV=2.10s FFN=3.04s) eta=18:38:31 | 44.3K token/s | 
[epoch_0]_22581  loss=3.255483 |g|=0.399	lr=4.26e-04 | 49.8%@S19  T=1.74s(data=1.4ms QKV=2.10s FFN=3.04s) eta=18:33:32 | 44.5K token/s | 
[epoch_0]_22591  loss=3.323320 |g|=0.38	lr=4.26e-04 | 50.7%@S19  T=1.75s(data=1.6ms QKV=2.10s FFN=3.04s) eta=18:43:15 | 44.6K token/s | 
[Fuyou] head="3" update algorithm=4 t=10.43s
[eval] 
	 Loss@"edu_fineweb1B"=3.312(0.0032) nBranch=1 nToken=6.31M best=3.3151(111) E2T=0.00516 T=36.7059(0)s x=0
	#3.31187±0.0975 tps=172K(6.30784M) a=[3.11748,3.57948] T=36.7059(sec)
[Section@22600] layer[32-40] tasks=19(nPassBack=0) last_loss=3.30671(-0.0124063) N=(772,25984,25424 2983068)
[epoch_0]_22601  loss=3.266723 |g|=0.384	lr=4.26e-04 | 51.5%@S19  T=12.04s(data=1.8ms QKV=2.10s FFN=3.04s) eta=5d 08:31:39 | 42.7K token/s | 
[epoch_0]_22611  loss=3.249423 |g|=0.396	lr=4.26e-04 | 52.3%@S19  T=1.76s(data=1.6ms QKV=2.10s FFN=3.04s) eta=18:46:57 | 42.9K token/s | 
[epoch_0]_22621  loss=3.328131 |g|=0.372	lr=4.26e-04 | 53.1%@S19  T=1.75s(data=1.8ms QKV=2.10s FFN=3.04s) eta=18:38:41 | 43.1K token/s | 
[epoch_0]_22631  loss=3.349082 |g|=0.408	lr=4.26e-04 | 53.9%@S19  T=1.75s(data=1.5ms QKV=2.10s FFN=3.04s) eta=18:40:08 | 43.3K token/s | 
[epoch_0]_22641  loss=3.242898 |g|=0.402	lr=4.25e-04 | 54.8%@S19  T=1.74s(data=1.7ms QKV=2.10s FFN=3.04s) eta=18:35:01 | 43.5K token/s | 
[epoch_0]_22651  loss=3.342653 |g|=0.428	lr=4.25e-04 | 55.6%@S19  T=1.76s(data=1.7ms QKV=2.10s FFN=3.04s) eta=18:46:30 | 43.6K token/s | 
[epoch_0]_22661  loss=3.358112 |g|=0.406	lr=4.25e-04 | 56.4%@S19  T=1.72s(data=1.7ms QKV=2.10s FFN=3.04s) eta=18:19:49 | 43.8K token/s | 
[epoch_0]_22671  loss=3.285399 |g|=0.382	lr=4.25e-04 | 57.2%@S19  T=1.70s(data=1.6ms QKV=2.10s FFN=3.04s) eta=18:09:50 | 44.0K token/s | 
[epoch_0]_22681  loss=3.358370 |g|=0.396	lr=4.25e-04 | 58.0%@S19  T=1.73s(data=1.9ms QKV=2.10s FFN=3.04s) eta=18:23:39 | 44.2K token/s | 
[epoch_0]_22691  loss=3.289543 |g|=0.382	lr=4.25e-04 | 58.9%@S19  T=1.76s(data=1.6ms QKV=2.10s FFN=3.04s) eta=18:43:47 | 44.3K token/s | 
[Fuyou] head="4" update algorithm=4 t=10.98s
[Section@22700] layer[40-48] tasks=19(nPassBack=0) last_loss=3.21726(0.0884569) N=(772,26096,25536 2996268)
[epoch_0]_22701  loss=3.278853 |g|=0.378	lr=4.25e-04 | 59.7%@S19  T=3.85s(data=1.6ms QKV=2.10s FFN=3.03s) eta=1d 16:59:17 | 43.2K token/s | 
[epoch_0]_22711  loss=3.282488 |g|=0.408	lr=4.24e-04 | 60.5%@S19  T=1.73s(data=1.6ms QKV=2.10s FFN=3.04s) eta=18:22:58 | 43.4K token/s | 
[epoch_0]_22721  loss=3.264772 |g|=0.402	lr=4.24e-04 | 61.3%@S19  T=1.69s(data=1.7ms QKV=2.10s FFN=3.04s) eta=18:02:15 | 43.6K token/s | 
[epoch_0]_22731  loss=3.332936 |g|=0.382	lr=4.24e-04 | 62.1%@S19  T=1.75s(data=2.1ms QKV=2.10s FFN=3.04s) eta=18:36:13 | 43.8K token/s | 
[epoch_0]_22741  loss=3.337068 |g|=0.392	lr=4.24e-04 | 62.9%@S19  T=1.74s(data=1.7ms QKV=2.10s FFN=3.04s) eta=18:30:06 | 44.0K token/s | 
[epoch_0]_22751  loss=3.273005 |g|=0.408	lr=4.24e-04 | 63.8%@S19  T=1.75s(data=1.6ms QKV=2.10s FFN=3.04s) eta=18:34:43 | 44.1K token/s | 
[epoch_0]_22761  loss=3.329751 |g|=0.378	lr=4.24e-04 | 64.6%@S19  T=1.74s(data=1.6ms QKV=2.10s FFN=3.04s) eta=18:32:47 | 44.2K token/s | 
[epoch_0]_22771  loss=3.292595 |g|=0.415	lr=4.24e-04 | 65.4%@S19  T=1.76s(data=1.6ms QKV=2.10s FFN=3.04s) eta=18:40:32 | 44.4K token/s | 
[epoch_0]_22781  loss=3.270938 |g|=0.405	lr=4.23e-04 | 66.2%@S19  T=1.74s(data=1.6ms QKV=2.10s FFN=3.04s) eta=18:30:25 | 44.5K token/s | 
[epoch_0]_22791  loss=3.288698 |g|=0.361	lr=4.23e-04 | 67.0%@S19  T=1.74s(data=1.5ms QKV=2.10s FFN=3.04s) eta=18:29:36 | 44.6K token/s | 
[Fuyou] head="5" update algorithm=4 t=10.24s
[eval] 
	 Loss@"edu_fineweb1B"=3.309(0.0031) nBranch=1 nToken=6.31M best=3.3119(112) E2T=0.0235 T=36.7277(0)s x=0
	#3.3088±0.0982 tps=172K(6.30784M) a=[3.11583,3.5778] T=36.7277(sec)
[Section@22800] layer[0-8] tasks=19(nPassBack=0) last_loss=3.28526(-0.0183828) N=(772,26208,25648 3009468)
[epoch_0]_22801  loss=3.220877 |g|=0.378	lr=4.23e-04 | 67.9%@S19  T=11.82s(data=2.4ms QKV=2.10s FFN=3.04s) eta=5d 05:32:10 | 42.7K token/s | 
[epoch_0]_22811  loss=3.272591 |g|=0.38	lr=4.23e-04 | 68.7%@S19  T=1.74s(data=1.7ms QKV=2.10s FFN=3.04s) eta=18:25:34 | 43.0K token/s | 
[epoch_0]_22821  loss=3.333982 |g|=0.394	lr=4.23e-04 | 69.5%@S19  T=1.75s(data=1.6ms QKV=2.10s FFN=3.04s) eta=18:34:39 | 43.2K token/s | 
[epoch_0]_22831  loss=3.397424 |g|=0.374	lr=4.23e-04 | 70.3%@S19  T=1.74s(data=1.7ms QKV=2.10s FFN=3.04s) eta=18:27:01 | 43.4K token/s | 
[epoch_0]_22841  loss=3.254274 |g|=0.383	lr=4.23e-04 | 71.1%@S19  T=1.76s(data=1.5ms QKV=2.11s FFN=3.04s) eta=18:39:43 | 43.5K token/s | 
[epoch_0]_22851  loss=3.315422 |g|=0.41	lr=4.23e-04 | 72.0%@S19  T=1.76s(data=1.6ms QKV=2.10s FFN=3.04s) eta=18:38:38 | 43.7K token/s | 
[epoch_0]_22861  loss=3.341235 |g|=0.401	lr=4.22e-04 | 72.8%@S19  T=1.77s(data=1.7ms QKV=2.10s FFN=3.04s) eta=18:44:48 | 43.8K token/s | 
[epoch_0]_22871  loss=3.262164 |g|=0.4	lr=4.22e-04 | 73.6%@S19  T=1.75s(data=1.6ms QKV=2.10s FFN=3.04s) eta=18:32:48 | 44.0K token/s | 
[epoch_0]_22881  loss=3.240196 |g|=0.39	lr=4.22e-04 | 74.4%@S19  T=1.71s(data=1.8ms QKV=2.10s FFN=3.04s) eta=18:06:46 | 44.2K token/s | 
[epoch_0]_22891  loss=3.286244 |g|=0.378	lr=4.22e-04 | 75.2%@S19  T=1.74s(data=1.6ms QKV=2.10s FFN=3.04s) eta=18:24:43 | 44.3K token/s | 
[Fuyou] head="0" update algorithm=4 t=9.87s
[Section@22900] layer[8-16] tasks=19(nPassBack=0) last_loss=3.2549(0.119093) N=(772,26320,25760 3022668)
[epoch_0]_22901  loss=3.252387 |g|=0.416	lr=4.22e-04 | 76.1%@S19  T=4.39s(data=2.0ms QKV=2.10s FFN=3.04s) eta=1d 22:29:19 | 43.0K token/s | 
[epoch_0]_22911  loss=3.269697 |g|=0.404	lr=4.22e-04 | 76.9%@S19  T=1.75s(data=1.7ms QKV=2.10s FFN=3.04s) eta=18:31:18 | 43.2K token/s | 
[epoch_0]_22921  loss=3.376902 |g|=0.401	lr=4.22e-04 | 77.7%@S19  T=1.72s(data=1.6ms QKV=2.10s FFN=3.04s) eta=18:11:05 | 43.4K token/s | 
[epoch_0]_22931  loss=3.221008 |g|=0.386	lr=4.21e-04 | 78.5%@S19  T=1.76s(data=1.5ms QKV=2.10s FFN=3.04s) eta=18:36:14 | 43.6K token/s | 
[epoch_0]_22941  loss=3.324744 |g|=0.392	lr=4.21e-04 | 79.3%@S19  T=1.71s(data=1.6ms QKV=2.10s FFN=3.04s) eta=18:08:34 | 43.8K token/s | 
[epoch_0]_22951  loss=3.282817 |g|=0.41	lr=4.21e-04 | 80.2%@S19  T=1.76s(data=1.7ms QKV=2.10s FFN=3.04s) eta=18:38:54 | 43.9K token/s | 
[epoch_0]_22961  loss=3.292880 |g|=0.378	lr=4.21e-04 | 81.0%@S19  T=1.71s(data=1.8ms QKV=2.10s FFN=3.04s) eta=18:02:21 | 44.1K token/s | 
[epoch_0]_22971  loss=3.303435 |g|=0.395	lr=4.21e-04 | 81.8%@S19  T=1.73s(data=1.6ms QKV=2.11s FFN=3.04s) eta=18:16:39 | 44.3K token/s | 
[epoch_0]_22981  loss=3.261325 |g|=0.383	lr=4.21e-04 | 82.6%@S19  T=1.75s(data=1.8ms QKV=2.10s FFN=3.04s) eta=18:31:10 | 44.4K token/s | 
[epoch_0]_22991  loss=3.324791 |g|=0.403	lr=4.21e-04 | 83.4%@S19  T=1.72s(data=1.6ms QKV=2.11s FFN=3.04s) eta=18:09:01 | 44.6K token/s | 
[Fuyou] head="1" update algorithm=4 t=11.29s
[eval] 
	 Loss@"edu_fineweb1B"=3.306(0.0029) nBranch=1 nToken=6.31M best=3.3088(113) E2T=0.0126 T=36.7194(0)s x=0
	#3.30589±0.0977 tps=172K(6.30784M) a=[3.11281,3.57466] T=36.7194(sec)
[Section@23000] layer[16-24] tasks=19(nPassBack=0) last_loss=3.29327(-0.0059886) N=(772,26432,25872 3035868)
[epoch_0]_23001  loss=3.290617 |g|=0.382	lr=4.20e-04 | 84.2%@S19  T=11.61s(data=2.0ms QKV=2.10s FFN=3.04s) eta=5d 02:38:58 | 42.7K token/s | 
[epoch_0]_23011  loss=3.270145 |g|=0.396	lr=4.20e-04 | 85.1%@S19  T=1.75s(data=2.0ms QKV=2.10s FFN=3.04s) eta=18:30:56 | 42.9K token/s | 
[epoch_0]_23021  loss=3.284712 |g|=0.402	lr=4.20e-04 | 85.9%@S19  T=1.75s(data=1.8ms QKV=2.10s FFN=3.04s) eta=18:30:47 | 43.1K token/s | 
[epoch_0]_23031  loss=3.316376 |g|=0.381	lr=4.20e-04 | 86.7%@S19  T=1.75s(data=1.6ms QKV=2.10s FFN=3.04s) eta=18:25:21 | 43.3K token/s | 
[epoch_0]_23041  loss=3.346213 |g|=0.424	lr=4.20e-04 | 87.5%@S19  T=1.75s(data=1.8ms QKV=2.11s FFN=3.04s) eta=18:28:08 | 43.5K token/s | 
[epoch_0]_23051  loss=3.317811 |g|=0.383	lr=4.20e-04 | 88.3%@S19  T=1.75s(data=1.5ms QKV=2.10s FFN=3.04s) eta=18:30:37 | 43.6K token/s | 
[epoch_0]_23061  loss=3.267820 |g|=0.384	lr=4.20e-04 | 89.2%@S19  T=1.76s(data=1.5ms QKV=2.10s FFN=3.04s) eta=18:31:50 | 43.8K token/s | 
[epoch_0]_23071  loss=3.312813 |g|=0.381	lr=4.19e-04 | 90.0%@S19  T=1.71s(data=1.7ms QKV=2.10s FFN=3.04s) eta=18:00:12 | 44.0K token/s | 
[epoch_0]_23081  loss=3.367342 |g|=0.445	lr=4.19e-04 | 90.8%@S19  T=1.75s(data=1.5ms QKV=2.10s FFN=3.04s) eta=18:24:23 | 44.1K token/s | 
[epoch_0]_23091  loss=3.285506 |g|=0.463	lr=4.19e-04 | 91.6%@S19  T=1.77s(data=1.5ms QKV=2.10s FFN=3.04s) eta=18:39:57 | 44.2K token/s | 
[Fuyou] head="2" update algorithm=4 t=9.81s
[Section@23100] layer[24-32] tasks=19(nPassBack=0) last_loss=3.32069(-0.0533395) N=(772,26544,25984 3049068)
[epoch_0]_23101  loss=3.372557 |g|=0.363	lr=4.19e-04 | 92.4%@S19  T=4.35s(data=2.2ms QKV=2.10s FFN=3.04s) eta=1d 21:51:58 | 43.0K token/s | 
[epoch_0]_23111  loss=3.246791 |g|=0.419	lr=4.19e-04 | 93.3%@S19  T=1.69s(data=1.8ms QKV=2.11s FFN=3.04s) eta=17:50:42 | 43.2K token/s | 
[epoch_0]_23121  loss=3.288373 |g|=0.404	lr=4.19e-04 | 94.1%@S19  T=1.72s(data=2.1ms QKV=2.11s FFN=3.04s) eta=18:05:06 | 43.5K token/s | 
[epoch_0]_23131  loss=3.332842 |g|=0.397	lr=4.19e-04 | 94.9%@S19  T=1.73s(data=1.9ms QKV=2.11s FFN=3.04s) eta=18:12:22 | 43.7K token/s | 
[epoch_0]_23141  loss=3.245156 |g|=0.381	lr=4.18e-04 | 95.7%@S19  T=1.70s(data=1.8ms QKV=2.11s FFN=3.04s) eta=17:54:14 | 43.9K token/s | 
[epoch_0]_23151  loss=3.265506 |g|=0.393	lr=4.18e-04 | 96.5%@S19  T=1.76s(data=1.6ms QKV=2.11s FFN=3.04s) eta=18:32:11 | 44.0K token/s | 
[epoch_0]_23161  loss=3.262235 |g|=0.376	lr=4.18e-04 | 97.4%@S19  T=1.71s(data=1.9ms QKV=2.11s FFN=3.04s) eta=17:57:45 | 44.2K token/s | 
[epoch_0]_23171  loss=3.317235 |g|=0.398	lr=4.18e-04 | 98.2%@S19  T=1.71s(data=1.7ms QKV=2.11s FFN=3.04s) eta=17:56:26 | 44.4K token/s | 
[epoch_0]_23181  loss=3.253147 |g|=0.414	lr=4.18e-04 | 99.0%@S19  T=1.72s(data=2.1ms QKV=2.11s FFN=3.04s) eta=18:04:59 | 44.6K token/s | 
[epoch_0]_23191  loss=3.258970 |g|=0.391	lr=4.18e-04 | 99.8%@S19  T=1.72s(data=1.6ms QKV=2.11s FFN=3.04s) eta=18:02:36 | 44.7K token/s | 
[epoch_0]_23193  loss=3.365475 |g|=0.409	lr=4.18e-04 | 100.0%@S19  T=1.70s(data=1.7ms QKV=2.11s FFN=3.04s) eta=17:51:46 | 44.9K token/s | 
-------- End of shard_19@"./Datasets/edu_fineweb1B/edu_fineweb_train_000473.bin"-------- 
[shard-20]@"./Datasets/edu_fineweb1B/edu_fineweb_train_000474.bin": tokens=100(M) nShardSamples=1220(1953120) 
[Fuyou] head="3" update algorithm=4 t=10.15s
[eval] 
	 Loss@"edu_fineweb1B"=3.305(0.0013) nBranch=1 nToken=6.31M best=3.3059(114) E2T=-0.0655 T=36.7162(0)s x=0
	#3.30454±0.0982 tps=172K(6.30784M) a=[3.10891,3.56915] T=36.7162(sec)
[Section@23200] layer[32-40] tasks=19(nPassBack=0) last_loss=3.37004(-0.0633309) N=(772,26656,26096 3062268)
[epoch_0]_23201  loss=3.300103 |g|=0.386	lr=4.18e-04 | 0.6%@S20  T=12.03s(data=1.7ms QKV=2.10s FFN=3.04s) eta=5d 06:27:06 | 43.0K token/s | 
[epoch_0]_23211  loss=3.370977 |g|=0.394	lr=4.17e-04 | 1.5%@S20  T=1.74s(data=1.9ms QKV=2.11s FFN=3.04s) eta=18:19:29 | 43.2K token/s | 
[epoch_0]_23221  loss=3.309093 |g|=0.389	lr=4.17e-04 | 2.3%@S20  T=1.73s(data=2.5ms QKV=2.11s FFN=3.04s) eta=18:12:01 | 43.4K token/s | 
[epoch_0]_23231  loss=3.379468 |g|=0.399	lr=4.17e-04 | 3.1%@S20  T=1.72s(data=2.0ms QKV=2.11s FFN=3.04s) eta=18:03:11 | 43.6K token/s | 
[epoch_0]_23241  loss=3.320627 |g|=0.407	lr=4.17e-04 | 3.9%@S20  T=1.73s(data=2.0ms QKV=2.11s FFN=3.04s) eta=18:07:32 | 43.8K token/s | 
[epoch_0]_23251  loss=3.339861 |g|=0.403	lr=4.17e-04 | 4.7%@S20  T=1.71s(data=1.7ms QKV=2.11s FFN=3.04s) eta=17:54:33 | 44.0K token/s | 
[epoch_0]_23261  loss=3.412312 |g|=0.399	lr=4.17e-04 | 5.5%@S20  T=1.70s(data=2.0ms QKV=2.11s FFN=3.04s) eta=17:50:45 | 44.2K token/s | 
[epoch_0]_23271  loss=3.358174 |g|=0.403	lr=4.17e-04 | 6.4%@S20  T=1.76s(data=1.6ms QKV=2.11s FFN=3.04s) eta=18:28:16 | 44.3K token/s | 
[epoch_0]_23281  loss=3.343727 |g|=0.41	lr=4.16e-04 | 7.2%@S20  T=1.71s(data=2.1ms QKV=2.11s FFN=3.04s) eta=17:55:04 | 44.5K token/s | 
[epoch_0]_23291  loss=3.320436 |g|=0.426	lr=4.16e-04 | 8.0%@S20  T=1.75s(data=1.9ms QKV=2.11s FFN=3.04s) eta=18:18:10 | 44.6K token/s | 
[Fuyou] head="4" update algorithm=4 t=11.57s
[Section@23300] layer[40-48] tasks=19(nPassBack=0) last_loss=3.36611(-0.148844) N=(772,26768,26208 3075468)
[epoch_0]_23301  loss=3.377108 |g|=0.377	lr=4.16e-04 | 8.8%@S20  T=4.22s(data=2.1ms QKV=2.10s FFN=3.03s) eta=1d 20:14:59 | 43.4K token/s | 
[epoch_0]_23311  loss=3.313956 |g|=0.398	lr=4.16e-04 | 9.6%@S20  T=1.73s(data=1.6ms QKV=2.11s FFN=3.04s) eta=18:09:02 | 43.6K token/s | 
[epoch_0]_23321  loss=3.316689 |g|=0.392	lr=4.16e-04 | 10.5%@S20  T=1.73s(data=1.4ms QKV=2.10s FFN=3.04s) eta=18:06:38 | 43.8K token/s | 
[epoch_0]_23331  loss=3.380508 |g|=0.403	lr=4.16e-04 | 11.3%@S20  T=1.72s(data=1.3ms QKV=2.11s FFN=3.04s) eta=17:59:51 | 44.0K token/s | 
[epoch_0]_23341  loss=3.333982 |g|=0.374	lr=4.16e-04 | 12.1%@S20  T=1.70s(data=2.0ms QKV=2.11s FFN=3.04s) eta=17:50:54 | 44.2K token/s | 
[epoch_0]_23351  loss=3.353750 |g|=0.395	lr=4.15e-04 | 12.9%@S20  T=1.71s(data=2.0ms QKV=2.11s FFN=3.04s) eta=17:53:18 | 44.4K token/s | 
[epoch_0]_23361  loss=3.266418 |g|=0.396	lr=4.15e-04 | 13.7%@S20  T=1.71s(data=1.9ms QKV=2.11s FFN=3.04s) eta=17:52:46 | 44.5K token/s | 
[epoch_0]_23371  loss=3.323146 |g|=0.4	lr=4.15e-04 | 14.6%@S20  T=1.76s(data=1.9ms QKV=2.11s FFN=3.04s) eta=18:23:04 | 44.6K token/s | 
[epoch_0]_23381  loss=3.357882 |g|=0.401	lr=4.15e-04 | 15.4%@S20  T=1.73s(data=1.9ms QKV=2.11s FFN=3.04s) eta=18:08:23 | 44.8K token/s | 
[epoch_0]_23391  loss=3.303949 |g|=0.402	lr=4.15e-04 | 16.2%@S20  T=1.72s(data=2.2ms QKV=2.11s FFN=3.04s) eta=18:01:41 | 44.9K token/s | 
[Fuyou] head="5" update algorithm=4 t=12.02s
[eval] 
	 Loss@"edu_fineweb1B"=3.310(-0.0052) nBranch=1 nToken=6.31M best=3.3059(114) E2T=0.027 T=36.7218(0)s x=0
	#3.30978±0.0980 tps=172K(6.30784M) a=[3.11285,3.57695] T=36.7218(sec)
[Section@23400] layer[0-8] tasks=19(nPassBack=0) last_loss=3.28279(0.00246835) N=(772,26880,26320 3088668)
[epoch_0]_23401  loss=3.297394 |g|=0.372	lr=4.15e-04 | 17.0%@S20  T=12.35s(data=2.5ms QKV=2.10s FFN=3.04s) eta=5d 09:06:47 | 43.0K token/s | 
[epoch_0]_23411  loss=3.291388 |g|=0.376	lr=4.15e-04 | 17.8%@S20  T=1.69s(data=1.9ms QKV=2.10s FFN=3.04s) eta=17:40:49 | 43.3K token/s | 
[epoch_0]_23421  loss=3.310248 |g|=0.413	lr=4.14e-04 | 18.7%@S20  T=1.71s(data=1.4ms QKV=2.10s FFN=3.04s) eta=17:55:07 | 43.5K token/s | 
[epoch_0]_23431  loss=3.352597 |g|=0.397	lr=4.14e-04 | 19.5%@S20  T=1.74s(data=1.7ms QKV=2.11s FFN=3.04s) eta=18:12:06 | 43.7K token/s | 
[epoch_0]_23441  loss=3.335914 |g|=0.393	lr=4.14e-04 | 20.3%@S20  T=1.75s(data=1.7ms QKV=2.11s FFN=3.04s) eta=18:19:26 | 43.8K token/s | 
[epoch_0]_23451  loss=3.328066 |g|=0.432	lr=4.14e-04 | 21.1%@S20  T=1.74s(data=2.0ms QKV=2.11s FFN=3.04s) eta=18:12:27 | 44.0K token/s | 
[epoch_0]_23461  loss=3.236292 |g|=0.413	lr=4.14e-04 | 21.9%@S20  T=1.75s(data=6.2ms QKV=2.11s FFN=3.04s) eta=18:16:22 | 44.1K token/s | 
[epoch_0]_23471  loss=3.342684 |g|=0.387	lr=4.14e-04 | 22.8%@S20  T=1.76s(data=1.6ms QKV=2.11s FFN=3.04s) eta=18:19:08 | 44.2K token/s | 
[epoch_0]_23481  loss=3.294149 |g|=0.397	lr=4.14e-04 | 23.6%@S20  T=1.72s(data=1.8ms QKV=2.11s FFN=3.04s) eta=17:56:24 | 44.4K token/s | 
[epoch_0]_23491  loss=3.366259 |g|=0.388	lr=4.13e-04 | 24.4%@S20  T=1.77s(data=1.6ms QKV=2.11s FFN=3.04s) eta=18:25:31 | 44.5K token/s | 
[Fuyou] head="0" update algorithm=4 t=12.06s
[Section@23500] layer[8-16] tasks=19(nPassBack=0) last_loss=3.24871(0.00619411) N=(772,26992,26432 3101868)
[epoch_0]_23501  loss=3.287803 |g|=0.385	lr=4.13e-04 | 25.2%@S20  T=4.33s(data=1.7ms QKV=2.10s FFN=3.04s) eta=1d 21:11:23 | 43.2K token/s | 
[epoch_0]_23511  loss=3.304601 |g|=0.405	lr=4.13e-04 | 26.0%@S20  T=1.74s(data=1.5ms QKV=2.10s FFN=3.04s) eta=18:08:15 | 43.4K token/s | 
[epoch_0]_23521  loss=3.237747 |g|=0.384	lr=4.13e-04 | 26.8%@S20  T=1.75s(data=1.4ms QKV=2.10s FFN=3.04s) eta=18:14:29 | 43.6K token/s | 
[epoch_0]_23531  loss=3.389418 |g|=0.401	lr=4.13e-04 | 27.7%@S20  T=1.76s(data=1.5ms QKV=2.11s FFN=3.04s) eta=18:22:56 | 43.7K token/s | 
[epoch_0]_23541  loss=3.193603 |g|=0.392	lr=4.13e-04 | 28.5%@S20  T=1.70s(data=1.6ms QKV=2.11s FFN=3.04s) eta=17:42:33 | 44.0K token/s | 
[epoch_0]_23551  loss=3.324070 |g|=0.391	lr=4.13e-04 | 29.3%@S20  T=1.76s(data=1.5ms QKV=2.11s FFN=3.04s) eta=18:21:50 | 44.1K token/s | 
[epoch_0]_23561  loss=3.321028 |g|=0.408	lr=4.12e-04 | 30.1%@S20  T=1.71s(data=1.7ms QKV=2.11s FFN=3.04s) eta=17:47:56 | 44.3K token/s | 
[epoch_0]_23571  loss=3.278516 |g|=0.397	lr=4.12e-04 | 30.9%@S20  T=1.75s(data=1.6ms QKV=2.10s FFN=3.04s) eta=18:12:59 | 44.4K token/s | 
[epoch_0]_23581  loss=3.255914 |g|=0.404	lr=4.12e-04 | 31.8%@S20  T=1.77s(data=1.5ms QKV=2.11s FFN=3.04s) eta=18:21:55 | 44.5K token/s | 
[epoch_0]_23591  loss=3.277689 |g|=0.385	lr=4.12e-04 | 32.6%@S20  T=1.74s(data=1.4ms QKV=2.11s FFN=3.04s) eta=18:07:53 | 44.6K token/s | 
[Fuyou] head="1" update algorithm=4 t=11.50s
[eval] 
	 Loss@"edu_fineweb1B"=3.309(0.00041) nBranch=1 nToken=6.31M best=3.3059(114) E2T=-0.00964 T=36.7223(0)s x=0
	#3.30937±0.0979 tps=172K(6.30784M) a=[3.11757,3.57342] T=36.7223(sec)
[Section@23600] layer[16-24] tasks=19(nPassBack=0) last_loss=3.31901(-0.0257478) N=(772,27104,26544 3115068)
[epoch_0]_23601  loss=3.366880 |g|=0.387	lr=4.12e-04 | 33.4%@S20  T=11.80s(data=1.9ms QKV=2.10s FFN=3.04s) eta=5d 02:41:38 | 42.7K token/s | 
[epoch_0]_23611  loss=3.314824 |g|=0.408	lr=4.12e-04 | 34.2%@S20  T=1.71s(data=2.0ms QKV=2.10s FFN=3.04s) eta=17:44:55 | 43.0K token/s | 
[epoch_0]_23621  loss=3.301398 |g|=0.418	lr=4.12e-04 | 35.0%@S20  T=1.75s(data=1.6ms QKV=2.10s FFN=3.04s) eta=18:11:22 | 43.2K token/s | 
[epoch_0]_23631  loss=3.290188 |g|=0.379	lr=4.11e-04 | 35.9%@S20  T=1.75s(data=1.6ms QKV=2.10s FFN=3.04s) eta=18:09:32 | 43.4K token/s | 
[epoch_0]_23641  loss=3.192699 |g|=0.375	lr=4.11e-04 | 36.7%@S20  T=1.71s(data=1.8ms QKV=2.10s FFN=3.04s) eta=17:43:08 | 43.6K token/s | 
[epoch_0]_23651  loss=3.321750 |g|=0.4	lr=4.11e-04 | 37.5%@S20  T=1.73s(data=1.6ms QKV=2.10s FFN=3.04s) eta=17:59:12 | 43.8K token/s | 
[epoch_0]_23661  loss=3.224923 |g|=0.413	lr=4.11e-04 | 38.3%@S20  T=1.77s(data=1.7ms QKV=2.10s FFN=3.04s) eta=18:21:59 | 43.9K token/s | 
[epoch_0]_23671  loss=3.383525 |g|=0.4	lr=4.11e-04 | 39.1%@S20  T=1.75s(data=1.8ms QKV=2.11s FFN=3.04s) eta=18:08:06 | 44.1K token/s | 
[epoch_0]_23681  loss=3.343149 |g|=0.399	lr=4.11e-04 | 40.0%@S20  T=1.79s(data=1.9ms QKV=2.10s FFN=3.04s) eta=18:35:03 | 44.1K token/s | 
[epoch_0]_23691  loss=3.366980 |g|=0.406	lr=4.11e-04 | 40.8%@S20  T=1.70s(data=1.8ms QKV=2.10s FFN=3.04s) eta=17:36:18 | 44.4K token/s | 
[Fuyou] head="2" update algorithm=4 t=11.37s
[Section@23700] layer[24-32] tasks=19(nPassBack=0) last_loss=3.27201(0.0486803) N=(772,27216,26656 3128268)
[epoch_0]_23701  loss=3.252099 |g|=0.396	lr=4.10e-04 | 41.6%@S20  T=4.01s(data=1.6ms QKV=2.10s FFN=3.04s) eta=1d 17:38:08 | 43.2K token/s | 
[epoch_0]_23711  loss=3.345282 |g|=0.391	lr=4.10e-04 | 42.4%@S20  T=1.74s(data=1.5ms QKV=2.10s FFN=3.04s) eta=18:01:45 | 43.4K token/s | 
[epoch_0]_23721  loss=3.284502 |g|=0.383	lr=4.10e-04 | 43.2%@S20  T=1.76s(data=1.6ms QKV=2.10s FFN=3.04s) eta=18:12:48 | 43.5K token/s | 
[epoch_0]_23731  loss=3.376071 |g|=0.413	lr=4.10e-04 | 44.0%@S20  T=1.75s(data=1.9ms QKV=2.10s FFN=3.04s) eta=18:10:34 | 43.7K token/s | 
[epoch_0]_23741  loss=3.292346 |g|=0.378	lr=4.10e-04 | 44.9%@S20  T=1.80s(data=1.9ms QKV=2.10s FFN=3.04s) eta=18:37:03 | 43.8K token/s | 
[epoch_0]_23751  loss=3.351602 |g|=0.405	lr=4.10e-04 | 45.7%@S20  T=1.75s(data=1.6ms QKV=2.10s FFN=3.04s) eta=18:04:40 | 43.9K token/s | 
[epoch_0]_23761  loss=3.272787 |g|=0.387	lr=4.10e-04 | 46.5%@S20  T=1.75s(data=1.6ms QKV=2.11s FFN=3.04s) eta=18:04:44 | 44.1K token/s | 
[epoch_0]_23771  loss=3.351442 |g|=0.386	lr=4.09e-04 | 47.3%@S20  T=1.77s(data=1.8ms QKV=2.10s FFN=3.04s) eta=18:17:27 | 44.2K token/s | 
[epoch_0]_23781  loss=3.311890 |g|=0.365	lr=4.09e-04 | 48.1%@S20  T=1.76s(data=1.5ms QKV=2.10s FFN=3.04s) eta=18:13:59 | 44.3K token/s | 
[epoch_0]_23791  loss=3.312278 |g|=0.388	lr=4.09e-04 | 49.0%@S20  T=1.76s(data=4.3ms QKV=2.10s FFN=3.04s) eta=18:13:23 | 44.4K token/s | 
[Fuyou] head="3" update algorithm=4 t=11.78s
[eval] 
	 Loss@"edu_fineweb1B"=3.307(0.0019) nBranch=1 nToken=6.31M best=3.3059(114) E2T=-0.0141 T=36.7293(0)s x=0
	#3.30743±0.0985 tps=172K(6.30784M) a=[3.11228,3.57677] T=36.7293(sec)
[Section@23800] layer[32-40] tasks=19(nPassBack=0) last_loss=3.32149(0.0485513) N=(772,27328,26768 3141468)
[epoch_0]_23801  loss=3.311790 |g|=0.407	lr=4.09e-04 | 49.8%@S20  T=11.91s(data=1.8ms QKV=2.10s FFN=3.04s) eta=5d 03:09:33 | 42.5K token/s | 
[epoch_0]_23811  loss=3.275563 |g|=0.387	lr=4.09e-04 | 50.6%@S20  T=1.69s(data=2.1ms QKV=2.10s FFN=3.04s) eta=17:31:28 | 42.8K token/s | 
[epoch_0]_23821  loss=3.314664 |g|=0.395	lr=4.09e-04 | 51.4%@S20  T=1.72s(data=1.7ms QKV=2.10s FFN=3.04s) eta=17:43:47 | 43.1K token/s | 
[epoch_0]_23831  loss=3.358962 |g|=0.391	lr=4.09e-04 | 52.2%@S20  T=1.76s(data=1.8ms QKV=2.10s FFN=3.04s) eta=18:10:50 | 43.3K token/s | 
[epoch_0]_23841  loss=3.282484 |g|=0.422	lr=4.08e-04 | 53.1%@S20  T=1.73s(data=3.0ms QKV=2.11s FFN=3.04s) eta=17:51:19 | 43.5K token/s | 
[epoch_0]_23851  loss=3.328194 |g|=0.401	lr=4.08e-04 | 53.9%@S20  T=1.71s(data=2.0ms QKV=2.10s FFN=3.04s) eta=17:37:59 | 43.7K token/s | 
[epoch_0]_23861  loss=3.337126 |g|=0.397	lr=4.08e-04 | 54.7%@S20  T=1.72s(data=1.7ms QKV=2.10s FFN=3.04s) eta=17:44:32 | 43.9K token/s | 
[epoch_0]_23871  loss=3.339998 |g|=0.389	lr=4.08e-04 | 55.5%@S20  T=1.71s(data=1.9ms QKV=2.11s FFN=3.04s) eta=17:40:34 | 44.1K token/s | 
[epoch_0]_23881  loss=3.247844 |g|=0.372	lr=4.08e-04 | 56.3%@S20  T=1.71s(data=1.9ms QKV=2.10s FFN=3.04s) eta=17:38:41 | 44.3K token/s | 
[epoch_0]_23891  loss=3.285236 |g|=0.373	lr=4.08e-04 | 57.2%@S20  T=1.69s(data=1.7ms QKV=2.10s FFN=3.04s) eta=17:27:54 | 44.5K token/s | 
[Fuyou] head="4" update algorithm=4 t=11.51s
[Section@23900] layer[40-48] tasks=19(nPassBack=0) last_loss=3.32997(0.0361364) N=(772,27440,26880 3154668)
[epoch_0]_23901  loss=3.280490 |g|=0.396	lr=4.07e-04 | 58.0%@S20  T=4.02s(data=1.9ms QKV=2.10s FFN=3.03s) eta=1d 17:27:55 | 43.3K token/s | 
[epoch_0]_23911  loss=3.323287 |g|=0.364	lr=4.07e-04 | 58.8%@S20  T=1.70s(data=2.0ms QKV=2.10s FFN=3.04s) eta=17:32:51 | 43.5K token/s | 
[epoch_0]_23921  loss=3.326902 |g|=0.397	lr=4.07e-04 | 59.6%@S20  T=1.77s(data=1.8ms QKV=2.10s FFN=3.04s) eta=18:15:11 | 43.7K token/s | 
[epoch_0]_23931  loss=3.305264 |g|=0.394	lr=4.07e-04 | 60.4%@S20  T=1.76s(data=2.0ms QKV=2.10s FFN=3.04s) eta=18:06:25 | 43.8K token/s | 
[epoch_0]_23941  loss=3.293749 |g|=0.406	lr=4.07e-04 | 61.3%@S20  T=1.75s(data=1.6ms QKV=2.10s FFN=3.04s) eta=18:03:56 | 44.0K token/s | 
[epoch_0]_23951  loss=3.298407 |g|=0.444	lr=4.07e-04 | 62.1%@S20  T=1.76s(data=1.7ms QKV=2.10s FFN=3.04s) eta=18:09:58 | 44.1K token/s | 
[epoch_0]_23961  loss=3.220944 |g|=0.415	lr=4.07e-04 | 62.9%@S20  T=1.75s(data=1.6ms QKV=2.11s FFN=3.04s) eta=18:00:12 | 44.2K token/s | 
[epoch_0]_23971  loss=3.285003 |g|=0.406	lr=4.06e-04 | 63.7%@S20  T=1.74s(data=1.6ms QKV=2.10s FFN=3.04s) eta=17:55:23 | 44.4K token/s | 
[epoch_0]_23981  loss=3.338727 |g|=0.384	lr=4.06e-04 | 64.5%@S20  T=1.75s(data=2.2ms QKV=2.10s FFN=3.04s) eta=17:57:52 | 44.5K token/s | 
[epoch_0]_23991  loss=3.291155 |g|=0.398	lr=4.06e-04 | 65.3%@S20  T=1.71s(data=2.0ms QKV=2.11s FFN=3.04s) eta=17:38:40 | 44.7K token/s | 
[Fuyou] head="5" update algorithm=4 t=11.11s
[eval] 
	 Loss@"edu_fineweb1B"=3.309(-0.0012) nBranch=1 nToken=6.31M best=3.3059(114) E2T=-0.0264 T=36.7439(0)s x=0
	#3.30859±0.0981 tps=172K(6.30784M) a=[3.11636,3.57902] T=36.7439(sec)
[Section@24000] layer[0-8] tasks=19(nPassBack=0) last_loss=3.335(-0.0522122) N=(772,27552,26992 3167868)
[epoch_0]_24001  loss=3.300259 |g|=0.367	lr=4.06e-04 | 66.2%@S20  T=12.22s(data=2.1ms QKV=2.10s FFN=3.04s) eta=5d 05:42:58 | 42.8K token/s | 
[epoch_0]_24011  loss=3.261254 |g|=0.419	lr=4.06e-04 | 67.0%@S20  T=1.72s(data=1.7ms QKV=2.10s FFN=3.04s) eta=17:38:20 | 43.0K token/s | 
[epoch_0]_24021  loss=3.225726 |g|=0.414	lr=4.06e-04 | 67.8%@S20  T=1.71s(data=2.0ms QKV=2.10s FFN=3.04s) eta=17:32:07 | 43.3K token/s | 
[epoch_0]_24031  loss=3.348903 |g|=0.402	lr=4.06e-04 | 68.6%@S20  T=1.73s(data=2.0ms QKV=2.10s FFN=3.04s) eta=17:46:46 | 43.5K token/s | 
[epoch_0]_24041  loss=3.280668 |g|=0.41	lr=4.05e-04 | 69.4%@S20  T=1.74s(data=2.3ms QKV=2.10s FFN=3.04s) eta=17:50:58 | 43.6K token/s | 
[epoch_0]_24051  loss=3.331291 |g|=0.417	lr=4.05e-04 | 70.3%@S20  T=1.74s(data=1.9ms QKV=2.10s FFN=3.04s) eta=17:49:27 | 43.8K token/s | 
[epoch_0]_24061  loss=3.321899 |g|=0.392	lr=4.05e-04 | 71.1%@S20  T=1.73s(data=1.9ms QKV=2.10s FFN=3.04s) eta=17:46:36 | 44.0K token/s | 
[epoch_0]_24071  loss=3.316746 |g|=0.409	lr=4.05e-04 | 71.9%@S20  T=1.75s(data=2.1ms QKV=2.11s FFN=3.04s) eta=17:55:22 | 44.1K token/s | 
[epoch_0]_24081  loss=3.346239 |g|=0.423	lr=4.05e-04 | 72.7%@S20  T=1.75s(data=1.6ms QKV=2.11s FFN=3.04s) eta=17:59:26 | 44.3K token/s | 
[epoch_0]_24091  loss=3.322011 |g|=0.407	lr=4.05e-04 | 73.5%@S20  T=1.79s(data=1.5ms QKV=2.10s FFN=3.04s) eta=18:24:53 | 44.3K token/s | 
[Fuyou] head="0" update algorithm=4 t=10.50s
[Section@24100] layer[8-16] tasks=19(nPassBack=0) last_loss=3.34163(-0.0929282) N=(772,27664,27104 3181068)
[epoch_0]_24101  loss=3.292094 |g|=0.369	lr=4.05e-04 | 74.4%@S20  T=4.23s(data=2.4ms QKV=2.10s FFN=3.04s) eta=1d 19:22:15 | 43.1K token/s | 
[epoch_0]_24111  loss=3.285224 |g|=0.398	lr=4.04e-04 | 75.2%@S20  T=1.70s(data=2.3ms QKV=2.10s FFN=3.04s) eta=17:25:04 | 43.4K token/s | 
[epoch_0]_24121  loss=3.308191 |g|=0.383	lr=4.04e-04 | 76.0%@S20  T=1.72s(data=2.3ms QKV=2.10s FFN=3.04s) eta=17:35:57 | 43.6K token/s | 
[epoch_0]_24131  loss=3.295996 |g|=0.379	lr=4.04e-04 | 76.8%@S20  T=1.76s(data=2.0ms QKV=2.10s FFN=3.04s) eta=18:00:38 | 43.7K token/s | 
[epoch_0]_24141  loss=3.321952 |g|=0.416	lr=4.04e-04 | 77.6%@S20  T=1.75s(data=1.6ms QKV=2.10s FFN=3.04s) eta=17:54:03 | 43.9K token/s | 
[epoch_0]_24151  loss=3.299809 |g|=0.42	lr=4.04e-04 | 78.5%@S20  T=1.76s(data=1.6ms QKV=2.11s FFN=3.04s) eta=18:02:48 | 44.0K token/s | 
[epoch_0]_24161  loss=3.314017 |g|=0.385	lr=4.04e-04 | 79.3%@S20  T=1.77s(data=1.6ms QKV=2.10s FFN=3.04s) eta=18:08:23 | 44.1K token/s | 
[epoch_0]_24171  loss=3.318164 |g|=0.405	lr=4.04e-04 | 80.1%@S20  T=1.72s(data=1.7ms QKV=2.10s FFN=3.04s) eta=17:37:54 | 44.3K token/s | 
[epoch_0]_24181  loss=3.289071 |g|=0.381	lr=4.03e-04 | 80.9%@S20  T=1.75s(data=1.8ms QKV=2.10s FFN=3.04s) eta=17:52:19 | 44.4K token/s | 
[epoch_0]_24191  loss=3.254132 |g|=0.374	lr=4.03e-04 | 81.7%@S20  T=1.77s(data=1.5ms QKV=2.11s FFN=3.04s) eta=18:05:28 | 44.5K token/s | 
[Fuyou] head="1" update algorithm=4 t=8.82s
[eval] 
	 Loss@"edu_fineweb1B"=3.309(-0.00054) nBranch=1 nToken=6.31M best=3.3059(114) E2T=0.0214 T=36.7417(0)s x=0
	#3.30913±0.0986 tps=172K(6.30784M) a=[3.11445,3.57781] T=36.7417(sec)
[Section@24200] layer[16-24] tasks=19(nPassBack=0) last_loss=3.28769(0.0313249) N=(772,27776,27216 3194268)
[epoch_0]_24201  loss=3.288269 |g|=0.357	lr=4.03e-04 | 82.6%@S20  T=12.32s(data=2.3ms QKV=2.10s FFN=3.04s) eta=5d 06:04:35 | 42.6K token/s | 
[epoch_0]_24211  loss=3.282917 |g|=0.382	lr=4.03e-04 | 83.4%@S20  T=1.74s(data=1.6ms QKV=2.10s FFN=3.04s) eta=17:46:22 | 42.9K token/s | 
[epoch_0]_24221  loss=3.275707 |g|=0.4	lr=4.03e-04 | 84.2%@S20  T=1.78s(data=1.6ms QKV=2.10s FFN=3.04s) eta=18:12:12 | 43.0K token/s | 
[epoch_0]_24231  loss=3.310451 |g|=0.38	lr=4.03e-04 | 85.0%@S20  T=1.75s(data=1.9ms QKV=2.10s FFN=3.04s) eta=17:55:27 | 43.2K token/s | 
[epoch_0]_24241  loss=3.282686 |g|=0.425	lr=4.03e-04 | 85.8%@S20  T=1.77s(data=1.6ms QKV=2.10s FFN=3.04s) eta=18:02:35 | 43.4K token/s | 
[epoch_0]_24251  loss=3.337254 |g|=0.437	lr=4.02e-04 | 86.6%@S20  T=1.75s(data=1.6ms QKV=2.10s FFN=3.04s) eta=17:54:40 | 43.5K token/s | 
[epoch_0]_24261  loss=3.266921 |g|=0.401	lr=4.02e-04 | 87.5%@S20  T=1.75s(data=1.6ms QKV=2.11s FFN=3.04s) eta=17:54:23 | 43.7K token/s | 
[epoch_0]_24271  loss=3.296708 |g|=0.382	lr=4.02e-04 | 88.3%@S20  T=1.76s(data=2.0ms QKV=2.10s FFN=3.04s) eta=18:00:14 | 43.8K token/s | 
[epoch_0]_24281  loss=3.268321 |g|=0.403	lr=4.02e-04 | 89.1%@S20  T=1.77s(data=1.5ms QKV=2.10s FFN=3.04s) eta=18:04:06 | 44.0K token/s | 
[epoch_0]_24291  loss=3.352694 |g|=0.4	lr=4.02e-04 | 89.9%@S20  T=1.75s(data=1.7ms QKV=2.10s FFN=3.04s) eta=17:50:58 | 44.1K token/s | 
[Fuyou] head="2" update algorithm=4 t=9.70s
[Section@24300] layer[24-32] tasks=19(nPassBack=0) last_loss=3.31047(-0.0384595) N=(772,27888,27328 3207468)
[epoch_0]_24301  loss=3.199805 |g|=0.365	lr=4.02e-04 | 90.7%@S20  T=3.79s(data=1.6ms QKV=2.10s FFN=3.04s) eta=1d 14:43:07 | 43.0K token/s | 
[epoch_0]_24311  loss=3.438365 |g|=0.427	lr=4.02e-04 | 91.6%@S20  T=1.76s(data=1.6ms QKV=2.11s FFN=3.04s) eta=17:57:35 | 43.1K token/s | 
[epoch_0]_24321  loss=3.340216 |g|=0.381	lr=4.01e-04 | 92.4%@S20  T=1.75s(data=1.6ms QKV=2.10s FFN=3.04s) eta=17:49:10 | 43.3K token/s | 
[epoch_0]_24331  loss=3.348170 |g|=0.383	lr=4.01e-04 | 93.2%@S20  T=1.76s(data=1.5ms QKV=2.10s FFN=3.04s) eta=17:56:00 | 43.5K token/s | 
[epoch_0]_24341  loss=3.364105 |g|=0.395	lr=4.01e-04 | 94.0%@S20  T=1.75s(data=1.5ms QKV=2.10s FFN=3.04s) eta=17:48:27 | 43.7K token/s | 
[epoch_0]_24351  loss=3.269150 |g|=0.383	lr=4.01e-04 | 94.8%@S20  T=1.75s(data=1.5ms QKV=2.10s FFN=3.04s) eta=17:51:07 | 43.8K token/s | 
[epoch_0]_24361  loss=3.329517 |g|=0.4	lr=4.01e-04 | 95.7%@S20  T=1.77s(data=1.9ms QKV=2.10s FFN=3.04s) eta=18:00:47 | 43.9K token/s | 
[epoch_0]_24371  loss=3.262283 |g|=0.388	lr=4.01e-04 | 96.5%@S20  T=1.76s(data=1.6ms QKV=2.10s FFN=3.04s) eta=17:56:43 | 44.1K token/s | 
[epoch_0]_24381  loss=3.309696 |g|=0.425	lr=4.01e-04 | 97.3%@S20  T=1.78s(data=1.6ms QKV=2.10s FFN=3.04s) eta=18:05:01 | 44.2K token/s | 
[epoch_0]_24391  loss=3.359754 |g|=0.405	lr=4.00e-04 | 98.1%@S20  T=1.75s(data=1.6ms QKV=2.10s FFN=3.04s) eta=17:47:32 | 44.3K token/s | 
[Fuyou] head="3" update algorithm=4 t=10.97s
[eval] 
	 Loss@"edu_fineweb1B"=3.307(0.0017) nBranch=1 nToken=6.31M best=3.3059(114) E2T=0.0179 T=36.7074(0)s x=0
	#3.30743±0.0987 tps=172K(6.30784M) a=[3.11854,3.5774] T=36.7074(sec)
[Section@24400] layer[32-40] tasks=19(nPassBack=0) last_loss=3.28957(0.0319202) N=(772,28000,27440 3220668)
[epoch_0]_24401  loss=3.298394 |g|=0.367	lr=4.00e-04 | 98.9%@S20  T=12.06s(data=1.5ms QKV=2.10s FFN=3.04s) eta=5d 02:43:13 | 42.4K token/s | 
[epoch_0]_24411  loss=3.336643 |g|=0.4	lr=4.00e-04 | 99.8%@S20  T=1.76s(data=2.0ms QKV=2.11s FFN=3.04s) eta=17:54:10 | 42.6K token/s | 
[epoch_0]_24413  loss=3.254334 |g|=0.389	lr=4.00e-04 | 99.9%@S20  T=1.72s(data=1.6ms QKV=2.10s FFN=3.04s) eta=17:27:13 | 42.9K token/s | 
[epoch_0]_24414  loss=3.308020 |g|=0.386	lr=4.00e-04 | 100.0%@S20  T=1.74s(data=1.6ms QKV=2.10s FFN=3.04s) eta=17:41:19 | 43.1K token/s | 
-------- End of shard_20@"./Datasets/edu_fineweb1B/edu_fineweb_train_000474.bin"-------- 
[shard-21]@"./Datasets/edu_fineweb1B/edu_fineweb_train_000475.bin": tokens=100(M) nShardSamples=1220(2050776) 
[epoch_0]_24421  loss=3.289741 |g|=0.427	lr=4.00e-04 | 0.6%@S21  T=1.77s(data=1.4ms QKV=2.10s FFN=3.04s) eta=17:58:03 | 43.3K token/s | 
[epoch_0]_24431  loss=3.306906 |g|=0.372	lr=4.00e-04 | 1.4%@S21  T=1.75s(data=1.3ms QKV=2.10s FFN=3.04s) eta=17:45:28 | 43.5K token/s | 
[epoch_0]_24441  loss=3.268817 |g|=0.402	lr=4.00e-04 | 2.2%@S21  T=1.75s(data=1.5ms QKV=2.11s FFN=3.04s) eta=17:48:19 | 43.6K token/s | 
[epoch_0]_24451  loss=3.349634 |g|=0.412	lr=4.00e-04 | 3.0%@S21  T=1.75s(data=1.7ms QKV=2.10s FFN=3.04s) eta=17:46:04 | 43.8K token/s | 
[epoch_0]_24461  loss=3.283799 |g|=0.386	lr=3.99e-04 | 3.9%@S21  T=1.75s(data=1.7ms QKV=2.10s FFN=3.04s) eta=17:49:35 | 43.9K token/s | 
[epoch_0]_24471  loss=3.281898 |g|=0.397	lr=3.99e-04 | 4.7%@S21  T=1.76s(data=1.6ms QKV=2.10s FFN=3.04s) eta=17:53:56 | 44.1K token/s | 
[epoch_0]_24481  loss=3.228674 |g|=0.398	lr=3.99e-04 | 5.5%@S21  T=1.78s(data=1.7ms QKV=2.10s FFN=3.04s) eta=18:03:38 | 44.2K token/s | 
[epoch_0]_24491  loss=3.254964 |g|=0.402	lr=3.99e-04 | 6.3%@S21  T=1.71s(data=1.6ms QKV=2.10s FFN=3.04s) eta=17:18:32 | 44.3K token/s | 
[Fuyou] head="4" update algorithm=4 t=12.09s
[Section@24500] layer[40-48] tasks=19(nPassBack=0) last_loss=3.29769(0.0322826) N=(772,28112,27552 3233868)
[epoch_0]_24501  loss=3.257320 |g|=0.387	lr=3.99e-04 | 7.1%@S21  T=4.50s(data=2.2ms QKV=2.10s FFN=3.03s) eta=1d 21:37:33 | 43.0K token/s | 
[epoch_0]_24511  loss=3.317136 |g|=0.376	lr=3.99e-04 | 7.9%@S21  T=1.69s(data=1.9ms QKV=2.10s FFN=3.04s) eta=17:10:56 | 43.3K token/s | 
[epoch_0]_24521  loss=3.252220 |g|=0.392	lr=3.98e-04 | 8.8%@S21  T=1.71s(data=1.7ms QKV=2.10s FFN=3.04s) eta=17:22:30 | 43.5K token/s | 
[epoch_0]_24531  loss=3.323703 |g|=0.376	lr=3.98e-04 | 9.6%@S21  T=1.70s(data=1.6ms QKV=2.10s FFN=3.04s) eta=17:13:36 | 43.8K token/s | 
[epoch_0]_24541  loss=3.237691 |g|=0.43	lr=3.98e-04 | 10.4%@S21  T=1.71s(data=1.5ms QKV=2.10s FFN=3.04s) eta=17:18:13 | 44.0K token/s | 
[epoch_0]_24551  loss=3.161962 |g|=0.402	lr=3.98e-04 | 11.2%@S21  T=1.69s(data=1.3ms QKV=2.10s FFN=3.04s) eta=17:09:13 | 44.2K token/s | 
[epoch_0]_24561  loss=3.261779 |g|=0.423	lr=3.98e-04 | 12.0%@S21  T=1.70s(data=1.7ms QKV=2.10s FFN=3.04s) eta=17:11:41 | 44.4K token/s | 
[epoch_0]_24571  loss=3.307114 |g|=0.391	lr=3.98e-04 | 12.9%@S21  T=1.76s(data=1.6ms QKV=2.10s FFN=3.04s) eta=17:50:31 | 44.5K token/s | 
[epoch_0]_24581  loss=3.313121 |g|=0.407	lr=3.98e-04 | 13.7%@S21  T=1.76s(data=1.7ms QKV=2.11s FFN=3.04s) eta=17:49:38 | 44.6K token/s | 
[epoch_0]_24591  loss=3.355818 |g|=0.394	lr=3.97e-04 | 14.5%@S21  T=1.76s(data=1.5ms QKV=2.10s FFN=3.04s) eta=17:49:38 | 44.7K token/s | 
[Fuyou] head="5" update algorithm=4 t=12.62s
[eval] 
	 Loss@"edu_fineweb1B"=3.293(0.015) nBranch=1 nToken=6.31M best=3.3074(121) E2T=0.0662 T=36.7064(0)s x=0
	#3.29262±0.0982 tps=172K(6.30784M) a=[3.09623,3.55915] T=36.7064(sec)
[Section@24600] layer[0-8] tasks=19(nPassBack=0) last_loss=3.22644(0.108564) N=(772,28224,27664 3247068)
[epoch_0]_24601  loss=3.273504 |g|=0.368	lr=3.97e-04 | 15.3%@S21  T=12.17s(data=1.7ms QKV=2.10s FFN=3.04s) eta=5d 03:08:57 | 42.8K token/s | 
[epoch_0]_24611  loss=3.283663 |g|=0.446	lr=3.97e-04 | 16.1%@S21  T=1.72s(data=1.7ms QKV=2.10s FFN=3.04s) eta=17:22:26 | 43.1K token/s | 
[epoch_0]_24621  loss=3.247546 |g|=0.394	lr=3.97e-04 | 17.0%@S21  T=1.75s(data=1.7ms QKV=2.10s FFN=3.04s) eta=17:44:26 | 43.2K token/s | 
[epoch_0]_24631  loss=3.232882 |g|=0.389	lr=3.97e-04 | 17.8%@S21  T=1.74s(data=1.7ms QKV=2.10s FFN=3.04s) eta=17:38:41 | 43.4K token/s | 
[epoch_0]_24641  loss=3.244911 |g|=0.388	lr=3.97e-04 | 18.6%@S21  T=1.73s(data=1.7ms QKV=2.10s FFN=3.04s) eta=17:30:37 | 43.6K token/s | 
[epoch_0]_24651  loss=3.302897 |g|=0.385	lr=3.97e-04 | 19.4%@S21  T=1.75s(data=1.6ms QKV=2.10s FFN=3.04s) eta=17:42:23 | 43.8K token/s | 
[epoch_0]_24661  loss=3.313025 |g|=0.414	lr=3.96e-04 | 20.2%@S21  T=1.78s(data=1.7ms QKV=2.10s FFN=3.04s) eta=17:58:11 | 43.9K token/s | 
[epoch_0]_24671  loss=3.316172 |g|=0.418	lr=3.96e-04 | 21.1%@S21  T=1.74s(data=1.7ms QKV=2.10s FFN=3.04s) eta=17:35:34 | 44.0K token/s | 
[epoch_0]_24681  loss=3.187304 |g|=0.415	lr=3.96e-04 | 21.9%@S21  T=1.77s(data=1.5ms QKV=2.10s FFN=3.04s) eta=17:51:33 | 44.2K token/s | 
[epoch_0]_24691  loss=3.299088 |g|=0.408	lr=3.96e-04 | 22.7%@S21  T=1.76s(data=1.7ms QKV=2.10s FFN=3.04s) eta=17:48:34 | 44.3K token/s | 
[Fuyou] head="0" update algorithm=4 t=11.77s
[Section@24700] layer[8-16] tasks=19(nPassBack=0) last_loss=3.33042(0.0112121) N=(772,28336,27776 3260268)
[epoch_0]_24701  loss=3.339064 |g|=0.392	lr=3.96e-04 | 23.5%@S21  T=4.35s(data=1.9ms QKV=2.10s FFN=3.04s) eta=1d 19:52:54 | 43.0K token/s | 
[epoch_0]_24711  loss=3.342040 |g|=0.397	lr=3.96e-04 | 24.3%@S21  T=1.69s(data=1.8ms QKV=2.10s FFN=3.04s) eta=17:05:12 | 43.3K token/s | 
[epoch_0]_24721  loss=3.302427 |g|=0.402	lr=3.96e-04 | 25.2%@S21  T=1.72s(data=1.9ms QKV=2.10s FFN=3.04s) eta=17:22:29 | 43.5K token/s | 
[epoch_0]_24731  loss=3.221699 |g|=0.372	lr=3.95e-04 | 26.0%@S21  T=1.70s(data=1.5ms QKV=2.10s FFN=3.04s) eta=17:10:59 | 43.7K token/s | 
[epoch_0]_24741  loss=3.236648 |g|=0.386	lr=3.95e-04 | 26.8%@S21  T=1.72s(data=1.5ms QKV=2.10s FFN=3.04s) eta=17:19:48 | 43.9K token/s | 
[epoch_0]_24751  loss=3.287883 |g|=0.399	lr=3.95e-04 | 27.6%@S21  T=1.69s(data=1.6ms QKV=2.10s FFN=3.04s) eta=17:02:28 | 44.1K token/s | 
[epoch_0]_24761  loss=3.303202 |g|=0.423	lr=3.95e-04 | 28.4%@S21  T=1.70s(data=1.8ms QKV=2.10s FFN=3.04s) eta=17:07:53 | 44.3K token/s | 
[epoch_0]_24771  loss=3.279501 |g|=0.404	lr=3.95e-04 | 29.2%@S21  T=1.72s(data=1.4ms QKV=2.10s FFN=3.04s) eta=17:17:35 | 44.5K token/s | 
[epoch_0]_24781  loss=3.201232 |g|=0.401	lr=3.95e-04 | 30.1%@S21  T=1.76s(data=1.5ms QKV=2.10s FFN=3.04s) eta=17:44:30 | 44.6K token/s | 
[epoch_0]_24791  loss=3.281660 |g|=0.388	lr=3.95e-04 | 30.9%@S21  T=1.77s(data=1.5ms QKV=2.10s FFN=3.04s) eta=17:48:31 | 44.7K token/s | 
[Fuyou] head="1" update algorithm=4 t=11.16s
[eval] 
	 Loss@"edu_fineweb1B"=3.289(0.0039) nBranch=1 nToken=6.31M best=3.2926(122) E2T=-0.0343 T=36.7274(0)s x=0
	#3.28868±0.0976 tps=172K(6.30784M) a=[3.09081,3.55282] T=36.7274(sec)
[Section@24800] layer[16-24] tasks=19(nPassBack=0) last_loss=3.32296(-0.0352745) N=(772,28448,27888 3273468)
[epoch_0]_24801  loss=3.390648 |g|=0.39	lr=3.94e-04 | 31.7%@S21  T=11.70s(data=1.5ms QKV=2.10s FFN=3.04s) eta=4d 21:46:58 | 42.8K token/s | 
[epoch_0]_24811  loss=3.292495 |g|=0.394	lr=3.94e-04 | 32.5%@S21  T=1.75s(data=1.5ms QKV=2.10s FFN=3.04s) eta=17:35:37 | 43.0K token/s | 
[epoch_0]_24821  loss=3.315942 |g|=0.39	lr=3.94e-04 | 33.3%@S21  T=1.71s(data=1.6ms QKV=2.10s FFN=3.04s) eta=17:10:29 | 43.3K token/s | 
[epoch_0]_24831  loss=3.300721 |g|=0.431	lr=3.94e-04 | 34.2%@S21  T=1.78s(data=2.0ms QKV=2.10s FFN=3.04s) eta=17:54:30 | 43.4K token/s | 
[epoch_0]_24841  loss=3.269214 |g|=0.421	lr=3.94e-04 | 35.0%@S21  T=1.77s(data=1.6ms QKV=2.11s FFN=3.04s) eta=17:45:03 | 43.5K token/s | 
[epoch_0]_24851  loss=3.278992 |g|=0.414	lr=3.94e-04 | 35.8%@S21  T=1.77s(data=1.7ms QKV=2.10s FFN=3.04s) eta=17:46:45 | 43.7K token/s | 
[epoch_0]_24861  loss=3.305242 |g|=0.403	lr=3.93e-04 | 36.6%@S21  T=1.77s(data=1.6ms QKV=2.10s FFN=3.04s) eta=17:49:11 | 43.8K token/s | 
[epoch_0]_24871  loss=3.272965 |g|=0.391	lr=3.93e-04 | 37.4%@S21  T=1.75s(data=1.6ms QKV=2.10s FFN=3.04s) eta=17:35:28 | 44.0K token/s | 
[epoch_0]_24881  loss=3.296196 |g|=0.391	lr=3.93e-04 | 38.3%@S21  T=1.74s(data=1.6ms QKV=2.10s FFN=3.04s) eta=17:27:43 | 44.1K token/s | 
[epoch_0]_24891  loss=3.322562 |g|=0.385	lr=3.93e-04 | 39.1%@S21  T=1.77s(data=1.6ms QKV=2.10s FFN=3.04s) eta=17:47:37 | 44.2K token/s | 
[Fuyou] head="2" update algorithm=4 t=10.91s
[Section@24900] layer[24-32] tasks=19(nPassBack=0) last_loss=3.27981(0.0306537) N=(772,28560,28000 3286668)
[epoch_0]_24901  loss=3.251529 |g|=0.357	lr=3.93e-04 | 39.9%@S21  T=4.23s(data=2.1ms QKV=2.10s FFN=3.03s) eta=1d 18:30:07 | 43.0K token/s | 
[epoch_0]_24911  loss=3.226493 |g|=0.4	lr=3.93e-04 | 40.7%@S21  T=1.78s(data=1.7ms QKV=2.10s FFN=3.04s) eta=17:49:16 | 43.1K token/s | 
[epoch_0]_24921  loss=3.180163 |g|=0.408	lr=3.93e-04 | 41.5%@S21  T=1.71s(data=1.6ms QKV=2.10s FFN=3.04s) eta=17:09:06 | 43.4K token/s | 
[epoch_0]_24931  loss=3.236220 |g|=0.377	lr=3.92e-04 | 42.4%@S21  T=1.76s(data=1.5ms QKV=2.10s FFN=3.04s) eta=17:41:12 | 43.5K token/s | 
[epoch_0]_24941  loss=3.264367 |g|=0.373	lr=3.92e-04 | 43.2%@S21  T=1.76s(data=1.8ms QKV=2.10s FFN=3.04s) eta=17:37:07 | 43.7K token/s | 
[epoch_0]_24951  loss=3.301718 |g|=0.423	lr=3.92e-04 | 44.0%@S21  T=1.76s(data=1.6ms QKV=2.10s FFN=3.04s) eta=17:40:49 | 43.8K token/s | 
[epoch_0]_24961  loss=3.307488 |g|=0.391	lr=3.92e-04 | 44.8%@S21  T=1.75s(data=2.2ms QKV=2.10s FFN=3.04s) eta=17:33:32 | 44.0K token/s | 
[epoch_0]_24971  loss=3.221637 |g|=0.427	lr=3.92e-04 | 45.6%@S21  T=1.74s(data=1.7ms QKV=2.10s FFN=3.04s) eta=17:27:16 | 44.1K token/s | 
[epoch_0]_24981  loss=3.279280 |g|=0.376	lr=3.92e-04 | 46.4%@S21  T=1.77s(data=1.5ms QKV=2.10s FFN=3.04s) eta=17:45:40 | 44.2K token/s | 
[epoch_0]_24991  loss=3.249522 |g|=0.416	lr=3.92e-04 | 47.3%@S21  T=1.78s(data=1.7ms QKV=2.10s FFN=3.04s) eta=17:47:07 | 44.3K token/s | 
[Fuyou] head="3" update algorithm=4 t=12.06s
[eval] 
	 Loss@"edu_fineweb1B"=3.286(0.0026) nBranch=1 nToken=6.31M best=3.2887(123) E2T=0.0712 T=36.7288(0)s x=0
	#3.28604±0.0987 tps=172K(6.30784M) a=[3.07696,3.55522] T=36.7288(sec)
[Section@25000] layer[32-40] tasks=19(nPassBack=0) last_loss=3.21485(0.0747223) N=(772,28672,28112 3299868)
[epoch_0]_25001  loss=3.277824 |g|=0.381	lr=3.91e-04 | 48.1%@S21  T=12.08s(data=1.8ms QKV=2.10s FFN=3.04s) eta=5d 00:54:23 | 42.4K token/s | 
[epoch_0]_25011  loss=3.315226 |g|=0.399	lr=3.91e-04 | 48.9%@S21  T=1.69s(data=1.7ms QKV=2.10s FFN=3.04s) eta=16:57:09 | 42.7K token/s | 
[epoch_0]_25021  loss=3.324559 |g|=0.399	lr=3.91e-04 | 49.7%@S21  T=1.72s(data=1.7ms QKV=2.10s FFN=3.04s) eta=17:14:08 | 43.0K token/s | 
[epoch_0]_25031  loss=3.260456 |g|=0.406	lr=3.91e-04 | 50.5%@S21  T=1.75s(data=2.8ms QKV=2.10s FFN=3.04s) eta=17:30:30 | 43.2K token/s | 
[epoch_0]_25041  loss=3.314010 |g|=0.398	lr=3.91e-04 | 51.4%@S21  T=1.77s(data=1.7ms QKV=2.10s FFN=3.04s) eta=17:43:46 | 43.3K token/s | 
[epoch_0]_25051  loss=3.256267 |g|=0.371	lr=3.91e-04 | 52.2%@S21  T=1.76s(data=1.6ms QKV=2.10s FFN=3.04s) eta=17:35:34 | 43.5K token/s | 
[epoch_0]_25061  loss=3.218924 |g|=0.378	lr=3.91e-04 | 53.0%@S21  T=1.78s(data=1.5ms QKV=2.10s FFN=3.04s) eta=17:45:47 | 43.6K token/s | 
[epoch_0]_25071  loss=3.223202 |g|=0.422	lr=3.90e-04 | 53.8%@S21  T=1.74s(data=1.9ms QKV=2.10s FFN=3.04s) eta=17:22:45 | 43.8K token/s | 
[epoch_0]_25081  loss=3.264586 |g|=0.402	lr=3.90e-04 | 54.6%@S21  T=1.75s(data=1.8ms QKV=2.10s FFN=3.04s) eta=17:29:27 | 43.9K token/s | 
[epoch_0]_25091  loss=3.313759 |g|=0.386	lr=3.90e-04 | 55.5%@S21  T=1.72s(data=1.8ms QKV=2.10s FFN=3.04s) eta=17:11:27 | 44.1K token/s | 
[Fuyou] head="4" update algorithm=4 t=11.90s
[Section@25100] layer[40-48] tasks=19(nPassBack=0) last_loss=3.26732(0.0303729) N=(772,28784,28224 3313068)
[epoch_0]_25101  loss=3.255839 |g|=0.387	lr=3.90e-04 | 56.3%@S21  T=4.05s(data=2.0ms QKV=2.10s FFN=3.03s) eta=1d 16:22:39 | 42.9K token/s | 
[epoch_0]_25111  loss=3.212267 |g|=0.403	lr=3.90e-04 | 57.1%@S21  T=1.75s(data=1.8ms QKV=2.10s FFN=3.04s) eta=17:29:33 | 43.1K token/s | 
[epoch_0]_25121  loss=3.263991 |g|=0.401	lr=3.90e-04 | 57.9%@S21  T=1.71s(data=1.9ms QKV=2.10s FFN=3.04s) eta=17:02:36 | 43.4K token/s | 
[epoch_0]_25131  loss=3.273748 |g|=0.412	lr=3.90e-04 | 58.7%@S21  T=1.72s(data=1.6ms QKV=2.10s FFN=3.04s) eta=17:10:14 | 43.6K token/s | 
[epoch_0]_25141  loss=3.276119 |g|=0.412	lr=3.89e-04 | 59.6%@S21  T=1.73s(data=1.6ms QKV=2.10s FFN=3.04s) eta=17:14:28 | 43.8K token/s | 
[epoch_0]_25151  loss=3.273941 |g|=0.407	lr=3.89e-04 | 60.4%@S21  T=1.76s(data=1.7ms QKV=2.10s FFN=3.04s) eta=17:35:05 | 43.9K token/s | 
[epoch_0]_25161  loss=3.231775 |g|=0.392	lr=3.89e-04 | 61.2%@S21  T=1.75s(data=1.8ms QKV=2.10s FFN=3.04s) eta=17:24:15 | 44.0K token/s | 
[epoch_0]_25171  loss=3.247428 |g|=0.411	lr=3.89e-04 | 62.0%@S21  T=1.79s(data=1.6ms QKV=2.10s FFN=3.04s) eta=17:49:24 | 44.1K token/s | 
[epoch_0]_25181  loss=3.214702 |g|=0.416	lr=3.89e-04 | 62.8%@S21  T=1.77s(data=1.6ms QKV=2.10s FFN=3.04s) eta=17:39:29 | 44.2K token/s | 
[epoch_0]_25191  loss=3.231863 |g|=0.404	lr=3.89e-04 | 63.7%@S21  T=1.77s(data=1.6ms QKV=2.10s FFN=3.04s) eta=17:39:30 | 44.3K token/s | 
[Fuyou] head="5" update algorithm=4 t=10.62s
[eval] 
	 Loss@"edu_fineweb1B"=3.281(0.0047) nBranch=1 nToken=6.31M best=3.2860(124) E2T=-0.0149 T=36.6991(0)s x=0
	#3.28139±0.0992 tps=172K(6.30784M) a=[3.06661,3.55303] T=36.6991(sec)
[Section@25200] layer[0-8] tasks=19(nPassBack=0) last_loss=3.29628(-0.0698385) N=(772,28896,28336 3326268)
[epoch_0]_25201  loss=3.296754 |g|=0.383	lr=3.88e-04 | 64.5%@S21  T=12.26s(data=2.1ms QKV=2.10s FFN=3.04s) eta=5d 02:03:49 | 42.4K token/s | 
[epoch_0]_25211  loss=3.240993 |g|=0.398	lr=3.88e-04 | 65.3%@S21  T=1.73s(data=1.6ms QKV=2.10s FFN=3.04s) eta=17:13:09 | 42.7K token/s | 
[epoch_0]_25221  loss=3.237017 |g|=0.413	lr=3.88e-04 | 66.1%@S21  T=1.76s(data=1.6ms QKV=2.10s FFN=3.04s) eta=17:28:45 | 42.9K token/s | 
[epoch_0]_25231  loss=3.245412 |g|=0.423	lr=3.88e-04 | 66.9%@S21  T=1.71s(data=1.9ms QKV=2.10s FFN=3.04s) eta=17:02:43 | 43.1K token/s | 
[epoch_0]_25241  loss=3.229107 |g|=0.42	lr=3.88e-04 | 67.7%@S21  T=1.76s(data=6.3ms QKV=2.10s FFN=3.04s) eta=17:32:53 | 43.3K token/s | 
[epoch_0]_25251  loss=3.354065 |g|=0.409	lr=3.88e-04 | 68.6%@S21  T=1.80s(data=1.8ms QKV=2.10s FFN=3.04s) eta=17:50:53 | 43.4K token/s | 
[epoch_0]_25261  loss=3.233526 |g|=0.399	lr=3.88e-04 | 69.4%@S21  T=1.72s(data=1.6ms QKV=2.10s FFN=3.04s) eta=17:04:18 | 43.6K token/s | 
[epoch_0]_25271  loss=3.280607 |g|=0.401	lr=3.87e-04 | 70.2%@S21  T=1.77s(data=1.6ms QKV=2.10s FFN=3.04s) eta=17:32:50 | 43.8K token/s | 
[epoch_0]_25281  loss=3.228498 |g|=0.394	lr=3.87e-04 | 71.0%@S21  T=1.76s(data=1.7ms QKV=2.10s FFN=3.04s) eta=17:29:06 | 43.9K token/s | 
[epoch_0]_25291  loss=3.302624 |g|=0.397	lr=3.87e-04 | 71.8%@S21  T=1.76s(data=1.6ms QKV=2.10s FFN=3.04s) eta=17:29:27 | 44.0K token/s | 
[Fuyou] head="0" update algorithm=4 t=10.92s
[Section@25300] layer[8-16] tasks=19(nPassBack=0) last_loss=3.27902(0.0514076) N=(772,29008,28448 3339468)
[epoch_0]_25301  loss=3.257358 |g|=0.382	lr=3.87e-04 | 72.7%@S21  T=4.59s(data=2.1ms QKV=2.10s FFN=3.03s) eta=1d 21:35:20 | 42.7K token/s | 
[epoch_0]_25311  loss=3.252967 |g|=0.392	lr=3.87e-04 | 73.5%@S21  T=1.70s(data=2.1ms QKV=2.10s FFN=3.04s) eta=16:54:56 | 43.0K token/s | 
[epoch_0]_25321  loss=3.252062 |g|=0.411	lr=3.87e-04 | 74.3%@S21  T=1.70s(data=2.1ms QKV=2.10s FFN=3.04s) eta=16:52:09 | 43.3K token/s | 
[epoch_0]_25331  loss=3.274917 |g|=0.406	lr=3.87e-04 | 75.1%@S21  T=1.71s(data=2.0ms QKV=2.10s FFN=3.04s) eta=16:58:27 | 43.5K token/s | 
[epoch_0]_25341  loss=3.247011 |g|=0.388	lr=3.86e-04 | 75.9%@S21  T=1.76s(data=1.7ms QKV=2.10s FFN=3.04s) eta=17:26:10 | 43.6K token/s | 
[epoch_0]_25351  loss=3.297480 |g|=0.387	lr=3.86e-04 | 76.8%@S21  T=1.72s(data=2.2ms QKV=2.10s FFN=3.04s) eta=17:05:03 | 43.8K token/s | 
[epoch_0]_25361  loss=3.260469 |g|=0.411	lr=3.86e-04 | 77.6%@S21  T=1.79s(data=1.8ms QKV=2.10s FFN=3.04s) eta=17:41:25 | 43.9K token/s | 
[epoch_0]_25371  loss=3.264948 |g|=0.407	lr=3.86e-04 | 78.4%@S21  T=1.74s(data=1.7ms QKV=2.10s FFN=3.04s) eta=17:11:34 | 44.1K token/s | 
[epoch_0]_25381  loss=3.195180 |g|=0.388	lr=3.86e-04 | 79.2%@S21  T=1.76s(data=1.6ms QKV=2.11s FFN=3.04s) eta=17:26:15 | 44.2K token/s | 
[epoch_0]_25391  loss=3.230737 |g|=0.395	lr=3.86e-04 | 80.0%@S21  T=1.72s(data=1.6ms QKV=2.10s FFN=3.04s) eta=17:02:56 | 44.4K token/s | 
[Fuyou] head="1" update algorithm=4 t=11.18s
[eval] 
	 Loss@"edu_fineweb1B"=3.278(0.0031) nBranch=1 nToken=6.31M best=3.2814(125) E2T=0.0714 T=36.7144(0)s x=0
	#3.2783±0.0990 tps=172K(6.30784M) a=[3.05787,3.5462] T=36.7144(sec)
[Section@25400] layer[16-24] tasks=19(nPassBack=0) last_loss=3.20688(0.116087) N=(772,29120,28560 3352668)
[epoch_0]_25401  loss=3.199553 |g|=0.378	lr=3.86e-04 | 80.9%@S21  T=11.87s(data=2.0ms QKV=2.10s FFN=3.04s) eta=4d 21:29:49 | 42.5K token/s | 
[epoch_0]_25411  loss=3.247537 |g|=0.396	lr=3.85e-04 | 81.7%@S21  T=1.77s(data=1.7ms QKV=2.10s FFN=3.04s) eta=17:29:01 | 42.7K token/s | 
[epoch_0]_25421  loss=3.327382 |g|=0.411	lr=3.85e-04 | 82.5%@S21  T=1.78s(data=1.8ms QKV=2.10s FFN=3.04s) eta=17:34:34 | 42.9K token/s | 
[epoch_0]_25431  loss=3.178715 |g|=0.407	lr=3.85e-04 | 83.3%@S21  T=1.78s(data=1.6ms QKV=2.10s FFN=3.04s) eta=17:36:26 | 43.0K token/s | 
[epoch_0]_25441  loss=3.261508 |g|=0.401	lr=3.85e-04 | 84.1%@S21  T=1.78s(data=1.6ms QKV=2.10s FFN=3.04s) eta=17:34:23 | 43.2K token/s | 
[epoch_0]_25451  loss=3.267654 |g|=0.393	lr=3.85e-04 | 85.0%@S21  T=1.76s(data=1.6ms QKV=2.10s FFN=3.04s) eta=17:25:58 | 43.3K token/s | 
[epoch_0]_25461  loss=3.266580 |g|=0.405	lr=3.85e-04 | 85.8%@S21  T=1.78s(data=1.6ms QKV=2.10s FFN=3.04s) eta=17:32:51 | 43.5K token/s | 
[epoch_0]_25471  loss=3.246511 |g|=0.4	lr=3.84e-04 | 86.6%@S21  T=1.75s(data=1.5ms QKV=2.10s FFN=3.04s) eta=17:19:48 | 43.6K token/s | 
[epoch_0]_25481  loss=3.269690 |g|=0.412	lr=3.84e-04 | 87.4%@S21  T=1.76s(data=1.5ms QKV=2.10s FFN=3.04s) eta=17:22:10 | 43.8K token/s | 
[epoch_0]_25491  loss=3.305551 |g|=0.391	lr=3.84e-04 | 88.2%@S21  T=1.78s(data=1.6ms QKV=2.11s FFN=3.04s) eta=17:35:24 | 43.9K token/s | 
[Fuyou] head="2" update algorithm=4 t=10.88s
[Section@25500] layer[24-32] tasks=19(nPassBack=0) last_loss=3.2788(0.00101137) N=(772,29232,28672 3365868)
[epoch_0]_25501  loss=3.192580 |g|=0.373	lr=3.84e-04 | 89.0%@S21  T=3.99s(data=1.9ms QKV=2.10s FFN=3.03s) eta=1d 15:24:40 | 42.7K token/s | 
[epoch_0]_25511  loss=3.198932 |g|=0.399	lr=3.84e-04 | 89.9%@S21  T=1.79s(data=1.6ms QKV=2.11s FFN=3.04s) eta=17:37:25 | 42.9K token/s | 
[epoch_0]_25521  loss=3.296347 |g|=0.378	lr=3.84e-04 | 90.7%@S21  T=1.73s(data=6.9ms QKV=2.11s FFN=3.04s) eta=17:02:51 | 43.1K token/s | 
[epoch_0]_25531  loss=3.219086 |g|=0.38	lr=3.84e-04 | 91.5%@S21  T=1.76s(data=2.0ms QKV=2.10s FFN=3.04s) eta=17:19:15 | 43.3K token/s | 
[epoch_0]_25541  loss=3.209569 |g|=0.406	lr=3.83e-04 | 92.3%@S21  T=1.76s(data=1.9ms QKV=2.11s FFN=3.04s) eta=17:23:20 | 43.5K token/s | 
[epoch_0]_25551  loss=3.298651 |g|=0.412	lr=3.83e-04 | 93.1%@S21  T=1.76s(data=1.6ms QKV=2.11s FFN=3.04s) eta=17:22:00 | 43.6K token/s | 
[epoch_0]_25561  loss=3.306818 |g|=0.398	lr=3.83e-04 | 94.0%@S21  T=1.78s(data=1.5ms QKV=2.11s FFN=3.04s) eta=17:32:06 | 43.7K token/s | 
[epoch_0]_25571  loss=3.258076 |g|=0.391	lr=3.83e-04 | 94.8%@S21  T=1.72s(data=2.1ms QKV=2.11s FFN=3.04s) eta=16:56:21 | 43.9K token/s | 
[epoch_0]_25581  loss=3.191539 |g|=0.405	lr=3.83e-04 | 95.6%@S21  T=1.76s(data=1.7ms QKV=2.11s FFN=3.04s) eta=17:21:33 | 44.0K token/s | 
[epoch_0]_25591  loss=3.240340 |g|=0.419	lr=3.83e-04 | 96.4%@S21  T=1.78s(data=1.6ms QKV=2.11s FFN=3.04s) eta=17:33:57 | 44.1K token/s | 
[Fuyou] head="3" update algorithm=4 t=11.62s
[eval] 
	 Loss@"edu_fineweb1B"=3.276(0.0022) nBranch=1 nToken=6.31M best=3.2783(126) E2T=0.0991 T=36.7381(0)s x=0
	#3.27608±0.0986 tps=172K(6.30784M) a=[3.06725,3.54842] T=36.7381(sec)
[Section@25600] layer[32-40] tasks=19(nPassBack=0) last_loss=3.17699(0.0378537) N=(772,29344,28784 3379068)
[epoch_0]_25601  loss=3.234175 |g|=0.388	lr=3.83e-04 | 97.2%@S21  T=12.09s(data=2.6ms QKV=2.10s FFN=3.04s) eta=4d 23:02:53 | 42.3K token/s | 
[epoch_0]_25611  loss=3.304858 |g|=0.369	lr=3.82e-04 | 98.1%@S21  T=1.76s(data=1.6ms QKV=2.10s FFN=3.04s) eta=17:19:44 | 42.5K token/s | 
[epoch_0]_25621  loss=3.263928 |g|=0.395	lr=3.82e-04 | 98.9%@S21  T=1.77s(data=1.6ms QKV=2.11s FFN=3.04s) eta=17:26:36 | 42.7K token/s | 
[epoch_0]_25631  loss=3.279156 |g|=0.42	lr=3.82e-04 | 99.7%@S21  T=1.73s(data=1.7ms QKV=2.11s FFN=3.04s) eta=17:03:05 | 42.9K token/s | 
[epoch_0]_25634  loss=3.325512 |g|=0.425	lr=3.82e-04 | 99.9%@S21  T=1.77s(data=1.6ms QKV=2.11s FFN=3.04s) eta=17:26:25 | 43.1K token/s | 
-------- End of shard_21@"./Datasets/edu_fineweb1B/edu_fineweb_train_000475.bin"-------- 
[shard-22]@"./Datasets/edu_fineweb1B/edu_fineweb_train_000476.bin": tokens=100(M) nShardSamples=1220(2148432) 
[epoch_0]_25641  loss=3.284416 |g|=0.382	lr=3.82e-04 | 0.5%@S22  T=1.78s(data=1.3ms QKV=2.11s FFN=3.04s) eta=17:31:03 | 43.2K token/s | 
[epoch_0]_25651  loss=3.326102 |g|=0.42	lr=3.82e-04 | 1.3%@S22  T=1.78s(data=1.3ms QKV=2.10s FFN=3.04s) eta=17:28:24 | 43.4K token/s | 
[epoch_0]_25661  loss=3.295029 |g|=0.409	lr=3.82e-04 | 2.2%@S22  T=1.76s(data=1.2ms QKV=2.10s FFN=3.04s) eta=17:19:17 | 43.5K token/s | 
[epoch_0]_25671  loss=3.359367 |g|=0.414	lr=3.82e-04 | 3.0%@S22  T=1.70s(data=1.3ms QKV=2.10s FFN=3.04s) eta=16:42:25 | 43.7K token/s | 
[epoch_0]_25681  loss=3.262074 |g|=0.403	lr=3.81e-04 | 3.8%@S22  T=1.77s(data=1.2ms QKV=2.10s FFN=3.04s) eta=17:20:30 | 43.9K token/s | 
[epoch_0]_25691  loss=3.286676 |g|=0.402	lr=3.81e-04 | 4.6%@S22  T=1.77s(data=1.2ms QKV=2.11s FFN=3.04s) eta=17:24:32 | 44.0K token/s | 
[Fuyou] head="4" update algorithm=4 t=11.57s
[Section@25700] layer[40-48] tasks=19(nPassBack=0) last_loss=3.30758(-0.0402648) N=(772,29456,28896 3392268)
[epoch_0]_25701  loss=3.290158 |g|=0.379	lr=3.81e-04 | 5.4%@S22  T=4.03s(data=2.0ms QKV=2.10s FFN=3.03s) eta=1d 15:35:54 | 42.8K token/s | 
[epoch_0]_25711  loss=3.225458 |g|=0.397	lr=3.81e-04 | 6.3%@S22  T=1.75s(data=1.5ms QKV=2.10s FFN=3.04s) eta=17:10:03 | 43.0K token/s | 
[epoch_0]_25721  loss=3.389518 |g|=0.4	lr=3.81e-04 | 7.1%@S22  T=1.75s(data=1.6ms QKV=2.11s FFN=3.04s) eta=17:12:46 | 43.2K token/s | 
[epoch_0]_25731  loss=3.307718 |g|=0.401	lr=3.81e-04 | 7.9%@S22  T=1.76s(data=1.8ms QKV=2.10s FFN=3.04s) eta=17:16:37 | 43.4K token/s | 
[epoch_0]_25741  loss=3.368814 |g|=0.399	lr=3.80e-04 | 8.7%@S22  T=1.76s(data=1.8ms QKV=2.10s FFN=3.04s) eta=17:15:02 | 43.5K token/s | 
[epoch_0]_25751  loss=3.291953 |g|=0.381	lr=3.80e-04 | 9.5%@S22  T=1.76s(data=2.0ms QKV=2.11s FFN=3.04s) eta=17:14:38 | 43.7K token/s | 
[epoch_0]_25761  loss=3.312868 |g|=0.448	lr=3.80e-04 | 10.3%@S22  T=1.76s(data=1.8ms QKV=2.10s FFN=3.04s) eta=17:16:04 | 43.8K token/s | 
[epoch_0]_25771  loss=3.310133 |g|=0.385	lr=3.80e-04 | 11.2%@S22  T=1.77s(data=1.3ms QKV=2.10s FFN=3.04s) eta=17:22:45 | 43.9K token/s | 
[epoch_0]_25781  loss=3.238415 |g|=0.401	lr=3.80e-04 | 12.0%@S22  T=1.77s(data=1.5ms QKV=2.10s FFN=3.04s) eta=17:21:34 | 44.0K token/s | 
[epoch_0]_25791  loss=3.266067 |g|=0.397	lr=3.80e-04 | 12.8%@S22  T=1.73s(data=2.0ms QKV=2.10s FFN=3.04s) eta=16:57:24 | 44.2K token/s | 
[Fuyou] head="5" update algorithm=4 t=12.23s
[eval] 
	 Loss@"edu_fineweb1B"=3.282(-0.0056) nBranch=1 nToken=6.31M best=3.2783(126) E2T=-0.00397 T=36.7184(0)s x=0
	#3.28168±0.0989 tps=172K(6.30784M) a=[3.07888,3.55416] T=36.7184(sec)
[Section@25800] layer[0-8] tasks=19(nPassBack=0) last_loss=3.28565(0.0106273) N=(772,29568,29008 3405468)
[epoch_0]_25801  loss=3.336725 |g|=0.39	lr=3.80e-04 | 13.6%@S22  T=11.78s(data=1.8ms QKV=2.10s FFN=3.04s) eta=4d 19:15:16 | 42.3K token/s | 
[epoch_0]_25811  loss=3.283566 |g|=0.411	lr=3.79e-04 | 14.4%@S22  T=1.70s(data=1.5ms QKV=2.10s FFN=3.04s) eta=16:39:28 | 42.6K token/s | 
[epoch_0]_25821  loss=3.288186 |g|=0.387	lr=3.79e-04 | 15.3%@S22  T=1.74s(data=1.8ms QKV=2.10s FFN=3.04s) eta=17:01:01 | 42.9K token/s | 
[epoch_0]_25831  loss=3.262043 |g|=0.401	lr=3.79e-04 | 16.1%@S22  T=1.75s(data=1.6ms QKV=2.10s FFN=3.04s) eta=17:04:27 | 43.1K token/s | 
[epoch_0]_25841  loss=3.213137 |g|=0.386	lr=3.79e-04 | 16.9%@S22  T=1.78s(data=2.0ms QKV=2.10s FFN=3.04s) eta=17:24:29 | 43.2K token/s | 
[epoch_0]_25851  loss=3.274870 |g|=0.421	lr=3.79e-04 | 17.7%@S22  T=1.76s(data=1.6ms QKV=2.10s FFN=3.04s) eta=17:12:06 | 43.4K token/s | 
[epoch_0]_25861  loss=3.275178 |g|=0.413	lr=3.79e-04 | 18.5%@S22  T=1.77s(data=1.8ms QKV=2.10s FFN=3.04s) eta=17:20:05 | 43.5K token/s | 
[epoch_0]_25871  loss=3.249569 |g|=0.389	lr=3.79e-04 | 19.4%@S22  T=1.77s(data=1.6ms QKV=2.10s FFN=3.04s) eta=17:17:18 | 43.7K token/s | 
[epoch_0]_25881  loss=3.312849 |g|=0.391	lr=3.78e-04 | 20.2%@S22  T=1.77s(data=1.6ms QKV=2.10s FFN=3.04s) eta=17:18:56 | 43.8K token/s | 
[epoch_0]_25891  loss=3.306223 |g|=0.375	lr=3.78e-04 | 21.0%@S22  T=1.77s(data=1.6ms QKV=2.11s FFN=3.04s) eta=17:18:14 | 43.9K token/s | 
[Fuyou] head="0" update algorithm=4 t=10.96s
[Section@25900] layer[8-16] tasks=19(nPassBack=0) last_loss=3.30638(-0.0273678) N=(772,29680,29120 3418668)
[epoch_0]_25901  loss=3.302374 |g|=0.376	lr=3.78e-04 | 21.8%@S22  T=4.21s(data=1.6ms QKV=2.10s FFN=3.03s) eta=1d 17:03:10 | 42.7K token/s | 
[epoch_0]_25911  loss=3.231830 |g|=0.404	lr=3.78e-04 | 22.6%@S22  T=1.72s(data=1.5ms QKV=2.10s FFN=3.04s) eta=16:47:41 | 42.9K token/s | 
[epoch_0]_25921  loss=3.253409 |g|=0.398	lr=3.78e-04 | 23.5%@S22  T=1.75s(data=1.5ms QKV=2.10s FFN=3.04s) eta=17:02:42 | 43.1K token/s | 
[epoch_0]_25931  loss=3.314598 |g|=0.391	lr=3.78e-04 | 24.3%@S22  T=1.75s(data=1.9ms QKV=2.11s FFN=3.04s) eta=17:04:36 | 43.3K token/s | 
[epoch_0]_25941  loss=3.286427 |g|=0.401	lr=3.77e-04 | 25.1%@S22  T=1.77s(data=1.6ms QKV=2.11s FFN=3.04s) eta=17:16:21 | 43.5K token/s | 
[epoch_0]_25951  loss=3.245171 |g|=0.398	lr=3.77e-04 | 25.9%@S22  T=1.78s(data=1.4ms QKV=2.11s FFN=3.04s) eta=17:23:01 | 43.6K token/s | 
[epoch_0]_25961  loss=3.288667 |g|=0.39	lr=3.77e-04 | 26.7%@S22  T=1.76s(data=7.5ms QKV=2.11s FFN=3.04s) eta=17:09:40 | 43.7K token/s | 
[epoch_0]_25971  loss=3.251992 |g|=0.382	lr=3.77e-04 | 27.6%@S22  T=1.78s(data=1.4ms QKV=2.11s FFN=3.04s) eta=17:19:51 | 43.8K token/s | 
[epoch_0]_25981  loss=3.263556 |g|=0.387	lr=3.77e-04 | 28.4%@S22  T=1.71s(data=1.9ms QKV=2.11s FFN=3.04s) eta=16:39:10 | 44.0K token/s | 
[epoch_0]_25991  loss=3.383308 |g|=0.403	lr=3.77e-04 | 29.2%@S22  T=1.78s(data=1.4ms QKV=2.11s FFN=3.04s) eta=17:16:52 | 44.1K token/s | 
[Fuyou] head="1" update algorithm=4 t=8.89s
[eval] 
	 Loss@"edu_fineweb1B"=3.281(0.00046) nBranch=1 nToken=6.31M best=3.2783(126) E2T=-0.00162 T=36.7321(0)s x=0
	#3.28122±0.0988 tps=172K(6.30784M) a=[3.08109,3.55543] T=36.7321(sec)
[Section@26000] layer[16-24] tasks=19(nPassBack=0) last_loss=3.28284(-0.0759628) N=(772,29792,29232 3431868)
[epoch_0]_26001  loss=3.245017 |g|=0.381	lr=3.77e-04 | 30.0%@S22  T=12.18s(data=1.9ms QKV=2.10s FFN=3.03s) eta=4d 22:33:35 | 42.3K token/s | 
[epoch_0]_26011  loss=3.317630 |g|=0.413	lr=3.76e-04 | 30.8%@S22  T=1.77s(data=1.6ms QKV=2.10s FFN=3.04s) eta=17:15:07 | 42.5K token/s | 
[epoch_0]_26021  loss=3.234628 |g|=0.413	lr=3.76e-04 | 31.6%@S22  T=1.77s(data=1.7ms QKV=2.11s FFN=3.04s) eta=17:10:32 | 42.7K token/s | 
[epoch_0]_26031  loss=3.273179 |g|=0.401	lr=3.76e-04 | 32.5%@S22  T=1.78s(data=1.9ms QKV=2.10s FFN=3.04s) eta=17:15:39 | 42.8K token/s | 
[epoch_0]_26041  loss=3.252478 |g|=0.414	lr=3.76e-04 | 33.3%@S22  T=1.76s(data=1.5ms QKV=2.11s FFN=3.04s) eta=17:05:19 | 43.0K token/s | 
[epoch_0]_26051  loss=3.338628 |g|=0.391	lr=3.76e-04 | 34.1%@S22  T=1.76s(data=1.7ms QKV=2.11s FFN=3.04s) eta=17:08:57 | 43.2K token/s | 
[epoch_0]_26061  loss=3.264118 |g|=0.394	lr=3.76e-04 | 34.9%@S22  T=1.72s(data=1.9ms QKV=2.10s FFN=3.04s) eta=16:44:24 | 43.4K token/s | 
[epoch_0]_26071  loss=3.297189 |g|=0.405	lr=3.76e-04 | 35.7%@S22  T=1.76s(data=1.6ms QKV=2.11s FFN=3.04s) eta=17:06:36 | 43.6K token/s | 
[epoch_0]_26081  loss=3.282078 |g|=0.401	lr=3.75e-04 | 36.6%@S22  T=1.77s(data=1.6ms QKV=2.11s FFN=3.04s) eta=17:13:54 | 43.7K token/s | 
[epoch_0]_26091  loss=3.249028 |g|=0.396	lr=3.75e-04 | 37.4%@S22  T=1.76s(data=1.6ms QKV=2.10s FFN=3.04s) eta=17:03:29 | 43.8K token/s | 
[Fuyou] head="2" update algorithm=4 t=10.76s
[Section@26100] layer[24-32] tasks=19(nPassBack=0) last_loss=3.30147(-0.0226693) N=(772,29904,29344 3445068)
[epoch_0]_26101  loss=3.248869 |g|=0.377	lr=3.75e-04 | 38.2%@S22  T=4.13s(data=1.9ms QKV=2.10s FFN=3.03s) eta=1d 16:02:59 | 42.6K token/s | 
[epoch_0]_26111  loss=3.241557 |g|=0.392	lr=3.75e-04 | 39.0%@S22  T=1.77s(data=1.5ms QKV=2.11s FFN=3.04s) eta=17:11:10 | 42.8K token/s | 
[epoch_0]_26121  loss=3.286580 |g|=0.399	lr=3.75e-04 | 39.8%@S22  T=1.71s(data=1.8ms QKV=2.11s FFN=3.04s) eta=16:35:25 | 43.1K token/s | 
[epoch_0]_26131  loss=3.361254 |g|=0.394	lr=3.75e-04 | 40.7%@S22  T=1.78s(data=2.2ms QKV=2.11s FFN=3.04s) eta=17:14:32 | 43.2K token/s | 
[epoch_0]_26141  loss=3.305623 |g|=0.377	lr=3.74e-04 | 41.5%@S22  T=1.76s(data=1.6ms QKV=2.11s FFN=3.04s) eta=17:03:32 | 43.4K token/s | 
[epoch_0]_26151  loss=3.225236 |g|=0.391	lr=3.74e-04 | 42.3%@S22  T=1.76s(data=1.4ms QKV=2.11s FFN=3.04s) eta=17:05:02 | 43.5K token/s | 
[epoch_0]_26161  loss=3.269942 |g|=0.392	lr=3.74e-04 | 43.1%@S22  T=1.76s(data=1.5ms QKV=2.11s FFN=3.04s) eta=17:01:45 | 43.7K token/s | 
[epoch_0]_26171  loss=3.340534 |g|=0.427	lr=3.74e-04 | 43.9%@S22  T=1.77s(data=1.5ms QKV=2.11s FFN=3.04s) eta=17:06:26 | 43.8K token/s | 
[epoch_0]_26181  loss=3.285827 |g|=0.419	lr=3.74e-04 | 44.8%@S22  T=1.78s(data=1.5ms QKV=2.11s FFN=3.04s) eta=17:14:30 | 43.9K token/s | 
[epoch_0]_26191  loss=3.232123 |g|=0.379	lr=3.74e-04 | 45.6%@S22  T=1.72s(data=1.7ms QKV=2.11s FFN=3.04s) eta=16:41:28 | 44.1K token/s | 
[Fuyou] head="3" update algorithm=4 t=11.48s
[eval] 
	 Loss@"edu_fineweb1B"=3.282(-0.001) nBranch=1 nToken=6.31M best=3.2783(126) E2T=-0.00136 T=36.7351(0)s x=0
	#3.28224±0.0995 tps=172K(6.30784M) a=[3.08292,3.55568] T=36.7351(sec)
[Section@26200] layer[32-40] tasks=19(nPassBack=0) last_loss=3.28361(-0.106614) N=(772,30016,29456 3458268)
[epoch_0]_26201  loss=3.326228 |g|=0.38	lr=3.74e-04 | 46.4%@S22  T=11.86s(data=1.9ms QKV=2.11s FFN=3.04s) eta=4d 18:43:12 | 42.3K token/s | 
[epoch_0]_26211  loss=3.332616 |g|=0.399	lr=3.73e-04 | 47.2%@S22  T=1.74s(data=2.0ms QKV=2.11s FFN=3.04s) eta=16:51:11 | 42.5K token/s | 
[epoch_0]_26221  loss=3.227113 |g|=0.416	lr=3.73e-04 | 48.0%@S22  T=1.79s(data=1.8ms QKV=2.11s FFN=3.04s) eta=17:19:30 | 42.7K token/s | 
[epoch_0]_26231  loss=3.256583 |g|=0.375	lr=3.73e-04 | 48.9%@S22  T=1.79s(data=1.6ms QKV=2.11s FFN=3.04s) eta=17:16:04 | 42.8K token/s | 
[epoch_0]_26241  loss=3.173220 |g|=0.391	lr=3.73e-04 | 49.7%@S22  T=1.79s(data=1.5ms QKV=2.11s FFN=3.04s) eta=17:20:12 | 43.0K token/s | 
[epoch_0]_26251  loss=3.247812 |g|=0.385	lr=3.73e-04 | 50.5%@S22  T=1.78s(data=1.6ms QKV=2.11s FFN=3.04s) eta=17:10:00 | 43.1K token/s | 
[epoch_0]_26261  loss=3.267359 |g|=0.402	lr=3.73e-04 | 51.3%@S22  T=1.76s(data=1.6ms QKV=2.11s FFN=3.04s) eta=17:02:08 | 43.3K token/s | 
[epoch_0]_26271  loss=3.229742 |g|=0.402	lr=3.73e-04 | 52.1%@S22  T=1.79s(data=1.6ms QKV=2.11s FFN=3.05s) eta=17:16:51 | 43.4K token/s | 
[epoch_0]_26281  loss=3.221734 |g|=0.414	lr=3.72e-04 | 52.9%@S22  T=1.70s(data=1.7ms QKV=2.11s FFN=3.04s) eta=16:27:00 | 43.6K token/s | 
[epoch_0]_26291  loss=3.226327 |g|=0.391	lr=3.72e-04 | 53.8%@S22  T=1.71s(data=1.6ms QKV=2.11s FFN=3.04s) eta=16:29:19 | 43.9K token/s | 
[Fuyou] head="4" update algorithm=4 t=11.79s
[Section@26300] layer[40-48] tasks=19(nPassBack=0) last_loss=3.28997(0.0176065) N=(772,30128,29568 3471468)
[epoch_0]_26301  loss=3.344047 |g|=0.373	lr=3.72e-04 | 54.6%@S22  T=4.29s(data=1.9ms QKV=2.10s FFN=3.04s) eta=1d 17:24:56 | 42.6K token/s | 
[epoch_0]_26311  loss=3.257703 |g|=0.412	lr=3.72e-04 | 55.4%@S22  T=1.72s(data=2.0ms QKV=2.11s FFN=3.04s) eta=16:34:50 | 42.9K token/s | 
[epoch_0]_26321  loss=3.288113 |g|=0.415	lr=3.72e-04 | 56.2%@S22  T=1.77s(data=1.6ms QKV=2.11s FFN=3.04s) eta=17:04:12 | 43.0K token/s | 
[epoch_0]_26331  loss=3.237026 |g|=0.379	lr=3.72e-04 | 57.0%@S22  T=1.78s(data=1.8ms QKV=2.11s FFN=3.04s) eta=17:10:30 | 43.2K token/s | 
[epoch_0]_26341  loss=3.282368 |g|=0.389	lr=3.71e-04 | 57.9%@S22  T=1.72s(data=1.6ms QKV=2.11s FFN=3.04s) eta=16:33:35 | 43.4K token/s | 
[epoch_0]_26351  loss=3.232017 |g|=0.415	lr=3.71e-04 | 58.7%@S22  T=1.72s(data=1.9ms QKV=2.11s FFN=3.04s) eta=16:31:44 | 43.6K token/s | 
[epoch_0]_26361  loss=3.266039 |g|=0.421	lr=3.71e-04 | 59.5%@S22  T=1.79s(data=2.1ms QKV=2.11s FFN=3.04s) eta=17:14:14 | 43.7K token/s | 
[epoch_0]_26371  loss=3.336434 |g|=0.407	lr=3.71e-04 | 60.3%@S22  T=1.76s(data=1.6ms QKV=2.11s FFN=3.04s) eta=16:56:54 | 43.9K token/s | 
[epoch_0]_26381  loss=3.275340 |g|=0.4	lr=3.71e-04 | 61.1%@S22  T=1.76s(data=1.6ms QKV=2.11s FFN=3.04s) eta=16:57:41 | 44.0K token/s | 
[epoch_0]_26391  loss=3.342055 |g|=0.406	lr=3.71e-04 | 62.0%@S22  T=1.74s(data=1.9ms QKV=2.11s FFN=3.04s) eta=16:45:08 | 44.2K token/s | 
[Fuyou] head="5" update algorithm=4 t=12.25s
[eval] 
	 Loss@"edu_fineweb1B"=3.280(0.0018) nBranch=1 nToken=6.31M best=3.2783(126) E2T=-0.0159 T=36.7278(0)s x=0
	#3.28041±0.0986 tps=172K(6.30784M) a=[3.08557,3.54931] T=36.7278(sec)
[Section@26400] layer[0-8] tasks=19(nPassBack=0) last_loss=3.29632(-0.0106673) N=(772,30240,29680 3484668)
[epoch_0]_26401  loss=3.264734 |g|=0.366	lr=3.71e-04 | 62.8%@S22  T=12.08s(data=2.0ms QKV=2.10s FFN=3.04s) eta=4d 20:15:31 | 42.3K token/s | 
[epoch_0]_26411  loss=3.306006 |g|=0.412	lr=3.70e-04 | 63.6%@S22  T=1.77s(data=1.6ms QKV=2.10s FFN=3.04s) eta=17:00:51 | 42.5K token/s | 
[epoch_0]_26421  loss=3.280770 |g|=0.418	lr=3.70e-04 | 64.4%@S22  T=1.76s(data=1.9ms QKV=2.11s FFN=3.04s) eta=16:54:31 | 42.7K token/s | 
[epoch_0]_26431  loss=3.223769 |g|=0.399	lr=3.70e-04 | 65.2%@S22  T=1.76s(data=1.6ms QKV=2.11s FFN=3.04s) eta=16:54:01 | 42.9K token/s | 
[epoch_0]_26441  loss=3.257297 |g|=0.402	lr=3.70e-04 | 66.1%@S22  T=1.77s(data=1.6ms QKV=2.11s FFN=3.04s) eta=17:01:36 | 43.1K token/s | 
[epoch_0]_26451  loss=3.271414 |g|=0.389	lr=3.70e-04 | 66.9%@S22  T=1.77s(data=1.6ms QKV=2.11s FFN=3.04s) eta=17:01:45 | 43.2K token/s | 
[epoch_0]_26461  loss=3.258172 |g|=0.38	lr=3.70e-04 | 67.7%@S22  T=1.78s(data=1.6ms QKV=2.11s FFN=3.04s) eta=17:03:07 | 43.4K token/s | 
[epoch_0]_26471  loss=3.243712 |g|=0.421	lr=3.70e-04 | 68.5%@S22  T=1.78s(data=1.7ms QKV=2.11s FFN=3.04s) eta=17:06:45 | 43.5K token/s | 
[epoch_0]_26481  loss=3.392584 |g|=0.403	lr=3.69e-04 | 69.3%@S22  T=1.76s(data=1.5ms QKV=2.11s FFN=3.04s) eta=16:51:53 | 43.6K token/s | 
[epoch_0]_26491  loss=3.289875 |g|=0.411	lr=3.69e-04 | 70.1%@S22  T=1.71s(data=1.5ms QKV=2.11s FFN=3.04s) eta=16:22:30 | 43.9K token/s | 
[Fuyou] head="0" update algorithm=4 t=11.20s
[Section@26500] layer[8-16] tasks=19(nPassBack=0) last_loss=3.33974(-0.0333545) N=(772,30352,29792 3497868)
[epoch_0]_26501  loss=3.295017 |g|=0.386	lr=3.69e-04 | 71.0%@S22  T=4.24s(data=2.1ms QKV=2.10s FFN=3.04s) eta=1d 16:43:12 | 42.6K token/s | 
[epoch_0]_26511  loss=3.268899 |g|=0.38	lr=3.69e-04 | 71.8%@S22  T=1.70s(data=1.9ms QKV=2.10s FFN=3.04s) eta=16:18:47 | 42.9K token/s | 
[epoch_0]_26521  loss=3.241318 |g|=0.397	lr=3.69e-04 | 72.6%@S22  T=1.71s(data=1.8ms QKV=2.10s FFN=3.04s) eta=16:25:46 | 43.2K token/s | 
[epoch_0]_26531  loss=3.268587 |g|=0.455	lr=3.69e-04 | 73.4%@S22  T=1.73s(data=1.8ms QKV=2.11s FFN=3.04s) eta=16:36:01 | 43.4K token/s | 
[epoch_0]_26541  loss=3.189485 |g|=0.407	lr=3.68e-04 | 74.2%@S22  T=1.76s(data=1.5ms QKV=2.11s FFN=3.04s) eta=16:51:00 | 43.5K token/s | 
[epoch_0]_26551  loss=3.351019 |g|=0.43	lr=3.68e-04 | 75.1%@S22  T=1.72s(data=1.8ms QKV=2.11s FFN=3.04s) eta=16:28:37 | 43.7K token/s | 
[epoch_0]_26561  loss=3.277658 |g|=0.404	lr=3.68e-04 | 75.9%@S22  T=1.78s(data=1.7ms QKV=2.11s FFN=3.04s) eta=17:00:34 | 43.9K token/s | 
[epoch_0]_26571  loss=3.279726 |g|=0.393	lr=3.68e-04 | 76.7%@S22  T=1.79s(data=1.5ms QKV=2.11s FFN=3.04s) eta=17:05:33 | 44.0K token/s | 
[epoch_0]_26581  loss=3.248752 |g|=0.432	lr=3.68e-04 | 77.5%@S22  T=1.76s(data=1.5ms QKV=2.11s FFN=3.04s) eta=16:50:21 | 44.1K token/s | 
[epoch_0]_26591  loss=3.263444 |g|=0.407	lr=3.68e-04 | 78.3%@S22  T=1.78s(data=1.6ms QKV=2.11s FFN=3.04s) eta=17:03:53 | 44.2K token/s | 
[Fuyou] head="1" update algorithm=4 t=9.30s
[eval] 
	 Loss@"edu_fineweb1B"=3.281(-0.00044) nBranch=1 nToken=6.31M best=3.2783(126) E2T=-0.000315 T=36.7588(0)s x=0
	#3.28085±0.0988 tps=172K(6.30784M) a=[3.08504,3.55489] T=36.7588(sec)
[Section@26600] layer[16-24] tasks=19(nPassBack=0) last_loss=3.28117(0.00167084) N=(772,30464,29904 3511068)
[epoch_0]_26601  loss=3.263019 |g|=0.392	lr=3.68e-04 | 79.2%@S22  T=11.85s(data=7.7ms QKV=2.11s FFN=3.04s) eta=4d 17:19:56 | 42.3K token/s | 
[epoch_0]_26611  loss=3.258842 |g|=0.438	lr=3.67e-04 | 80.0%@S22  T=1.70s(data=1.9ms QKV=2.10s FFN=3.04s) eta=16:17:42 | 42.6K token/s | 
[epoch_0]_26621  loss=3.283255 |g|=0.405	lr=3.67e-04 | 80.8%@S22  T=1.72s(data=2.2ms QKV=2.10s FFN=3.04s) eta=16:23:59 | 42.9K token/s | 
[epoch_0]_26631  loss=3.244447 |g|=0.418	lr=3.67e-04 | 81.6%@S22  T=1.77s(data=1.6ms QKV=2.10s FFN=3.04s) eta=16:54:57 | 43.0K token/s | 
[epoch_0]_26641  loss=3.288509 |g|=0.392	lr=3.67e-04 | 82.4%@S22  T=1.77s(data=1.7ms QKV=2.10s FFN=3.04s) eta=16:53:10 | 43.2K token/s | 
[epoch_0]_26651  loss=3.290767 |g|=0.402	lr=3.67e-04 | 83.3%@S22  T=1.76s(data=2.0ms QKV=2.11s FFN=3.04s) eta=16:49:45 | 43.4K token/s | 
[epoch_0]_26661  loss=3.312682 |g|=0.409	lr=3.67e-04 | 84.1%@S22  T=1.80s(data=6.3ms QKV=2.11s FFN=3.04s) eta=17:12:04 | 43.5K token/s | 
[epoch_0]_26671  loss=3.255333 |g|=0.381	lr=3.67e-04 | 84.9%@S22  T=1.76s(data=1.7ms QKV=2.10s FFN=3.04s) eta=16:47:18 | 43.6K token/s | 
[epoch_0]_26681  loss=3.351046 |g|=0.386	lr=3.66e-04 | 85.7%@S22  T=1.76s(data=1.5ms QKV=2.10s FFN=3.04s) eta=16:47:55 | 43.8K token/s | 
[epoch_0]_26691  loss=3.332607 |g|=0.394	lr=3.66e-04 | 86.5%@S22  T=1.75s(data=1.7ms QKV=2.10s FFN=3.04s) eta=16:42:56 | 43.9K token/s | 
[Fuyou] head="2" update algorithm=4 t=10.66s
[Section@26700] layer[24-32] tasks=19(nPassBack=0) last_loss=3.31723(-0.0157633) N=(772,30576,30016 3524268)
[epoch_0]_26701  loss=3.283763 |g|=0.4	lr=3.66e-04 | 87.4%@S22  T=4.69s(data=2.3ms QKV=2.10s FFN=3.04s) eta=1d 20:42:41 | 42.6K token/s | 
[epoch_0]_26711  loss=3.269558 |g|=0.41	lr=3.66e-04 | 88.2%@S22  T=1.77s(data=1.6ms QKV=2.11s FFN=3.04s) eta=16:51:52 | 42.8K token/s | 
[epoch_0]_26721  loss=3.251380 |g|=0.389	lr=3.66e-04 | 89.0%@S22  T=1.76s(data=1.9ms QKV=2.11s FFN=3.04s) eta=16:47:27 | 43.0K token/s | 
[epoch_0]_26731  loss=3.257365 |g|=0.412	lr=3.66e-04 | 89.8%@S22  T=1.78s(data=1.5ms QKV=2.11s FFN=3.04s) eta=16:56:41 | 43.1K token/s | 
[epoch_0]_26741  loss=3.308523 |g|=0.403	lr=3.65e-04 | 90.6%@S22  T=1.76s(data=2.2ms QKV=2.10s FFN=3.04s) eta=16:48:39 | 43.3K token/s | 
[epoch_0]_26751  loss=3.235371 |g|=0.396	lr=3.65e-04 | 91.4%@S22  T=1.78s(data=1.6ms QKV=2.11s FFN=3.04s) eta=16:58:35 | 43.4K token/s | 
[epoch_0]_26761  loss=3.242237 |g|=0.411	lr=3.65e-04 | 92.3%@S22  T=1.78s(data=1.6ms QKV=2.10s FFN=3.04s) eta=16:54:23 | 43.6K token/s | 
[epoch_0]_26771  loss=3.278897 |g|=0.451	lr=3.65e-04 | 93.1%@S22  T=1.82s(data=1.5ms QKV=2.11s FFN=3.04s) eta=17:16:35 | 43.6K token/s | 
[epoch_0]_26781  loss=3.228122 |g|=0.428	lr=3.65e-04 | 93.9%@S22  T=1.78s(data=1.5ms QKV=2.10s FFN=3.04s) eta=16:56:50 | 43.8K token/s | 
[epoch_0]_26791  loss=3.286896 |g|=0.405	lr=3.65e-04 | 94.7%@S22  T=1.78s(data=1.5ms QKV=2.11s FFN=3.04s) eta=16:56:06 | 43.9K token/s | 
[Fuyou] head="3" update algorithm=4 t=11.39s
[eval] 
	 Loss@"edu_fineweb1B"=3.280(0.00064) nBranch=1 nToken=6.31M best=3.2783(126) E2T=0.0216 T=36.7576(0)s x=0
	#3.28022±0.0991 tps=172K(6.30784M) a=[3.08455,3.5535] T=36.7576(sec)
[Section@26800] layer[32-40] tasks=19(nPassBack=0) last_loss=3.25865(0.0249596) N=(772,30688,30128 3537468)
[epoch_0]_26801  loss=3.218930 |g|=0.383	lr=3.65e-04 | 95.5%@S22  T=11.86s(data=2.0ms QKV=2.10s FFN=3.04s) eta=4d 16:45:29 | 42.0K token/s | 
[epoch_0]_26811  loss=3.251733 |g|=0.38	lr=3.64e-04 | 96.4%@S22  T=1.77s(data=1.6ms QKV=2.11s FFN=3.04s) eta=16:48:51 | 42.2K token/s | 
[epoch_0]_26821  loss=3.343749 |g|=0.437	lr=3.64e-04 | 97.2%@S22  T=1.74s(data=2.3ms QKV=2.10s FFN=3.04s) eta=16:29:21 | 42.5K token/s | 
[epoch_0]_26831  loss=3.244138 |g|=0.396	lr=3.64e-04 | 98.0%@S22  T=1.80s(data=1.6ms QKV=2.10s FFN=3.04s) eta=17:04:56 | 42.6K token/s | 
[epoch_0]_26841  loss=3.270453 |g|=0.396	lr=3.64e-04 | 98.8%@S22  T=1.72s(data=1.9ms QKV=2.10s FFN=3.04s) eta=16:20:03 | 42.9K token/s | 
[epoch_0]_26851  loss=3.261822 |g|=0.438	lr=3.64e-04 | 99.6%@S22  T=1.80s(data=1.6ms QKV=2.11s FFN=3.04s) eta=17:06:10 | 43.0K token/s | 
[epoch_0]_26855  loss=3.251318 |g|=0.412	lr=3.64e-04 | 100.0%@S22  T=1.77s(data=1.6ms QKV=2.11s FFN=3.04s) eta=16:48:54 | 43.2K token/s | 
-------- End of shard_22@"./Datasets/edu_fineweb1B/edu_fineweb_train_000476.bin"-------- 
[shard-23]@"./Datasets/edu_fineweb1B/edu_fineweb_train_000477.bin": tokens=100(M) nShardSamples=1220(2246088) 
[epoch_0]_26861  loss=3.254110 |g|=0.389	lr=3.64e-04 | 0.5%@S23  T=1.78s(data=1.3ms QKV=2.10s FFN=3.04s) eta=16:52:15 | 43.3K token/s | 
[epoch_0]_26871  loss=3.322174 |g|=0.415	lr=3.64e-04 | 1.3%@S23  T=1.79s(data=1.2ms QKV=2.10s FFN=3.04s) eta=17:00:02 | 43.4K token/s | 
[epoch_0]_26881  loss=3.268966 |g|=0.424	lr=3.63e-04 | 2.1%@S23  T=1.76s(data=1.2ms QKV=2.10s FFN=3.04s) eta=16:44:25 | 43.6K token/s | 
[epoch_0]_26891  loss=3.216244 |g|=0.393	lr=3.63e-04 | 2.9%@S23  T=1.74s(data=1.4ms QKV=2.10s FFN=3.04s) eta=16:29:49 | 43.8K token/s | 
[Fuyou] head="4" update algorithm=4 t=12.64s
[Section@26900] layer[40-48] tasks=19(nPassBack=0) last_loss=3.23388(0.0560973) N=(772,30800,30240 3550668)
[epoch_0]_26901  loss=3.252374 |g|=0.378	lr=3.63e-04 | 3.7%@S23  T=4.39s(data=1.9ms QKV=2.10s FFN=3.04s) eta=1d 17:36:15 | 42.5K token/s | 
[epoch_0]_26911  loss=3.160998 |g|=0.384	lr=3.63e-04 | 4.6%@S23  T=1.75s(data=1.6ms QKV=2.10s FFN=3.04s) eta=16:34:59 | 42.7K token/s | 
[epoch_0]_26921  loss=3.309278 |g|=0.42	lr=3.63e-04 | 5.4%@S23  T=1.76s(data=7.3ms QKV=2.11s FFN=3.04s) eta=16:42:21 | 42.9K token/s | 
[epoch_0]_26931  loss=3.321523 |g|=0.408	lr=3.63e-04 | 6.2%@S23  T=1.76s(data=1.5ms QKV=2.10s FFN=3.04s) eta=16:42:29 | 43.1K token/s | 
[epoch_0]_26941  loss=3.339007 |g|=0.425	lr=3.62e-04 | 7.0%@S23  T=1.78s(data=1.7ms QKV=2.10s FFN=3.04s) eta=16:53:19 | 43.2K token/s | 
[epoch_0]_26951  loss=3.243912 |g|=0.417	lr=3.62e-04 | 7.8%@S23  T=1.75s(data=1.6ms QKV=2.10s FFN=3.04s) eta=16:33:35 | 43.4K token/s | 
[epoch_0]_26961  loss=3.263563 |g|=0.408	lr=3.62e-04 | 8.7%@S23  T=1.78s(data=1.6ms QKV=2.10s FFN=3.04s) eta=16:50:43 | 43.5K token/s | 
[epoch_0]_26971  loss=3.290552 |g|=0.396	lr=3.62e-04 | 9.5%@S23  T=1.79s(data=1.4ms QKV=2.11s FFN=3.04s) eta=16:54:56 | 43.7K token/s | 
[epoch_0]_26981  loss=3.217731 |g|=0.408	lr=3.62e-04 | 10.3%@S23  T=1.79s(data=1.8ms QKV=2.11s FFN=3.04s) eta=16:58:16 | 43.8K token/s | 
[epoch_0]_26991  loss=3.290326 |g|=0.416	lr=3.62e-04 | 11.1%@S23  T=1.78s(data=1.5ms QKV=2.10s FFN=3.04s) eta=16:47:20 | 43.9K token/s | 
[Fuyou] head="5" update algorithm=4 t=11.71s
[eval] 
	 Loss@"edu_fineweb1B"=3.270(0.0098) nBranch=1 nToken=6.31M best=3.2802(133) E2T=-0.00925 T=36.7225(0)s x=0
	#3.27039±0.0986 tps=172K(6.30784M) a=[3.0772,3.54599] T=36.7225(sec)
[Section@27000] layer[0-8] tasks=19(nPassBack=0) last_loss=3.27964(0.0166802) N=(772,30912,30352 3563868)
[epoch_0]_27001  loss=3.261487 |g|=0.38	lr=3.62e-04 | 11.9%@S23  T=12.01s(data=1.9ms QKV=2.10s FFN=3.04s) eta=4d 17:31:10 | 42.0K token/s | 
[epoch_0]_27011  loss=3.233717 |g|=0.403	lr=3.61e-04 | 12.7%@S23  T=1.80s(data=1.7ms QKV=2.10s FFN=3.04s) eta=16:58:12 | 42.2K token/s | 
[epoch_0]_27021  loss=3.262261 |g|=0.396	lr=3.61e-04 | 13.6%@S23  T=1.79s(data=1.6ms QKV=2.11s FFN=3.04s) eta=16:55:06 | 42.4K token/s | 
[epoch_0]_27031  loss=3.356982 |g|=0.409	lr=3.61e-04 | 14.4%@S23  T=1.77s(data=1.5ms QKV=2.11s FFN=3.04s) eta=16:42:24 | 42.6K token/s | 
[epoch_0]_27041  loss=3.284530 |g|=0.407	lr=3.61e-04 | 15.2%@S23  T=1.79s(data=2.0ms QKV=2.11s FFN=3.04s) eta=16:56:01 | 42.7K token/s | 
[epoch_0]_27051  loss=3.263486 |g|=0.407	lr=3.61e-04 | 16.0%@S23  T=1.77s(data=1.6ms QKV=2.10s FFN=3.04s) eta=16:41:27 | 42.9K token/s | 
[epoch_0]_27061  loss=3.319818 |g|=0.405	lr=3.61e-04 | 16.8%@S23  T=1.77s(data=1.7ms QKV=2.11s FFN=3.04s) eta=16:41:54 | 43.1K token/s | 
[epoch_0]_27071  loss=3.319457 |g|=0.397	lr=3.60e-04 | 17.7%@S23  T=1.77s(data=1.7ms QKV=2.11s FFN=3.04s) eta=16:41:39 | 43.2K token/s | 
[epoch_0]_27081  loss=3.330036 |g|=0.414	lr=3.60e-04 | 18.5%@S23  T=1.76s(data=1.7ms QKV=2.11s FFN=3.04s) eta=16:33:43 | 43.4K token/s | 
[epoch_0]_27091  loss=3.272820 |g|=0.408	lr=3.60e-04 | 19.3%@S23  T=1.74s(data=1.8ms QKV=2.10s FFN=3.04s) eta=16:25:01 | 43.6K token/s | 
[Fuyou] head="0" update algorithm=4 t=11.46s
[Section@27100] layer[8-16] tasks=19(nPassBack=0) last_loss=3.21706(0.122682) N=(772,31024,30464 3577068)
[epoch_0]_27101  loss=3.323793 |g|=0.377	lr=3.60e-04 | 20.1%@S23  T=4.29s(data=2.2ms QKV=2.10s FFN=3.04s) eta=1d 16:26:41 | 42.4K token/s | 
[epoch_0]_27111  loss=3.272432 |g|=0.399	lr=3.60e-04 | 20.9%@S23  T=1.72s(data=2.3ms QKV=2.10s FFN=3.04s) eta=16:10:05 | 42.6K token/s | 
[epoch_0]_27121  loss=3.322447 |g|=0.441	lr=3.60e-04 | 21.8%@S23  T=1.70s(data=1.9ms QKV=2.10s FFN=3.04s) eta=16:02:40 | 42.9K token/s | 
[epoch_0]_27131  loss=3.238455 |g|=0.416	lr=3.60e-04 | 22.6%@S23  T=1.76s(data=1.8ms QKV=2.10s FFN=3.04s) eta=16:32:20 | 43.1K token/s | 
[epoch_0]_27141  loss=3.249278 |g|=0.423	lr=3.59e-04 | 23.4%@S23  T=1.78s(data=1.8ms QKV=2.10s FFN=3.04s) eta=16:47:19 | 43.2K token/s | 
[epoch_0]_27151  loss=3.274509 |g|=0.438	lr=3.59e-04 | 24.2%@S23  T=1.72s(data=1.9ms QKV=2.11s FFN=3.04s) eta=16:10:43 | 43.5K token/s | 
[epoch_0]_27161  loss=3.214906 |g|=0.392	lr=3.59e-04 | 25.0%@S23  T=1.72s(data=1.9ms QKV=2.11s FFN=3.04s) eta=16:09:16 | 43.7K token/s | 
[epoch_0]_27171  loss=3.274189 |g|=0.382	lr=3.59e-04 | 25.9%@S23  T=1.72s(data=1.7ms QKV=2.11s FFN=3.04s) eta=16:10:55 | 43.9K token/s | 
[epoch_0]_27181  loss=3.247690 |g|=0.381	lr=3.59e-04 | 26.7%@S23  T=1.73s(data=1.7ms QKV=2.11s FFN=3.04s) eta=16:18:46 | 44.0K token/s | 
[epoch_0]_27191  loss=3.295595 |g|=0.424	lr=3.59e-04 | 27.5%@S23  T=1.79s(data=1.5ms QKV=2.11s FFN=3.04s) eta=16:49:55 | 44.1K token/s | 
[Fuyou] head="1" update algorithm=4 t=10.50s
[eval] 
	 Loss@"edu_fineweb1B"=3.266(0.0047) nBranch=1 nToken=6.31M best=3.2704(134) E2T=0.0534 T=36.7529(0)s x=0
	#3.26573±0.0983 tps=172K(6.30784M) a=[3.067,3.53649] T=36.7529(sec)
[Section@27200] layer[16-24] tasks=19(nPassBack=0) last_loss=3.21234(0.0688329) N=(772,31136,30576 3590268)
[epoch_0]_27201  loss=3.244783 |g|=0.374	lr=3.59e-04 | 28.3%@S23  T=12.05s(data=2.0ms QKV=2.10s FFN=3.04s) eta=4d 17:14:12 | 42.3K token/s | 
[epoch_0]_27211  loss=3.233157 |g|=0.414	lr=3.58e-04 | 29.1%@S23  T=1.78s(data=1.7ms QKV=2.11s FFN=3.04s) eta=16:41:13 | 42.5K token/s | 
[epoch_0]_27221  loss=3.293681 |g|=0.408	lr=3.58e-04 | 30.0%@S23  T=1.79s(data=1.7ms QKV=2.10s FFN=3.04s) eta=16:49:41 | 42.6K token/s | 
[epoch_0]_27231  loss=3.230881 |g|=0.391	lr=3.58e-04 | 30.8%@S23  T=1.78s(data=1.5ms QKV=2.11s FFN=3.04s) eta=16:41:17 | 42.8K token/s | 
[epoch_0]_27241  loss=3.270737 |g|=0.442	lr=3.58e-04 | 31.6%@S23  T=1.77s(data=1.5ms QKV=2.11s FFN=3.04s) eta=16:37:47 | 43.0K token/s | 
[epoch_0]_27251  loss=3.238539 |g|=0.391	lr=3.58e-04 | 32.4%@S23  T=1.79s(data=1.4ms QKV=2.10s FFN=3.04s) eta=16:45:04 | 43.1K token/s | 
[epoch_0]_27261  loss=3.273879 |g|=0.423	lr=3.58e-04 | 33.2%@S23  T=1.77s(data=1.4ms QKV=2.11s FFN=3.04s) eta=16:36:31 | 43.3K token/s | 
[epoch_0]_27271  loss=3.220246 |g|=0.383	lr=3.57e-04 | 34.0%@S23  T=1.78s(data=1.6ms QKV=2.11s FFN=3.04s) eta=16:41:21 | 43.4K token/s | 
[epoch_0]_27281  loss=3.251073 |g|=0.412	lr=3.57e-04 | 34.9%@S23  T=1.74s(data=1.6ms QKV=2.10s FFN=3.04s) eta=16:17:38 | 43.6K token/s | 
[epoch_0]_27291  loss=3.265715 |g|=0.404	lr=3.57e-04 | 35.7%@S23  T=1.77s(data=1.6ms QKV=2.10s FFN=3.04s) eta=16:37:02 | 43.7K token/s | 
[Fuyou] head="2" update algorithm=4 t=9.24s
[Section@27300] layer[24-32] tasks=19(nPassBack=0) last_loss=3.26435(0.0528874) N=(772,31248,30688 3603468)
[epoch_0]_27301  loss=3.317996 |g|=0.395	lr=3.57e-04 | 36.5%@S23  T=4.40s(data=2.1ms QKV=2.10s FFN=3.04s) eta=1d 17:13:43 | 42.5K token/s | 
[epoch_0]_27311  loss=3.267927 |g|=0.424	lr=3.57e-04 | 37.3%@S23  T=1.79s(data=1.7ms QKV=2.11s FFN=3.04s) eta=16:46:17 | 42.6K token/s | 
[epoch_0]_27321  loss=3.220564 |g|=0.393	lr=3.57e-04 | 38.1%@S23  T=1.76s(data=1.8ms QKV=2.11s FFN=3.04s) eta=16:26:50 | 42.8K token/s | 
[epoch_0]_27331  loss=3.302573 |g|=0.422	lr=3.57e-04 | 39.0%@S23  T=1.72s(data=1.9ms QKV=2.11s FFN=3.04s) eta=16:06:57 | 43.1K token/s | 
[epoch_0]_27341  loss=3.340390 |g|=0.41	lr=3.56e-04 | 39.8%@S23  T=1.78s(data=1.7ms QKV=2.11s FFN=3.04s) eta=16:40:14 | 43.2K token/s | 
[epoch_0]_27351  loss=3.360276 |g|=0.417	lr=3.56e-04 | 40.6%@S23  T=1.77s(data=1.6ms QKV=2.11s FFN=3.04s) eta=16:33:30 | 43.4K token/s | 
[epoch_0]_27361  loss=3.315926 |g|=0.432	lr=3.56e-04 | 41.4%@S23  T=1.79s(data=1.6ms QKV=2.11s FFN=3.04s) eta=16:47:10 | 43.5K token/s | 
[epoch_0]_27371  loss=3.251116 |g|=0.4	lr=3.56e-04 | 42.2%@S23  T=1.79s(data=1.6ms QKV=2.11s FFN=3.04s) eta=16:45:57 | 43.6K token/s | 
[epoch_0]_27381  loss=3.274633 |g|=0.4	lr=3.56e-04 | 43.1%@S23  T=1.81s(data=1.6ms QKV=2.11s FFN=3.05s) eta=16:56:07 | 43.7K token/s | 
[epoch_0]_27391  loss=3.322450 |g|=0.411	lr=3.56e-04 | 43.9%@S23  T=1.75s(data=1.7ms QKV=2.11s FFN=3.05s) eta=16:22:10 | 43.8K token/s | 
[Fuyou] head="3" update algorithm=4 t=10.45s
[eval] 
	 Loss@"edu_fineweb1B"=3.263(0.0032) nBranch=1 nToken=6.31M best=3.2657(135) E2T=-0.000835 T=36.7662(0)s x=0
	#3.26257±0.0976 tps=172K(6.30784M) a=[3.06714,3.53069] T=36.7662(sec)
[Section@27400] layer[32-40] tasks=19(nPassBack=0) last_loss=3.2634(-0.00475264) N=(772,31360,30800 3616668)
[epoch_0]_27401  loss=3.288383 |g|=0.394	lr=3.55e-04 | 44.7%@S23  T=11.83s(data=1.6ms QKV=2.10s FFN=3.04s) eta=4d 14:31:17 | 42.0K token/s | 
[epoch_0]_27411  loss=3.280194 |g|=0.476	lr=3.55e-04 | 45.5%@S23  T=1.78s(data=1.6ms QKV=2.10s FFN=3.04s) eta=16:36:06 | 42.2K token/s | 
[epoch_0]_27421  loss=3.330791 |g|=0.407	lr=3.55e-04 | 46.3%@S23  T=1.71s(data=1.6ms QKV=2.11s FFN=3.04s) eta=15:56:49 | 42.5K token/s | 
[epoch_0]_27431  loss=3.244091 |g|=0.406	lr=3.55e-04 | 47.2%@S23  T=1.76s(data=1.7ms QKV=2.10s FFN=3.04s) eta=16:26:15 | 42.7K token/s | 
[epoch_0]_27441  loss=3.258371 |g|=0.425	lr=3.55e-04 | 48.0%@S23  T=1.74s(data=1.8ms QKV=2.11s FFN=3.04s) eta=16:12:44 | 42.9K token/s | 
[epoch_0]_27451  loss=3.261707 |g|=0.415	lr=3.55e-04 | 48.8%@S23  T=1.77s(data=1.7ms QKV=2.11s FFN=3.04s) eta=16:32:46 | 43.1K token/s | 
[epoch_0]_27461  loss=3.255275 |g|=0.427	lr=3.55e-04 | 49.6%@S23  T=1.79s(data=1.5ms QKV=2.11s FFN=3.04s) eta=16:41:03 | 43.2K token/s | 
[epoch_0]_27471  loss=3.198486 |g|=0.396	lr=3.54e-04 | 50.4%@S23  T=1.78s(data=1.7ms QKV=2.10s FFN=3.04s) eta=16:37:09 | 43.3K token/s | 
[epoch_0]_27481  loss=3.274104 |g|=0.411	lr=3.54e-04 | 51.3%@S23  T=1.79s(data=1.7ms QKV=2.11s FFN=3.04s) eta=16:40:50 | 43.5K token/s | 
[epoch_0]_27491  loss=3.314558 |g|=0.41	lr=3.54e-04 | 52.1%@S23  T=1.80s(data=1.6ms QKV=2.11s FFN=3.04s) eta=16:48:46 | 43.6K token/s | 
[Fuyou] head="4" update algorithm=4 t=11.49s
[Section@27500] layer[40-48] tasks=19(nPassBack=0) last_loss=3.24934(-0.0154614) N=(772,31472,30912 3629868)
[epoch_0]_27501  loss=3.262244 |g|=0.375	lr=3.54e-04 | 52.9%@S23  T=4.47s(data=2.3ms QKV=2.10s FFN=3.04s) eta=1d 17:36:21 | 42.3K token/s | 
[epoch_0]_27511  loss=3.313208 |g|=0.41	lr=3.54e-04 | 53.7%@S23  T=1.70s(data=1.8ms QKV=2.11s FFN=3.04s) eta=15:50:02 | 42.6K token/s | 
[epoch_0]_27521  loss=3.225448 |g|=0.417	lr=3.54e-04 | 54.5%@S23  T=1.71s(data=1.8ms QKV=2.11s FFN=3.04s) eta=15:56:13 | 42.9K token/s | 
[epoch_0]_27531  loss=3.249335 |g|=0.42	lr=3.53e-04 | 55.3%@S23  T=1.72s(data=1.8ms QKV=2.11s FFN=3.04s) eta=15:58:17 | 43.1K token/s | 
[epoch_0]_27541  loss=3.279768 |g|=0.388	lr=3.53e-04 | 56.2%@S23  T=1.71s(data=1.8ms QKV=2.11s FFN=3.04s) eta=15:53:23 | 43.3K token/s | 
[epoch_0]_27551  loss=3.259880 |g|=0.399	lr=3.53e-04 | 57.0%@S23  T=1.73s(data=1.8ms QKV=2.11s FFN=3.04s) eta=16:05:28 | 43.5K token/s | 
[epoch_0]_27561  loss=3.274520 |g|=0.397	lr=3.53e-04 | 57.8%@S23  T=1.79s(data=1.6ms QKV=2.11s FFN=3.04s) eta=16:38:38 | 43.7K token/s | 
[epoch_0]_27571  loss=3.205932 |g|=0.395	lr=3.53e-04 | 58.6%@S23  T=1.73s(data=1.5ms QKV=2.11s FFN=3.04s) eta=16:05:49 | 43.8K token/s | 
[epoch_0]_27581  loss=3.228184 |g|=0.457	lr=3.53e-04 | 59.4%@S23  T=1.78s(data=1.5ms QKV=2.11s FFN=3.04s) eta=16:30:25 | 44.0K token/s | 
[epoch_0]_27591  loss=3.231575 |g|=0.422	lr=3.53e-04 | 60.3%@S23  T=1.82s(data=1.6ms QKV=2.11s FFN=3.05s) eta=16:53:02 | 44.0K token/s | 
[Fuyou] head="5" update algorithm=4 t=11.57s
[eval] 
	 Loss@"edu_fineweb1B"=3.260(0.0022) nBranch=1 nToken=6.31M best=3.2626(136) E2T=0.0159 T=36.7241(0)s x=0
	#3.26035±0.0976 tps=172K(6.30784M) a=[3.07053,3.52767] T=36.7241(sec)
[Section@27600] layer[0-8] tasks=19(nPassBack=0) last_loss=3.24449(0.0351479) N=(772,31584,31024 3643068)
[epoch_0]_27601  loss=3.285280 |g|=0.393	lr=3.52e-04 | 61.1%@S23  T=12.07s(data=1.6ms QKV=2.11s FFN=3.04s) eta=4d 16:08:26 | 42.1K token/s | 
[epoch_0]_27611  loss=3.222623 |g|=0.414	lr=3.52e-04 | 61.9%@S23  T=1.78s(data=1.5ms QKV=2.11s FFN=3.04s) eta=16:31:10 | 42.3K token/s | 
[epoch_0]_27621  loss=3.226121 |g|=0.407	lr=3.52e-04 | 62.7%@S23  T=1.79s(data=1.7ms QKV=2.11s FFN=3.04s) eta=16:34:16 | 42.5K token/s | 
[epoch_0]_27631  loss=3.267116 |g|=0.412	lr=3.52e-04 | 63.5%@S23  T=1.83s(data=1.7ms QKV=2.11s FFN=3.04s) eta=16:59:09 | 42.6K token/s | 
[epoch_0]_27641  loss=3.303126 |g|=0.437	lr=3.52e-04 | 64.4%@S23  T=1.78s(data=1.6ms QKV=2.11s FFN=3.04s) eta=16:29:16 | 42.8K token/s | 
[epoch_0]_27651  loss=3.146481 |g|=0.397	lr=3.52e-04 | 65.2%@S23  T=1.78s(data=1.6ms QKV=2.11s FFN=3.04s) eta=16:31:23 | 43.0K token/s | 
[epoch_0]_27661  loss=3.210181 |g|=0.398	lr=3.52e-04 | 66.0%@S23  T=1.78s(data=1.6ms QKV=2.11s FFN=3.04s) eta=16:29:37 | 43.1K token/s | 
[epoch_0]_27671  loss=3.182779 |g|=0.375	lr=3.51e-04 | 66.8%@S23  T=1.73s(data=1.8ms QKV=2.11s FFN=3.04s) eta=16:04:18 | 43.3K token/s | 
[epoch_0]_27681  loss=3.337079 |g|=0.435	lr=3.51e-04 | 67.6%@S23  T=1.72s(data=1.8ms QKV=2.11s FFN=3.04s) eta=15:54:58 | 43.5K token/s | 
[epoch_0]_27691  loss=3.281458 |g|=0.401	lr=3.51e-04 | 68.5%@S23  T=1.77s(data=1.7ms QKV=2.11s FFN=3.04s) eta=16:23:16 | 43.7K token/s | 
[Fuyou] head="0" update algorithm=4 t=11.53s
[Section@27700] layer[8-16] tasks=19(nPassBack=0) last_loss=3.24175(-0.0246937) N=(772,31696,31136 3656268)
[epoch_0]_27701  loss=3.282239 |g|=0.386	lr=3.51e-04 | 69.3%@S23  T=4.23s(data=1.7ms QKV=2.11s FFN=3.04s) eta=1d 15:11:31 | 42.5K token/s | 
[epoch_0]_27711  loss=3.238894 |g|=0.398	lr=3.51e-04 | 70.1%@S23  T=1.78s(data=1.7ms QKV=2.11s FFN=3.04s) eta=16:30:45 | 42.6K token/s | 
[epoch_0]_27721  loss=3.204098 |g|=0.396	lr=3.51e-04 | 70.9%@S23  T=1.73s(data=1.6ms QKV=2.11s FFN=3.04s) eta=15:58:39 | 42.9K token/s | 
[epoch_0]_27731  loss=3.234766 |g|=0.406	lr=3.50e-04 | 71.7%@S23  T=1.72s(data=1.8ms QKV=2.11s FFN=3.04s) eta=15:55:20 | 43.1K token/s | 
[epoch_0]_27741  loss=3.236037 |g|=0.427	lr=3.50e-04 | 72.5%@S23  T=1.73s(data=1.8ms QKV=2.11s FFN=3.04s) eta=16:00:06 | 43.3K token/s | 
[epoch_0]_27751  loss=3.246345 |g|=0.421	lr=3.50e-04 | 73.4%@S23  T=1.78s(data=1.6ms QKV=2.11s FFN=3.04s) eta=16:28:03 | 43.5K token/s | 
[epoch_0]_27761  loss=3.242561 |g|=0.408	lr=3.50e-04 | 74.2%@S23  T=1.71s(data=1.7ms QKV=2.11s FFN=3.04s) eta=15:48:05 | 43.7K token/s | 
[epoch_0]_27771  loss=3.259580 |g|=0.424	lr=3.50e-04 | 75.0%@S23  T=1.74s(data=1.9ms QKV=2.11s FFN=3.04s) eta=16:02:27 | 43.9K token/s | 
[epoch_0]_27781  loss=3.246474 |g|=0.415	lr=3.50e-04 | 75.8%@S23  T=1.72s(data=1.6ms QKV=2.11s FFN=3.04s) eta=15:52:25 | 44.0K token/s | 
[epoch_0]_27791  loss=3.198092 |g|=0.395	lr=3.50e-04 | 76.6%@S23  T=1.71s(data=1.7ms QKV=2.11s FFN=3.04s) eta=15:47:04 | 44.2K token/s | 
[Fuyou] head="1" update algorithm=4 t=9.45s
[eval] 
	 Loss@"edu_fineweb1B"=3.257(0.0034) nBranch=1 nToken=6.31M best=3.2604(137) E2T=0.00565 T=36.7416(0)s x=0
	#3.25693±0.0978 tps=172K(6.30784M) a=[3.0629,3.52606] T=36.7416(sec)
[Section@27800] layer[16-24] tasks=19(nPassBack=0) last_loss=3.25128(-0.0389445) N=(772,31808,31248 3669468)
[epoch_0]_27801  loss=3.301788 |g|=0.4	lr=3.49e-04 | 77.5%@S23  T=11.99s(data=2.0ms QKV=2.10s FFN=3.04s) eta=4d 14:43:53 | 42.4K token/s | 
[epoch_0]_27811  loss=3.263430 |g|=0.419	lr=3.49e-04 | 78.3%@S23  T=1.71s(data=2.0ms QKV=2.11s FFN=3.04s) eta=15:48:13 | 42.6K token/s | 
[epoch_0]_27821  loss=3.282952 |g|=0.443	lr=3.49e-04 | 79.1%@S23  T=1.78s(data=1.6ms QKV=2.10s FFN=3.04s) eta=16:22:40 | 42.8K token/s | 
[epoch_0]_27831  loss=3.293236 |g|=0.403	lr=3.49e-04 | 79.9%@S23  T=1.78s(data=2.0ms QKV=2.11s FFN=3.04s) eta=16:22:55 | 43.0K token/s | 
[epoch_0]_27841  loss=3.235221 |g|=0.405	lr=3.49e-04 | 80.7%@S23  T=1.78s(data=1.6ms QKV=2.11s FFN=3.04s) eta=16:23:51 | 43.1K token/s | 
[epoch_0]_27851  loss=3.217276 |g|=0.403	lr=3.49e-04 | 81.6%@S23  T=1.78s(data=1.6ms QKV=2.11s FFN=3.04s) eta=16:25:04 | 43.3K token/s | 
[epoch_0]_27861  loss=3.212193 |g|=0.403	lr=3.48e-04 | 82.4%@S23  T=1.78s(data=1.6ms QKV=2.11s FFN=3.04s) eta=16:26:05 | 43.4K token/s | 
[epoch_0]_27871  loss=3.213027 |g|=0.397	lr=3.48e-04 | 83.2%@S23  T=1.72s(data=3.8ms QKV=2.11s FFN=3.04s) eta=15:50:52 | 43.6K token/s | 
[epoch_0]_27881  loss=3.229140 |g|=0.412	lr=3.48e-04 | 84.0%@S23  T=1.77s(data=1.5ms QKV=2.11s FFN=3.04s) eta=16:16:29 | 43.8K token/s | 
[epoch_0]_27891  loss=3.219361 |g|=0.406	lr=3.48e-04 | 84.8%@S23  T=1.77s(data=1.5ms QKV=2.11s FFN=3.04s) eta=16:16:21 | 43.9K token/s | 
[Fuyou] head="2" update algorithm=4 t=9.24s
[Section@27900] layer[24-32] tasks=19(nPassBack=0) last_loss=3.2006(0.0637491) N=(772,31920,31360 3682668)
[epoch_0]_27901  loss=3.253922 |g|=0.388	lr=3.48e-04 | 85.7%@S23  T=4.58s(data=5.3ms QKV=2.10s FFN=3.04s) eta=1d 18:06:30 | 42.6K token/s | 
[epoch_0]_27911  loss=3.255064 |g|=0.413	lr=3.48e-04 | 86.5%@S23  T=1.70s(data=1.9ms QKV=2.10s FFN=3.04s) eta=15:38:41 | 42.9K token/s | 
[epoch_0]_27921  loss=3.203715 |g|=0.422	lr=3.48e-04 | 87.3%@S23  T=1.72s(data=1.8ms QKV=2.11s FFN=3.04s) eta=15:49:41 | 43.1K token/s | 
[epoch_0]_27931  loss=3.301821 |g|=0.407	lr=3.47e-04 | 88.1%@S23  T=1.72s(data=1.8ms QKV=2.11s FFN=3.04s) eta=15:48:08 | 43.3K token/s | 
[epoch_0]_27941  loss=3.260171 |g|=0.389	lr=3.47e-04 | 88.9%@S23  T=1.73s(data=1.8ms QKV=2.11s FFN=3.04s) eta=15:51:48 | 43.5K token/s | 
[epoch_0]_27951  loss=3.215682 |g|=0.429	lr=3.47e-04 | 89.8%@S23  T=1.78s(data=1.5ms QKV=2.11s FFN=3.04s) eta=16:22:31 | 43.7K token/s | 
[epoch_0]_27961  loss=3.231150 |g|=0.399	lr=3.47e-04 | 90.6%@S23  T=1.72s(data=1.7ms QKV=2.11s FFN=3.04s) eta=15:45:48 | 43.9K token/s | 
[epoch_0]_27971  loss=3.241278 |g|=0.384	lr=3.47e-04 | 91.4%@S23  T=1.73s(data=1.9ms QKV=2.11s FFN=3.04s) eta=15:51:56 | 44.0K token/s | 
[epoch_0]_27981  loss=3.270187 |g|=0.388	lr=3.47e-04 | 92.2%@S23  T=1.73s(data=1.7ms QKV=2.11s FFN=3.04s) eta=15:51:23 | 44.2K token/s | 
[epoch_0]_27991  loss=3.282484 |g|=0.384	lr=3.46e-04 | 93.0%@S23  T=1.73s(data=1.7ms QKV=2.11s FFN=3.04s) eta=15:54:50 | 44.4K token/s | 
[Fuyou] head="3" update algorithm=4 t=11.94s
[eval] 
	 Loss@"edu_fineweb1B"=3.256(0.00045) nBranch=1 nToken=6.31M best=3.2569(138) E2T=-0.0196 T=36.719(0)s x=0
	#3.25647±0.0976 tps=172K(6.30784M) a=[3.06381,3.52568] T=36.719(sec)
[Section@28000] layer[32-40] tasks=19(nPassBack=0) last_loss=3.27608(-0.012677) N=(772,32032,31472 3695868)
[epoch_0]_28001  loss=3.253893 |g|=0.414	lr=3.46e-04 | 93.8%@S23  T=12.08s(data=2.4ms QKV=2.10s FFN=3.04s) eta=4d 14:48:23 | 42.5K token/s | 
[epoch_0]_28011  loss=3.315871 |g|=0.431	lr=3.46e-04 | 94.7%@S23  T=1.70s(data=2.0ms QKV=2.10s FFN=3.04s) eta=15:37:50 | 42.8K token/s | 
[epoch_0]_28021  loss=3.255578 |g|=0.413	lr=3.46e-04 | 95.5%@S23  T=1.72s(data=1.8ms QKV=2.10s FFN=3.04s) eta=15:45:34 | 43.0K token/s | 
[epoch_0]_28031  loss=3.299138 |g|=0.401	lr=3.46e-04 | 96.3%@S23  T=1.83s(data=2.0ms QKV=2.10s FFN=3.04s) eta=16:46:56 | 43.1K token/s | 
[epoch_0]_28041  loss=3.261622 |g|=0.401	lr=3.46e-04 | 97.1%@S23  T=1.82s(data=1.7ms QKV=2.11s FFN=3.04s) eta=16:38:24 | 43.2K token/s | 
[epoch_0]_28051  loss=3.303639 |g|=0.397	lr=3.46e-04 | 97.9%@S23  T=1.81s(data=1.8ms QKV=2.10s FFN=3.04s) eta=16:32:44 | 43.3K token/s | 
[epoch_0]_28061  loss=3.281662 |g|=0.412	lr=3.45e-04 | 98.8%@S23  T=1.79s(data=1.8ms QKV=2.10s FFN=3.04s) eta=16:24:05 | 43.4K token/s | 
[epoch_0]_28071  loss=3.236641 |g|=0.407	lr=3.45e-04 | 99.6%@S23  T=1.83s(data=1.6ms QKV=2.10s FFN=3.04s) eta=16:43:59 | 43.5K token/s | 
[epoch_0]_28076  loss=3.269560 |g|=0.414	lr=3.45e-04 | 100.0%@S23  T=1.78s(data=2.8ms QKV=2.11s FFN=3.04s) eta=16:19:23 | 43.6K token/s | 
-------- End of shard_23@"./Datasets/edu_fineweb1B/edu_fineweb_train_000477.bin"-------- 
[shard-24]@"./Datasets/edu_fineweb1B/edu_fineweb_train_000478.bin": tokens=100(M) nShardSamples=1220(2343744) 
[epoch_0]_28081  loss=3.242270 |g|=0.419	lr=3.45e-04 | 0.4%@S24  T=1.73s(data=1.2ms QKV=2.10s FFN=3.04s) eta=15:51:15 | 43.8K token/s | 
[epoch_0]_28091  loss=3.294185 |g|=0.399	lr=3.45e-04 | 1.2%@S24  T=1.73s(data=1.2ms QKV=2.10s FFN=3.04s) eta=15:48:16 | 44.0K token/s | 
[Fuyou] head="4" update algorithm=4 t=11.55s
[Section@28100] layer[40-48] tasks=19(nPassBack=0) last_loss=3.27139(-0.0220568) N=(772,32144,31584 3709068)
[epoch_0]_28101  loss=3.357509 |g|=0.382	lr=3.45e-04 | 2.0%@S24  T=4.34s(data=1.8ms QKV=2.10s FFN=3.04s) eta=1d 15:42:48 | 42.7K token/s | 
[epoch_0]_28111  loss=3.191534 |g|=0.437	lr=3.45e-04 | 2.9%@S24  T=1.72s(data=4.2ms QKV=2.10s FFN=3.04s) eta=15:45:10 | 43.0K token/s | 
[epoch_0]_28121  loss=3.302726 |g|=0.418	lr=3.44e-04 | 3.7%@S24  T=1.73s(data=1.9ms QKV=2.10s FFN=3.04s) eta=15:49:07 | 43.2K token/s | 
[epoch_0]_28131  loss=3.228978 |g|=0.388	lr=3.44e-04 | 4.5%@S24  T=1.73s(data=2.7ms QKV=2.10s FFN=3.04s) eta=15:47:41 | 43.4K token/s | 
[epoch_0]_28141  loss=3.258320 |g|=0.413	lr=3.44e-04 | 5.3%@S24  T=1.72s(data=3.1ms QKV=2.10s FFN=3.04s) eta=15:43:21 | 43.6K token/s | 
[epoch_0]_28151  loss=3.294580 |g|=0.413	lr=3.44e-04 | 6.1%@S24  T=1.73s(data=1.7ms QKV=2.10s FFN=3.04s) eta=15:49:26 | 43.8K token/s | 
[epoch_0]_28161  loss=3.267611 |g|=0.395	lr=3.44e-04 | 7.0%@S24  T=1.79s(data=1.8ms QKV=2.10s FFN=3.04s) eta=16:19:57 | 43.9K token/s | 
[epoch_0]_28171  loss=3.226878 |g|=0.421	lr=3.44e-04 | 7.8%@S24  T=1.73s(data=2.5ms QKV=2.10s FFN=3.04s) eta=15:45:50 | 44.1K token/s | 
[epoch_0]_28181  loss=3.184260 |g|=0.407	lr=3.44e-04 | 8.6%@S24  T=1.71s(data=2.9ms QKV=2.10s FFN=3.04s) eta=15:35:21 | 44.3K token/s | 
[epoch_0]_28191  loss=3.194335 |g|=0.4	lr=3.43e-04 | 9.4%@S24  T=1.72s(data=1.6ms QKV=2.10s FFN=3.04s) eta=15:39:41 | 44.4K token/s | 
[Fuyou] head="5" update algorithm=4 t=11.39s
[eval] 
	 Loss@"edu_fineweb1B"=3.260(-0.004) nBranch=1 nToken=6.31M best=3.2569(138) E2T=0.0347 T=36.7396(0)s x=0
	#3.26044±0.0975 tps=172K(6.30784M) a=[3.05947,3.53292] T=36.7396(sec)
[Section@28200] layer[0-8] tasks=19(nPassBack=0) last_loss=3.22579(0.0187023) N=(772,32256,31696 3722268)
[epoch_0]_28201  loss=3.244663 |g|=0.385	lr=3.43e-04 | 10.2%@S24  T=11.81s(data=2.1ms QKV=2.10s FFN=3.04s) eta=4d 11:43:37 | 42.6K token/s | 
[epoch_0]_28211  loss=3.255289 |g|=0.399	lr=3.43e-04 | 11.1%@S24  T=1.78s(data=1.7ms QKV=2.10s FFN=3.04s) eta=16:13:05 | 42.7K token/s | 
[epoch_0]_28221  loss=3.258821 |g|=0.385	lr=3.43e-04 | 11.9%@S24  T=1.77s(data=1.7ms QKV=2.11s FFN=3.04s) eta=16:09:47 | 42.9K token/s | 
[epoch_0]_28231  loss=3.232300 |g|=0.395	lr=3.43e-04 | 12.7%@S24  T=1.73s(data=1.8ms QKV=2.10s FFN=3.04s) eta=15:48:08 | 43.1K token/s | 
[epoch_0]_28241  loss=3.216367 |g|=0.429	lr=3.43e-04 | 13.5%@S24  T=1.77s(data=1.6ms QKV=2.10s FFN=3.04s) eta=16:10:06 | 43.3K token/s | 
[epoch_0]_28251  loss=3.261810 |g|=0.394	lr=3.43e-04 | 14.3%@S24  T=1.79s(data=1.3ms QKV=2.11s FFN=3.04s) eta=16:16:26 | 43.4K token/s | 
[epoch_0]_28261  loss=3.207725 |g|=0.413	lr=3.42e-04 | 15.1%@S24  T=1.78s(data=1.4ms QKV=2.10s FFN=3.04s) eta=16:10:38 | 43.5K token/s | 
[epoch_0]_28271  loss=3.190026 |g|=0.383	lr=3.42e-04 | 16.0%@S24  T=1.75s(data=1.6ms QKV=2.10s FFN=3.04s) eta=15:57:59 | 43.7K token/s | 
[epoch_0]_28281  loss=3.277390 |g|=0.406	lr=3.42e-04 | 16.8%@S24  T=1.73s(data=1.5ms QKV=2.11s FFN=3.04s) eta=15:45:53 | 43.9K token/s | 
[epoch_0]_28291  loss=3.225633 |g|=0.396	lr=3.42e-04 | 17.6%@S24  T=1.73s(data=1.8ms QKV=2.10s FFN=3.04s) eta=15:44:10 | 44.1K token/s | 
[Fuyou] head="0" update algorithm=4 t=10.77s
[Section@28300] layer[8-16] tasks=19(nPassBack=0) last_loss=3.17562(0.0661323) N=(772,32368,31808 3735468)
[epoch_0]_28301  loss=3.252002 |g|=0.374	lr=3.42e-04 | 18.4%@S24  T=4.45s(data=1.5ms QKV=2.10s FFN=3.03s) eta=1d 16:27:59 | 42.8K token/s | 
[epoch_0]_28311  loss=3.213141 |g|=0.411	lr=3.42e-04 | 19.2%@S24  T=1.75s(data=1.7ms QKV=2.10s FFN=3.04s) eta=15:56:38 | 43.0K token/s | 
[epoch_0]_28321  loss=3.232679 |g|=0.39	lr=3.41e-04 | 20.1%@S24  T=1.72s(data=1.6ms QKV=2.10s FFN=3.04s) eta=15:36:30 | 43.2K token/s | 
[epoch_0]_28331  loss=3.327638 |g|=0.399	lr=3.41e-04 | 20.9%@S24  T=1.78s(data=1.5ms QKV=2.11s FFN=3.04s) eta=16:10:35 | 43.3K token/s | 
[epoch_0]_28341  loss=3.204519 |g|=0.402	lr=3.41e-04 | 21.7%@S24  T=1.78s(data=1.6ms QKV=2.10s FFN=3.04s) eta=16:07:41 | 43.5K token/s | 
[epoch_0]_28351  loss=3.199841 |g|=0.409	lr=3.41e-04 | 22.5%@S24  T=1.72s(data=1.5ms QKV=2.11s FFN=3.04s) eta=15:34:59 | 43.7K token/s | 
[epoch_0]_28361  loss=3.233179 |g|=0.42	lr=3.41e-04 | 23.3%@S24  T=1.78s(data=1.7ms QKV=2.11s FFN=3.04s) eta=16:06:40 | 43.8K token/s | 
[epoch_0]_28371  loss=3.284037 |g|=0.402	lr=3.41e-04 | 24.2%@S24  T=1.74s(data=1.6ms QKV=2.11s FFN=3.04s) eta=15:46:59 | 44.0K token/s | 
[epoch_0]_28381  loss=3.296368 |g|=0.406	lr=3.41e-04 | 25.0%@S24  T=1.76s(data=1.5ms QKV=2.11s FFN=3.04s) eta=16:00:16 | 44.1K token/s | 
[epoch_0]_28391  loss=3.279889 |g|=0.404	lr=3.40e-04 | 25.8%@S24  T=1.77s(data=1.7ms QKV=2.11s FFN=3.04s) eta=16:02:16 | 44.2K token/s | 
[Fuyou] head="1" update algorithm=4 t=9.84s
[eval] 
	 Loss@"edu_fineweb1B"=3.261(-0.00022) nBranch=1 nToken=6.31M best=3.2569(138) E2T=0.0825 T=36.7218(0)s x=0
	#3.26066±0.0980 tps=172K(6.30784M) a=[3.06069,3.53256] T=36.7218(sec)
[Section@28400] layer[16-24] tasks=19(nPassBack=0) last_loss=3.17815(0.0731261) N=(772,32480,31920 3748668)
[epoch_0]_28401  loss=3.215028 |g|=0.376	lr=3.40e-04 | 26.6%@S24  T=12.16s(data=1.6ms QKV=2.10s FFN=3.04s) eta=4d 14:14:02 | 42.3K token/s | 
[epoch_0]_28411  loss=3.304171 |g|=0.391	lr=3.40e-04 | 27.4%@S24  T=1.78s(data=1.6ms QKV=2.10s FFN=3.04s) eta=16:06:48 | 42.5K token/s | 
[epoch_0]_28421  loss=3.292366 |g|=0.396	lr=3.40e-04 | 28.3%@S24  T=1.81s(data=1.8ms QKV=2.11s FFN=3.04s) eta=16:21:33 | 42.7K token/s | 
[epoch_0]_28431  loss=3.275568 |g|=0.394	lr=3.40e-04 | 29.1%@S24  T=1.76s(data=1.5ms QKV=2.11s FFN=3.04s) eta=15:58:34 | 42.9K token/s | 
[epoch_0]_28441  loss=3.276000 |g|=0.414	lr=3.40e-04 | 29.9%@S24  T=1.75s(data=1.6ms QKV=2.11s FFN=3.04s) eta=15:52:35 | 43.1K token/s | 
[epoch_0]_28451  loss=3.224590 |g|=0.414	lr=3.39e-04 | 30.7%@S24  T=1.72s(data=1.5ms QKV=2.11s FFN=3.04s) eta=15:35:43 | 43.3K token/s | 
[epoch_0]_28461  loss=3.255632 |g|=0.413	lr=3.39e-04 | 31.5%@S24  T=1.74s(data=1.6ms QKV=2.11s FFN=3.04s) eta=15:45:03 | 43.5K token/s | 
[epoch_0]_28471  loss=3.242368 |g|=0.391	lr=3.39e-04 | 32.4%@S24  T=1.72s(data=1.8ms QKV=2.11s FFN=3.04s) eta=15:33:56 | 43.7K token/s | 
[epoch_0]_28481  loss=3.229848 |g|=0.415	lr=3.39e-04 | 33.2%@S24  T=1.73s(data=1.8ms QKV=2.11s FFN=3.04s) eta=15:36:00 | 43.9K token/s | 
[epoch_0]_28491  loss=3.287009 |g|=0.409	lr=3.39e-04 | 34.0%@S24  T=1.72s(data=1.9ms QKV=2.11s FFN=3.04s) eta=15:30:20 | 44.1K token/s | 
[Fuyou] head="2" update algorithm=4 t=10.43s
[Section@28500] layer[24-32] tasks=19(nPassBack=0) last_loss=3.27854(-0.077939) N=(772,32592,32032 3761868)
[epoch_0]_28501  loss=3.204086 |g|=0.382	lr=3.39e-04 | 34.8%@S24  T=3.87s(data=1.9ms QKV=2.10s FFN=3.04s) eta=1d 10:56:43 | 42.9K token/s | 
[epoch_0]_28511  loss=3.244285 |g|=0.414	lr=3.39e-04 | 35.6%@S24  T=1.76s(data=1.8ms QKV=2.10s FFN=3.04s) eta=15:51:37 | 43.1K token/s | 
[epoch_0]_28521  loss=3.221798 |g|=0.408	lr=3.38e-04 | 36.4%@S24  T=1.76s(data=1.8ms QKV=2.10s FFN=3.04s) eta=15:56:13 | 43.3K token/s | 
[epoch_0]_28531  loss=3.220280 |g|=0.41	lr=3.38e-04 | 37.3%@S24  T=1.72s(data=1.6ms QKV=2.11s FFN=3.04s) eta=15:33:37 | 43.5K token/s | 
[epoch_0]_28541  loss=3.257856 |g|=0.425	lr=3.38e-04 | 38.1%@S24  T=1.74s(data=1.8ms QKV=2.11s FFN=3.04s) eta=15:41:47 | 43.7K token/s | 
[epoch_0]_28551  loss=3.184927 |g|=0.418	lr=3.38e-04 | 38.9%@S24  T=1.74s(data=2.1ms QKV=2.11s FFN=3.04s) eta=15:39:51 | 43.8K token/s | 
[epoch_0]_28561  loss=3.277173 |g|=0.426	lr=3.38e-04 | 39.7%@S24  T=1.78s(data=1.7ms QKV=2.11s FFN=3.04s) eta=16:03:37 | 43.9K token/s | 
[epoch_0]_28571  loss=3.214180 |g|=0.396	lr=3.38e-04 | 40.5%@S24  T=1.76s(data=1.6ms QKV=2.11s FFN=3.04s) eta=15:53:22 | 44.1K token/s | 
[epoch_0]_28581  loss=3.267181 |g|=0.405	lr=3.37e-04 | 41.4%@S24  T=1.77s(data=1.9ms QKV=2.11s FFN=3.04s) eta=15:54:46 | 44.2K token/s | 
[epoch_0]_28591  loss=3.204368 |g|=0.4	lr=3.37e-04 | 42.2%@S24  T=1.73s(data=1.7ms QKV=2.11s FFN=3.04s) eta=15:33:34 | 44.4K token/s | 
[Fuyou] head="3" update algorithm=4 t=10.14s
[eval] 
	 Loss@"edu_fineweb1B"=3.262(-0.0017) nBranch=1 nToken=6.31M best=3.2569(138) E2T=0.0409 T=36.7285(0)s x=0
	#3.26236±0.0978 tps=172K(6.30784M) a=[3.07044,3.53415] T=36.7285(sec)
[Section@28600] layer[32-40] tasks=19(nPassBack=0) last_loss=3.22145(0.0546296) N=(772,32704,32144 3775068)
[epoch_0]_28601  loss=3.236924 |g|=0.406	lr=3.37e-04 | 43.0%@S24  T=12.41s(data=1.9ms QKV=2.10s FFN=3.04s) eta=4d 15:51:05 | 42.5K token/s | 
[epoch_0]_28611  loss=3.260034 |g|=0.411	lr=3.37e-04 | 43.8%@S24  T=1.77s(data=2.0ms QKV=2.10s FFN=3.04s) eta=15:55:02 | 42.7K token/s | 
[epoch_0]_28621  loss=3.223378 |g|=0.403	lr=3.37e-04 | 44.6%@S24  T=1.73s(data=1.8ms QKV=2.11s FFN=3.04s) eta=15:37:11 | 42.9K token/s | 
[epoch_0]_28631  loss=3.216280 |g|=0.416	lr=3.37e-04 | 45.5%@S24  T=1.79s(data=1.8ms QKV=2.11s FFN=3.04s) eta=16:08:23 | 43.0K token/s | 
[epoch_0]_28641  loss=3.312673 |g|=0.416	lr=3.37e-04 | 46.3%@S24  T=1.73s(data=1.6ms QKV=2.10s FFN=3.04s) eta=15:36:34 | 43.2K token/s | 
[epoch_0]_28651  loss=3.240262 |g|=0.409	lr=3.36e-04 | 47.1%@S24  T=1.75s(data=2.1ms QKV=2.11s FFN=3.04s) eta=15:45:22 | 43.4K token/s | 
[epoch_0]_28661  loss=3.159889 |g|=0.4	lr=3.36e-04 | 47.9%@S24  T=1.74s(data=1.5ms QKV=2.11s FFN=3.04s) eta=15:38:54 | 43.6K token/s | 
[epoch_0]_28671  loss=3.191102 |g|=0.415	lr=3.36e-04 | 48.7%@S24  T=1.80s(data=1.6ms QKV=2.11s FFN=3.04s) eta=16:10:39 | 43.7K token/s | 
[epoch_0]_28681  loss=3.247379 |g|=0.397	lr=3.36e-04 | 49.6%@S24  T=1.72s(data=1.5ms QKV=2.11s FFN=3.04s) eta=15:26:18 | 43.9K token/s | 
[epoch_0]_28691  loss=3.214193 |g|=0.404	lr=3.36e-04 | 50.4%@S24  T=1.78s(data=1.6ms QKV=2.11s FFN=3.04s) eta=15:58:10 | 44.0K token/s | 
[Fuyou] head="4" update algorithm=4 t=11.41s
[Section@28700] layer[40-48] tasks=19(nPassBack=0) last_loss=3.1979(0.0734956) N=(772,32816,32256 3788268)
[epoch_0]_28701  loss=3.333924 |g|=0.391	lr=3.36e-04 | 51.2%@S24  T=4.14s(data=2.0ms QKV=2.10s FFN=3.03s) eta=1d 13:12:15 | 42.8K token/s | 
[epoch_0]_28711  loss=3.323250 |g|=0.395	lr=3.35e-04 | 52.0%@S24  T=1.69s(data=1.8ms QKV=2.10s FFN=3.04s) eta=15:12:34 | 43.1K token/s | 
[epoch_0]_28721  loss=3.292268 |g|=0.412	lr=3.35e-04 | 52.8%@S24  T=1.73s(data=1.6ms QKV=2.11s FFN=3.04s) eta=15:31:14 | 43.3K token/s | 
[epoch_0]_28731  loss=3.206740 |g|=0.412	lr=3.35e-04 | 53.7%@S24  T=1.73s(data=2.3ms QKV=2.11s FFN=3.04s) eta=15:31:26 | 43.5K token/s | 
[epoch_0]_28741  loss=3.229835 |g|=0.404	lr=3.35e-04 | 54.5%@S24  T=1.79s(data=1.5ms QKV=2.11s FFN=3.04s) eta=16:05:20 | 43.6K token/s | 
[epoch_0]_28751  loss=3.208176 |g|=0.385	lr=3.35e-04 | 55.3%@S24  T=1.70s(data=2.7ms QKV=2.11s FFN=3.04s) eta=15:17:03 | 43.8K token/s | 
[epoch_0]_28761  loss=3.337250 |g|=0.419	lr=3.35e-04 | 56.1%@S24  T=1.73s(data=2.6ms QKV=2.11s FFN=3.04s) eta=15:30:28 | 44.0K token/s | 
[epoch_0]_28771  loss=3.265440 |g|=0.408	lr=3.35e-04 | 56.9%@S24  T=1.71s(data=2.8ms QKV=2.11s FFN=3.04s) eta=15:20:14 | 44.2K token/s | 
[epoch_0]_28781  loss=3.286893 |g|=0.394	lr=3.34e-04 | 57.7%@S24  T=1.73s(data=3.2ms QKV=2.11s FFN=3.04s) eta=15:29:13 | 44.4K token/s | 
[epoch_0]_28791  loss=3.243922 |g|=0.385	lr=3.34e-04 | 58.6%@S24  T=1.72s(data=2.4ms QKV=2.11s FFN=3.04s) eta=15:22:44 | 44.5K token/s | 
[Fuyou] head="5" update algorithm=4 t=14.46s
[eval] 
	 Loss@"edu_fineweb1B"=3.261(0.00094) nBranch=1 nToken=6.31M best=3.2569(138) E2T=0.0679 T=36.7045(0)s x=0
	#3.26142±0.0988 tps=172K(6.30784M) a=[3.06615,3.53859] T=36.7045(sec)
[Section@28800] layer[0-8] tasks=19(nPassBack=0) last_loss=3.19348(0.0323036) N=(772,32928,32368 3801468)
[epoch_0]_28801  loss=3.299273 |g|=0.399	lr=3.34e-04 | 59.4%@S24  T=12.29s(data=2.0ms QKV=2.10s FFN=3.04s) eta=4d 14:01:40 | 42.6K token/s | 
[epoch_0]_28811  loss=3.298901 |g|=0.427	lr=3.34e-04 | 60.2%@S24  T=1.71s(data=2.0ms QKV=2.11s FFN=3.04s) eta=15:17:29 | 42.9K token/s | 
[epoch_0]_28821  loss=3.240118 |g|=0.407	lr=3.34e-04 | 61.0%@S24  T=1.73s(data=2.2ms QKV=2.10s FFN=3.04s) eta=15:26:51 | 43.1K token/s | 
[epoch_0]_28831  loss=3.259874 |g|=0.416	lr=3.34e-04 | 61.8%@S24  T=1.77s(data=1.5ms QKV=2.11s FFN=3.04s) eta=15:48:41 | 43.3K token/s | 
[epoch_0]_28841  loss=3.218046 |g|=0.39	lr=3.33e-04 | 62.7%@S24  T=1.71s(data=1.9ms QKV=2.11s FFN=3.04s) eta=15:17:20 | 43.5K token/s | 
[epoch_0]_28851  loss=3.264701 |g|=0.438	lr=3.33e-04 | 63.5%@S24  T=1.78s(data=1.6ms QKV=2.11s FFN=3.04s) eta=15:56:27 | 43.6K token/s | 
[epoch_0]_28861  loss=3.206089 |g|=0.416	lr=3.33e-04 | 64.3%@S24  T=1.72s(data=1.6ms QKV=2.11s FFN=3.04s) eta=15:19:40 | 43.8K token/s | 
[epoch_0]_28871  loss=3.298070 |g|=0.402	lr=3.33e-04 | 65.1%@S24  T=1.70s(data=2.0ms QKV=2.11s FFN=3.04s) eta=15:13:18 | 44.1K token/s | 
[epoch_0]_28881  loss=3.196591 |g|=0.377	lr=3.33e-04 | 65.9%@S24  T=1.74s(data=1.9ms QKV=2.11s FFN=3.04s) eta=15:31:25 | 44.2K token/s | 
[epoch_0]_28891  loss=3.214514 |g|=0.423	lr=3.33e-04 | 66.8%@S24  T=1.76s(data=1.8ms QKV=2.11s FFN=3.04s) eta=15:43:45 | 44.3K token/s | 
[Fuyou] head="0" update algorithm=4 t=10.85s
[Section@28900] layer[8-16] tasks=19(nPassBack=0) last_loss=3.22186(-0.0462399) N=(772,33040,32480 3814668)
[epoch_0]_28901  loss=3.167842 |g|=0.404	lr=3.33e-04 | 67.6%@S24  T=4.23s(data=2.0ms QKV=2.10s FFN=3.03s) eta=1d 13:43:59 | 43.1K token/s | 
[epoch_0]_28911  loss=3.206862 |g|=0.414	lr=3.32e-04 | 68.4%@S24  T=1.70s(data=1.7ms QKV=2.10s FFN=3.04s) eta=15:10:41 | 43.3K token/s | 
[epoch_0]_28921  loss=3.225682 |g|=0.431	lr=3.32e-04 | 69.2%@S24  T=1.80s(data=1.6ms QKV=2.11s FFN=3.04s) eta=16:05:02 | 43.4K token/s | 
[epoch_0]_28931  loss=3.249388 |g|=0.391	lr=3.32e-04 | 70.0%@S24  T=1.73s(data=1.7ms QKV=2.11s FFN=3.04s) eta=15:23:53 | 43.6K token/s | 
[epoch_0]_28941  loss=3.251536 |g|=0.399	lr=3.32e-04 | 70.9%@S24  T=1.77s(data=1.9ms QKV=2.11s FFN=3.04s) eta=15:48:02 | 43.8K token/s | 
[epoch_0]_28951  loss=3.297984 |g|=0.408	lr=3.32e-04 | 71.7%@S24  T=1.74s(data=1.8ms QKV=2.11s FFN=3.04s) eta=15:31:39 | 43.9K token/s | 
[epoch_0]_28961  loss=3.238151 |g|=0.391	lr=3.32e-04 | 72.5%@S24  T=1.79s(data=1.6ms QKV=2.11s FFN=3.04s) eta=15:57:09 | 44.0K token/s | 
[epoch_0]_28971  loss=3.294662 |g|=0.398	lr=3.31e-04 | 73.3%@S24  T=1.79s(data=1.6ms QKV=2.11s FFN=3.04s) eta=15:55:35 | 44.1K token/s | 
[epoch_0]_28981  loss=3.271405 |g|=0.377	lr=3.31e-04 | 74.1%@S24  T=1.73s(data=1.7ms QKV=2.11s FFN=3.04s) eta=15:25:22 | 44.3K token/s | 
[epoch_0]_28991  loss=3.234652 |g|=0.416	lr=3.31e-04 | 74.9%@S24  T=1.78s(data=1.6ms QKV=2.11s FFN=3.04s) eta=15:52:56 | 44.4K token/s | 
[Fuyou] head="1" update algorithm=4 t=10.60s
[eval] 
	 Loss@"edu_fineweb1B"=3.261(6.7e-05) nBranch=1 nToken=6.31M best=3.2569(138) E2T=0.0283 T=36.7194(0)s x=0
	#3.26135±0.0985 tps=172K(6.30784M) a=[3.06902,3.53567] T=36.7194(sec)
[Section@29000] layer[16-24] tasks=19(nPassBack=0) last_loss=3.23309(-0.0549338) N=(772,33152,32592 3827868)
[epoch_0]_29001  loss=3.180231 |g|=0.398	lr=3.31e-04 | 75.8%@S24  T=12.34s(data=1.9ms QKV=2.10s FFN=3.04s) eta=4d 13:49:32 | 42.5K token/s | 
[epoch_0]_29011  loss=3.221889 |g|=0.403	lr=3.31e-04 | 76.6%@S24  T=1.70s(data=2.2ms QKV=2.10s FFN=3.04s) eta=15:08:28 | 42.7K token/s | 
[epoch_0]_29021  loss=3.202143 |g|=0.394	lr=3.31e-04 | 77.4%@S24  T=1.76s(data=1.6ms QKV=2.11s FFN=3.04s) eta=15:38:43 | 42.9K token/s | 
[epoch_0]_29031  loss=3.295663 |g|=0.422	lr=3.31e-04 | 78.2%@S24  T=1.72s(data=1.9ms QKV=2.11s FFN=3.04s) eta=15:16:37 | 43.2K token/s | 
[epoch_0]_29041  loss=3.258346 |g|=0.421	lr=3.30e-04 | 79.0%@S24  T=1.79s(data=1.7ms QKV=2.11s FFN=3.04s) eta=15:55:25 | 43.3K token/s | 
[epoch_0]_29051  loss=3.229835 |g|=0.416	lr=3.30e-04 | 79.9%@S24  T=1.74s(data=1.5ms QKV=2.11s FFN=3.04s) eta=15:26:42 | 43.5K token/s | 
[epoch_0]_29061  loss=3.252921 |g|=0.398	lr=3.30e-04 | 80.7%@S24  T=1.73s(data=1.6ms QKV=2.11s FFN=3.04s) eta=15:22:00 | 43.7K token/s | 
[epoch_0]_29071  loss=3.214743 |g|=0.456	lr=3.30e-04 | 81.5%@S24  T=1.78s(data=6.5ms QKV=2.11s FFN=3.04s) eta=15:50:03 | 43.8K token/s | 
[epoch_0]_29081  loss=3.227596 |g|=0.421	lr=3.30e-04 | 82.3%@S24  T=1.79s(data=1.6ms QKV=2.11s FFN=3.04s) eta=15:52:04 | 43.9K token/s | 
[epoch_0]_29091  loss=3.270574 |g|=0.424	lr=3.30e-04 | 83.1%@S24  T=1.78s(data=1.5ms QKV=2.11s FFN=3.04s) eta=15:48:19 | 44.0K token/s | 
[Fuyou] head="2" update algorithm=4 t=9.30s
[Section@29100] layer[24-32] tasks=19(nPassBack=0) last_loss=3.21591(0.0626304) N=(772,33264,32704 3841068)
[epoch_0]_29101  loss=3.258847 |g|=0.382	lr=3.29e-04 | 84.0%@S24  T=4.61s(data=1.7ms QKV=2.10s FFN=3.03s) eta=1d 16:54:40 | 42.7K token/s | 
[epoch_0]_29111  loss=3.286620 |g|=0.43	lr=3.29e-04 | 84.8%@S24  T=1.70s(data=2.0ms QKV=2.11s FFN=3.04s) eta=15:04:35 | 43.0K token/s | 
[epoch_0]_29121  loss=3.196470 |g|=0.388	lr=3.29e-04 | 85.6%@S24  T=1.76s(data=1.6ms QKV=2.11s FFN=3.04s) eta=15:38:37 | 43.1K token/s | 
[epoch_0]_29131  loss=3.291286 |g|=0.404	lr=3.29e-04 | 86.4%@S24  T=1.72s(data=1.6ms QKV=2.11s FFN=3.04s) eta=15:15:08 | 43.4K token/s | 
[epoch_0]_29141  loss=3.275945 |g|=0.397	lr=3.29e-04 | 87.2%@S24  T=1.70s(data=1.9ms QKV=2.11s FFN=3.04s) eta=15:04:53 | 43.6K token/s | 
[epoch_0]_29151  loss=3.269822 |g|=0.406	lr=3.29e-04 | 88.1%@S24  T=1.78s(data=1.5ms QKV=2.11s FFN=3.04s) eta=15:44:16 | 43.7K token/s | 
[epoch_0]_29161  loss=3.288104 |g|=0.433	lr=3.29e-04 | 88.9%@S24  T=1.78s(data=1.5ms QKV=2.11s FFN=3.04s) eta=15:43:47 | 43.8K token/s | 
[epoch_0]_29171  loss=3.187462 |g|=0.443	lr=3.28e-04 | 89.7%@S24  T=1.79s(data=1.6ms QKV=2.11s FFN=3.04s) eta=15:48:44 | 43.9K token/s | 
[epoch_0]_29181  loss=3.205842 |g|=0.429	lr=3.28e-04 | 90.5%@S24  T=1.71s(data=1.8ms QKV=2.11s FFN=3.04s) eta=15:06:34 | 44.1K token/s | 
[epoch_0]_29191  loss=3.231583 |g|=0.406	lr=3.28e-04 | 91.3%@S24  T=1.79s(data=1.6ms QKV=2.11s FFN=3.04s) eta=15:48:46 | 44.2K token/s | 
[Fuyou] head="3" update algorithm=4 t=9.57s
[eval] 
	 Loss@"edu_fineweb1B"=3.259(0.0026) nBranch=1 nToken=6.31M best=3.2569(138) E2T=0.0415 T=36.7398(0)s x=0
	#3.25875±0.0981 tps=172K(6.30784M) a=[3.06905,3.53192] T=36.7398(sec)
[Section@29200] layer[32-40] tasks=19(nPassBack=0) last_loss=3.21724(0.00421095) N=(772,33376,32816 3854268)
[epoch_0]_29201  loss=3.179436 |g|=0.379	lr=3.28e-04 | 92.2%@S24  T=12.07s(data=2.0ms QKV=2.11s FFN=3.03s) eta=4d 10:43:57 | 42.4K token/s | 
[epoch_0]_29211  loss=3.191111 |g|=0.429	lr=3.28e-04 | 93.0%@S24  T=1.79s(data=1.7ms QKV=2.11s FFN=3.04s) eta=15:50:14 | 42.5K token/s | 
[epoch_0]_29221  loss=3.238855 |g|=0.442	lr=3.28e-04 | 93.8%@S24  T=1.72s(data=2.1ms QKV=2.11s FFN=3.04s) eta=15:11:58 | 42.8K token/s | 
[epoch_0]_29231  loss=3.242280 |g|=0.403	lr=3.27e-04 | 94.6%@S24  T=1.73s(data=1.5ms QKV=2.11s FFN=3.04s) eta=15:18:30 | 43.0K token/s | 
[epoch_0]_29241  loss=3.194938 |g|=0.398	lr=3.27e-04 | 95.4%@S24  T=1.77s(data=1.9ms QKV=2.11s FFN=3.04s) eta=15:38:06 | 43.2K token/s | 
[epoch_0]_29251  loss=3.246075 |g|=0.394	lr=3.27e-04 | 96.2%@S24  T=1.72s(data=1.6ms QKV=2.11s FFN=3.04s) eta=15:12:46 | 43.4K token/s | 
[epoch_0]_29261  loss=3.272239 |g|=0.401	lr=3.27e-04 | 97.1%@S24  T=1.79s(data=1.5ms QKV=2.11s FFN=3.04s) eta=15:50:13 | 43.5K token/s | 
[epoch_0]_29271  loss=3.333515 |g|=0.437	lr=3.27e-04 | 97.9%@S24  T=1.71s(data=1.8ms QKV=2.11s FFN=3.04s) eta=15:07:44 | 43.7K token/s | 
[epoch_0]_29281  loss=3.242375 |g|=0.397	lr=3.27e-04 | 98.7%@S24  T=1.71s(data=1.9ms QKV=2.11s FFN=3.04s) eta=15:02:49 | 43.9K token/s | 
[epoch_0]_29291  loss=3.199605 |g|=0.41	lr=3.27e-04 | 99.5%@S24  T=1.71s(data=1.8ms QKV=2.11s FFN=3.04s) eta=15:05:59 | 44.1K token/s | 
[epoch_0]_29296  loss=3.199839 |g|=0.412	lr=3.26e-04 | 99.9%@S24  T=1.73s(data=2.0ms QKV=2.11s FFN=3.04s) eta=15:13:48 | 44.3K token/s | 
-------- End of shard_24@"./Datasets/edu_fineweb1B/edu_fineweb_train_000478.bin"-------- 
[shard-25]@"./Datasets/edu_fineweb1B/edu_fineweb_train_000479.bin": tokens=100(M) nShardSamples=1220(2441400) 
[Fuyou] head="4" update algorithm=4 t=11.67s
[Section@29300] layer[40-48] tasks=19(nPassBack=0) last_loss=3.20738(-0.00947857) N=(772,33488,32928 3867468)
[epoch_0]_29301  loss=3.218046 |g|=0.408	lr=3.26e-04 | 0.3%@S25  T=4.19s(data=1.7ms QKV=2.10s FFN=3.03s) eta=1d 12:58:21 | 43.1K token/s | 
[epoch_0]_29311  loss=3.211315 |g|=0.42	lr=3.26e-04 | 1.2%@S25  T=1.77s(data=1.2ms QKV=2.11s FFN=3.04s) eta=15:34:31 | 43.2K token/s | 
[epoch_0]_29321  loss=3.308474 |g|=0.442	lr=3.26e-04 | 2.0%@S25  T=1.70s(data=1.6ms QKV=2.11s FFN=3.04s) eta=15:01:06 | 43.5K token/s | 
[epoch_0]_29331  loss=3.240397 |g|=0.399	lr=3.26e-04 | 2.8%@S25  T=1.75s(data=1.7ms QKV=2.11s FFN=3.04s) eta=15:22:58 | 43.6K token/s | 
[epoch_0]_29341  loss=3.294197 |g|=0.407	lr=3.26e-04 | 3.6%@S25  T=1.70s(data=1.6ms QKV=2.11s FFN=3.04s) eta=14:57:06 | 43.9K token/s | 
[epoch_0]_29351  loss=3.287890 |g|=0.43	lr=3.26e-04 | 4.4%@S25  T=1.71s(data=1.6ms QKV=2.11s FFN=3.04s) eta=15:04:48 | 44.1K token/s | 
[epoch_0]_29361  loss=3.281667 |g|=0.42	lr=3.25e-04 | 5.3%@S25  T=1.77s(data=1.7ms QKV=2.11s FFN=3.04s) eta=15:35:11 | 44.2K token/s | 
[epoch_0]_29371  loss=3.286052 |g|=0.42	lr=3.25e-04 | 6.1%@S25  T=1.72s(data=1.6ms QKV=2.11s FFN=3.04s) eta=15:06:49 | 44.3K token/s | 
[epoch_0]_29381  loss=3.281898 |g|=0.421	lr=3.25e-04 | 6.9%@S25  T=1.80s(data=1.7ms QKV=2.11s FFN=3.04s) eta=15:47:16 | 44.4K token/s | 
[epoch_0]_29391  loss=3.221549 |g|=0.41	lr=3.25e-04 | 7.7%@S25  T=1.74s(data=1.5ms QKV=2.11s FFN=3.04s) eta=15:20:16 | 44.5K token/s | 
[Fuyou] head="5" update algorithm=4 t=11.08s
[eval] 
	 Loss@"edu_fineweb1B"=3.251(0.0075) nBranch=1 nToken=6.31M best=3.2587(145) E2T=0.0373 T=36.7159(0)s x=0
	#3.25125±0.0979 tps=172K(6.30784M) a=[3.0628,3.52246] T=36.7159(sec)
[Section@29400] layer[0-8] tasks=19(nPassBack=0) last_loss=3.21393(-0.0204477) N=(772,33600,33040 3880668)
[epoch_0]_29401  loss=3.309824 |g|=0.405	lr=3.25e-04 | 8.5%@S25  T=11.80s(data=1.6ms QKV=2.10s FFN=3.04s) eta=4d 07:41:29 | 42.7K token/s | 
[epoch_0]_29411  loss=3.264541 |g|=0.439	lr=3.25e-04 | 9.4%@S25  T=1.71s(data=1.6ms QKV=2.11s FFN=3.04s) eta=15:01:39 | 42.9K token/s | 
[epoch_0]_29421  loss=3.226997 |g|=0.412	lr=3.25e-04 | 10.2%@S25  T=1.74s(data=1.7ms QKV=2.11s FFN=3.04s) eta=15:19:01 | 43.1K token/s | 
[epoch_0]_29431  loss=3.189504 |g|=0.419	lr=3.24e-04 | 11.0%@S25  T=1.70s(data=1.7ms QKV=2.11s FFN=3.04s) eta=14:56:39 | 43.4K token/s | 
[epoch_0]_29441  loss=3.223717 |g|=0.434	lr=3.24e-04 | 11.8%@S25  T=1.72s(data=1.8ms QKV=2.11s FFN=3.04s) eta=15:03:42 | 43.6K token/s | 
[epoch_0]_29451  loss=3.235929 |g|=0.402	lr=3.24e-04 | 12.6%@S25  T=1.79s(data=1.8ms QKV=2.11s FFN=3.04s) eta=15:40:59 | 43.7K token/s | 
[epoch_0]_29461  loss=3.316838 |g|=0.443	lr=3.24e-04 | 13.5%@S25  T=1.74s(data=1.7ms QKV=2.11s FFN=3.04s) eta=15:15:16 | 43.9K token/s | 
[epoch_0]_29471  loss=3.358684 |g|=0.415	lr=3.24e-04 | 14.3%@S25  T=1.71s(data=1.7ms QKV=2.11s FFN=3.04s) eta=15:01:38 | 44.1K token/s | 
[epoch_0]_29481  loss=3.180631 |g|=0.418	lr=3.24e-04 | 15.1%@S25  T=1.71s(data=1.6ms QKV=2.11s FFN=3.04s) eta=14:57:19 | 44.3K token/s | 
[epoch_0]_29491  loss=3.305659 |g|=0.405	lr=3.23e-04 | 15.9%@S25  T=1.74s(data=1.6ms QKV=2.11s FFN=3.04s) eta=15:15:33 | 44.4K token/s | 
[Fuyou] head="0" update algorithm=4 t=10.91s
[Section@29500] layer[8-16] tasks=19(nPassBack=0) last_loss=3.28083(-0.0589693) N=(772,33712,33152 3893868)
[epoch_0]_29501  loss=3.190705 |g|=0.385	lr=3.23e-04 | 16.7%@S25  T=4.34s(data=1.6ms QKV=2.10s FFN=3.03s) eta=1d 14:02:33 | 43.1K token/s | 
[epoch_0]_29511  loss=3.286958 |g|=0.406	lr=3.23e-04 | 17.5%@S25  T=1.71s(data=1.7ms QKV=2.10s FFN=3.04s) eta=14:57:16 | 43.4K token/s | 
[epoch_0]_29521  loss=3.323765 |g|=0.396	lr=3.23e-04 | 18.4%@S25  T=1.71s(data=1.5ms QKV=2.10s FFN=3.04s) eta=14:59:04 | 43.6K token/s | 
[epoch_0]_29531  loss=3.270365 |g|=0.42	lr=3.23e-04 | 19.2%@S25  T=1.79s(data=1.7ms QKV=2.11s FFN=3.04s) eta=15:41:01 | 43.7K token/s | 
[epoch_0]_29541  loss=3.238023 |g|=0.432	lr=3.23e-04 | 20.0%@S25  T=1.75s(data=1.8ms QKV=2.11s FFN=3.04s) eta=15:17:58 | 43.9K token/s | 
[epoch_0]_29551  loss=3.254255 |g|=0.422	lr=3.23e-04 | 20.8%@S25  T=1.76s(data=1.5ms QKV=2.11s FFN=3.04s) eta=15:22:59 | 44.0K token/s | 
[epoch_0]_29561  loss=3.255872 |g|=0.4	lr=3.22e-04 | 21.6%@S25  T=1.73s(data=2.0ms QKV=2.11s FFN=3.04s) eta=15:09:03 | 44.2K token/s | 
[epoch_0]_29571  loss=3.252934 |g|=0.463	lr=3.22e-04 | 22.5%@S25  T=1.78s(data=1.5ms QKV=2.11s FFN=3.04s) eta=15:31:29 | 44.3K token/s | 
[epoch_0]_29581  loss=3.207985 |g|=0.403	lr=3.22e-04 | 23.3%@S25  T=1.70s(data=1.7ms QKV=2.11s FFN=3.04s) eta=14:53:04 | 44.4K token/s | 
[epoch_0]_29591  loss=3.326622 |g|=0.423	lr=3.22e-04 | 24.1%@S25  T=1.71s(data=1.6ms QKV=2.11s FFN=3.04s) eta=14:56:45 | 44.6K token/s | 
[Fuyou] head="1" update algorithm=4 t=11.07s
[eval] 
	 Loss@"edu_fineweb1B"=3.245(0.0058) nBranch=1 nToken=6.31M best=3.2512(146) E2T=0.0359 T=36.7164(0)s x=0
	#3.24542±0.0979 tps=172K(6.30784M) a=[3.05851,3.51736] T=36.7164(sec)
[Section@29600] layer[16-24] tasks=19(nPassBack=0) last_loss=3.20949(0.0235965) N=(772,33824,33264 3907068)
[epoch_0]_29601  loss=3.208430 |g|=0.374	lr=3.22e-04 | 24.9%@S25  T=11.95s(data=1.9ms QKV=2.10s FFN=3.04s) eta=4d 08:18:46 | 42.7K token/s | 
[epoch_0]_29611  loss=3.206913 |g|=0.392	lr=3.22e-04 | 25.7%@S25  T=1.80s(data=1.5ms QKV=2.10s FFN=3.04s) eta=15:40:23 | 42.9K token/s | 
[epoch_0]_29621  loss=3.293056 |g|=0.396	lr=3.21e-04 | 26.6%@S25  T=1.79s(data=1.7ms QKV=2.10s FFN=3.04s) eta=15:35:41 | 43.0K token/s | 
[epoch_0]_29631  loss=3.314148 |g|=0.406	lr=3.21e-04 | 27.4%@S25  T=1.71s(data=1.5ms QKV=2.10s FFN=3.04s) eta=14:56:31 | 43.3K token/s | 
[epoch_0]_29641  loss=3.260059 |g|=0.413	lr=3.21e-04 | 28.2%@S25  T=1.82s(data=5.8ms QKV=2.10s FFN=3.04s) eta=15:52:25 | 43.3K token/s | 
[epoch_0]_29651  loss=3.153485 |g|=0.419	lr=3.21e-04 | 29.0%@S25  T=1.72s(data=1.7ms QKV=2.10s FFN=3.04s) eta=14:58:04 | 43.6K token/s | 
[epoch_0]_29661  loss=3.214885 |g|=0.425	lr=3.21e-04 | 29.8%@S25  T=1.76s(data=1.8ms QKV=2.11s FFN=3.04s) eta=15:20:08 | 43.7K token/s | 
[epoch_0]_29671  loss=3.223869 |g|=0.409	lr=3.21e-04 | 30.7%@S25  T=1.72s(data=1.6ms QKV=2.11s FFN=3.04s) eta=15:00:35 | 43.9K token/s | 
[epoch_0]_29681  loss=3.264826 |g|=0.431	lr=3.21e-04 | 31.5%@S25  T=1.72s(data=2.6ms QKV=2.11s FFN=3.04s) eta=14:57:18 | 44.1K token/s | 
[epoch_0]_29691  loss=3.273136 |g|=0.41	lr=3.20e-04 | 32.3%@S25  T=1.71s(data=1.8ms QKV=2.10s FFN=3.04s) eta=14:54:43 | 44.3K token/s | 
[Fuyou] head="2" update algorithm=4 t=10.55s
[Section@29700] layer[24-32] tasks=19(nPassBack=0) last_loss=3.17176(0.044148) N=(772,33936,33376 3920268)
[epoch_0]_29701  loss=3.233746 |g|=0.387	lr=3.20e-04 | 33.1%@S25  T=3.97s(data=1.9ms QKV=2.10s FFN=3.03s) eta=1d 10:30:50 | 43.1K token/s | 
[epoch_0]_29711  loss=3.190163 |g|=0.428	lr=3.20e-04 | 33.9%@S25  T=1.71s(data=1.7ms QKV=2.10s FFN=3.04s) eta=14:54:41 | 43.3K token/s | 
[epoch_0]_29721  loss=3.244299 |g|=0.395	lr=3.20e-04 | 34.8%@S25  T=1.73s(data=1.8ms QKV=2.11s FFN=3.04s) eta=15:04:24 | 43.5K token/s | 
[epoch_0]_29731  loss=3.169642 |g|=0.396	lr=3.20e-04 | 35.6%@S25  T=1.77s(data=1.8ms QKV=2.10s FFN=3.04s) eta=15:22:16 | 43.7K token/s | 
[epoch_0]_29741  loss=3.199852 |g|=0.409	lr=3.20e-04 | 36.4%@S25  T=1.73s(data=1.6ms QKV=2.10s FFN=3.04s) eta=15:03:42 | 43.9K token/s | 
[epoch_0]_29751  loss=3.207998 |g|=0.42	lr=3.19e-04 | 37.2%@S25  T=1.80s(data=1.8ms QKV=2.10s FFN=3.04s) eta=15:36:41 | 43.9K token/s | 
[epoch_0]_29761  loss=3.272847 |g|=0.412	lr=3.19e-04 | 38.0%@S25  T=1.77s(data=1.7ms QKV=2.10s FFN=3.04s) eta=15:23:53 | 44.1K token/s | 
[epoch_0]_29771  loss=3.281700 |g|=0.432	lr=3.19e-04 | 38.8%@S25  T=1.77s(data=1.7ms QKV=2.11s FFN=3.04s) eta=15:23:17 | 44.2K token/s | 
[epoch_0]_29781  loss=3.231349 |g|=0.445	lr=3.19e-04 | 39.7%@S25  T=1.72s(data=1.5ms QKV=2.10s FFN=3.04s) eta=14:56:12 | 44.3K token/s | 
[epoch_0]_29791  loss=3.267108 |g|=0.411	lr=3.19e-04 | 40.5%@S25  T=1.73s(data=1.8ms QKV=2.10s FFN=3.04s) eta=15:01:08 | 44.5K token/s | 
[Fuyou] head="3" update algorithm=4 t=11.23s
[eval] 
	 Loss@"edu_fineweb1B"=3.241(0.0046) nBranch=1 nToken=6.31M best=3.2454(147) E2T=0.0025 T=36.7026(0)s x=0
	#3.24086±0.0974 tps=172K(6.30784M) a=[3.05397,3.51322] T=36.7026(sec)
[Section@29800] layer[32-40] tasks=19(nPassBack=0) last_loss=3.23837(-0.0211275) N=(772,34048,33488 3933468)
[epoch_0]_29801  loss=3.349312 |g|=0.405	lr=3.19e-04 | 41.3%@S25  T=12.16s(data=1.7ms QKV=2.10s FFN=3.04s) eta=4d 09:31:05 | 42.6K token/s | 
[epoch_0]_29811  loss=3.225706 |g|=0.433	lr=3.19e-04 | 42.1%@S25  T=1.77s(data=1.5ms QKV=2.10s FFN=3.04s) eta=15:21:11 | 42.8K token/s | 
[epoch_0]_29821  loss=3.191917 |g|=0.406	lr=3.18e-04 | 42.9%@S25  T=1.78s(data=1.6ms QKV=2.10s FFN=3.04s) eta=15:28:12 | 42.9K token/s | 
[epoch_0]_29831  loss=3.183123 |g|=0.406	lr=3.18e-04 | 43.8%@S25  T=1.74s(data=1.5ms QKV=2.10s FFN=3.04s) eta=15:06:50 | 43.1K token/s | 
[epoch_0]_29841  loss=3.200328 |g|=0.412	lr=3.18e-04 | 44.6%@S25  T=1.70s(data=1.8ms QKV=2.10s FFN=3.04s) eta=14:46:07 | 43.4K token/s | 
[epoch_0]_29851  loss=3.189306 |g|=0.406	lr=3.18e-04 | 45.4%@S25  T=1.74s(data=1.6ms QKV=2.10s FFN=3.04s) eta=15:01:44 | 43.6K token/s | 
[epoch_0]_29861  loss=3.306340 |g|=0.415	lr=3.18e-04 | 46.2%@S25  T=1.72s(data=1.8ms QKV=2.10s FFN=3.04s) eta=14:53:58 | 43.8K token/s | 
[epoch_0]_29871  loss=3.222815 |g|=0.41	lr=3.18e-04 | 47.0%@S25  T=1.72s(data=1.9ms QKV=2.10s FFN=3.04s) eta=14:53:37 | 44.0K token/s | 
[epoch_0]_29881  loss=3.211553 |g|=0.41	lr=3.17e-04 | 47.9%@S25  T=1.70s(data=2.0ms QKV=2.10s FFN=3.04s) eta=14:43:07 | 44.2K token/s | 
[epoch_0]_29891  loss=3.233663 |g|=0.416	lr=3.17e-04 | 48.7%@S25  T=1.71s(data=1.7ms QKV=2.10s FFN=3.04s) eta=14:47:40 | 44.4K token/s | 
[Fuyou] head="4" update algorithm=4 t=12.31s
[Section@29900] layer[40-48] tasks=19(nPassBack=0) last_loss=3.21254(-0.00516081) N=(772,34160,33600 3946668)
[epoch_0]_29901  loss=3.265093 |g|=0.433	lr=3.17e-04 | 49.5%@S25  T=4.28s(data=1.5ms QKV=2.10s FFN=3.03s) eta=1d 13:00:11 | 43.1K token/s | 
[epoch_0]_29911  loss=3.229423 |g|=0.442	lr=3.17e-04 | 50.3%@S25  T=1.72s(data=1.7ms QKV=2.10s FFN=3.04s) eta=14:54:28 | 43.3K token/s | 
[epoch_0]_29921  loss=3.270759 |g|=0.434	lr=3.17e-04 | 51.1%@S25  T=1.76s(data=1.8ms QKV=2.11s FFN=3.04s) eta=15:12:28 | 43.5K token/s | 
[epoch_0]_29931  loss=3.229994 |g|=0.416	lr=3.17e-04 | 52.0%@S25  T=1.71s(data=1.6ms QKV=2.11s FFN=3.04s) eta=14:44:19 | 43.7K token/s | 
[epoch_0]_29941  loss=3.232017 |g|=0.427	lr=3.17e-04 | 52.8%@S25  T=1.72s(data=1.9ms QKV=2.11s FFN=3.04s) eta=14:53:04 | 43.9K token/s | 
[epoch_0]_29951  loss=3.275120 |g|=0.403	lr=3.16e-04 | 53.6%@S25  T=1.73s(data=1.9ms QKV=2.11s FFN=3.04s) eta=14:54:52 | 44.1K token/s | 
[epoch_0]_29961  loss=3.249865 |g|=0.388	lr=3.16e-04 | 54.4%@S25  T=1.73s(data=1.5ms QKV=2.11s FFN=3.04s) eta=14:56:53 | 44.2K token/s | 
[epoch_0]_29971  loss=3.271810 |g|=0.427	lr=3.16e-04 | 55.2%@S25  T=1.73s(data=1.7ms QKV=2.11s FFN=3.04s) eta=14:55:05 | 44.4K token/s | 
[epoch_0]_29981  loss=3.198440 |g|=0.402	lr=3.16e-04 | 56.1%@S25  T=1.80s(data=1.6ms QKV=2.11s FFN=3.04s) eta=15:30:05 | 44.5K token/s | 
[epoch_0]_29991  loss=3.293454 |g|=0.426	lr=3.16e-04 | 56.9%@S25  T=1.71s(data=1.8ms QKV=2.11s FFN=3.04s) eta=14:42:12 | 44.6K token/s | 
[Fuyou] head="5" update algorithm=4 t=11.40s
[eval] 
	 Loss@"edu_fineweb1B"=3.240(0.00087) nBranch=1 nToken=6.31M best=3.2409(148) E2T=0.0586 T=36.6941(0)s x=0
	#3.24±0.0972 tps=172K(6.30784M) a=[3.04875,3.5114] T=36.6941(sec)
[Section@30000] layer[0-8] tasks=19(nPassBack=0) last_loss=3.18142(0.0325143) N=(772,34272,33712 3959868)
[epoch_0]_30001  loss=3.226695 |g|=0.396	lr=3.16e-04 | 57.7%@S25  T=12.13s(data=2.3ms QKV=2.10s FFN=3.04s) eta=4d 08:35:05 | 42.7K token/s | 
[epoch_0]_30011  loss=3.236167 |g|=0.439	lr=3.15e-04 | 58.5%@S25  T=1.79s(data=1.7ms QKV=2.10s FFN=3.04s) eta=15:24:24 | 42.9K token/s | 
[epoch_0]_30021  loss=3.286848 |g|=0.42	lr=3.15e-04 | 59.3%@S25  T=1.80s(data=1.6ms QKV=2.11s FFN=3.04s) eta=15:31:58 | 43.0K token/s | 
[epoch_0]_30031  loss=3.186823 |g|=0.446	lr=3.15e-04 | 60.1%@S25  T=1.78s(data=1.6ms QKV=2.11s FFN=3.04s) eta=15:17:27 | 43.2K token/s | 
[epoch_0]_30041  loss=3.206042 |g|=0.4	lr=3.15e-04 | 61.0%@S25  T=1.80s(data=1.5ms QKV=2.11s FFN=3.04s) eta=15:29:39 | 43.3K token/s | 
[epoch_0]_30051  loss=3.184636 |g|=0.408	lr=3.15e-04 | 61.8%@S25  T=1.85s(data=1.6ms QKV=2.10s FFN=3.04s) eta=15:54:52 | 43.3K token/s | 
[epoch_0]_30061  loss=3.251408 |g|=0.434	lr=3.15e-04 | 62.6%@S25  T=1.79s(data=1.6ms QKV=2.11s FFN=3.04s) eta=15:26:00 | 43.5K token/s | 
[epoch_0]_30071  loss=3.275667 |g|=0.412	lr=3.15e-04 | 63.4%@S25  T=1.80s(data=1.5ms QKV=2.11s FFN=3.04s) eta=15:29:53 | 43.6K token/s | 
[epoch_0]_30081  loss=3.259496 |g|=0.432	lr=3.14e-04 | 64.2%@S25  T=1.72s(data=1.7ms QKV=2.11s FFN=3.04s) eta=14:46:13 | 43.8K token/s | 
[epoch_0]_30091  loss=3.217263 |g|=0.409	lr=3.14e-04 | 65.1%@S25  T=1.78s(data=1.5ms QKV=2.11s FFN=3.04s) eta=15:19:58 | 43.9K token/s | 
[Fuyou] head="0" update algorithm=4 t=10.98s
[Section@30100] layer[8-16] tasks=19(nPassBack=0) last_loss=3.18688(0.0939498) N=(772,34384,33824 3973068)
[epoch_0]_30101  loss=3.184806 |g|=0.415	lr=3.14e-04 | 65.9%@S25  T=4.39s(data=2.4ms QKV=2.10s FFN=3.03s) eta=1d 13:42:24 | 42.6K token/s | 
[epoch_0]_30111  loss=3.237456 |g|=0.396	lr=3.14e-04 | 66.7%@S25  T=1.73s(data=1.8ms QKV=2.10s FFN=3.04s) eta=14:49:51 | 42.9K token/s | 
[epoch_0]_30121  loss=3.216828 |g|=0.418	lr=3.14e-04 | 67.5%@S25  T=1.70s(data=1.7ms QKV=2.11s FFN=3.04s) eta=14:38:16 | 43.1K token/s | 
[epoch_0]_30131  loss=3.236364 |g|=0.42	lr=3.14e-04 | 68.3%@S25  T=1.72s(data=1.6ms QKV=2.11s FFN=3.04s) eta=14:47:27 | 43.3K token/s | 
[epoch_0]_30141  loss=3.159541 |g|=0.394	lr=3.13e-04 | 69.2%@S25  T=1.70s(data=1.8ms QKV=2.11s FFN=3.04s) eta=14:36:11 | 43.6K token/s | 
[epoch_0]_30151  loss=3.221141 |g|=0.422	lr=3.13e-04 | 70.0%@S25  T=1.79s(data=1.7ms QKV=2.10s FFN=3.04s) eta=15:21:49 | 43.7K token/s | 
[epoch_0]_30161  loss=3.224733 |g|=0.399	lr=3.13e-04 | 70.8%@S25  T=1.79s(data=1.8ms QKV=2.11s FFN=3.04s) eta=15:22:48 | 43.8K token/s | 
[epoch_0]_30171  loss=3.250256 |g|=0.435	lr=3.13e-04 | 71.6%@S25  T=1.79s(data=1.5ms QKV=2.11s FFN=3.04s) eta=15:23:13 | 43.9K token/s | 
[epoch_0]_30181  loss=3.234859 |g|=0.402	lr=3.13e-04 | 72.4%@S25  T=1.78s(data=1.5ms QKV=2.11s FFN=3.04s) eta=15:15:08 | 44.0K token/s | 
[epoch_0]_30191  loss=3.224459 |g|=0.388	lr=3.13e-04 | 73.3%@S25  T=1.80s(data=1.5ms QKV=2.11s FFN=3.04s) eta=15:22:48 | 44.1K token/s | 
[Fuyou] head="1" update algorithm=4 t=11.06s
[eval] 
	 Loss@"edu_fineweb1B"=3.238(0.002) nBranch=1 nToken=6.31M best=3.2400(149) E2T=0.00752 T=36.697(0)s x=0
	#3.23804±0.0962 tps=172K(6.30784M) a=[3.05332,3.50982] T=36.697(sec)
[Section@30200] layer[16-24] tasks=19(nPassBack=0) last_loss=3.23053(-0.0210366) N=(772,34496,33936 3986268)
[epoch_0]_30201  loss=3.248397 |g|=0.397	lr=3.13e-04 | 74.1%@S25  T=11.96s(data=1.9ms QKV=2.10s FFN=3.03s) eta=4d 06:25:38 | 42.2K token/s | 
[epoch_0]_30211  loss=3.292089 |g|=0.434	lr=3.12e-04 | 74.9%@S25  T=1.78s(data=1.6ms QKV=2.11s FFN=3.04s) eta=15:12:41 | 42.4K token/s | 
[epoch_0]_30221  loss=3.263282 |g|=0.395	lr=3.12e-04 | 75.7%@S25  T=1.76s(data=1.6ms QKV=2.11s FFN=3.04s) eta=15:04:41 | 42.6K token/s | 
[epoch_0]_30231  loss=3.183923 |g|=0.431	lr=3.12e-04 | 76.5%@S25  T=1.72s(data=2.0ms QKV=2.11s FFN=3.04s) eta=14:41:46 | 42.9K token/s | 
[epoch_0]_30241  loss=3.169119 |g|=0.412	lr=3.12e-04 | 77.4%@S25  T=1.75s(data=1.9ms QKV=2.11s FFN=3.04s) eta=14:57:48 | 43.1K token/s | 
[epoch_0]_30251  loss=3.223290 |g|=0.394	lr=3.12e-04 | 78.2%@S25  T=1.80s(data=1.5ms QKV=2.11s FFN=3.04s) eta=15:23:39 | 43.2K token/s | 
[epoch_0]_30261  loss=3.225265 |g|=0.422	lr=3.12e-04 | 79.0%@S25  T=1.80s(data=1.6ms QKV=2.11s FFN=3.04s) eta=15:23:15 | 43.3K token/s | 
[epoch_0]_30271  loss=3.224405 |g|=0.41	lr=3.11e-04 | 79.8%@S25  T=1.81s(data=1.6ms QKV=2.11s FFN=3.04s) eta=15:29:35 | 43.4K token/s | 
[epoch_0]_30281  loss=3.180734 |g|=0.426	lr=3.11e-04 | 80.6%@S25  T=1.80s(data=1.5ms QKV=2.11s FFN=3.04s) eta=15:23:24 | 43.5K token/s | 
[epoch_0]_30291  loss=3.126806 |g|=0.422	lr=3.11e-04 | 81.4%@S25  T=1.79s(data=1.6ms QKV=2.11s FFN=3.04s) eta=15:19:21 | 43.6K token/s | 
[Fuyou] head="2" update algorithm=4 t=11.97s
[Section@30300] layer[24-32] tasks=19(nPassBack=0) last_loss=3.21195(-0.0401955) N=(772,34608,34048 3999468)
[epoch_0]_30301  loss=3.214979 |g|=0.39	lr=3.11e-04 | 82.3%@S25  T=4.15s(data=1.7ms QKV=2.10s FFN=3.03s) eta=1d 11:26:16 | 42.4K token/s | 
[epoch_0]_30311  loss=3.216334 |g|=0.416	lr=3.11e-04 | 83.1%@S25  T=1.78s(data=1.9ms QKV=2.11s FFN=3.04s) eta=15:12:53 | 42.6K token/s | 
[epoch_0]_30321  loss=3.262518 |g|=0.427	lr=3.11e-04 | 83.9%@S25  T=1.79s(data=1.6ms QKV=2.11s FFN=3.04s) eta=15:17:26 | 42.7K token/s | 
[epoch_0]_30331  loss=3.251706 |g|=0.436	lr=3.11e-04 | 84.7%@S25  T=1.82s(data=1.6ms QKV=2.11s FFN=3.04s) eta=15:31:30 | 42.9K token/s | 
[epoch_0]_30341  loss=3.209902 |g|=0.427	lr=3.10e-04 | 85.5%@S25  T=1.71s(data=1.7ms QKV=2.11s FFN=3.04s) eta=14:33:56 | 43.1K token/s | 
[epoch_0]_30351  loss=3.283138 |g|=0.403	lr=3.10e-04 | 86.4%@S25  T=1.79s(data=1.5ms QKV=2.11s FFN=3.04s) eta=15:14:38 | 43.2K token/s | 
[epoch_0]_30361  loss=3.233295 |g|=0.435	lr=3.10e-04 | 87.2%@S25  T=1.74s(data=1.6ms QKV=2.11s FFN=3.04s) eta=14:50:58 | 43.4K token/s | 
[epoch_0]_30371  loss=3.289785 |g|=0.402	lr=3.10e-04 | 88.0%@S25  T=1.74s(data=1.7ms QKV=2.11s FFN=3.04s) eta=14:49:24 | 43.6K token/s | 
[epoch_0]_30381  loss=3.226233 |g|=0.398	lr=3.10e-04 | 88.8%@S25  T=1.73s(data=1.6ms QKV=2.11s FFN=3.04s) eta=14:46:02 | 43.8K token/s | 
[epoch_0]_30391  loss=3.205562 |g|=0.419	lr=3.10e-04 | 89.6%@S25  T=1.72s(data=1.8ms QKV=2.11s FFN=3.04s) eta=14:36:37 | 44.0K token/s | 
[Fuyou] head="3" update algorithm=4 t=12.43s
[eval] 
	 Loss@"edu_fineweb1B"=3.234(0.0036) nBranch=1 nToken=6.31M best=3.2380(150) E2T=-0.0411 T=36.6994(0)s x=0
	#3.23449±0.0963 tps=172K(6.30784M) a=[3.04856,3.50847] T=36.6994(sec)
[Section@30400] layer[32-40] tasks=19(nPassBack=0) last_loss=3.27564(-0.0372753) N=(772,34720,34160 4012668)
[epoch_0]_30401  loss=3.247903 |g|=0.406	lr=3.09e-04 | 90.5%@S25  T=12.15s(data=2.2ms QKV=2.10s FFN=3.04s) eta=4d 07:21:06 | 42.1K token/s | 
[epoch_0]_30411  loss=3.264948 |g|=0.39	lr=3.09e-04 | 91.3%@S25  T=1.77s(data=1.6ms QKV=2.11s FFN=3.04s) eta=15:03:49 | 42.3K token/s | 
[epoch_0]_30421  loss=3.281322 |g|=0.429	lr=3.09e-04 | 92.1%@S25  T=1.78s(data=1.6ms QKV=2.11s FFN=3.04s) eta=15:07:19 | 42.5K token/s | 
[epoch_0]_30431  loss=3.301306 |g|=0.428	lr=3.09e-04 | 92.9%@S25  T=1.77s(data=1.6ms QKV=2.11s FFN=3.04s) eta=15:03:50 | 42.7K token/s | 
[epoch_0]_30441  loss=3.175419 |g|=0.428	lr=3.09e-04 | 93.7%@S25  T=1.76s(data=1.7ms QKV=2.11s FFN=3.04s) eta=14:57:20 | 42.9K token/s | 
[epoch_0]_30451  loss=3.174333 |g|=0.406	lr=3.09e-04 | 94.6%@S25  T=1.81s(data=1.8ms QKV=2.10s FFN=3.04s) eta=15:23:49 | 43.0K token/s | 
[epoch_0]_30461  loss=3.249499 |g|=0.413	lr=3.09e-04 | 95.4%@S25  T=1.74s(data=1.9ms QKV=2.10s FFN=3.04s) eta=14:45:05 | 43.2K token/s | 
[epoch_0]_30471  loss=3.240892 |g|=0.413	lr=3.08e-04 | 96.2%@S25  T=1.79s(data=1.8ms QKV=2.10s FFN=3.04s) eta=15:13:00 | 43.3K token/s | 
[epoch_0]_30481  loss=3.183197 |g|=0.425	lr=3.08e-04 | 97.0%@S25  T=1.72s(data=1.6ms QKV=2.10s FFN=3.04s) eta=14:37:18 | 43.6K token/s | 
[epoch_0]_30491  loss=3.256287 |g|=0.407	lr=3.08e-04 | 97.8%@S25  T=1.74s(data=1.6ms QKV=2.11s FFN=3.04s) eta=14:45:34 | 43.7K token/s | 
[Fuyou] head="4" update algorithm=4 t=11.09s
[Section@30500] layer[40-48] tasks=19(nPassBack=0) last_loss=3.16186(0.0506742) N=(772,34832,34272 4025868)
[epoch_0]_30501  loss=3.214122 |g|=0.415	lr=3.08e-04 | 98.6%@S25  T=4.35s(data=1.6ms QKV=2.11s FFN=3.03s) eta=1d 12:54:13 | 42.5K token/s | 
[epoch_0]_30511  loss=3.217686 |g|=0.416	lr=3.08e-04 | 99.5%@S25  T=1.73s(data=1.6ms QKV=2.11s FFN=3.04s) eta=14:39:15 | 42.7K token/s | 
[epoch_0]_30517  loss=3.214710 |g|=0.393	lr=3.08e-04 | 100.0%@S25  T=1.72s(data=1.8ms QKV=2.11s FFN=3.04s) eta=14:37:15 | 43.0K token/s | 
-------- End of shard_25@"./Datasets/edu_fineweb1B/edu_fineweb_train_000479.bin"-------- 
[shard-26]@"./Datasets/edu_fineweb1B/edu_fineweb_train_000480.bin": tokens=100(M) nShardSamples=1220(2539056) 
[epoch_0]_30521  loss=3.214609 |g|=0.415	lr=3.08e-04 | 0.3%@S26  T=1.73s(data=1.4ms QKV=2.11s FFN=3.04s) eta=14:37:45 | 43.2K token/s | 
[epoch_0]_30531  loss=3.160623 |g|=0.404	lr=3.07e-04 | 1.1%@S26  T=1.78s(data=1.4ms QKV=2.11s FFN=3.04s) eta=15:04:59 | 43.3K token/s | 
[epoch_0]_30541  loss=3.244446 |g|=0.414	lr=3.07e-04 | 1.9%@S26  T=1.71s(data=1.4ms QKV=2.11s FFN=3.04s) eta=14:28:30 | 43.6K token/s | 
[epoch_0]_30551  loss=3.210597 |g|=0.424	lr=3.07e-04 | 2.7%@S26  T=1.73s(data=1.4ms QKV=2.11s FFN=3.04s) eta=14:41:04 | 43.8K token/s | 
[epoch_0]_30561  loss=3.258440 |g|=0.416	lr=3.07e-04 | 3.6%@S26  T=1.78s(data=2.2ms QKV=2.11s FFN=3.04s) eta=15:04:01 | 43.9K token/s | 
[epoch_0]_30571  loss=3.305266 |g|=0.413	lr=3.07e-04 | 4.4%@S26  T=1.71s(data=2.2ms QKV=2.11s FFN=3.04s) eta=14:28:14 | 44.1K token/s | 
[epoch_0]_30581  loss=3.232179 |g|=0.417	lr=3.07e-04 | 5.2%@S26  T=1.75s(data=2.0ms QKV=2.11s FFN=3.04s) eta=14:47:25 | 44.2K token/s | 
[epoch_0]_30591  loss=3.221686 |g|=0.443	lr=3.06e-04 | 6.0%@S26  T=1.72s(data=1.3ms QKV=2.11s FFN=3.04s) eta=14:31:46 | 44.4K token/s | 
[Fuyou] head="5" update algorithm=4 t=11.73s
[eval] 
	 Loss@"edu_fineweb1B"=3.236(-0.0018) nBranch=1 nToken=6.31M best=3.2345(151) E2T=-0.00504 T=36.7063(0)s x=0
	#3.23631±0.0964 tps=172K(6.30784M) a=[3.0518,3.51392] T=36.7063(sec)
[Section@30600] layer[0-8] tasks=19(nPassBack=0) last_loss=3.24135(-0.0599327) N=(772,34944,34384 4039068)
[epoch_0]_30601  loss=3.243265 |g|=0.4	lr=3.06e-04 | 6.8%@S26  T=12.19s(data=1.9ms QKV=2.11s FFN=3.03s) eta=4d 07:01:16 | 42.5K token/s | 
[epoch_0]_30611  loss=3.218687 |g|=0.401	lr=3.06e-04 | 7.7%@S26  T=1.79s(data=1.6ms QKV=2.11s FFN=3.04s) eta=15:06:40 | 42.7K token/s | 
[epoch_0]_30621  loss=3.196142 |g|=0.407	lr=3.06e-04 | 8.5%@S26  T=1.73s(data=1.4ms QKV=2.11s FFN=3.04s) eta=14:36:33 | 42.9K token/s | 
[epoch_0]_30631  loss=3.223459 |g|=0.429	lr=3.06e-04 | 9.3%@S26  T=1.71s(data=1.4ms QKV=2.11s FFN=3.04s) eta=14:24:10 | 43.2K token/s | 
[epoch_0]_30641  loss=3.212247 |g|=0.424	lr=3.06e-04 | 10.1%@S26  T=1.72s(data=1.7ms QKV=2.11s FFN=3.04s) eta=14:30:31 | 43.4K token/s | 
[epoch_0]_30651  loss=3.234575 |g|=0.396	lr=3.06e-04 | 10.9%@S26  T=1.72s(data=1.7ms QKV=2.11s FFN=3.04s) eta=14:30:24 | 43.6K token/s | 
[epoch_0]_30661  loss=3.218244 |g|=0.414	lr=3.05e-04 | 11.8%@S26  T=1.75s(data=1.6ms QKV=2.11s FFN=3.04s) eta=14:46:55 | 43.8K token/s | 
[epoch_0]_30671  loss=3.116748 |g|=0.415	lr=3.05e-04 | 12.6%@S26  T=1.73s(data=1.7ms QKV=2.11s FFN=3.04s) eta=14:36:41 | 43.9K token/s | 
[epoch_0]_30681  loss=3.285702 |g|=0.426	lr=3.05e-04 | 13.4%@S26  T=1.70s(data=2.4ms QKV=2.11s FFN=3.04s) eta=14:21:11 | 44.1K token/s | 
[epoch_0]_30691  loss=3.206913 |g|=0.416	lr=3.05e-04 | 14.2%@S26  T=1.79s(data=1.5ms QKV=2.11s FFN=3.04s) eta=15:03:19 | 44.2K token/s | 
[Fuyou] head="0" update algorithm=4 t=10.89s
[Section@30700] layer[8-16] tasks=19(nPassBack=0) last_loss=3.20554(-0.0186634) N=(772,35056,34496 4052268)
[epoch_0]_30701  loss=3.214477 |g|=0.401	lr=3.05e-04 | 15.0%@S26  T=4.43s(data=1.4ms QKV=2.11s FFN=3.03s) eta=1d 13:18:18 | 42.9K token/s | 
[epoch_0]_30711  loss=3.199963 |g|=0.43	lr=3.05e-04 | 15.9%@S26  T=1.75s(data=1.6ms QKV=2.11s FFN=3.04s) eta=14:46:07 | 43.1K token/s | 
[epoch_0]_30721  loss=3.222092 |g|=0.402	lr=3.04e-04 | 16.7%@S26  T=1.73s(data=2.0ms QKV=2.11s FFN=3.04s) eta=14:31:54 | 43.3K token/s | 
[epoch_0]_30731  loss=3.172508 |g|=0.414	lr=3.04e-04 | 17.5%@S26  T=1.78s(data=1.9ms QKV=2.11s FFN=3.04s) eta=14:57:41 | 43.5K token/s | 
[epoch_0]_30741  loss=3.259298 |g|=0.438	lr=3.04e-04 | 18.3%@S26  T=1.72s(data=1.7ms QKV=2.11s FFN=3.04s) eta=14:26:26 | 43.7K token/s | 
[epoch_0]_30751  loss=3.300354 |g|=0.421	lr=3.04e-04 | 19.1%@S26  T=1.74s(data=1.6ms QKV=2.11s FFN=3.04s) eta=14:35:43 | 43.9K token/s | 
[epoch_0]_30761  loss=3.216853 |g|=0.422	lr=3.04e-04 | 19.9%@S26  T=1.80s(data=1.6ms QKV=2.11s FFN=3.04s) eta=15:06:50 | 44.0K token/s | 
[epoch_0]_30771  loss=3.236540 |g|=0.703	lr=3.04e-04 | 20.8%@S26  T=1.80s(data=1.6ms QKV=2.11s FFN=3.04s) eta=15:08:29 | 44.0K token/s | 
[epoch_0]_30781  loss=3.224524 |g|=0.421	lr=3.04e-04 | 21.6%@S26  T=1.73s(data=3.0ms QKV=2.11s FFN=3.04s) eta=14:31:05 | 44.2K token/s | 
[epoch_0]_30791  loss=3.247149 |g|=0.421	lr=3.03e-04 | 22.4%@S26  T=1.80s(data=1.6ms QKV=2.11s FFN=3.04s) eta=15:05:16 | 44.3K token/s | 
[Fuyou] head="1" update algorithm=4 t=10.96s
[eval] 
	 Loss@"edu_fineweb1B"=3.237(-0.00031) nBranch=1 nToken=6.31M best=3.2345(151) E2T=0.0507 T=36.7237(0)s x=0
	#3.23663±0.0967 tps=172K(6.30784M) a=[3.04924,3.5126] T=36.7237(sec)
[Section@30800] layer[16-24] tasks=19(nPassBack=0) last_loss=3.18597(0.0445609) N=(772,35168,34608 4065468)
[epoch_0]_30801  loss=3.288567 |g|=0.431	lr=3.03e-04 | 23.2%@S26  T=11.98s(data=1.6ms QKV=2.11s FFN=3.04s) eta=4d 04:39:08 | 42.4K token/s | 
[epoch_0]_30811  loss=3.180583 |g|=0.417	lr=3.03e-04 | 24.0%@S26  T=1.72s(data=1.7ms QKV=2.11s FFN=3.04s) eta=14:26:34 | 42.7K token/s | 
[epoch_0]_30821  loss=3.146767 |g|=0.408	lr=3.03e-04 | 24.9%@S26  T=1.78s(data=7.0ms QKV=2.11s FFN=3.04s) eta=14:54:57 | 42.8K token/s | 
[epoch_0]_30831  loss=3.191783 |g|=0.41	lr=3.03e-04 | 25.7%@S26  T=1.72s(data=1.5ms QKV=2.11s FFN=3.04s) eta=14:23:35 | 43.1K token/s | 
[epoch_0]_30841  loss=3.159125 |g|=0.427	lr=3.03e-04 | 26.5%@S26  T=1.76s(data=1.8ms QKV=2.11s FFN=3.04s) eta=14:45:27 | 43.3K token/s | 
[epoch_0]_30851  loss=3.186275 |g|=0.415	lr=3.02e-04 | 27.3%@S26  T=1.71s(data=1.5ms QKV=2.11s FFN=3.04s) eta=14:20:24 | 43.5K token/s | 
[epoch_0]_30861  loss=3.163440 |g|=0.413	lr=3.02e-04 | 28.1%@S26  T=1.72s(data=1.6ms QKV=2.11s FFN=3.04s) eta=14:23:10 | 43.7K token/s | 
[epoch_0]_30871  loss=3.220878 |g|=0.419	lr=3.02e-04 | 29.0%@S26  T=1.77s(data=8.3ms QKV=2.11s FFN=3.04s) eta=14:47:23 | 43.8K token/s | 
[epoch_0]_30881  loss=3.241557 |g|=0.403	lr=3.02e-04 | 29.8%@S26  T=1.71s(data=1.8ms QKV=2.11s FFN=3.04s) eta=14:18:22 | 44.0K token/s | 
[epoch_0]_30891  loss=3.206185 |g|=0.408	lr=3.02e-04 | 30.6%@S26  T=1.82s(data=1.4ms QKV=2.11s FFN=3.04s) eta=15:13:50 | 44.1K token/s | 
[Fuyou] head="2" update algorithm=4 t=10.44s
[Section@30900] layer[24-32] tasks=19(nPassBack=0) last_loss=3.24096(-0.0290015) N=(772,35280,34720 4078668)
[epoch_0]_30901  loss=3.307862 |g|=0.384	lr=3.02e-04 | 31.4%@S26  T=3.94s(data=1.5ms QKV=2.11s FFN=3.03s) eta=1d 08:56:51 | 42.9K token/s | 
[epoch_0]_30911  loss=3.173211 |g|=0.438	lr=3.02e-04 | 32.2%@S26  T=1.81s(data=1.5ms QKV=2.11s FFN=3.04s) eta=15:09:23 | 43.0K token/s | 
[epoch_0]_30921  loss=3.240746 |g|=0.404	lr=3.01e-04 | 33.1%@S26  T=1.78s(data=1.7ms QKV=2.11s FFN=3.04s) eta=14:52:03 | 43.2K token/s | 
[epoch_0]_30931  loss=3.222722 |g|=0.42	lr=3.01e-04 | 33.9%@S26  T=1.74s(data=1.7ms QKV=2.11s FFN=3.04s) eta=14:32:48 | 43.4K token/s | 
[epoch_0]_30941  loss=3.204820 |g|=0.421	lr=3.01e-04 | 34.7%@S26  T=1.71s(data=1.6ms QKV=2.11s FFN=3.04s) eta=14:19:21 | 43.6K token/s | 
[epoch_0]_30951  loss=3.267884 |g|=0.407	lr=3.01e-04 | 35.5%@S26  T=1.78s(data=1.7ms QKV=2.11s FFN=3.04s) eta=14:53:34 | 43.7K token/s | 
[epoch_0]_30961  loss=3.189148 |g|=0.414	lr=3.01e-04 | 36.3%@S26  T=1.71s(data=1.5ms QKV=2.11s FFN=3.04s) eta=14:16:29 | 43.9K token/s | 
[epoch_0]_30971  loss=3.176819 |g|=0.438	lr=3.01e-04 | 37.2%@S26  T=1.77s(data=1.6ms QKV=2.11s FFN=3.04s) eta=14:45:19 | 44.1K token/s | 
[epoch_0]_30981  loss=3.192418 |g|=0.422	lr=3.00e-04 | 38.0%@S26  T=1.74s(data=1.5ms QKV=2.12s FFN=3.04s) eta=14:32:49 | 44.2K token/s | 
[epoch_0]_30991  loss=3.163234 |g|=0.404	lr=3.00e-04 | 38.8%@S26  T=1.76s(data=5.9ms QKV=2.11s FFN=3.04s) eta=14:40:52 | 44.3K token/s | 
[Fuyou] head="3" update algorithm=4 t=11.79s
[eval] 
	 Loss@"edu_fineweb1B"=3.236(0.001) nBranch=1 nToken=6.31M best=3.2345(151) E2T=0.0612 T=36.7071(0)s x=0
	#3.23559±0.0967 tps=172K(6.30784M) a=[3.05147,3.50889] T=36.7071(sec)
[Section@31000] layer[32-40] tasks=19(nPassBack=0) last_loss=3.17443(0.101208) N=(772,35392,34832 4091868)
[epoch_0]_31001  loss=3.149157 |g|=0.394	lr=3.00e-04 | 39.6%@S26  T=11.75s(data=1.7ms QKV=2.10s FFN=3.04s) eta=4d 02:00:26 | 42.5K token/s | 
[epoch_0]_31011  loss=3.247553 |g|=0.41	lr=3.00e-04 | 40.4%@S26  T=1.72s(data=1.6ms QKV=2.11s FFN=3.04s) eta=14:20:11 | 42.7K token/s | 
[epoch_0]_31021  loss=3.191749 |g|=0.407	lr=3.00e-04 | 41.2%@S26  T=1.80s(data=1.6ms QKV=2.11s FFN=3.04s) eta=14:58:08 | 42.9K token/s | 
[epoch_0]_31031  loss=3.240436 |g|=0.444	lr=3.00e-04 | 42.1%@S26  T=1.81s(data=1.5ms QKV=2.11s FFN=3.04s) eta=15:06:57 | 43.0K token/s | 
[epoch_0]_31041  loss=3.195209 |g|=0.404	lr=3.00e-04 | 42.9%@S26  T=1.82s(data=1.6ms QKV=2.11s FFN=3.04s) eta=15:11:42 | 43.1K token/s | 
[epoch_0]_31051  loss=3.210705 |g|=0.414	lr=2.99e-04 | 43.7%@S26  T=1.81s(data=1.7ms QKV=2.11s FFN=3.04s) eta=15:03:17 | 43.2K token/s | 
[epoch_0]_31061  loss=3.260140 |g|=0.445	lr=2.99e-04 | 44.5%@S26  T=1.79s(data=1.6ms QKV=2.11s FFN=3.04s) eta=14:54:43 | 43.3K token/s | 
[epoch_0]_31071  loss=3.219278 |g|=0.406	lr=2.99e-04 | 45.3%@S26  T=1.71s(data=1.9ms QKV=2.11s FFN=3.04s) eta=14:15:11 | 43.5K token/s | 
[epoch_0]_31081  loss=3.200686 |g|=0.408	lr=2.99e-04 | 46.2%@S26  T=1.80s(data=1.5ms QKV=2.11s FFN=3.04s) eta=15:00:37 | 43.6K token/s | 
[epoch_0]_31091  loss=3.216508 |g|=0.432	lr=2.99e-04 | 47.0%@S26  T=1.73s(data=1.7ms QKV=2.11s FFN=3.04s) eta=14:22:53 | 43.8K token/s | 
[Fuyou] head="4" update algorithm=4 t=13.58s
[Section@31100] layer[40-48] tasks=19(nPassBack=0) last_loss=3.34946(-0.187593) N=(772,35504,34944 4105068)
[epoch_0]_31101  loss=3.196071 |g|=0.397	lr=2.99e-04 | 47.8%@S26  T=4.56s(data=1.8ms QKV=2.11s FFN=3.03s) eta=1d 13:55:24 | 42.5K token/s | 
[epoch_0]_31111  loss=3.176570 |g|=0.418	lr=2.98e-04 | 48.6%@S26  T=1.72s(data=1.7ms QKV=2.11s FFN=3.04s) eta=14:20:17 | 42.8K token/s | 
[epoch_0]_31121  loss=3.257324 |g|=0.418	lr=2.98e-04 | 49.4%@S26  T=1.72s(data=2.0ms QKV=2.11s FFN=3.04s) eta=14:16:14 | 43.0K token/s | 
[epoch_0]_31131  loss=3.200055 |g|=0.428	lr=2.98e-04 | 50.3%@S26  T=1.79s(data=1.6ms QKV=2.11s FFN=3.04s) eta=14:52:35 | 43.2K token/s | 
[epoch_0]_31141  loss=3.208295 |g|=0.41	lr=2.98e-04 | 51.1%@S26  T=1.72s(data=1.8ms QKV=2.11s FFN=3.04s) eta=14:16:37 | 43.4K token/s | 
[epoch_0]_31151  loss=3.231734 |g|=0.402	lr=2.98e-04 | 51.9%@S26  T=1.74s(data=1.7ms QKV=2.11s FFN=3.04s) eta=14:26:50 | 43.6K token/s | 
[epoch_0]_31161  loss=3.138124 |g|=0.391	lr=2.98e-04 | 52.7%@S26  T=1.78s(data=1.6ms QKV=2.11s FFN=3.04s) eta=14:46:29 | 43.7K token/s | 
[epoch_0]_31171  loss=3.250688 |g|=0.411	lr=2.98e-04 | 53.5%@S26  T=1.80s(data=1.5ms QKV=2.11s FFN=3.04s) eta=14:56:33 | 43.8K token/s | 
[epoch_0]_31181  loss=3.278463 |g|=0.403	lr=2.97e-04 | 54.4%@S26  T=1.71s(data=1.5ms QKV=2.11s FFN=3.04s) eta=14:10:53 | 44.0K token/s | 
[epoch_0]_31191  loss=3.202914 |g|=0.416	lr=2.97e-04 | 55.2%@S26  T=1.71s(data=1.8ms QKV=2.11s FFN=3.04s) eta=14:12:25 | 44.2K token/s | 
[Fuyou] head="5" update algorithm=4 t=11.44s
[eval] 
	 Loss@"edu_fineweb1B"=3.235(0.00026) nBranch=1 nToken=6.31M best=3.2345(151) E2T=-0.0278 T=36.711(0)s x=0
	#3.23533±0.0964 tps=172K(6.30784M) a=[3.05063,3.51103] T=36.711(sec)
[Section@31200] layer[0-8] tasks=19(nPassBack=0) last_loss=3.26311(-0.0217662) N=(772,35616,35056 4118268)
[epoch_0]_31201  loss=3.146314 |g|=0.416	lr=2.97e-04 | 56.0%@S26  T=12.15s(data=1.9ms QKV=2.10s FFN=3.04s) eta=4d 04:39:21 | 42.3K token/s | 
[epoch_0]_31211  loss=3.205389 |g|=0.392	lr=2.97e-04 | 56.8%@S26  T=1.73s(data=1.5ms QKV=2.11s FFN=3.04s) eta=14:21:47 | 42.6K token/s | 
[epoch_0]_31221  loss=3.217296 |g|=0.401	lr=2.97e-04 | 57.6%@S26  T=1.74s(data=1.5ms QKV=2.11s FFN=3.04s) eta=14:22:11 | 42.8K token/s | 
[epoch_0]_31231  loss=3.170006 |g|=0.427	lr=2.97e-04 | 58.5%@S26  T=1.76s(data=1.8ms QKV=2.11s FFN=3.04s) eta=14:35:01 | 43.0K token/s | 
[epoch_0]_31241  loss=3.258233 |g|=0.436	lr=2.96e-04 | 59.3%@S26  T=1.72s(data=1.7ms QKV=2.11s FFN=3.04s) eta=14:11:45 | 43.2K token/s | 
[epoch_0]_31251  loss=3.131352 |g|=0.414	lr=2.96e-04 | 60.1%@S26  T=1.74s(data=1.7ms QKV=2.11s FFN=3.04s) eta=14:22:49 | 43.4K token/s | 
[epoch_0]_31261  loss=3.279326 |g|=0.44	lr=2.96e-04 | 60.9%@S26  T=1.72s(data=1.9ms QKV=2.11s FFN=3.04s) eta=14:15:13 | 43.6K token/s | 
[epoch_0]_31271  loss=3.197657 |g|=0.413	lr=2.96e-04 | 61.7%@S26  T=1.73s(data=1.6ms QKV=2.11s FFN=3.04s) eta=14:19:15 | 43.8K token/s | 
[epoch_0]_31281  loss=3.195948 |g|=0.403	lr=2.96e-04 | 62.5%@S26  T=1.72s(data=1.9ms QKV=2.11s FFN=3.04s) eta=14:12:40 | 44.0K token/s | 
[epoch_0]_31291  loss=3.188106 |g|=0.417	lr=2.96e-04 | 63.4%@S26  T=1.74s(data=2.0ms QKV=2.11s FFN=3.04s) eta=14:21:58 | 44.1K token/s | 
[Fuyou] head="0" update algorithm=4 t=11.73s
[Section@31300] layer[8-16] tasks=19(nPassBack=0) last_loss=3.22278(-0.017236) N=(772,35728,35168 4131468)
[epoch_0]_31301  loss=3.196533 |g|=0.396	lr=2.96e-04 | 64.2%@S26  T=4.47s(data=1.5ms QKV=2.11s FFN=3.04s) eta=1d 12:56:54 | 42.9K token/s | 
[epoch_0]_31311  loss=3.272230 |g|=0.407	lr=2.95e-04 | 65.0%@S26  T=1.77s(data=1.5ms QKV=2.11s FFN=3.04s) eta=14:39:19 | 43.0K token/s | 
[epoch_0]_31321  loss=3.224474 |g|=0.415	lr=2.95e-04 | 65.8%@S26  T=1.72s(data=1.7ms QKV=2.11s FFN=3.04s) eta=14:10:08 | 43.3K token/s | 
[epoch_0]_31331  loss=3.254557 |g|=0.413	lr=2.95e-04 | 66.6%@S26  T=1.79s(data=1.6ms QKV=2.11s FFN=3.04s) eta=14:48:26 | 43.4K token/s | 
[epoch_0]_31341  loss=3.213178 |g|=0.417	lr=2.95e-04 | 67.5%@S26  T=1.82s(data=1.6ms QKV=2.12s FFN=3.04s) eta=14:59:02 | 43.5K token/s | 
[epoch_0]_31351  loss=3.271384 |g|=0.442	lr=2.95e-04 | 68.3%@S26  T=1.80s(data=1.5ms QKV=2.11s FFN=3.04s) eta=14:48:37 | 43.6K token/s | 
[epoch_0]_31361  loss=3.172015 |g|=0.414	lr=2.95e-04 | 69.1%@S26  T=1.77s(data=1.8ms QKV=2.11s FFN=3.04s) eta=14:35:07 | 43.7K token/s | 
[epoch_0]_31371  loss=3.168227 |g|=0.408	lr=2.94e-04 | 69.9%@S26  T=1.81s(data=1.8ms QKV=2.11s FFN=3.04s) eta=14:55:17 | 43.8K token/s | 
[epoch_0]_31381  loss=3.235943 |g|=0.4	lr=2.94e-04 | 70.7%@S26  T=1.72s(data=2.2ms QKV=2.11s FFN=3.04s) eta=14:09:16 | 44.0K token/s | 
[epoch_0]_31391  loss=3.121102 |g|=0.405	lr=2.94e-04 | 71.6%@S26  T=1.74s(data=2.3ms QKV=2.11s FFN=3.04s) eta=14:21:55 | 44.1K token/s | 
[Fuyou] head="1" update algorithm=4 t=11.89s
[eval] 
	 Loss@"edu_fineweb1B"=3.233(0.0019) nBranch=1 nToken=6.31M best=3.2353(155) E2T=0.0334 T=36.7274(0)s x=0
	#3.2334±0.0970 tps=172K(6.30784M) a=[3.04784,3.50754] T=36.7274(sec)
[Section@31400] layer[16-24] tasks=19(nPassBack=0) last_loss=3.19996(-0.0139966) N=(772,35840,35280 4144668)
[epoch_0]_31401  loss=3.249209 |g|=0.406	lr=2.94e-04 | 72.4%@S26  T=11.95s(data=1.6ms QKV=2.10s FFN=3.04s) eta=4d 02:23:23 | 42.3K token/s | 
[epoch_0]_31411  loss=3.198092 |g|=0.416	lr=2.94e-04 | 73.2%@S26  T=1.74s(data=1.6ms QKV=2.11s FFN=3.04s) eta=14:17:44 | 42.5K token/s | 
[epoch_0]_31421  loss=3.215795 |g|=0.43	lr=2.94e-04 | 74.0%@S26  T=1.73s(data=1.9ms QKV=2.10s FFN=3.04s) eta=14:12:09 | 42.8K token/s | 
[epoch_0]_31431  loss=3.207989 |g|=0.413	lr=2.94e-04 | 74.8%@S26  T=1.72s(data=2.1ms QKV=2.11s FFN=3.04s) eta=14:10:48 | 43.0K token/s | 
[epoch_0]_31441  loss=3.174443 |g|=0.393	lr=2.93e-04 | 75.7%@S26  T=1.79s(data=1.6ms QKV=2.11s FFN=3.04s) eta=14:42:58 | 43.1K token/s | 
[epoch_0]_31451  loss=3.156765 |g|=0.418	lr=2.93e-04 | 76.5%@S26  T=1.78s(data=1.6ms QKV=2.11s FFN=3.04s) eta=14:36:25 | 43.3K token/s | 
[epoch_0]_31461  loss=3.063834 |g|=0.402	lr=2.93e-04 | 77.3%@S26  T=1.77s(data=1.7ms QKV=2.11s FFN=3.04s) eta=14:33:26 | 43.4K token/s | 
[epoch_0]_31471  loss=3.221002 |g|=0.434	lr=2.93e-04 | 78.1%@S26  T=1.72s(data=1.6ms QKV=2.11s FFN=3.04s) eta=14:08:30 | 43.6K token/s | 
[epoch_0]_31481  loss=3.278221 |g|=0.423	lr=2.93e-04 | 78.9%@S26  T=1.79s(data=1.6ms QKV=2.11s FFN=3.04s) eta=14:43:49 | 43.7K token/s | 
[epoch_0]_31491  loss=3.150030 |g|=0.398	lr=2.93e-04 | 79.8%@S26  T=1.73s(data=1.5ms QKV=2.11s FFN=3.04s) eta=14:12:20 | 43.9K token/s | 
[Fuyou] head="2" update algorithm=4 t=11.57s
[Section@31500] layer[24-32] tasks=19(nPassBack=0) last_loss=3.29567(-0.0547101) N=(772,35952,35392 4157868)
[epoch_0]_31501  loss=3.196390 |g|=0.394	lr=2.92e-04 | 80.6%@S26  T=4.66s(data=1.6ms QKV=2.11s FFN=3.04s) eta=1d 14:13:19 | 42.6K token/s | 
[epoch_0]_31511  loss=3.187870 |g|=0.396	lr=2.92e-04 | 81.4%@S26  T=1.71s(data=1.9ms QKV=2.10s FFN=3.04s) eta=14:03:13 | 42.9K token/s | 
[epoch_0]_31521  loss=3.215658 |g|=0.434	lr=2.92e-04 | 82.2%@S26  T=1.71s(data=2.0ms QKV=2.11s FFN=3.04s) eta=14:03:35 | 43.1K token/s | 
[epoch_0]_31531  loss=3.258716 |g|=0.419	lr=2.92e-04 | 83.0%@S26  T=1.73s(data=1.8ms QKV=2.11s FFN=3.04s) eta=14:10:48 | 43.3K token/s | 
[epoch_0]_31541  loss=3.233660 |g|=0.419	lr=2.92e-04 | 83.8%@S26  T=1.76s(data=2.1ms QKV=2.11s FFN=3.04s) eta=14:25:54 | 43.5K token/s | 
[epoch_0]_31551  loss=3.213336 |g|=0.412	lr=2.92e-04 | 84.7%@S26  T=1.79s(data=2.1ms QKV=2.11s FFN=3.04s) eta=14:38:12 | 43.6K token/s | 
[epoch_0]_31561  loss=3.216542 |g|=0.426	lr=2.92e-04 | 85.5%@S26  T=1.80s(data=1.8ms QKV=2.11s FFN=3.04s) eta=14:42:07 | 43.7K token/s | 
[epoch_0]_31571  loss=3.174436 |g|=0.393	lr=2.91e-04 | 86.3%@S26  T=1.73s(data=1.8ms QKV=2.11s FFN=3.04s) eta=14:10:52 | 43.9K token/s | 
[epoch_0]_31581  loss=3.246083 |g|=0.407	lr=2.91e-04 | 87.1%@S26  T=1.72s(data=1.7ms QKV=2.11s FFN=3.04s) eta=14:04:17 | 44.1K token/s | 
[epoch_0]_31591  loss=3.177593 |g|=0.411	lr=2.91e-04 | 87.9%@S26  T=1.74s(data=1.8ms QKV=2.11s FFN=3.04s) eta=14:15:36 | 44.2K token/s | 
[Fuyou] head="3" update algorithm=4 t=12.76s
[eval] 
	 Loss@"edu_fineweb1B"=3.233(0.00029) nBranch=1 nToken=6.31M best=3.2334(156) E2T=0.0261 T=36.6911(0)s x=0
	#3.23311±0.0967 tps=172K(6.30784M) a=[3.05008,3.50917] T=36.6911(sec)
[Section@31600] layer[32-40] tasks=19(nPassBack=0) last_loss=3.20702(-0.0325863) N=(772,36064,35504 4171068)
[epoch_0]_31601  loss=3.200114 |g|=0.389	lr=2.91e-04 | 88.8%@S26  T=12.09s(data=1.8ms QKV=2.10s FFN=3.04s) eta=4d 02:51:24 | 42.3K token/s | 
[epoch_0]_31611  loss=3.143973 |g|=0.399	lr=2.91e-04 | 89.6%@S26  T=1.72s(data=2.0ms QKV=2.10s FFN=3.04s) eta=14:01:08 | 42.6K token/s | 
[epoch_0]_31621  loss=3.267639 |g|=0.41	lr=2.91e-04 | 90.4%@S26  T=1.82s(data=6.7ms QKV=2.12s FFN=3.04s) eta=14:53:34 | 42.7K token/s | 
[epoch_0]_31631  loss=3.276207 |g|=0.426	lr=2.90e-04 | 91.2%@S26  T=1.74s(data=2.0ms QKV=2.11s FFN=3.04s) eta=14:13:24 | 42.9K token/s | 
[epoch_0]_31641  loss=3.139451 |g|=0.424	lr=2.90e-04 | 92.0%@S26  T=1.82s(data=1.9ms QKV=2.11s FFN=3.04s) eta=14:49:17 | 43.0K token/s | 
[epoch_0]_31651  loss=3.243170 |g|=0.406	lr=2.90e-04 | 92.9%@S26  T=1.79s(data=1.6ms QKV=2.11s FFN=3.04s) eta=14:38:27 | 43.2K token/s | 
[epoch_0]_31661  loss=3.216114 |g|=0.405	lr=2.90e-04 | 93.7%@S26  T=1.73s(data=1.8ms QKV=2.11s FFN=3.04s) eta=14:05:33 | 43.4K token/s | 
[epoch_0]_31671  loss=3.166584 |g|=0.412	lr=2.90e-04 | 94.5%@S26  T=1.73s(data=2.0ms QKV=2.11s FFN=3.04s) eta=14:05:58 | 43.6K token/s | 
[epoch_0]_31681  loss=3.160833 |g|=0.398	lr=2.90e-04 | 95.3%@S26  T=1.81s(data=1.8ms QKV=2.11s FFN=3.04s) eta=14:47:05 | 43.7K token/s | 
[epoch_0]_31691  loss=3.158010 |g|=0.427	lr=2.90e-04 | 96.1%@S26  T=1.74s(data=1.7ms QKV=2.10s FFN=3.04s) eta=14:12:38 | 43.8K token/s | 
[Fuyou] head="4" update algorithm=4 t=11.67s
[Section@31700] layer[40-48] tasks=19(nPassBack=0) last_loss=3.23925(0.11021) N=(772,36176,35616 4184268)
[epoch_0]_31701  loss=3.198269 |g|=0.41	lr=2.89e-04 | 97.0%@S26  T=4.36s(data=1.8ms QKV=2.11s FFN=3.03s) eta=1d 11:31:24 | 42.6K token/s | 
[epoch_0]_31711  loss=3.122470 |g|=0.408	lr=2.89e-04 | 97.8%@S26  T=1.71s(data=1.9ms QKV=2.11s FFN=3.04s) eta=13:54:34 | 42.9K token/s | 
[epoch_0]_31721  loss=3.238702 |g|=0.412	lr=2.89e-04 | 98.6%@S26  T=1.79s(data=1.6ms QKV=2.11s FFN=3.04s) eta=14:35:19 | 43.0K token/s | 
[epoch_0]_31731  loss=3.169290 |g|=0.411	lr=2.89e-04 | 99.4%@S26  T=1.73s(data=1.9ms QKV=2.12s FFN=3.04s) eta=14:06:41 | 43.2K token/s | 
[epoch_0]_31738  loss=3.151645 |g|=0.394	lr=2.89e-04 | 100.0%@S26  T=1.74s(data=1.9ms QKV=2.11s FFN=3.04s) eta=14:08:33 | 43.4K token/s | 
-------- End of shard_26@"./Datasets/edu_fineweb1B/edu_fineweb_train_000480.bin"-------- 
[shard-27]@"./Datasets/edu_fineweb1B/edu_fineweb_train_000481.bin": tokens=100(M) nShardSamples=1220(2636712) 
[epoch_0]_31741  loss=3.247430 |g|=0.416	lr=2.89e-04 | 0.2%@S27  T=1.82s(data=1.3ms QKV=2.11s FFN=3.04s) eta=14:47:20 | 43.5K token/s | 
[epoch_0]_31751  loss=3.313495 |g|=0.407	lr=2.89e-04 | 1.0%@S27  T=1.80s(data=1.4ms QKV=2.11s FFN=3.04s) eta=14:40:26 | 43.6K token/s | 
[epoch_0]_31761  loss=3.284295 |g|=0.408	lr=2.88e-04 | 1.9%@S27  T=1.80s(data=1.8ms QKV=2.11s FFN=3.04s) eta=14:37:49 | 43.7K token/s | 
[epoch_0]_31771  loss=3.258172 |g|=0.42	lr=2.88e-04 | 2.7%@S27  T=1.73s(data=1.6ms QKV=2.11s FFN=3.04s) eta=14:03:22 | 43.9K token/s | 
[epoch_0]_31781  loss=3.226412 |g|=0.444	lr=2.88e-04 | 3.5%@S27  T=1.75s(data=1.6ms QKV=2.11s FFN=3.04s) eta=14:11:22 | 44.0K token/s | 
[epoch_0]_31791  loss=3.267522 |g|=0.426	lr=2.88e-04 | 4.3%@S27  T=1.77s(data=3.7ms QKV=2.11s FFN=3.04s) eta=14:23:28 | 44.1K token/s | 
[Fuyou] head="5" update algorithm=4 t=11.64s
[eval] 
	 Loss@"edu_fineweb1B"=3.227(0.0063) nBranch=1 nToken=6.31M best=3.2331(157) E2T=-0.0575 T=36.7292(0)s x=0
	#3.22679±0.0969 tps=172K(6.30784M) a=[3.04105,3.49836] T=36.7292(sec)
[Section@31800] layer[0-8] tasks=19(nPassBack=0) last_loss=3.28429(-0.0211709) N=(772,36288,35728 4197468)
[epoch_0]_31801  loss=3.313429 |g|=0.407	lr=2.88e-04 | 5.1%@S27  T=12.15s(data=2.9ms QKV=2.10s FFN=3.04s) eta=4d 02:41:21 | 42.3K token/s | 
[epoch_0]_31811  loss=3.172762 |g|=0.431	lr=2.88e-04 | 6.0%@S27  T=1.73s(data=1.6ms QKV=2.11s FFN=3.04s) eta=14:04:02 | 42.5K token/s | 
[epoch_0]_31821  loss=3.284170 |g|=0.432	lr=2.88e-04 | 6.8%@S27  T=1.73s(data=2.1ms QKV=2.11s FFN=3.04s) eta=14:02:16 | 42.8K token/s | 
[epoch_0]_31831  loss=3.265385 |g|=0.414	lr=2.87e-04 | 7.6%@S27  T=1.71s(data=2.0ms QKV=2.11s FFN=3.04s) eta=13:54:36 | 43.0K token/s | 
[epoch_0]_31841  loss=3.219474 |g|=0.432	lr=2.87e-04 | 8.4%@S27  T=1.79s(data=1.3ms QKV=2.11s FFN=3.04s) eta=14:30:16 | 43.1K token/s | 
[epoch_0]_31851  loss=3.302235 |g|=0.431	lr=2.87e-04 | 9.2%@S27  T=1.80s(data=1.3ms QKV=2.11s FFN=3.04s) eta=14:33:24 | 43.3K token/s | 
[epoch_0]_31861  loss=3.353993 |g|=0.428	lr=2.87e-04 | 10.1%@S27  T=1.73s(data=1.3ms QKV=2.11s FFN=3.04s) eta=13:58:56 | 43.5K token/s | 
[epoch_0]_31871  loss=3.289149 |g|=0.405	lr=2.87e-04 | 10.9%@S27  T=1.71s(data=1.3ms QKV=2.11s FFN=3.04s) eta=13:52:55 | 43.7K token/s | 
[epoch_0]_31881  loss=3.258788 |g|=0.427	lr=2.87e-04 | 11.7%@S27  T=1.74s(data=1.7ms QKV=2.11s FFN=3.04s) eta=14:07:40 | 43.9K token/s | 
[epoch_0]_31891  loss=3.262611 |g|=0.415	lr=2.86e-04 | 12.5%@S27  T=1.72s(data=1.8ms QKV=2.11s FFN=3.04s) eta=13:55:06 | 44.0K token/s | 
[Fuyou] head="0" update algorithm=4 t=12.48s
[Section@31900] layer[8-16] tasks=19(nPassBack=0) last_loss=3.24285(-0.020076) N=(772,36400,35840 4210668)
[epoch_0]_31901  loss=3.267306 |g|=0.42	lr=2.86e-04 | 13.3%@S27  T=4.45s(data=3.3ms QKV=2.11s FFN=3.03s) eta=1d 12:01:21 | 42.8K token/s | 
[epoch_0]_31911  loss=3.309266 |g|=0.423	lr=2.86e-04 | 14.2%@S27  T=1.72s(data=3.2ms QKV=2.11s FFN=3.04s) eta=13:54:32 | 43.0K token/s | 
[epoch_0]_31921  loss=3.182011 |g|=0.427	lr=2.86e-04 | 15.0%@S27  T=1.72s(data=1.8ms QKV=2.11s FFN=3.04s) eta=13:54:44 | 43.2K token/s | 
[epoch_0]_31931  loss=3.319391 |g|=0.446	lr=2.86e-04 | 15.8%@S27  T=1.81s(data=1.7ms QKV=2.11s FFN=3.04s) eta=14:36:07 | 43.3K token/s | 
[epoch_0]_31941  loss=3.312093 |g|=0.417	lr=2.86e-04 | 16.6%@S27  T=1.72s(data=2.9ms QKV=2.11s FFN=3.04s) eta=13:52:32 | 43.6K token/s | 
[epoch_0]_31951  loss=3.325094 |g|=0.418	lr=2.86e-04 | 17.4%@S27  T=1.75s(data=3.1ms QKV=2.11s FFN=3.04s) eta=14:06:19 | 43.7K token/s | 
[epoch_0]_31961  loss=3.225624 |g|=0.409	lr=2.85e-04 | 18.3%@S27  T=1.76s(data=2.1ms QKV=2.11s FFN=3.04s) eta=14:11:46 | 43.9K token/s | 
[epoch_0]_31971  loss=3.260133 |g|=0.407	lr=2.85e-04 | 19.1%@S27  T=1.72s(data=2.6ms QKV=2.11s FFN=3.04s) eta=13:54:18 | 44.1K token/s | 
[epoch_0]_31981  loss=3.221710 |g|=0.406	lr=2.85e-04 | 19.9%@S27  T=1.71s(data=1.5ms QKV=2.11s FFN=3.04s) eta=13:49:21 | 44.2K token/s | 
[epoch_0]_31991  loss=3.225436 |g|=0.408	lr=2.85e-04 | 20.7%@S27  T=1.78s(data=1.7ms QKV=2.11s FFN=3.04s) eta=14:21:59 | 44.3K token/s | 
[Fuyou] head="1" update algorithm=4 t=12.03s
[eval] 
	 Loss@"edu_fineweb1B"=3.223(0.0041) nBranch=1 nToken=6.31M best=3.2268(158) E2T=-0.0287 T=36.7292(0)s x=0
	#3.22266±0.0967 tps=172K(6.30784M) a=[3.03767,3.49697] T=36.7292(sec)
[Section@32000] layer[16-24] tasks=19(nPassBack=0) last_loss=3.2514(-0.0514338) N=(772,36512,35952 4223868)
[epoch_0]_32001  loss=3.200577 |g|=0.388	lr=2.85e-04 | 21.5%@S27  T=12.33s(data=3.1ms QKV=2.11s FFN=3.04s) eta=4d 03:26:13 | 42.5K token/s | 
[epoch_0]_32011  loss=3.264019 |g|=0.426	lr=2.85e-04 | 22.3%@S27  T=1.72s(data=1.5ms QKV=2.11s FFN=3.04s) eta=13:51:02 | 42.7K token/s | 
[epoch_0]_32021  loss=3.274786 |g|=0.433	lr=2.84e-04 | 23.2%@S27  T=1.71s(data=2.1ms QKV=2.11s FFN=3.04s) eta=13:49:04 | 43.0K token/s | 
[epoch_0]_32031  loss=3.269697 |g|=0.405	lr=2.84e-04 | 24.0%@S27  T=1.75s(data=1.4ms QKV=2.11s FFN=3.04s) eta=14:05:03 | 43.2K token/s | 
[epoch_0]_32041  loss=3.282686 |g|=0.414	lr=2.84e-04 | 24.8%@S27  T=1.76s(data=1.4ms QKV=2.11s FFN=3.04s) eta=14:12:41 | 43.3K token/s | 
[epoch_0]_32051  loss=3.234757 |g|=0.421	lr=2.84e-04 | 25.6%@S27  T=1.83s(data=6.3ms QKV=2.11s FFN=3.04s) eta=14:43:48 | 43.4K token/s | 
[epoch_0]_32061  loss=3.223153 |g|=0.398	lr=2.84e-04 | 26.4%@S27  T=1.82s(data=1.6ms QKV=2.11s FFN=3.04s) eta=14:39:14 | 43.5K token/s | 
[epoch_0]_32071  loss=3.323548 |g|=0.43	lr=2.84e-04 | 27.3%@S27  T=1.74s(data=1.5ms QKV=2.11s FFN=3.04s) eta=14:01:59 | 43.7K token/s | 
[epoch_0]_32081  loss=3.235685 |g|=0.399	lr=2.84e-04 | 28.1%@S27  T=1.80s(data=1.6ms QKV=2.11s FFN=3.04s) eta=14:28:30 | 43.7K token/s | 
[epoch_0]_32091  loss=3.262117 |g|=0.446	lr=2.83e-04 | 28.9%@S27  T=1.72s(data=1.6ms QKV=2.11s FFN=3.04s) eta=13:50:12 | 43.9K token/s | 
[Fuyou] head="2" update algorithm=4 t=13.47s
[Section@32100] layer[24-32] tasks=19(nPassBack=0) last_loss=3.23629(0.0593712) N=(772,36624,36064 4237068)
[epoch_0]_32101  loss=3.203898 |g|=0.405	lr=2.83e-04 | 29.7%@S27  T=4.22s(data=2.9ms QKV=2.11s FFN=3.03s) eta=1d 09:56:33 | 42.7K token/s | 
[epoch_0]_32111  loss=3.196817 |g|=0.391	lr=2.83e-04 | 30.5%@S27  T=1.75s(data=1.5ms QKV=2.11s FFN=3.04s) eta=14:05:31 | 42.9K token/s | 
[epoch_0]_32121  loss=3.210519 |g|=0.449	lr=2.83e-04 | 31.4%@S27  T=1.81s(data=1.7ms QKV=2.11s FFN=3.04s) eta=14:32:36 | 43.0K token/s | 
[epoch_0]_32131  loss=3.206485 |g|=0.413	lr=2.83e-04 | 32.2%@S27  T=1.80s(data=1.5ms QKV=2.11s FFN=3.04s) eta=14:28:46 | 43.1K token/s | 
[epoch_0]_32141  loss=3.287441 |g|=0.447	lr=2.83e-04 | 33.0%@S27  T=1.73s(data=1.8ms QKV=2.11s FFN=3.04s) eta=13:51:40 | 43.4K token/s | 
[epoch_0]_32151  loss=3.183671 |g|=0.432	lr=2.82e-04 | 33.8%@S27  T=1.71s(data=1.5ms QKV=2.11s FFN=3.04s) eta=13:44:58 | 43.6K token/s | 
[epoch_0]_32161  loss=3.324392 |g|=0.411	lr=2.82e-04 | 34.6%@S27  T=1.72s(data=1.8ms QKV=2.11s FFN=3.04s) eta=13:48:01 | 43.8K token/s | 
[epoch_0]_32171  loss=3.315261 |g|=0.405	lr=2.82e-04 | 35.5%@S27  T=1.73s(data=1.5ms QKV=2.11s FFN=3.04s) eta=13:54:09 | 44.0K token/s | 
[epoch_0]_32181  loss=3.290554 |g|=0.422	lr=2.82e-04 | 36.3%@S27  T=1.74s(data=1.5ms QKV=2.11s FFN=3.04s) eta=13:56:37 | 44.1K token/s | 
[epoch_0]_32191  loss=3.202727 |g|=0.416	lr=2.82e-04 | 37.1%@S27  T=1.72s(data=1.5ms QKV=2.11s FFN=3.04s) eta=13:47:49 | 44.3K token/s | 
[Fuyou] head="3" update algorithm=4 t=12.48s
[eval] 
	 Loss@"edu_fineweb1B"=3.220(0.003) nBranch=1 nToken=6.31M best=3.2227(159) E2T=0.0266 T=36.7114(0)s x=0
	#3.2197±0.0969 tps=172K(6.30784M) a=[3.02638,3.49205] T=36.7114(sec)
[Section@32200] layer[32-40] tasks=19(nPassBack=0) last_loss=3.19309(0.0139334) N=(772,36736,36176 4250268)
[epoch_0]_32201  loss=3.237551 |g|=0.43	lr=2.82e-04 | 37.9%@S27  T=12.30s(data=1.8ms QKV=2.11s FFN=3.04s) eta=4d 02:31:38 | 42.4K token/s | 
[epoch_0]_32211  loss=3.246737 |g|=0.411	lr=2.82e-04 | 38.7%@S27  T=1.71s(data=2.5ms QKV=2.11s FFN=3.04s) eta=13:41:53 | 42.7K token/s | 
[epoch_0]_32221  loss=3.212541 |g|=0.424	lr=2.81e-04 | 39.6%@S27  T=1.76s(data=1.5ms QKV=2.11s FFN=3.04s) eta=14:06:17 | 42.9K token/s | 
[epoch_0]_32231  loss=3.200399 |g|=0.427	lr=2.81e-04 | 40.4%@S27  T=1.75s(data=2.1ms QKV=2.11s FFN=3.04s) eta=13:59:12 | 43.1K token/s | 
[epoch_0]_32241  loss=3.240921 |g|=0.432	lr=2.81e-04 | 41.2%@S27  T=1.78s(data=1.5ms QKV=2.11s FFN=3.04s) eta=14:14:43 | 43.2K token/s | 
[epoch_0]_32251  loss=3.274043 |g|=0.465	lr=2.81e-04 | 42.0%@S27  T=1.72s(data=1.9ms QKV=2.11s FFN=3.04s) eta=13:45:48 | 43.4K token/s | 
[epoch_0]_32261  loss=3.265255 |g|=0.418	lr=2.81e-04 | 42.8%@S27  T=1.74s(data=1.7ms QKV=2.11s FFN=3.04s) eta=13:55:42 | 43.6K token/s | 
[epoch_0]_32271  loss=3.219063 |g|=0.415	lr=2.81e-04 | 43.6%@S27  T=1.72s(data=1.8ms QKV=2.11s FFN=3.04s) eta=13:43:48 | 43.8K token/s | 
[epoch_0]_32281  loss=3.227634 |g|=0.415	lr=2.80e-04 | 44.5%@S27  T=1.74s(data=1.8ms QKV=2.11s FFN=3.04s) eta=13:52:25 | 44.0K token/s | 
[epoch_0]_32291  loss=3.202609 |g|=0.405	lr=2.80e-04 | 45.3%@S27  T=1.79s(data=1.6ms QKV=2.11s FFN=3.04s) eta=14:18:58 | 44.1K token/s | 
[Fuyou] head="4" update algorithm=4 t=11.95s
[Section@32300] layer[40-48] tasks=19(nPassBack=0) last_loss=3.20096(0.0382855) N=(772,36848,36288 4263468)
[epoch_0]_32301  loss=3.238231 |g|=0.411	lr=2.80e-04 | 46.1%@S27  T=4.35s(data=2.5ms QKV=2.11s FFN=3.03s) eta=1d 10:42:07 | 42.8K token/s | 
[epoch_0]_32311  loss=3.208920 |g|=0.409	lr=2.80e-04 | 46.9%@S27  T=1.78s(data=2.5ms QKV=2.11s FFN=3.04s) eta=14:11:31 | 43.0K token/s | 
[epoch_0]_32321  loss=3.310047 |g|=0.415	lr=2.80e-04 | 47.7%@S27  T=1.78s(data=1.8ms QKV=2.11s FFN=3.04s) eta=14:14:01 | 43.1K token/s | 
[epoch_0]_32331  loss=3.209290 |g|=0.423	lr=2.80e-04 | 48.6%@S27  T=1.83s(data=1.7ms QKV=2.11s FFN=3.04s) eta=14:34:36 | 43.2K token/s | 
[epoch_0]_32341  loss=3.221012 |g|=0.41	lr=2.80e-04 | 49.4%@S27  T=1.76s(data=1.6ms QKV=2.11s FFN=3.04s) eta=14:02:06 | 43.4K token/s | 
[epoch_0]_32351  loss=3.235353 |g|=0.428	lr=2.79e-04 | 50.2%@S27  T=1.78s(data=1.7ms QKV=2.11s FFN=3.04s) eta=14:09:29 | 43.5K token/s | 
[epoch_0]_32361  loss=3.265100 |g|=0.421	lr=2.79e-04 | 51.0%@S27  T=1.74s(data=1.6ms QKV=2.11s FFN=3.04s) eta=13:53:48 | 43.7K token/s | 
[epoch_0]_32371  loss=3.222449 |g|=0.427	lr=2.79e-04 | 51.8%@S27  T=1.81s(data=1.5ms QKV=2.11s FFN=3.04s) eta=14:22:21 | 43.8K token/s | 
[epoch_0]_32381  loss=3.180434 |g|=0.406	lr=2.79e-04 | 52.7%@S27  T=1.78s(data=1.7ms QKV=2.11s FFN=3.04s) eta=14:10:02 | 43.9K token/s | 
[epoch_0]_32391  loss=3.202747 |g|=0.405	lr=2.79e-04 | 53.5%@S27  T=1.79s(data=1.5ms QKV=2.11s FFN=3.04s) eta=14:16:31 | 44.0K token/s | 
[Fuyou] head="5" update algorithm=4 t=12.45s
[eval] 
	 Loss@"edu_fineweb1B"=3.217(0.0032) nBranch=1 nToken=6.31M best=3.2197(160) E2T=-0.029 T=36.7064(0)s x=0
	#3.21652±0.0960 tps=172K(6.30784M) a=[3.02221,3.48821] T=36.7064(sec)
[Section@32400] layer[0-8] tasks=19(nPassBack=0) last_loss=3.24551(0.038779) N=(772,36960,36400 4276668)
[epoch_0]_32401  loss=3.246413 |g|=0.409	lr=2.79e-04 | 54.3%@S27  T=12.01s(data=1.6ms QKV=2.10s FFN=3.04s) eta=3d 23:29:27 | 42.1K token/s | 
[epoch_0]_32411  loss=3.231319 |g|=0.449	lr=2.78e-04 | 55.1%@S27  T=1.71s(data=1.6ms QKV=2.10s FFN=3.04s) eta=13:35:15 | 42.4K token/s | 
[epoch_0]_32421  loss=3.185084 |g|=0.417	lr=2.78e-04 | 55.9%@S27  T=1.79s(data=1.7ms QKV=2.11s FFN=3.04s) eta=14:12:23 | 42.6K token/s | 
[epoch_0]_32431  loss=3.267966 |g|=0.452	lr=2.78e-04 | 56.8%@S27  T=1.81s(data=1.7ms QKV=2.11s FFN=3.04s) eta=14:24:11 | 42.7K token/s | 
[epoch_0]_32441  loss=3.260035 |g|=0.441	lr=2.78e-04 | 57.6%@S27  T=1.85s(data=1.6ms QKV=2.11s FFN=3.04s) eta=14:41:25 | 42.8K token/s | 
[epoch_0]_32451  loss=3.226839 |g|=0.442	lr=2.78e-04 | 58.4%@S27  T=1.78s(data=1.8ms QKV=2.10s FFN=3.04s) eta=14:09:37 | 42.9K token/s | 
[epoch_0]_32461  loss=3.239493 |g|=0.419	lr=2.78e-04 | 59.2%@S27  T=1.75s(data=1.8ms QKV=2.11s FFN=3.04s) eta=13:54:34 | 43.1K token/s | 
[epoch_0]_32471  loss=3.294585 |g|=0.445	lr=2.78e-04 | 60.0%@S27  T=1.74s(data=1.7ms QKV=2.11s FFN=3.04s) eta=13:49:30 | 43.3K token/s | 
[epoch_0]_32481  loss=3.243166 |g|=0.422	lr=2.77e-04 | 60.9%@S27  T=1.77s(data=1.5ms QKV=2.11s FFN=3.04s) eta=14:00:04 | 43.5K token/s | 
[epoch_0]_32491  loss=3.177054 |g|=0.419	lr=2.77e-04 | 61.7%@S27  T=1.83s(data=1.8ms QKV=2.11s FFN=3.04s) eta=14:30:31 | 43.5K token/s | 
[Fuyou] head="0" update algorithm=4 t=10.76s
[Section@32500] layer[8-16] tasks=19(nPassBack=0) last_loss=3.20018(0.0426731) N=(772,37072,36512 4289868)
[epoch_0]_32501  loss=3.275046 |g|=0.406	lr=2.77e-04 | 62.5%@S27  T=4.56s(data=1.7ms QKV=2.10s FFN=3.03s) eta=1d 12:09:16 | 42.3K token/s | 
[epoch_0]_32511  loss=3.188223 |g|=0.44	lr=2.77e-04 | 63.3%@S27  T=1.79s(data=1.6ms QKV=2.10s FFN=3.04s) eta=14:09:33 | 42.4K token/s | 
[epoch_0]_32521  loss=3.200409 |g|=0.422	lr=2.77e-04 | 64.1%@S27  T=1.77s(data=1.6ms QKV=2.11s FFN=3.04s) eta=13:59:37 | 42.6K token/s | 
[epoch_0]_32531  loss=3.223688 |g|=0.431	lr=2.77e-04 | 64.9%@S27  T=1.72s(data=1.9ms QKV=2.11s FFN=3.04s) eta=13:37:26 | 42.9K token/s | 
[epoch_0]_32541  loss=3.146742 |g|=0.423	lr=2.76e-04 | 65.8%@S27  T=1.75s(data=1.9ms QKV=2.11s FFN=3.04s) eta=13:52:17 | 43.1K token/s | 
[epoch_0]_32551  loss=3.247319 |g|=0.41	lr=2.76e-04 | 66.6%@S27  T=1.80s(data=1.6ms QKV=2.11s FFN=3.04s) eta=14:14:58 | 43.2K token/s | 
[epoch_0]_32561  loss=3.242554 |g|=0.431	lr=2.76e-04 | 67.4%@S27  T=1.76s(data=1.7ms QKV=2.11s FFN=3.04s) eta=13:56:01 | 43.4K token/s | 
[epoch_0]_32571  loss=3.178761 |g|=0.427	lr=2.76e-04 | 68.2%@S27  T=1.72s(data=2.1ms QKV=2.11s FFN=3.04s) eta=13:37:23 | 43.6K token/s | 
[epoch_0]_32581  loss=3.269029 |g|=0.422	lr=2.76e-04 | 69.0%@S27  T=1.72s(data=2.1ms QKV=2.11s FFN=3.04s) eta=13:34:13 | 43.8K token/s | 
[epoch_0]_32591  loss=3.231275 |g|=0.424	lr=2.76e-04 | 69.9%@S27  T=1.72s(data=2.2ms QKV=2.11s FFN=3.04s) eta=13:35:15 | 44.0K token/s | 
[Fuyou] head="1" update algorithm=4 t=11.23s
[eval] 
	 Loss@"edu_fineweb1B"=3.214(0.0021) nBranch=1 nToken=6.31M best=3.2165(161) E2T=-0.0238 T=36.7242(0)s x=0
	#3.21445±0.0972 tps=172K(6.30784M) a=[3.02149,3.48699] T=36.7242(sec)
[Section@32600] layer[16-24] tasks=19(nPassBack=0) last_loss=3.23828(0.0131204) N=(772,37184,36624 4303068)
[epoch_0]_32601  loss=3.248836 |g|=0.407	lr=2.76e-04 | 70.7%@S27  T=12.32s(data=2.5ms QKV=2.10s FFN=3.04s) eta=4d 01:16:15 | 42.1K token/s | 
[epoch_0]_32611  loss=3.306087 |g|=0.444	lr=2.75e-04 | 71.5%@S27  T=1.78s(data=1.8ms QKV=2.11s FFN=3.04s) eta=14:01:42 | 42.3K token/s | 
[epoch_0]_32621  loss=3.266698 |g|=0.426	lr=2.75e-04 | 72.3%@S27  T=1.72s(data=2.1ms QKV=2.10s FFN=3.04s) eta=13:36:37 | 42.6K token/s | 
[epoch_0]_32631  loss=3.254614 |g|=0.428	lr=2.75e-04 | 73.1%@S27  T=1.77s(data=1.6ms QKV=2.10s FFN=3.04s) eta=13:58:54 | 42.8K token/s | 
[epoch_0]_32641  loss=3.200165 |g|=0.403	lr=2.75e-04 | 74.0%@S27  T=1.73s(data=2.1ms QKV=2.10s FFN=3.04s) eta=13:38:14 | 43.0K token/s | 
[epoch_0]_32651  loss=3.199089 |g|=0.426	lr=2.75e-04 | 74.8%@S27  T=1.72s(data=2.0ms QKV=2.10s FFN=3.04s) eta=13:34:08 | 43.2K token/s | 
[epoch_0]_32661  loss=3.216813 |g|=0.423	lr=2.75e-04 | 75.6%@S27  T=1.73s(data=1.6ms QKV=2.10s FFN=3.04s) eta=13:39:59 | 43.4K token/s | 
[epoch_0]_32671  loss=3.231799 |g|=0.421	lr=2.74e-04 | 76.4%@S27  T=1.82s(data=1.6ms QKV=2.10s FFN=3.04s) eta=14:19:37 | 43.5K token/s | 
[epoch_0]_32681  loss=3.241905 |g|=0.419	lr=2.74e-04 | 77.2%@S27  T=1.72s(data=2.1ms QKV=2.10s FFN=3.04s) eta=13:33:22 | 43.7K token/s | 
[epoch_0]_32691  loss=3.220031 |g|=0.435	lr=2.74e-04 | 78.1%@S27  T=1.79s(data=1.7ms QKV=2.10s FFN=3.04s) eta=14:07:49 | 43.8K token/s | 
[Fuyou] head="2" update algorithm=4 t=10.22s
[Section@32700] layer[24-32] tasks=19(nPassBack=0) last_loss=3.20663(0.0296664) N=(772,37296,36736 4316268)
[epoch_0]_32701  loss=3.216534 |g|=0.41	lr=2.74e-04 | 78.9%@S27  T=4.52s(data=1.6ms QKV=2.10s FFN=3.03s) eta=1d 11:35:03 | 42.5K token/s | 
[epoch_0]_32711  loss=3.243875 |g|=0.439	lr=2.74e-04 | 79.7%@S27  T=1.80s(data=2.4ms QKV=2.10s FFN=3.04s) eta=14:10:35 | 42.7K token/s | 
[epoch_0]_32721  loss=3.196652 |g|=0.44	lr=2.74e-04 | 80.5%@S27  T=1.82s(data=1.6ms QKV=2.10s FFN=3.04s) eta=14:18:33 | 42.8K token/s | 
[epoch_0]_32731  loss=3.236207 |g|=0.413	lr=2.74e-04 | 81.3%@S27  T=1.79s(data=2.6ms QKV=2.10s FFN=3.04s) eta=14:05:53 | 42.9K token/s | 
[epoch_0]_32741  loss=3.165258 |g|=0.426	lr=2.73e-04 | 82.2%@S27  T=1.80s(data=1.6ms QKV=2.11s FFN=3.04s) eta=14:08:53 | 43.1K token/s | 
[epoch_0]_32751  loss=3.146636 |g|=0.412	lr=2.73e-04 | 83.0%@S27  T=1.81s(data=1.6ms QKV=2.11s FFN=3.04s) eta=14:12:11 | 43.2K token/s | 
[epoch_0]_32761  loss=3.179932 |g|=0.42	lr=2.73e-04 | 83.8%@S27  T=1.76s(data=1.6ms QKV=2.11s FFN=3.04s) eta=13:50:19 | 43.3K token/s | 
[epoch_0]_32771  loss=3.252972 |g|=0.422	lr=2.73e-04 | 84.6%@S27  T=1.80s(data=1.7ms QKV=2.11s FFN=3.04s) eta=14:08:16 | 43.4K token/s | 
[epoch_0]_32781  loss=3.185778 |g|=0.414	lr=2.73e-04 | 85.4%@S27  T=1.79s(data=1.8ms QKV=2.10s FFN=3.04s) eta=14:02:39 | 43.6K token/s | 
[epoch_0]_32791  loss=3.361675 |g|=0.436	lr=2.73e-04 | 86.2%@S27  T=1.72s(data=1.7ms QKV=2.11s FFN=3.04s) eta=13:31:59 | 43.8K token/s | 
[Fuyou] head="3" update algorithm=4 t=11.26s
[eval] 
	 Loss@"edu_fineweb1B"=3.213(0.0018) nBranch=1 nToken=6.31M best=3.2145(162) E2T=0.0274 T=36.7452(0)s x=0
	#3.21264±0.0962 tps=172K(6.30784M) a=[3.02424,3.48757] T=36.7452(sec)
[Section@32800] layer[32-40] tasks=19(nPassBack=0) last_loss=3.18526(0.00782418) N=(772,37408,36848 4329468)
[epoch_0]_32801  loss=3.263242 |g|=0.44	lr=2.72e-04 | 87.1%@S27  T=11.85s(data=1.8ms QKV=2.10s FFN=3.04s) eta=3d 20:56:51 | 41.9K token/s | 
[epoch_0]_32811  loss=3.176242 |g|=0.406	lr=2.72e-04 | 87.9%@S27  T=1.80s(data=1.6ms QKV=2.10s FFN=3.04s) eta=14:08:25 | 42.1K token/s | 
[epoch_0]_32821  loss=3.180850 |g|=0.418	lr=2.72e-04 | 88.7%@S27  T=1.72s(data=1.8ms QKV=2.11s FFN=3.04s) eta=13:29:00 | 42.4K token/s | 
[epoch_0]_32831  loss=3.224383 |g|=0.416	lr=2.72e-04 | 89.5%@S27  T=1.75s(data=1.8ms QKV=2.11s FFN=3.04s) eta=13:40:42 | 42.6K token/s | 
[epoch_0]_32841  loss=3.242650 |g|=0.428	lr=2.72e-04 | 90.3%@S27  T=1.72s(data=1.8ms QKV=2.10s FFN=3.04s) eta=13:29:44 | 42.8K token/s | 
[epoch_0]_32851  loss=3.183380 |g|=0.431	lr=2.72e-04 | 91.2%@S27  T=1.81s(data=1.6ms QKV=2.11s FFN=3.04s) eta=14:11:20 | 43.0K token/s | 
[epoch_0]_32861  loss=3.185492 |g|=0.423	lr=2.72e-04 | 92.0%@S27  T=1.73s(data=2.0ms QKV=2.10s FFN=3.04s) eta=13:34:27 | 43.2K token/s | 
[epoch_0]_32871  loss=3.199917 |g|=0.446	lr=2.71e-04 | 92.8%@S27  T=1.80s(data=2.0ms QKV=2.10s FFN=3.04s) eta=14:04:50 | 43.3K token/s | 
[epoch_0]_32881  loss=3.255957 |g|=0.428	lr=2.71e-04 | 93.6%@S27  T=1.74s(data=2.2ms QKV=2.10s FFN=3.04s) eta=13:36:08 | 43.5K token/s | 
[epoch_0]_32891  loss=3.149106 |g|=0.403	lr=2.71e-04 | 94.4%@S27  T=1.75s(data=1.6ms QKV=2.11s FFN=3.04s) eta=13:42:59 | 43.6K token/s | 
[Fuyou] head="4" update algorithm=4 t=12.27s
[Section@32900] layer[40-48] tasks=19(nPassBack=0) last_loss=3.21599(-0.015027) N=(772,37520,36960 4342668)
[epoch_0]_32901  loss=3.160227 |g|=0.404	lr=2.71e-04 | 95.3%@S27  T=4.04s(data=2.0ms QKV=2.10s FFN=3.03s) eta=1d 07:33:01 | 42.5K token/s | 
[epoch_0]_32911  loss=3.213032 |g|=0.444	lr=2.71e-04 | 96.1%@S27  T=1.80s(data=1.7ms QKV=2.10s FFN=3.04s) eta=14:04:12 | 42.6K token/s | 
[epoch_0]_32921  loss=3.214442 |g|=0.411	lr=2.71e-04 | 96.9%@S27  T=1.74s(data=1.5ms QKV=2.11s FFN=3.04s) eta=13:34:49 | 42.8K token/s | 
[epoch_0]_32931  loss=3.261787 |g|=0.431	lr=2.70e-04 | 97.7%@S27  T=1.81s(data=2.1ms QKV=2.11s FFN=3.04s) eta=14:09:04 | 43.0K token/s | 
[epoch_0]_32941  loss=3.219399 |g|=0.416	lr=2.70e-04 | 98.5%@S27  T=1.84s(data=1.5ms QKV=2.11s FFN=3.04s) eta=14:22:06 | 43.0K token/s | 
[epoch_0]_32951  loss=3.259822 |g|=0.402	lr=2.70e-04 | 99.4%@S27  T=1.75s(data=1.7ms QKV=2.11s FFN=3.04s) eta=13:38:11 | 43.2K token/s | 
[epoch_0]_32958  loss=3.213619 |g|=0.423	lr=2.70e-04 | 99.9%@S27  T=1.81s(data=1.6ms QKV=2.11s FFN=3.04s) eta=14:09:10 | 43.3K token/s | 
-------- End of shard_27@"./Datasets/edu_fineweb1B/edu_fineweb_train_000481.bin"-------- 
[shard-28]@"./Datasets/edu_fineweb1B/edu_fineweb_train_000482.bin": tokens=100(M) nShardSamples=1220(2734368) 
[epoch_0]_32961  loss=3.294155 |g|=0.422	lr=2.70e-04 | 0.2%@S28  T=1.77s(data=1.6ms QKV=2.10s FFN=3.04s) eta=13:46:31 | 43.5K token/s | 
[epoch_0]_32971  loss=3.185706 |g|=0.424	lr=2.70e-04 | 1.0%@S28  T=1.80s(data=1.3ms QKV=2.11s FFN=3.04s) eta=14:03:22 | 43.6K token/s | 
[epoch_0]_32981  loss=3.257521 |g|=0.428	lr=2.70e-04 | 1.8%@S28  T=1.79s(data=1.2ms QKV=2.10s FFN=3.04s) eta=13:56:03 | 43.7K token/s | 
[epoch_0]_32991  loss=3.224020 |g|=0.426	lr=2.70e-04 | 2.6%@S28  T=1.72s(data=1.3ms QKV=2.10s FFN=3.04s) eta=13:24:05 | 43.9K token/s | 
[Fuyou] head="5" update algorithm=4 t=11.36s
[eval] 
	 Loss@"edu_fineweb1B"=3.212(0.00095) nBranch=1 nToken=6.31M best=3.2126(163) E2T=-0.0768 T=36.7466(0)s x=0
	#3.21169±0.0962 tps=172K(6.30784M) a=[3.02412,3.48187] T=36.7466(sec)
[Section@33000] layer[0-8] tasks=19(nPassBack=0) last_loss=3.28849(-0.0429797) N=(772,37632,37072 4355868)
[epoch_0]_33001  loss=3.236943 |g|=0.427	lr=2.69e-04 | 3.4%@S28  T=12.13s(data=1.8ms QKV=2.10s FFN=3.04s) eta=3d 22:29:40 | 42.0K token/s | 
[epoch_0]_33011  loss=3.222235 |g|=0.412	lr=2.69e-04 | 4.3%@S28  T=1.81s(data=1.3ms QKV=2.10s FFN=3.04s) eta=14:06:16 | 42.2K token/s | 
[epoch_0]_33021  loss=3.164709 |g|=0.416	lr=2.69e-04 | 5.1%@S28  T=1.82s(data=1.8ms QKV=2.10s FFN=3.04s) eta=14:11:18 | 42.3K token/s | 
[epoch_0]_33031  loss=3.195090 |g|=0.442	lr=2.69e-04 | 5.9%@S28  T=1.75s(data=1.8ms QKV=2.11s FFN=3.04s) eta=13:37:44 | 42.5K token/s | 
[epoch_0]_33041  loss=3.165286 |g|=0.43	lr=2.69e-04 | 6.7%@S28  T=1.82s(data=1.6ms QKV=2.11s FFN=3.04s) eta=14:09:29 | 42.7K token/s | 
[epoch_0]_33051  loss=3.256664 |g|=0.41	lr=2.69e-04 | 7.5%@S28  T=1.80s(data=1.6ms QKV=2.11s FFN=3.04s) eta=13:59:35 | 42.8K token/s | 
[epoch_0]_33061  loss=3.131563 |g|=0.427	lr=2.68e-04 | 8.4%@S28  T=1.79s(data=1.4ms QKV=2.11s FFN=3.04s) eta=13:55:30 | 43.0K token/s | 
[epoch_0]_33071  loss=3.230348 |g|=0.406	lr=2.68e-04 | 9.2%@S28  T=1.78s(data=1.3ms QKV=2.10s FFN=3.04s) eta=13:51:20 | 43.1K token/s | 
[epoch_0]_33081  loss=3.153733 |g|=0.416	lr=2.68e-04 | 10.0%@S28  T=1.74s(data=1.3ms QKV=2.10s FFN=3.04s) eta=13:30:12 | 43.3K token/s | 
[epoch_0]_33091  loss=3.245386 |g|=0.413	lr=2.68e-04 | 10.8%@S28  T=1.77s(data=1.3ms QKV=2.10s FFN=3.04s) eta=13:46:34 | 43.4K token/s | 
[Fuyou] head="0" update algorithm=4 t=11.91s
[Section@33100] layer[8-16] tasks=19(nPassBack=0) last_loss=3.18921(0.010967) N=(772,37744,37184 4369068)
[epoch_0]_33101  loss=3.315383 |g|=0.416	lr=2.68e-04 | 11.6%@S28  T=4.72s(data=1.8ms QKV=2.10s FFN=3.03s) eta=1d 12:35:18 | 42.1K token/s | 
[epoch_0]_33111  loss=3.232372 |g|=0.449	lr=2.68e-04 | 12.5%@S28  T=1.75s(data=1.7ms QKV=2.11s FFN=3.04s) eta=13:32:29 | 42.4K token/s | 
[epoch_0]_33121  loss=3.242960 |g|=0.436	lr=2.68e-04 | 13.3%@S28  T=1.85s(data=6.4ms QKV=2.11s FFN=3.04s) eta=14:22:23 | 42.5K token/s | 
[epoch_0]_33131  loss=3.276315 |g|=0.414	lr=2.67e-04 | 14.1%@S28  T=1.72s(data=1.6ms QKV=2.11s FFN=3.04s) eta=13:18:21 | 42.7K token/s | 
[epoch_0]_33141  loss=3.174105 |g|=0.449	lr=2.67e-04 | 14.9%@S28  T=1.72s(data=1.4ms QKV=2.11s FFN=3.04s) eta=13:21:39 | 43.0K token/s | 
[epoch_0]_33151  loss=3.159655 |g|=0.411	lr=2.67e-04 | 15.7%@S28  T=1.74s(data=1.5ms QKV=2.11s FFN=3.04s) eta=13:30:27 | 43.2K token/s | 
[epoch_0]_33161  loss=3.140680 |g|=0.426	lr=2.67e-04 | 16.6%@S28  T=1.72s(data=1.5ms QKV=2.11s FFN=3.04s) eta=13:17:59 | 43.4K token/s | 
[epoch_0]_33171  loss=3.233456 |g|=0.416	lr=2.67e-04 | 17.4%@S28  T=1.73s(data=1.6ms QKV=2.11s FFN=3.04s) eta=13:24:26 | 43.6K token/s | 
[epoch_0]_33181  loss=3.193476 |g|=0.425	lr=2.67e-04 | 18.2%@S28  T=1.73s(data=1.7ms QKV=2.11s FFN=3.04s) eta=13:22:44 | 43.8K token/s | 
[epoch_0]_33191  loss=3.260894 |g|=0.441	lr=2.66e-04 | 19.0%@S28  T=1.71s(data=1.6ms QKV=2.11s FFN=3.04s) eta=13:15:09 | 44.0K token/s | 
[Fuyou] head="1" update algorithm=4 t=10.91s
[eval] 
	 Loss@"edu_fineweb1B"=3.211(0.00073) nBranch=1 nToken=6.31M best=3.2117(164) E2T=0.000325 T=36.7176(0)s x=0
	#3.21097±0.0964 tps=172K(6.30784M) a=[3.01942,3.48139] T=36.7176(sec)
[Section@33200] layer[16-24] tasks=19(nPassBack=0) last_loss=3.21064(0.0276365) N=(772,37856,37296 4382268)
[epoch_0]_33201  loss=3.249230 |g|=0.396	lr=2.66e-04 | 19.8%@S28  T=12.26s(data=2.4ms QKV=2.10s FFN=3.03s) eta=3d 22:47:59 | 42.1K token/s | 
[epoch_0]_33211  loss=3.244546 |g|=0.434	lr=2.66e-04 | 20.7%@S28  T=1.78s(data=1.9ms QKV=2.10s FFN=3.04s) eta=13:46:54 | 42.3K token/s | 
[epoch_0]_33221  loss=3.122481 |g|=0.461	lr=2.66e-04 | 21.5%@S28  T=1.80s(data=1.5ms QKV=2.10s FFN=3.04s) eta=13:54:25 | 42.5K token/s | 
[epoch_0]_33231  loss=3.200608 |g|=0.427	lr=2.66e-04 | 22.3%@S28  T=1.79s(data=1.5ms QKV=2.11s FFN=3.04s) eta=13:49:16 | 42.6K token/s | 
[epoch_0]_33241  loss=3.206133 |g|=0.412	lr=2.66e-04 | 23.1%@S28  T=1.71s(data=1.8ms QKV=2.10s FFN=3.04s) eta=13:11:38 | 42.9K token/s | 
[epoch_0]_33251  loss=3.199432 |g|=0.429	lr=2.66e-04 | 23.9%@S28  T=1.80s(data=1.4ms QKV=2.11s FFN=3.04s) eta=13:51:55 | 43.0K token/s | 
[epoch_0]_33261  loss=3.232958 |g|=0.42	lr=2.65e-04 | 24.7%@S28  T=1.78s(data=1.4ms QKV=2.11s FFN=3.04s) eta=13:42:54 | 43.2K token/s | 
[epoch_0]_33271  loss=3.196069 |g|=0.422	lr=2.65e-04 | 25.6%@S28  T=1.83s(data=1.8ms QKV=2.10s FFN=3.04s) eta=14:04:32 | 43.3K token/s | 
[epoch_0]_33281  loss=3.195006 |g|=0.413	lr=2.65e-04 | 26.4%@S28  T=1.80s(data=1.7ms QKV=2.11s FFN=3.04s) eta=13:50:57 | 43.4K token/s | 
[epoch_0]_33291  loss=3.217708 |g|=0.418	lr=2.65e-04 | 27.2%@S28  T=1.80s(data=1.6ms QKV=2.10s FFN=3.04s) eta=13:50:04 | 43.5K token/s | 
[Fuyou] head="2" update algorithm=4 t=10.19s
[Section@33300] layer[24-32] tasks=19(nPassBack=0) last_loss=3.18109(0.0255392) N=(772,37968,37408 4395468)
[epoch_0]_33301  loss=3.186837 |g|=0.409	lr=2.65e-04 | 28.0%@S28  T=3.92s(data=2.0ms QKV=2.10s FFN=3.03s) eta=1d 06:10:03 | 42.4K token/s | 
[epoch_0]_33311  loss=3.158034 |g|=0.421	lr=2.65e-04 | 28.8%@S28  T=1.81s(data=1.5ms QKV=2.11s FFN=3.04s) eta=13:54:15 | 42.5K token/s | 
[epoch_0]_33321  loss=3.153898 |g|=0.426	lr=2.64e-04 | 29.7%@S28  T=1.75s(data=1.5ms QKV=2.11s FFN=3.04s) eta=13:29:06 | 42.7K token/s | 
[epoch_0]_33331  loss=3.183526 |g|=0.419	lr=2.64e-04 | 30.5%@S28  T=1.75s(data=1.6ms QKV=2.11s FFN=3.04s) eta=13:25:48 | 42.9K token/s | 
[epoch_0]_33341  loss=3.190332 |g|=0.431	lr=2.64e-04 | 31.3%@S28  T=1.74s(data=1.6ms QKV=2.11s FFN=3.04s) eta=13:25:22 | 43.1K token/s | 
[epoch_0]_33351  loss=3.205304 |g|=0.405	lr=2.64e-04 | 32.1%@S28  T=1.78s(data=1.5ms QKV=2.11s FFN=3.04s) eta=13:40:59 | 43.3K token/s | 
[epoch_0]_33361  loss=3.166018 |g|=0.411	lr=2.64e-04 | 32.9%@S28  T=1.80s(data=1.6ms QKV=2.11s FFN=3.04s) eta=13:52:16 | 43.4K token/s | 
[epoch_0]_33371  loss=3.261388 |g|=0.421	lr=2.64e-04 | 33.8%@S28  T=1.81s(data=1.4ms QKV=2.11s FFN=3.04s) eta=13:54:40 | 43.5K token/s | 
[epoch_0]_33381  loss=3.195332 |g|=0.42	lr=2.64e-04 | 34.6%@S28  T=1.80s(data=1.6ms QKV=2.11s FFN=3.04s) eta=13:51:00 | 43.6K token/s | 
[epoch_0]_33391  loss=3.177867 |g|=0.402	lr=2.63e-04 | 35.4%@S28  T=1.82s(data=1.6ms QKV=2.11s FFN=3.04s) eta=13:58:49 | 43.7K token/s | 
[Fuyou] head="3" update algorithm=4 t=12.18s
[eval] 
	 Loss@"edu_fineweb1B"=3.210(0.0015) nBranch=1 nToken=6.31M best=3.2110(165) E2T=0.0318 T=36.7382(0)s x=0
	#3.20951±0.0966 tps=172K(6.30784M) a=[3.02309,3.48011] T=36.7382(sec)
[Section@33400] layer[32-40] tasks=19(nPassBack=0) last_loss=3.17772(0.00753903) N=(772,38080,37520 4408668)
[epoch_0]_33401  loss=3.205308 |g|=0.401	lr=2.63e-04 | 36.2%@S28  T=12.12s(data=1.9ms QKV=2.10s FFN=3.04s) eta=3d 21:01:43 | 41.8K token/s | 
[epoch_0]_33411  loss=3.133792 |g|=0.414	lr=2.63e-04 | 37.0%@S28  T=1.79s(data=1.6ms QKV=2.11s FFN=3.04s) eta=13:43:20 | 42.0K token/s | 
[epoch_0]_33421  loss=3.166656 |g|=0.461	lr=2.63e-04 | 37.9%@S28  T=1.80s(data=1.7ms QKV=2.11s FFN=3.04s) eta=13:50:25 | 42.2K token/s | 
[epoch_0]_33431  loss=3.170451 |g|=0.406	lr=2.63e-04 | 38.7%@S28  T=1.81s(data=1.6ms QKV=2.11s FFN=3.04s) eta=13:52:22 | 42.3K token/s | 
[epoch_0]_33441  loss=3.144531 |g|=0.415	lr=2.63e-04 | 39.5%@S28  T=1.74s(data=1.6ms QKV=2.11s FFN=3.04s) eta=13:21:42 | 42.6K token/s | 
[epoch_0]_33451  loss=3.146044 |g|=0.436	lr=2.62e-04 | 40.3%@S28  T=1.80s(data=1.6ms QKV=2.11s FFN=3.04s) eta=13:47:18 | 42.7K token/s | 
[epoch_0]_33461  loss=3.107786 |g|=0.409	lr=2.62e-04 | 41.1%@S28  T=1.72s(data=1.7ms QKV=2.11s FFN=3.04s) eta=13:11:01 | 43.0K token/s | 
[epoch_0]_33471  loss=3.219280 |g|=0.414	lr=2.62e-04 | 42.0%@S28  T=1.81s(data=1.4ms QKV=2.11s FFN=3.04s) eta=13:50:18 | 43.1K token/s | 
[epoch_0]_33481  loss=3.172855 |g|=0.43	lr=2.62e-04 | 42.8%@S28  T=1.75s(data=1.5ms QKV=2.11s FFN=3.04s) eta=13:25:52 | 43.3K token/s | 
[epoch_0]_33491  loss=3.175523 |g|=0.429	lr=2.62e-04 | 43.6%@S28  T=1.81s(data=1.6ms QKV=2.11s FFN=3.04s) eta=13:50:16 | 43.4K token/s | 
[Fuyou] head="4" update algorithm=4 t=12.73s
[Section@33500] layer[40-48] tasks=19(nPassBack=0) last_loss=3.1362(0.0797882) N=(772,38192,37632 4421868)
[epoch_0]_33501  loss=3.221823 |g|=0.405	lr=2.62e-04 | 44.4%@S28  T=4.26s(data=1.6ms QKV=2.11s FFN=3.03s) eta=1d 08:36:20 | 42.2K token/s | 
[epoch_0]_33511  loss=3.213821 |g|=0.444	lr=2.62e-04 | 45.2%@S28  T=1.78s(data=1.6ms QKV=2.11s FFN=3.04s) eta=13:36:22 | 42.3K token/s | 
[epoch_0]_33521  loss=3.200254 |g|=0.432	lr=2.61e-04 | 46.0%@S28  T=1.78s(data=2.0ms QKV=2.11s FFN=3.04s) eta=13:35:27 | 42.5K token/s | 
[epoch_0]_33531  loss=3.138992 |g|=0.416	lr=2.61e-04 | 46.9%@S28  T=1.82s(data=1.7ms QKV=2.11s FFN=3.04s) eta=13:53:41 | 42.7K token/s | 
[epoch_0]_33541  loss=3.198467 |g|=0.43	lr=2.61e-04 | 47.7%@S28  T=1.74s(data=2.0ms QKV=2.11s FFN=3.04s) eta=13:15:19 | 42.9K token/s | 
[epoch_0]_33551  loss=3.234293 |g|=0.405	lr=2.61e-04 | 48.5%@S28  T=1.78s(data=1.8ms QKV=2.11s FFN=3.04s) eta=13:34:46 | 43.0K token/s | 
[epoch_0]_33561  loss=3.229070 |g|=0.42	lr=2.61e-04 | 49.3%@S28  T=1.80s(data=1.5ms QKV=2.11s FFN=3.04s) eta=13:45:31 | 43.2K token/s | 
[epoch_0]_33571  loss=3.195075 |g|=0.42	lr=2.61e-04 | 50.1%@S28  T=1.80s(data=1.4ms QKV=2.11s FFN=3.04s) eta=13:45:12 | 43.3K token/s | 
[epoch_0]_33581  loss=3.189917 |g|=0.432	lr=2.60e-04 | 51.0%@S28  T=1.78s(data=1.5ms QKV=2.11s FFN=3.04s) eta=13:35:02 | 43.4K token/s | 
[epoch_0]_33591  loss=3.227577 |g|=0.421	lr=2.60e-04 | 51.8%@S28  T=1.71s(data=1.8ms QKV=2.11s FFN=3.04s) eta=13:04:18 | 43.6K token/s | 
[Fuyou] head="5" update algorithm=4 t=10.90s
[eval] 
	 Loss@"edu_fineweb1B"=3.209(0.00094) nBranch=1 nToken=6.31M best=3.2095(166) E2T=-0.0268 T=36.7333(0)s x=0
	#3.20856±0.0974 tps=172K(6.30784M) a=[3.01429,3.48647] T=36.7333(sec)
[Section@33600] layer[0-8] tasks=19(nPassBack=0) last_loss=3.23534(0.0531428) N=(772,38304,37744 4435068)
[epoch_0]_33601  loss=3.285064 |g|=0.422	lr=2.60e-04 | 52.6%@S28  T=12.07s(data=1.8ms QKV=2.11s FFN=3.04s) eta=3d 20:00:46 | 41.8K token/s | 
[epoch_0]_33611  loss=3.204003 |g|=0.443	lr=2.60e-04 | 53.4%@S28  T=1.72s(data=1.8ms QKV=2.11s FFN=3.04s) eta=13:03:56 | 42.1K token/s | 
[epoch_0]_33621  loss=3.111962 |g|=0.413	lr=2.60e-04 | 54.2%@S28  T=1.80s(data=1.7ms QKV=2.11s FFN=3.04s) eta=13:41:21 | 42.3K token/s | 
[epoch_0]_33631  loss=3.196673 |g|=0.438	lr=2.60e-04 | 55.1%@S28  T=1.90s(data=1.5ms QKV=2.11s FFN=3.04s) eta=14:25:54 | 42.3K token/s | 
[epoch_0]_33641  loss=3.282911 |g|=0.457	lr=2.60e-04 | 55.9%@S28  T=1.81s(data=1.6ms QKV=2.11s FFN=3.04s) eta=13:48:12 | 42.5K token/s | 
[epoch_0]_33651  loss=3.180955 |g|=0.429	lr=2.59e-04 | 56.7%@S28  T=1.81s(data=1.6ms QKV=2.11s FFN=3.04s) eta=13:44:46 | 42.6K token/s | 
[epoch_0]_33661  loss=3.152307 |g|=0.404	lr=2.59e-04 | 57.5%@S28  T=1.80s(data=1.6ms QKV=2.11s FFN=3.04s) eta=13:39:55 | 42.7K token/s | 
[epoch_0]_33671  loss=3.211749 |g|=0.418	lr=2.59e-04 | 58.3%@S28  T=1.79s(data=1.6ms QKV=2.11s FFN=3.04s) eta=13:35:27 | 42.9K token/s | 
[epoch_0]_33681  loss=3.199602 |g|=0.442	lr=2.59e-04 | 59.2%@S28  T=1.74s(data=1.7ms QKV=2.11s FFN=3.04s) eta=13:12:35 | 43.1K token/s | 
[epoch_0]_33691  loss=3.210928 |g|=0.435	lr=2.59e-04 | 60.0%@S28  T=1.78s(data=1.5ms QKV=2.11s FFN=3.04s) eta=13:33:03 | 43.3K token/s | 
[Fuyou] head="0" update algorithm=4 t=11.86s
[Section@33700] layer[8-16] tasks=19(nPassBack=0) last_loss=3.139(0.0502093) N=(772,38416,37856 4448268)
[epoch_0]_33701  loss=3.232515 |g|=0.405	lr=2.59e-04 | 60.8%@S28  T=4.68s(data=1.8ms QKV=2.11s FFN=3.03s) eta=1d 11:33:27 | 42.0K token/s | 
[epoch_0]_33711  loss=3.193706 |g|=0.409	lr=2.58e-04 | 61.6%@S28  T=1.72s(data=1.9ms QKV=2.11s FFN=3.04s) eta=13:01:10 | 42.3K token/s | 
[epoch_0]_33721  loss=3.234706 |g|=0.42	lr=2.58e-04 | 62.4%@S28  T=1.84s(data=1.5ms QKV=2.11s FFN=3.04s) eta=13:56:28 | 42.4K token/s | 
[epoch_0]_33731  loss=3.168120 |g|=0.419	lr=2.58e-04 | 63.3%@S28  T=1.81s(data=1.6ms QKV=2.11s FFN=3.04s) eta=13:42:28 | 42.5K token/s | 
[epoch_0]_33741  loss=3.156028 |g|=0.411	lr=2.58e-04 | 64.1%@S28  T=1.76s(data=1.5ms QKV=2.11s FFN=3.04s) eta=13:19:13 | 42.7K token/s | 
[epoch_0]_33751  loss=3.188486 |g|=0.428	lr=2.58e-04 | 64.9%@S28  T=1.76s(data=1.6ms QKV=2.11s FFN=3.04s) eta=13:20:48 | 42.9K token/s | 
[epoch_0]_33761  loss=3.183903 |g|=0.439	lr=2.58e-04 | 65.7%@S28  T=1.76s(data=1.6ms QKV=2.11s FFN=3.04s) eta=13:21:03 | 43.1K token/s | 
[epoch_0]_33771  loss=3.150134 |g|=0.396	lr=2.58e-04 | 66.5%@S28  T=1.76s(data=1.6ms QKV=2.11s FFN=3.04s) eta=13:18:26 | 43.3K token/s | 
[epoch_0]_33781  loss=3.141369 |g|=0.406	lr=2.57e-04 | 67.3%@S28  T=1.75s(data=1.7ms QKV=2.11s FFN=3.04s) eta=13:13:03 | 43.4K token/s | 
[epoch_0]_33791  loss=3.217583 |g|=0.441	lr=2.57e-04 | 68.2%@S28  T=1.73s(data=1.7ms QKV=2.11s FFN=3.04s) eta=13:05:46 | 43.6K token/s | 
[Fuyou] head="1" update algorithm=4 t=11.35s
[eval] 
	 Loss@"edu_fineweb1B"=3.208(0.00071) nBranch=1 nToken=6.31M best=3.2086(167) E2T=0.0583 T=36.7778(0)s x=0
	#3.20785±0.0968 tps=172K(6.30784M) a=[3.01392,3.48273] T=36.7778(sec)
[Section@33800] layer[16-24] tasks=19(nPassBack=0) last_loss=3.14952(0.061125) N=(772,38528,37968 4461468)
[epoch_0]_33801  loss=3.314460 |g|=0.443	lr=2.57e-04 | 69.0%@S28  T=12.29s(data=2.1ms QKV=2.10s FFN=3.04s) eta=3d 20:58:50 | 41.8K token/s | 
[epoch_0]_33811  loss=3.285828 |g|=0.424	lr=2.57e-04 | 69.8%@S28  T=1.76s(data=1.7ms QKV=2.11s FFN=3.04s) eta=13:18:07 | 42.0K token/s | 
[epoch_0]_33821  loss=3.141485 |g|=0.422	lr=2.57e-04 | 70.6%@S28  T=1.72s(data=1.9ms QKV=2.11s FFN=3.04s) eta=12:59:43 | 42.3K token/s | 
[epoch_0]_33831  loss=3.197053 |g|=0.421	lr=2.57e-04 | 71.4%@S28  T=1.72s(data=1.7ms QKV=2.11s FFN=3.04s) eta=13:01:12 | 42.6K token/s | 
[epoch_0]_33841  loss=3.166014 |g|=0.416	lr=2.57e-04 | 72.3%@S28  T=1.72s(data=1.8ms QKV=2.11s FFN=3.04s) eta=13:00:10 | 42.8K token/s | 
[epoch_0]_33851  loss=3.163131 |g|=0.453	lr=2.56e-04 | 73.1%@S28  T=1.76s(data=1.5ms QKV=2.11s FFN=3.04s) eta=13:17:04 | 43.0K token/s | 
[epoch_0]_33861  loss=3.091854 |g|=0.408	lr=2.56e-04 | 73.9%@S28  T=1.72s(data=1.8ms QKV=2.11s FFN=3.04s) eta=12:58:09 | 43.2K token/s | 
[epoch_0]_33871  loss=3.196975 |g|=0.398	lr=2.56e-04 | 74.7%@S28  T=1.83s(data=1.5ms QKV=2.11s FFN=3.04s) eta=13:47:11 | 43.3K token/s | 
[epoch_0]_33881  loss=3.157259 |g|=0.427	lr=2.56e-04 | 75.5%@S28  T=1.75s(data=1.5ms QKV=2.11s FFN=3.04s) eta=13:14:12 | 43.5K token/s | 
[epoch_0]_33891  loss=3.147478 |g|=0.444	lr=2.56e-04 | 76.4%@S28  T=1.76s(data=1.8ms QKV=2.11s FFN=3.04s) eta=13:15:21 | 43.6K token/s | 
[Fuyou] head="2" update algorithm=4 t=10.78s
[Section@33900] layer[24-32] tasks=19(nPassBack=0) last_loss=3.18302(-0.00192618) N=(772,38640,38080 4474668)
[epoch_0]_33901  loss=3.233479 |g|=0.413	lr=2.56e-04 | 77.2%@S28  T=4.06s(data=2.0ms QKV=2.12s FFN=3.03s) eta=1d 06:34:24 | 42.5K token/s | 
[epoch_0]_33911  loss=3.200190 |g|=0.429	lr=2.55e-04 | 78.0%@S28  T=1.87s(data=2.0ms QKV=2.12s FFN=3.04s) eta=14:06:38 | 42.5K token/s | 
[epoch_0]_33921  loss=3.158672 |g|=0.449	lr=2.55e-04 | 78.8%@S28  T=1.74s(data=2.2ms QKV=2.12s FFN=3.04s) eta=13:07:03 | 42.8K token/s | 
[epoch_0]_33931  loss=3.088175 |g|=0.416	lr=2.55e-04 | 79.6%@S28  T=1.82s(data=1.6ms QKV=2.12s FFN=3.04s) eta=13:41:19 | 42.9K token/s | 
[epoch_0]_33941  loss=3.174314 |g|=0.424	lr=2.55e-04 | 80.5%@S28  T=1.81s(data=1.7ms QKV=2.12s FFN=3.04s) eta=13:36:41 | 43.0K token/s | 
[epoch_0]_33951  loss=3.201755 |g|=0.425	lr=2.55e-04 | 81.3%@S28  T=1.81s(data=1.7ms QKV=2.12s FFN=3.04s) eta=13:36:33 | 43.1K token/s | 
[epoch_0]_33961  loss=3.189075 |g|=0.445	lr=2.55e-04 | 82.1%@S28  T=1.81s(data=1.6ms QKV=2.12s FFN=3.04s) eta=13:38:17 | 43.2K token/s | 
[epoch_0]_33971  loss=3.135303 |g|=0.415	lr=2.55e-04 | 82.9%@S28  T=1.81s(data=1.6ms QKV=2.12s FFN=3.04s) eta=13:37:00 | 43.3K token/s | 
[epoch_0]_33981  loss=3.140477 |g|=0.425	lr=2.54e-04 | 83.7%@S28  T=1.81s(data=1.6ms QKV=2.13s FFN=3.04s) eta=13:36:08 | 43.4K token/s | 
[epoch_0]_33991  loss=3.147488 |g|=0.415	lr=2.54e-04 | 84.6%@S28  T=1.80s(data=1.8ms QKV=2.12s FFN=3.04s) eta=13:33:12 | 43.5K token/s | 
[Fuyou] head="3" update algorithm=4 t=10.73s
[eval] 
	 Loss@"edu_fineweb1B"=3.205(0.0026) nBranch=1 nToken=6.31M best=3.2078(168) E2T=-0.00945 T=36.751(0)s x=0
	#3.20527±0.0973 tps=172K(6.30784M) a=[3.01057,3.48153] T=36.751(sec)
[Section@34000] layer[32-40] tasks=19(nPassBack=0) last_loss=3.21471(-0.0369911) N=(772,38752,38192 4487868)
[epoch_0]_34001  loss=3.163120 |g|=0.396	lr=2.54e-04 | 85.4%@S28  T=11.98s(data=2.0ms QKV=2.12s FFN=3.04s) eta=3d 17:58:11 | 41.7K token/s | 
[epoch_0]_34011  loss=3.210328 |g|=0.437	lr=2.54e-04 | 86.2%@S28  T=1.73s(data=1.9ms QKV=2.12s FFN=3.04s) eta=13:00:31 | 42.0K token/s | 
[epoch_0]_34021  loss=3.159548 |g|=0.442	lr=2.54e-04 | 87.0%@S28  T=1.74s(data=1.8ms QKV=2.12s FFN=3.04s) eta=13:03:06 | 42.2K token/s | 
[epoch_0]_34031  loss=3.162417 |g|=0.447	lr=2.54e-04 | 87.8%@S28  T=1.87s(data=1.7ms QKV=2.12s FFN=3.04s) eta=14:00:06 | 42.3K token/s | 
[epoch_0]_34041  loss=3.204483 |g|=0.418	lr=2.53e-04 | 88.6%@S28  T=1.95s(data=1.8ms QKV=2.12s FFN=3.04s) eta=14:39:04 | 42.3K token/s | 
[epoch_0]_34051  loss=3.145370 |g|=0.459	lr=2.53e-04 | 89.5%@S28  T=1.73s(data=2.0ms QKV=2.12s FFN=3.04s) eta=12:56:40 | 42.5K token/s | 
[epoch_0]_34061  loss=3.159912 |g|=0.455	lr=2.53e-04 | 90.3%@S28  T=1.89s(data=1.7ms QKV=2.12s FFN=3.04s) eta=14:08:03 | 42.6K token/s | 
[epoch_0]_34071  loss=3.121542 |g|=0.416	lr=2.53e-04 | 91.1%@S28  T=1.83s(data=1.6ms QKV=2.12s FFN=3.04s) eta=13:43:32 | 42.7K token/s | 
[epoch_0]_34081  loss=3.121826 |g|=0.413	lr=2.53e-04 | 91.9%@S28  T=1.74s(data=1.8ms QKV=2.12s FFN=3.04s) eta=13:03:05 | 42.9K token/s | 
[epoch_0]_34091  loss=3.202624 |g|=0.409	lr=2.53e-04 | 92.7%@S28  T=1.73s(data=1.8ms QKV=2.12s FFN=3.04s) eta=12:58:49 | 43.1K token/s | 
[Fuyou] head="4" update algorithm=4 t=12.42s
[Section@34100] layer[40-48] tasks=19(nPassBack=0) last_loss=3.17505(-0.038846) N=(772,38864,38304 4501068)
[epoch_0]_34101  loss=3.185901 |g|=0.413	lr=2.53e-04 | 93.6%@S28  T=4.32s(data=1.8ms QKV=2.12s FFN=3.03s) eta=1d 08:18:54 | 41.9K token/s | 
[epoch_0]_34111  loss=3.178760 |g|=0.418	lr=2.52e-04 | 94.4%@S28  T=1.92s(data=1.7ms QKV=2.12s FFN=3.04s) eta=14:22:45 | 41.9K token/s | 
[epoch_0]_34121  loss=3.168433 |g|=0.426	lr=2.52e-04 | 95.2%@S28  T=1.75s(data=1.6ms QKV=2.12s FFN=3.04s) eta=13:02:46 | 42.2K token/s | 
[epoch_0]_34131  loss=3.201346 |g|=0.422	lr=2.52e-04 | 96.0%@S28  T=1.74s(data=1.7ms QKV=2.12s FFN=3.04s) eta=12:59:44 | 42.4K token/s | 
[epoch_0]_34141  loss=3.135075 |g|=0.406	lr=2.52e-04 | 96.8%@S28  T=1.75s(data=1.8ms QKV=2.12s FFN=3.04s) eta=13:02:24 | 42.7K token/s | 
[epoch_0]_34151  loss=3.247188 |g|=0.442	lr=2.52e-04 | 97.7%@S28  T=1.76s(data=2.0ms QKV=2.12s FFN=3.04s) eta=13:07:04 | 42.9K token/s | 
[epoch_0]_34161  loss=3.112574 |g|=0.43	lr=2.52e-04 | 98.5%@S28  T=1.89s(data=1.9ms QKV=2.12s FFN=3.04s) eta=14:06:18 | 42.9K token/s | 
[epoch_0]_34171  loss=3.228492 |g|=0.421	lr=2.51e-04 | 99.3%@S28  T=1.76s(data=1.7ms QKV=2.12s FFN=3.04s) eta=13:08:48 | 43.1K token/s | 
[epoch_0]_34179  loss=3.141708 |g|=0.407	lr=2.51e-04 | 100.0%@S28  T=1.84s(data=1.8ms QKV=2.13s FFN=3.04s) eta=13:41:24 | 43.1K token/s | 
-------- End of shard_28@"./Datasets/edu_fineweb1B/edu_fineweb_train_000482.bin"-------- 
[shard-29]@"./Datasets/edu_fineweb1B/edu_fineweb_train_000483.bin": tokens=100(M) nShardSamples=1220(2832024) 
[epoch_0]_34181  loss=3.286234 |g|=0.469	lr=2.51e-04 | 0.1%@S29  T=2.13s(data=1.5ms QKV=2.12s FFN=3.04s) eta=15:53:15 | 42.9K token/s | 
[epoch_0]_34191  loss=3.206388 |g|=0.426	lr=2.51e-04 | 0.9%@S29  T=1.87s(data=1.4ms QKV=2.12s FFN=3.04s) eta=13:55:09 | 43.0K token/s | 
[Fuyou] head="5" update algorithm=4 t=10.82s
[eval] 
	 Loss@"edu_fineweb1B"=3.204(0.0015) nBranch=1 nToken=6.31M best=3.2053(169) E2T=-0.0107 T=36.7442(0)s x=0
	#3.20377±0.0970 tps=172K(6.30784M) a=[3.01158,3.47551] T=36.7442(sec)
[Section@34200] layer[0-8] tasks=19(nPassBack=0) last_loss=3.2145(0.0208447) N=(772,38976,38416 4514268)
[epoch_0]_34201  loss=3.205157 |g|=0.403	lr=2.51e-04 | 1.8%@S29  T=12.33s(data=2.0ms QKV=2.12s FFN=3.04s) eta=3d 19:53:56 | 41.1K token/s | 
[epoch_0]_34211  loss=3.216495 |g|=0.456	lr=2.51e-04 | 2.6%@S29  T=1.74s(data=1.8ms QKV=2.12s FFN=3.04s) eta=12:58:35 | 41.4K token/s | 
[epoch_0]_34221  loss=3.218818 |g|=0.427	lr=2.51e-04 | 3.4%@S29  T=1.71s(data=1.5ms QKV=2.12s FFN=3.04s) eta=12:44:33 | 41.8K token/s | 
[epoch_0]_34231  loss=3.228548 |g|=0.435	lr=2.51e-04 | 4.2%@S29  T=1.73s(data=1.7ms QKV=2.12s FFN=3.04s) eta=12:52:16 | 42.0K token/s | 
[epoch_0]_34241  loss=3.124629 |g|=0.397	lr=2.50e-04 | 5.0%@S29  T=1.82s(data=1.9ms QKV=2.12s FFN=3.04s) eta=13:32:48 | 42.2K token/s | 
[epoch_0]_34251  loss=3.222621 |g|=0.42	lr=2.50e-04 | 5.9%@S29  T=1.72s(data=1.6ms QKV=2.12s FFN=3.04s) eta=12:48:22 | 42.5K token/s | 
[epoch_0]_34261  loss=3.125913 |g|=0.421	lr=2.50e-04 | 6.7%@S29  T=1.76s(data=2.1ms QKV=2.12s FFN=3.04s) eta=13:05:19 | 42.7K token/s | 
[epoch_0]_34271  loss=3.243837 |g|=0.436	lr=2.50e-04 | 7.5%@S29  T=1.77s(data=1.7ms QKV=2.12s FFN=3.04s) eta=13:08:12 | 42.9K token/s | 
[epoch_0]_34281  loss=3.175327 |g|=0.438	lr=2.50e-04 | 8.3%@S29  T=1.72s(data=1.6ms QKV=2.12s FFN=3.04s) eta=12:46:17 | 43.1K token/s | 
[epoch_0]_34291  loss=3.240143 |g|=0.429	lr=2.50e-04 | 9.1%@S29  T=1.87s(data=1.6ms QKV=2.12s FFN=3.04s) eta=13:51:37 | 43.1K token/s | 
[Fuyou] head="0" update algorithm=4 t=11.24s
[Section@34300] layer[8-16] tasks=19(nPassBack=0) last_loss=3.16558(-0.0265729) N=(772,39088,38528 4527468)
[epoch_0]_34301  loss=3.320767 |g|=0.407	lr=2.50e-04 | 9.9%@S29  T=4.13s(data=1.7ms QKV=2.12s FFN=3.03s) eta=1d 06:39:48 | 42.0K token/s | 
[epoch_0]_34311  loss=3.205063 |g|=0.441	lr=2.49e-04 | 10.8%@S29  T=1.76s(data=1.3ms QKV=2.12s FFN=3.04s) eta=13:05:15 | 42.2K token/s | 
[epoch_0]_34321  loss=3.137355 |g|=0.413	lr=2.49e-04 | 11.6%@S29  T=1.73s(data=1.9ms QKV=2.12s FFN=3.04s) eta=12:49:10 | 42.5K token/s | 
[epoch_0]_34331  loss=3.178886 |g|=0.434	lr=2.49e-04 | 12.4%@S29  T=1.73s(data=1.7ms QKV=2.12s FFN=3.04s) eta=12:47:49 | 42.7K token/s | 
[epoch_0]_34341  loss=3.165036 |g|=0.439	lr=2.49e-04 | 13.2%@S29  T=1.80s(data=1.9ms QKV=2.12s FFN=3.04s) eta=13:21:55 | 42.8K token/s | 
[epoch_0]_34351  loss=3.238301 |g|=0.435	lr=2.49e-04 | 14.0%@S29  T=1.88s(data=2.0ms QKV=2.12s FFN=3.04s) eta=13:55:26 | 42.9K token/s | 
[epoch_0]_34361  loss=3.157169 |g|=0.442	lr=2.49e-04 | 14.9%@S29  T=1.77s(data=1.7ms QKV=2.13s FFN=3.04s) eta=13:07:03 | 43.1K token/s | 
[epoch_0]_34371  loss=3.168116 |g|=0.449	lr=2.48e-04 | 15.7%@S29  T=1.74s(data=1.9ms QKV=2.12s FFN=3.04s) eta=12:55:12 | 43.2K token/s | 
[epoch_0]_34381  loss=3.153563 |g|=0.42	lr=2.48e-04 | 16.5%@S29  T=1.81s(data=1.8ms QKV=2.12s FFN=3.04s) eta=13:21:57 | 43.4K token/s | 
[epoch_0]_34391  loss=3.301743 |g|=0.432	lr=2.48e-04 | 17.3%@S29  T=1.72s(data=1.9ms QKV=2.12s FFN=3.04s) eta=12:45:35 | 43.6K token/s | 
[Fuyou] head="1" update algorithm=4 t=11.50s
[eval] 
	 Loss@"edu_fineweb1B"=3.198(0.006) nBranch=1 nToken=6.31M best=3.2038(170) E2T=-0.0513 T=36.7594(0)s x=0
	#3.19775±0.0973 tps=172K(6.30784M) a=[3.00279,3.4705] T=36.7594(sec)
[Section@34400] layer[16-24] tasks=19(nPassBack=0) last_loss=3.24907(-0.0995498) N=(772,39200,38640 4540668)
[epoch_0]_34401  loss=3.225413 |g|=0.414	lr=2.48e-04 | 18.1%@S29  T=12.28s(data=1.8ms QKV=2.11s FFN=3.04s) eta=3d 18:51:35 | 41.7K token/s | 
[epoch_0]_34411  loss=3.188570 |g|=0.442	lr=2.48e-04 | 19.0%@S29  T=1.73s(data=1.8ms QKV=2.11s FFN=3.04s) eta=12:49:10 | 42.0K token/s | 
[epoch_0]_34421  loss=3.208259 |g|=0.425	lr=2.48e-04 | 19.8%@S29  T=1.76s(data=1.6ms QKV=2.11s FFN=3.04s) eta=13:00:37 | 42.2K token/s | 
[epoch_0]_34431  loss=3.196763 |g|=0.422	lr=2.48e-04 | 20.6%@S29  T=1.73s(data=1.7ms QKV=2.11s FFN=3.04s) eta=12:48:32 | 42.5K token/s | 
[epoch_0]_34441  loss=3.143573 |g|=0.418	lr=2.47e-04 | 21.4%@S29  T=1.85s(data=1.6ms QKV=2.11s FFN=3.04s) eta=13:40:35 | 42.6K token/s | 
[epoch_0]_34451  loss=3.154144 |g|=0.436	lr=2.47e-04 | 22.2%@S29  T=1.72s(data=1.5ms QKV=2.11s FFN=3.04s) eta=12:43:23 | 42.8K token/s | 
[epoch_0]_34461  loss=3.193352 |g|=0.414	lr=2.47e-04 | 23.1%@S29  T=1.73s(data=1.7ms QKV=2.11s FFN=3.04s) eta=12:47:52 | 43.0K token/s | 
[epoch_0]_34471  loss=3.255413 |g|=0.424	lr=2.47e-04 | 23.9%@S29  T=1.91s(data=1.6ms QKV=2.11s FFN=3.04s) eta=14:04:57 | 43.0K token/s | 
[epoch_0]_34481  loss=3.166587 |g|=0.433	lr=2.47e-04 | 24.7%@S29  T=1.82s(data=1.6ms QKV=2.11s FFN=3.04s) eta=13:24:58 | 43.1K token/s | 
[epoch_0]_34491  loss=3.186371 |g|=0.447	lr=2.47e-04 | 25.5%@S29  T=1.76s(data=1.7ms QKV=2.11s FFN=3.04s) eta=13:00:47 | 43.3K token/s | 
[Fuyou] head="2" update algorithm=4 t=11.41s
[Section@34500] layer[24-32] tasks=19(nPassBack=0) last_loss=3.1694(0.013618) N=(772,39312,38752 4553868)
[epoch_0]_34501  loss=3.205650 |g|=0.418	lr=2.46e-04 | 26.3%@S29  T=4.11s(data=1.8ms QKV=2.11s FFN=3.03s) eta=1d 06:18:36 | 42.1K token/s | 
[epoch_0]_34511  loss=3.208285 |g|=0.444	lr=2.46e-04 | 27.1%@S29  T=1.83s(data=2.0ms QKV=2.11s FFN=3.04s) eta=13:30:54 | 42.3K token/s | 
[epoch_0]_34521  loss=3.150503 |g|=0.428	lr=2.46e-04 | 28.0%@S29  T=1.74s(data=1.7ms QKV=2.11s FFN=3.04s) eta=12:50:43 | 42.5K token/s | 
[epoch_0]_34531  loss=3.193652 |g|=0.401	lr=2.46e-04 | 28.8%@S29  T=1.75s(data=1.8ms QKV=2.11s FFN=3.04s) eta=12:52:39 | 42.7K token/s | 
[epoch_0]_34541  loss=3.224298 |g|=0.432	lr=2.46e-04 | 29.6%@S29  T=1.88s(data=1.6ms QKV=2.11s FFN=3.04s) eta=13:50:41 | 42.7K token/s | 
[epoch_0]_34551  loss=3.205461 |g|=0.402	lr=2.46e-04 | 30.4%@S29  T=1.84s(data=1.8ms QKV=2.11s FFN=3.04s) eta=13:33:18 | 42.8K token/s | 
[epoch_0]_34561  loss=3.177317 |g|=0.443	lr=2.46e-04 | 31.2%@S29  T=1.86s(data=2.0ms QKV=2.11s FFN=3.04s) eta=13:42:14 | 42.9K token/s | 
[epoch_0]_34571  loss=3.218873 |g|=0.436	lr=2.45e-04 | 32.1%@S29  T=1.81s(data=1.8ms QKV=2.11s FFN=3.04s) eta=13:16:10 | 43.0K token/s | 
[epoch_0]_34581  loss=3.231439 |g|=0.421	lr=2.45e-04 | 32.9%@S29  T=1.74s(data=2.1ms QKV=2.11s FFN=3.04s) eta=12:47:30 | 43.2K token/s | 
[epoch_0]_34591  loss=3.137183 |g|=0.403	lr=2.45e-04 | 33.7%@S29  T=1.84s(data=1.7ms QKV=2.11s FFN=3.04s) eta=13:29:36 | 43.3K token/s | 
[Fuyou] head="3" update algorithm=4 t=11.35s
[eval] 
	 Loss@"edu_fineweb1B"=3.197(0.00075) nBranch=1 nToken=6.31M best=3.1978(171) E2T=-0.013 T=36.7606(0)s x=0
	#3.197±0.0976 tps=172K(6.30784M) a=[3.00361,3.47271] T=36.7606(sec)
[Section@34600] layer[32-40] tasks=19(nPassBack=0) last_loss=3.21005(0.00466847) N=(772,39424,38864 4567068)
[epoch_0]_34601  loss=3.249462 |g|=0.427	lr=2.45e-04 | 34.5%@S29  T=12.20s(data=1.8ms QKV=2.11s FFN=3.04s) eta=3d 17:33:11 | 41.5K token/s | 
[epoch_0]_34611  loss=3.137698 |g|=0.45	lr=2.45e-04 | 35.3%@S29  T=1.76s(data=1.8ms QKV=2.11s FFN=3.04s) eta=12:53:05 | 41.7K token/s | 
[epoch_0]_34621  loss=3.221286 |g|=0.438	lr=2.45e-04 | 36.2%@S29  T=1.73s(data=1.7ms QKV=2.11s FFN=3.04s) eta=12:43:36 | 42.0K token/s | 
[epoch_0]_34631  loss=3.177120 |g|=0.432	lr=2.45e-04 | 37.0%@S29  T=1.76s(data=1.9ms QKV=2.11s FFN=3.04s) eta=12:55:02 | 42.2K token/s | 
[epoch_0]_34641  loss=3.184197 |g|=0.408	lr=2.44e-04 | 37.8%@S29  T=1.75s(data=1.6ms QKV=2.11s FFN=3.04s) eta=12:51:17 | 42.4K token/s | 
[epoch_0]_34651  loss=3.159292 |g|=0.415	lr=2.44e-04 | 38.6%@S29  T=1.83s(data=1.6ms QKV=2.11s FFN=3.04s) eta=13:25:12 | 42.6K token/s | 
[epoch_0]_34661  loss=3.187696 |g|=0.424	lr=2.44e-04 | 39.4%@S29  T=1.82s(data=1.5ms QKV=2.11s FFN=3.04s) eta=13:21:11 | 42.7K token/s | 
[epoch_0]_34671  loss=3.159937 |g|=0.397	lr=2.44e-04 | 40.3%@S29  T=1.78s(data=1.6ms QKV=2.11s FFN=3.04s) eta=13:00:26 | 42.8K token/s | 
[epoch_0]_34681  loss=3.190534 |g|=0.418	lr=2.44e-04 | 41.1%@S29  T=1.84s(data=1.6ms QKV=2.11s FFN=3.04s) eta=13:26:34 | 42.9K token/s | 
[epoch_0]_34691  loss=3.202419 |g|=0.424	lr=2.44e-04 | 41.9%@S29  T=1.84s(data=1.6ms QKV=2.11s FFN=3.04s) eta=13:27:24 | 43.0K token/s | 
[Fuyou] head="4" update algorithm=4 t=12.88s
[Section@34700] layer[40-48] tasks=19(nPassBack=0) last_loss=3.19118(-0.0161324) N=(772,39536,38976 4580268)
[epoch_0]_34701  loss=3.247164 |g|=0.419	lr=2.43e-04 | 42.7%@S29  T=4.59s(data=2.1ms QKV=2.11s FFN=3.03s) eta=1d 09:32:27 | 41.8K token/s | 
[epoch_0]_34711  loss=3.225697 |g|=0.419	lr=2.43e-04 | 43.5%@S29  T=1.71s(data=1.9ms QKV=2.11s FFN=3.04s) eta=12:31:56 | 42.1K token/s | 
[epoch_0]_34721  loss=3.134114 |g|=0.442	lr=2.43e-04 | 44.4%@S29  T=1.73s(data=2.2ms QKV=2.12s FFN=3.04s) eta=12:40:35 | 42.3K token/s | 
[epoch_0]_34731  loss=3.230060 |g|=0.43	lr=2.43e-04 | 45.2%@S29  T=1.74s(data=1.8ms QKV=2.12s FFN=3.04s) eta=12:44:58 | 42.6K token/s | 
[epoch_0]_34741  loss=3.156862 |g|=0.418	lr=2.43e-04 | 46.0%@S29  T=1.85s(data=1.7ms QKV=2.12s FFN=3.04s) eta=13:31:39 | 42.6K token/s | 
[epoch_0]_34751  loss=3.179828 |g|=0.415	lr=2.43e-04 | 46.8%@S29  T=1.72s(data=1.8ms QKV=2.12s FFN=3.04s) eta=12:33:04 | 42.9K token/s | 
[epoch_0]_34761  loss=3.226932 |g|=0.409	lr=2.43e-04 | 47.6%@S29  T=1.85s(data=1.7ms QKV=2.12s FFN=3.04s) eta=13:29:40 | 43.0K token/s | 
[epoch_0]_34771  loss=3.185219 |g|=0.427	lr=2.42e-04 | 48.4%@S29  T=1.76s(data=2.1ms QKV=2.12s FFN=3.04s) eta=12:50:48 | 43.1K token/s | 
[epoch_0]_34781  loss=3.259054 |g|=0.415	lr=2.42e-04 | 49.3%@S29  T=1.76s(data=2.2ms QKV=2.12s FFN=3.04s) eta=12:49:41 | 43.3K token/s | 
[epoch_0]_34791  loss=3.223146 |g|=0.439	lr=2.42e-04 | 50.1%@S29  T=1.78s(data=1.6ms QKV=2.12s FFN=3.04s) eta=12:56:44 | 43.4K token/s | 
[Fuyou] head="5" update algorithm=4 t=12.21s
[eval] 
	 Loss@"edu_fineweb1B"=3.193(0.004) nBranch=1 nToken=6.31M best=3.1970(172) E2T=0.0804 T=36.7629(0)s x=0
	#3.19305±0.0970 tps=172K(6.30784M) a=[2.99776,3.466] T=36.7629(sec)
[Section@34800] layer[0-8] tasks=19(nPassBack=0) last_loss=3.11261(0.101884) N=(772,39648,39088 4593468)
[epoch_0]_34801  loss=3.182448 |g|=0.419	lr=2.42e-04 | 50.9%@S29  T=12.23s(data=1.9ms QKV=2.11s FFN=3.04s) eta=3d 17:06:12 | 41.6K token/s | 
[epoch_0]_34811  loss=3.201064 |g|=0.474	lr=2.42e-04 | 51.7%@S29  T=1.73s(data=2.2ms QKV=2.11s FFN=3.04s) eta=12:37:54 | 41.9K token/s | 
[epoch_0]_34821  loss=3.161446 |g|=0.451	lr=2.42e-04 | 52.5%@S29  T=1.76s(data=2.3ms QKV=2.12s FFN=3.04s) eta=12:50:17 | 42.1K token/s | 
[epoch_0]_34831  loss=3.130834 |g|=0.42	lr=2.41e-04 | 53.4%@S29  T=1.85s(data=1.6ms QKV=2.12s FFN=3.04s) eta=13:26:02 | 42.2K token/s | 
[epoch_0]_34841  loss=3.141242 |g|=0.415	lr=2.41e-04 | 54.2%@S29  T=1.88s(data=1.8ms QKV=2.11s FFN=3.04s) eta=13:39:52 | 42.3K token/s | 
[epoch_0]_34851  loss=3.118873 |g|=0.441	lr=2.41e-04 | 55.0%@S29  T=1.73s(data=3.1ms QKV=2.12s FFN=3.04s) eta=12:35:19 | 42.6K token/s | 
[epoch_0]_34861  loss=3.257575 |g|=0.424	lr=2.41e-04 | 55.8%@S29  T=1.83s(data=1.8ms QKV=2.12s FFN=3.04s) eta=13:18:56 | 42.7K token/s | 
[epoch_0]_34871  loss=3.224656 |g|=0.427	lr=2.41e-04 | 56.6%@S29  T=1.77s(data=2.1ms QKV=2.12s FFN=3.04s) eta=12:51:42 | 42.8K token/s | 
[epoch_0]_34881  loss=3.097863 |g|=0.422	lr=2.41e-04 | 57.5%@S29  T=1.73s(data=1.6ms QKV=2.12s FFN=3.04s) eta=12:33:24 | 43.1K token/s | 
[epoch_0]_34891  loss=3.188959 |g|=0.439	lr=2.41e-04 | 58.3%@S29  T=1.75s(data=1.8ms QKV=2.12s FFN=3.04s) eta=12:42:35 | 43.3K token/s | 
[Fuyou] head="0" update algorithm=4 t=10.36s
[Section@34900] layer[8-16] tasks=19(nPassBack=0) last_loss=3.17093(-0.0053556) N=(772,39760,39200 4606668)
[epoch_0]_34901  loss=3.263034 |g|=0.43	lr=2.40e-04 | 59.1%@S29  T=4.61s(data=2.4ms QKV=2.12s FFN=3.04s) eta=1d 09:26:41 | 42.0K token/s | 
[epoch_0]_34911  loss=3.113824 |g|=0.427	lr=2.40e-04 | 59.9%@S29  T=1.76s(data=1.9ms QKV=2.11s FFN=3.04s) eta=12:47:56 | 42.2K token/s | 
[epoch_0]_34921  loss=3.159291 |g|=0.428	lr=2.40e-04 | 60.7%@S29  T=1.75s(data=2.0ms QKV=2.12s FFN=3.04s) eta=12:40:29 | 42.4K token/s | 
[epoch_0]_34931  loss=3.155015 |g|=0.433	lr=2.40e-04 | 61.6%@S29  T=1.74s(data=1.9ms QKV=2.12s FFN=3.04s) eta=12:37:58 | 42.7K token/s | 
[epoch_0]_34941  loss=3.111315 |g|=0.424	lr=2.40e-04 | 62.4%@S29  T=1.73s(data=1.8ms QKV=2.12s FFN=3.04s) eta=12:32:39 | 42.9K token/s | 
[epoch_0]_34951  loss=3.187792 |g|=0.454	lr=2.40e-04 | 63.2%@S29  T=1.73s(data=1.8ms QKV=2.12s FFN=3.04s) eta=12:31:46 | 43.1K token/s | 
[epoch_0]_34961  loss=3.127378 |g|=0.413	lr=2.40e-04 | 64.0%@S29  T=1.76s(data=1.5ms QKV=2.12s FFN=3.04s) eta=12:43:47 | 43.3K token/s | 
[epoch_0]_34971  loss=3.163518 |g|=0.425	lr=2.39e-04 | 64.8%@S29  T=1.83s(data=1.7ms QKV=2.12s FFN=3.04s) eta=13:16:46 | 43.4K token/s | 
[epoch_0]_34981  loss=3.181868 |g|=0.419	lr=2.39e-04 | 65.7%@S29  T=1.75s(data=1.9ms QKV=2.12s FFN=3.04s) eta=12:39:55 | 43.5K token/s | 
[epoch_0]_34991  loss=3.141848 |g|=0.402	lr=2.39e-04 | 66.5%@S29  T=1.74s(data=2.0ms QKV=2.12s FFN=3.04s) eta=12:33:52 | 43.7K token/s | 
[Fuyou] head="1" update algorithm=4 t=9.28s
[eval] 
	 Loss@"edu_fineweb1B"=3.193(0.0005) nBranch=1 nToken=6.31M best=3.1931(173) E2T=0.0306 T=36.8078(0)s x=0
	#3.19255±0.0971 tps=171K(6.30784M) a=[2.99528,3.46554] T=36.8078(sec)
[Section@35000] layer[16-24] tasks=19(nPassBack=0) last_loss=3.162(0.0870695) N=(772,39872,39312 4619868)
[epoch_0]_35001  loss=3.117365 |g|=0.42	lr=2.39e-04 | 67.3%@S29  T=12.28s(data=2.2ms QKV=2.11s FFN=3.04s) eta=3d 16:48:39 | 41.9K token/s | 
[epoch_0]_35011  loss=3.179872 |g|=0.431	lr=2.39e-04 | 68.1%@S29  T=1.74s(data=2.3ms QKV=2.11s FFN=3.04s) eta=12:33:47 | 42.1K token/s | 
[epoch_0]_35021  loss=3.155035 |g|=0.432	lr=2.39e-04 | 68.9%@S29  T=1.88s(data=1.9ms QKV=2.12s FFN=3.04s) eta=13:36:31 | 42.2K token/s | 
[epoch_0]_35031  loss=3.254959 |g|=0.424	lr=2.38e-04 | 69.7%@S29  T=1.81s(data=2.2ms QKV=2.11s FFN=3.04s) eta=13:02:55 | 42.4K token/s | 
[epoch_0]_35041  loss=3.167362 |g|=0.435	lr=2.38e-04 | 70.6%@S29  T=1.85s(data=1.9ms QKV=2.12s FFN=3.04s) eta=13:23:10 | 42.5K token/s | 
[epoch_0]_35051  loss=3.174007 |g|=0.427	lr=2.38e-04 | 71.4%@S29  T=1.77s(data=1.6ms QKV=2.12s FFN=3.04s) eta=12:48:07 | 42.6K token/s | 
[epoch_0]_35061  loss=3.180309 |g|=0.422	lr=2.38e-04 | 72.2%@S29  T=1.77s(data=2.1ms QKV=2.11s FFN=3.04s) eta=12:46:39 | 42.8K token/s | 
[epoch_0]_35071  loss=3.233267 |g|=0.438	lr=2.38e-04 | 73.0%@S29  T=1.76s(data=1.5ms QKV=2.12s FFN=3.04s) eta=12:42:51 | 43.0K token/s | 
[epoch_0]_35081  loss=3.159439 |g|=0.43	lr=2.38e-04 | 73.8%@S29  T=1.79s(data=1.9ms QKV=2.11s FFN=3.04s) eta=12:55:01 | 43.1K token/s | 
[epoch_0]_35091  loss=3.210684 |g|=0.422	lr=2.38e-04 | 74.7%@S29  T=1.75s(data=1.7ms QKV=2.11s FFN=3.04s) eta=12:34:39 | 43.3K token/s | 
[Fuyou] head="2" update algorithm=4 t=10.62s
[Section@35100] layer[24-32] tasks=19(nPassBack=0) last_loss=3.16835(0.00104952) N=(772,39984,39424 4633068)
[epoch_0]_35101  loss=3.203702 |g|=0.41	lr=2.37e-04 | 75.5%@S29  T=4.83s(data=1.9ms QKV=2.11s FFN=3.03s) eta=1d 10:49:44 | 42.0K token/s | 
[epoch_0]_35111  loss=3.152248 |g|=0.42	lr=2.37e-04 | 76.3%@S29  T=1.73s(data=1.7ms QKV=2.11s FFN=3.04s) eta=12:25:52 | 42.3K token/s | 
[epoch_0]_35121  loss=3.169904 |g|=0.441	lr=2.37e-04 | 77.1%@S29  T=1.79s(data=1.8ms QKV=2.11s FFN=3.04s) eta=12:51:05 | 42.5K token/s | 
[epoch_0]_35131  loss=3.208454 |g|=0.423	lr=2.37e-04 | 77.9%@S29  T=1.91s(data=1.7ms QKV=2.12s FFN=3.04s) eta=13:43:17 | 42.5K token/s | 
[epoch_0]_35141  loss=3.147084 |g|=0.427	lr=2.37e-04 | 78.8%@S29  T=1.91s(data=1.7ms QKV=2.12s FFN=3.04s) eta=13:45:13 | 42.5K token/s | 
[epoch_0]_35151  loss=3.230566 |g|=0.422	lr=2.37e-04 | 79.6%@S29  T=1.91s(data=1.7ms QKV=2.12s FFN=3.04s) eta=13:43:10 | 42.5K token/s | 
[epoch_0]_35161  loss=3.172678 |g|=0.439	lr=2.37e-04 | 80.4%@S29  T=1.90s(data=1.6ms QKV=2.12s FFN=3.04s) eta=13:41:00 | 42.6K token/s | 
[epoch_0]_35171  loss=3.261738 |g|=0.469	lr=2.36e-04 | 81.2%@S29  T=1.80s(data=2.5ms QKV=2.12s FFN=3.04s) eta=12:54:27 | 42.7K token/s | 
[epoch_0]_35181  loss=3.191633 |g|=0.433	lr=2.36e-04 | 82.0%@S29  T=1.81s(data=2.7ms QKV=2.11s FFN=3.04s) eta=12:59:50 | 42.8K token/s | 
[epoch_0]_35191  loss=3.150491 |g|=0.425	lr=2.36e-04 | 82.9%@S29  T=1.79s(data=2.3ms QKV=2.11s FFN=3.04s) eta=12:51:08 | 43.0K token/s | 
[Fuyou] head="3" update algorithm=4 t=13.30s
[eval] 
	 Loss@"edu_fineweb1B"=3.191(0.0019) nBranch=1 nToken=6.31M best=3.1925(174) E2T=0.0411 T=36.7551(0)s x=0
	#3.19067±0.0976 tps=172K(6.30784M) a=[2.99498,3.46494] T=36.7551(sec)
[Section@35200] layer[32-40] tasks=19(nPassBack=0) last_loss=3.14953(0.0605109) N=(772,40096,39536 4646268)
[epoch_0]_35201  loss=3.164237 |g|=0.427	lr=2.36e-04 | 83.7%@S29  T=12.41s(data=2.5ms QKV=2.11s FFN=3.04s) eta=3d 17:05:19 | 41.2K token/s | 
[epoch_0]_35211  loss=3.263139 |g|=0.43	lr=2.36e-04 | 84.5%@S29  T=1.82s(data=1.6ms QKV=2.12s FFN=3.04s) eta=13:03:45 | 41.3K token/s | 
[epoch_0]_35221  loss=3.181206 |g|=0.432	lr=2.36e-04 | 85.3%@S29  T=1.74s(data=1.9ms QKV=2.11s FFN=3.04s) eta=12:28:56 | 41.6K token/s | 
[epoch_0]_35231  loss=3.213033 |g|=0.445	lr=2.35e-04 | 86.1%@S29  T=1.77s(data=1.6ms QKV=2.11s FFN=3.04s) eta=12:39:13 | 41.9K token/s | 
[epoch_0]_35241  loss=3.238136 |g|=0.45	lr=2.35e-04 | 87.0%@S29  T=1.76s(data=1.7ms QKV=2.11s FFN=3.04s) eta=12:34:29 | 42.1K token/s | 
[epoch_0]_35251  loss=3.165676 |g|=0.444	lr=2.35e-04 | 87.8%@S29  T=1.81s(data=1.5ms QKV=2.11s FFN=3.04s) eta=12:58:02 | 42.3K token/s | 
[epoch_0]_35261  loss=3.293900 |g|=0.45	lr=2.35e-04 | 88.6%@S29  T=1.85s(data=1.5ms QKV=2.11s FFN=3.04s) eta=13:14:04 | 42.4K token/s | 
[epoch_0]_35271  loss=3.189727 |g|=0.449	lr=2.35e-04 | 89.4%@S29  T=1.85s(data=1.8ms QKV=2.11s FFN=3.04s) eta=13:16:29 | 42.5K token/s | 
[epoch_0]_35281  loss=3.227453 |g|=0.424	lr=2.35e-04 | 90.2%@S29  T=1.73s(data=1.5ms QKV=2.11s FFN=3.04s) eta=12:21:59 | 42.7K token/s | 
[epoch_0]_35291  loss=3.233881 |g|=0.435	lr=2.35e-04 | 91.0%@S29  T=1.77s(data=1.6ms QKV=2.11s FFN=3.04s) eta=12:39:04 | 42.9K token/s | 
[Fuyou] head="4" update algorithm=4 t=12.67s
[Section@35300] layer[40-48] tasks=19(nPassBack=0) last_loss=3.22728(-0.0361021) N=(772,40208,39648 4659468)
[epoch_0]_35301  loss=3.207924 |g|=0.414	lr=2.34e-04 | 91.9%@S29  T=4.39s(data=1.7ms QKV=2.11s FFN=3.03s) eta=1d 07:24:09 | 41.7K token/s | 
[epoch_0]_35311  loss=3.158653 |g|=0.436	lr=2.34e-04 | 92.7%@S29  T=1.74s(data=1.9ms QKV=2.12s FFN=3.04s) eta=12:25:35 | 41.9K token/s | 
[epoch_0]_35321  loss=3.227237 |g|=0.422	lr=2.34e-04 | 93.5%@S29  T=1.79s(data=2.1ms QKV=2.12s FFN=3.04s) eta=12:45:04 | 42.1K token/s | 
[epoch_0]_35331  loss=3.196655 |g|=0.448	lr=2.34e-04 | 94.3%@S29  T=1.73s(data=2.0ms QKV=2.12s FFN=3.04s) eta=12:19:06 | 42.4K token/s | 
[epoch_0]_35341  loss=3.178904 |g|=0.46	lr=2.34e-04 | 95.1%@S29  T=1.99s(data=1.7ms QKV=2.12s FFN=3.04s) eta=14:11:20 | 42.4K token/s | 
[epoch_0]_35351  loss=3.167763 |g|=0.429	lr=2.34e-04 | 96.0%@S29  T=1.73s(data=1.8ms QKV=2.12s FFN=3.04s) eta=12:20:06 | 42.6K token/s | 
[epoch_0]_35361  loss=3.187784 |g|=0.451	lr=2.34e-04 | 96.8%@S29  T=1.86s(data=2.0ms QKV=2.12s FFN=3.04s) eta=13:17:16 | 42.7K token/s | 
[epoch_0]_35371  loss=3.121590 |g|=0.417	lr=2.33e-04 | 97.6%@S29  T=1.87s(data=1.7ms QKV=2.12s FFN=3.04s) eta=13:19:01 | 42.7K token/s | 
[epoch_0]_35381  loss=3.202085 |g|=0.408	lr=2.33e-04 | 98.4%@S29  T=1.83s(data=1.8ms QKV=2.12s FFN=3.04s) eta=13:03:15 | 42.8K token/s | 
[epoch_0]_35391  loss=3.224265 |g|=0.435	lr=2.33e-04 | 99.2%@S29  T=1.89s(data=1.7ms QKV=2.12s FFN=3.04s) eta=13:29:19 | 42.9K token/s | 
[Fuyou] head="5" update algorithm=4 t=12.51s
[eval] 
	 Loss@"edu_fineweb1B"=3.189(0.0017) nBranch=1 nToken=6.31M best=3.1907(175) E2T=-0.0206 T=36.7373(0)s x=0
	#3.18894±0.0982 tps=172K(6.30784M) a=[2.99085,3.46737] T=36.7373(sec)
[Section@35400] layer[0-8] tasks=19(nPassBack=0) last_loss=3.20953(-0.0969164) N=(772,40320,39760 4672668)
[epoch_0]_35400  loss=3.213343 |g|=0.44	lr=2.33e-04 | 100.0%@S29  T=36.95s(data=2.5ms QKV=2.11s FFN=3.03s) eta=10d 23:05:32 | 40.8K token/s | 
-------- End of shard_29@"./Datasets/edu_fineweb1B/edu_fineweb_train_000483.bin"-------- 
[shard-30]@"./Datasets/edu_fineweb1B/edu_fineweb_train_000484.bin": tokens=100(M) nShardSamples=1220(2929680) 
[epoch_0]_35401  loss=3.237013 |g|=0.426	lr=2.33e-04 | 0.1%@S30  T=13.04s(data=1.03s QKV=2.11s FFN=3.04s) eta=3d 20:52:54 | 39.1K token/s | 
[epoch_0]_35411  loss=3.145028 |g|=0.45	lr=2.33e-04 | 0.9%@S30  T=1.84s(data=1.3ms QKV=2.12s FFN=3.04s) eta=13:05:18 | 39.4K token/s | 
[epoch_0]_35421  loss=3.150892 |g|=0.428	lr=2.33e-04 | 1.7%@S30  T=1.72s(data=1.5ms QKV=2.11s FFN=3.04s) eta=12:13:49 | 39.8K token/s | 
[epoch_0]_35431  loss=3.183272 |g|=0.426	lr=2.32e-04 | 2.5%@S30  T=1.73s(data=1.3ms QKV=2.11s FFN=3.04s) eta=12:18:44 | 40.2K token/s | 
[epoch_0]_35441  loss=3.255625 |g|=0.41	lr=2.32e-04 | 3.3%@S30  T=1.79s(data=1.2ms QKV=2.11s FFN=3.04s) eta=12:43:09 | 40.4K token/s | 
[epoch_0]_35451  loss=3.162161 |g|=0.446	lr=2.32e-04 | 4.2%@S30  T=1.76s(data=1.9ms QKV=2.11s FFN=3.04s) eta=12:30:13 | 40.7K token/s | 
[epoch_0]_35461  loss=3.077876 |g|=0.455	lr=2.32e-04 | 5.0%@S30  T=1.73s(data=1.3ms QKV=2.11s FFN=3.04s) eta=12:18:55 | 41.1K token/s | 
[epoch_0]_35471  loss=3.162163 |g|=0.435	lr=2.32e-04 | 5.8%@S30  T=1.78s(data=1.5ms QKV=2.12s FFN=3.04s) eta=12:37:13 | 41.3K token/s | 
[epoch_0]_35481  loss=3.151792 |g|=0.427	lr=2.32e-04 | 6.6%@S30  T=1.78s(data=3.3ms QKV=2.12s FFN=3.04s) eta=12:38:05 | 41.6K token/s | 
[epoch_0]_35491  loss=3.180830 |g|=0.415	lr=2.32e-04 | 7.4%@S30  T=1.75s(data=3.0ms QKV=2.11s FFN=3.04s) eta=12:24:13 | 41.8K token/s | 
[Fuyou] head="0" update algorithm=4 t=11.52s
[Section@35500] layer[8-16] tasks=19(nPassBack=0) last_loss=3.15116(0.0197749) N=(772,40432,39872 4685868)
[epoch_0]_35501  loss=3.193090 |g|=0.446	lr=2.31e-04 | 8.3%@S30  T=4.58s(data=1.5ms QKV=2.11s FFN=3.03s) eta=1d 08:27:20 | 40.6K token/s | 
[epoch_0]_35511  loss=3.163672 |g|=0.422	lr=2.31e-04 | 9.1%@S30  T=1.84s(data=1.5ms QKV=2.11s FFN=3.04s) eta=13:02:58 | 40.8K token/s | 
[epoch_0]_35521  loss=3.149800 |g|=0.433	lr=2.31e-04 | 9.9%@S30  T=1.90s(data=1.5ms QKV=2.12s FFN=3.04s) eta=13:27:33 | 40.9K token/s | 
[epoch_0]_35531  loss=3.191712 |g|=0.416	lr=2.31e-04 | 10.7%@S30  T=1.72s(data=1.4ms QKV=2.12s FFN=3.04s) eta=12:13:05 | 41.3K token/s | 
[epoch_0]_35541  loss=3.177441 |g|=0.421	lr=2.31e-04 | 11.5%@S30  T=1.83s(data=1.4ms QKV=2.11s FFN=3.04s) eta=12:57:25 | 41.4K token/s | 
[epoch_0]_35551  loss=3.237253 |g|=0.424	lr=2.31e-04 | 12.3%@S30  T=1.89s(data=1.9ms QKV=2.12s FFN=3.04s) eta=13:24:18 | 41.5K token/s | 
[epoch_0]_35561  loss=3.215041 |g|=0.419	lr=2.31e-04 | 13.2%@S30  T=1.87s(data=1.9ms QKV=2.12s FFN=3.04s) eta=13:12:10 | 41.6K token/s | 
[epoch_0]_35571  loss=3.258944 |g|=0.421	lr=2.30e-04 | 14.0%@S30  T=1.73s(data=1.6ms QKV=2.11s FFN=3.04s) eta=12:15:41 | 41.9K token/s | 
[epoch_0]_35581  loss=3.184127 |g|=0.436	lr=2.30e-04 | 14.8%@S30  T=1.73s(data=1.5ms QKV=2.12s FFN=3.04s) eta=12:13:09 | 42.2K token/s | 
[epoch_0]_35591  loss=3.207771 |g|=0.42	lr=2.30e-04 | 15.6%@S30  T=1.78s(data=1.9ms QKV=2.12s FFN=3.04s) eta=12:34:48 | 42.4K token/s | 
[Fuyou] head="1" update algorithm=4 t=10.78s
[eval] 
	 Loss@"edu_fineweb1B"=3.186(0.0031) nBranch=1 nToken=6.31M best=3.1889(176) E2T=0.0245 T=36.7434(0)s x=0
	#3.18587±0.0976 tps=172K(6.30784M) a=[2.99031,3.46255] T=36.7434(sec)
[Section@35600] layer[16-24] tasks=19(nPassBack=0) last_loss=3.16136(0.000633955) N=(772,40544,39984 4699068)
[epoch_0]_35601  loss=3.112566 |g|=0.44	lr=2.30e-04 | 16.4%@S30  T=12.11s(data=4.1ms QKV=2.11s FFN=3.04s) eta=3d 13:33:47 | 40.6K token/s | 
[epoch_0]_35611  loss=3.222959 |g|=0.451	lr=2.30e-04 | 17.3%@S30  T=1.72s(data=2.0ms QKV=2.11s FFN=3.04s) eta=12:10:42 | 41.0K token/s | 
[epoch_0]_35621  loss=3.185793 |g|=0.424	lr=2.30e-04 | 18.1%@S30  T=1.87s(data=2.5ms QKV=2.12s FFN=3.04s) eta=13:12:24 | 41.1K token/s | 
[epoch_0]_35631  loss=3.242856 |g|=0.427	lr=2.29e-04 | 18.9%@S30  T=1.74s(data=1.8ms QKV=2.11s FFN=3.04s) eta=12:14:58 | 41.4K token/s | 
[epoch_0]_35641  loss=3.173363 |g|=0.425	lr=2.29e-04 | 19.7%@S30  T=1.94s(data=1.7ms QKV=2.11s FFN=3.04s) eta=13:42:04 | 41.4K token/s | 
[epoch_0]_35651  loss=3.183454 |g|=0.445	lr=2.29e-04 | 20.5%@S30  T=1.74s(data=2.7ms QKV=2.11s FFN=3.04s) eta=12:16:48 | 41.7K token/s | 
[epoch_0]_35661  loss=3.194137 |g|=0.425	lr=2.29e-04 | 21.4%@S30  T=1.74s(data=1.9ms QKV=2.11s FFN=3.04s) eta=12:17:07 | 42.0K token/s | 
[epoch_0]_35671  loss=3.222253 |g|=0.431	lr=2.29e-04 | 22.2%@S30  T=1.80s(data=2.6ms QKV=2.11s FFN=3.04s) eta=12:41:19 | 42.2K token/s | 
[epoch_0]_35681  loss=3.142508 |g|=0.421	lr=2.29e-04 | 23.0%@S30  T=1.84s(data=1.9ms QKV=2.11s FFN=3.04s) eta=12:55:35 | 42.3K token/s | 
[epoch_0]_35691  loss=3.165478 |g|=0.435	lr=2.29e-04 | 23.8%@S30  T=1.91s(data=1.9ms QKV=2.12s FFN=3.04s) eta=13:25:32 | 42.3K token/s | 
[Fuyou] head="2" update algorithm=4 t=11.38s
[Section@35700] layer[24-32] tasks=19(nPassBack=0) last_loss=3.23223(-0.063884) N=(772,40656,40096 4712268)
[epoch_0]_35701  loss=3.153723 |g|=0.448	lr=2.28e-04 | 24.6%@S30  T=4.30s(data=1.7ms QKV=2.11s FFN=3.03s) eta=1d 06:16:40 | 41.2K token/s | 
[epoch_0]_35711  loss=3.181874 |g|=0.434	lr=2.28e-04 | 25.5%@S30  T=1.77s(data=2.3ms QKV=2.11s FFN=3.04s) eta=12:27:41 | 41.4K token/s | 
[epoch_0]_35721  loss=3.108402 |g|=0.42	lr=2.28e-04 | 26.3%@S30  T=1.73s(data=4.6ms QKV=2.12s FFN=3.04s) eta=12:11:31 | 41.7K token/s | 
[epoch_0]_35731  loss=3.188717 |g|=0.431	lr=2.28e-04 | 27.1%@S30  T=1.83s(data=1.7ms QKV=2.12s FFN=3.04s) eta=12:49:45 | 41.9K token/s | 
[epoch_0]_35741  loss=3.126208 |g|=0.421	lr=2.28e-04 | 27.9%@S30  T=1.79s(data=2.0ms QKV=2.12s FFN=3.04s) eta=12:35:52 | 42.1K token/s | 
[epoch_0]_35751  loss=3.231813 |g|=0.417	lr=2.28e-04 | 28.7%@S30  T=1.74s(data=2.7ms QKV=2.12s FFN=3.04s) eta=12:13:00 | 42.3K token/s | 
[epoch_0]_35761  loss=3.195389 |g|=0.441	lr=2.28e-04 | 29.5%@S30  T=1.76s(data=1.7ms QKV=2.12s FFN=3.04s) eta=12:22:20 | 42.5K token/s | 
[epoch_0]_35771  loss=3.213675 |g|=0.425	lr=2.27e-04 | 30.4%@S30  T=1.73s(data=2.4ms QKV=2.12s FFN=3.04s) eta=12:08:09 | 42.8K token/s | 
[epoch_0]_35781  loss=3.150187 |g|=0.431	lr=2.27e-04 | 31.2%@S30  T=1.72s(data=3.3ms QKV=2.12s FFN=3.04s) eta=12:04:33 | 43.0K token/s | 
[epoch_0]_35791  loss=3.278794 |g|=0.441	lr=2.27e-04 | 32.0%@S30  T=1.72s(data=2.0ms QKV=2.12s FFN=3.04s) eta=12:04:33 | 43.2K token/s | 
[Fuyou] head="3" update algorithm=4 t=11.84s
[eval] 
	 Loss@"edu_fineweb1B"=3.185(0.00084) nBranch=1 nToken=6.31M best=3.1859(177) E2T=-0.0259 T=36.7652(0)s x=0
	#3.18503±0.0969 tps=172K(6.30784M) a=[2.99755,3.46003] T=36.7652(sec)
[Section@35800] layer[32-40] tasks=19(nPassBack=0) last_loss=3.21089(-0.0613537) N=(772,40768,40208 4725468)
[epoch_0]_35801  loss=3.094539 |g|=0.461	lr=2.27e-04 | 32.8%@S30  T=12.23s(data=2.1ms QKV=2.11s FFN=3.04s) eta=3d 13:43:37 | 41.4K token/s | 
[epoch_0]_35811  loss=3.213558 |g|=0.431	lr=2.27e-04 | 33.6%@S30  T=1.72s(data=1.7ms QKV=2.11s FFN=3.04s) eta=12:03:10 | 41.7K token/s | 
[epoch_0]_35821  loss=3.121095 |g|=0.425	lr=2.27e-04 | 34.5%@S30  T=1.74s(data=2.0ms QKV=2.11s FFN=3.04s) eta=12:09:26 | 42.0K token/s | 
[epoch_0]_35831  loss=3.240301 |g|=0.474	lr=2.26e-04 | 35.3%@S30  T=1.87s(data=1.6ms QKV=2.11s FFN=3.04s) eta=13:06:58 | 42.1K token/s | 
[epoch_0]_35841  loss=3.158461 |g|=0.437	lr=2.26e-04 | 36.1%@S30  T=1.87s(data=1.9ms QKV=2.11s FFN=3.04s) eta=13:03:37 | 42.2K token/s | 
[epoch_0]_35851  loss=3.158355 |g|=0.421	lr=2.26e-04 | 36.9%@S30  T=1.84s(data=1.7ms QKV=2.11s FFN=3.04s) eta=12:51:05 | 42.3K token/s | 
[epoch_0]_35861  loss=3.200830 |g|=0.42	lr=2.26e-04 | 37.7%@S30  T=1.74s(data=1.7ms QKV=2.11s FFN=3.04s) eta=12:11:20 | 42.5K token/s | 
[epoch_0]_35871  loss=3.135920 |g|=0.438	lr=2.26e-04 | 38.6%@S30  T=1.86s(data=1.9ms QKV=2.11s FFN=3.04s) eta=13:01:58 | 42.6K token/s | 
[epoch_0]_35881  loss=3.219867 |g|=0.433	lr=2.26e-04 | 39.4%@S30  T=1.86s(data=1.6ms QKV=2.11s FFN=3.04s) eta=12:57:52 | 42.7K token/s | 
[epoch_0]_35891  loss=3.180676 |g|=0.431	lr=2.26e-04 | 40.2%@S30  T=1.77s(data=1.8ms QKV=2.11s FFN=3.04s) eta=12:23:22 | 42.8K token/s | 
[Fuyou] head="4" update algorithm=4 t=12.19s
[Section@35900] layer[40-48] tasks=19(nPassBack=0) last_loss=3.19847(0.0288069) N=(772,40880,40320 4738668)
[epoch_0]_35901  loss=3.144605 |g|=0.413	lr=2.25e-04 | 41.0%@S30  T=4.38s(data=2.9ms QKV=2.11s FFN=3.03s) eta=1d 06:34:19 | 41.6K token/s | 
[epoch_0]_35911  loss=3.202641 |g|=0.428	lr=2.25e-04 | 41.8%@S30  T=1.75s(data=1.9ms QKV=2.11s FFN=3.04s) eta=12:11:07 | 41.9K token/s | 
[epoch_0]_35921  loss=3.109144 |g|=0.467	lr=2.25e-04 | 42.7%@S30  T=1.72s(data=2.3ms QKV=2.11s FFN=3.04s) eta=11:59:14 | 42.2K token/s | 
[epoch_0]_35931  loss=3.164068 |g|=0.452	lr=2.25e-04 | 43.5%@S30  T=1.73s(data=2.1ms QKV=2.11s FFN=3.04s) eta=12:04:18 | 42.4K token/s | 
[epoch_0]_35941  loss=3.248918 |g|=0.428	lr=2.25e-04 | 44.3%@S30  T=1.72s(data=2.7ms QKV=2.11s FFN=3.04s) eta=12:00:18 | 42.7K token/s | 
[epoch_0]_35951  loss=3.170435 |g|=0.44	lr=2.25e-04 | 45.1%@S30  T=1.76s(data=2.6ms QKV=2.11s FFN=3.04s) eta=12:14:02 | 42.9K token/s | 
[epoch_0]_35961  loss=3.157100 |g|=0.417	lr=2.25e-04 | 45.9%@S30  T=1.73s(data=2.0ms QKV=2.11s FFN=3.04s) eta=12:04:04 | 43.1K token/s | 
[epoch_0]_35971  loss=3.218776 |g|=0.426	lr=2.24e-04 | 46.8%@S30  T=1.92s(data=1.5ms QKV=2.11s FFN=3.04s) eta=13:23:59 | 43.1K token/s | 
[epoch_0]_35981  loss=3.188235 |g|=0.45	lr=2.24e-04 | 47.6%@S30  T=1.73s(data=1.9ms QKV=2.11s FFN=3.04s) eta=12:04:11 | 43.3K token/s | 
[epoch_0]_35991  loss=3.122000 |g|=0.441	lr=2.24e-04 | 48.4%@S30  T=1.81s(data=1.7ms QKV=2.11s FFN=3.04s) eta=12:34:35 | 43.4K token/s | 
[Fuyou] head="5" update algorithm=4 t=12.11s
[eval] 
	 Loss@"edu_fineweb1B"=3.183(0.0019) nBranch=1 nToken=6.31M best=3.1850(178) E2T=-0.000601 T=36.7751(0)s x=0
	#3.18315±0.0978 tps=172K(6.30784M) a=[2.99247,3.46128] T=36.7751(sec)
[Section@36000] layer[0-8] tasks=19(nPassBack=0) last_loss=3.18376(0.0257754) N=(772,40992,40432 4751868)
[epoch_0]_36001  loss=3.123589 |g|=0.438	lr=2.24e-04 | 49.2%@S30  T=12.27s(data=2.1ms QKV=2.10s FFN=3.04s) eta=3d 13:18:36 | 41.6K token/s | 
[epoch_0]_36011  loss=3.120214 |g|=0.416	lr=2.24e-04 | 50.0%@S30  T=1.82s(data=1.8ms QKV=2.11s FFN=3.04s) eta=12:38:51 | 41.7K token/s | 
[epoch_0]_36021  loss=3.181661 |g|=0.445	lr=2.24e-04 | 50.8%@S30  T=1.81s(data=2.0ms QKV=2.11s FFN=3.04s) eta=12:36:38 | 41.9K token/s | 
[epoch_0]_36031  loss=3.169330 |g|=0.432	lr=2.23e-04 | 51.7%@S30  T=1.76s(data=1.9ms QKV=2.11s FFN=3.04s) eta=12:13:02 | 42.1K token/s | 
[epoch_0]_36041  loss=3.160995 |g|=0.437	lr=2.23e-04 | 52.5%@S30  T=1.83s(data=1.7ms QKV=2.12s FFN=3.04s) eta=12:41:57 | 42.3K token/s | 
[epoch_0]_36051  loss=3.204874 |g|=0.418	lr=2.23e-04 | 53.3%@S30  T=1.74s(data=2.0ms QKV=2.11s FFN=3.04s) eta=12:03:43 | 42.5K token/s | 
[epoch_0]_36061  loss=3.187900 |g|=0.43	lr=2.23e-04 | 54.1%@S30  T=1.87s(data=1.8ms QKV=2.11s FFN=3.04s) eta=12:56:35 | 42.6K token/s | 
[epoch_0]_36071  loss=3.170239 |g|=0.454	lr=2.23e-04 | 54.9%@S30  T=1.80s(data=2.0ms QKV=2.11s FFN=3.04s) eta=12:30:05 | 42.7K token/s | 
[epoch_0]_36081  loss=3.215737 |g|=0.427	lr=2.23e-04 | 55.8%@S30  T=1.74s(data=2.0ms QKV=2.11s FFN=3.04s) eta=12:04:00 | 42.9K token/s | 
[epoch_0]_36091  loss=3.130745 |g|=0.427	lr=2.23e-04 | 56.6%@S30  T=1.74s(data=1.9ms QKV=2.11s FFN=3.04s) eta=12:05:26 | 43.1K token/s | 
[Fuyou] head="0" update algorithm=4 t=13.22s
[Section@36100] layer[8-16] tasks=19(nPassBack=0) last_loss=3.08741(0.063745) N=(772,41104,40544 4765068)
[epoch_0]_36101  loss=3.226546 |g|=0.417	lr=2.22e-04 | 57.4%@S30  T=5.01s(data=2.7ms QKV=2.11s FFN=3.04s) eta=1d 10:43:27 | 41.8K token/s | 
[epoch_0]_36111  loss=3.205498 |g|=0.434	lr=2.22e-04 | 58.2%@S30  T=1.75s(data=2.7ms QKV=2.11s FFN=3.04s) eta=12:08:40 | 42.0K token/s | 
[epoch_0]_36121  loss=3.181368 |g|=0.428	lr=2.22e-04 | 59.0%@S30  T=1.90s(data=2.9ms QKV=2.11s FFN=3.04s) eta=13:09:55 | 42.1K token/s | 
[epoch_0]_36131  loss=3.136608 |g|=0.454	lr=2.22e-04 | 59.9%@S30  T=1.85s(data=2.9ms QKV=2.11s FFN=3.04s) eta=12:49:09 | 42.2K token/s | 
[epoch_0]_36141  loss=3.231596 |g|=0.444	lr=2.22e-04 | 60.7%@S30  T=1.79s(data=1.8ms QKV=2.12s FFN=3.04s) eta=12:21:30 | 42.4K token/s | 
[epoch_0]_36151  loss=3.229420 |g|=0.435	lr=2.22e-04 | 61.5%@S30  T=1.85s(data=2.6ms QKV=2.11s FFN=3.04s) eta=12:47:51 | 42.5K token/s | 
[epoch_0]_36161  loss=3.177336 |g|=0.468	lr=2.22e-04 | 62.3%@S30  T=1.75s(data=2.7ms QKV=2.11s FFN=3.04s) eta=12:04:13 | 42.7K token/s | 
[epoch_0]_36171  loss=3.103201 |g|=0.444	lr=2.21e-04 | 63.1%@S30  T=1.73s(data=2.9ms QKV=2.11s FFN=3.04s) eta=11:55:49 | 42.9K token/s | 
[epoch_0]_36181  loss=3.149472 |g|=0.432	lr=2.21e-04 | 64.0%@S30  T=1.87s(data=1.6ms QKV=2.12s FFN=3.04s) eta=12:54:50 | 43.0K token/s | 
[epoch_0]_36191  loss=3.143141 |g|=0.444	lr=2.21e-04 | 64.8%@S30  T=1.77s(data=2.7ms QKV=2.11s FFN=3.04s) eta=12:12:05 | 43.1K token/s | 
[Fuyou] head="1" update algorithm=4 t=13.81s
[eval] 
	 Loss@"edu_fineweb1B"=3.181(0.002) nBranch=1 nToken=6.31M best=3.1832(179) E2T=-0.0802 T=36.7992(0)s x=0
	#3.18116±0.0974 tps=171K(6.30784M) a=[2.98873,3.45664] T=36.7992(sec)
[Section@36200] layer[16-24] tasks=19(nPassBack=0) last_loss=3.2614(-0.100038) N=(772,41216,40656 4778268)
[epoch_0]_36201  loss=3.178873 |g|=0.436	lr=2.21e-04 | 65.6%@S30  T=13.17s(data=3.4ms QKV=2.11s FFN=3.04s) eta=3d 18:50:31 | 41.3K token/s | 
[epoch_0]_36211  loss=3.163572 |g|=0.438	lr=2.21e-04 | 66.4%@S30  T=1.73s(data=3.0ms QKV=2.11s FFN=3.04s) eta=11:53:47 | 41.6K token/s | 
[epoch_0]_36221  loss=3.190238 |g|=0.43	lr=2.21e-04 | 67.2%@S30  T=1.73s(data=2.7ms QKV=2.11s FFN=3.04s) eta=11:56:27 | 41.9K token/s | 
[epoch_0]_36231  loss=3.187251 |g|=0.431	lr=2.21e-04 | 68.1%@S30  T=1.72s(data=2.7ms QKV=2.11s FFN=3.04s) eta=11:52:35 | 42.2K token/s | 
[epoch_0]_36241  loss=3.129162 |g|=0.447	lr=2.20e-04 | 68.9%@S30  T=1.74s(data=2.5ms QKV=2.11s FFN=3.04s) eta=11:59:33 | 42.4K token/s | 
[epoch_0]_36251  loss=3.221579 |g|=0.452	lr=2.20e-04 | 69.7%@S30  T=1.75s(data=2.7ms QKV=2.11s FFN=3.04s) eta=12:04:32 | 42.6K token/s | 
[epoch_0]_36261  loss=3.217836 |g|=0.44	lr=2.20e-04 | 70.5%@S30  T=1.76s(data=1.8ms QKV=2.12s FFN=3.04s) eta=12:06:34 | 42.8K token/s | 
[epoch_0]_36271  loss=3.196099 |g|=0.441	lr=2.20e-04 | 71.3%@S30  T=1.74s(data=2.5ms QKV=2.11s FFN=3.04s) eta=11:57:37 | 43.0K token/s | 
[epoch_0]_36281  loss=3.175706 |g|=0.422	lr=2.20e-04 | 72.1%@S30  T=1.73s(data=2.6ms QKV=2.11s FFN=3.04s) eta=11:52:06 | 43.3K token/s | 
[epoch_0]_36291  loss=3.211916 |g|=0.438	lr=2.20e-04 | 73.0%@S30  T=1.74s(data=2.5ms QKV=2.11s FFN=3.04s) eta=11:57:01 | 43.5K token/s | 
[Fuyou] head="2" update algorithm=4 t=13.84s
[Section@36300] layer[24-32] tasks=19(nPassBack=0) last_loss=3.11719(0.115039) N=(772,41328,40768 4791468)
[epoch_0]_36301  loss=3.126953 |g|=0.455	lr=2.19e-04 | 73.8%@S30  T=5.11s(data=2.9ms QKV=2.11s FFN=3.04s) eta=1d 11:06:38 | 42.1K token/s | 
[epoch_0]_36311  loss=3.188096 |g|=0.448	lr=2.19e-04 | 74.6%@S30  T=1.90s(data=1.8ms QKV=2.11s FFN=3.04s) eta=13:03:38 | 42.1K token/s | 
[epoch_0]_36321  loss=3.150531 |g|=0.428	lr=2.19e-04 | 75.4%@S30  T=1.73s(data=3.0ms QKV=2.11s FFN=3.04s) eta=11:54:12 | 42.4K token/s | 
[epoch_0]_36331  loss=3.237852 |g|=0.457	lr=2.19e-04 | 76.2%@S30  T=1.81s(data=3.0ms QKV=2.11s FFN=3.04s) eta=12:27:14 | 42.5K token/s | 
[epoch_0]_36341  loss=3.110592 |g|=0.435	lr=2.19e-04 | 77.1%@S30  T=1.74s(data=2.7ms QKV=2.11s FFN=3.04s) eta=11:55:53 | 42.8K token/s | 
[epoch_0]_36351  loss=3.155721 |g|=0.429	lr=2.19e-04 | 77.9%@S30  T=1.74s(data=2.8ms QKV=2.11s FFN=3.04s) eta=11:57:32 | 43.0K token/s | 
[epoch_0]_36361  loss=3.185507 |g|=0.448	lr=2.19e-04 | 78.7%@S30  T=1.85s(data=1.9ms QKV=2.11s FFN=3.04s) eta=12:41:30 | 43.0K token/s | 
[epoch_0]_36371  loss=3.112805 |g|=0.429	lr=2.18e-04 | 79.5%@S30  T=1.74s(data=3.3ms QKV=2.11s FFN=3.04s) eta=11:55:20 | 43.2K token/s | 
[epoch_0]_36381  loss=3.179049 |g|=0.451	lr=2.18e-04 | 80.3%@S30  T=1.89s(data=2.9ms QKV=2.11s FFN=3.04s) eta=12:54:59 | 43.2K token/s | 
[epoch_0]_36391  loss=3.141091 |g|=0.428	lr=2.18e-04 | 81.2%@S30  T=1.75s(data=2.5ms QKV=2.11s FFN=3.04s) eta=12:00:44 | 43.4K token/s | 
[Fuyou] head="3" update algorithm=4 t=14.82s
[eval] 
	 Loss@"edu_fineweb1B"=3.180(0.0011) nBranch=1 nToken=6.31M best=3.1812(180) E2T=0.00106 T=36.7559(0)s x=0
	#3.18005±0.0976 tps=172K(6.30784M) a=[2.99266,3.45734] T=36.7559(sec)
[Section@36400] layer[32-40] tasks=19(nPassBack=0) last_loss=3.17899(0.0318933) N=(772,41440,40880 4804668)
[epoch_0]_36401  loss=3.163655 |g|=0.432	lr=2.18e-04 | 82.0%@S30  T=12.53s(data=3.8ms QKV=2.11s FFN=3.04s) eta=3d 13:45:17 | 41.6K token/s | 
[epoch_0]_36411  loss=3.147547 |g|=0.43	lr=2.18e-04 | 82.8%@S30  T=1.78s(data=1.9ms QKV=2.11s FFN=3.04s) eta=12:11:37 | 41.8K token/s | 
[epoch_0]_36421  loss=3.130700 |g|=0.43	lr=2.18e-04 | 83.6%@S30  T=1.77s(data=1.8ms QKV=2.12s FFN=3.04s) eta=12:07:05 | 42.0K token/s | 
[epoch_0]_36431  loss=3.192812 |g|=0.435	lr=2.18e-04 | 84.4%@S30  T=1.85s(data=2.7ms QKV=2.11s FFN=3.04s) eta=12:37:17 | 42.1K token/s | 
[epoch_0]_36441  loss=3.158967 |g|=0.417	lr=2.17e-04 | 85.3%@S30  T=1.88s(data=1.7ms QKV=2.12s FFN=3.04s) eta=12:51:33 | 42.2K token/s | 
[epoch_0]_36451  loss=3.180082 |g|=0.426	lr=2.17e-04 | 86.1%@S30  T=1.91s(data=2.8ms QKV=2.11s FFN=3.04s) eta=13:00:59 | 42.2K token/s | 
[epoch_0]_36461  loss=3.139138 |g|=0.428	lr=2.17e-04 | 86.9%@S30  T=1.85s(data=1.8ms QKV=2.11s FFN=3.04s) eta=12:38:04 | 42.3K token/s | 
[epoch_0]_36471  loss=3.158123 |g|=0.42	lr=2.17e-04 | 87.7%@S30  T=1.76s(data=2.6ms QKV=2.11s FFN=3.04s) eta=12:00:19 | 42.5K token/s | 
[epoch_0]_36481  loss=3.156071 |g|=0.434	lr=2.17e-04 | 88.5%@S30  T=1.77s(data=2.5ms QKV=2.12s FFN=3.04s) eta=12:02:40 | 42.7K token/s | 
[epoch_0]_36491  loss=3.156703 |g|=0.426	lr=2.17e-04 | 89.4%@S30  T=1.74s(data=2.7ms QKV=2.11s FFN=3.04s) eta=11:50:54 | 43.0K token/s | 
[Fuyou] head="4" update algorithm=4 t=14.43s
[Section@36500] layer[40-48] tasks=19(nPassBack=0) last_loss=3.11351(0.0849619) N=(772,41552,40992 4817868)
[epoch_0]_36501  loss=3.129977 |g|=0.439	lr=2.17e-04 | 90.2%@S30  T=4.81s(data=2.9ms QKV=2.11s FFN=3.03s) eta=1d 08:46:58 | 41.7K token/s | 
[epoch_0]_36511  loss=3.177632 |g|=0.417	lr=2.16e-04 | 91.0%@S30  T=2.06s(data=2.1ms QKV=2.12s FFN=3.04s) eta=14:02:27 | 41.6K token/s | 
[epoch_0]_36521  loss=3.298702 |g|=0.444	lr=2.16e-04 | 91.8%@S30  T=1.91s(data=3.0ms QKV=2.11s FFN=3.04s) eta=13:01:37 | 41.6K token/s | 
[epoch_0]_36531  loss=3.217757 |g|=0.442	lr=2.16e-04 | 92.6%@S30  T=1.89s(data=1.8ms QKV=2.13s FFN=3.04s) eta=12:53:46 | 41.7K token/s | 
[epoch_0]_36541  loss=3.229544 |g|=0.451	lr=2.16e-04 | 93.4%@S30  T=1.93s(data=2.9ms QKV=2.12s FFN=3.04s) eta=13:07:16 | 41.8K token/s | 
[epoch_0]_36551  loss=3.199622 |g|=0.419	lr=2.16e-04 | 94.3%@S30  T=1.80s(data=1.9ms QKV=2.12s FFN=3.04s) eta=12:16:24 | 41.9K token/s | 
[epoch_0]_36561  loss=3.155347 |g|=0.438	lr=2.16e-04 | 95.1%@S30  T=1.74s(data=2.9ms QKV=2.12s FFN=3.04s) eta=11:49:21 | 42.2K token/s | 
[epoch_0]_36571  loss=3.200614 |g|=0.427	lr=2.15e-04 | 95.9%@S30  T=1.78s(data=2.9ms QKV=2.12s FFN=3.04s) eta=12:07:07 | 42.4K token/s | 
[epoch_0]_36581  loss=3.153203 |g|=0.417	lr=2.15e-04 | 96.7%@S30  T=1.78s(data=2.8ms QKV=2.12s FFN=3.04s) eta=12:05:27 | 42.6K token/s | 
[epoch_0]_36591  loss=3.173637 |g|=0.436	lr=2.15e-04 | 97.5%@S30  T=1.76s(data=2.8ms QKV=2.12s FFN=3.04s) eta=11:56:21 | 42.8K token/s | 
[Fuyou] head="5" update algorithm=4 t=13.67s
[eval] 
	 Loss@"edu_fineweb1B"=3.179(0.00098) nBranch=1 nToken=6.31M best=3.1801(181) E2T=-0.0574 T=36.7458(0)s x=0
	#3.17907±0.0977 tps=172K(6.30784M) a=[2.99061,3.45732] T=36.7458(sec)
[Section@36600] layer[0-8] tasks=19(nPassBack=0) last_loss=3.23652(-0.0527606) N=(772,41664,41104 4831068)
[epoch_0]_36601  loss=3.185300 |g|=0.435	lr=2.15e-04 | 98.4%@S30  T=12.34s(data=2.2ms QKV=2.11s FFN=3.04s) eta=3d 11:46:16 | 41.0K token/s | 
[epoch_0]_36611  loss=3.134173 |g|=0.424	lr=2.15e-04 | 99.2%@S30  T=1.74s(data=2.0ms QKV=2.11s FFN=3.04s) eta=11:47:04 | 41.3K token/s | 
[epoch_0]_36620  loss=3.091752 |g|=0.437	lr=2.15e-04 | 99.9%@S30  T=1.75s(data=2.0ms QKV=2.11s FFN=3.04s) eta=11:52:08 | 41.5K token/s | 
[epoch_0]_36621  loss=3.156741 |g|=0.432	lr=2.15e-04 | 100.0%@S30  T=1.86s(data=1.9ms QKV=2.11s FFN=3.04s) eta=12:38:51 | 41.7K token/s | 
-------- End of shard_30@"./Datasets/edu_fineweb1B/edu_fineweb_train_000484.bin"-------- 
[shard-31]@"./Datasets/edu_fineweb1B/edu_fineweb_train_000485.bin": tokens=100(M) nShardSamples=1220(3027336) 
[epoch_0]_36631  loss=3.276232 |g|=0.45	lr=2.15e-04 | 0.8%@S31  T=1.74s(data=1.2ms QKV=2.11s FFN=3.04s) eta=11:49:16 | 41.9K token/s | 
[epoch_0]_36641  loss=3.174908 |g|=0.453	lr=2.14e-04 | 1.6%@S31  T=1.84s(data=1.3ms QKV=2.11s FFN=3.04s) eta=12:26:42 | 42.1K token/s | 
[epoch_0]_36651  loss=3.205003 |g|=0.437	lr=2.14e-04 | 2.5%@S31  T=1.84s(data=1.4ms QKV=2.11s FFN=3.04s) eta=12:29:31 | 42.2K token/s | 
[epoch_0]_36661  loss=3.126280 |g|=0.446	lr=2.14e-04 | 3.3%@S31  T=1.78s(data=1.4ms QKV=2.11s FFN=3.04s) eta=12:04:21 | 42.4K token/s | 
[epoch_0]_36671  loss=3.262989 |g|=0.456	lr=2.14e-04 | 4.1%@S31  T=1.77s(data=1.4ms QKV=2.11s FFN=3.04s) eta=11:56:46 | 42.6K token/s | 
[epoch_0]_36681  loss=3.170177 |g|=0.436	lr=2.14e-04 | 4.9%@S31  T=1.74s(data=1.3ms QKV=2.11s FFN=3.04s) eta=11:45:10 | 42.8K token/s | 
[epoch_0]_36691  loss=3.214497 |g|=0.425	lr=2.14e-04 | 5.7%@S31  T=1.73s(data=1.3ms QKV=2.11s FFN=3.04s) eta=11:43:37 | 43.0K token/s | 
[Fuyou] head="0" update algorithm=4 t=12.14s
[Section@36700] layer[8-16] tasks=19(nPassBack=0) last_loss=3.22865(-0.141243) N=(772,41776,41216 4844268)
[epoch_0]_36701  loss=3.168613 |g|=0.435	lr=2.14e-04 | 6.6%@S31  T=4.66s(data=1.7ms QKV=2.11s FFN=3.03s) eta=1d 07:31:43 | 41.7K token/s | 
[epoch_0]_36711  loss=3.214463 |g|=0.449	lr=2.13e-04 | 7.4%@S31  T=1.77s(data=1.9ms QKV=2.11s FFN=3.04s) eta=11:59:18 | 42.0K token/s | 
[epoch_0]_36721  loss=3.289752 |g|=0.45	lr=2.13e-04 | 8.2%@S31  T=1.73s(data=1.9ms QKV=2.11s FFN=3.04s) eta=11:39:28 | 42.2K token/s | 
[epoch_0]_36731  loss=3.144818 |g|=0.427	lr=2.13e-04 | 9.0%@S31  T=1.84s(data=1.5ms QKV=2.11s FFN=3.04s) eta=12:24:45 | 42.4K token/s | 
[epoch_0]_36741  loss=3.140203 |g|=0.444	lr=2.13e-04 | 9.8%@S31  T=1.85s(data=1.4ms QKV=2.11s FFN=3.04s) eta=12:30:35 | 42.5K token/s | 
[epoch_0]_36751  loss=3.180936 |g|=0.459	lr=2.13e-04 | 10.7%@S31  T=1.77s(data=1.5ms QKV=2.11s FFN=3.04s) eta=11:55:07 | 42.6K token/s | 
[epoch_0]_36761  loss=3.183337 |g|=0.449	lr=2.13e-04 | 11.5%@S31  T=1.82s(data=6.4ms QKV=2.11s FFN=3.04s) eta=12:14:52 | 42.8K token/s | 
[epoch_0]_36771  loss=3.087761 |g|=0.439	lr=2.13e-04 | 12.3%@S31  T=1.75s(data=1.9ms QKV=2.11s FFN=3.04s) eta=11:46:16 | 43.0K token/s | 
[epoch_0]_36781  loss=3.142303 |g|=0.434	lr=2.12e-04 | 13.1%@S31  T=1.76s(data=1.9ms QKV=2.11s FFN=3.04s) eta=11:53:26 | 43.1K token/s | 
[epoch_0]_36791  loss=3.145561 |g|=0.442	lr=2.12e-04 | 13.9%@S31  T=1.81s(data=1.9ms QKV=2.11s FFN=3.04s) eta=12:10:07 | 43.3K token/s | 
[Fuyou] head="1" update algorithm=4 t=11.48s
[eval] 
	 Loss@"edu_fineweb1B"=3.177(0.0022) nBranch=1 nToken=6.31M best=3.1791(182) E2T=-0.0653 T=36.7371(0)s x=0
	#3.17692±0.0980 tps=172K(6.30784M) a=[2.98668,3.45655] T=36.7371(sec)
[Section@36800] layer[16-24] tasks=19(nPassBack=0) last_loss=3.24225(0.0191517) N=(772,41888,41328 4857468)
[epoch_0]_36801  loss=3.143393 |g|=0.436	lr=2.12e-04 | 14.7%@S31  T=12.27s(data=1.5ms QKV=2.11s FFN=3.03s) eta=3d 10:34:18 | 41.4K token/s | 
[epoch_0]_36811  loss=3.251114 |g|=0.439	lr=2.12e-04 | 15.6%@S31  T=1.82s(data=1.9ms QKV=2.11s FFN=3.04s) eta=12:16:06 | 41.6K token/s | 
[epoch_0]_36821  loss=3.125915 |g|=0.427	lr=2.12e-04 | 16.4%@S31  T=1.74s(data=1.8ms QKV=2.11s FFN=3.04s) eta=11:41:09 | 41.9K token/s | 
[epoch_0]_36831  loss=3.128891 |g|=0.422	lr=2.12e-04 | 17.2%@S31  T=1.75s(data=2.0ms QKV=2.11s FFN=3.04s) eta=11:45:12 | 42.1K token/s | 
[epoch_0]_36841  loss=3.179017 |g|=0.416	lr=2.12e-04 | 18.0%@S31  T=1.83s(data=1.8ms QKV=2.11s FFN=3.04s) eta=12:16:42 | 42.3K token/s | 
[epoch_0]_36851  loss=3.118285 |g|=0.444	lr=2.11e-04 | 18.8%@S31  T=1.77s(data=1.4ms QKV=2.11s FFN=3.04s) eta=11:53:43 | 42.5K token/s | 
[epoch_0]_36861  loss=3.279581 |g|=0.427	lr=2.11e-04 | 19.7%@S31  T=1.74s(data=1.9ms QKV=2.11s FFN=3.04s) eta=11:39:25 | 42.7K token/s | 
[epoch_0]_36871  loss=3.179811 |g|=0.463	lr=2.11e-04 | 20.5%@S31  T=1.75s(data=1.6ms QKV=2.11s FFN=3.04s) eta=11:45:59 | 42.9K token/s | 
[epoch_0]_36881  loss=3.155611 |g|=0.419	lr=2.11e-04 | 21.3%@S31  T=1.76s(data=1.7ms QKV=2.11s FFN=3.04s) eta=11:47:14 | 43.1K token/s | 
[epoch_0]_36891  loss=3.258417 |g|=0.444	lr=2.11e-04 | 22.1%@S31  T=1.76s(data=1.5ms QKV=2.11s FFN=3.04s) eta=11:46:25 | 43.3K token/s | 
[Fuyou] head="2" update algorithm=4 t=11.57s
[Section@36900] layer[24-32] tasks=19(nPassBack=0) last_loss=3.16983(-0.0526414) N=(772,42000,41440 4870668)
[epoch_0]_36901  loss=3.186936 |g|=0.418	lr=2.11e-04 | 22.9%@S31  T=4.29s(data=1.8ms QKV=2.11s FFN=3.03s) eta=1d 04:47:02 | 42.1K token/s | 
[epoch_0]_36911  loss=3.204569 |g|=0.446	lr=2.10e-04 | 23.8%@S31  T=1.72s(data=1.7ms QKV=2.11s FFN=3.04s) eta=11:31:39 | 42.3K token/s | 
[epoch_0]_36921  loss=3.137671 |g|=0.44	lr=2.10e-04 | 24.6%@S31  T=1.73s(data=1.7ms QKV=2.12s FFN=3.04s) eta=11:33:37 | 42.6K token/s | 
[epoch_0]_36931  loss=3.188815 |g|=0.434	lr=2.10e-04 | 25.4%@S31  T=1.73s(data=1.7ms QKV=2.11s FFN=3.04s) eta=11:33:57 | 42.8K token/s | 
[epoch_0]_36941  loss=3.128079 |g|=0.448	lr=2.10e-04 | 26.2%@S31  T=1.79s(data=1.6ms QKV=2.11s FFN=3.04s) eta=11:59:58 | 43.0K token/s | 
[epoch_0]_36951  loss=3.181192 |g|=0.428	lr=2.10e-04 | 27.0%@S31  T=1.73s(data=1.7ms QKV=2.12s FFN=3.04s) eta=11:34:06 | 43.2K token/s | 
[epoch_0]_36961  loss=3.229123 |g|=0.438	lr=2.10e-04 | 27.9%@S31  T=1.74s(data=1.6ms QKV=2.12s FFN=3.04s) eta=11:38:53 | 43.4K token/s | 
[epoch_0]_36971  loss=3.139241 |g|=0.429	lr=2.10e-04 | 28.7%@S31  T=1.75s(data=1.4ms QKV=2.12s FFN=3.04s) eta=11:41:31 | 43.6K token/s | 
[epoch_0]_36981  loss=3.193534 |g|=0.434	lr=2.09e-04 | 29.5%@S31  T=1.74s(data=1.7ms QKV=2.12s FFN=3.04s) eta=11:38:32 | 43.7K token/s | 
[epoch_0]_36991  loss=3.156682 |g|=0.42	lr=2.09e-04 | 30.3%@S31  T=1.74s(data=1.4ms QKV=2.12s FFN=3.04s) eta=11:36:24 | 43.9K token/s | 
[Fuyou] head="3" update algorithm=4 t=12.13s
[eval] 
	 Loss@"edu_fineweb1B"=3.176(0.00098) nBranch=1 nToken=6.31M best=3.1769(183) E2T=0.024 T=36.7332(0)s x=0
	#3.17594±0.0978 tps=172K(6.30784M) a=[2.98716,3.45518] T=36.7332(sec)
[Section@37000] layer[32-40] tasks=19(nPassBack=0) last_loss=3.1519(0.0270903) N=(772,42112,41552 4883868)
[epoch_0]_37001  loss=3.216177 |g|=0.427	lr=2.09e-04 | 31.1%@S31  T=11.90s(data=2.3ms QKV=2.11s FFN=3.04s) eta=3d 07:25:25 | 42.1K token/s | 
[epoch_0]_37011  loss=3.161904 |g|=0.43	lr=2.09e-04 | 31.9%@S31  T=1.73s(data=1.8ms QKV=2.11s FFN=3.04s) eta=11:34:14 | 42.3K token/s | 
[epoch_0]_37021  loss=3.138284 |g|=0.432	lr=2.09e-04 | 32.8%@S31  T=1.74s(data=1.9ms QKV=2.11s FFN=3.04s) eta=11:34:45 | 42.6K token/s | 
[epoch_0]_37031  loss=3.220131 |g|=0.429	lr=2.09e-04 | 33.6%@S31  T=1.73s(data=1.5ms QKV=2.11s FFN=3.04s) eta=11:33:03 | 42.8K token/s | 
[epoch_0]_37041  loss=3.186699 |g|=0.451	lr=2.09e-04 | 34.4%@S31  T=1.84s(data=1.8ms QKV=2.12s FFN=3.04s) eta=12:15:04 | 42.9K token/s | 
[epoch_0]_37051  loss=3.158535 |g|=0.438	lr=2.08e-04 | 35.2%@S31  T=1.75s(data=1.7ms QKV=2.11s FFN=3.04s) eta=11:38:41 | 43.1K token/s | 
[epoch_0]_37061  loss=3.162257 |g|=0.43	lr=2.08e-04 | 36.0%@S31  T=1.74s(data=2.1ms QKV=2.11s FFN=3.04s) eta=11:34:45 | 43.3K token/s | 
[epoch_0]_37071  loss=3.127424 |g|=0.452	lr=2.08e-04 | 36.9%@S31  T=1.82s(data=1.9ms QKV=2.11s FFN=3.04s) eta=12:05:18 | 43.4K token/s | 
[epoch_0]_37081  loss=3.181173 |g|=0.43	lr=2.08e-04 | 37.7%@S31  T=1.75s(data=2.0ms QKV=2.11s FFN=3.04s) eta=11:39:42 | 43.5K token/s | 
[epoch_0]_37091  loss=3.185211 |g|=0.419	lr=2.08e-04 | 38.5%@S31  T=1.74s(data=2.3ms QKV=2.11s FFN=3.04s) eta=11:35:52 | 43.7K token/s | 
[Fuyou] head="4" update algorithm=4 t=12.36s
[Section@37100] layer[40-48] tasks=19(nPassBack=0) last_loss=3.19016(-0.076647) N=(772,42224,41664 4897068)
[epoch_0]_37101  loss=3.163718 |g|=0.433	lr=2.08e-04 | 39.3%@S31  T=4.32s(data=1.6ms QKV=2.11s FFN=3.03s) eta=1d 04:44:33 | 42.5K token/s | 
[epoch_0]_37111  loss=3.143298 |g|=0.42	lr=2.08e-04 | 40.1%@S31  T=1.73s(data=2.0ms QKV=2.11s FFN=3.04s) eta=11:30:19 | 42.7K token/s | 
[epoch_0]_37121  loss=3.124151 |g|=0.435	lr=2.07e-04 | 41.0%@S31  T=1.79s(data=1.6ms QKV=2.12s FFN=3.04s) eta=11:54:04 | 42.9K token/s | 
[epoch_0]_37131  loss=3.173335 |g|=0.459	lr=2.07e-04 | 41.8%@S31  T=1.82s(data=2.0ms QKV=2.11s FFN=3.04s) eta=12:03:48 | 43.0K token/s | 
[epoch_0]_37141  loss=3.137572 |g|=0.442	lr=2.07e-04 | 42.6%@S31  T=1.73s(data=1.7ms QKV=2.11s FFN=3.04s) eta=11:28:34 | 43.2K token/s | 
[epoch_0]_37151  loss=3.197275 |g|=0.459	lr=2.07e-04 | 43.4%@S31  T=1.78s(data=1.5ms QKV=2.11s FFN=3.04s) eta=11:47:36 | 43.3K token/s | 
[epoch_0]_37161  loss=3.158895 |g|=0.428	lr=2.07e-04 | 44.2%@S31  T=1.74s(data=1.7ms QKV=2.11s FFN=3.04s) eta=11:30:29 | 43.5K token/s | 
[epoch_0]_37171  loss=3.132643 |g|=0.438	lr=2.07e-04 | 45.1%@S31  T=1.83s(data=1.7ms QKV=2.12s FFN=3.04s) eta=12:06:43 | 43.6K token/s | 
[epoch_0]_37181  loss=3.205721 |g|=0.427	lr=2.07e-04 | 45.9%@S31  T=1.84s(data=1.6ms QKV=2.12s FFN=3.04s) eta=12:12:47 | 43.6K token/s | 
[epoch_0]_37191  loss=3.142314 |g|=0.439	lr=2.06e-04 | 46.7%@S31  T=1.82s(data=1.7ms QKV=2.12s FFN=3.04s) eta=12:04:35 | 43.7K token/s | 
[Fuyou] head="5" update algorithm=4 t=11.86s
[eval] 
	 Loss@"edu_fineweb1B"=3.175(0.00064) nBranch=1 nToken=6.31M best=3.1759(184) E2T=0.0256 T=36.7273(0)s x=0
	#3.17529±0.0974 tps=172K(6.30784M) a=[2.98675,3.45146] T=36.7273(sec)
[Section@37200] layer[0-8] tasks=19(nPassBack=0) last_loss=3.14968(0.0868394) N=(772,42336,41776 4910268)
[epoch_0]_37201  loss=3.076535 |g|=0.438	lr=2.06e-04 | 47.5%@S31  T=12.10s(data=1.6ms QKV=2.11s FFN=3.04s) eta=3d 08:07:47 | 41.9K token/s | 
[epoch_0]_37211  loss=3.158186 |g|=0.444	lr=2.06e-04 | 48.3%@S31  T=1.74s(data=2.5ms QKV=2.12s FFN=3.04s) eta=11:32:06 | 42.1K token/s | 
[epoch_0]_37221  loss=3.186848 |g|=0.45	lr=2.06e-04 | 49.2%@S31  T=1.73s(data=1.7ms QKV=2.11s FFN=3.04s) eta=11:25:47 | 42.4K token/s | 
[epoch_0]_37231  loss=3.162139 |g|=0.459	lr=2.06e-04 | 50.0%@S31  T=1.77s(data=1.9ms QKV=2.11s FFN=3.04s) eta=11:42:34 | 42.6K token/s | 
[epoch_0]_37241  loss=3.196406 |g|=0.457	lr=2.06e-04 | 50.8%@S31  T=1.74s(data=1.7ms QKV=2.11s FFN=3.04s) eta=11:29:33 | 42.8K token/s | 
[epoch_0]_37251  loss=3.203435 |g|=0.45	lr=2.06e-04 | 51.6%@S31  T=1.80s(data=1.9ms QKV=2.11s FFN=3.04s) eta=11:54:15 | 42.9K token/s | 
[epoch_0]_37261  loss=3.176764 |g|=0.424	lr=2.05e-04 | 52.4%@S31  T=1.72s(data=1.8ms QKV=2.11s FFN=3.04s) eta=11:23:22 | 43.2K token/s | 
[epoch_0]_37271  loss=3.181518 |g|=0.447	lr=2.05e-04 | 53.2%@S31  T=1.75s(data=1.6ms QKV=2.12s FFN=3.04s) eta=11:34:49 | 43.3K token/s | 
[epoch_0]_37281  loss=3.196090 |g|=0.425	lr=2.05e-04 | 54.1%@S31  T=1.80s(data=1.7ms QKV=2.11s FFN=3.04s) eta=11:53:13 | 43.4K token/s | 
[epoch_0]_37291  loss=3.231855 |g|=0.448	lr=2.05e-04 | 54.9%@S31  T=1.79s(data=1.7ms QKV=2.11s FFN=3.04s) eta=11:48:06 | 43.6K token/s | 
[Fuyou] head="0" update algorithm=4 t=12.04s
[Section@37300] layer[8-16] tasks=19(nPassBack=0) last_loss=3.19737(0.0312872) N=(772,42448,41888 4923468)
[epoch_0]_37301  loss=3.210397 |g|=0.416	lr=2.05e-04 | 55.7%@S31  T=4.75s(data=2.5ms QKV=2.11s FFN=3.03s) eta=1d 07:20:52 | 42.2K token/s | 
[epoch_0]_37311  loss=3.083421 |g|=0.429	lr=2.05e-04 | 56.5%@S31  T=1.82s(data=1.7ms QKV=2.12s FFN=3.04s) eta=12:01:20 | 42.4K token/s | 
[epoch_0]_37321  loss=3.168687 |g|=0.45	lr=2.04e-04 | 57.3%@S31  T=1.81s(data=1.6ms QKV=2.12s FFN=3.04s) eta=11:55:32 | 42.5K token/s | 
[epoch_0]_37331  loss=3.157070 |g|=0.468	lr=2.04e-04 | 58.2%@S31  T=1.73s(data=1.9ms QKV=2.12s FFN=3.04s) eta=11:21:44 | 42.8K token/s | 
[epoch_0]_37341  loss=3.127901 |g|=0.449	lr=2.04e-04 | 59.0%@S31  T=1.77s(data=1.7ms QKV=2.12s FFN=3.04s) eta=11:38:50 | 42.9K token/s | 
[epoch_0]_37351  loss=3.255641 |g|=0.435	lr=2.04e-04 | 59.8%@S31  T=1.85s(data=1.6ms QKV=2.12s FFN=3.04s) eta=12:08:45 | 43.0K token/s | 
[epoch_0]_37361  loss=3.137016 |g|=0.443	lr=2.04e-04 | 60.6%@S31  T=1.82s(data=1.6ms QKV=2.12s FFN=3.04s) eta=11:58:01 | 43.1K token/s | 
[epoch_0]_37371  loss=3.137756 |g|=0.45	lr=2.04e-04 | 61.4%@S31  T=1.74s(data=1.8ms QKV=2.12s FFN=3.04s) eta=11:27:51 | 43.3K token/s | 
[epoch_0]_37381  loss=3.116254 |g|=0.427	lr=2.04e-04 | 62.3%@S31  T=1.73s(data=1.8ms QKV=2.12s FFN=3.04s) eta=11:23:28 | 43.5K token/s | 
[epoch_0]_37391  loss=3.183534 |g|=0.433	lr=2.03e-04 | 63.1%@S31  T=1.83s(data=1.6ms QKV=2.12s FFN=3.04s) eta=11:59:55 | 43.6K token/s | 
[Fuyou] head="1" update algorithm=4 t=11.68s
[eval] 
	 Loss@"edu_fineweb1B"=3.174(0.0016) nBranch=1 nToken=6.31M best=3.1753(185) E2T=-0.055 T=36.7302(0)s x=0
	#3.17374±0.0982 tps=172K(6.30784M) a=[2.9831,3.45052] T=36.7302(sec)
[Section@37400] layer[16-24] tasks=19(nPassBack=0) last_loss=3.22873(0.0135155) N=(772,42560,42000 4936668)
[epoch_0]_37401  loss=3.152802 |g|=0.428	lr=2.03e-04 | 63.9%@S31  T=12.26s(data=2.0ms QKV=2.11s FFN=3.03s) eta=3d 08:30:08 | 41.7K token/s | 
[epoch_0]_37411  loss=3.194108 |g|=0.459	lr=2.03e-04 | 64.7%@S31  T=1.76s(data=1.7ms QKV=2.11s FFN=3.04s) eta=11:33:19 | 42.0K token/s | 
[epoch_0]_37421  loss=3.172822 |g|=0.446	lr=2.03e-04 | 65.5%@S31  T=1.78s(data=1.9ms QKV=2.11s FFN=3.04s) eta=11:38:35 | 42.2K token/s | 
[epoch_0]_37431  loss=3.092339 |g|=0.434	lr=2.03e-04 | 66.4%@S31  T=1.78s(data=1.7ms QKV=2.12s FFN=3.04s) eta=11:41:25 | 42.4K token/s | 
[epoch_0]_37441  loss=3.216087 |g|=0.457	lr=2.03e-04 | 67.2%@S31  T=1.76s(data=1.7ms QKV=2.12s FFN=3.04s) eta=11:33:38 | 42.6K token/s | 
[epoch_0]_37451  loss=3.166833 |g|=0.449	lr=2.03e-04 | 68.0%@S31  T=1.74s(data=2.1ms QKV=2.11s FFN=3.04s) eta=11:24:24 | 42.8K token/s | 
[epoch_0]_37461  loss=3.174617 |g|=0.447	lr=2.02e-04 | 68.8%@S31  T=1.83s(data=1.8ms QKV=2.12s FFN=3.04s) eta=11:57:56 | 42.9K token/s | 
[epoch_0]_37471  loss=3.114385 |g|=0.437	lr=2.02e-04 | 69.6%@S31  T=1.81s(data=1.9ms QKV=2.11s FFN=3.04s) eta=11:51:59 | 43.0K token/s | 
[epoch_0]_37481  loss=3.227885 |g|=0.452	lr=2.02e-04 | 70.5%@S31  T=1.82s(data=1.6ms QKV=2.12s FFN=3.04s) eta=11:55:52 | 43.1K token/s | 
[epoch_0]_37491  loss=3.178299 |g|=0.436	lr=2.02e-04 | 71.3%@S31  T=1.84s(data=1.6ms QKV=2.12s FFN=3.04s) eta=12:00:41 | 43.2K token/s | 
[Fuyou] head="2" update algorithm=4 t=10.94s
[Section@37500] layer[24-32] tasks=19(nPassBack=0) last_loss=3.16998(-0.000140905) N=(772,42672,42112 4949868)
[epoch_0]_37501  loss=3.162524 |g|=0.441	lr=2.02e-04 | 72.1%@S31  T=4.23s(data=1.8ms QKV=2.11s FFN=3.03s) eta=1d 03:38:15 | 42.0K token/s | 
[epoch_0]_37511  loss=3.185943 |g|=0.454	lr=2.02e-04 | 72.9%@S31  T=1.73s(data=1.9ms QKV=2.12s FFN=3.04s) eta=11:16:47 | 42.3K token/s | 
[epoch_0]_37521  loss=3.144312 |g|=0.436	lr=2.02e-04 | 73.7%@S31  T=1.77s(data=1.7ms QKV=2.12s FFN=3.04s) eta=11:32:47 | 42.5K token/s | 
[epoch_0]_37531  loss=3.214649 |g|=0.442	lr=2.01e-04 | 74.5%@S31  T=1.77s(data=1.6ms QKV=2.12s FFN=3.04s) eta=11:31:33 | 42.7K token/s | 
[epoch_0]_37541  loss=3.234848 |g|=0.433	lr=2.01e-04 | 75.4%@S31  T=1.82s(data=1.8ms QKV=2.13s FFN=3.04s) eta=11:51:31 | 42.8K token/s | 
[epoch_0]_37551  loss=3.184604 |g|=0.438	lr=2.01e-04 | 76.2%@S31  T=1.72s(data=1.9ms QKV=2.12s FFN=3.04s) eta=11:12:55 | 43.0K token/s | 
[epoch_0]_37561  loss=3.203577 |g|=0.424	lr=2.01e-04 | 77.0%@S31  T=1.73s(data=1.8ms QKV=2.12s FFN=3.04s) eta=11:14:58 | 43.3K token/s | 
[epoch_0]_37571  loss=3.167827 |g|=0.437	lr=2.01e-04 | 77.8%@S31  T=1.76s(data=2.0ms QKV=2.12s FFN=3.04s) eta=11:27:47 | 43.4K token/s | 
[epoch_0]_37581  loss=3.218249 |g|=0.44	lr=2.01e-04 | 78.6%@S31  T=1.81s(data=1.6ms QKV=2.12s FFN=3.04s) eta=11:46:47 | 43.5K token/s | 
[epoch_0]_37591  loss=3.167840 |g|=0.434	lr=2.01e-04 | 79.5%@S31  T=1.80s(data=1.9ms QKV=2.12s FFN=3.04s) eta=11:44:40 | 43.6K token/s | 
[Fuyou] head="3" update algorithm=4 t=11.76s
[eval] 
	 Loss@"edu_fineweb1B"=3.173(0.00079) nBranch=1 nToken=6.31M best=3.1737(186) E2T=-0.0177 T=36.7141(0)s x=0
	#3.17295±0.0979 tps=172K(6.30784M) a=[2.98281,3.45359] T=36.7141(sec)
[Section@37600] layer[32-40] tasks=19(nPassBack=0) last_loss=3.19067(-0.0387638) N=(772,42784,42224 4963068)
[epoch_0]_37601  loss=3.169830 |g|=0.428	lr=2.00e-04 | 80.3%@S31  T=12.08s(data=1.9ms QKV=2.13s FFN=3.03s) eta=3d 06:39:51 | 41.8K token/s | 
[epoch_0]_37611  loss=3.243426 |g|=0.448	lr=2.00e-04 | 81.1%@S31  T=1.74s(data=1.7ms QKV=2.12s FFN=3.04s) eta=11:19:43 | 42.0K token/s | 
[epoch_0]_37621  loss=3.131003 |g|=0.448	lr=2.00e-04 | 81.9%@S31  T=1.83s(data=1.7ms QKV=2.12s FFN=3.04s) eta=11:55:14 | 42.2K token/s | 
[epoch_0]_37631  loss=3.203112 |g|=0.434	lr=2.00e-04 | 82.7%@S31  T=1.74s(data=1.7ms QKV=2.12s FFN=3.04s) eta=11:17:57 | 42.4K token/s | 
[epoch_0]_37641  loss=3.177940 |g|=0.44	lr=2.00e-04 | 83.6%@S31  T=1.73s(data=1.7ms QKV=2.12s FFN=3.04s) eta=11:13:53 | 42.7K token/s | 
[epoch_0]_37651  loss=3.231436 |g|=0.449	lr=2.00e-04 | 84.4%@S31  T=1.76s(data=1.6ms QKV=2.12s FFN=3.04s) eta=11:26:51 | 42.9K token/s | 
[epoch_0]_37661  loss=3.177145 |g|=0.432	lr=2.00e-04 | 85.2%@S31  T=1.82s(data=1.6ms QKV=2.13s FFN=3.04s) eta=11:47:27 | 43.0K token/s | 
[epoch_0]_37671  loss=3.241216 |g|=0.435	lr=1.99e-04 | 86.0%@S31  T=1.73s(data=1.6ms QKV=2.12s FFN=3.04s) eta=11:13:44 | 43.2K token/s | 
[epoch_0]_37681  loss=3.163977 |g|=0.45	lr=1.99e-04 | 86.8%@S31  T=1.74s(data=1.9ms QKV=2.12s FFN=3.04s) eta=11:18:30 | 43.4K token/s | 
[epoch_0]_37691  loss=3.204652 |g|=0.463	lr=1.99e-04 | 87.7%@S31  T=1.84s(data=1.8ms QKV=2.12s FFN=3.04s) eta=11:54:37 | 43.4K token/s | 
[Fuyou] head="4" update algorithm=4 t=12.39s
[Section@37700] layer[40-48] tasks=19(nPassBack=0) last_loss=3.26642(-0.0762637) N=(772,42896,42336 4976268)
[epoch_0]_37701  loss=3.115878 |g|=0.447	lr=1.99e-04 | 88.5%@S31  T=4.38s(data=1.6ms QKV=2.12s FFN=3.03s) eta=1d 04:23:50 | 42.2K token/s | 
[epoch_0]_37711  loss=3.117852 |g|=0.438	lr=1.99e-04 | 89.3%@S31  T=1.75s(data=1.6ms QKV=2.12s FFN=3.03s) eta=11:21:30 | 42.4K token/s | 
[epoch_0]_37721  loss=3.160242 |g|=0.429	lr=1.99e-04 | 90.1%@S31  T=1.87s(data=1.6ms QKV=2.12s FFN=3.04s) eta=12:07:16 | 42.5K token/s | 
[epoch_0]_37731  loss=3.114896 |g|=0.458	lr=1.99e-04 | 90.9%@S31  T=1.74s(data=1.7ms QKV=2.12s FFN=3.04s) eta=11:14:08 | 42.7K token/s | 
[epoch_0]_37741  loss=3.141984 |g|=0.443	lr=1.98e-04 | 91.8%@S31  T=1.83s(data=1.6ms QKV=2.13s FFN=3.04s) eta=11:50:50 | 42.8K token/s | 
[epoch_0]_37751  loss=3.171942 |g|=0.436	lr=1.98e-04 | 92.6%@S31  T=1.75s(data=2.4ms QKV=2.12s FFN=3.04s) eta=11:17:34 | 43.0K token/s | 
[epoch_0]_37761  loss=3.215456 |g|=0.447	lr=1.98e-04 | 93.4%@S31  T=1.83s(data=1.6ms QKV=2.12s FFN=3.04s) eta=11:50:39 | 43.1K token/s | 
[epoch_0]_37771  loss=3.209152 |g|=0.425	lr=1.98e-04 | 94.2%@S31  T=1.84s(data=1.6ms QKV=2.12s FFN=3.04s) eta=11:52:03 | 43.2K token/s | 
[epoch_0]_37781  loss=3.214202 |g|=0.444	lr=1.98e-04 | 95.0%@S31  T=1.84s(data=1.6ms QKV=2.12s FFN=3.04s) eta=11:54:21 | 43.3K token/s | 
[epoch_0]_37791  loss=3.124301 |g|=0.453	lr=1.98e-04 | 95.8%@S31  T=1.83s(data=1.6ms QKV=2.13s FFN=3.04s) eta=11:49:45 | 43.3K token/s | 
[Fuyou] head="5" update algorithm=4 t=12.12s
[eval] 
	 Loss@"edu_fineweb1B"=3.172(0.00065) nBranch=1 nToken=6.31M best=3.1730(187) E2T=-0.00185 T=36.7058(0)s x=0
	#3.1723±0.0977 tps=172K(6.30784M) a=[2.98467,3.44692] T=36.7058(sec)
[Section@37800] layer[0-8] tasks=19(nPassBack=0) last_loss=3.17415(-0.0244737) N=(772,43008,42448 4989468)
[epoch_0]_37801  loss=3.150456 |g|=0.434	lr=1.98e-04 | 96.7%@S31  T=12.20s(data=2.0ms QKV=2.11s FFN=3.03s) eta=3d 06:42:59 | 41.5K token/s | 
[epoch_0]_37811  loss=3.167105 |g|=0.458	lr=1.97e-04 | 97.5%@S31  T=1.88s(data=1.9ms QKV=2.12s FFN=3.04s) eta=12:08:28 | 41.6K token/s | 
[epoch_0]_37821  loss=3.197250 |g|=0.45	lr=1.97e-04 | 98.3%@S31  T=1.86s(data=1.8ms QKV=2.11s FFN=3.04s) eta=11:58:25 | 41.7K token/s | 
[epoch_0]_37831  loss=3.188651 |g|=0.452	lr=1.97e-04 | 99.1%@S31  T=1.82s(data=1.8ms QKV=2.12s FFN=3.04s) eta=11:45:09 | 41.9K token/s | 
[epoch_0]_37841  loss=3.160287 |g|=0.451	lr=1.97e-04 | 99.9%@S31  T=1.81s(data=2.4ms QKV=2.11s FFN=3.04s) eta=11:39:29 | 42.1K token/s | 
-------- End of shard_31@"./Datasets/edu_fineweb1B/edu_fineweb_train_000485.bin"-------- 
[shard-32]@"./Datasets/edu_fineweb1B/edu_fineweb_train_000486.bin": tokens=100(M) nShardSamples=1220(3124992) 
[epoch_0]_37851  loss=3.174902 |g|=0.459	lr=1.97e-04 | 0.8%@S32  T=1.80s(data=1.4ms QKV=2.12s FFN=3.04s) eta=11:35:00 | 42.2K token/s | 
[epoch_0]_37861  loss=3.252266 |g|=0.453	lr=1.97e-04 | 1.6%@S32  T=1.81s(data=1.4ms QKV=2.11s FFN=3.04s) eta=11:40:30 | 42.4K token/s | 
[epoch_0]_37871  loss=3.111053 |g|=0.446	lr=1.97e-04 | 2.4%@S32  T=1.83s(data=1.3ms QKV=2.11s FFN=3.04s) eta=11:48:02 | 42.5K token/s | 
[epoch_0]_37881  loss=3.136355 |g|=0.462	lr=1.96e-04 | 3.2%@S32  T=1.82s(data=1.2ms QKV=2.11s FFN=3.04s) eta=11:41:59 | 42.6K token/s | 
[epoch_0]_37891  loss=3.241424 |g|=0.442	lr=1.96e-04 | 4.0%@S32  T=1.84s(data=1.4ms QKV=2.11s FFN=3.04s) eta=11:50:32 | 42.7K token/s | 
[Fuyou] head="0" update algorithm=4 t=12.48s
[Section@37900] layer[8-16] tasks=19(nPassBack=0) last_loss=3.18877(0.00859857) N=(772,43120,42560 5002668)
[epoch_0]_37901  loss=3.107203 |g|=0.433	lr=1.96e-04 | 4.9%@S32  T=4.77s(data=2.1ms QKV=2.11s FFN=3.03s) eta=1d 06:38:18 | 41.4K token/s | 
[epoch_0]_37911  loss=3.154653 |g|=0.451	lr=1.96e-04 | 5.7%@S32  T=1.84s(data=2.4ms QKV=2.12s FFN=3.04s) eta=11:47:31 | 41.6K token/s | 
[epoch_0]_37921  loss=3.172793 |g|=0.447	lr=1.96e-04 | 6.5%@S32  T=1.76s(data=1.7ms QKV=2.12s FFN=3.04s) eta=11:16:15 | 41.8K token/s | 
[epoch_0]_37931  loss=3.126910 |g|=0.448	lr=1.96e-04 | 7.3%@S32  T=1.80s(data=1.7ms QKV=2.12s FFN=3.04s) eta=11:31:58 | 42.0K token/s | 
[epoch_0]_37941  loss=3.141820 |g|=0.445	lr=1.96e-04 | 8.1%@S32  T=1.84s(data=1.6ms QKV=2.12s FFN=3.04s) eta=11:49:33 | 42.2K token/s | 
[epoch_0]_37951  loss=3.138623 |g|=0.436	lr=1.95e-04 | 9.0%@S32  T=1.85s(data=1.8ms QKV=2.12s FFN=3.04s) eta=11:53:32 | 42.3K token/s | 
[epoch_0]_37961  loss=3.200494 |g|=0.457	lr=1.95e-04 | 9.8%@S32  T=1.82s(data=1.3ms QKV=2.12s FFN=3.04s) eta=11:38:04 | 42.4K token/s | 
[epoch_0]_37971  loss=3.204076 |g|=0.452	lr=1.95e-04 | 10.6%@S32  T=1.87s(data=1.6ms QKV=2.12s FFN=3.04s) eta=11:58:10 | 42.5K token/s | 
[epoch_0]_37981  loss=3.133382 |g|=0.468	lr=1.95e-04 | 11.4%@S32  T=1.88s(data=1.4ms QKV=2.12s FFN=3.04s) eta=12:01:40 | 42.5K token/s | 
[epoch_0]_37991  loss=3.152985 |g|=0.458	lr=1.95e-04 | 12.2%@S32  T=1.85s(data=1.8ms QKV=2.12s FFN=3.04s) eta=11:50:40 | 42.6K token/s | 
[Fuyou] head="1" update algorithm=4 t=11.55s
[eval] 
	 Loss@"edu_fineweb1B"=3.166(0.0065) nBranch=1 nToken=6.31M best=3.1723(188) E2T=-0.000992 T=36.7392(0)s x=0
	#3.16582±0.0973 tps=172K(6.30784M) a=[2.98129,3.43884] T=36.7392(sec)
[Section@38000] layer[16-24] tasks=19(nPassBack=0) last_loss=3.16681(0.0619199) N=(772,43232,42672 5015868)
[epoch_0]_38001  loss=3.224408 |g|=0.457	lr=1.95e-04 | 13.1%@S32  T=12.37s(data=2.1ms QKV=2.11s FFN=3.03s) eta=3d 07:10:03 | 40.8K token/s | 
[epoch_0]_38011  loss=3.152633 |g|=0.453	lr=1.95e-04 | 13.9%@S32  T=1.80s(data=2.2ms QKV=2.11s FFN=3.04s) eta=11:32:33 | 41.0K token/s | 
[epoch_0]_38021  loss=3.134455 |g|=0.45	lr=1.94e-04 | 14.7%@S32  T=1.74s(data=2.4ms QKV=2.11s FFN=3.04s) eta=11:05:51 | 41.4K token/s | 
[epoch_0]_38031  loss=3.152875 |g|=0.442	lr=1.94e-04 | 15.5%@S32  T=1.76s(data=1.9ms QKV=2.11s FFN=3.04s) eta=11:13:04 | 41.6K token/s | 
[epoch_0]_38041  loss=3.172858 |g|=0.447	lr=1.94e-04 | 16.3%@S32  T=1.92s(data=2.1ms QKV=2.11s FFN=3.04s) eta=12:14:12 | 41.7K token/s | 
[epoch_0]_38051  loss=3.166557 |g|=0.457	lr=1.94e-04 | 17.1%@S32  T=1.75s(data=2.1ms QKV=2.11s FFN=3.04s) eta=11:08:34 | 41.9K token/s | 
[epoch_0]_38061  loss=3.120886 |g|=0.431	lr=1.94e-04 | 18.0%@S32  T=1.84s(data=1.9ms QKV=2.11s FFN=3.04s) eta=11:44:28 | 42.1K token/s | 
[epoch_0]_38071  loss=3.238103 |g|=0.444	lr=1.94e-04 | 18.8%@S32  T=1.84s(data=1.6ms QKV=2.11s FFN=3.04s) eta=11:44:46 | 42.2K token/s | 
[epoch_0]_38081  loss=3.163399 |g|=0.444	lr=1.94e-04 | 19.6%@S32  T=1.74s(data=1.7ms QKV=2.11s FFN=3.04s) eta=11:07:15 | 42.4K token/s | 
[epoch_0]_38091  loss=3.221196 |g|=0.453	lr=1.93e-04 | 20.4%@S32  T=1.85s(data=1.7ms QKV=2.11s FFN=3.04s) eta=11:48:11 | 42.5K token/s | 
[Fuyou] head="2" update algorithm=4 t=10.81s
[Section@38100] layer[24-32] tasks=19(nPassBack=0) last_loss=3.18123(-0.0112536) N=(772,43344,42784 5029068)
[epoch_0]_38101  loss=3.187168 |g|=0.441	lr=1.93e-04 | 21.2%@S32  T=4.59s(data=2.5ms QKV=2.12s FFN=3.03s) eta=1d 05:14:36 | 41.3K token/s | 
[epoch_0]_38111  loss=3.121319 |g|=0.457	lr=1.93e-04 | 22.1%@S32  T=1.77s(data=1.8ms QKV=2.11s FFN=3.04s) eta=11:15:43 | 41.5K token/s | 
[epoch_0]_38121  loss=3.130074 |g|=0.456	lr=1.93e-04 | 22.9%@S32  T=1.87s(data=2.2ms QKV=2.12s FFN=3.04s) eta=11:55:47 | 41.6K token/s | 
[epoch_0]_38131  loss=3.160108 |g|=0.439	lr=1.93e-04 | 23.7%@S32  T=1.74s(data=1.7ms QKV=2.11s FFN=3.04s) eta=11:03:19 | 41.9K token/s | 
[epoch_0]_38141  loss=3.115012 |g|=0.437	lr=1.93e-04 | 24.5%@S32  T=1.75s(data=1.6ms QKV=2.12s FFN=3.04s) eta=11:09:01 | 42.2K token/s | 
[epoch_0]_38151  loss=3.207273 |g|=0.429	lr=1.93e-04 | 25.3%@S32  T=1.74s(data=1.5ms QKV=2.11s FFN=3.04s) eta=11:02:29 | 42.4K token/s | 
[epoch_0]_38161  loss=3.140911 |g|=0.457	lr=1.92e-04 | 26.2%@S32  T=1.75s(data=1.6ms QKV=2.11s FFN=3.04s) eta=11:05:19 | 42.6K token/s | 
[epoch_0]_38171  loss=3.206631 |g|=0.454	lr=1.92e-04 | 27.0%@S32  T=1.74s(data=1.4ms QKV=2.12s FFN=3.04s) eta=11:02:59 | 42.9K token/s | 
[epoch_0]_38181  loss=3.194513 |g|=0.474	lr=1.92e-04 | 27.8%@S32  T=1.82s(data=1.5ms QKV=2.12s FFN=3.04s) eta=11:33:50 | 43.0K token/s | 
[epoch_0]_38191  loss=3.170437 |g|=0.459	lr=1.92e-04 | 28.6%@S32  T=1.75s(data=1.8ms QKV=2.11s FFN=3.04s) eta=11:07:38 | 43.2K token/s | 
[Fuyou] head="3" update algorithm=4 t=12.03s
[eval] 
	 Loss@"edu_fineweb1B"=3.163(0.0033) nBranch=1 nToken=6.31M best=3.1658(189) E2T=-0.0349 T=36.7379(0)s x=0
	#3.16256±0.0972 tps=172K(6.30784M) a=[2.97757,3.43587] T=36.7379(sec)
[Section@38200] layer[32-40] tasks=19(nPassBack=0) last_loss=3.19744(-0.00676775) N=(772,43456,42896 5042268)
[epoch_0]_38201  loss=3.187587 |g|=0.451	lr=1.92e-04 | 29.4%@S32  T=12.27s(data=1.7ms QKV=2.11s FFN=3.03s) eta=3d 05:48:26 | 41.3K token/s | 
[epoch_0]_38211  loss=3.161702 |g|=0.461	lr=1.92e-04 | 30.3%@S32  T=1.72s(data=2.0ms QKV=2.11s FFN=3.04s) eta=10:55:19 | 41.6K token/s | 
[epoch_0]_38221  loss=3.143432 |g|=0.436	lr=1.91e-04 | 31.1%@S32  T=1.76s(data=2.3ms QKV=2.12s FFN=3.04s) eta=11:10:27 | 41.9K token/s | 
[epoch_0]_38231  loss=3.140819 |g|=0.436	lr=1.91e-04 | 31.9%@S32  T=1.80s(data=2.0ms QKV=2.12s FFN=3.04s) eta=11:22:39 | 42.1K token/s | 
[epoch_0]_38241  loss=3.204462 |g|=0.455	lr=1.91e-04 | 32.7%@S32  T=1.88s(data=2.1ms QKV=2.12s FFN=3.04s) eta=11:53:14 | 42.1K token/s | 
[epoch_0]_38251  loss=3.137580 |g|=0.452	lr=1.91e-04 | 33.5%@S32  T=1.86s(data=1.6ms QKV=2.11s FFN=3.04s) eta=11:47:33 | 42.2K token/s | 
[epoch_0]_38261  loss=3.168819 |g|=0.465	lr=1.91e-04 | 34.4%@S32  T=1.77s(data=2.0ms QKV=2.11s FFN=3.04s) eta=11:10:44 | 42.4K token/s | 
[epoch_0]_38271  loss=3.096925 |g|=0.454	lr=1.91e-04 | 35.2%@S32  T=1.78s(data=2.0ms QKV=2.12s FFN=3.04s) eta=11:14:01 | 42.6K token/s | 
[epoch_0]_38281  loss=3.187348 |g|=0.49	lr=1.91e-04 | 36.0%@S32  T=1.82s(data=1.7ms QKV=2.11s FFN=3.04s) eta=11:30:33 | 42.7K token/s | 
[epoch_0]_38291  loss=3.097757 |g|=0.472	lr=1.90e-04 | 36.8%@S32  T=1.90s(data=1.9ms QKV=2.12s FFN=3.04s) eta=11:59:00 | 42.8K token/s | 
[Fuyou] head="4" update algorithm=4 t=13.04s
[Section@38300] layer[40-48] tasks=19(nPassBack=0) last_loss=3.09111(0.175309) N=(772,43568,43008 5055468)
[epoch_0]_38301  loss=3.153882 |g|=0.448	lr=1.90e-04 | 37.6%@S32  T=4.42s(data=2.4ms QKV=2.12s FFN=3.03s) eta=1d 03:53:59 | 41.6K token/s | 
[epoch_0]_38311  loss=3.218831 |g|=0.46	lr=1.90e-04 | 38.4%@S32  T=1.74s(data=1.9ms QKV=2.12s FFN=3.04s) eta=10:58:14 | 41.8K token/s | 
[epoch_0]_38321  loss=3.255586 |g|=0.457	lr=1.90e-04 | 39.3%@S32  T=1.78s(data=2.0ms QKV=2.12s FFN=3.04s) eta=11:14:43 | 42.0K token/s | 
[epoch_0]_38331  loss=3.151811 |g|=0.471	lr=1.90e-04 | 40.1%@S32  T=1.75s(data=1.8ms QKV=2.12s FFN=3.04s) eta=11:02:41 | 42.3K token/s | 
[epoch_0]_38341  loss=3.203063 |g|=0.475	lr=1.90e-04 | 40.9%@S32  T=1.75s(data=1.7ms QKV=2.12s FFN=3.04s) eta=11:01:36 | 42.5K token/s | 
[epoch_0]_38351  loss=3.181788 |g|=0.459	lr=1.90e-04 | 41.7%@S32  T=1.75s(data=1.6ms QKV=2.12s FFN=3.04s) eta=11:03:16 | 42.7K token/s | 
[epoch_0]_38361  loss=3.155732 |g|=0.442	lr=1.89e-04 | 42.5%@S32  T=1.80s(data=1.8ms QKV=2.12s FFN=3.04s) eta=11:18:49 | 42.9K token/s | 
[epoch_0]_38371  loss=3.117688 |g|=0.472	lr=1.89e-04 | 43.4%@S32  T=1.73s(data=1.5ms QKV=2.12s FFN=3.04s) eta=10:54:29 | 43.1K token/s | 
[epoch_0]_38381  loss=3.175528 |g|=0.441	lr=1.89e-04 | 44.2%@S32  T=1.76s(data=1.6ms QKV=2.12s FFN=3.04s) eta=11:04:19 | 43.3K token/s | 
[epoch_0]_38391  loss=3.154815 |g|=0.444	lr=1.89e-04 | 45.0%@S32  T=1.74s(data=1.8ms QKV=2.12s FFN=3.04s) eta=10:55:41 | 43.4K token/s | 
[Fuyou] head="5" update algorithm=4 t=11.56s
[eval] 
	 Loss@"edu_fineweb1B"=3.161(0.0013) nBranch=1 nToken=6.31M best=3.1626(190) E2T=0.0501 T=36.7391(0)s x=0
	#3.16124±0.0967 tps=172K(6.30784M) a=[2.97609,3.43206] T=36.7391(sec)
[Section@38400] layer[0-8] tasks=19(nPassBack=0) last_loss=3.11117(0.0629771) N=(772,43680,43120 5068668)
[epoch_0]_38401  loss=3.071155 |g|=0.442	lr=1.89e-04 | 45.8%@S32  T=12.18s(data=2.0ms QKV=2.11s FFN=3.04s) eta=3d 04:33:40 | 41.6K token/s | 
[epoch_0]_38411  loss=3.197515 |g|=0.468	lr=1.89e-04 | 46.6%@S32  T=1.73s(data=1.8ms QKV=2.11s FFN=3.04s) eta=10:52:19 | 41.9K token/s | 
[epoch_0]_38421  loss=3.152850 |g|=0.433	lr=1.89e-04 | 47.5%@S32  T=1.73s(data=1.8ms QKV=2.11s FFN=3.04s) eta=10:53:15 | 42.2K token/s | 
[epoch_0]_38431  loss=3.226767 |g|=0.442	lr=1.89e-04 | 48.3%@S32  T=1.78s(data=1.8ms QKV=2.11s FFN=3.04s) eta=11:11:04 | 42.4K token/s | 
[epoch_0]_38441  loss=3.113557 |g|=0.433	lr=1.88e-04 | 49.1%@S32  T=1.88s(data=1.7ms QKV=2.11s FFN=3.04s) eta=11:46:46 | 42.4K token/s | 
[epoch_0]_38451  loss=3.100365 |g|=0.446	lr=1.88e-04 | 49.9%@S32  T=1.74s(data=2.0ms QKV=2.11s FFN=3.04s) eta=10:53:11 | 42.7K token/s | 
[epoch_0]_38461  loss=3.149780 |g|=0.453	lr=1.88e-04 | 50.7%@S32  T=1.74s(data=2.1ms QKV=2.11s FFN=3.04s) eta=10:54:05 | 42.9K token/s | 
[epoch_0]_38471  loss=3.055845 |g|=0.434	lr=1.88e-04 | 51.6%@S32  T=1.87s(data=2.0ms QKV=2.12s FFN=3.04s) eta=11:43:22 | 42.9K token/s | 
[epoch_0]_38481  loss=3.164397 |g|=0.431	lr=1.88e-04 | 52.4%@S32  T=1.88s(data=2.0ms QKV=2.12s FFN=3.04s) eta=11:47:39 | 43.0K token/s | 
[epoch_0]_38491  loss=3.215976 |g|=0.45	lr=1.88e-04 | 53.2%@S32  T=1.89s(data=2.0ms QKV=2.12s FFN=3.04s) eta=11:49:24 | 43.0K token/s | 
[Fuyou] head="0" update algorithm=4 t=12.57s
[Section@38500] layer[8-16] tasks=19(nPassBack=0) last_loss=3.21129(-0.0225179) N=(772,43792,43232 5081868)
[epoch_0]_38501  loss=3.112260 |g|=0.453	lr=1.88e-04 | 54.0%@S32  T=5.04s(data=2.6ms QKV=2.11s FFN=3.03s) eta=1d 07:31:35 | 41.6K token/s | 
[epoch_0]_38511  loss=3.147758 |g|=0.435	lr=1.87e-04 | 54.8%@S32  T=1.79s(data=2.2ms QKV=2.11s FFN=3.04s) eta=11:12:45 | 41.8K token/s | 
[epoch_0]_38521  loss=3.153972 |g|=0.453	lr=1.87e-04 | 55.6%@S32  T=1.87s(data=2.0ms QKV=2.12s FFN=3.04s) eta=11:41:00 | 41.9K token/s | 
[epoch_0]_38531  loss=3.134435 |g|=0.449	lr=1.87e-04 | 56.5%@S32  T=1.87s(data=2.0ms QKV=2.12s FFN=3.04s) eta=11:42:02 | 42.0K token/s | 
[epoch_0]_38541  loss=3.216993 |g|=0.461	lr=1.87e-04 | 57.3%@S32  T=1.75s(data=1.6ms QKV=2.11s FFN=3.04s) eta=10:56:43 | 42.3K token/s | 
[epoch_0]_38551  loss=3.144950 |g|=0.441	lr=1.87e-04 | 58.1%@S32  T=1.79s(data=2.0ms QKV=2.12s FFN=3.04s) eta=11:09:23 | 42.5K token/s | 
[epoch_0]_38561  loss=3.172896 |g|=0.441	lr=1.87e-04 | 58.9%@S32  T=1.74s(data=1.8ms QKV=2.11s FFN=3.04s) eta=10:52:11 | 42.7K token/s | 
[epoch_0]_38571  loss=3.129677 |g|=0.445	lr=1.87e-04 | 59.7%@S32  T=1.87s(data=2.0ms QKV=2.12s FFN=3.04s) eta=11:38:55 | 42.7K token/s | 
[epoch_0]_38581  loss=3.202177 |g|=0.445	lr=1.86e-04 | 60.6%@S32  T=1.76s(data=1.8ms QKV=2.12s FFN=3.04s) eta=10:58:52 | 42.9K token/s | 
[epoch_0]_38591  loss=3.165730 |g|=0.481	lr=1.86e-04 | 61.4%@S32  T=1.93s(data=2.1ms QKV=2.12s FFN=3.04s) eta=12:01:58 | 42.9K token/s | 
[Fuyou] head="1" update algorithm=4 t=10.68s
[eval] 
	 Loss@"edu_fineweb1B"=3.159(0.0027) nBranch=1 nToken=6.31M best=3.1612(191) E2T=0.0371 T=36.7338(0)s x=0
	#3.15852±0.0972 tps=172K(6.30784M) a=[2.97284,3.42904] T=36.7338(sec)
[Section@38600] layer[16-24] tasks=19(nPassBack=0) last_loss=3.12141(0.0454028) N=(772,43904,43344 5095068)
[epoch_0]_38601  loss=3.103662 |g|=0.445	lr=1.86e-04 | 62.2%@S32  T=12.27s(data=2.2ms QKV=2.11s FFN=3.03s) eta=3d 04:27:30 | 41.1K token/s | 
[epoch_0]_38611  loss=3.140076 |g|=0.481	lr=1.86e-04 | 63.0%@S32  T=1.78s(data=2.4ms QKV=2.11s FFN=3.04s) eta=11:06:43 | 41.3K token/s | 
[epoch_0]_38621  loss=3.153696 |g|=0.458	lr=1.86e-04 | 63.8%@S32  T=1.74s(data=1.9ms QKV=2.11s FFN=3.04s) eta=10:48:11 | 41.6K token/s | 
[epoch_0]_38631  loss=3.147498 |g|=0.438	lr=1.86e-04 | 64.7%@S32  T=1.74s(data=2.0ms QKV=2.11s FFN=3.04s) eta=10:48:22 | 41.9K token/s | 
[epoch_0]_38641  loss=3.191819 |g|=0.469	lr=1.86e-04 | 65.5%@S32  T=1.77s(data=1.6ms QKV=2.11s FFN=3.04s) eta=11:01:03 | 42.1K token/s | 
[epoch_0]_38651  loss=3.166537 |g|=0.48	lr=1.85e-04 | 66.3%@S32  T=1.74s(data=1.8ms QKV=2.11s FFN=3.04s) eta=10:50:40 | 42.4K token/s | 
[epoch_0]_38661  loss=3.094138 |g|=0.447	lr=1.85e-04 | 67.1%@S32  T=2.00s(data=3.2ms QKV=2.12s FFN=3.04s) eta=12:24:06 | 42.3K token/s | 
[epoch_0]_38671  loss=3.225818 |g|=0.462	lr=1.85e-04 | 67.9%@S32  T=1.87s(data=2.2ms QKV=2.11s FFN=3.04s) eta=11:35:15 | 42.4K token/s | 
[epoch_0]_38681  loss=3.164201 |g|=0.453	lr=1.85e-04 | 68.8%@S32  T=1.76s(data=2.1ms QKV=2.11s FFN=3.04s) eta=10:54:32 | 42.6K token/s | 
[epoch_0]_38691  loss=3.142221 |g|=0.466	lr=1.85e-04 | 69.6%@S32  T=1.84s(data=2.1ms QKV=2.11s FFN=3.04s) eta=11:24:21 | 42.7K token/s | 
[Fuyou] head="2" update algorithm=4 t=12.59s
[Section@38700] layer[24-32] tasks=19(nPassBack=0) last_loss=3.16841(0.0128186) N=(772,44016,43456 5108268)
[epoch_0]_38701  loss=3.126980 |g|=0.432	lr=1.85e-04 | 70.4%@S32  T=4.61s(data=1.7ms QKV=2.11s FFN=3.03s) eta=1d 04:37:32 | 41.4K token/s | 
[epoch_0]_38711  loss=3.146479 |g|=0.448	lr=1.85e-04 | 71.2%@S32  T=1.77s(data=2.0ms QKV=2.12s FFN=3.04s) eta=10:58:33 | 41.7K token/s | 
[epoch_0]_38721  loss=3.151030 |g|=0.466	lr=1.84e-04 | 72.0%@S32  T=1.78s(data=1.7ms QKV=2.11s FFN=3.04s) eta=11:02:45 | 41.9K token/s | 
[epoch_0]_38731  loss=3.216884 |g|=0.457	lr=1.84e-04 | 72.9%@S32  T=1.83s(data=1.6ms QKV=2.11s FFN=3.04s) eta=11:19:08 | 42.1K token/s | 
[epoch_0]_38741  loss=3.128727 |g|=0.472	lr=1.84e-04 | 73.7%@S32  T=1.87s(data=2.1ms QKV=2.11s FFN=3.04s) eta=11:34:44 | 42.1K token/s | 
[epoch_0]_38751  loss=3.194391 |g|=0.437	lr=1.84e-04 | 74.5%@S32  T=1.87s(data=2.0ms QKV=2.12s FFN=3.04s) eta=11:35:18 | 42.2K token/s | 
[epoch_0]_38761  loss=3.045163 |g|=0.439	lr=1.84e-04 | 75.3%@S32  T=1.86s(data=1.7ms QKV=2.12s FFN=3.04s) eta=11:30:29 | 42.3K token/s | 
[epoch_0]_38771  loss=3.157754 |g|=0.446	lr=1.84e-04 | 76.1%@S32  T=1.85s(data=2.0ms QKV=2.12s FFN=3.04s) eta=11:26:33 | 42.4K token/s | 
[epoch_0]_38781  loss=3.214704 |g|=0.442	lr=1.84e-04 | 76.9%@S32  T=1.84s(data=1.8ms QKV=2.11s FFN=3.04s) eta=11:21:49 | 42.5K token/s | 
[epoch_0]_38791  loss=3.137829 |g|=0.446	lr=1.83e-04 | 77.8%@S32  T=1.87s(data=1.8ms QKV=2.12s FFN=3.04s) eta=11:32:16 | 42.6K token/s | 
[Fuyou] head="3" update algorithm=4 t=11.93s
[eval] 
	 Loss@"edu_fineweb1B"=3.156(0.0025) nBranch=1 nToken=6.31M best=3.1585(192) E2T=-0.009 T=36.7318(0)s x=0
	#3.15597±0.0966 tps=172K(6.30784M) a=[2.96901,3.43138] T=36.7318(sec)
[Section@38800] layer[32-40] tasks=19(nPassBack=0) last_loss=3.16497(0.0324647) N=(772,44128,43568 5121468)
[epoch_0]_38801  loss=3.157065 |g|=0.439	lr=1.83e-04 | 78.6%@S32  T=11.93s(data=4.5ms QKV=2.11s FFN=3.04s) eta=3d 01:41:57 | 40.8K token/s | 
[epoch_0]_38811  loss=3.055671 |g|=0.448	lr=1.83e-04 | 79.4%@S32  T=1.77s(data=2.0ms QKV=2.11s FFN=3.04s) eta=10:53:48 | 41.1K token/s | 
[epoch_0]_38821  loss=3.193841 |g|=0.441	lr=1.83e-04 | 80.2%@S32  T=1.75s(data=2.0ms QKV=2.11s FFN=3.04s) eta=10:47:24 | 41.4K token/s | 
[epoch_0]_38831  loss=3.147664 |g|=0.446	lr=1.83e-04 | 81.0%@S32  T=1.77s(data=2.1ms QKV=2.11s FFN=3.04s) eta=10:53:15 | 41.6K token/s | 
[epoch_0]_38841  loss=3.205466 |g|=0.457	lr=1.83e-04 | 81.9%@S32  T=1.76s(data=2.4ms QKV=2.11s FFN=3.04s) eta=10:52:07 | 41.9K token/s | 
[epoch_0]_38851  loss=3.193635 |g|=0.455	lr=1.83e-04 | 82.7%@S32  T=1.74s(data=1.9ms QKV=2.11s FFN=3.04s) eta=10:43:56 | 42.1K token/s | 
[epoch_0]_38861  loss=3.109550 |g|=0.494	lr=1.82e-04 | 83.5%@S32  T=1.75s(data=1.8ms QKV=2.11s FFN=3.04s) eta=10:45:37 | 42.4K token/s | 
[epoch_0]_38871  loss=3.186909 |g|=0.455	lr=1.82e-04 | 84.3%@S32  T=1.74s(data=2.0ms QKV=2.11s FFN=3.04s) eta=10:43:32 | 42.6K token/s | 
[epoch_0]_38881  loss=3.172650 |g|=0.456	lr=1.82e-04 | 85.1%@S32  T=1.77s(data=1.9ms QKV=2.11s FFN=3.04s) eta=10:54:25 | 42.8K token/s | 
[epoch_0]_38891  loss=3.149637 |g|=0.446	lr=1.82e-04 | 86.0%@S32  T=1.90s(data=2.0ms QKV=2.11s FFN=3.04s) eta=11:40:17 | 42.8K token/s | 
[Fuyou] head="4" update algorithm=4 t=12.00s
[Section@38900] layer[40-48] tasks=19(nPassBack=0) last_loss=3.12393(-0.0328171) N=(772,44240,43680 5134668)
[epoch_0]_38901  loss=3.143905 |g|=0.461	lr=1.82e-04 | 86.8%@S32  T=4.41s(data=3.5ms QKV=2.12s FFN=3.03s) eta=1d 03:06:07 | 41.6K token/s | 
[epoch_0]_38911  loss=3.228096 |g|=0.463	lr=1.82e-04 | 87.6%@S32  T=1.74s(data=1.7ms QKV=2.11s FFN=3.04s) eta=10:42:37 | 41.9K token/s | 
[epoch_0]_38921  loss=3.147801 |g|=0.48	lr=1.82e-04 | 88.4%@S32  T=1.74s(data=1.8ms QKV=2.11s FFN=3.04s) eta=10:42:23 | 42.1K token/s | 
[epoch_0]_38931  loss=3.140252 |g|=0.442	lr=1.81e-04 | 89.2%@S32  T=1.81s(data=1.9ms QKV=2.11s FFN=3.04s) eta=11:06:31 | 42.3K token/s | 
[epoch_0]_38941  loss=3.155127 |g|=0.446	lr=1.81e-04 | 90.1%@S32  T=1.89s(data=2.1ms QKV=2.12s FFN=3.04s) eta=11:35:05 | 42.3K token/s | 
[epoch_0]_38951  loss=3.215672 |g|=0.449	lr=1.81e-04 | 90.9%@S32  T=1.89s(data=2.2ms QKV=2.13s FFN=3.04s) eta=11:36:45 | 42.4K token/s | 
[epoch_0]_38961  loss=3.148383 |g|=0.444	lr=1.81e-04 | 91.7%@S32  T=1.77s(data=2.1ms QKV=2.12s FFN=3.04s) eta=10:52:50 | 42.6K token/s | 
[epoch_0]_38971  loss=3.193650 |g|=0.453	lr=1.81e-04 | 92.5%@S32  T=1.91s(data=2.1ms QKV=2.12s FFN=3.04s) eta=11:43:28 | 42.6K token/s | 
[epoch_0]_38981  loss=3.119834 |g|=0.431	lr=1.81e-04 | 93.3%@S32  T=1.75s(data=2.0ms QKV=2.12s FFN=3.04s) eta=10:44:44 | 42.8K token/s | 
[epoch_0]_38991  loss=3.158685 |g|=0.43	lr=1.81e-04 | 94.2%@S32  T=1.77s(data=1.6ms QKV=2.11s FFN=3.04s) eta=10:49:56 | 43.0K token/s | 
[Fuyou] head="5" update algorithm=4 t=12.34s
[eval] 
	 Loss@"edu_fineweb1B"=3.155(0.0015) nBranch=1 nToken=6.31M best=3.1560(193) E2T=-0.00856 T=36.7619(0)s x=0
	#3.1545±0.0969 tps=172K(6.30784M) a=[2.96969,3.43097] T=36.7619(sec)
[Section@39000] layer[0-8] tasks=19(nPassBack=0) last_loss=3.16306(-0.051887) N=(772,44352,43792 5147868)
[epoch_0]_39001  loss=3.096810 |g|=0.464	lr=1.80e-04 | 95.0%@S32  T=12.35s(data=2.4ms QKV=2.11s FFN=3.04s) eta=3d 03:34:16 | 41.1K token/s | 
[epoch_0]_39011  loss=3.123989 |g|=0.475	lr=1.80e-04 | 95.8%@S32  T=1.87s(data=2.5ms QKV=2.11s FFN=3.04s) eta=11:27:10 | 41.3K token/s | 
[epoch_0]_39021  loss=3.172318 |g|=0.464	lr=1.80e-04 | 96.6%@S32  T=1.83s(data=2.2ms QKV=2.11s FFN=3.04s) eta=11:12:55 | 41.4K token/s | 
[epoch_0]_39031  loss=3.181307 |g|=0.501	lr=1.80e-04 | 97.4%@S32  T=1.76s(data=2.3ms QKV=2.12s FFN=3.04s) eta=10:44:55 | 41.7K token/s | 
[epoch_0]_39041  loss=3.024499 |g|=0.455	lr=1.80e-04 | 98.2%@S32  T=1.89s(data=2.1ms QKV=2.11s FFN=3.04s) eta=11:32:56 | 41.8K token/s | 
[epoch_0]_39051  loss=3.093100 |g|=0.443	lr=1.80e-04 | 99.1%@S32  T=1.73s(data=1.8ms QKV=2.11s FFN=3.04s) eta=10:35:28 | 42.1K token/s | 
[epoch_0]_39061  loss=3.134434 |g|=0.443	lr=1.80e-04 | 99.9%@S32  T=1.75s(data=2.5ms QKV=2.11s FFN=3.04s) eta=10:40:11 | 42.3K token/s | 
[epoch_0]_39062  loss=3.163915 |g|=0.44	lr=1.80e-04 | 100.0%@S32  T=1.87s(data=2.4ms QKV=2.11s FFN=3.04s) eta=11:25:55 | 42.4K token/s | 
-------- End of shard_32@"./Datasets/edu_fineweb1B/edu_fineweb_train_000486.bin"-------- 
[shard-33]@"./Datasets/edu_fineweb1B/edu_fineweb_train_000487.bin": tokens=100(M) nShardSamples=1220(3222648) 
[epoch_0]_39071  loss=3.126179 |g|=0.48	lr=1.79e-04 | 0.7%@S33  T=1.75s(data=1.4ms QKV=2.11s FFN=3.04s) eta=10:42:26 | 42.6K token/s | 
[epoch_0]_39081  loss=3.124258 |g|=0.446	lr=1.79e-04 | 1.5%@S33  T=1.73s(data=1.5ms QKV=2.11s FFN=3.04s) eta=10:32:52 | 42.8K token/s | 
[epoch_0]_39091  loss=3.151858 |g|=0.434	lr=1.79e-04 | 2.3%@S33  T=1.82s(data=2.4ms QKV=2.11s FFN=3.04s) eta=11:05:33 | 42.9K token/s | 
[Fuyou] head="0" update algorithm=4 t=14.37s
[Section@39100] layer[8-16] tasks=19(nPassBack=0) last_loss=3.16025(0.0510323) N=(772,44464,43904 5161068)
[epoch_0]_39101  loss=3.181581 |g|=0.454	lr=1.79e-04 | 3.2%@S33  T=5.34s(data=1.8ms QKV=2.11s FFN=3.04s) eta=1d 08:33:22 | 41.6K token/s | 
[epoch_0]_39111  loss=3.155435 |g|=0.44	lr=1.79e-04 | 4.0%@S33  T=1.88s(data=2.3ms QKV=2.11s FFN=3.04s) eta=11:27:31 | 41.7K token/s | 
[epoch_0]_39121  loss=3.177938 |g|=0.425	lr=1.79e-04 | 4.8%@S33  T=1.94s(data=2.2ms QKV=2.11s FFN=3.04s) eta=11:48:14 | 41.7K token/s | 
[epoch_0]_39131  loss=3.142028 |g|=0.451	lr=1.79e-04 | 5.6%@S33  T=1.89s(data=2.3ms QKV=2.12s FFN=3.04s) eta=11:28:22 | 41.8K token/s | 
[epoch_0]_39141  loss=3.194645 |g|=0.431	lr=1.78e-04 | 6.4%@S33  T=1.85s(data=2.1ms QKV=2.12s FFN=3.04s) eta=11:14:13 | 41.9K token/s | 
[epoch_0]_39151  loss=3.165776 |g|=0.452	lr=1.78e-04 | 7.3%@S33  T=1.82s(data=1.9ms QKV=2.11s FFN=3.04s) eta=11:04:45 | 42.0K token/s | 
[epoch_0]_39161  loss=3.151062 |g|=0.443	lr=1.78e-04 | 8.1%@S33  T=1.76s(data=2.4ms QKV=2.11s FFN=3.04s) eta=10:39:59 | 42.3K token/s | 
[epoch_0]_39171  loss=3.136424 |g|=0.44	lr=1.78e-04 | 8.9%@S33  T=1.76s(data=1.9ms QKV=2.11s FFN=3.04s) eta=10:42:36 | 42.5K token/s | 
[epoch_0]_39181  loss=3.213935 |g|=0.427	lr=1.78e-04 | 9.7%@S33  T=1.79s(data=1.8ms QKV=2.12s FFN=3.04s) eta=10:50:38 | 42.7K token/s | 
[epoch_0]_39191  loss=3.207574 |g|=0.463	lr=1.78e-04 | 10.5%@S33  T=1.76s(data=1.6ms QKV=2.12s FFN=3.04s) eta=10:40:41 | 42.9K token/s | 
[Fuyou] head="1" update algorithm=4 t=13.01s
[eval] 
	 Loss@"edu_fineweb1B"=3.155(-0.00034) nBranch=1 nToken=6.31M best=3.1545(194) E2T=-0.00199 T=36.7846(0)s x=0
	#3.15484±0.0974 tps=171K(6.30784M) a=[2.96544,3.43068] T=36.7846(sec)
[Section@39200] layer[16-24] tasks=19(nPassBack=0) last_loss=3.15683(-0.0354187) N=(772,44576,44016 5174268)
[epoch_0]_39201  loss=3.158863 |g|=0.434	lr=1.78e-04 | 11.4%@S33  T=13.24s(data=2.3ms QKV=2.11s FFN=3.04s) eta=3d 08:19:06 | 41.0K token/s | 
[epoch_0]_39211  loss=3.164466 |g|=0.453	lr=1.77e-04 | 12.2%@S33  T=1.72s(data=2.1ms QKV=2.11s FFN=3.04s) eta=10:24:00 | 41.4K token/s | 
[epoch_0]_39221  loss=3.096701 |g|=0.437	lr=1.77e-04 | 13.0%@S33  T=1.74s(data=2.1ms QKV=2.11s FFN=3.04s) eta=10:32:03 | 41.6K token/s | 
[epoch_0]_39231  loss=3.190226 |g|=0.456	lr=1.77e-04 | 13.8%@S33  T=1.93s(data=2.1ms QKV=2.12s FFN=3.04s) eta=11:41:21 | 41.7K token/s | 
[epoch_0]_39241  loss=3.133394 |g|=0.44	lr=1.77e-04 | 14.6%@S33  T=1.76s(data=2.2ms QKV=2.11s FFN=3.04s) eta=10:38:47 | 41.9K token/s | 
[epoch_0]_39251  loss=3.142561 |g|=0.475	lr=1.77e-04 | 15.5%@S33  T=1.91s(data=2.1ms QKV=2.11s FFN=3.04s) eta=11:34:50 | 42.0K token/s | 
[epoch_0]_39261  loss=3.127930 |g|=0.455	lr=1.77e-04 | 16.3%@S33  T=1.73s(data=1.9ms QKV=2.11s FFN=3.04s) eta=10:27:44 | 42.2K token/s | 
[epoch_0]_39271  loss=3.201743 |g|=0.46	lr=1.77e-04 | 17.1%@S33  T=1.78s(data=2.0ms QKV=2.12s FFN=3.04s) eta=10:46:26 | 42.4K token/s | 
[epoch_0]_39281  loss=3.113925 |g|=0.461	lr=1.77e-04 | 17.9%@S33  T=1.76s(data=1.7ms QKV=2.11s FFN=3.04s) eta=10:38:49 | 42.6K token/s | 
[epoch_0]_39291  loss=3.262156 |g|=0.464	lr=1.76e-04 | 18.7%@S33  T=1.84s(data=1.8ms QKV=2.11s FFN=3.04s) eta=11:07:44 | 42.7K token/s | 
[Fuyou] head="2" update algorithm=4 t=14.30s
[Section@39300] layer[24-32] tasks=19(nPassBack=0) last_loss=3.20032(-0.0319142) N=(772,44688,44128 5187468)
[epoch_0]_39301  loss=3.182617 |g|=0.447	lr=1.76e-04 | 19.5%@S33  T=5.10s(data=2.5ms QKV=2.11s FFN=3.03s) eta=1d 06:46:39 | 41.4K token/s | 
[epoch_0]_39311  loss=3.107422 |g|=0.452	lr=1.76e-04 | 20.4%@S33  T=1.74s(data=2.1ms QKV=2.12s FFN=3.04s) eta=10:28:20 | 41.7K token/s | 
[epoch_0]_39321  loss=3.173561 |g|=0.452	lr=1.76e-04 | 21.2%@S33  T=1.82s(data=2.4ms QKV=2.12s FFN=3.04s) eta=11:00:18 | 41.8K token/s | 
[epoch_0]_39331  loss=3.124156 |g|=0.448	lr=1.76e-04 | 22.0%@S33  T=1.77s(data=2.1ms QKV=2.12s FFN=3.04s) eta=10:39:17 | 42.1K token/s | 
[epoch_0]_39341  loss=3.150709 |g|=0.467	lr=1.76e-04 | 22.8%@S33  T=1.74s(data=3.4ms QKV=2.12s FFN=3.04s) eta=10:28:43 | 42.3K token/s | 
[epoch_0]_39351  loss=3.162102 |g|=0.433	lr=1.76e-04 | 23.6%@S33  T=1.79s(data=2.1ms QKV=2.12s FFN=3.04s) eta=10:45:56 | 42.5K token/s | 
[epoch_0]_39361  loss=3.190759 |g|=0.452	lr=1.75e-04 | 24.5%@S33  T=1.86s(data=2.5ms QKV=2.12s FFN=3.04s) eta=11:13:04 | 42.6K token/s | 
[epoch_0]_39371  loss=3.176002 |g|=0.464	lr=1.75e-04 | 25.3%@S33  T=1.84s(data=2.1ms QKV=2.12s FFN=3.04s) eta=11:05:55 | 42.7K token/s | 
[epoch_0]_39381  loss=3.236929 |g|=0.472	lr=1.75e-04 | 26.1%@S33  T=1.73s(data=2.3ms QKV=2.12s FFN=3.04s) eta=10:23:54 | 42.9K token/s | 
[epoch_0]_39391  loss=3.168255 |g|=0.439	lr=1.75e-04 | 26.9%@S33  T=1.73s(data=2.2ms QKV=2.12s FFN=3.04s) eta=10:25:44 | 43.1K token/s | 
[Fuyou] head="3" update algorithm=4 t=14.34s
[eval] 
	 Loss@"edu_fineweb1B"=3.156(-0.00077) nBranch=1 nToken=6.31M best=3.1545(194) E2T=0.0198 T=36.7386(0)s x=0
	#3.15561±0.0972 tps=172K(6.30784M) a=[2.96647,3.4304] T=36.7386(sec)
[Section@39400] layer[32-40] tasks=19(nPassBack=0) last_loss=3.13583(0.0291367) N=(772,44800,44240 5200668)
[epoch_0]_39401  loss=3.134235 |g|=0.429	lr=1.75e-04 | 27.7%@S33  T=12.90s(data=2.8ms QKV=2.11s FFN=3.04s) eta=3d 05:32:19 | 41.3K token/s | 
[epoch_0]_39411  loss=3.171303 |g|=0.447	lr=1.75e-04 | 28.6%@S33  T=1.74s(data=2.1ms QKV=2.11s FFN=3.04s) eta=10:27:22 | 41.6K token/s | 
[epoch_0]_39421  loss=3.177023 |g|=0.441	lr=1.75e-04 | 29.4%@S33  T=2.00s(data=1.9ms QKV=2.12s FFN=3.04s) eta=11:58:56 | 41.5K token/s | 
[epoch_0]_39431  loss=3.261047 |g|=0.451	lr=1.74e-04 | 30.2%@S33  T=1.74s(data=2.5ms QKV=2.11s FFN=3.04s) eta=10:26:36 | 41.8K token/s | 
[epoch_0]_39441  loss=3.151512 |g|=0.444	lr=1.74e-04 | 31.0%@S33  T=1.98s(data=2.1ms QKV=2.12s FFN=3.04s) eta=11:51:03 | 41.8K token/s | 
[epoch_0]_39451  loss=3.212021 |g|=0.45	lr=1.74e-04 | 31.8%@S33  T=1.98s(data=6.0ms QKV=2.14s FFN=3.04s) eta=11:50:45 | 41.8K token/s | 
[epoch_0]_39461  loss=3.189602 |g|=0.454	lr=1.74e-04 | 32.7%@S33  T=1.80s(data=2.0ms QKV=2.12s FFN=3.04s) eta=10:48:41 | 42.0K token/s | 
[epoch_0]_39471  loss=3.080244 |g|=0.455	lr=1.74e-04 | 33.5%@S33  T=1.94s(data=2.1ms QKV=2.12s FFN=3.04s) eta=11:38:16 | 42.0K token/s | 
[epoch_0]_39481  loss=3.082664 |g|=0.465	lr=1.74e-04 | 34.3%@S33  T=1.82s(data=2.2ms QKV=2.12s FFN=3.04s) eta=10:54:19 | 42.1K token/s | 
[epoch_0]_39491  loss=3.065972 |g|=0.458	lr=1.74e-04 | 35.1%@S33  T=1.80s(data=2.0ms QKV=2.13s FFN=3.04s) eta=10:45:48 | 42.3K token/s | 
[Fuyou] head="4" update algorithm=4 t=12.24s
[Section@39500] layer[40-48] tasks=19(nPassBack=0) last_loss=3.13115(-0.00722265) N=(772,44912,44352 5213868)
[epoch_0]_39501  loss=3.190882 |g|=0.44	lr=1.73e-04 | 35.9%@S33  T=4.30s(data=2.0ms QKV=2.11s FFN=3.03s) eta=1d 01:43:00 | 41.1K token/s | 
[epoch_0]_39511  loss=3.178174 |g|=0.453	lr=1.73e-04 | 36.8%@S33  T=1.76s(data=1.9ms QKV=2.12s FFN=3.04s) eta=10:32:27 | 41.4K token/s | 
[epoch_0]_39521  loss=3.224075 |g|=0.479	lr=1.73e-04 | 37.6%@S33  T=1.73s(data=1.9ms QKV=2.12s FFN=3.04s) eta=10:21:06 | 41.7K token/s | 
[epoch_0]_39531  loss=3.179257 |g|=0.511	lr=1.73e-04 | 38.4%@S33  T=1.74s(data=1.7ms QKV=2.12s FFN=3.04s) eta=10:22:51 | 42.0K token/s | 
[epoch_0]_39541  loss=3.136636 |g|=0.463	lr=1.73e-04 | 39.2%@S33  T=1.89s(data=2.0ms QKV=2.12s FFN=3.04s) eta=11:17:45 | 42.0K token/s | 
[epoch_0]_39551  loss=3.182514 |g|=0.451	lr=1.73e-04 | 40.0%@S33  T=1.87s(data=1.8ms QKV=2.12s FFN=3.04s) eta=11:11:04 | 42.1K token/s | 
[epoch_0]_39561  loss=3.217288 |g|=0.468	lr=1.73e-04 | 40.8%@S33  T=1.94s(data=2.0ms QKV=2.12s FFN=3.04s) eta=11:35:04 | 42.1K token/s | 
[epoch_0]_39571  loss=3.129870 |g|=0.427	lr=1.72e-04 | 41.7%@S33  T=1.83s(data=2.1ms QKV=2.12s FFN=3.04s) eta=10:53:55 | 42.3K token/s | 
[epoch_0]_39581  loss=3.194666 |g|=0.449	lr=1.72e-04 | 42.5%@S33  T=1.90s(data=1.9ms QKV=2.12s FFN=3.05s) eta=11:20:02 | 42.3K token/s | 
[epoch_0]_39591  loss=3.133824 |g|=0.443	lr=1.72e-04 | 43.3%@S33  T=1.91s(data=2.4ms QKV=2.12s FFN=3.04s) eta=11:23:16 | 42.3K token/s | 
[Fuyou] head="5" update algorithm=4 t=12.74s
[eval] 
	 Loss@"edu_fineweb1B"=3.155(0.00058) nBranch=1 nToken=6.31M best=3.1545(194) E2T=-0.0208 T=36.6998(0)s x=0
	#3.15503±0.0973 tps=172K(6.30784M) a=[2.96923,3.43228] T=36.6998(sec)
[Section@39600] layer[0-8] tasks=19(nPassBack=0) last_loss=3.1758(-0.0127437) N=(772,45024,44464 5227068)
[epoch_0]_39601  loss=3.138500 |g|=0.452	lr=1.72e-04 | 44.1%@S33  T=12.44s(data=2.6ms QKV=2.11s FFN=3.04s) eta=3d 02:03:19 | 40.5K token/s | 
[epoch_0]_39611  loss=3.112723 |g|=0.463	lr=1.72e-04 | 44.9%@S33  T=1.79s(data=2.2ms QKV=2.12s FFN=3.04s) eta=10:38:41 | 40.8K token/s | 
[epoch_0]_39621  loss=3.178007 |g|=0.451	lr=1.72e-04 | 45.8%@S33  T=1.74s(data=1.8ms QKV=2.11s FFN=3.04s) eta=10:21:00 | 41.1K token/s | 
[epoch_0]_39631  loss=3.190942 |g|=0.441	lr=1.72e-04 | 46.6%@S33  T=1.89s(data=2.0ms QKV=2.12s FFN=3.04s) eta=11:13:15 | 41.2K token/s | 
[epoch_0]_39641  loss=3.109578 |g|=0.45	lr=1.72e-04 | 47.4%@S33  T=1.89s(data=2.1ms QKV=2.12s FFN=3.04s) eta=11:13:33 | 41.3K token/s | 
[epoch_0]_39651  loss=3.145104 |g|=0.44	lr=1.71e-04 | 48.2%@S33  T=1.93s(data=1.9ms QKV=2.12s FFN=3.04s) eta=11:26:12 | 41.4K token/s | 
[epoch_0]_39661  loss=3.071727 |g|=0.452	lr=1.71e-04 | 49.0%@S33  T=1.92s(data=2.2ms QKV=2.12s FFN=3.04s) eta=11:24:51 | 41.5K token/s | 
[epoch_0]_39671  loss=3.141666 |g|=0.481	lr=1.71e-04 | 49.9%@S33  T=1.74s(data=1.8ms QKV=2.12s FFN=3.04s) eta=10:18:43 | 41.7K token/s | 
[epoch_0]_39681  loss=3.104443 |g|=0.455	lr=1.71e-04 | 50.7%@S33  T=1.85s(data=2.0ms QKV=2.12s FFN=3.04s) eta=10:56:46 | 41.9K token/s | 
[epoch_0]_39691  loss=3.181365 |g|=0.443	lr=1.71e-04 | 51.5%@S33  T=1.89s(data=2.1ms QKV=2.12s FFN=3.04s) eta=11:13:10 | 41.9K token/s | 
[Fuyou] head="0" update algorithm=4 t=12.04s
[Section@39700] layer[8-16] tasks=19(nPassBack=0) last_loss=3.18903(-0.0287762) N=(772,45136,44576 5240268)
[epoch_0]_39701  loss=3.116469 |g|=0.443	lr=1.71e-04 | 52.3%@S33  T=4.67s(data=1.9ms QKV=2.12s FFN=3.03s) eta=1d 03:41:19 | 40.7K token/s | 
[epoch_0]_39711  loss=3.171490 |g|=0.438	lr=1.71e-04 | 53.1%@S33  T=1.88s(data=2.1ms QKV=2.12s FFN=3.04s) eta=11:08:01 | 40.9K token/s | 
[epoch_0]_39721  loss=3.145789 |g|=0.493	lr=1.70e-04 | 54.0%@S33  T=1.78s(data=6.5ms QKV=2.12s FFN=3.04s) eta=10:32:06 | 41.1K token/s | 
[epoch_0]_39731  loss=3.139824 |g|=0.459	lr=1.70e-04 | 54.8%@S33  T=1.76s(data=1.6ms QKV=2.12s FFN=3.04s) eta=10:26:16 | 41.4K token/s | 
[epoch_0]_39741  loss=3.169960 |g|=0.461	lr=1.70e-04 | 55.6%@S33  T=1.94s(data=2.0ms QKV=2.12s FFN=3.04s) eta=11:30:03 | 41.4K token/s | 
[epoch_0]_39751  loss=3.191549 |g|=0.46	lr=1.70e-04 | 56.4%@S33  T=1.88s(data=1.8ms QKV=2.12s FFN=3.04s) eta=11:08:02 | 41.5K token/s | 
[epoch_0]_39761  loss=3.112779 |g|=0.457	lr=1.70e-04 | 57.2%@S33  T=1.87s(data=2.0ms QKV=2.13s FFN=3.04s) eta=11:01:32 | 41.7K token/s | 
[epoch_0]_39771  loss=3.153892 |g|=0.443	lr=1.70e-04 | 58.0%@S33  T=1.74s(data=1.6ms QKV=2.12s FFN=3.04s) eta=10:18:16 | 41.9K token/s | 
[epoch_0]_39781  loss=3.196133 |g|=0.471	lr=1.70e-04 | 58.9%@S33  T=1.74s(data=1.9ms QKV=2.12s FFN=3.04s) eta=10:16:02 | 42.2K token/s | 
[epoch_0]_39791  loss=3.085258 |g|=0.432	lr=1.69e-04 | 59.7%@S33  T=1.86s(data=1.7ms QKV=2.12s FFN=3.04s) eta=10:58:56 | 42.3K token/s | 
[Fuyou] head="1" update algorithm=4 t=13.67s
[eval] 
	 Loss@"edu_fineweb1B"=3.154(0.00095) nBranch=1 nToken=6.31M best=3.1550(197) E2T=0.0314 T=36.7069(0)s x=0
	#3.15407±0.0975 tps=172K(6.30784M) a=[2.96558,3.43025] T=36.7069(sec)
[Section@39800] layer[16-24] tasks=19(nPassBack=0) last_loss=3.12271(0.0341158) N=(772,45248,44688 5253468)
[epoch_0]_39801  loss=3.226290 |g|=0.44	lr=1.69e-04 | 60.5%@S33  T=12.45s(data=2.2ms QKV=2.11s FFN=3.03s) eta=3d 01:25:46 | 40.5K token/s | 
[epoch_0]_39811  loss=3.224913 |g|=0.449	lr=1.69e-04 | 61.3%@S33  T=1.74s(data=1.9ms QKV=2.11s FFN=3.04s) eta=10:16:50 | 40.8K token/s | 
[epoch_0]_39821  loss=3.219749 |g|=0.462	lr=1.69e-04 | 62.1%@S33  T=1.74s(data=2.0ms QKV=2.11s FFN=3.04s) eta=10:15:47 | 41.1K token/s | 
[epoch_0]_39831  loss=3.240654 |g|=0.468	lr=1.69e-04 | 63.0%@S33  T=1.78s(data=1.9ms QKV=2.11s FFN=3.04s) eta=10:28:21 | 41.4K token/s | 
[epoch_0]_39841  loss=3.126564 |g|=0.443	lr=1.69e-04 | 63.8%@S33  T=1.89s(data=2.1ms QKV=2.12s FFN=3.04s) eta=11:05:53 | 41.5K token/s | 
[epoch_0]_39851  loss=3.174883 |g|=0.462	lr=1.69e-04 | 64.6%@S33  T=1.75s(data=2.1ms QKV=2.11s FFN=3.04s) eta=10:19:22 | 41.7K token/s | 
[epoch_0]_39861  loss=3.074447 |g|=0.458	lr=1.68e-04 | 65.4%@S33  T=1.76s(data=1.9ms QKV=2.11s FFN=3.04s) eta=10:19:28 | 42.0K token/s | 
[epoch_0]_39871  loss=3.096521 |g|=0.448	lr=1.68e-04 | 66.2%@S33  T=1.97s(data=2.3ms QKV=2.12s FFN=3.04s) eta=11:34:07 | 42.0K token/s | 
[epoch_0]_39881  loss=3.192199 |g|=0.488	lr=1.68e-04 | 67.1%@S33  T=1.78s(data=1.8ms QKV=2.11s FFN=3.04s) eta=10:26:20 | 42.2K token/s | 
[epoch_0]_39891  loss=3.145411 |g|=0.483	lr=1.68e-04 | 67.9%@S33  T=1.89s(data=2.2ms QKV=2.12s FFN=3.04s) eta=11:05:39 | 42.2K token/s | 
[Fuyou] head="2" update algorithm=4 t=11.39s
[Section@39900] layer[24-32] tasks=19(nPassBack=0) last_loss=3.13489(0.0654299) N=(772,45360,44800 5266668)
[epoch_0]_39901  loss=3.245830 |g|=0.462	lr=1.68e-04 | 68.7%@S33  T=4.35s(data=2.0ms QKV=2.11s FFN=3.03s) eta=1d 01:30:49 | 41.1K token/s | 
[epoch_0]_39911  loss=3.156589 |g|=0.466	lr=1.68e-04 | 69.5%@S33  T=1.85s(data=2.0ms QKV=2.12s FFN=3.04s) eta=10:49:34 | 41.2K token/s | 
[epoch_0]_39921  loss=3.153178 |g|=0.453	lr=1.68e-04 | 70.3%@S33  T=1.93s(data=1.9ms QKV=2.11s FFN=3.04s) eta=11:19:31 | 41.3K token/s | 
[epoch_0]_39931  loss=3.132142 |g|=0.481	lr=1.68e-04 | 71.2%@S33  T=1.93s(data=2.0ms QKV=2.12s FFN=3.04s) eta=11:20:24 | 41.3K token/s | 
[epoch_0]_39941  loss=3.152628 |g|=0.453	lr=1.67e-04 | 72.0%@S33  T=1.74s(data=2.0ms QKV=2.12s FFN=3.04s) eta=10:13:01 | 41.6K token/s | 
[epoch_0]_39951  loss=3.155823 |g|=0.461	lr=1.67e-04 | 72.8%@S33  T=1.82s(data=2.0ms QKV=2.12s FFN=3.04s) eta=10:40:11 | 41.8K token/s | 
[epoch_0]_39961  loss=3.090523 |g|=0.435	lr=1.67e-04 | 73.6%@S33  T=1.79s(data=2.0ms QKV=2.12s FFN=3.04s) eta=10:27:24 | 42.0K token/s | 
[epoch_0]_39971  loss=3.153725 |g|=0.465	lr=1.67e-04 | 74.4%@S33  T=1.92s(data=2.1ms QKV=2.12s FFN=3.04s) eta=11:15:38 | 42.0K token/s | 
[epoch_0]_39981  loss=3.155020 |g|=0.451	lr=1.67e-04 | 75.3%@S33  T=1.88s(data=2.2ms QKV=2.12s FFN=3.04s) eta=11:00:28 | 42.1K token/s | 
[epoch_0]_39991  loss=3.136165 |g|=0.44	lr=1.67e-04 | 76.1%@S33  T=1.78s(data=1.7ms QKV=2.12s FFN=3.04s) eta=10:24:37 | 42.3K token/s | 
[Fuyou] head="3" update algorithm=4 t=11.84s
[eval] 
	 Loss@"edu_fineweb1B"=3.153(0.001) nBranch=1 nToken=6.31M best=3.1541(198) E2T=0.00403 T=36.731(0)s x=0
	#3.15307±0.0974 tps=172K(6.30784M) a=[2.96649,3.43174] T=36.731(sec)
[Section@40000] layer[32-40] tasks=19(nPassBack=0) last_loss=3.14904(-0.0132096) N=(772,45472,44912 5279868)
[epoch_0]_40001  loss=3.032924 |g|=0.437	lr=1.67e-04 | 76.9%@S33  T=11.89s(data=3.7ms QKV=2.12s FFN=3.04s) eta=2d 21:27:50 | 40.5K token/s | 
[epoch_0]_40011  loss=3.043818 |g|=0.433	lr=1.66e-04 | 77.7%@S33  T=1.74s(data=1.6ms QKV=2.11s FFN=3.04s) eta=10:09:59 | 40.8K token/s | 
[epoch_0]_40021  loss=3.156152 |g|=0.456	lr=1.66e-04 | 78.5%@S33  T=1.76s(data=1.6ms QKV=2.11s FFN=3.04s) eta=10:17:45 | 41.1K token/s | 
[epoch_0]_40031  loss=3.157880 |g|=0.458	lr=1.66e-04 | 79.3%@S33  T=1.74s(data=1.7ms QKV=2.11s FFN=3.04s) eta=10:10:44 | 41.4K token/s | 
[epoch_0]_40041  loss=3.148294 |g|=0.459	lr=1.66e-04 | 80.2%@S33  T=1.79s(data=1.9ms QKV=2.11s FFN=3.04s) eta=10:24:37 | 41.6K token/s | 
[epoch_0]_40051  loss=3.238524 |g|=0.476	lr=1.66e-04 | 81.0%@S33  T=1.75s(data=1.9ms QKV=2.11s FFN=3.04s) eta=10:13:09 | 41.9K token/s | 
[epoch_0]_40061  loss=3.168961 |g|=0.444	lr=1.66e-04 | 81.8%@S33  T=1.88s(data=2.2ms QKV=2.13s FFN=3.04s) eta=10:56:08 | 42.0K token/s | 
[epoch_0]_40071  loss=3.237665 |g|=0.457	lr=1.66e-04 | 82.6%@S33  T=1.88s(data=1.8ms QKV=2.11s FFN=3.04s) eta=10:55:44 | 42.1K token/s | 
[epoch_0]_40081  loss=3.190890 |g|=0.458	lr=1.65e-04 | 83.4%@S33  T=1.95s(data=2.1ms QKV=2.12s FFN=3.04s) eta=11:21:00 | 42.1K token/s | 
[epoch_0]_40091  loss=3.209488 |g|=0.461	lr=1.65e-04 | 84.3%@S33  T=1.91s(data=2.1ms QKV=2.12s FFN=3.04s) eta=11:05:49 | 42.1K token/s | 
[Fuyou] head="4" update algorithm=4 t=13.01s
[Section@40100] layer[40-48] tasks=19(nPassBack=0) last_loss=3.16196(-0.0308042) N=(772,45584,45024 5293068)
[epoch_0]_40101  loss=3.163527 |g|=0.447	lr=1.65e-04 | 85.1%@S33  T=4.48s(data=2.0ms QKV=2.12s FFN=3.03s) eta=1d 02:02:21 | 40.9K token/s | 
[epoch_0]_40111  loss=3.042487 |g|=0.46	lr=1.65e-04 | 85.9%@S33  T=1.93s(data=2.0ms QKV=2.13s FFN=3.04s) eta=11:13:15 | 41.0K token/s | 
[epoch_0]_40121  loss=3.230029 |g|=0.439	lr=1.65e-04 | 86.7%@S33  T=1.77s(data=2.1ms QKV=2.12s FFN=3.04s) eta=10:15:16 | 41.3K token/s | 
[epoch_0]_40131  loss=3.085502 |g|=0.451	lr=1.65e-04 | 87.5%@S33  T=1.93s(data=2.2ms QKV=2.13s FFN=3.04s) eta=11:12:33 | 41.3K token/s | 
[epoch_0]_40141  loss=3.161793 |g|=0.437	lr=1.65e-04 | 88.4%@S33  T=1.99s(data=2.1ms QKV=2.13s FFN=3.04s) eta=11:31:17 | 41.3K token/s | 
[epoch_0]_40151  loss=3.238925 |g|=0.473	lr=1.64e-04 | 89.2%@S33  T=1.74s(data=1.8ms QKV=2.12s FFN=3.04s) eta=10:04:30 | 41.6K token/s | 
[epoch_0]_40161  loss=3.140323 |g|=0.448	lr=1.64e-04 | 90.0%@S33  T=1.98s(data=2.0ms QKV=2.14s FFN=3.04s) eta=11:28:54 | 41.6K token/s | 
[epoch_0]_40171  loss=3.155359 |g|=0.447	lr=1.64e-04 | 90.8%@S33  T=1.94s(data=2.1ms QKV=2.14s FFN=3.04s) eta=11:13:56 | 41.6K token/s | 
[epoch_0]_40181  loss=3.100748 |g|=0.432	lr=1.64e-04 | 91.6%@S33  T=1.90s(data=2.1ms QKV=2.13s FFN=3.04s) eta=11:00:58 | 41.7K token/s | 
[epoch_0]_40191  loss=3.016356 |g|=0.468	lr=1.64e-04 | 92.5%@S33  T=1.92s(data=1.7ms QKV=2.13s FFN=3.04s) eta=11:08:18 | 41.8K token/s | 
[Fuyou] head="5" update algorithm=4 t=12.23s
[eval] 
	 Loss@"edu_fineweb1B"=3.154(-0.00055) nBranch=1 nToken=6.31M best=3.1531(199) E2T=0.0634 T=36.7345(0)s x=0
	#3.15362±0.0980 tps=172K(6.30784M) a=[2.9668,3.43477] T=36.7345(sec)
[Section@40200] layer[0-8] tasks=19(nPassBack=0) last_loss=3.09019(0.0856152) N=(772,45696,45136 5306268)
[epoch_0]_40201  loss=3.142575 |g|=0.47	lr=1.64e-04 | 93.3%@S33  T=12.45s(data=2.0ms QKV=2.12s FFN=3.04s) eta=3d 00:03:51 | 40.0K token/s | 
[epoch_0]_40211  loss=3.122968 |g|=0.454	lr=1.64e-04 | 94.1%@S33  T=1.93s(data=2.1ms QKV=2.12s FFN=3.04s) eta=11:09:31 | 40.1K token/s | 
[epoch_0]_40221  loss=3.105291 |g|=0.481	lr=1.64e-04 | 94.9%@S33  T=1.74s(data=1.7ms QKV=2.12s FFN=3.04s) eta=10:04:28 | 40.5K token/s | 
[epoch_0]_40231  loss=3.173245 |g|=0.494	lr=1.63e-04 | 95.7%@S33  T=1.97s(data=2.3ms QKV=2.12s FFN=3.04s) eta=11:22:39 | 40.5K token/s | 
[epoch_0]_40241  loss=3.158358 |g|=0.452	lr=1.63e-04 | 96.6%@S33  T=2.00s(data=2.4ms QKV=2.13s FFN=3.04s) eta=11:32:36 | 40.5K token/s | 
[epoch_0]_40251  loss=3.188425 |g|=0.465	lr=1.63e-04 | 97.4%@S33  T=1.79s(data=2.1ms QKV=2.12s FFN=3.04s) eta=10:20:54 | 40.8K token/s | 
[epoch_0]_40261  loss=3.191441 |g|=0.462	lr=1.63e-04 | 98.2%@S33  T=2.00s(data=2.1ms QKV=2.13s FFN=3.04s) eta=11:33:42 | 40.8K token/s | 
[epoch_0]_40271  loss=3.166584 |g|=0.473	lr=1.63e-04 | 99.0%@S33  T=1.97s(data=2.2ms QKV=2.13s FFN=3.04s) eta=11:22:05 | 40.8K token/s | 
[epoch_0]_40281  loss=3.176754 |g|=0.479	lr=1.63e-04 | 99.8%@S33  T=2.01s(data=2.1ms QKV=2.12s FFN=3.04s) eta=11:34:25 | 40.8K token/s | 
[epoch_0]_40283  loss=3.087408 |g|=0.441	lr=1.63e-04 | 100.0%@S33  T=2.04s(data=2.1ms QKV=2.14s FFN=3.04s) eta=11:45:19 | 40.8K token/s | 
-------- End of shard_33@"./Datasets/edu_fineweb1B/edu_fineweb_train_000487.bin"-------- 
[shard-34]@"./Datasets/edu_fineweb1B/edu_fineweb_train_000792.bin": tokens=100(M) nShardSamples=1220(3320304) 
[epoch_0]_40291  loss=3.116773 |g|=0.462	lr=1.63e-04 | 0.6%@S34  T=1.96s(data=1.7ms QKV=2.12s FFN=3.04s) eta=11:16:39 | 40.9K token/s | 
[Fuyou] head="0" update algorithm=4 t=11.95s
[Section@40300] layer[8-16] tasks=19(nPassBack=0) last_loss=3.13069(0.0583439) N=(772,45808,45248 5319468)
[epoch_0]_40301  loss=3.119729 |g|=0.444	lr=1.62e-04 | 1.5%@S34  T=4.77s(data=2.0ms QKV=2.13s FFN=3.03s) eta=1d 03:29:33 | 39.7K token/s | 
[epoch_0]_40311  loss=3.102383 |g|=0.453	lr=1.62e-04 | 2.3%@S34  T=1.83s(data=1.8ms QKV=2.13s FFN=3.04s) eta=10:32:52 | 39.9K token/s | 
[epoch_0]_40321  loss=3.107368 |g|=0.474	lr=1.62e-04 | 3.1%@S34  T=1.90s(data=1.7ms QKV=2.13s FFN=3.04s) eta=10:56:36 | 40.1K token/s | 
[epoch_0]_40331  loss=3.074829 |g|=0.441	lr=1.62e-04 | 3.9%@S34  T=1.74s(data=1.6ms QKV=2.13s FFN=3.04s) eta=09:59:46 | 40.4K token/s | 
[epoch_0]_40341  loss=3.150876 |g|=0.463	lr=1.62e-04 | 4.7%@S34  T=1.73s(data=1.6ms QKV=2.13s FFN=3.04s) eta=09:57:33 | 40.8K token/s | 
[epoch_0]_40351  loss=3.095032 |g|=0.496	lr=1.62e-04 | 5.6%@S34  T=1.99s(data=3.3ms QKV=2.14s FFN=3.04s) eta=11:26:36 | 40.8K token/s | 
[epoch_0]_40361  loss=3.115141 |g|=0.44	lr=1.62e-04 | 6.4%@S34  T=1.73s(data=1.5ms QKV=2.13s FFN=3.04s) eta=09:57:02 | 41.1K token/s | 
[epoch_0]_40371  loss=3.104515 |g|=0.469	lr=1.61e-04 | 7.2%@S34  T=2.00s(data=2.2ms QKV=2.14s FFN=3.04s) eta=11:27:35 | 41.1K token/s | 
[epoch_0]_40381  loss=3.162432 |g|=0.469	lr=1.61e-04 | 8.0%@S34  T=1.86s(data=1.6ms QKV=2.13s FFN=3.04s) eta=10:40:14 | 41.3K token/s | 
[epoch_0]_40391  loss=3.162495 |g|=0.447	lr=1.61e-04 | 8.8%@S34  T=1.75s(data=2.1ms QKV=2.13s FFN=3.04s) eta=10:00:35 | 41.5K token/s | 
[Fuyou] head="1" update algorithm=4 t=11.92s
[eval] 
	 Loss@"edu_fineweb1B"=3.153(0.00094) nBranch=1 nToken=6.31M best=3.1536(200) E2T=0.0244 T=36.7171(0)s x=0
	#3.15268±0.0976 tps=172K(6.30784M) a=[2.96384,3.43119] T=36.7171(sec)
[Section@40400] layer[16-24] tasks=19(nPassBack=0) last_loss=3.12833(-0.00561714) N=(772,45920,45360 5332668)
[epoch_0]_40401  loss=3.161342 |g|=0.448	lr=1.61e-04 | 9.7%@S34  T=12.71s(data=2.0ms QKV=2.13s FFN=3.04s) eta=3d 00:50:08 | 39.8K token/s | 
[epoch_0]_40411  loss=3.071048 |g|=0.458	lr=1.61e-04 | 10.5%@S34  T=1.74s(data=1.9ms QKV=2.13s FFN=3.04s) eta=09:57:10 | 40.2K token/s | 
[epoch_0]_40421  loss=3.083525 |g|=0.443	lr=1.61e-04 | 11.3%@S34  T=1.75s(data=1.7ms QKV=2.13s FFN=3.04s) eta=10:00:38 | 40.5K token/s | 
[epoch_0]_40431  loss=3.086782 |g|=0.46	lr=1.61e-04 | 12.1%@S34  T=1.88s(data=1.8ms QKV=2.13s FFN=3.04s) eta=10:46:41 | 40.6K token/s | 
[epoch_0]_40441  loss=3.156272 |g|=0.447	lr=1.61e-04 | 12.9%@S34  T=1.74s(data=2.0ms QKV=2.13s FFN=3.04s) eta=09:56:53 | 41.0K token/s | 
[epoch_0]_40451  loss=3.070771 |g|=0.442	lr=1.60e-04 | 13.8%@S34  T=1.78s(data=1.9ms QKV=2.13s FFN=3.04s) eta=10:12:01 | 41.2K token/s | 
[epoch_0]_40461  loss=3.163505 |g|=0.457	lr=1.60e-04 | 14.6%@S34  T=1.96s(data=2.1ms QKV=2.13s FFN=3.04s) eta=11:12:31 | 41.2K token/s | 
[epoch_0]_40471  loss=3.096357 |g|=0.474	lr=1.60e-04 | 15.4%@S34  T=1.98s(data=2.4ms QKV=2.13s FFN=3.04s) eta=11:19:29 | 41.2K token/s | 
[epoch_0]_40481  loss=3.139373 |g|=0.505	lr=1.60e-04 | 16.2%@S34  T=1.91s(data=2.4ms QKV=2.13s FFN=3.04s) eta=10:53:18 | 41.3K token/s | 
[epoch_0]_40491  loss=3.064080 |g|=0.445	lr=1.60e-04 | 17.0%@S34  T=1.90s(data=2.0ms QKV=2.13s FFN=3.04s) eta=10:51:14 | 41.4K token/s | 
[Fuyou] head="2" update algorithm=4 t=10.94s
[Section@40500] layer[24-32] tasks=19(nPassBack=0) last_loss=3.13418(0.000719309) N=(772,46032,45472 5345868)
[epoch_0]_40501  loss=3.111664 |g|=0.441	lr=1.60e-04 | 17.9%@S34  T=4.82s(data=2.4ms QKV=2.13s FFN=3.03s) eta=1d 03:29:06 | 40.2K token/s | 
[epoch_0]_40511  loss=3.103645 |g|=0.474	lr=1.60e-04 | 18.7%@S34  T=1.76s(data=1.6ms QKV=2.13s FFN=3.04s) eta=10:02:20 | 40.5K token/s | 
[epoch_0]_40521  loss=3.099921 |g|=0.446	lr=1.59e-04 | 19.5%@S34  T=1.75s(data=1.7ms QKV=2.13s FFN=3.04s) eta=09:57:01 | 40.8K token/s | 
[epoch_0]_40531  loss=3.070422 |g|=0.434	lr=1.59e-04 | 20.3%@S34  T=1.75s(data=1.6ms QKV=2.13s FFN=3.04s) eta=09:57:36 | 41.1K token/s | 
[epoch_0]_40541  loss=3.117691 |g|=0.489	lr=1.59e-04 | 21.1%@S34  T=1.96s(data=2.3ms QKV=2.14s FFN=3.04s) eta=11:08:36 | 41.2K token/s | 
[epoch_0]_40551  loss=3.173265 |g|=0.478	lr=1.59e-04 | 21.9%@S34  T=1.75s(data=2.9ms QKV=2.13s FFN=3.04s) eta=09:56:14 | 41.5K token/s | 
[epoch_0]_40561  loss=3.170152 |g|=0.459	lr=1.59e-04 | 22.8%@S34  T=1.74s(data=1.9ms QKV=2.13s FFN=3.04s) eta=09:53:58 | 41.7K token/s | 
[epoch_0]_40571  loss=3.119040 |g|=0.46	lr=1.59e-04 | 23.6%@S34  T=1.94s(data=2.1ms QKV=2.14s FFN=3.04s) eta=11:03:15 | 41.8K token/s | 
[epoch_0]_40581  loss=3.191929 |g|=0.466	lr=1.59e-04 | 24.4%@S34  T=1.82s(data=3.2ms QKV=2.14s FFN=3.04s) eta=10:18:46 | 41.9K token/s | 
[epoch_0]_40591  loss=3.113618 |g|=0.463	lr=1.59e-04 | 25.2%@S34  T=1.91s(data=1.6ms QKV=2.13s FFN=3.04s) eta=10:52:08 | 42.0K token/s | 
[Fuyou] head="3" update algorithm=4 t=12.44s
[eval] 
	 Loss@"edu_fineweb1B"=3.151(0.0013) nBranch=1 nToken=6.31M best=3.1527(201) E2T=0.0667 T=36.7237(0)s x=0
	#3.15137±0.0979 tps=172K(6.30784M) a=[2.95719,3.43165] T=36.7237(sec)
[Section@40600] layer[32-40] tasks=19(nPassBack=0) last_loss=3.08467(0.0643721) N=(772,46144,45584 5359068)
[epoch_0]_40601  loss=3.110064 |g|=0.449	lr=1.58e-04 | 26.0%@S34  T=12.21s(data=2.2ms QKV=2.11s FFN=3.04s) eta=2d 21:17:36 | 40.2K token/s | 
[epoch_0]_40611  loss=3.066744 |g|=0.461	lr=1.58e-04 | 26.9%@S34  T=1.89s(data=1.7ms QKV=2.12s FFN=3.04s) eta=10:44:27 | 40.4K token/s | 
[epoch_0]_40621  loss=3.142038 |g|=0.465	lr=1.58e-04 | 27.7%@S34  T=1.77s(data=1.8ms QKV=2.12s FFN=3.04s) eta=10:02:56 | 40.7K token/s | 
[epoch_0]_40631  loss=3.218671 |g|=0.451	lr=1.58e-04 | 28.5%@S34  T=1.75s(data=2.0ms QKV=2.12s FFN=3.04s) eta=09:53:29 | 41.0K token/s | 
[epoch_0]_40641  loss=3.086852 |g|=0.449	lr=1.58e-04 | 29.3%@S34  T=1.83s(data=1.9ms QKV=2.13s FFN=3.04s) eta=10:22:32 | 41.2K token/s | 
[epoch_0]_40651  loss=3.129922 |g|=0.447	lr=1.58e-04 | 30.1%@S34  T=1.97s(data=2.0ms QKV=2.12s FFN=3.04s) eta=11:10:53 | 41.2K token/s | 
[epoch_0]_40661  loss=3.099091 |g|=0.487	lr=1.58e-04 | 31.0%@S34  T=1.80s(data=2.0ms QKV=2.12s FFN=3.04s) eta=10:09:41 | 41.4K token/s | 
[epoch_0]_40671  loss=3.109325 |g|=0.452	lr=1.57e-04 | 31.8%@S34  T=1.90s(data=1.8ms QKV=2.12s FFN=3.04s) eta=10:43:55 | 41.5K token/s | 
[epoch_0]_40681  loss=3.129460 |g|=0.448	lr=1.57e-04 | 32.6%@S34  T=1.89s(data=2.1ms QKV=2.12s FFN=3.04s) eta=10:39:55 | 41.6K token/s | 
[epoch_0]_40691  loss=3.100227 |g|=0.446	lr=1.57e-04 | 33.4%@S34  T=1.79s(data=2.1ms QKV=2.12s FFN=3.04s) eta=10:08:12 | 41.8K token/s | 
[Fuyou] head="4" update algorithm=4 t=19.01s
[Section@40700] layer[40-48] tasks=19(nPassBack=0) last_loss=3.11462(0.0473402) N=(772,46256,45696 5372268)
[epoch_0]_40701  loss=3.101166 |g|=0.435	lr=1.57e-04 | 34.2%@S34  T=6.01s(data=3.8ms QKV=2.12s FFN=3.03s) eta=1d 09:56:29 | 40.4K token/s | 
[epoch_0]_40711  loss=3.143404 |g|=0.469	lr=1.57e-04 | 35.1%@S34  T=1.95s(data=2.1ms QKV=2.12s FFN=3.04s) eta=11:01:20 | 40.5K token/s | 
[epoch_0]_40721  loss=3.088871 |g|=0.462	lr=1.57e-04 | 35.9%@S34  T=1.97s(data=2.1ms QKV=2.13s FFN=3.04s) eta=11:06:53 | 40.5K token/s | 
[epoch_0]_40731  loss=3.152813 |g|=0.475	lr=1.57e-04 | 36.7%@S34  T=1.74s(data=2.8ms QKV=2.12s FFN=3.04s) eta=09:50:18 | 40.8K token/s | 
[epoch_0]_40741  loss=3.120523 |g|=0.456	lr=1.56e-04 | 37.5%@S34  T=1.92s(data=2.9ms QKV=2.12s FFN=3.04s) eta=10:50:44 | 40.9K token/s | 
[epoch_0]_40751  loss=3.072734 |g|=0.448	lr=1.56e-04 | 38.3%@S34  T=1.95s(data=2.2ms QKV=2.13s FFN=3.04s) eta=10:57:36 | 41.0K token/s | 
[epoch_0]_40761  loss=3.110401 |g|=0.453	lr=1.56e-04 | 39.2%@S34  T=1.82s(data=2.5ms QKV=2.13s FFN=3.04s) eta=10:13:35 | 41.2K token/s | 
[epoch_0]_40771  loss=3.083074 |g|=0.461	lr=1.56e-04 | 40.0%@S34  T=1.74s(data=3.1ms QKV=2.12s FFN=3.04s) eta=09:48:06 | 41.5K token/s | 
[epoch_0]_40781  loss=3.130098 |g|=0.454	lr=1.56e-04 | 40.8%@S34  T=1.77s(data=3.1ms QKV=2.12s FFN=3.04s) eta=09:56:13 | 41.7K token/s | 
[epoch_0]_40791  loss=3.049125 |g|=0.468	lr=1.56e-04 | 41.6%@S34  T=1.83s(data=2.1ms QKV=2.12s FFN=3.04s) eta=10:17:44 | 41.9K token/s | 
[Fuyou] head="5" update algorithm=4 t=14.01s
[eval] 
	 Loss@"edu_fineweb1B"=3.150(0.0012) nBranch=1 nToken=6.31M best=3.1514(202) E2T=-0.0266 T=36.7458(0)s x=0
	#3.1502±0.0981 tps=172K(6.30784M) a=[2.95152,3.4337] T=36.7458(sec)
[Section@40800] layer[0-8] tasks=19(nPassBack=0) last_loss=3.1768(-0.0866086) N=(772,46368,45808 5385468)
[epoch_0]_40801  loss=3.099929 |g|=0.443	lr=1.56e-04 | 42.4%@S34  T=12.62s(data=2.0ms QKV=2.11s FFN=3.04s) eta=2d 22:56:54 | 40.1K token/s | 
[epoch_0]_40811  loss=3.053422 |g|=0.441	lr=1.56e-04 | 43.2%@S34  T=1.75s(data=1.6ms QKV=2.11s FFN=3.04s) eta=09:50:50 | 40.4K token/s | 
[epoch_0]_40821  loss=3.034182 |g|=0.439	lr=1.55e-04 | 44.1%@S34  T=1.86s(data=1.8ms QKV=2.11s FFN=3.04s) eta=10:27:42 | 40.6K token/s | 
[epoch_0]_40831  loss=3.046414 |g|=0.448	lr=1.55e-04 | 44.9%@S34  T=1.77s(data=1.8ms QKV=2.11s FFN=3.04s) eta=09:55:45 | 40.9K token/s | 
[epoch_0]_40841  loss=3.019911 |g|=0.482	lr=1.55e-04 | 45.7%@S34  T=1.76s(data=1.8ms QKV=2.11s FFN=3.04s) eta=09:53:39 | 41.2K token/s | 
[epoch_0]_40851  loss=3.129590 |g|=0.466	lr=1.55e-04 | 46.5%@S34  T=1.75s(data=1.9ms QKV=2.11s FFN=3.04s) eta=09:48:20 | 41.5K token/s | 
[epoch_0]_40861  loss=3.108084 |g|=0.472	lr=1.55e-04 | 47.3%@S34  T=1.92s(data=2.1ms QKV=2.12s FFN=3.04s) eta=10:44:12 | 41.5K token/s | 
[epoch_0]_40871  loss=3.092245 |g|=0.456	lr=1.55e-04 | 48.2%@S34  T=1.90s(data=1.9ms QKV=2.11s FFN=3.04s) eta=10:38:13 | 41.6K token/s | 
[epoch_0]_40881  loss=3.071189 |g|=0.462	lr=1.55e-04 | 49.0%@S34  T=1.92s(data=2.1ms QKV=2.12s FFN=3.04s) eta=10:45:27 | 41.7K token/s | 
[epoch_0]_40891  loss=3.093551 |g|=0.439	lr=1.54e-04 | 49.8%@S34  T=1.78s(data=1.8ms QKV=2.11s FFN=3.04s) eta=09:57:21 | 41.9K token/s | 
[Fuyou] head="0" update algorithm=4 t=12.77s
[Section@40900] layer[8-16] tasks=19(nPassBack=0) last_loss=3.09921(0.0314748) N=(772,46480,45920 5398668)
[epoch_0]_40901  loss=3.082423 |g|=0.45	lr=1.54e-04 | 50.6%@S34  T=4.83s(data=1.9ms QKV=2.13s FFN=3.03s) eta=1d 02:59:54 | 40.6K token/s | 
[epoch_0]_40911  loss=3.134773 |g|=0.443	lr=1.54e-04 | 51.4%@S34  T=1.83s(data=2.2ms QKV=2.12s FFN=3.04s) eta=10:14:17 | 40.8K token/s | 
[epoch_0]_40921  loss=3.094289 |g|=0.486	lr=1.54e-04 | 52.3%@S34  T=1.75s(data=1.7ms QKV=2.12s FFN=3.04s) eta=09:45:14 | 41.1K token/s | 
[epoch_0]_40931  loss=3.155861 |g|=0.464	lr=1.54e-04 | 53.1%@S34  T=1.87s(data=1.6ms QKV=2.12s FFN=3.04s) eta=10:27:24 | 41.3K token/s | 
[epoch_0]_40941  loss=3.162641 |g|=0.454	lr=1.54e-04 | 53.9%@S34  T=1.85s(data=2.0ms QKV=2.13s FFN=3.04s) eta=10:18:33 | 41.4K token/s | 
[epoch_0]_40951  loss=3.144888 |g|=0.453	lr=1.54e-04 | 54.7%@S34  T=1.74s(data=1.5ms QKV=2.12s FFN=3.04s) eta=09:41:34 | 41.7K token/s | 
[epoch_0]_40961  loss=3.130955 |g|=0.451	lr=1.54e-04 | 55.5%@S34  T=1.93s(data=2.1ms QKV=2.13s FFN=3.04s) eta=10:45:38 | 41.7K token/s | 
[epoch_0]_40971  loss=3.113981 |g|=0.467	lr=1.53e-04 | 56.4%@S34  T=2.00s(data=2.0ms QKV=2.13s FFN=3.04s) eta=11:08:40 | 41.7K token/s | 
[epoch_0]_40981  loss=3.093131 |g|=0.441	lr=1.53e-04 | 57.2%@S34  T=1.92s(data=2.0ms QKV=2.13s FFN=3.04s) eta=10:43:12 | 41.8K token/s | 
[epoch_0]_40991  loss=3.118705 |g|=0.468	lr=1.53e-04 | 58.0%@S34  T=1.82s(data=2.0ms QKV=2.13s FFN=3.04s) eta=10:06:24 | 41.9K token/s | 
[Fuyou] head="1" update algorithm=4 t=13.94s
[eval] 
	 Loss@"edu_fineweb1B"=3.150(-9e-05) nBranch=1 nToken=6.31M best=3.1502(203) E2T=-0.06 T=36.7933(0)s x=0
	#3.15029±0.0978 tps=171K(6.30784M) a=[2.95437,3.42957] T=36.7933(sec)
[Section@41000] layer[16-24] tasks=19(nPassBack=0) last_loss=3.21026(-0.0819333) N=(772,46592,46032 5411868)
[epoch_0]_41001  loss=3.156425 |g|=0.449	lr=1.53e-04 | 58.8%@S34  T=13.51s(data=3.8ms QKV=2.12s FFN=3.04s) eta=3d 03:09:22 | 40.1K token/s | 
[epoch_0]_41011  loss=3.110989 |g|=0.467	lr=1.53e-04 | 59.6%@S34  T=1.78s(data=3.3ms QKV=2.12s FFN=3.04s) eta=09:54:29 | 40.4K token/s | 
[epoch_0]_41021  loss=3.115299 |g|=0.452	lr=1.53e-04 | 60.4%@S34  T=1.74s(data=2.7ms QKV=2.12s FFN=3.04s) eta=09:39:56 | 40.8K token/s | 
[epoch_0]_41031  loss=3.097255 |g|=0.488	lr=1.53e-04 | 61.3%@S34  T=1.81s(data=2.0ms QKV=2.13s FFN=3.04s) eta=10:03:27 | 41.0K token/s | 
[epoch_0]_41041  loss=3.090890 |g|=0.459	lr=1.52e-04 | 62.1%@S34  T=1.92s(data=2.1ms QKV=2.12s FFN=3.04s) eta=10:40:59 | 41.1K token/s | 
[epoch_0]_41051  loss=3.060526 |g|=0.47	lr=1.52e-04 | 62.9%@S34  T=1.88s(data=2.8ms QKV=2.12s FFN=3.04s) eta=10:27:09 | 41.2K token/s | 
[epoch_0]_41061  loss=3.067029 |g|=0.434	lr=1.52e-04 | 63.7%@S34  T=1.95s(data=2.0ms QKV=2.13s FFN=3.05s) eta=10:48:41 | 41.2K token/s | 
[epoch_0]_41071  loss=3.183177 |g|=0.47	lr=1.52e-04 | 64.5%@S34  T=1.99s(data=2.1ms QKV=2.13s FFN=3.04s) eta=11:02:53 | 41.2K token/s | 
[epoch_0]_41081  loss=3.133979 |g|=0.469	lr=1.52e-04 | 65.4%@S34  T=1.82s(data=2.9ms QKV=2.12s FFN=3.04s) eta=10:06:33 | 41.4K token/s | 
[epoch_0]_41091  loss=3.126556 |g|=0.454	lr=1.52e-04 | 66.2%@S34  T=1.95s(data=2.2ms QKV=2.13s FFN=3.04s) eta=10:46:41 | 41.4K token/s | 
[Fuyou] head="2" update algorithm=4 t=12.24s
[Section@41100] layer[24-32] tasks=19(nPassBack=0) last_loss=3.11146(0.0227182) N=(772,46704,46144 5425068)
[epoch_0]_41101  loss=3.115432 |g|=0.439	lr=1.52e-04 | 67.0%@S34  T=5.21s(data=2.7ms QKV=2.12s FFN=3.04s) eta=1d 04:50:17 | 40.2K token/s | 
[epoch_0]_41111  loss=3.135521 |g|=0.481	lr=1.52e-04 | 67.8%@S34  T=1.93s(data=2.1ms QKV=2.14s FFN=3.04s) eta=10:41:13 | 40.3K token/s | 
[epoch_0]_41121  loss=3.106797 |g|=0.444	lr=1.51e-04 | 68.6%@S34  T=1.85s(data=2.2ms QKV=2.14s FFN=3.04s) eta=10:15:00 | 40.5K token/s | 
[epoch_0]_41131  loss=3.068706 |g|=0.447	lr=1.51e-04 | 69.5%@S34  T=1.94s(data=2.2ms QKV=2.13s FFN=3.04s) eta=10:42:01 | 40.6K token/s | 
[epoch_0]_41141  loss=3.061192 |g|=0.438	lr=1.51e-04 | 70.3%@S34  T=1.93s(data=2.1ms QKV=2.13s FFN=3.04s) eta=10:39:46 | 40.7K token/s | 
[epoch_0]_41151  loss=3.141710 |g|=0.447	lr=1.51e-04 | 71.1%@S34  T=1.93s(data=2.1ms QKV=2.14s FFN=3.04s) eta=10:41:08 | 40.7K token/s | 
[epoch_0]_41161  loss=3.125859 |g|=0.434	lr=1.51e-04 | 71.9%@S34  T=1.90s(data=2.1ms QKV=2.14s FFN=3.04s) eta=10:29:43 | 40.9K token/s | 
[epoch_0]_41171  loss=3.106509 |g|=0.454	lr=1.51e-04 | 72.7%@S34  T=1.92s(data=2.1ms QKV=2.13s FFN=3.04s) eta=10:35:45 | 40.9K token/s | 
[epoch_0]_41181  loss=3.035685 |g|=0.442	lr=1.51e-04 | 73.6%@S34  T=1.94s(data=2.0ms QKV=2.13s FFN=3.04s) eta=10:42:05 | 41.0K token/s | 
[epoch_0]_41191  loss=3.147298 |g|=0.474	lr=1.50e-04 | 74.4%@S34  T=1.95s(data=2.2ms QKV=2.14s FFN=3.04s) eta=10:43:57 | 41.1K token/s | 
[Fuyou] head="3" update algorithm=4 t=11.88s
[eval] 
	 Loss@"edu_fineweb1B"=3.149(0.0015) nBranch=1 nToken=6.31M best=3.1503(204) E2T=0.0105 T=36.7201(0)s x=0
	#3.14882±0.0977 tps=172K(6.30784M) a=[2.95321,3.42845] T=36.7201(sec)
[Section@41200] layer[32-40] tasks=19(nPassBack=0) last_loss=3.1383(-0.0536299) N=(772,46816,46256 5438268)
[epoch_0]_41201  loss=3.058460 |g|=0.465	lr=1.50e-04 | 75.2%@S34  T=12.00s(data=2.2ms QKV=2.12s FFN=3.04s) eta=2d 18:07:50 | 39.4K token/s | 
[epoch_0]_41211  loss=3.120068 |g|=0.453	lr=1.50e-04 | 76.0%@S34  T=1.76s(data=2.1ms QKV=2.13s FFN=3.04s) eta=09:39:58 | 39.7K token/s | 
[epoch_0]_41221  loss=3.058058 |g|=0.442	lr=1.50e-04 | 76.8%@S34  T=1.84s(data=2.0ms QKV=2.13s FFN=3.04s) eta=10:07:26 | 40.0K token/s | 
[epoch_0]_41231  loss=3.126528 |g|=0.458	lr=1.50e-04 | 77.7%@S34  T=1.75s(data=1.8ms QKV=2.12s FFN=3.04s) eta=09:36:52 | 40.3K token/s | 
[epoch_0]_41241  loss=3.104385 |g|=0.464	lr=1.50e-04 | 78.5%@S34  T=2.02s(data=2.1ms QKV=2.13s FFN=3.04s) eta=11:07:35 | 40.3K token/s | 
[epoch_0]_41251  loss=3.127808 |g|=0.452	lr=1.50e-04 | 79.3%@S34  T=1.97s(data=2.1ms QKV=2.13s FFN=3.04s) eta=10:51:00 | 40.4K token/s | 
[epoch_0]_41261  loss=3.065635 |g|=0.453	lr=1.50e-04 | 80.1%@S34  T=1.89s(data=2.0ms QKV=2.13s FFN=3.04s) eta=10:23:53 | 40.5K token/s | 
[epoch_0]_41271  loss=3.053977 |g|=0.441	lr=1.49e-04 | 80.9%@S34  T=1.99s(data=2.1ms QKV=2.14s FFN=3.04s) eta=10:53:58 | 40.6K token/s | 
[epoch_0]_41281  loss=3.082022 |g|=0.45	lr=1.49e-04 | 81.7%@S34  T=1.93s(data=2.2ms QKV=2.13s FFN=3.04s) eta=10:36:36 | 40.6K token/s | 
[epoch_0]_41291  loss=3.134341 |g|=0.446	lr=1.49e-04 | 82.6%@S34  T=1.98s(data=2.2ms QKV=2.13s FFN=3.04s) eta=10:53:10 | 40.7K token/s | 
[Fuyou] head="4" update algorithm=4 t=12.65s
[Section@41300] layer[40-48] tasks=19(nPassBack=0) last_loss=3.16917(-0.0545571) N=(772,46928,46368 5451468)
[epoch_0]_41301  loss=3.114382 |g|=0.459	lr=1.49e-04 | 83.4%@S34  T=4.24s(data=2.0ms QKV=2.12s FFN=3.03s) eta=23:13:50 | 39.6K token/s | 
[epoch_0]_41311  loss=3.069110 |g|=0.477	lr=1.49e-04 | 84.2%@S34  T=1.74s(data=1.9ms QKV=2.13s FFN=3.04s) eta=09:30:49 | 40.0K token/s | 
[epoch_0]_41321  loss=3.129118 |g|=0.446	lr=1.49e-04 | 85.0%@S34  T=1.80s(data=2.3ms QKV=2.13s FFN=3.04s) eta=09:52:35 | 40.3K token/s | 
[epoch_0]_41331  loss=3.152559 |g|=0.459	lr=1.49e-04 | 85.8%@S34  T=2.02s(data=2.2ms QKV=2.13s FFN=3.04s) eta=11:02:59 | 40.3K token/s | 
[epoch_0]_41341  loss=3.024312 |g|=0.449	lr=1.49e-04 | 86.7%@S34  T=1.95s(data=2.2ms QKV=2.14s FFN=3.04s) eta=10:40:11 | 40.4K token/s | 
[epoch_0]_41351  loss=3.146269 |g|=0.468	lr=1.48e-04 | 87.5%@S34  T=1.80s(data=2.1ms QKV=2.14s FFN=3.04s) eta=09:50:07 | 40.6K token/s | 
[epoch_0]_41361  loss=3.093433 |g|=0.477	lr=1.48e-04 | 88.3%@S34  T=1.75s(data=1.8ms QKV=2.13s FFN=3.04s) eta=09:35:26 | 40.9K token/s | 
[epoch_0]_41371  loss=3.142526 |g|=0.446	lr=1.48e-04 | 89.1%@S34  T=1.81s(data=1.9ms QKV=2.13s FFN=3.04s) eta=09:53:25 | 41.1K token/s | 
[epoch_0]_41381  loss=3.060097 |g|=0.477	lr=1.48e-04 | 89.9%@S34  T=1.82s(data=2.2ms QKV=2.14s FFN=3.04s) eta=09:56:46 | 41.3K token/s | 
[epoch_0]_41391  loss=3.129097 |g|=0.457	lr=1.48e-04 | 90.8%@S34  T=1.77s(data=2.1ms QKV=2.13s FFN=3.04s) eta=09:38:30 | 41.6K token/s | 
[Fuyou] head="5" update algorithm=4 t=10.52s
[eval] 
	 Loss@"edu_fineweb1B"=3.147(0.0016) nBranch=1 nToken=6.31M best=3.1488(205) E2T=0.12 T=36.7699(0)s x=0
	#3.14719±0.0985 tps=172K(6.30784M) a=[2.95137,3.43012] T=36.7699(sec)
[Section@41400] layer[0-8] tasks=19(nPassBack=0) last_loss=3.02701(0.149789) N=(772,47040,46480 5464668)
[epoch_0]_41401  loss=3.027871 |g|=0.434	lr=1.48e-04 | 91.6%@S34  T=12.26s(data=2.2ms QKV=2.13s FFN=3.04s) eta=2d 18:51:22 | 39.8K token/s | 
[epoch_0]_41411  loss=2.998886 |g|=0.451	lr=1.48e-04 | 92.4%@S34  T=1.87s(data=2.1ms QKV=2.12s FFN=3.04s) eta=10:12:36 | 40.0K token/s | 
[epoch_0]_41421  loss=3.149393 |g|=0.473	lr=1.47e-04 | 93.2%@S34  T=1.84s(data=2.6ms QKV=2.13s FFN=3.04s) eta=10:00:40 | 40.3K token/s | 
[epoch_0]_41431  loss=3.113089 |g|=0.462	lr=1.47e-04 | 94.0%@S34  T=1.77s(data=2.2ms QKV=2.12s FFN=3.04s) eta=09:39:04 | 40.6K token/s | 
[epoch_0]_41441  loss=3.099016 |g|=0.453	lr=1.47e-04 | 94.9%@S34  T=1.77s(data=1.9ms QKV=2.12s FFN=3.04s) eta=09:38:33 | 40.8K token/s | 
[epoch_0]_41451  loss=3.143446 |g|=0.467	lr=1.47e-04 | 95.7%@S34  T=1.73s(data=1.8ms QKV=2.12s FFN=3.04s) eta=09:26:07 | 41.2K token/s | 
[epoch_0]_41461  loss=3.089724 |g|=0.456	lr=1.47e-04 | 96.5%@S34  T=1.75s(data=2.0ms QKV=2.12s FFN=3.04s) eta=09:31:43 | 41.4K token/s | 
[epoch_0]_41471  loss=3.176134 |g|=0.469	lr=1.47e-04 | 97.3%@S34  T=1.75s(data=1.8ms QKV=2.12s FFN=3.04s) eta=09:29:12 | 41.7K token/s | 
[epoch_0]_41481  loss=3.109753 |g|=0.455	lr=1.47e-04 | 98.1%@S34  T=1.85s(data=1.9ms QKV=2.12s FFN=3.04s) eta=10:01:47 | 41.8K token/s | 
[epoch_0]_41491  loss=3.040087 |g|=0.482	lr=1.47e-04 | 99.0%@S34  T=1.83s(data=1.8ms QKV=2.12s FFN=3.04s) eta=09:55:09 | 42.0K token/s | 
[Fuyou] head="0" update algorithm=4 t=12.82s
[Section@41500] layer[8-16] tasks=19(nPassBack=0) last_loss=3.10994(-0.0107245) N=(772,47152,46592 5477868)
[epoch_0]_41501  loss=3.172901 |g|=0.47	lr=1.46e-04 | 99.8%@S34  T=4.88s(data=2.1ms QKV=2.12s FFN=3.03s) eta=1d 02:29:39 | 40.7K token/s | 
[epoch_0]_41503  loss=3.086995 |g|=0.463	lr=1.46e-04 | 99.9%@S34  T=2.14s(data=1.8ms QKV=2.12s FFN=3.03s) eta=11:36:23 | 40.6K token/s | 
-------- End of shard_34@"./Datasets/edu_fineweb1B/edu_fineweb_train_000792.bin"-------- 
[shard-35]@"./Datasets/edu_fineweb1B/edu_fineweb_train_000793.bin": tokens=100(M) nShardSamples=1220(3417960) 
[epoch_0]_41511  loss=3.145795 |g|=0.474	lr=1.46e-04 | 0.6%@S35  T=1.78s(data=1.4ms QKV=2.13s FFN=3.03s) eta=09:40:03 | 40.9K token/s | 
[epoch_0]_41521  loss=3.090996 |g|=0.454	lr=1.46e-04 | 1.4%@S35  T=1.88s(data=6.7ms QKV=2.13s FFN=3.04s) eta=10:12:56 | 41.0K token/s | 
[epoch_0]_41531  loss=3.118001 |g|=0.457	lr=1.46e-04 | 2.2%@S35  T=1.74s(data=1.2ms QKV=2.12s FFN=3.04s) eta=09:24:28 | 41.3K token/s | 
[epoch_0]_41541  loss=3.178293 |g|=0.457	lr=1.46e-04 | 3.0%@S35  T=1.81s(data=1.2ms QKV=2.12s FFN=3.04s) eta=09:47:53 | 41.5K token/s | 
[epoch_0]_41551  loss=3.121243 |g|=0.461	lr=1.46e-04 | 3.9%@S35  T=1.81s(data=1.4ms QKV=2.12s FFN=3.04s) eta=09:47:47 | 41.7K token/s | 
[epoch_0]_41561  loss=3.128998 |g|=0.464	lr=1.46e-04 | 4.7%@S35  T=1.88s(data=1.3ms QKV=2.13s FFN=3.04s) eta=10:09:43 | 41.8K token/s | 
[epoch_0]_41571  loss=3.074784 |g|=0.467	lr=1.45e-04 | 5.5%@S35  T=1.74s(data=1.2ms QKV=2.12s FFN=3.04s) eta=09:24:53 | 42.1K token/s | 
[epoch_0]_41581  loss=3.139367 |g|=0.463	lr=1.45e-04 | 6.3%@S35  T=1.89s(data=1.2ms QKV=2.12s FFN=3.04s) eta=10:11:42 | 42.1K token/s | 
[epoch_0]_41591  loss=3.106778 |g|=0.464	lr=1.45e-04 | 7.1%@S35  T=1.84s(data=1.4ms QKV=2.13s FFN=3.04s) eta=09:57:43 | 42.2K token/s | 
[Fuyou] head="1" update algorithm=4 t=9.74s
[eval] 
	 Loss@"edu_fineweb1B"=3.142(0.0054) nBranch=1 nToken=6.31M best=3.1472(206) E2T=0.0599 T=36.783(0)s x=0
	#3.14176±0.0976 tps=171K(6.30784M) a=[2.94486,3.41933] T=36.783(sec)
[Section@41600] layer[16-24] tasks=19(nPassBack=0) last_loss=3.08183(0.128428) N=(772,47264,46704 5491068)
[epoch_0]_41601  loss=3.166628 |g|=0.459	lr=1.45e-04 | 8.0%@S35  T=12.65s(data=1.8ms QKV=2.11s FFN=3.03s) eta=2d 20:17:24 | 40.5K token/s | 
[epoch_0]_41611  loss=3.175751 |g|=0.462	lr=1.45e-04 | 8.8%@S35  T=1.82s(data=1.8ms QKV=2.11s FFN=3.04s) eta=09:50:34 | 40.7K token/s | 
[epoch_0]_41621  loss=3.115305 |g|=0.46	lr=1.45e-04 | 9.6%@S35  T=1.87s(data=2.1ms QKV=2.11s FFN=3.04s) eta=10:04:13 | 40.8K token/s | 
[epoch_0]_41631  loss=3.194593 |g|=0.468	lr=1.45e-04 | 10.4%@S35  T=1.80s(data=2.0ms QKV=2.12s FFN=3.04s) eta=09:43:26 | 41.1K token/s | 
[epoch_0]_41641  loss=3.164187 |g|=0.477	lr=1.45e-04 | 11.2%@S35  T=1.75s(data=1.4ms QKV=2.11s FFN=3.04s) eta=09:25:29 | 41.4K token/s | 
[epoch_0]_41651  loss=3.110579 |g|=0.46	lr=1.44e-04 | 12.1%@S35  T=1.79s(data=1.7ms QKV=2.11s FFN=3.04s) eta=09:39:10 | 41.6K token/s | 
[epoch_0]_41661  loss=3.094881 |g|=0.475	lr=1.44e-04 | 12.9%@S35  T=1.83s(data=2.2ms QKV=2.12s FFN=3.04s) eta=09:51:50 | 41.7K token/s | 
[epoch_0]_41671  loss=3.120257 |g|=0.456	lr=1.44e-04 | 13.7%@S35  T=1.99s(data=2.4ms QKV=2.12s FFN=3.04s) eta=10:40:52 | 41.7K token/s | 
[epoch_0]_41681  loss=3.163258 |g|=0.457	lr=1.44e-04 | 14.5%@S35  T=1.92s(data=2.0ms QKV=2.12s FFN=3.04s) eta=10:18:36 | 41.8K token/s | 
[epoch_0]_41691  loss=3.079998 |g|=0.467	lr=1.44e-04 | 15.3%@S35  T=1.79s(data=2.0ms QKV=2.11s FFN=3.04s) eta=09:37:30 | 42.0K token/s | 
[Fuyou] head="2" update algorithm=4 t=11.55s
[Section@41700] layer[24-32] tasks=19(nPassBack=0) last_loss=3.0748(0.0366571) N=(772,47376,46816 5504268)
[epoch_0]_41701  loss=3.071956 |g|=0.476	lr=1.44e-04 | 16.2%@S35  T=4.95s(data=2.1ms QKV=2.11s FFN=3.03s) eta=1d 02:36:13 | 40.7K token/s | 
[epoch_0]_41711  loss=3.092217 |g|=0.455	lr=1.44e-04 | 17.0%@S35  T=1.77s(data=2.0ms QKV=2.12s FFN=3.03s) eta=09:29:52 | 41.0K token/s | 
[epoch_0]_41721  loss=3.111307 |g|=0.469	lr=1.44e-04 | 17.8%@S35  T=1.83s(data=2.0ms QKV=2.12s FFN=3.04s) eta=09:50:08 | 41.1K token/s | 
[epoch_0]_41731  loss=3.097889 |g|=0.475	lr=1.43e-04 | 18.6%@S35  T=1.73s(data=2.0ms QKV=2.11s FFN=3.04s) eta=09:17:42 | 41.5K token/s | 
[epoch_0]_41741  loss=3.145456 |g|=0.476	lr=1.43e-04 | 19.4%@S35  T=1.77s(data=2.8ms QKV=2.12s FFN=3.04s) eta=09:30:15 | 41.7K token/s | 
[epoch_0]_41751  loss=3.198909 |g|=0.458	lr=1.43e-04 | 20.3%@S35  T=1.75s(data=3.1ms QKV=2.12s FFN=3.04s) eta=09:23:42 | 41.9K token/s | 
[epoch_0]_41761  loss=3.131382 |g|=0.466	lr=1.43e-04 | 21.1%@S35  T=1.78s(data=3.9ms QKV=2.12s FFN=3.04s) eta=09:31:04 | 42.1K token/s | 
[epoch_0]_41771  loss=3.162448 |g|=0.466	lr=1.43e-04 | 21.9%@S35  T=1.78s(data=2.9ms QKV=2.11s FFN=3.04s) eta=09:32:11 | 42.3K token/s | 
[epoch_0]_41781  loss=3.039261 |g|=0.464	lr=1.43e-04 | 22.7%@S35  T=1.93s(data=4.0ms QKV=2.12s FFN=3.04s) eta=10:20:42 | 42.3K token/s | 
[epoch_0]_41791  loss=3.142425 |g|=0.48	lr=1.43e-04 | 23.5%@S35  T=1.78s(data=2.7ms QKV=2.12s FFN=3.04s) eta=09:31:14 | 42.5K token/s | 
[Fuyou] head="3" update algorithm=4 t=15.51s
[eval] 
	 Loss@"edu_fineweb1B"=3.138(0.004) nBranch=1 nToken=6.31M best=3.1418(207) E2T=-0.0596 T=36.7637(0)s x=0
	#3.13774±0.0980 tps=172K(6.30784M) a=[2.93825,3.41647] T=36.7637(sec)
[Section@41800] layer[32-40] tasks=19(nPassBack=0) last_loss=3.19737(-0.0590711) N=(772,47488,46928 5517468)
[epoch_0]_41801  loss=3.114584 |g|=0.452	lr=1.42e-04 | 24.3%@S35  T=13.26s(data=3.4ms QKV=2.11s FFN=3.03s) eta=2d 22:50:17 | 40.7K token/s | 
[epoch_0]_41811  loss=3.115371 |g|=0.465	lr=1.42e-04 | 25.2%@S35  T=1.75s(data=3.3ms QKV=2.11s FFN=3.04s) eta=09:21:18 | 41.0K token/s | 
[epoch_0]_41821  loss=3.120595 |g|=0.448	lr=1.42e-04 | 26.0%@S35  T=1.75s(data=2.7ms QKV=2.11s FFN=3.04s) eta=09:21:53 | 41.3K token/s | 
[epoch_0]_41831  loss=3.098667 |g|=0.483	lr=1.42e-04 | 26.8%@S35  T=1.94s(data=2.0ms QKV=2.12s FFN=3.04s) eta=10:21:09 | 41.3K token/s | 
[epoch_0]_41841  loss=3.078015 |g|=0.464	lr=1.42e-04 | 27.6%@S35  T=1.98s(data=2.0ms QKV=2.12s FFN=3.04s) eta=10:33:46 | 41.3K token/s | 
[epoch_0]_41851  loss=3.202703 |g|=0.457	lr=1.42e-04 | 28.4%@S35  T=1.93s(data=4.5ms QKV=2.11s FFN=3.04s) eta=10:17:08 | 41.4K token/s | 
[epoch_0]_41861  loss=3.070189 |g|=0.463	lr=1.42e-04 | 29.3%@S35  T=1.81s(data=3.2ms QKV=2.11s FFN=3.04s) eta=09:37:15 | 41.6K token/s | 
[epoch_0]_41871  loss=3.127635 |g|=0.501	lr=1.42e-04 | 30.1%@S35  T=1.79s(data=2.9ms QKV=2.11s FFN=3.04s) eta=09:30:26 | 41.8K token/s | 
[epoch_0]_41881  loss=3.172650 |g|=0.482	lr=1.41e-04 | 30.9%@S35  T=1.77s(data=2.7ms QKV=2.11s FFN=3.04s) eta=09:26:24 | 42.0K token/s | 
[epoch_0]_41891  loss=3.159121 |g|=0.456	lr=1.41e-04 | 31.7%@S35  T=1.76s(data=2.3ms QKV=2.11s FFN=3.04s) eta=09:22:22 | 42.2K token/s | 
[Fuyou] head="4" update algorithm=4 t=15.58s
[Section@41900] layer[40-48] tasks=19(nPassBack=0) last_loss=3.11379(0.0553844) N=(772,47600,47040 5530668)
[epoch_0]_41901  loss=3.075935 |g|=0.461	lr=1.41e-04 | 32.5%@S35  T=5.37s(data=3.5ms QKV=2.11s FFN=3.03s) eta=1d 04:33:50 | 40.9K token/s | 
[epoch_0]_41911  loss=3.097616 |g|=0.474	lr=1.41e-04 | 33.4%@S35  T=1.74s(data=2.5ms QKV=2.11s FFN=3.04s) eta=09:15:54 | 41.2K token/s | 
[epoch_0]_41921  loss=3.081024 |g|=0.459	lr=1.41e-04 | 34.2%@S35  T=1.75s(data=3.4ms QKV=2.12s FFN=3.04s) eta=09:18:45 | 41.5K token/s | 
[epoch_0]_41931  loss=3.188378 |g|=0.485	lr=1.41e-04 | 35.0%@S35  T=1.76s(data=2.9ms QKV=2.12s FFN=3.04s) eta=09:21:54 | 41.7K token/s | 
[epoch_0]_41941  loss=3.173328 |g|=0.469	lr=1.41e-04 | 35.8%@S35  T=1.84s(data=2.7ms QKV=2.12s FFN=3.04s) eta=09:46:16 | 41.9K token/s | 
[epoch_0]_41951  loss=3.130471 |g|=0.503	lr=1.41e-04 | 36.6%@S35  T=1.92s(data=3.5ms QKV=2.12s FFN=3.04s) eta=10:11:36 | 41.9K token/s | 
[epoch_0]_41961  loss=3.104727 |g|=0.45	lr=1.40e-04 | 37.5%@S35  T=1.76s(data=3.2ms QKV=2.12s FFN=3.04s) eta=09:21:00 | 42.1K token/s | 
[epoch_0]_41971  loss=3.075804 |g|=0.477	lr=1.40e-04 | 38.3%@S35  T=1.78s(data=3.3ms QKV=2.12s FFN=3.04s) eta=09:25:41 | 42.3K token/s | 
[epoch_0]_41981  loss=3.031287 |g|=0.496	lr=1.40e-04 | 39.1%@S35  T=1.90s(data=2.1ms QKV=2.12s FFN=3.04s) eta=10:03:37 | 42.4K token/s | 
[epoch_0]_41991  loss=3.081589 |g|=0.467	lr=1.40e-04 | 39.9%@S35  T=1.78s(data=3.3ms QKV=2.12s FFN=3.04s) eta=09:25:44 | 42.5K token/s | 
[Fuyou] head="5" update algorithm=4 t=15.16s
[eval] 
	 Loss@"edu_fineweb1B"=3.136(0.0017) nBranch=1 nToken=6.31M best=3.1377(208) E2T=0.052 T=36.7476(0)s x=0
	#3.136±0.0983 tps=172K(6.30784M) a=[2.93946,3.41387] T=36.7476(sec)
[Section@42000] layer[0-8] tasks=19(nPassBack=0) last_loss=3.08398(-0.0569715) N=(772,47712,47152 5543868)
[epoch_0]_42001  loss=3.086690 |g|=0.501	lr=1.40e-04 | 40.7%@S35  T=13.45s(data=2.4ms QKV=2.11s FFN=3.03s) eta=2d 23:05:25 | 40.7K token/s | 
[epoch_0]_42011  loss=3.094279 |g|=0.455	lr=1.40e-04 | 41.6%@S35  T=1.88s(data=3.0ms QKV=2.11s FFN=3.04s) eta=09:55:21 | 40.9K token/s | 
[epoch_0]_42021  loss=3.128394 |g|=0.458	lr=1.40e-04 | 42.4%@S35  T=1.90s(data=2.1ms QKV=2.12s FFN=3.04s) eta=10:01:48 | 41.0K token/s | 
[epoch_0]_42031  loss=3.060967 |g|=0.448	lr=1.40e-04 | 43.2%@S35  T=1.78s(data=3.9ms QKV=2.11s FFN=3.04s) eta=09:23:10 | 41.2K token/s | 
[epoch_0]_42041  loss=3.101013 |g|=0.46	lr=1.39e-04 | 44.0%@S35  T=1.80s(data=3.1ms QKV=2.11s FFN=3.04s) eta=09:30:58 | 41.4K token/s | 
[epoch_0]_42051  loss=3.164616 |g|=0.475	lr=1.39e-04 | 44.8%@S35  T=1.79s(data=3.8ms QKV=2.11s FFN=3.04s) eta=09:24:47 | 41.7K token/s | 
[epoch_0]_42061  loss=3.091958 |g|=0.474	lr=1.39e-04 | 45.6%@S35  T=1.92s(data=2.0ms QKV=2.12s FFN=3.04s) eta=10:07:36 | 41.7K token/s | 
[epoch_0]_42071  loss=3.142085 |g|=0.475	lr=1.39e-04 | 46.5%@S35  T=1.94s(data=2.1ms QKV=2.12s FFN=3.04s) eta=10:11:52 | 41.7K token/s | 
[epoch_0]_42081  loss=3.130804 |g|=0.469	lr=1.39e-04 | 47.3%@S35  T=1.79s(data=3.7ms QKV=2.11s FFN=3.04s) eta=09:25:17 | 41.9K token/s | 
[epoch_0]_42091  loss=3.112522 |g|=0.468	lr=1.39e-04 | 48.1%@S35  T=1.75s(data=3.3ms QKV=2.11s FFN=3.04s) eta=09:13:37 | 42.2K token/s | 
[Fuyou] head="0" update algorithm=4 t=15.24s
[Section@42100] layer[8-16] tasks=19(nPassBack=0) last_loss=3.16793(-0.0579913) N=(772,47824,47264 5557068)
[epoch_0]_42101  loss=3.078859 |g|=0.466	lr=1.39e-04 | 48.9%@S35  T=5.35s(data=3.3ms QKV=2.11s FFN=3.03s) eta=1d 04:09:06 | 40.8K token/s | 
[epoch_0]_42111  loss=3.108516 |g|=0.467	lr=1.38e-04 | 49.7%@S35  T=1.73s(data=2.6ms QKV=2.11s FFN=3.04s) eta=09:06:51 | 41.2K token/s | 
[epoch_0]_42121  loss=3.132320 |g|=0.461	lr=1.38e-04 | 50.6%@S35  T=1.75s(data=3.2ms QKV=2.11s FFN=3.04s) eta=09:12:49 | 41.4K token/s | 
[epoch_0]_42131  loss=3.115553 |g|=0.45	lr=1.38e-04 | 51.4%@S35  T=1.97s(data=4.1ms QKV=2.12s FFN=3.04s) eta=10:21:22 | 41.4K token/s | 
[epoch_0]_42141  loss=3.003771 |g|=0.462	lr=1.38e-04 | 52.2%@S35  T=1.77s(data=2.8ms QKV=2.11s FFN=3.04s) eta=09:15:49 | 41.7K token/s | 
[epoch_0]_42151  loss=3.140248 |g|=0.488	lr=1.38e-04 | 53.0%@S35  T=1.74s(data=2.9ms QKV=2.12s FFN=3.04s) eta=09:07:10 | 42.0K token/s | 
[epoch_0]_42161  loss=3.029947 |g|=0.476	lr=1.38e-04 | 53.8%@S35  T=1.80s(data=2.5ms QKV=2.11s FFN=3.04s) eta=09:25:57 | 42.1K token/s | 
[epoch_0]_42171  loss=3.055982 |g|=0.463	lr=1.38e-04 | 54.7%@S35  T=1.81s(data=2.1ms QKV=2.12s FFN=3.04s) eta=09:28:27 | 42.3K token/s | 
[epoch_0]_42181  loss=3.134047 |g|=0.469	lr=1.38e-04 | 55.5%@S35  T=1.76s(data=2.7ms QKV=2.11s FFN=3.04s) eta=09:12:37 | 42.5K token/s | 
[epoch_0]_42191  loss=3.049201 |g|=0.464	lr=1.37e-04 | 56.3%@S35  T=1.76s(data=2.7ms QKV=2.12s FFN=3.04s) eta=09:11:32 | 42.7K token/s | 
[Fuyou] head="1" update algorithm=4 t=15.65s
[eval] 
	 Loss@"edu_fineweb1B"=3.133(0.0029) nBranch=1 nToken=6.31M best=3.1360(209) E2T=0.0759 T=36.7784(0)s x=0
	#3.13307±0.0979 tps=172K(6.30784M) a=[2.93815,3.41171] T=36.7784(sec)
[Section@42200] layer[16-24] tasks=19(nPassBack=0) last_loss=3.05719(0.0246415) N=(772,47936,47376 5570268)
[epoch_0]_42201  loss=3.102789 |g|=0.472	lr=1.37e-04 | 57.1%@S35  T=13.51s(data=4.0ms QKV=2.11s FFN=3.03s) eta=2d 22:39:37 | 40.9K token/s | 
[epoch_0]_42211  loss=3.081612 |g|=0.482	lr=1.37e-04 | 57.9%@S35  T=1.75s(data=3.2ms QKV=2.11s FFN=3.04s) eta=09:08:32 | 41.2K token/s | 
[epoch_0]_42221  loss=3.140231 |g|=0.468	lr=1.37e-04 | 58.8%@S35  T=1.85s(data=3.2ms QKV=2.11s FFN=3.04s) eta=09:41:04 | 41.3K token/s | 
[epoch_0]_42231  loss=3.141763 |g|=0.466	lr=1.37e-04 | 59.6%@S35  T=1.91s(data=6.5ms QKV=2.12s FFN=3.04s) eta=09:59:38 | 41.4K token/s | 
[epoch_0]_42241  loss=3.043638 |g|=0.462	lr=1.37e-04 | 60.4%@S35  T=1.76s(data=3.2ms QKV=2.11s FFN=3.04s) eta=09:10:56 | 41.7K token/s | 
[epoch_0]_42251  loss=3.071378 |g|=0.459	lr=1.37e-04 | 61.2%@S35  T=1.81s(data=2.4ms QKV=2.12s FFN=3.04s) eta=09:25:12 | 41.9K token/s | 
[epoch_0]_42261  loss=3.118259 |g|=0.479	lr=1.37e-04 | 62.0%@S35  T=1.82s(data=2.9ms QKV=2.12s FFN=3.04s) eta=09:28:17 | 42.0K token/s | 
[epoch_0]_42271  loss=3.079027 |g|=0.481	lr=1.36e-04 | 62.9%@S35  T=1.77s(data=3.1ms QKV=2.11s FFN=3.04s) eta=09:12:57 | 42.2K token/s | 
[epoch_0]_42281  loss=3.094250 |g|=0.461	lr=1.36e-04 | 63.7%@S35  T=1.87s(data=3.0ms QKV=2.12s FFN=3.04s) eta=09:43:44 | 42.3K token/s | 
[epoch_0]_42291  loss=3.052224 |g|=0.463	lr=1.36e-04 | 64.5%@S35  T=1.91s(data=2.6ms QKV=2.11s FFN=3.04s) eta=09:57:45 | 42.3K token/s | 
[Fuyou] head="2" update algorithm=4 t=12.82s
[Section@42300] layer[24-32] tasks=19(nPassBack=0) last_loss=3.06464(0.0101581) N=(772,48048,47488 5583468)
[epoch_0]_42301  loss=3.174663 |g|=0.499	lr=1.36e-04 | 65.3%@S35  T=4.83s(data=2.3ms QKV=2.12s FFN=3.03s) eta=1d 01:06:50 | 41.1K token/s | 
[epoch_0]_42311  loss=3.082978 |g|=0.487	lr=1.36e-04 | 66.1%@S35  T=1.76s(data=2.2ms QKV=2.12s FFN=3.04s) eta=09:08:36 | 41.3K token/s | 
[epoch_0]_42321  loss=3.014724 |g|=0.447	lr=1.36e-04 | 66.9%@S35  T=1.78s(data=2.0ms QKV=2.12s FFN=3.04s) eta=09:14:59 | 41.6K token/s | 
[epoch_0]_42331  loss=3.051897 |g|=0.469	lr=1.36e-04 | 67.8%@S35  T=1.75s(data=1.9ms QKV=2.12s FFN=3.04s) eta=09:05:12 | 41.8K token/s | 
[epoch_0]_42341  loss=3.147384 |g|=0.492	lr=1.36e-04 | 68.6%@S35  T=1.77s(data=2.0ms QKV=2.13s FFN=3.04s) eta=09:10:27 | 42.1K token/s | 
[epoch_0]_42351  loss=3.135092 |g|=0.484	lr=1.35e-04 | 69.4%@S35  T=1.87s(data=2.0ms QKV=2.12s FFN=3.04s) eta=09:40:52 | 42.2K token/s | 
[epoch_0]_42361  loss=3.088116 |g|=0.467	lr=1.35e-04 | 70.2%@S35  T=1.74s(data=1.7ms QKV=2.12s FFN=3.04s) eta=09:02:19 | 42.4K token/s | 
[epoch_0]_42371  loss=3.093553 |g|=0.456	lr=1.35e-04 | 71.0%@S35  T=1.77s(data=1.7ms QKV=2.12s FFN=3.04s) eta=09:10:02 | 42.6K token/s | 
[epoch_0]_42381  loss=3.071977 |g|=0.47	lr=1.35e-04 | 71.9%@S35  T=1.93s(data=2.0ms QKV=2.13s FFN=3.04s) eta=09:59:25 | 42.6K token/s | 
[epoch_0]_42391  loss=3.161030 |g|=0.467	lr=1.35e-04 | 72.7%@S35  T=1.93s(data=1.9ms QKV=2.13s FFN=3.04s) eta=09:59:32 | 42.6K token/s | 
[Fuyou] head="3" update algorithm=4 t=12.59s
[eval] 
	 Loss@"edu_fineweb1B"=3.131(0.0018) nBranch=1 nToken=6.31M best=3.1331(210) E2T=0.0425 T=36.7832(0)s x=0
	#3.13123±0.0974 tps=171K(6.30784M) a=[2.93739,3.40891] T=36.7832(sec)
[Section@42400] layer[32-40] tasks=19(nPassBack=0) last_loss=3.08877(0.108603) N=(772,48160,47600 5596668)
[epoch_0]_42401  loss=3.151707 |g|=0.456	lr=1.35e-04 | 73.5%@S35  T=12.80s(data=4.4ms QKV=2.12s FFN=3.04s) eta=2d 18:16:47 | 40.8K token/s | 
[epoch_0]_42411  loss=3.181057 |g|=0.464	lr=1.35e-04 | 74.3%@S35  T=1.84s(data=4.0ms QKV=2.12s FFN=3.04s) eta=09:30:10 | 41.0K token/s | 
[epoch_0]_42421  loss=3.135443 |g|=0.481	lr=1.35e-04 | 75.1%@S35  T=1.76s(data=3.2ms QKV=2.12s FFN=3.04s) eta=09:05:24 | 41.3K token/s | 
[epoch_0]_42431  loss=3.146453 |g|=0.49	lr=1.34e-04 | 76.0%@S35  T=1.79s(data=3.3ms QKV=2.12s FFN=3.04s) eta=09:15:10 | 41.5K token/s | 
[epoch_0]_42441  loss=3.126333 |g|=0.465	lr=1.34e-04 | 76.8%@S35  T=1.78s(data=4.7ms QKV=2.12s FFN=3.04s) eta=09:13:01 | 41.7K token/s | 
[epoch_0]_42451  loss=3.093385 |g|=0.457	lr=1.34e-04 | 77.6%@S35  T=1.81s(data=3.0ms QKV=2.12s FFN=3.04s) eta=09:19:09 | 41.9K token/s | 
[epoch_0]_42461  loss=3.100071 |g|=0.467	lr=1.34e-04 | 78.4%@S35  T=1.79s(data=1.6ms QKV=2.13s FFN=3.04s) eta=09:12:50 | 42.1K token/s | 
[epoch_0]_42471  loss=3.052803 |g|=0.467	lr=1.34e-04 | 79.2%@S35  T=1.77s(data=2.9ms QKV=2.12s FFN=3.04s) eta=09:06:53 | 42.3K token/s | 
[epoch_0]_42481  loss=3.065427 |g|=0.48	lr=1.34e-04 | 80.1%@S35  T=1.77s(data=2.7ms QKV=2.12s FFN=3.04s) eta=09:08:50 | 42.5K token/s | 
[epoch_0]_42491  loss=3.107817 |g|=0.471	lr=1.34e-04 | 80.9%@S35  T=1.75s(data=3.6ms QKV=2.12s FFN=3.04s) eta=09:02:11 | 42.7K token/s | 
[Fuyou] head="4" update algorithm=4 t=16.05s
[Section@42500] layer[40-48] tasks=19(nPassBack=0) last_loss=3.09261(0.0211809) N=(772,48272,47712 5609868)
[epoch_0]_42501  loss=3.064454 |g|=0.466	lr=1.34e-04 | 81.7%@S35  T=5.14s(data=3.6ms QKV=2.12s FFN=3.03s) eta=1d 02:26:17 | 41.4K token/s | 
[epoch_0]_42511  loss=3.047354 |g|=0.458	lr=1.33e-04 | 82.5%@S35  T=1.79s(data=2.2ms QKV=2.12s FFN=3.04s) eta=09:13:30 | 41.6K token/s | 
[epoch_0]_42521  loss=3.080661 |g|=0.483	lr=1.33e-04 | 83.3%@S35  T=1.78s(data=2.9ms QKV=2.12s FFN=3.04s) eta=09:08:28 | 41.8K token/s | 
[epoch_0]_42531  loss=3.094712 |g|=0.483	lr=1.33e-04 | 84.1%@S35  T=1.89s(data=8.7ms QKV=2.13s FFN=3.04s) eta=09:42:44 | 41.9K token/s | 
[epoch_0]_42541  loss=2.999277 |g|=0.455	lr=1.33e-04 | 85.0%@S35  T=1.86s(data=2.9ms QKV=2.12s FFN=3.04s) eta=09:32:57 | 42.0K token/s | 
[epoch_0]_42551  loss=3.082700 |g|=0.465	lr=1.33e-04 | 85.8%@S35  T=1.94s(data=2.1ms QKV=2.13s FFN=3.04s) eta=09:59:03 | 42.0K token/s | 
[epoch_0]_42561  loss=3.075215 |g|=0.473	lr=1.33e-04 | 86.6%@S35  T=1.98s(data=3.1ms QKV=2.12s FFN=3.04s) eta=10:10:39 | 42.0K token/s | 
[epoch_0]_42571  loss=3.061831 |g|=0.471	lr=1.33e-04 | 87.4%@S35  T=1.90s(data=3.1ms QKV=2.12s FFN=3.04s) eta=09:43:27 | 42.0K token/s | 
[epoch_0]_42581  loss=3.133736 |g|=0.467	lr=1.32e-04 | 88.2%@S35  T=1.74s(data=2.9ms QKV=2.12s FFN=3.04s) eta=08:56:40 | 42.3K token/s | 
[epoch_0]_42591  loss=3.053425 |g|=0.462	lr=1.32e-04 | 89.1%@S35  T=1.81s(data=2.8ms QKV=2.12s FFN=3.04s) eta=09:15:54 | 42.4K token/s | 
[Fuyou] head="5" update algorithm=4 t=14.54s
[eval] 
	 Loss@"edu_fineweb1B"=3.129(0.0018) nBranch=1 nToken=6.31M best=3.1312(211) E2T=0.0393 T=36.7869(0)s x=0
	#3.1294±0.0978 tps=171K(6.30784M) a=[2.93812,3.40864] T=36.7869(sec)
[Section@42600] layer[0-8] tasks=19(nPassBack=0) last_loss=3.09007(-0.00609207) N=(772,48384,47824 5623068)
[epoch_0]_42601  loss=3.102754 |g|=0.474	lr=1.32e-04 | 89.9%@S35  T=13.26s(data=3.3ms QKV=2.11s FFN=3.03s) eta=2d 19:54:06 | 40.6K token/s | 
[epoch_0]_42611  loss=3.113485 |g|=0.483	lr=1.32e-04 | 90.7%@S35  T=1.90s(data=3.0ms QKV=2.12s FFN=3.04s) eta=09:43:15 | 40.7K token/s | 
[epoch_0]_42621  loss=3.098094 |g|=0.479	lr=1.32e-04 | 91.5%@S35  T=1.76s(data=3.2ms QKV=2.12s FFN=3.04s) eta=09:01:39 | 41.0K token/s | 
[epoch_0]_42631  loss=3.066260 |g|=0.467	lr=1.32e-04 | 92.3%@S35  T=1.87s(data=2.1ms QKV=2.13s FFN=3.04s) eta=09:32:15 | 41.2K token/s | 
[epoch_0]_42641  loss=3.043403 |g|=0.474	lr=1.32e-04 | 93.2%@S35  T=1.77s(data=2.5ms QKV=2.13s FFN=3.04s) eta=09:03:54 | 41.4K token/s | 
[epoch_0]_42651  loss=3.096192 |g|=0.46	lr=1.32e-04 | 94.0%@S35  T=1.77s(data=2.6ms QKV=2.12s FFN=3.04s) eta=09:02:05 | 41.7K token/s | 
[epoch_0]_42661  loss=3.083974 |g|=0.501	lr=1.31e-04 | 94.8%@S35  T=1.80s(data=2.1ms QKV=2.12s FFN=3.04s) eta=09:12:19 | 41.8K token/s | 
[epoch_0]_42671  loss=3.018293 |g|=0.466	lr=1.31e-04 | 95.6%@S35  T=1.97s(data=2.1ms QKV=2.13s FFN=3.04s) eta=10:01:27 | 41.8K token/s | 
[epoch_0]_42681  loss=3.118038 |g|=0.473	lr=1.31e-04 | 96.4%@S35  T=1.99s(data=2.1ms QKV=2.13s FFN=3.04s) eta=10:09:18 | 41.8K token/s | 
[epoch_0]_42691  loss=3.125699 |g|=0.488	lr=1.31e-04 | 97.3%@S35  T=1.90s(data=2.1ms QKV=2.12s FFN=3.04s) eta=09:40:34 | 41.9K token/s | 
[Fuyou] head="0" update algorithm=4 t=12.09s
[Section@42700] layer[8-16] tasks=19(nPassBack=0) last_loss=3.06085(0.10708) N=(772,48496,47936 5636268)
[epoch_0]_42701  loss=3.072520 |g|=0.482	lr=1.31e-04 | 98.1%@S35  T=4.90s(data=1.8ms QKV=2.12s FFN=3.03s) eta=1d 00:57:10 | 40.6K token/s | 
[epoch_0]_42711  loss=3.159848 |g|=0.509	lr=1.31e-04 | 98.9%@S35  T=1.90s(data=1.9ms QKV=2.12s FFN=3.04s) eta=09:39:44 | 40.7K token/s | 
[epoch_0]_42721  loss=3.108079 |g|=0.484	lr=1.31e-04 | 99.7%@S35  T=1.79s(data=1.9ms QKV=2.12s FFN=3.04s) eta=09:05:39 | 41.0K token/s | 
[epoch_0]_42724  loss=3.015870 |g|=0.481	lr=1.31e-04 | 100.0%@S35  T=1.76s(data=1.8ms QKV=2.12s FFN=3.04s) eta=08:56:19 | 41.3K token/s | 
-------- End of shard_35@"./Datasets/edu_fineweb1B/edu_fineweb_train_000793.bin"-------- 
[shard-36]@"./Datasets/edu_fineweb1B/edu_fineweb_train_000794.bin": tokens=100(M) nShardSamples=1220(3515616) 
[epoch_0]_42731  loss=3.142438 |g|=0.461	lr=1.31e-04 | 0.5%@S36  T=1.75s(data=1.7ms QKV=2.12s FFN=3.04s) eta=08:52:37 | 41.6K token/s | 
[epoch_0]_42741  loss=3.057695 |g|=0.507	lr=1.30e-04 | 1.4%@S36  T=1.83s(data=1.8ms QKV=2.13s FFN=3.04s) eta=09:18:48 | 41.7K token/s | 
[epoch_0]_42751  loss=3.107760 |g|=0.463	lr=1.30e-04 | 2.2%@S36  T=1.91s(data=4.6ms QKV=2.13s FFN=3.04s) eta=09:41:48 | 41.8K token/s | 
[epoch_0]_42761  loss=3.202891 |g|=0.478	lr=1.30e-04 | 3.0%@S36  T=1.76s(data=1.8ms QKV=2.12s FFN=3.04s) eta=08:54:32 | 42.0K token/s | 
[epoch_0]_42771  loss=3.154084 |g|=0.468	lr=1.30e-04 | 3.8%@S36  T=1.78s(data=2.0ms QKV=2.12s FFN=3.04s) eta=09:00:27 | 42.2K token/s | 
[epoch_0]_42781  loss=3.006595 |g|=0.461	lr=1.30e-04 | 4.6%@S36  T=1.80s(data=1.7ms QKV=2.12s FFN=3.04s) eta=09:07:46 | 42.4K token/s | 
[epoch_0]_42791  loss=3.123977 |g|=0.458	lr=1.30e-04 | 5.4%@S36  T=1.74s(data=1.6ms QKV=2.12s FFN=3.04s) eta=08:50:31 | 42.6K token/s | 
[Fuyou] head="1" update algorithm=4 t=10.94s
[eval] 
	 Loss@"edu_fineweb1B"=3.130(-0.00072) nBranch=1 nToken=6.31M best=3.1294(212) E2T=-0.0237 T=36.7448(0)s x=0
	#3.13012±0.0977 tps=172K(6.30784M) a=[2.93844,3.40721] T=36.7448(sec)
[Section@42800] layer[16-24] tasks=19(nPassBack=0) last_loss=3.1538(-0.0966079) N=(772,48608,48048 5649468)
[epoch_0]_42801  loss=3.181638 |g|=0.464	lr=1.30e-04 | 6.3%@S36  T=12.38s(data=2.4ms QKV=2.12s FFN=3.03s) eta=2d 14:41:54 | 40.8K token/s | 
[epoch_0]_42811  loss=3.118635 |g|=0.485	lr=1.30e-04 | 7.1%@S36  T=1.79s(data=2.2ms QKV=2.12s FFN=3.04s) eta=09:04:38 | 41.1K token/s | 
[epoch_0]_42821  loss=3.098576 |g|=0.472	lr=1.29e-04 | 7.9%@S36  T=1.83s(data=2.2ms QKV=2.11s FFN=3.04s) eta=09:15:45 | 41.2K token/s | 
[epoch_0]_42831  loss=3.160533 |g|=0.475	lr=1.29e-04 | 8.7%@S36  T=1.77s(data=2.1ms QKV=2.11s FFN=3.04s) eta=08:57:10 | 41.5K token/s | 
[epoch_0]_42841  loss=3.070062 |g|=0.49	lr=1.29e-04 | 9.5%@S36  T=1.80s(data=2.0ms QKV=2.11s FFN=3.04s) eta=09:04:21 | 41.7K token/s | 
[epoch_0]_42851  loss=3.080594 |g|=0.482	lr=1.29e-04 | 10.4%@S36  T=1.74s(data=1.8ms QKV=2.11s FFN=3.04s) eta=08:46:26 | 42.0K token/s | 
[epoch_0]_42861  loss=3.101590 |g|=0.48	lr=1.29e-04 | 11.2%@S36  T=1.74s(data=1.7ms QKV=2.11s FFN=3.04s) eta=08:46:40 | 42.2K token/s | 
[epoch_0]_42871  loss=3.070992 |g|=0.475	lr=1.29e-04 | 12.0%@S36  T=1.75s(data=1.7ms QKV=2.11s FFN=3.04s) eta=08:49:41 | 42.5K token/s | 
[epoch_0]_42881  loss=3.105489 |g|=0.466	lr=1.29e-04 | 12.8%@S36  T=1.86s(data=2.1ms QKV=2.11s FFN=3.04s) eta=09:24:00 | 42.5K token/s | 
[epoch_0]_42891  loss=3.193555 |g|=0.499	lr=1.29e-04 | 13.6%@S36  T=1.86s(data=2.6ms QKV=2.11s FFN=3.04s) eta=09:22:16 | 42.6K token/s | 
[Fuyou] head="2" update algorithm=4 t=13.82s
[Section@42900] layer[24-32] tasks=19(nPassBack=0) last_loss=3.08964(-0.0249946) N=(772,48720,48160 5662668)
[epoch_0]_42901  loss=3.123966 |g|=0.477	lr=1.28e-04 | 14.5%@S36  T=5.46s(data=2.1ms QKV=2.12s FFN=3.03s) eta=1d 03:28:45 | 41.2K token/s | 
[epoch_0]_42911  loss=3.099339 |g|=0.466	lr=1.28e-04 | 15.3%@S36  T=1.82s(data=2.5ms QKV=2.12s FFN=3.04s) eta=09:09:07 | 41.4K token/s | 
[epoch_0]_42921  loss=3.093504 |g|=0.486	lr=1.28e-04 | 16.1%@S36  T=1.89s(data=2.7ms QKV=2.12s FFN=3.04s) eta=09:29:24 | 41.5K token/s | 
[epoch_0]_42931  loss=3.104060 |g|=0.473	lr=1.28e-04 | 16.9%@S36  T=1.78s(data=2.4ms QKV=2.12s FFN=3.04s) eta=08:57:16 | 41.7K token/s | 
[epoch_0]_42941  loss=3.103410 |g|=0.475	lr=1.28e-04 | 17.7%@S36  T=1.80s(data=2.3ms QKV=2.13s FFN=3.04s) eta=09:01:56 | 41.9K token/s | 
[epoch_0]_42951  loss=3.161018 |g|=0.464	lr=1.28e-04 | 18.6%@S36  T=1.81s(data=1.9ms QKV=2.13s FFN=3.04s) eta=09:05:59 | 42.1K token/s | 
[epoch_0]_42961  loss=3.094755 |g|=0.483	lr=1.28e-04 | 19.4%@S36  T=1.87s(data=2.0ms QKV=2.12s FFN=3.04s) eta=09:22:11 | 42.2K token/s | 
[epoch_0]_42971  loss=3.084238 |g|=0.462	lr=1.28e-04 | 20.2%@S36  T=1.82s(data=1.8ms QKV=2.13s FFN=3.04s) eta=09:08:02 | 42.3K token/s | 
[epoch_0]_42981  loss=3.162788 |g|=0.501	lr=1.27e-04 | 21.0%@S36  T=1.80s(data=2.0ms QKV=2.12s FFN=3.04s) eta=09:00:09 | 42.5K token/s | 
[epoch_0]_42991  loss=3.113817 |g|=0.476	lr=1.27e-04 | 21.8%@S36  T=1.80s(data=2.1ms QKV=2.13s FFN=3.04s) eta=09:02:01 | 42.6K token/s | 
[Fuyou] head="3" update algorithm=4 t=16.01s
[eval] 
	 Loss@"edu_fineweb1B"=3.130(0.00023) nBranch=1 nToken=6.31M best=3.1294(212) E2T=0.052 T=36.7957(0)s x=0
	#3.12989±0.0984 tps=171K(6.30784M) a=[2.938,3.41168] T=36.7957(sec)
[Section@43000] layer[32-40] tasks=19(nPassBack=0) last_loss=3.07789(0.0108755) N=(772,48832,48272 5675868)
[epoch_0]_43001  loss=3.129744 |g|=0.483	lr=1.27e-04 | 22.7%@S36  T=13.36s(data=4.0ms QKV=2.12s FFN=3.04s) eta=2d 18:54:11 | 40.8K token/s | 
[epoch_0]_43011  loss=3.067437 |g|=0.462	lr=1.27e-04 | 23.5%@S36  T=1.89s(data=2.9ms QKV=2.12s FFN=3.04s) eta=09:28:02 | 40.9K token/s | 
[epoch_0]_43021  loss=3.095596 |g|=0.465	lr=1.27e-04 | 24.3%@S36  T=1.92s(data=2.0ms QKV=2.12s FFN=3.04s) eta=09:35:40 | 41.0K token/s | 
[epoch_0]_43031  loss=3.060901 |g|=0.456	lr=1.27e-04 | 25.1%@S36  T=1.76s(data=2.4ms QKV=2.12s FFN=3.04s) eta=08:48:04 | 41.3K token/s | 
[epoch_0]_43041  loss=3.030126 |g|=0.461	lr=1.27e-04 | 25.9%@S36  T=1.95s(data=2.1ms QKV=2.12s FFN=3.04s) eta=09:45:35 | 41.3K token/s | 
[epoch_0]_43051  loss=3.084639 |g|=0.468	lr=1.27e-04 | 26.7%@S36  T=1.79s(data=1.9ms QKV=2.12s FFN=3.04s) eta=08:57:30 | 41.6K token/s | 
[epoch_0]_43061  loss=3.097658 |g|=0.479	lr=1.26e-04 | 27.6%@S36  T=1.79s(data=1.8ms QKV=2.12s FFN=3.04s) eta=08:55:03 | 41.8K token/s | 
[epoch_0]_43071  loss=3.087170 |g|=0.458	lr=1.26e-04 | 28.4%@S36  T=1.75s(data=2.3ms QKV=2.12s FFN=3.04s) eta=08:44:45 | 42.0K token/s | 
[epoch_0]_43081  loss=3.071569 |g|=0.466	lr=1.26e-04 | 29.2%@S36  T=1.88s(data=1.9ms QKV=2.12s FFN=3.04s) eta=09:21:37 | 42.1K token/s | 
[epoch_0]_43091  loss=3.106082 |g|=0.458	lr=1.26e-04 | 30.0%@S36  T=1.87s(data=2.6ms QKV=2.12s FFN=3.04s) eta=09:17:58 | 42.2K token/s | 
[Fuyou] head="4" update algorithm=4 t=15.40s
[Section@43100] layer[40-48] tasks=19(nPassBack=0) last_loss=3.08393(0.00867462) N=(772,48944,48384 5689068)
[epoch_0]_43101  loss=3.075006 |g|=0.462	lr=1.26e-04 | 30.8%@S36  T=4.92s(data=2.2ms QKV=2.11s FFN=3.03s) eta=1d 00:30:26 | 40.9K token/s | 
[epoch_0]_43111  loss=3.023469 |g|=0.478	lr=1.26e-04 | 31.7%@S36  T=1.76s(data=2.2ms QKV=2.12s FFN=3.04s) eta=08:45:29 | 41.2K token/s | 
[epoch_0]_43121  loss=3.129580 |g|=0.474	lr=1.26e-04 | 32.5%@S36  T=1.85s(data=2.3ms QKV=2.12s FFN=3.04s) eta=09:13:10 | 41.4K token/s | 
[epoch_0]_43131  loss=3.047029 |g|=0.457	lr=1.26e-04 | 33.3%@S36  T=1.81s(data=1.8ms QKV=2.13s FFN=3.04s) eta=09:00:48 | 41.5K token/s | 
[epoch_0]_43141  loss=3.076056 |g|=0.493	lr=1.25e-04 | 34.1%@S36  T=1.90s(data=2.5ms QKV=2.12s FFN=3.04s) eta=09:26:48 | 41.6K token/s | 
[epoch_0]_43151  loss=3.063097 |g|=0.472	lr=1.25e-04 | 34.9%@S36  T=1.80s(data=3.4ms QKV=2.12s FFN=3.04s) eta=08:57:29 | 41.8K token/s | 
[epoch_0]_43161  loss=3.092018 |g|=0.484	lr=1.25e-04 | 35.8%@S36  T=1.80s(data=2.1ms QKV=2.13s FFN=3.04s) eta=08:54:53 | 42.0K token/s | 
[epoch_0]_43171  loss=3.122589 |g|=0.485	lr=1.25e-04 | 36.6%@S36  T=1.76s(data=2.2ms QKV=2.12s FFN=3.04s) eta=08:45:14 | 42.2K token/s | 
[epoch_0]_43181  loss=3.158550 |g|=0.499	lr=1.25e-04 | 37.4%@S36  T=1.90s(data=2.1ms QKV=2.13s FFN=3.04s) eta=09:25:49 | 42.3K token/s | 
[epoch_0]_43191  loss=3.101646 |g|=0.479	lr=1.25e-04 | 38.2%@S36  T=1.78s(data=2.6ms QKV=2.12s FFN=3.04s) eta=08:48:40 | 42.5K token/s | 
[Fuyou] head="5" update algorithm=4 t=15.44s
[eval] 
	 Loss@"edu_fineweb1B"=3.129(0.0011) nBranch=1 nToken=6.31M best=3.1299(214) E2T=0.049 T=36.784(0)s x=0
	#3.12876±0.0980 tps=171K(6.30784M) a=[2.93959,3.40643] T=36.784(sec)
[Section@43200] layer[0-8] tasks=19(nPassBack=0) last_loss=3.07977(0.0102987) N=(772,49056,48496 5702268)
[epoch_0]_43201  loss=3.101885 |g|=0.46	lr=1.25e-04 | 39.0%@S36  T=13.23s(data=3.0ms QKV=2.12s FFN=3.04s) eta=2d 17:33:52 | 40.6K token/s | 
[epoch_0]_43211  loss=3.071444 |g|=0.465	lr=1.25e-04 | 39.9%@S36  T=1.77s(data=2.6ms QKV=2.12s FFN=3.04s) eta=08:44:50 | 40.9K token/s | 
[epoch_0]_43221  loss=3.090806 |g|=0.467	lr=1.24e-04 | 40.7%@S36  T=1.94s(data=2.2ms QKV=2.13s FFN=3.04s) eta=09:36:51 | 41.0K token/s | 
[epoch_0]_43231  loss=3.077992 |g|=0.477	lr=1.24e-04 | 41.5%@S36  T=1.82s(data=2.7ms QKV=2.12s FFN=3.04s) eta=09:00:40 | 41.2K token/s | 
[epoch_0]_43241  loss=3.133073 |g|=0.487	lr=1.24e-04 | 42.3%@S36  T=1.82s(data=2.7ms QKV=2.12s FFN=3.04s) eta=09:01:12 | 41.4K token/s | 
[epoch_0]_43251  loss=3.109390 |g|=0.487	lr=1.24e-04 | 43.1%@S36  T=1.89s(data=2.4ms QKV=2.12s FFN=3.04s) eta=09:20:48 | 41.5K token/s | 
[epoch_0]_43261  loss=3.138344 |g|=0.479	lr=1.24e-04 | 44.0%@S36  T=1.91s(data=2.3ms QKV=2.12s FFN=3.04s) eta=09:24:53 | 41.5K token/s | 
[epoch_0]_43271  loss=3.079858 |g|=0.472	lr=1.24e-04 | 44.8%@S36  T=1.95s(data=2.1ms QKV=2.12s FFN=3.04s) eta=09:37:56 | 41.6K token/s | 
[epoch_0]_43281  loss=3.045171 |g|=0.463	lr=1.24e-04 | 45.6%@S36  T=1.84s(data=2.1ms QKV=2.12s FFN=3.04s) eta=09:04:57 | 41.7K token/s | 
[epoch_0]_43291  loss=3.107117 |g|=0.459	lr=1.24e-04 | 46.4%@S36  T=1.83s(data=2.0ms QKV=2.12s FFN=3.04s) eta=09:00:54 | 41.9K token/s | 
[Fuyou] head="0" update algorithm=4 t=15.08s
[Section@43300] layer[8-16] tasks=19(nPassBack=0) last_loss=3.11982(-0.0589736) N=(772,49168,48608 5715468)
[epoch_0]_43301  loss=3.051085 |g|=0.469	lr=1.24e-04 | 47.2%@S36  T=5.76s(data=2.6ms QKV=2.13s FFN=3.03s) eta=1d 04:22:47 | 40.5K token/s | 
[epoch_0]_43311  loss=3.016490 |g|=0.488	lr=1.23e-04 | 48.0%@S36  T=1.75s(data=2.8ms QKV=2.12s FFN=3.04s) eta=08:35:41 | 40.8K token/s | 
[epoch_0]_43321  loss=3.029406 |g|=0.484	lr=1.23e-04 | 48.9%@S36  T=1.74s(data=2.6ms QKV=2.13s FFN=3.04s) eta=08:34:55 | 41.1K token/s | 
[epoch_0]_43331  loss=3.088000 |g|=0.472	lr=1.23e-04 | 49.7%@S36  T=1.74s(data=2.2ms QKV=2.13s FFN=3.04s) eta=08:32:45 | 41.4K token/s | 
[epoch_0]_43341  loss=3.102617 |g|=0.474	lr=1.23e-04 | 50.5%@S36  T=1.76s(data=2.6ms QKV=2.13s FFN=3.04s) eta=08:38:53 | 41.7K token/s | 
[epoch_0]_43351  loss=3.063297 |g|=0.477	lr=1.23e-04 | 51.3%@S36  T=1.82s(data=2.8ms QKV=2.13s FFN=3.04s) eta=08:57:07 | 41.8K token/s | 
[epoch_0]_43361  loss=3.006990 |g|=0.494	lr=1.23e-04 | 52.1%@S36  T=1.75s(data=2.6ms QKV=2.13s FFN=3.04s) eta=08:35:40 | 42.1K token/s | 
[epoch_0]_43371  loss=3.033420 |g|=0.485	lr=1.23e-04 | 53.0%@S36  T=1.77s(data=2.5ms QKV=2.14s FFN=3.04s) eta=08:39:45 | 42.3K token/s | 
[epoch_0]_43381  loss=3.163489 |g|=0.47	lr=1.23e-04 | 53.8%@S36  T=1.78s(data=2.2ms QKV=2.13s FFN=3.04s) eta=08:43:10 | 42.5K token/s | 
[epoch_0]_43391  loss=3.172700 |g|=0.479	lr=1.22e-04 | 54.6%@S36  T=1.94s(data=2.0ms QKV=2.13s FFN=3.04s) eta=09:31:19 | 42.5K token/s | 
[Fuyou] head="1" update algorithm=4 t=15.26s
[eval] 
	 Loss@"edu_fineweb1B"=3.128(0.00086) nBranch=1 nToken=6.31M best=3.1288(215) E2T=0.0641 T=36.7789(0)s x=0
	#3.1279±0.0983 tps=172K(6.30784M) a=[2.93387,3.4091] T=36.7789(sec)
[Section@43400] layer[16-24] tasks=19(nPassBack=0) last_loss=3.06379(0.0900092) N=(772,49280,48720 5728668)
[epoch_0]_43401  loss=3.027740 |g|=0.448	lr=1.22e-04 | 55.4%@S36  T=13.63s(data=3.6ms QKV=2.12s FFN=3.03s) eta=2d 18:45:00 | 40.6K token/s | 
[epoch_0]_43411  loss=3.079437 |g|=0.464	lr=1.22e-04 | 56.2%@S36  T=1.77s(data=2.6ms QKV=2.11s FFN=3.04s) eta=08:40:07 | 40.9K token/s | 
[epoch_0]_43421  loss=3.114712 |g|=0.471	lr=1.22e-04 | 57.1%@S36  T=1.80s(data=2.0ms QKV=2.11s FFN=3.04s) eta=08:48:20 | 41.2K token/s | 
[epoch_0]_43431  loss=3.100855 |g|=0.486	lr=1.22e-04 | 57.9%@S36  T=1.88s(data=1.9ms QKV=2.12s FFN=3.04s) eta=09:12:38 | 41.3K token/s | 
[epoch_0]_43441  loss=3.062536 |g|=0.475	lr=1.22e-04 | 58.7%@S36  T=1.84s(data=1.6ms QKV=2.12s FFN=3.04s) eta=08:59:19 | 41.4K token/s | 
[epoch_0]_43451  loss=2.993028 |g|=0.453	lr=1.22e-04 | 59.5%@S36  T=1.89s(data=2.2ms QKV=2.12s FFN=3.04s) eta=09:14:32 | 41.5K token/s | 
[epoch_0]_43461  loss=3.105683 |g|=0.478	lr=1.22e-04 | 60.3%@S36  T=1.96s(data=2.1ms QKV=2.12s FFN=3.04s) eta=09:34:07 | 41.5K token/s | 
[epoch_0]_43471  loss=3.023402 |g|=0.459	lr=1.21e-04 | 61.2%@S36  T=1.80s(data=2.0ms QKV=2.13s FFN=3.04s) eta=08:47:44 | 41.7K token/s | 
[epoch_0]_43481  loss=3.048909 |g|=0.468	lr=1.21e-04 | 62.0%@S36  T=1.77s(data=1.7ms QKV=2.12s FFN=3.04s) eta=08:36:45 | 42.0K token/s | 
[epoch_0]_43491  loss=3.021214 |g|=0.479	lr=1.21e-04 | 62.8%@S36  T=1.81s(data=2.0ms QKV=2.13s FFN=3.04s) eta=08:50:25 | 42.1K token/s | 
[Fuyou] head="2" update algorithm=4 t=11.02s
[Section@43500] layer[24-32] tasks=19(nPassBack=0) last_loss=3.12637(-0.036736) N=(772,49392,48832 5741868)
[epoch_0]_43501  loss=3.151435 |g|=0.482	lr=1.21e-04 | 63.6%@S36  T=4.80s(data=1.6ms QKV=2.12s FFN=3.03s) eta=23:22:10 | 40.9K token/s | 
[epoch_0]_43511  loss=3.080595 |g|=0.478	lr=1.21e-04 | 64.4%@S36  T=1.74s(data=1.6ms QKV=2.12s FFN=3.04s) eta=08:27:04 | 41.2K token/s | 
[epoch_0]_43521  loss=3.032310 |g|=0.477	lr=1.21e-04 | 65.3%@S36  T=1.77s(data=1.6ms QKV=2.12s FFN=3.04s) eta=08:35:16 | 41.5K token/s | 
[epoch_0]_43531  loss=3.072288 |g|=0.473	lr=1.21e-04 | 66.1%@S36  T=1.78s(data=1.9ms QKV=2.12s FFN=3.04s) eta=08:40:20 | 41.7K token/s | 
[epoch_0]_43541  loss=3.100625 |g|=0.487	lr=1.21e-04 | 66.9%@S36  T=1.82s(data=2.1ms QKV=2.13s FFN=3.04s) eta=08:49:20 | 41.9K token/s | 
[epoch_0]_43551  loss=3.124207 |g|=0.475	lr=1.20e-04 | 67.7%@S36  T=1.75s(data=1.7ms QKV=2.12s FFN=3.04s) eta=08:28:52 | 42.1K token/s | 
[epoch_0]_43561  loss=3.036643 |g|=0.46	lr=1.20e-04 | 68.5%@S36  T=1.77s(data=1.9ms QKV=2.12s FFN=3.04s) eta=08:34:12 | 42.3K token/s | 
[epoch_0]_43571  loss=3.105862 |g|=0.483	lr=1.20e-04 | 69.3%@S36  T=1.91s(data=1.5ms QKV=2.12s FFN=3.04s) eta=09:14:58 | 42.4K token/s | 
[epoch_0]_43581  loss=3.026776 |g|=0.457	lr=1.20e-04 | 70.2%@S36  T=1.75s(data=1.5ms QKV=2.12s FFN=3.04s) eta=08:28:12 | 42.6K token/s | 
[epoch_0]_43591  loss=2.990501 |g|=0.468	lr=1.20e-04 | 71.0%@S36  T=1.90s(data=1.6ms QKV=2.12s FFN=3.04s) eta=09:12:20 | 42.6K token/s | 
[Fuyou] head="3" update algorithm=4 t=11.53s
[eval] 
	 Loss@"edu_fineweb1B"=3.128(-1.5e-05) nBranch=1 nToken=6.31M best=3.1279(216) E2T=0.102 T=36.76(0)s x=0
	#3.12792±0.0985 tps=172K(6.30784M) a=[2.93284,3.41149] T=36.76(sec)
[Section@43600] layer[32-40] tasks=19(nPassBack=0) last_loss=3.02572(0.0521746) N=(772,49504,48944 5755068)
[epoch_0]_43601  loss=3.079360 |g|=0.456	lr=1.20e-04 | 71.8%@S36  T=12.15s(data=2.0ms QKV=2.11s FFN=3.04s) eta=2d 10:51:31 | 40.8K token/s | 
[epoch_0]_43611  loss=3.043117 |g|=0.455	lr=1.20e-04 | 72.6%@S36  T=1.87s(data=1.7ms QKV=2.12s FFN=3.04s) eta=09:02:33 | 41.0K token/s | 
[epoch_0]_43621  loss=3.120857 |g|=0.475	lr=1.20e-04 | 73.4%@S36  T=1.81s(data=1.9ms QKV=2.12s FFN=3.04s) eta=08:44:53 | 41.2K token/s | 
[epoch_0]_43631  loss=3.032842 |g|=0.461	lr=1.19e-04 | 74.3%@S36  T=1.75s(data=1.7ms QKV=2.12s FFN=3.04s) eta=08:26:53 | 41.5K token/s | 
[epoch_0]_43641  loss=3.076159 |g|=0.469	lr=1.19e-04 | 75.1%@S36  T=1.75s(data=1.8ms QKV=2.12s FFN=3.04s) eta=08:28:05 | 41.7K token/s | 
[epoch_0]_43651  loss=3.051435 |g|=0.464	lr=1.19e-04 | 75.9%@S36  T=1.92s(data=1.9ms QKV=2.12s FFN=3.04s) eta=09:14:58 | 41.8K token/s | 
[epoch_0]_43661  loss=3.027314 |g|=0.459	lr=1.19e-04 | 76.7%@S36  T=1.75s(data=1.7ms QKV=2.12s FFN=3.04s) eta=08:27:57 | 42.0K token/s | 
[epoch_0]_43671  loss=3.101081 |g|=0.481	lr=1.19e-04 | 77.5%@S36  T=1.76s(data=2.2ms QKV=2.12s FFN=3.04s) eta=08:29:36 | 42.3K token/s | 
[epoch_0]_43681  loss=3.129924 |g|=0.473	lr=1.19e-04 | 78.4%@S36  T=1.76s(data=2.1ms QKV=2.12s FFN=3.04s) eta=08:29:37 | 42.5K token/s | 
[epoch_0]_43691  loss=3.056606 |g|=0.475	lr=1.19e-04 | 79.2%@S36  T=1.81s(data=2.0ms QKV=2.12s FFN=3.04s) eta=08:44:10 | 42.6K token/s | 
[Fuyou] head="4" update algorithm=4 t=11.93s
[Section@43700] layer[40-48] tasks=19(nPassBack=0) last_loss=3.09623(-0.0122969) N=(772,49616,49056 5768268)
[epoch_0]_43701  loss=3.074764 |g|=0.454	lr=1.19e-04 | 80.0%@S36  T=4.21s(data=1.9ms QKV=2.12s FFN=3.03s) eta=20:15:00 | 41.4K token/s | 
[epoch_0]_43711  loss=3.070251 |g|=0.468	lr=1.19e-04 | 80.8%@S36  T=1.74s(data=1.9ms QKV=2.12s FFN=3.04s) eta=08:21:33 | 41.7K token/s | 
[epoch_0]_43721  loss=3.038679 |g|=0.47	lr=1.18e-04 | 81.6%@S36  T=1.79s(data=7.7ms QKV=2.12s FFN=3.04s) eta=08:35:25 | 41.9K token/s | 
[epoch_0]_43731  loss=3.106192 |g|=0.478	lr=1.18e-04 | 82.5%@S36  T=1.83s(data=2.1ms QKV=2.13s FFN=3.04s) eta=08:48:37 | 42.1K token/s | 
[epoch_0]_43741  loss=3.047280 |g|=0.469	lr=1.18e-04 | 83.3%@S36  T=1.77s(data=2.5ms QKV=2.12s FFN=3.04s) eta=08:30:58 | 42.3K token/s | 
[epoch_0]_43751  loss=3.112239 |g|=0.462	lr=1.18e-04 | 84.1%@S36  T=1.82s(data=2.0ms QKV=2.13s FFN=3.04s) eta=08:45:26 | 42.4K token/s | 
[epoch_0]_43761  loss=3.096549 |g|=0.464	lr=1.18e-04 | 84.9%@S36  T=1.90s(data=2.4ms QKV=2.12s FFN=3.04s) eta=09:06:06 | 42.5K token/s | 
[epoch_0]_43771  loss=3.007673 |g|=0.503	lr=1.18e-04 | 85.7%@S36  T=1.92s(data=3.2ms QKV=2.12s FFN=3.04s) eta=09:13:36 | 42.5K token/s | 
[epoch_0]_43781  loss=3.095602 |g|=0.477	lr=1.18e-04 | 86.5%@S36  T=1.89s(data=3.0ms QKV=2.13s FFN=3.04s) eta=09:04:15 | 42.5K token/s | 
[epoch_0]_43791  loss=3.021690 |g|=0.467	lr=1.18e-04 | 87.4%@S36  T=1.75s(data=2.5ms QKV=2.12s FFN=3.04s) eta=08:21:32 | 42.7K token/s | 
[Fuyou] head="5" update algorithm=4 t=14.21s
[eval] 
	 Loss@"edu_fineweb1B"=3.127(0.0011) nBranch=1 nToken=6.31M best=3.1279(217) E2T=0.0482 T=36.7849(0)s x=0
	#3.12683±0.0985 tps=171K(6.30784M) a=[2.93446,3.41029] T=36.7849(sec)
[Section@43800] layer[0-8] tasks=19(nPassBack=0) last_loss=3.07863(0.00114083) N=(772,49728,49168 5781468)
[epoch_0]_43801  loss=3.123422 |g|=0.456	lr=1.17e-04 | 88.2%@S36  T=12.61s(data=2.7ms QKV=2.11s FFN=3.04s) eta=2d 12:20:47 | 40.9K token/s | 
[epoch_0]_43811  loss=3.110502 |g|=0.498	lr=1.17e-04 | 89.0%@S36  T=1.83s(data=2.0ms QKV=2.12s FFN=3.04s) eta=08:45:14 | 41.1K token/s | 
[epoch_0]_43821  loss=3.044473 |g|=0.489	lr=1.17e-04 | 89.8%@S36  T=1.91s(data=2.1ms QKV=2.12s FFN=3.04s) eta=09:08:48 | 41.2K token/s | 
[epoch_0]_43831  loss=3.104095 |g|=0.496	lr=1.17e-04 | 90.6%@S36  T=1.80s(data=2.9ms QKV=2.11s FFN=3.04s) eta=08:35:47 | 41.4K token/s | 
[epoch_0]_43841  loss=3.098351 |g|=0.481	lr=1.17e-04 | 91.5%@S36  T=1.76s(data=2.9ms QKV=2.11s FFN=3.04s) eta=08:23:13 | 41.7K token/s | 
[epoch_0]_43851  loss=3.131104 |g|=0.506	lr=1.17e-04 | 92.3%@S36  T=1.75s(data=2.7ms QKV=2.11s FFN=3.04s) eta=08:20:56 | 41.9K token/s | 
[epoch_0]_43861  loss=3.094091 |g|=0.464	lr=1.17e-04 | 93.1%@S36  T=1.75s(data=2.5ms QKV=2.11s FFN=3.04s) eta=08:20:50 | 42.2K token/s | 
[epoch_0]_43871  loss=3.124245 |g|=0.488	lr=1.17e-04 | 93.9%@S36  T=1.75s(data=2.6ms QKV=2.12s FFN=3.04s) eta=08:21:42 | 42.4K token/s | 
[epoch_0]_43881  loss=3.129925 |g|=0.479	lr=1.16e-04 | 94.7%@S36  T=1.83s(data=2.5ms QKV=2.11s FFN=3.04s) eta=08:43:22 | 42.5K token/s | 
[epoch_0]_43891  loss=3.116902 |g|=0.483	lr=1.16e-04 | 95.6%@S36  T=1.75s(data=2.2ms QKV=2.11s FFN=3.04s) eta=08:19:58 | 42.7K token/s | 
[Fuyou] head="0" update algorithm=4 t=12.53s
[Section@43900] layer[8-16] tasks=19(nPassBack=0) last_loss=3.04284(0.0769827) N=(772,49840,49280 5794668)
[epoch_0]_43901  loss=3.113787 |g|=0.463	lr=1.16e-04 | 96.4%@S36  T=4.90s(data=2.6ms QKV=2.13s FFN=3.03s) eta=23:19:13 | 41.4K token/s | 
[epoch_0]_43911  loss=3.079188 |g|=0.465	lr=1.16e-04 | 97.2%@S36  T=1.74s(data=2.4ms QKV=2.14s FFN=3.04s) eta=08:17:22 | 41.7K token/s | 
[epoch_0]_43921  loss=3.007166 |g|=0.466	lr=1.16e-04 | 98.0%@S36  T=1.75s(data=1.9ms QKV=2.13s FFN=3.04s) eta=08:18:19 | 42.0K token/s | 
[epoch_0]_43931  loss=3.049530 |g|=0.464	lr=1.16e-04 | 98.8%@S36  T=1.84s(data=2.0ms QKV=2.14s FFN=3.04s) eta=08:45:36 | 42.1K token/s | 
[epoch_0]_43941  loss=3.126664 |g|=0.466	lr=1.16e-04 | 99.7%@S36  T=1.89s(data=2.0ms QKV=2.14s FFN=3.04s) eta=08:57:25 | 42.2K token/s | 
[epoch_0]_43945  loss=3.102219 |g|=0.463	lr=1.16e-04 | 100.0%@S36  T=1.75s(data=1.7ms QKV=2.14s FFN=3.04s) eta=08:19:19 | 42.4K token/s | 
-------- End of shard_36@"./Datasets/edu_fineweb1B/edu_fineweb_train_000794.bin"-------- 
[shard-37]@"./Datasets/edu_fineweb1B/edu_fineweb_train_000795.bin": tokens=100(M) nShardSamples=1220(3613272) 
[epoch_0]_43951  loss=3.172490 |g|=0.469	lr=1.16e-04 | 0.5%@S37  T=1.76s(data=1.4ms QKV=2.14s FFN=3.04s) eta=08:22:29 | 42.6K token/s | 
[epoch_0]_43961  loss=3.063998 |g|=0.483	lr=1.16e-04 | 1.3%@S37  T=1.76s(data=1.4ms QKV=2.14s FFN=3.04s) eta=08:22:01 | 42.8K token/s | 
[epoch_0]_43971  loss=3.066069 |g|=0.476	lr=1.15e-04 | 2.1%@S37  T=1.82s(data=1.7ms QKV=2.14s FFN=3.04s) eta=08:38:44 | 42.9K token/s | 
[epoch_0]_43981  loss=3.106309 |g|=0.494	lr=1.15e-04 | 2.9%@S37  T=1.88s(data=1.5ms QKV=2.14s FFN=3.04s) eta=08:54:58 | 42.9K token/s | 
[epoch_0]_43991  loss=3.137109 |g|=0.475	lr=1.15e-04 | 3.8%@S37  T=1.75s(data=1.4ms QKV=2.14s FFN=3.04s) eta=08:16:15 | 43.1K token/s | 
[Fuyou] head="1" update algorithm=4 t=11.60s
[eval] 
	 Loss@"edu_fineweb1B"=3.123(0.0039) nBranch=1 nToken=6.31M best=3.1268(218) E2T=0.0476 T=36.7686(0)s x=0
	#3.12291±0.0983 tps=172K(6.30784M) a=[2.93246,3.40503] T=36.7686(sec)
[Section@44000] layer[16-24] tasks=19(nPassBack=0) last_loss=3.07531(-0.0115225) N=(772,49952,49392 5807868)
[epoch_0]_44001  loss=3.071542 |g|=0.475	lr=1.15e-04 | 4.6%@S37  T=12.68s(data=2.1ms QKV=2.13s FFN=3.04s) eta=2d 12:00:11 | 41.3K token/s | 
[epoch_0]_44011  loss=3.102033 |g|=0.485	lr=1.15e-04 | 5.4%@S37  T=1.89s(data=1.7ms QKV=2.13s FFN=3.04s) eta=08:56:37 | 41.4K token/s | 
[epoch_0]_44021  loss=3.037815 |g|=0.475	lr=1.15e-04 | 6.2%@S37  T=1.94s(data=2.1ms QKV=2.14s FFN=3.04s) eta=09:11:02 | 41.4K token/s | 
[epoch_0]_44031  loss=3.082265 |g|=0.515	lr=1.15e-04 | 7.0%@S37  T=1.79s(data=1.7ms QKV=2.13s FFN=3.04s) eta=08:28:23 | 41.6K token/s | 
[epoch_0]_44041  loss=3.125277 |g|=0.491	lr=1.15e-04 | 7.8%@S37  T=1.99s(data=2.2ms QKV=2.14s FFN=3.04s) eta=09:23:34 | 41.6K token/s | 
[epoch_0]_44051  loss=3.159196 |g|=0.471	lr=1.14e-04 | 8.7%@S37  T=2.00s(data=2.2ms QKV=2.14s FFN=3.04s) eta=09:26:56 | 41.6K token/s | 
[epoch_0]_44061  loss=3.149478 |g|=0.49	lr=1.14e-04 | 9.5%@S37  T=1.92s(data=2.0ms QKV=2.13s FFN=3.04s) eta=09:01:56 | 41.6K token/s | 
[epoch_0]_44071  loss=3.052249 |g|=0.479	lr=1.14e-04 | 10.3%@S37  T=1.95s(data=2.3ms QKV=2.14s FFN=3.04s) eta=09:12:24 | 41.7K token/s | 
[epoch_0]_44081  loss=3.055347 |g|=0.458	lr=1.14e-04 | 11.1%@S37  T=2.00s(data=2.0ms QKV=2.14s FFN=3.04s) eta=09:24:55 | 41.6K token/s | 
[epoch_0]_44091  loss=3.026008 |g|=0.491	lr=1.14e-04 | 11.9%@S37  T=1.86s(data=1.9ms QKV=2.13s FFN=3.04s) eta=08:46:18 | 41.7K token/s | 
[Fuyou] head="2" update algorithm=4 t=10.89s
[Section@44100] layer[24-32] tasks=19(nPassBack=0) last_loss=3.02354(0.102831) N=(772,50064,49504 5821068)
[epoch_0]_44101  loss=3.052218 |g|=0.484	lr=1.14e-04 | 12.8%@S37  T=4.82s(data=1.9ms QKV=2.14s FFN=3.03s) eta=22:39:02 | 40.5K token/s | 
[epoch_0]_44111  loss=3.032950 |g|=0.478	lr=1.14e-04 | 13.6%@S37  T=1.98s(data=2.2ms QKV=2.15s FFN=3.04s) eta=09:17:16 | 40.5K token/s | 
[epoch_0]_44121  loss=3.175414 |g|=0.492	lr=1.14e-04 | 14.4%@S37  T=2.00s(data=2.0ms QKV=2.15s FFN=3.04s) eta=09:24:29 | 40.6K token/s | 
[epoch_0]_44131  loss=3.048450 |g|=0.472	lr=1.13e-04 | 15.2%@S37  T=1.98s(data=2.2ms QKV=2.15s FFN=3.04s) eta=09:16:48 | 40.6K token/s | 
[epoch_0]_44141  loss=3.187040 |g|=0.477	lr=1.13e-04 | 16.0%@S37  T=1.81s(data=2.2ms QKV=2.15s FFN=3.04s) eta=08:29:50 | 40.8K token/s | 
[epoch_0]_44151  loss=3.200993 |g|=0.49	lr=1.13e-04 | 16.9%@S37  T=2.01s(data=2.1ms QKV=2.15s FFN=3.04s) eta=09:26:57 | 40.8K token/s | 
[epoch_0]_44161  loss=3.086653 |g|=0.481	lr=1.13e-04 | 17.7%@S37  T=1.90s(data=1.8ms QKV=2.14s FFN=3.04s) eta=08:52:56 | 41.0K token/s | 
[epoch_0]_44171  loss=3.111692 |g|=0.489	lr=1.13e-04 | 18.5%@S37  T=1.95s(data=1.8ms QKV=2.15s FFN=3.04s) eta=09:07:29 | 41.0K token/s | 
[epoch_0]_44181  loss=3.098176 |g|=0.471	lr=1.13e-04 | 19.3%@S37  T=1.82s(data=2.0ms QKV=2.15s FFN=3.04s) eta=08:29:50 | 41.2K token/s | 
[epoch_0]_44191  loss=3.131221 |g|=0.467	lr=1.13e-04 | 20.1%@S37  T=1.93s(data=2.2ms QKV=2.15s FFN=3.04s) eta=09:01:19 | 41.3K token/s | 
[Fuyou] head="3" update algorithm=4 t=11.25s
[eval] 
	 Loss@"edu_fineweb1B"=3.118(0.0044) nBranch=1 nToken=6.31M best=3.1229(219) E2T=-0.000878 T=36.7595(0)s x=0
	#3.11848±0.0982 tps=172K(6.30784M) a=[2.92976,3.40015] T=36.7595(sec)
[Section@44200] layer[32-40] tasks=19(nPassBack=0) last_loss=3.11936(-0.0936408) N=(772,50176,49616 5834268)
[epoch_0]_44201  loss=3.064521 |g|=0.466	lr=1.13e-04 | 21.0%@S37  T=12.42s(data=2.3ms QKV=2.14s FFN=3.04s) eta=2d 10:05:03 | 39.5K token/s | 
[epoch_0]_44211  loss=3.116382 |g|=0.505	lr=1.13e-04 | 21.8%@S37  T=1.96s(data=2.3ms QKV=2.14s FFN=3.04s) eta=09:09:46 | 39.7K token/s | 
[epoch_0]_44221  loss=3.118537 |g|=0.497	lr=1.12e-04 | 22.6%@S37  T=1.75s(data=1.9ms QKV=2.14s FFN=3.04s) eta=08:09:57 | 40.0K token/s | 
[epoch_0]_44231  loss=3.081650 |g|=0.478	lr=1.12e-04 | 23.4%@S37  T=1.90s(data=1.9ms QKV=2.14s FFN=3.04s) eta=08:52:19 | 40.2K token/s | 
[epoch_0]_44241  loss=3.073319 |g|=0.489	lr=1.12e-04 | 24.2%@S37  T=1.96s(data=2.1ms QKV=2.14s FFN=3.04s) eta=09:08:12 | 40.3K token/s | 
[epoch_0]_44251  loss=3.169780 |g|=0.485	lr=1.12e-04 | 25.1%@S37  T=1.91s(data=1.7ms QKV=2.14s FFN=3.04s) eta=08:52:56 | 40.4K token/s | 
[epoch_0]_44261  loss=3.108848 |g|=0.474	lr=1.12e-04 | 25.9%@S37  T=1.99s(data=2.0ms QKV=2.15s FFN=3.04s) eta=09:14:57 | 40.4K token/s | 
[epoch_0]_44271  loss=3.131173 |g|=0.485	lr=1.12e-04 | 26.7%@S37  T=1.98s(data=2.1ms QKV=2.14s FFN=3.04s) eta=09:13:10 | 40.5K token/s | 
[epoch_0]_44281  loss=3.103489 |g|=0.484	lr=1.12e-04 | 27.5%@S37  T=1.77s(data=1.9ms QKV=2.14s FFN=3.04s) eta=08:14:18 | 40.8K token/s | 
[epoch_0]_44291  loss=3.128441 |g|=0.504	lr=1.12e-04 | 28.3%@S37  T=1.84s(data=2.0ms QKV=2.14s FFN=3.04s) eta=08:32:16 | 41.0K token/s | 
[Fuyou] head="4" update algorithm=4 t=13.21s
[Section@44300] layer[40-48] tasks=19(nPassBack=0) last_loss=3.04016(0.056066) N=(772,50288,49728 5847468)
[epoch_0]_44301  loss=3.036678 |g|=0.465	lr=1.11e-04 | 29.1%@S37  T=4.51s(data=1.9ms QKV=2.14s FFN=3.03s) eta=20:58:21 | 39.8K token/s | 
[epoch_0]_44311  loss=3.083447 |g|=0.49	lr=1.11e-04 | 30.0%@S37  T=1.83s(data=1.9ms QKV=2.14s FFN=3.04s) eta=08:29:53 | 40.1K token/s | 
[epoch_0]_44321  loss=3.108688 |g|=0.479	lr=1.11e-04 | 30.8%@S37  T=1.78s(data=1.5ms QKV=2.14s FFN=3.04s) eta=08:16:19 | 40.4K token/s | 
[epoch_0]_44331  loss=3.174965 |g|=0.491	lr=1.11e-04 | 31.6%@S37  T=1.77s(data=2.1ms QKV=2.14s FFN=3.04s) eta=08:13:46 | 40.7K token/s | 
[epoch_0]_44341  loss=3.144748 |g|=0.512	lr=1.11e-04 | 32.4%@S37  T=1.76s(data=1.5ms QKV=2.14s FFN=3.04s) eta=08:09:44 | 41.0K token/s | 
[epoch_0]_44351  loss=3.047903 |g|=0.474	lr=1.11e-04 | 33.2%@S37  T=1.76s(data=1.7ms QKV=2.14s FFN=3.04s) eta=08:09:54 | 41.2K token/s | 
[epoch_0]_44361  loss=3.104375 |g|=0.489	lr=1.11e-04 | 34.1%@S37  T=1.77s(data=2.0ms QKV=2.14s FFN=3.04s) eta=08:13:02 | 41.5K token/s | 
[epoch_0]_44371  loss=3.056458 |g|=0.463	lr=1.11e-04 | 34.9%@S37  T=1.79s(data=2.4ms QKV=2.14s FFN=3.04s) eta=08:15:49 | 41.7K token/s | 
[epoch_0]_44381  loss=3.102822 |g|=0.486	lr=1.11e-04 | 35.7%@S37  T=1.86s(data=2.3ms QKV=2.15s FFN=3.04s) eta=08:36:22 | 41.8K token/s | 
[epoch_0]_44391  loss=3.035377 |g|=0.468	lr=1.10e-04 | 36.5%@S37  T=1.96s(data=2.1ms QKV=2.15s FFN=3.04s) eta=09:04:47 | 41.8K token/s | 
[Fuyou] head="5" update algorithm=4 t=13.00s
[eval] 
	 Loss@"edu_fineweb1B"=3.117(0.0018) nBranch=1 nToken=6.31M best=3.1185(220) E2T=0.0626 T=36.7778(0)s x=0
	#3.11672±0.0983 tps=172K(6.30784M) a=[2.92836,3.39755] T=36.7778(sec)
[Section@44400] layer[0-8] tasks=19(nPassBack=0) last_loss=3.05414(0.0244944) N=(772,50400,49840 5860668)
[epoch_0]_44401  loss=3.046466 |g|=0.482	lr=1.10e-04 | 37.3%@S37  T=12.74s(data=2.5ms QKV=2.13s FFN=3.03s) eta=2d 10:50:45 | 40.0K token/s | 
[epoch_0]_44411  loss=3.110934 |g|=0.49	lr=1.10e-04 | 38.2%@S37  T=1.93s(data=1.7ms QKV=2.12s FFN=3.04s) eta=08:53:42 | 40.2K token/s | 
[epoch_0]_44421  loss=3.075038 |g|=0.48	lr=1.10e-04 | 39.0%@S37  T=1.83s(data=2.2ms QKV=2.12s FFN=3.04s) eta=08:26:47 | 40.4K token/s | 
[epoch_0]_44431  loss=3.080811 |g|=0.497	lr=1.10e-04 | 39.8%@S37  T=1.77s(data=1.8ms QKV=2.12s FFN=3.04s) eta=08:10:38 | 40.7K token/s | 
[epoch_0]_44441  loss=3.111175 |g|=0.491	lr=1.10e-04 | 40.6%@S37  T=1.92s(data=1.6ms QKV=2.12s FFN=3.04s) eta=08:50:14 | 40.8K token/s | 
[epoch_0]_44451  loss=3.084013 |g|=0.475	lr=1.10e-04 | 41.4%@S37  T=1.98s(data=2.1ms QKV=2.13s FFN=3.04s) eta=09:08:21 | 40.8K token/s | 
[epoch_0]_44461  loss=3.118545 |g|=0.485	lr=1.10e-04 | 42.3%@S37  T=1.81s(data=1.8ms QKV=2.12s FFN=3.04s) eta=08:18:38 | 41.0K token/s | 
[epoch_0]_44471  loss=2.965749 |g|=0.482	lr=1.09e-04 | 43.1%@S37  T=1.94s(data=2.0ms QKV=2.13s FFN=3.04s) eta=08:54:55 | 41.1K token/s | 
[epoch_0]_44481  loss=3.123205 |g|=0.48	lr=1.09e-04 | 43.9%@S37  T=1.94s(data=1.7ms QKV=2.12s FFN=3.04s) eta=08:54:38 | 41.2K token/s | 
[epoch_0]_44491  loss=3.133634 |g|=0.473	lr=1.09e-04 | 44.7%@S37  T=2.01s(data=2.2ms QKV=2.13s FFN=3.04s) eta=09:15:09 | 41.1K token/s | 
[Fuyou] head="0" update algorithm=4 t=13.06s
[Section@44500] layer[8-16] tasks=19(nPassBack=0) last_loss=3.07784(-0.0350025) N=(772,50512,49952 5873868)
[epoch_0]_44501  loss=3.125752 |g|=0.477	lr=1.09e-04 | 45.5%@S37  T=4.98s(data=2.1ms QKV=2.13s FFN=3.03s) eta=22:52:28 | 39.9K token/s | 
[epoch_0]_44511  loss=3.048849 |g|=0.479	lr=1.09e-04 | 46.4%@S37  T=1.75s(data=2.0ms QKV=2.13s FFN=3.04s) eta=08:01:45 | 40.2K token/s | 
[epoch_0]_44521  loss=3.045037 |g|=0.474	lr=1.09e-04 | 47.2%@S37  T=1.77s(data=1.8ms QKV=2.13s FFN=3.04s) eta=08:06:55 | 40.6K token/s | 
[epoch_0]_44531  loss=3.125937 |g|=0.504	lr=1.09e-04 | 48.0%@S37  T=1.74s(data=1.8ms QKV=2.13s FFN=3.04s) eta=07:59:35 | 40.9K token/s | 
[epoch_0]_44541  loss=3.119653 |g|=0.502	lr=1.09e-04 | 48.8%@S37  T=1.97s(data=1.9ms QKV=2.14s FFN=3.04s) eta=09:00:21 | 40.9K token/s | 
[epoch_0]_44551  loss=3.009533 |g|=0.494	lr=1.09e-04 | 49.6%@S37  T=1.89s(data=2.1ms QKV=2.14s FFN=3.04s) eta=08:38:19 | 41.0K token/s | 
[epoch_0]_44561  loss=3.181282 |g|=0.497	lr=1.08e-04 | 50.4%@S37  T=2.00s(data=2.2ms QKV=2.14s FFN=3.04s) eta=09:09:29 | 41.0K token/s | 
[epoch_0]_44571  loss=3.056892 |g|=0.491	lr=1.08e-04 | 51.3%@S37  T=1.96s(data=2.2ms QKV=2.15s FFN=3.04s) eta=08:57:02 | 41.1K token/s | 
[epoch_0]_44581  loss=3.047482 |g|=0.487	lr=1.08e-04 | 52.1%@S37  T=1.94s(data=2.1ms QKV=2.14s FFN=3.04s) eta=08:51:44 | 41.1K token/s | 
[epoch_0]_44591  loss=3.051223 |g|=0.486	lr=1.08e-04 | 52.9%@S37  T=1.89s(data=1.8ms QKV=2.13s FFN=3.04s) eta=08:37:50 | 41.2K token/s | 
[Fuyou] head="1" update algorithm=4 t=10.67s
[eval] 
	 Loss@"edu_fineweb1B"=3.115(0.0022) nBranch=1 nToken=6.31M best=3.1167(221) E2T=0.0258 T=36.7981(0)s x=0
	#3.11451±0.0981 tps=171K(6.30784M) a=[2.9277,3.39369] T=36.7981(sec)
[Section@44600] layer[16-24] tasks=19(nPassBack=0) last_loss=3.08875(-0.0134318) N=(772,50624,50064 5887068)
[epoch_0]_44601  loss=3.125310 |g|=0.502	lr=1.08e-04 | 53.7%@S37  T=12.79s(data=1.9ms QKV=2.12s FFN=3.04s) eta=2d 10:22:38 | 39.5K token/s | 
[epoch_0]_44611  loss=3.124634 |g|=0.508	lr=1.08e-04 | 54.5%@S37  T=1.95s(data=2.0ms QKV=2.13s FFN=3.04s) eta=08:53:55 | 39.6K token/s | 
[epoch_0]_44621  loss=3.063451 |g|=0.508	lr=1.08e-04 | 55.4%@S37  T=1.81s(data=2.2ms QKV=2.13s FFN=3.04s) eta=08:14:58 | 39.9K token/s | 
[epoch_0]_44631  loss=3.079862 |g|=0.495	lr=1.08e-04 | 56.2%@S37  T=1.95s(data=2.1ms QKV=2.13s FFN=3.04s) eta=08:54:12 | 40.0K token/s | 
[epoch_0]_44641  loss=3.129394 |g|=0.488	lr=1.07e-04 | 57.0%@S37  T=1.81s(data=2.1ms QKV=2.13s FFN=3.04s) eta=08:15:23 | 40.3K token/s | 
[epoch_0]_44651  loss=3.118646 |g|=0.482	lr=1.07e-04 | 57.8%@S37  T=1.99s(data=2.1ms QKV=2.13s FFN=3.04s) eta=09:02:43 | 40.3K token/s | 
[epoch_0]_44661  loss=3.019282 |g|=0.493	lr=1.07e-04 | 58.6%@S37  T=1.80s(data=1.8ms QKV=2.12s FFN=3.04s) eta=08:09:53 | 40.6K token/s | 
[epoch_0]_44671  loss=3.041086 |g|=0.502	lr=1.07e-04 | 59.5%@S37  T=1.97s(data=2.0ms QKV=2.13s FFN=3.04s) eta=08:56:26 | 40.6K token/s | 
[epoch_0]_44681  loss=3.135973 |g|=0.528	lr=1.07e-04 | 60.3%@S37  T=1.94s(data=1.9ms QKV=2.12s FFN=3.04s) eta=08:49:59 | 40.7K token/s | 
[epoch_0]_44691  loss=3.111790 |g|=0.474	lr=1.07e-04 | 61.1%@S37  T=1.99s(data=2.4ms QKV=2.14s FFN=3.04s) eta=09:01:51 | 40.7K token/s | 
[Fuyou] head="2" update algorithm=4 t=11.75s
[Section@44700] layer[24-32] tasks=19(nPassBack=0) last_loss=3.06722(-0.0436752) N=(772,50736,50176 5900268)
[epoch_0]_44701  loss=3.035711 |g|=0.473	lr=1.07e-04 | 61.9%@S37  T=5.01s(data=2.3ms QKV=2.12s FFN=3.03s) eta=22:43:02 | 39.5K token/s | 
[epoch_0]_44711  loss=3.022753 |g|=0.506	lr=1.07e-04 | 62.7%@S37  T=1.94s(data=1.9ms QKV=2.13s FFN=3.04s) eta=08:48:54 | 39.6K token/s | 
[epoch_0]_44721  loss=3.044773 |g|=0.477	lr=1.07e-04 | 63.6%@S37  T=1.76s(data=1.9ms QKV=2.12s FFN=3.04s) eta=07:57:11 | 40.0K token/s | 
[epoch_0]_44731  loss=3.052094 |g|=0.478	lr=1.06e-04 | 64.4%@S37  T=1.93s(data=2.1ms QKV=2.14s FFN=3.04s) eta=08:45:20 | 40.1K token/s | 
[epoch_0]_44741  loss=3.125318 |g|=0.489	lr=1.06e-04 | 65.2%@S37  T=1.79s(data=1.6ms QKV=2.13s FFN=3.04s) eta=08:05:50 | 40.4K token/s | 
[epoch_0]_44751  loss=3.052720 |g|=0.488	lr=1.06e-04 | 66.0%@S37  T=1.78s(data=1.8ms QKV=2.13s FFN=3.04s) eta=08:01:50 | 40.7K token/s | 
[epoch_0]_44761  loss=3.146567 |g|=0.471	lr=1.06e-04 | 66.8%@S37  T=1.91s(data=1.9ms QKV=2.13s FFN=3.04s) eta=08:37:51 | 40.8K token/s | 
[epoch_0]_44771  loss=3.073644 |g|=0.482	lr=1.06e-04 | 67.7%@S37  T=1.97s(data=2.0ms QKV=2.14s FFN=3.04s) eta=08:52:44 | 40.8K token/s | 
[epoch_0]_44781  loss=3.086186 |g|=0.503	lr=1.06e-04 | 68.5%@S37  T=1.75s(data=1.8ms QKV=2.13s FFN=3.04s) eta=07:55:05 | 41.1K token/s | 
[epoch_0]_44791  loss=3.060820 |g|=0.478	lr=1.06e-04 | 69.3%@S37  T=1.97s(data=2.0ms QKV=2.13s FFN=3.04s) eta=08:53:46 | 41.2K token/s | 
[Fuyou] head="3" update algorithm=4 t=12.33s
[eval] 
	 Loss@"edu_fineweb1B"=3.114(0.001) nBranch=1 nToken=6.31M best=3.1145(222) E2T=0.041 T=36.8316(0)s x=0
	#3.11351±0.0978 tps=171K(6.30784M) a=[2.92517,3.39086] T=36.8316(sec)
[Section@44800] layer[32-40] tasks=19(nPassBack=0) last_loss=3.07249(0.0468726) N=(772,50848,50288 5913468)
[epoch_0]_44801  loss=3.058769 |g|=0.48	lr=1.06e-04 | 70.1%@S37  T=12.14s(data=1.9ms QKV=2.12s FFN=3.04s) eta=2d 06:43:46 | 39.4K token/s | 
[epoch_0]_44811  loss=3.050247 |g|=0.485	lr=1.06e-04 | 70.9%@S37  T=1.78s(data=1.8ms QKV=2.12s FFN=3.04s) eta=08:00:21 | 39.8K token/s | 
[epoch_0]_44821  loss=2.994167 |g|=0.514	lr=1.05e-04 | 71.7%@S37  T=1.91s(data=1.7ms QKV=2.12s FFN=3.04s) eta=08:34:58 | 39.9K token/s | 
[epoch_0]_44831  loss=3.117645 |g|=0.497	lr=1.05e-04 | 72.6%@S37  T=1.82s(data=2.1ms QKV=2.13s FFN=3.04s) eta=08:11:23 | 40.2K token/s | 
[epoch_0]_44841  loss=3.056047 |g|=0.474	lr=1.05e-04 | 73.4%@S37  T=1.82s(data=2.1ms QKV=2.13s FFN=3.04s) eta=08:12:11 | 40.4K token/s | 
[epoch_0]_44851  loss=3.012406 |g|=0.47	lr=1.05e-04 | 74.2%@S37  T=1.76s(data=1.6ms QKV=2.12s FFN=3.04s) eta=07:55:14 | 40.7K token/s | 
[epoch_0]_44861  loss=3.177836 |g|=0.474	lr=1.05e-04 | 75.0%@S37  T=1.95s(data=2.1ms QKV=2.12s FFN=3.04s) eta=08:44:42 | 40.8K token/s | 
[epoch_0]_44871  loss=3.015176 |g|=0.473	lr=1.05e-04 | 75.8%@S37  T=1.82s(data=1.9ms QKV=2.14s FFN=3.04s) eta=08:10:32 | 41.0K token/s | 
[epoch_0]_44881  loss=3.172340 |g|=0.482	lr=1.05e-04 | 76.7%@S37  T=1.82s(data=2.0ms QKV=2.13s FFN=3.04s) eta=08:10:17 | 41.2K token/s | 
[epoch_0]_44891  loss=3.100866 |g|=0.488	lr=1.05e-04 | 77.5%@S37  T=1.87s(data=2.0ms QKV=2.14s FFN=3.04s) eta=08:23:02 | 41.3K token/s | 
[Fuyou] head="4" update algorithm=4 t=13.21s
[Section@44900] layer[40-48] tasks=19(nPassBack=0) last_loss=3.10951(-0.0693443) N=(772,50960,50400 5926668)
[epoch_0]_44901  loss=3.045150 |g|=0.475	lr=1.04e-04 | 78.3%@S37  T=4.33s(data=2.0ms QKV=2.13s FFN=3.03s) eta=19:23:49 | 40.2K token/s | 
[epoch_0]_44911  loss=3.132381 |g|=0.469	lr=1.04e-04 | 79.1%@S37  T=1.76s(data=2.0ms QKV=2.13s FFN=3.04s) eta=07:53:32 | 40.5K token/s | 
[epoch_0]_44921  loss=3.087819 |g|=0.477	lr=1.04e-04 | 79.9%@S37  T=1.90s(data=2.2ms QKV=2.13s FFN=3.04s) eta=08:29:49 | 40.7K token/s | 
[epoch_0]_44931  loss=3.114455 |g|=0.503	lr=1.04e-04 | 80.8%@S37  T=1.87s(data=1.8ms QKV=2.13s FFN=3.04s) eta=08:21:18 | 40.8K token/s | 
[epoch_0]_44941  loss=3.139789 |g|=0.49	lr=1.04e-04 | 81.6%@S37  T=1.95s(data=2.0ms QKV=2.14s FFN=3.04s) eta=08:42:41 | 40.9K token/s | 
[epoch_0]_44951  loss=3.018437 |g|=0.483	lr=1.04e-04 | 82.4%@S37  T=1.97s(data=2.0ms QKV=2.15s FFN=3.04s) eta=08:47:38 | 40.9K token/s | 
[epoch_0]_44961  loss=3.075966 |g|=0.476	lr=1.04e-04 | 83.2%@S37  T=1.81s(data=1.8ms QKV=2.14s FFN=3.04s) eta=08:04:14 | 41.1K token/s | 
[epoch_0]_44971  loss=3.073812 |g|=0.524	lr=1.04e-04 | 84.0%@S37  T=1.79s(data=1.9ms QKV=2.13s FFN=3.04s) eta=07:59:49 | 41.4K token/s | 
[epoch_0]_44981  loss=3.052829 |g|=0.486	lr=1.04e-04 | 84.9%@S37  T=1.77s(data=2.2ms QKV=2.13s FFN=3.04s) eta=07:53:37 | 41.6K token/s | 
[epoch_0]_44991  loss=3.034594 |g|=0.469	lr=1.03e-04 | 85.7%@S37  T=1.76s(data=1.9ms QKV=2.13s FFN=3.04s) eta=07:50:27 | 41.9K token/s | 
[Fuyou] head="5" update algorithm=4 t=12.80s
[eval] 
	 Loss@"edu_fineweb1B"=3.112(0.0017) nBranch=1 nToken=6.31M best=3.1135(223) E2T=0.0259 T=36.7298(0)s x=0
	#3.11181±0.0977 tps=172K(6.30784M) a=[2.92533,3.39116] T=36.7298(sec)
[Section@45000] layer[0-8] tasks=19(nPassBack=0) last_loss=3.08596(-0.0318244) N=(772,51072,50512 5939868)
[epoch_0]_45001  loss=3.069982 |g|=0.487	lr=1.03e-04 | 86.5%@S37  T=12.43s(data=2.3ms QKV=2.13s FFN=3.04s) eta=2d 07:22:28 | 40.1K token/s | 
[epoch_0]_45011  loss=3.078226 |g|=0.489	lr=1.03e-04 | 87.3%@S37  T=1.77s(data=1.9ms QKV=2.13s FFN=3.04s) eta=07:51:35 | 40.4K token/s | 
[epoch_0]_45021  loss=3.081306 |g|=0.481	lr=1.03e-04 | 88.1%@S37  T=1.75s(data=1.9ms QKV=2.13s FFN=3.04s) eta=07:47:33 | 40.7K token/s | 
[epoch_0]_45031  loss=3.145256 |g|=0.471	lr=1.03e-04 | 88.9%@S37  T=1.82s(data=1.9ms QKV=2.13s FFN=3.04s) eta=08:04:38 | 40.9K token/s | 
[epoch_0]_45041  loss=3.081242 |g|=0.506	lr=1.03e-04 | 89.8%@S37  T=1.86s(data=1.8ms QKV=2.13s FFN=3.04s) eta=08:16:47 | 41.1K token/s | 
[epoch_0]_45051  loss=3.079680 |g|=0.483	lr=1.03e-04 | 90.6%@S37  T=1.85s(data=2.2ms QKV=2.14s FFN=3.04s) eta=08:13:03 | 41.3K token/s | 
[epoch_0]_45061  loss=3.067174 |g|=0.489	lr=1.03e-04 | 91.4%@S37  T=1.82s(data=2.1ms QKV=2.14s FFN=3.04s) eta=08:03:58 | 41.4K token/s | 
[epoch_0]_45071  loss=3.053585 |g|=0.468	lr=1.03e-04 | 92.2%@S37  T=1.83s(data=2.1ms QKV=2.14s FFN=3.04s) eta=08:06:46 | 41.6K token/s | 
[epoch_0]_45081  loss=3.010866 |g|=0.482	lr=1.02e-04 | 93.0%@S37  T=1.82s(data=2.0ms QKV=2.14s FFN=3.04s) eta=08:02:39 | 41.8K token/s | 
[epoch_0]_45091  loss=3.034478 |g|=0.504	lr=1.02e-04 | 93.9%@S37  T=1.98s(data=2.2ms QKV=2.14s FFN=3.04s) eta=08:45:43 | 41.8K token/s | 
[Fuyou] head="0" update algorithm=4 t=12.77s
[Section@45100] layer[8-16] tasks=19(nPassBack=0) last_loss=3.03606(0.0417833) N=(772,51184,50624 5953068)
[epoch_0]_45101  loss=3.121534 |g|=0.478	lr=1.02e-04 | 94.7%@S37  T=5.04s(data=2.9ms QKV=2.14s FFN=3.03s) eta=22:18:34 | 40.5K token/s | 
[epoch_0]_45111  loss=3.044252 |g|=0.535	lr=1.02e-04 | 95.5%@S37  T=1.75s(data=2.2ms QKV=2.15s FFN=3.04s) eta=07:45:41 | 40.8K token/s | 
[epoch_0]_45121  loss=3.106705 |g|=0.484	lr=1.02e-04 | 96.3%@S37  T=1.76s(data=2.2ms QKV=2.15s FFN=3.04s) eta=07:47:08 | 41.1K token/s | 
[epoch_0]_45131  loss=3.139236 |g|=0.516	lr=1.02e-04 | 97.1%@S37  T=1.76s(data=1.9ms QKV=2.15s FFN=3.04s) eta=07:45:56 | 41.4K token/s | 
[epoch_0]_45141  loss=3.034726 |g|=0.471	lr=1.02e-04 | 98.0%@S37  T=1.77s(data=1.9ms QKV=2.15s FFN=3.04s) eta=07:48:22 | 41.6K token/s | 
[epoch_0]_45151  loss=3.090738 |g|=0.495	lr=1.02e-04 | 98.8%@S37  T=1.95s(data=2.1ms QKV=2.16s FFN=3.04s) eta=08:35:28 | 41.6K token/s | 
[epoch_0]_45161  loss=3.032911 |g|=0.477	lr=1.02e-04 | 99.6%@S37  T=1.75s(data=1.8ms QKV=2.15s FFN=3.04s) eta=07:42:25 | 41.9K token/s | 
[epoch_0]_45165  loss=3.073522 |g|=0.472	lr=1.01e-04 | 99.9%@S37  T=1.97s(data=2.9ms QKV=2.16s FFN=3.04s) eta=08:41:12 | 41.9K token/s | 
-------- End of shard_37@"./Datasets/edu_fineweb1B/edu_fineweb_train_000795.bin"-------- 
[shard-38]@"./Datasets/edu_fineweb1B/edu_fineweb_train_000796.bin": tokens=100(M) nShardSamples=1220(3710928) 
[epoch_0]_45171  loss=3.049864 |g|=0.477	lr=1.01e-04 | 0.4%@S38  T=1.75s(data=1.2ms QKV=2.15s FFN=3.04s) eta=07:43:07 | 42.1K token/s | 
[epoch_0]_45181  loss=3.089599 |g|=0.484	lr=1.01e-04 | 1.2%@S38  T=1.93s(data=1.2ms QKV=2.15s FFN=3.04s) eta=08:30:07 | 42.1K token/s | 
[epoch_0]_45191  loss=3.043532 |g|=0.482	lr=1.01e-04 | 2.1%@S38  T=1.78s(data=1.2ms QKV=2.15s FFN=3.04s) eta=07:49:45 | 42.3K token/s | 
[Fuyou] head="1" update algorithm=4 t=11.50s
[eval] 
	 Loss@"edu_fineweb1B"=3.111(0.00085) nBranch=1 nToken=6.31M best=3.1118(224) E2T=0.0224 T=36.7541(0)s x=0
	#3.11096±0.0977 tps=172K(6.30784M) a=[2.92328,3.38662] T=36.7541(sec)
[Section@45200] layer[16-24] tasks=19(nPassBack=0) last_loss=3.08852(0.000221491) N=(772,51296,50736 5966268)
[epoch_0]_45201  loss=3.093053 |g|=0.5	lr=1.01e-04 | 2.9%@S38  T=12.80s(data=4.1ms QKV=2.14s FFN=3.03s) eta=2d 08:18:34 | 40.5K token/s | 
[epoch_0]_45211  loss=3.066697 |g|=0.478	lr=1.01e-04 | 3.7%@S38  T=1.92s(data=2.2ms QKV=2.15s FFN=3.04s) eta=08:26:48 | 40.6K token/s | 
[epoch_0]_45221  loss=3.077354 |g|=0.487	lr=1.01e-04 | 4.5%@S38  T=1.91s(data=1.9ms QKV=2.14s FFN=3.04s) eta=08:22:21 | 40.8K token/s | 
[epoch_0]_45231  loss=3.154476 |g|=0.492	lr=1.01e-04 | 5.3%@S38  T=1.96s(data=2.2ms QKV=2.15s FFN=3.04s) eta=08:36:41 | 40.8K token/s | 
[epoch_0]_45241  loss=3.093421 |g|=0.47	lr=1.01e-04 | 6.2%@S38  T=2.00s(data=2.0ms QKV=2.15s FFN=3.04s) eta=08:45:39 | 40.8K token/s | 
[epoch_0]_45251  loss=3.115726 |g|=0.47	lr=1.00e-04 | 7.0%@S38  T=1.84s(data=2.1ms QKV=2.15s FFN=3.04s) eta=08:05:15 | 41.0K token/s | 
[epoch_0]_45261  loss=3.065193 |g|=0.481	lr=1.00e-04 | 7.8%@S38  T=1.99s(data=2.0ms QKV=2.15s FFN=3.04s) eta=08:42:16 | 41.0K token/s | 
[epoch_0]_45271  loss=2.977859 |g|=0.492	lr=1.00e-04 | 8.6%@S38  T=1.76s(data=3.0ms QKV=2.14s FFN=3.04s) eta=07:43:08 | 41.3K token/s | 
[epoch_0]_45281  loss=3.066362 |g|=0.481	lr=1.00e-04 | 9.4%@S38  T=1.99s(data=1.7ms QKV=2.15s FFN=3.04s) eta=08:43:29 | 41.3K token/s | 
[epoch_0]_45291  loss=3.067840 |g|=0.469	lr=1.00e-04 | 10.2%@S38  T=1.78s(data=2.9ms QKV=2.14s FFN=3.04s) eta=07:46:23 | 41.5K token/s | 
[Fuyou] head="2" update algorithm=4 t=12.73s
[Section@45300] layer[24-32] tasks=19(nPassBack=0) last_loss=3.08355(-0.0163331) N=(772,51408,50848 5979468)
[epoch_0]_45301  loss=3.020626 |g|=0.492	lr=9.99e-05 | 11.1%@S38  T=5.80s(data=3.4ms QKV=2.16s FFN=3.03s) eta=1d 01:21:06 | 40.1K token/s | 
[epoch_0]_45311  loss=3.151724 |g|=0.48	lr=9.98e-05 | 11.9%@S38  T=1.76s(data=3.1ms QKV=2.15s FFN=3.04s) eta=07:42:31 | 40.5K token/s | 
[epoch_0]_45321  loss=3.086731 |g|=0.477	lr=9.97e-05 | 12.7%@S38  T=1.77s(data=3.3ms QKV=2.15s FFN=3.04s) eta=07:43:34 | 40.8K token/s | 
[epoch_0]_45331  loss=3.118111 |g|=0.497	lr=9.96e-05 | 13.5%@S38  T=1.75s(data=3.0ms QKV=2.15s FFN=3.04s) eta=07:37:27 | 41.1K token/s | 
[epoch_0]_45341  loss=3.068924 |g|=0.479	lr=9.95e-05 | 14.3%@S38  T=2.01s(data=1.8ms QKV=2.16s FFN=3.04s) eta=08:45:00 | 41.0K token/s | 
[epoch_0]_45351  loss=3.136326 |g|=0.47	lr=9.94e-05 | 15.2%@S38  T=1.77s(data=2.1ms QKV=2.15s FFN=3.04s) eta=07:43:20 | 41.3K token/s | 
[epoch_0]_45361  loss=3.034849 |g|=0.477	lr=9.92e-05 | 16.0%@S38  T=1.90s(data=3.2ms QKV=2.15s FFN=3.04s) eta=08:15:15 | 41.4K token/s | 
[epoch_0]_45371  loss=3.120072 |g|=0.493	lr=9.91e-05 | 16.8%@S38  T=1.80s(data=3.1ms QKV=2.15s FFN=3.04s) eta=07:49:07 | 41.6K token/s | 
[epoch_0]_45381  loss=3.111715 |g|=0.503	lr=9.90e-05 | 17.6%@S38  T=1.95s(data=2.2ms QKV=2.16s FFN=3.04s) eta=08:29:48 | 41.6K token/s | 
[epoch_0]_45391  loss=3.095018 |g|=0.467	lr=9.89e-05 | 18.4%@S38  T=1.90s(data=1.9ms QKV=2.16s FFN=3.04s) eta=08:14:23 | 41.7K token/s | 
[Fuyou] head="3" update algorithm=4 t=15.36s
[eval] 
	 Loss@"edu_fineweb1B"=3.111(6.2e-05) nBranch=1 nToken=6.31M best=3.1110(225) E2T=-0.0463 T=36.7185(0)s x=0
	#3.1109±0.0974 tps=172K(6.30784M) a=[2.92559,3.38781] T=36.7185(sec)
[Section@45400] layer[32-40] tasks=19(nPassBack=0) last_loss=3.15716(-0.0846708) N=(772,51520,50960 5992668)
[epoch_0]_45401  loss=3.107889 |g|=0.494	lr=9.88e-05 | 19.3%@S38  T=13.10s(data=4.1ms QKV=2.14s FFN=3.04s) eta=2d 08:52:47 | 39.9K token/s | 
[epoch_0]_45411  loss=3.090049 |g|=0.482	lr=9.87e-05 | 20.1%@S38  T=1.94s(data=3.6ms QKV=2.14s FFN=3.04s) eta=08:25:39 | 40.0K token/s | 
[epoch_0]_45421  loss=3.110883 |g|=0.487	lr=9.86e-05 | 20.9%@S38  T=1.84s(data=3.2ms QKV=2.14s FFN=3.04s) eta=07:59:11 | 40.3K token/s | 
[epoch_0]_45431  loss=3.054332 |g|=0.47	lr=9.85e-05 | 21.7%@S38  T=1.75s(data=3.0ms QKV=2.14s FFN=3.04s) eta=07:35:03 | 40.6K token/s | 
[epoch_0]_45441  loss=3.029819 |g|=0.485	lr=9.84e-05 | 22.5%@S38  T=1.95s(data=2.8ms QKV=2.14s FFN=3.04s) eta=08:26:43 | 40.7K token/s | 
[epoch_0]_45451  loss=3.094848 |g|=0.483	lr=9.82e-05 | 23.4%@S38  T=1.83s(data=2.1ms QKV=2.15s FFN=3.04s) eta=07:55:22 | 40.9K token/s | 
[epoch_0]_45461  loss=3.059337 |g|=0.46	lr=9.81e-05 | 24.2%@S38  T=1.94s(data=2.0ms QKV=2.15s FFN=3.04s) eta=08:23:07 | 40.9K token/s | 
[epoch_0]_45471  loss=3.029846 |g|=0.475	lr=9.80e-05 | 25.0%@S38  T=1.95s(data=1.7ms QKV=2.15s FFN=3.04s) eta=08:24:40 | 41.0K token/s | 
[epoch_0]_45481  loss=3.075011 |g|=0.494	lr=9.79e-05 | 25.8%@S38  T=1.80s(data=1.9ms QKV=2.15s FFN=3.04s) eta=07:45:44 | 41.2K token/s | 
[epoch_0]_45491  loss=3.086036 |g|=0.512	lr=9.78e-05 | 26.6%@S38  T=1.82s(data=1.8ms QKV=2.15s FFN=3.04s) eta=07:51:40 | 41.4K token/s | 
[Fuyou] head="4" update algorithm=4 t=14.98s
[Section@45500] layer[40-48] tasks=19(nPassBack=0) last_loss=3.02861(0.0808949) N=(772,51632,51072 6005868)
[epoch_0]_45501  loss=3.055935 |g|=0.471	lr=9.77e-05 | 27.5%@S38  T=4.87s(data=2.4ms QKV=2.13s FFN=3.03s) eta=21:01:20 | 40.2K token/s | 
[epoch_0]_45511  loss=3.057415 |g|=0.473	lr=9.76e-05 | 28.3%@S38  T=1.90s(data=2.2ms QKV=2.14s FFN=3.04s) eta=08:11:06 | 40.3K token/s | 
[epoch_0]_45521  loss=3.067817 |g|=0.496	lr=9.75e-05 | 29.1%@S38  T=1.95s(data=1.9ms QKV=2.14s FFN=3.04s) eta=08:24:37 | 40.4K token/s | 
[epoch_0]_45531  loss=3.006604 |g|=0.481	lr=9.73e-05 | 29.9%@S38  T=1.81s(data=2.7ms QKV=2.14s FFN=3.04s) eta=07:47:01 | 40.7K token/s | 
[epoch_0]_45541  loss=3.089039 |g|=0.497	lr=9.72e-05 | 30.7%@S38  T=1.75s(data=1.7ms QKV=2.14s FFN=3.04s) eta=07:32:24 | 41.0K token/s | 
[epoch_0]_45551  loss=3.101743 |g|=0.513	lr=9.71e-05 | 31.5%@S38  T=1.90s(data=1.7ms QKV=2.14s FFN=3.04s) eta=08:09:29 | 41.1K token/s | 
[epoch_0]_45561  loss=3.047003 |g|=0.477	lr=9.70e-05 | 32.4%@S38  T=1.76s(data=1.7ms QKV=2.14s FFN=3.04s) eta=07:33:55 | 41.4K token/s | 
[epoch_0]_45571  loss=3.009758 |g|=0.491	lr=9.69e-05 | 33.2%@S38  T=1.75s(data=2.0ms QKV=2.14s FFN=3.04s) eta=07:30:59 | 41.6K token/s | 
[epoch_0]_45581  loss=3.078970 |g|=0.502	lr=9.68e-05 | 34.0%@S38  T=1.78s(data=2.5ms QKV=2.14s FFN=3.04s) eta=07:38:35 | 41.8K token/s | 
[epoch_0]_45591  loss=2.997853 |g|=0.474	lr=9.67e-05 | 34.8%@S38  T=1.76s(data=2.7ms QKV=2.14s FFN=3.04s) eta=07:32:55 | 42.1K token/s | 
[Fuyou] head="5" update algorithm=4 t=11.53s
[eval] 
	 Loss@"edu_fineweb1B"=3.109(0.0016) nBranch=1 nToken=6.31M best=3.1109(226) E2T=0.0857 T=36.7209(0)s x=0
	#3.10928±0.0974 tps=172K(6.30784M) a=[2.92327,3.38892] T=36.7209(sec)
[Section@45600] layer[0-8] tasks=19(nPassBack=0) last_loss=3.02354(0.0624242) N=(772,51744,51184 6019068)
[epoch_0]_45601  loss=3.054070 |g|=0.483	lr=9.66e-05 | 35.6%@S38  T=12.39s(data=3.4ms QKV=2.11s FFN=3.04s) eta=2d 05:05:54 | 40.3K token/s | 
[epoch_0]_45611  loss=3.100611 |g|=0.482	lr=9.65e-05 | 36.5%@S38  T=1.90s(data=2.1ms QKV=2.13s FFN=3.04s) eta=08:07:55 | 40.4K token/s | 
[epoch_0]_45621  loss=3.113889 |g|=0.475	lr=9.63e-05 | 37.3%@S38  T=1.84s(data=2.1ms QKV=2.12s FFN=3.04s) eta=07:51:31 | 40.7K token/s | 
[epoch_0]_45631  loss=3.088094 |g|=0.48	lr=9.62e-05 | 38.1%@S38  T=1.92s(data=2.0ms QKV=2.12s FFN=3.04s) eta=08:13:48 | 40.8K token/s | 
[epoch_0]_45641  loss=3.070474 |g|=0.477	lr=9.61e-05 | 38.9%@S38  T=1.76s(data=1.8ms QKV=2.12s FFN=3.04s) eta=07:32:36 | 41.0K token/s | 
[epoch_0]_45651  loss=3.079087 |g|=0.474	lr=9.60e-05 | 39.7%@S38  T=1.96s(data=2.2ms QKV=2.12s FFN=3.04s) eta=08:23:03 | 41.1K token/s | 
[epoch_0]_45661  loss=3.045903 |g|=0.485	lr=9.59e-05 | 40.6%@S38  T=1.92s(data=2.0ms QKV=2.12s FFN=3.04s) eta=08:12:31 | 41.2K token/s | 
[epoch_0]_45671  loss=3.050638 |g|=0.478	lr=9.58e-05 | 41.4%@S38  T=1.93s(data=2.0ms QKV=2.12s FFN=3.04s) eta=08:14:37 | 41.2K token/s | 
[epoch_0]_45681  loss=3.063452 |g|=0.496	lr=9.57e-05 | 42.2%@S38  T=1.98s(data=1.9ms QKV=2.13s FFN=3.04s) eta=08:27:08 | 41.2K token/s | 
[epoch_0]_45691  loss=3.034429 |g|=0.475	lr=9.56e-05 | 43.0%@S38  T=1.90s(data=2.0ms QKV=2.12s FFN=3.04s) eta=08:06:22 | 41.3K token/s | 
[Fuyou] head="0" update algorithm=4 t=12.69s
[Section@45700] layer[8-16] tasks=19(nPassBack=0) last_loss=3.00082(0.0352387) N=(772,51856,51296 6032268)
[epoch_0]_45701  loss=3.103408 |g|=0.485	lr=9.55e-05 | 43.8%@S38  T=5.11s(data=1.6ms QKV=2.12s FFN=3.03s) eta=21:45:36 | 40.0K token/s | 
[epoch_0]_45711  loss=3.068429 |g|=0.476	lr=9.54e-05 | 44.7%@S38  T=1.80s(data=1.7ms QKV=2.12s FFN=3.04s) eta=07:39:16 | 40.3K token/s | 
[epoch_0]_45721  loss=3.022779 |g|=0.492	lr=9.52e-05 | 45.5%@S38  T=1.80s(data=2.1ms QKV=2.13s FFN=3.04s) eta=07:40:27 | 40.6K token/s | 
[epoch_0]_45731  loss=3.019772 |g|=0.467	lr=9.51e-05 | 46.3%@S38  T=1.81s(data=2.0ms QKV=2.13s FFN=3.04s) eta=07:42:34 | 40.8K token/s | 
[epoch_0]_45741  loss=3.103703 |g|=0.474	lr=9.50e-05 | 47.1%@S38  T=1.96s(data=2.1ms QKV=2.13s FFN=3.04s) eta=08:19:38 | 40.9K token/s | 
[epoch_0]_45751  loss=3.035437 |g|=0.501	lr=9.49e-05 | 47.9%@S38  T=2.05s(data=2.2ms QKV=2.14s FFN=3.04s) eta=08:41:19 | 40.8K token/s | 
[epoch_0]_45761  loss=3.101424 |g|=0.504	lr=9.48e-05 | 48.8%@S38  T=1.96s(data=2.2ms QKV=2.13s FFN=3.04s) eta=08:19:43 | 40.9K token/s | 
[epoch_0]_45771  loss=3.045429 |g|=0.472	lr=9.47e-05 | 49.6%@S38  T=1.80s(data=2.1ms QKV=2.13s FFN=3.04s) eta=07:37:39 | 41.1K token/s | 
[epoch_0]_45781  loss=3.016920 |g|=0.481	lr=9.46e-05 | 50.4%@S38  T=1.96s(data=2.1ms QKV=2.13s FFN=3.04s) eta=08:19:23 | 41.1K token/s | 
[epoch_0]_45791  loss=3.108435 |g|=0.485	lr=9.45e-05 | 51.2%@S38  T=1.94s(data=2.0ms QKV=2.13s FFN=3.04s) eta=08:14:09 | 41.2K token/s | 
[Fuyou] head="1" update algorithm=4 t=11.85s
[eval] 
	 Loss@"edu_fineweb1B"=3.108(0.00083) nBranch=1 nToken=6.31M best=3.1093(227) E2T=0.0997 T=36.7201(0)s x=0
	#3.10845±0.0979 tps=172K(6.30784M) a=[2.91935,3.38761] T=36.7201(sec)
[Section@45800] layer[16-24] tasks=19(nPassBack=0) last_loss=3.00872(0.0798011) N=(772,51968,51408 6045468)
[epoch_0]_45801  loss=3.005605 |g|=0.485	lr=9.44e-05 | 52.0%@S38  T=12.23s(data=2.4ms QKV=2.11s FFN=3.04s) eta=2d 03:44:01 | 39.5K token/s | 
[epoch_0]_45811  loss=3.082136 |g|=0.481	lr=9.43e-05 | 52.8%@S38  T=1.76s(data=2.0ms QKV=2.11s FFN=3.04s) eta=07:27:46 | 39.8K token/s | 
[epoch_0]_45821  loss=3.069273 |g|=0.466	lr=9.41e-05 | 53.7%@S38  T=1.83s(data=1.9ms QKV=2.11s FFN=3.04s) eta=07:44:39 | 40.0K token/s | 
[epoch_0]_45831  loss=2.984032 |g|=0.462	lr=9.40e-05 | 54.5%@S38  T=1.76s(data=2.1ms QKV=2.11s FFN=3.04s) eta=07:24:51 | 40.4K token/s | 
[epoch_0]_45841  loss=3.005130 |g|=0.479	lr=9.39e-05 | 55.3%@S38  T=1.87s(data=2.3ms QKV=2.11s FFN=3.04s) eta=07:54:37 | 40.5K token/s | 
[epoch_0]_45851  loss=2.986965 |g|=0.513	lr=9.38e-05 | 56.1%@S38  T=1.97s(data=2.7ms QKV=2.12s FFN=3.04s) eta=08:19:39 | 40.6K token/s | 
[epoch_0]_45861  loss=3.073455 |g|=0.494	lr=9.37e-05 | 56.9%@S38  T=1.84s(data=2.6ms QKV=2.12s FFN=3.04s) eta=07:45:06 | 40.8K token/s | 
[epoch_0]_45871  loss=3.107109 |g|=0.496	lr=9.36e-05 | 57.8%@S38  T=1.78s(data=2.4ms QKV=2.11s FFN=3.04s) eta=07:28:41 | 41.1K token/s | 
[epoch_0]_45881  loss=3.076421 |g|=0.485	lr=9.35e-05 | 58.6%@S38  T=1.90s(data=2.7ms QKV=2.11s FFN=3.04s) eta=08:00:37 | 41.2K token/s | 
[epoch_0]_45891  loss=3.045516 |g|=0.471	lr=9.34e-05 | 59.4%@S38  T=1.76s(data=1.8ms QKV=2.11s FFN=3.04s) eta=07:24:38 | 41.4K token/s | 
[Fuyou] head="2" update algorithm=4 t=11.54s
[Section@45900] layer[24-32] tasks=19(nPassBack=0) last_loss=3.07134(0.012213) N=(772,52080,51520 6058668)
[epoch_0]_45901  loss=2.997893 |g|=0.484	lr=9.33e-05 | 60.2%@S38  T=4.99s(data=2.3ms QKV=2.12s FFN=3.03s) eta=20:59:09 | 40.2K token/s | 
[epoch_0]_45911  loss=3.068858 |g|=0.472	lr=9.32e-05 | 61.0%@S38  T=1.78s(data=1.9ms QKV=2.12s FFN=3.04s) eta=07:29:52 | 40.5K token/s | 
[epoch_0]_45921  loss=3.008932 |g|=0.481	lr=9.30e-05 | 61.9%@S38  T=1.91s(data=1.7ms QKV=2.12s FFN=3.04s) eta=08:02:20 | 40.6K token/s | 
[epoch_0]_45931  loss=3.000466 |g|=0.486	lr=9.29e-05 | 62.7%@S38  T=1.81s(data=2.1ms QKV=2.12s FFN=3.04s) eta=07:35:39 | 40.8K token/s | 
[epoch_0]_45941  loss=3.100914 |g|=0.502	lr=9.28e-05 | 63.5%@S38  T=1.84s(data=1.6ms QKV=2.12s FFN=3.04s) eta=07:41:51 | 41.0K token/s | 
[epoch_0]_45951  loss=3.113364 |g|=0.489	lr=9.27e-05 | 64.3%@S38  T=1.90s(data=1.9ms QKV=2.12s FFN=3.04s) eta=07:57:45 | 41.1K token/s | 
[epoch_0]_45961  loss=3.095005 |g|=0.482	lr=9.26e-05 | 65.1%@S38  T=1.78s(data=2.1ms QKV=2.12s FFN=3.04s) eta=07:26:01 | 41.4K token/s | 
[epoch_0]_45971  loss=3.084347 |g|=0.479	lr=9.25e-05 | 66.0%@S38  T=1.92s(data=1.7ms QKV=2.12s FFN=3.04s) eta=08:01:06 | 41.4K token/s | 
[epoch_0]_45981  loss=3.105269 |g|=0.488	lr=9.24e-05 | 66.8%@S38  T=1.96s(data=2.1ms QKV=2.12s FFN=3.04s) eta=08:12:33 | 41.4K token/s | 
[epoch_0]_45991  loss=3.064750 |g|=0.502	lr=9.23e-05 | 67.6%@S38  T=1.95s(data=2.0ms QKV=2.12s FFN=3.04s) eta=08:08:58 | 41.5K token/s | 
[Fuyou] head="3" update algorithm=4 t=11.24s
[eval] 
	 Loss@"edu_fineweb1B"=3.108(0.00089) nBranch=1 nToken=6.31M best=3.1084(228) E2T=0.0609 T=36.7487(0)s x=0
	#3.10756±0.0976 tps=172K(6.30784M) a=[2.91709,3.38666] T=36.7487(sec)
[Section@46000] layer[32-40] tasks=19(nPassBack=0) last_loss=3.04663(0.110528) N=(772,52192,51632 6071868)
[epoch_0]_46001  loss=3.121139 |g|=0.496	lr=9.22e-05 | 68.4%@S38  T=12.45s(data=2.5ms QKV=2.12s FFN=3.04s) eta=2d 03:59:00 | 39.7K token/s | 
[epoch_0]_46011  loss=3.103733 |g|=0.495	lr=9.21e-05 | 69.2%@S38  T=1.80s(data=2.0ms QKV=2.11s FFN=3.04s) eta=07:31:55 | 40.0K token/s | 
[epoch_0]_46021  loss=3.039237 |g|=0.486	lr=9.20e-05 | 70.1%@S38  T=1.78s(data=1.9ms QKV=2.11s FFN=3.04s) eta=07:25:09 | 40.3K token/s | 
[epoch_0]_46031  loss=3.101722 |g|=0.515	lr=9.18e-05 | 70.9%@S38  T=1.79s(data=1.9ms QKV=2.11s FFN=3.04s) eta=07:28:21 | 40.6K token/s | 
[epoch_0]_46041  loss=3.091281 |g|=0.516	lr=9.17e-05 | 71.7%@S38  T=1.82s(data=2.2ms QKV=2.12s FFN=3.04s) eta=07:33:44 | 40.8K token/s | 
[epoch_0]_46051  loss=2.963374 |g|=0.469	lr=9.16e-05 | 72.5%@S38  T=1.77s(data=1.6ms QKV=2.11s FFN=3.04s) eta=07:22:04 | 41.1K token/s | 
[epoch_0]_46061  loss=3.017653 |g|=0.489	lr=9.15e-05 | 73.3%@S38  T=1.97s(data=2.0ms QKV=2.12s FFN=3.04s) eta=08:12:31 | 41.1K token/s | 
[epoch_0]_46071  loss=3.063480 |g|=0.475	lr=9.14e-05 | 74.1%@S38  T=1.75s(data=1.6ms QKV=2.11s FFN=3.04s) eta=07:17:40 | 41.4K token/s | 
[epoch_0]_46081  loss=3.089097 |g|=0.47	lr=9.13e-05 | 75.0%@S38  T=1.81s(data=2.0ms QKV=2.12s FFN=3.04s) eta=07:30:51 | 41.6K token/s | 
[epoch_0]_46091  loss=3.033111 |g|=0.472	lr=9.12e-05 | 75.8%@S38  T=1.90s(data=2.0ms QKV=2.11s FFN=3.04s) eta=07:52:00 | 41.7K token/s | 
[Fuyou] head="4" update algorithm=4 t=12.01s
[Section@46100] layer[40-48] tasks=19(nPassBack=0) last_loss=3.15934(-0.130723) N=(772,52304,51744 6085068)
[epoch_0]_46101  loss=3.014545 |g|=0.48	lr=9.11e-05 | 76.6%@S38  T=4.22s(data=2.2ms QKV=2.12s FFN=3.03s) eta=17:29:52 | 40.5K token/s | 
[epoch_0]_46111  loss=3.018155 |g|=0.475	lr=9.10e-05 | 77.4%@S38  T=1.76s(data=2.2ms QKV=2.12s FFN=3.04s) eta=07:18:32 | 40.8K token/s | 
[epoch_0]_46121  loss=3.088897 |g|=0.499	lr=9.09e-05 | 78.2%@S38  T=1.77s(data=1.9ms QKV=2.12s FFN=3.04s) eta=07:19:35 | 41.1K token/s | 
[epoch_0]_46131  loss=2.971137 |g|=0.501	lr=9.08e-05 | 79.1%@S38  T=1.75s(data=1.9ms QKV=2.12s FFN=3.04s) eta=07:14:21 | 41.4K token/s | 
[epoch_0]_46141  loss=3.052636 |g|=0.47	lr=9.07e-05 | 79.9%@S38  T=1.95s(data=2.0ms QKV=2.12s FFN=3.04s) eta=08:03:28 | 41.4K token/s | 
[epoch_0]_46151  loss=2.998450 |g|=0.475	lr=9.06e-05 | 80.7%@S38  T=1.82s(data=2.8ms QKV=2.13s FFN=3.04s) eta=07:32:41 | 41.6K token/s | 
[epoch_0]_46161  loss=3.060398 |g|=0.488	lr=9.04e-05 | 81.5%@S38  T=1.75s(data=1.8ms QKV=2.12s FFN=3.04s) eta=07:14:04 | 41.9K token/s | 
[epoch_0]_46171  loss=3.056075 |g|=0.495	lr=9.03e-05 | 82.3%@S38  T=1.79s(data=2.1ms QKV=2.13s FFN=3.04s) eta=07:24:02 | 42.1K token/s | 
[epoch_0]_46181  loss=3.107919 |g|=0.474	lr=9.02e-05 | 83.2%@S38  T=1.92s(data=2.0ms QKV=2.13s FFN=3.04s) eta=07:54:41 | 42.1K token/s | 
[epoch_0]_46191  loss=3.013710 |g|=0.484	lr=9.01e-05 | 84.0%@S38  T=1.75s(data=1.5ms QKV=2.12s FFN=3.04s) eta=07:12:04 | 42.3K token/s | 
[Fuyou] head="5" update algorithm=4 t=11.33s
[eval] 
	 Loss@"edu_fineweb1B"=3.106(0.0013) nBranch=1 nToken=6.31M best=3.1076(229) E2T=-0.00275 T=36.7822(0)s x=0
	#3.10629±0.0975 tps=171K(6.30784M) a=[2.91765,3.38511] T=36.7822(sec)
[Section@46200] layer[0-8] tasks=19(nPassBack=0) last_loss=3.10904(-0.0855014) N=(772,52416,51856 6098268)
[epoch_0]_46201  loss=3.055425 |g|=0.485	lr=9.00e-05 | 84.8%@S38  T=12.43s(data=2.4ms QKV=2.11s FFN=3.03s) eta=2d 03:13:56 | 40.5K token/s | 
[epoch_0]_46211  loss=3.107598 |g|=0.466	lr=8.99e-05 | 85.6%@S38  T=1.85s(data=2.2ms QKV=2.11s FFN=3.04s) eta=07:36:19 | 40.7K token/s | 
[epoch_0]_46221  loss=3.055655 |g|=0.5	lr=8.98e-05 | 86.4%@S38  T=1.89s(data=2.6ms QKV=2.13s FFN=3.04s) eta=07:47:13 | 40.9K token/s | 
[epoch_0]_46231  loss=2.963781 |g|=0.488	lr=8.97e-05 | 87.3%@S38  T=1.76s(data=2.0ms QKV=2.11s FFN=3.04s) eta=07:13:50 | 41.2K token/s | 
[epoch_0]_46241  loss=3.067659 |g|=0.484	lr=8.96e-05 | 88.1%@S38  T=1.90s(data=2.2ms QKV=2.11s FFN=3.04s) eta=07:49:17 | 41.2K token/s | 
[epoch_0]_46251  loss=3.038225 |g|=0.474	lr=8.95e-05 | 88.9%@S38  T=1.82s(data=2.0ms QKV=2.12s FFN=3.04s) eta=07:29:40 | 41.4K token/s | 
[epoch_0]_46261  loss=3.032710 |g|=0.605	lr=8.94e-05 | 89.7%@S38  T=1.97s(data=2.1ms QKV=2.12s FFN=3.04s) eta=08:04:43 | 41.4K token/s | 
[epoch_0]_46271  loss=3.042475 |g|=0.485	lr=8.93e-05 | 90.5%@S38  T=1.83s(data=2.5ms QKV=2.12s FFN=3.04s) eta=07:29:11 | 41.6K token/s | 
[epoch_0]_46281  loss=3.083813 |g|=0.47	lr=8.92e-05 | 91.4%@S38  T=1.89s(data=2.7ms QKV=2.12s FFN=3.04s) eta=07:43:39 | 41.7K token/s | 
[epoch_0]_46291  loss=3.070530 |g|=0.479	lr=8.90e-05 | 92.2%@S38  T=1.86s(data=2.7ms QKV=2.12s FFN=3.04s) eta=07:38:16 | 41.8K token/s | 
[Fuyou] head="0" update algorithm=4 t=14.67s
[Section@46300] layer[8-16] tasks=19(nPassBack=0) last_loss=3.05674(-0.0559192) N=(772,52528,51968 6111468)
[epoch_0]_46301  loss=3.038344 |g|=0.467	lr=8.89e-05 | 93.0%@S38  T=5.36s(data=2.8ms QKV=2.12s FFN=3.03s) eta=21:56:13 | 40.5K token/s | 
[epoch_0]_46311  loss=3.034576 |g|=0.499	lr=8.88e-05 | 93.8%@S38  T=1.75s(data=3.1ms QKV=2.12s FFN=3.03s) eta=07:09:48 | 40.8K token/s | 
[epoch_0]_46321  loss=3.013314 |g|=0.469	lr=8.87e-05 | 94.6%@S38  T=1.96s(data=2.1ms QKV=2.13s FFN=3.04s) eta=08:00:40 | 40.8K token/s | 
[epoch_0]_46331  loss=3.100930 |g|=0.477	lr=8.86e-05 | 95.4%@S38  T=1.99s(data=2.1ms QKV=2.14s FFN=3.04s) eta=08:07:22 | 40.9K token/s | 
[epoch_0]_46341  loss=3.022597 |g|=0.466	lr=8.85e-05 | 96.3%@S38  T=1.81s(data=2.1ms QKV=2.14s FFN=3.04s) eta=07:24:26 | 41.1K token/s | 
[epoch_0]_46351  loss=3.052022 |g|=0.478	lr=8.84e-05 | 97.1%@S38  T=1.87s(data=2.5ms QKV=2.13s FFN=3.04s) eta=07:36:29 | 41.2K token/s | 
[epoch_0]_46361  loss=3.047535 |g|=0.504	lr=8.83e-05 | 97.9%@S38  T=1.77s(data=1.9ms QKV=2.13s FFN=3.04s) eta=07:12:09 | 41.5K token/s | 
[epoch_0]_46371  loss=3.040612 |g|=0.498	lr=8.82e-05 | 98.7%@S38  T=1.75s(data=1.8ms QKV=2.13s FFN=3.04s) eta=07:08:18 | 41.7K token/s | 
[epoch_0]_46381  loss=3.055551 |g|=0.481	lr=8.81e-05 | 99.5%@S38  T=1.85s(data=2.2ms QKV=2.14s FFN=3.04s) eta=07:32:51 | 41.9K token/s | 
[epoch_0]_46386  loss=2.982972 |g|=0.495	lr=8.80e-05 | 100.0%@S38  T=1.76s(data=2.0ms QKV=2.13s FFN=3.04s) eta=07:10:45 | 42.1K token/s | 
-------- End of shard_38@"./Datasets/edu_fineweb1B/edu_fineweb_train_000796.bin"-------- 
[shard-39]@"./Datasets/edu_fineweb1B/edu_fineweb_train_000797.bin": tokens=100(M) nShardSamples=1220(3808584) 
[epoch_0]_46391  loss=3.104625 |g|=0.463	lr=8.80e-05 | 0.4%@S39  T=1.83s(data=1.8ms QKV=2.13s FFN=3.04s) eta=07:27:02 | 42.2K token/s | 
[Fuyou] head="1" update algorithm=4 t=10.75s
[eval] 
	 Loss@"edu_fineweb1B"=3.104(0.002) nBranch=1 nToken=6.31M best=3.1063(230) E2T=0.0753 T=36.763(0)s x=0
	#3.10426±0.0976 tps=172K(6.30784M) a=[2.91553,3.38222] T=36.763(sec)
[Section@46400] layer[16-24] tasks=19(nPassBack=0) last_loss=3.029(-0.020278) N=(772,52640,52080 6124668)
[epoch_0]_46401  loss=3.037483 |g|=0.489	lr=8.79e-05 | 1.2%@S39  T=12.58s(data=2.0ms QKV=2.12s FFN=3.03s) eta=2d 03:09:00 | 40.4K token/s | 
[epoch_0]_46411  loss=3.072472 |g|=0.489	lr=8.78e-05 | 2.0%@S39  T=1.77s(data=2.4ms QKV=2.12s FFN=3.04s) eta=07:10:46 | 40.7K token/s | 
[epoch_0]_46421  loss=3.080467 |g|=0.482	lr=8.77e-05 | 2.8%@S39  T=1.81s(data=2.2ms QKV=2.13s FFN=3.04s) eta=07:19:46 | 41.0K token/s | 
[epoch_0]_46431  loss=3.120545 |g|=0.496	lr=8.76e-05 | 3.6%@S39  T=1.84s(data=3.8ms QKV=2.12s FFN=3.04s) eta=07:28:00 | 41.1K token/s | 
[epoch_0]_46441  loss=3.195880 |g|=0.487	lr=8.74e-05 | 4.5%@S39  T=1.77s(data=3.1ms QKV=2.12s FFN=3.04s) eta=07:10:39 | 41.4K token/s | 
[epoch_0]_46451  loss=3.084607 |g|=0.484	lr=8.73e-05 | 5.3%@S39  T=1.81s(data=2.0ms QKV=2.13s FFN=3.04s) eta=07:18:48 | 41.6K token/s | 
[epoch_0]_46461  loss=3.019286 |g|=0.504	lr=8.72e-05 | 6.1%@S39  T=1.95s(data=2.1ms QKV=2.13s FFN=3.04s) eta=07:53:33 | 41.6K token/s | 
[epoch_0]_46471  loss=3.109154 |g|=0.495	lr=8.71e-05 | 6.9%@S39  T=1.98s(data=2.3ms QKV=2.13s FFN=3.04s) eta=08:00:46 | 41.6K token/s | 
[epoch_0]_46481  loss=3.036296 |g|=0.525	lr=8.70e-05 | 7.7%@S39  T=1.76s(data=1.7ms QKV=2.12s FFN=3.04s) eta=07:07:57 | 41.8K token/s | 
[epoch_0]_46491  loss=3.042634 |g|=0.531	lr=8.69e-05 | 8.6%@S39  T=1.82s(data=1.9ms QKV=2.13s FFN=3.04s) eta=07:22:06 | 42.0K token/s | 
[Fuyou] head="2" update algorithm=4 t=10.18s
[Section@46500] layer[24-32] tasks=19(nPassBack=0) last_loss=3.07334(-0.00200438) N=(772,52752,52192 6137868)
[epoch_0]_46501  loss=3.053685 |g|=0.505	lr=8.68e-05 | 9.4%@S39  T=4.73s(data=1.9ms QKV=2.12s FFN=3.03s) eta=19:04:39 | 40.8K token/s | 
[epoch_0]_46511  loss=3.110301 |g|=0.496	lr=8.67e-05 | 10.2%@S39  T=1.74s(data=2.0ms QKV=2.12s FFN=3.03s) eta=07:00:38 | 41.1K token/s | 
[epoch_0]_46521  loss=3.112462 |g|=0.512	lr=8.66e-05 | 11.0%@S39  T=1.94s(data=3.3ms QKV=2.13s FFN=3.04s) eta=07:50:14 | 41.1K token/s | 
[epoch_0]_46531  loss=3.091143 |g|=0.484	lr=8.65e-05 | 11.8%@S39  T=1.78s(data=1.7ms QKV=2.13s FFN=3.04s) eta=07:10:07 | 41.4K token/s | 
[epoch_0]_46541  loss=3.116440 |g|=0.507	lr=8.64e-05 | 12.6%@S39  T=1.96s(data=2.9ms QKV=2.13s FFN=3.04s) eta=07:52:34 | 41.4K token/s | 
[epoch_0]_46551  loss=3.106377 |g|=0.479	lr=8.63e-05 | 13.5%@S39  T=1.80s(data=2.0ms QKV=2.14s FFN=3.04s) eta=07:15:14 | 41.6K token/s | 
[epoch_0]_46561  loss=3.014437 |g|=0.473	lr=8.62e-05 | 14.3%@S39  T=1.98s(data=1.7ms QKV=2.13s FFN=3.04s) eta=07:56:53 | 41.6K token/s | 
[epoch_0]_46571  loss=3.072027 |g|=0.468	lr=8.61e-05 | 15.1%@S39  T=1.79s(data=1.4ms QKV=2.13s FFN=3.04s) eta=07:12:29 | 41.8K token/s | 
[epoch_0]_46581  loss=3.043941 |g|=0.492	lr=8.60e-05 | 15.9%@S39  T=1.74s(data=1.9ms QKV=2.13s FFN=3.04s) eta=06:58:38 | 42.1K token/s | 
[epoch_0]_46591  loss=3.042207 |g|=0.503	lr=8.59e-05 | 16.7%@S39  T=1.77s(data=1.6ms QKV=2.13s FFN=3.04s) eta=07:06:05 | 42.3K token/s | 
[Fuyou] head="3" update algorithm=4 t=12.39s
[eval] 
	 Loss@"edu_fineweb1B"=3.100(0.0039) nBranch=1 nToken=6.31M best=3.1043(231) E2T=-0.0307 T=36.7371(0)s x=0
	#3.10034±0.0976 tps=172K(6.30784M) a=[2.91316,3.37746] T=36.7371(sec)
[Section@46600] layer[32-40] tasks=19(nPassBack=0) last_loss=3.13105(-0.0844183) N=(772,52864,52304 6151068)
[epoch_0]_46601  loss=3.061126 |g|=0.484	lr=8.58e-05 | 17.6%@S39  T=12.08s(data=2.2ms QKV=2.13s FFN=3.03s) eta=2d 00:26:30 | 40.5K token/s | 
[epoch_0]_46611  loss=3.044694 |g|=0.474	lr=8.56e-05 | 18.4%@S39  T=1.89s(data=1.7ms QKV=2.12s FFN=3.04s) eta=07:33:49 | 40.7K token/s | 
[epoch_0]_46621  loss=3.108689 |g|=0.478	lr=8.55e-05 | 19.2%@S39  T=1.91s(data=1.7ms QKV=2.12s FFN=3.04s) eta=07:37:51 | 40.8K token/s | 
[epoch_0]_46631  loss=3.099391 |g|=0.496	lr=8.54e-05 | 20.0%@S39  T=1.86s(data=1.9ms QKV=2.12s FFN=3.04s) eta=07:26:51 | 40.9K token/s | 
[epoch_0]_46641  loss=3.051316 |g|=0.479	lr=8.53e-05 | 20.8%@S39  T=1.98s(data=2.0ms QKV=2.13s FFN=3.04s) eta=07:54:38 | 41.0K token/s | 
[epoch_0]_46651  loss=3.068176 |g|=0.499	lr=8.52e-05 | 21.7%@S39  T=1.76s(data=1.9ms QKV=2.12s FFN=3.04s) eta=07:02:52 | 41.2K token/s | 
[epoch_0]_46661  loss=3.062212 |g|=0.497	lr=8.51e-05 | 22.5%@S39  T=1.80s(data=1.8ms QKV=2.12s FFN=3.04s) eta=07:10:02 | 41.4K token/s | 
[epoch_0]_46671  loss=2.961404 |g|=0.48	lr=8.50e-05 | 23.3%@S39  T=1.91s(data=1.9ms QKV=2.12s FFN=3.04s) eta=07:36:17 | 41.5K token/s | 
[epoch_0]_46681  loss=3.176096 |g|=0.475	lr=8.49e-05 | 24.1%@S39  T=1.78s(data=1.8ms QKV=2.12s FFN=3.04s) eta=07:04:41 | 41.8K token/s | 
[epoch_0]_46691  loss=2.998971 |g|=0.495	lr=8.48e-05 | 24.9%@S39  T=1.77s(data=1.8ms QKV=2.12s FFN=3.04s) eta=07:03:19 | 42.0K token/s | 
[Fuyou] head="4" update algorithm=4 t=12.09s
[Section@46700] layer[40-48] tasks=19(nPassBack=0) last_loss=3.11037(0.0489652) N=(772,52976,52416 6164268)
[epoch_0]_46701  loss=3.092907 |g|=0.501	lr=8.47e-05 | 25.8%@S39  T=4.30s(data=1.8ms QKV=2.14s FFN=3.03s) eta=17:08:00 | 40.8K token/s | 
[epoch_0]_46711  loss=3.092661 |g|=0.498	lr=8.46e-05 | 26.6%@S39  T=1.83s(data=1.9ms QKV=2.14s FFN=3.04s) eta=07:17:09 | 41.0K token/s | 
[epoch_0]_46721  loss=3.098276 |g|=0.481	lr=8.45e-05 | 27.4%@S39  T=2.00s(data=2.2ms QKV=2.14s FFN=3.04s) eta=07:57:45 | 41.0K token/s | 
[epoch_0]_46731  loss=3.099696 |g|=0.474	lr=8.44e-05 | 28.2%@S39  T=1.80s(data=2.1ms QKV=2.14s FFN=3.04s) eta=07:09:44 | 41.2K token/s | 
[epoch_0]_46741  loss=3.030256 |g|=0.472	lr=8.43e-05 | 29.0%@S39  T=1.91s(data=1.6ms QKV=2.13s FFN=3.04s) eta=07:34:16 | 41.3K token/s | 
[epoch_0]_46751  loss=3.018957 |g|=0.485	lr=8.42e-05 | 29.9%@S39  T=1.86s(data=2.0ms QKV=2.14s FFN=3.04s) eta=07:21:38 | 41.5K token/s | 
[epoch_0]_46761  loss=3.035760 |g|=0.483	lr=8.41e-05 | 30.7%@S39  T=1.93s(data=1.6ms QKV=2.14s FFN=3.04s) eta=07:38:02 | 41.5K token/s | 
[epoch_0]_46771  loss=3.050865 |g|=0.476	lr=8.40e-05 | 31.5%@S39  T=1.95s(data=2.0ms QKV=2.15s FFN=3.04s) eta=07:43:08 | 41.6K token/s | 
[epoch_0]_46781  loss=3.182655 |g|=0.484	lr=8.39e-05 | 32.3%@S39  T=1.78s(data=1.5ms QKV=2.14s FFN=3.04s) eta=07:02:21 | 41.8K token/s | 
[epoch_0]_46791  loss=3.039758 |g|=0.47	lr=8.38e-05 | 33.1%@S39  T=1.76s(data=1.5ms QKV=2.14s FFN=3.04s) eta=06:58:34 | 42.0K token/s | 
[Fuyou] head="5" update algorithm=4 t=11.25s
[eval] 
	 Loss@"edu_fineweb1B"=3.098(0.0024) nBranch=1 nToken=6.31M best=3.1003(232) E2T=0.015 T=36.7558(0)s x=0
	#3.09798±0.0979 tps=172K(6.30784M) a=[2.91189,3.37642] T=36.7558(sec)
[Section@46800] layer[0-8] tasks=19(nPassBack=0) last_loss=3.08294(0.0260992) N=(772,53088,52528 6177468)
[epoch_0]_46801  loss=3.110375 |g|=0.479	lr=8.37e-05 | 33.9%@S39  T=12.48s(data=2.4ms QKV=2.13s FFN=3.03s) eta=2d 01:21:05 | 40.2K token/s | 
[epoch_0]_46811  loss=2.999732 |g|=0.494	lr=8.36e-05 | 34.8%@S39  T=1.89s(data=2.1ms QKV=2.12s FFN=3.04s) eta=07:27:27 | 40.4K token/s | 
[epoch_0]_46821  loss=3.069621 |g|=0.48	lr=8.35e-05 | 35.6%@S39  T=1.84s(data=2.0ms QKV=2.13s FFN=3.04s) eta=07:14:54 | 40.6K token/s | 
[epoch_0]_46831  loss=3.085671 |g|=0.505	lr=8.33e-05 | 36.4%@S39  T=1.82s(data=2.7ms QKV=2.13s FFN=3.04s) eta=07:10:55 | 40.8K token/s | 
[epoch_0]_46841  loss=3.046954 |g|=0.494	lr=8.32e-05 | 37.2%@S39  T=1.77s(data=1.8ms QKV=2.12s FFN=3.04s) eta=06:58:23 | 41.1K token/s | 
[epoch_0]_46851  loss=3.164273 |g|=0.476	lr=8.31e-05 | 38.0%@S39  T=1.93s(data=2.0ms QKV=2.13s FFN=3.04s) eta=07:35:17 | 41.2K token/s | 
[epoch_0]_46861  loss=3.013223 |g|=0.482	lr=8.30e-05 | 38.9%@S39  T=1.88s(data=1.8ms QKV=2.13s FFN=3.04s) eta=07:23:30 | 41.3K token/s | 
[epoch_0]_46871  loss=3.055607 |g|=0.482	lr=8.29e-05 | 39.7%@S39  T=1.94s(data=1.9ms QKV=2.14s FFN=3.04s) eta=07:37:42 | 41.3K token/s | 
[epoch_0]_46881  loss=3.027318 |g|=0.473	lr=8.28e-05 | 40.5%@S39  T=1.95s(data=1.9ms QKV=2.13s FFN=3.04s) eta=07:40:14 | 41.4K token/s | 
[epoch_0]_46891  loss=3.050138 |g|=0.478	lr=8.27e-05 | 41.3%@S39  T=1.77s(data=1.8ms QKV=2.12s FFN=3.04s) eta=06:56:19 | 41.6K token/s | 
[Fuyou] head="0" update algorithm=4 t=11.12s
[Section@46900] layer[8-16] tasks=19(nPassBack=0) last_loss=3.12874(-0.0720036) N=(772,53200,52640 6190668)
[epoch_0]_46901  loss=3.063029 |g|=0.48	lr=8.26e-05 | 42.1%@S39  T=4.99s(data=2.6ms QKV=2.13s FFN=3.03s) eta=19:36:32 | 40.4K token/s | 
[epoch_0]_46911  loss=3.169708 |g|=0.499	lr=8.25e-05 | 43.0%@S39  T=1.77s(data=2.0ms QKV=2.13s FFN=3.04s) eta=06:55:44 | 40.7K token/s | 
[epoch_0]_46921  loss=3.126023 |g|=0.5	lr=8.24e-05 | 43.8%@S39  T=1.78s(data=1.5ms QKV=2.13s FFN=3.04s) eta=06:58:18 | 40.9K token/s | 
[epoch_0]_46931  loss=3.029003 |g|=0.486	lr=8.23e-05 | 44.6%@S39  T=1.88s(data=1.9ms QKV=2.13s FFN=3.04s) eta=07:22:03 | 41.1K token/s | 
[epoch_0]_46941  loss=3.086459 |g|=0.482	lr=8.22e-05 | 45.4%@S39  T=1.85s(data=2.1ms QKV=2.14s FFN=3.04s) eta=07:13:46 | 41.2K token/s | 
[epoch_0]_46951  loss=3.130161 |g|=0.493	lr=8.21e-05 | 46.2%@S39  T=1.96s(data=2.1ms QKV=2.14s FFN=3.04s) eta=07:40:36 | 41.3K token/s | 
[epoch_0]_46961  loss=3.026876 |g|=0.49	lr=8.20e-05 | 47.1%@S39  T=1.81s(data=1.7ms QKV=2.14s FFN=3.04s) eta=07:04:15 | 41.5K token/s | 
[epoch_0]_46971  loss=3.041781 |g|=0.491	lr=8.19e-05 | 47.9%@S39  T=1.98s(data=1.8ms QKV=2.14s FFN=3.04s) eta=07:42:57 | 41.5K token/s | 
[epoch_0]_46981  loss=3.109325 |g|=0.491	lr=8.18e-05 | 48.7%@S39  T=1.88s(data=2.2ms QKV=2.14s FFN=3.04s) eta=07:20:48 | 41.6K token/s | 
[epoch_0]_46991  loss=3.030238 |g|=0.482	lr=8.17e-05 | 49.5%@S39  T=1.82s(data=3.0ms QKV=2.13s FFN=3.04s) eta=07:06:37 | 41.7K token/s | 
[Fuyou] head="1" update algorithm=4 t=15.78s
[eval] 
	 Loss@"edu_fineweb1B"=3.097(0.0014) nBranch=1 nToken=6.31M best=3.0980(233) E2T=-0.0205 T=36.7532(0)s x=0
	#3.09654±0.0979 tps=172K(6.30784M) a=[2.91354,3.37623] T=36.7532(sec)
[Section@47000] layer[16-24] tasks=19(nPassBack=0) last_loss=3.11706(-0.0880611) N=(772,53312,52752 6203868)
[epoch_0]_47001  loss=3.031347 |g|=0.502	lr=8.16e-05 | 50.3%@S39  T=13.96s(data=3.8ms QKV=2.12s FFN=3.03s) eta=2d 06:26:04 | 39.9K token/s | 
[epoch_0]_47011  loss=3.113059 |g|=0.485	lr=8.15e-05 | 51.2%@S39  T=1.83s(data=3.5ms QKV=2.13s FFN=3.04s) eta=07:07:20 | 40.2K token/s | 
[epoch_0]_47021  loss=3.085451 |g|=0.516	lr=8.14e-05 | 52.0%@S39  T=1.84s(data=2.1ms QKV=2.13s FFN=3.04s) eta=07:10:43 | 40.4K token/s | 
[epoch_0]_47031  loss=3.114885 |g|=0.489	lr=8.13e-05 | 52.8%@S39  T=1.85s(data=2.7ms QKV=2.13s FFN=3.04s) eta=07:11:12 | 40.6K token/s | 
[epoch_0]_47041  loss=3.064625 |g|=0.517	lr=8.12e-05 | 53.6%@S39  T=1.81s(data=2.4ms QKV=2.12s FFN=3.04s) eta=07:02:07 | 40.8K token/s | 
[epoch_0]_47051  loss=3.074639 |g|=0.509	lr=8.11e-05 | 54.4%@S39  T=1.77s(data=1.6ms QKV=2.13s FFN=3.04s) eta=06:52:05 | 41.1K token/s | 
[epoch_0]_47061  loss=3.062859 |g|=0.479	lr=8.10e-05 | 55.2%@S39  T=1.77s(data=1.5ms QKV=2.12s FFN=3.04s) eta=06:52:24 | 41.4K token/s | 
[epoch_0]_47071  loss=3.047937 |g|=0.502	lr=8.09e-05 | 56.1%@S39  T=1.79s(data=2.1ms QKV=2.12s FFN=3.04s) eta=06:56:11 | 41.6K token/s | 
[epoch_0]_47081  loss=3.139805 |g|=0.495	lr=8.08e-05 | 56.9%@S39  T=1.80s(data=3.2ms QKV=2.13s FFN=3.04s) eta=06:58:45 | 41.8K token/s | 
[epoch_0]_47091  loss=3.053634 |g|=0.478	lr=8.07e-05 | 57.7%@S39  T=1.84s(data=3.1ms QKV=2.13s FFN=3.04s) eta=07:07:05 | 41.9K token/s | 
[Fuyou] head="2" update algorithm=4 t=15.34s
[Section@47100] layer[24-32] tasks=19(nPassBack=0) last_loss=3.05028(0.0230582) N=(772,53424,52864 6217068)
[epoch_0]_47101  loss=3.075925 |g|=0.478	lr=8.06e-05 | 58.5%@S39  T=5.91s(data=4.4ms QKV=2.13s FFN=3.03s) eta=22:52:30 | 40.5K token/s | 
[epoch_0]_47111  loss=3.140437 |g|=0.491	lr=8.05e-05 | 59.3%@S39  T=1.83s(data=3.9ms QKV=2.13s FFN=3.04s) eta=07:03:51 | 40.7K token/s | 
[epoch_0]_47121  loss=3.134301 |g|=0.521	lr=8.04e-05 | 60.2%@S39  T=1.81s(data=3.4ms QKV=2.13s FFN=3.04s) eta=06:59:35 | 41.0K token/s | 
[epoch_0]_47131  loss=3.103349 |g|=0.497	lr=8.03e-05 | 61.0%@S39  T=1.84s(data=3.9ms QKV=2.13s FFN=3.04s) eta=07:05:41 | 41.1K token/s | 
[epoch_0]_47141  loss=3.149385 |g|=0.495	lr=8.02e-05 | 61.8%@S39  T=1.83s(data=3.6ms QKV=2.13s FFN=3.04s) eta=07:03:17 | 41.3K token/s | 
[epoch_0]_47151  loss=3.141586 |g|=0.51	lr=8.01e-05 | 62.6%@S39  T=1.81s(data=3.8ms QKV=2.13s FFN=3.04s) eta=06:59:12 | 41.5K token/s | 
[epoch_0]_47161  loss=3.053941 |g|=0.514	lr=8.00e-05 | 63.4%@S39  T=1.84s(data=3.7ms QKV=2.13s FFN=3.04s) eta=07:05:34 | 41.7K token/s | 
[epoch_0]_47171  loss=3.049429 |g|=0.493	lr=7.98e-05 | 64.3%@S39  T=1.82s(data=3.5ms QKV=2.13s FFN=3.04s) eta=07:00:33 | 41.8K token/s | 
[epoch_0]_47181  loss=3.030851 |g|=0.473	lr=7.97e-05 | 65.1%@S39  T=1.84s(data=3.2ms QKV=2.13s FFN=3.04s) eta=07:05:02 | 42.0K token/s | 
[epoch_0]_47191  loss=3.062146 |g|=0.473	lr=7.96e-05 | 65.9%@S39  T=1.82s(data=3.0ms QKV=2.13s FFN=3.04s) eta=07:00:54 | 42.1K token/s | 
[Fuyou] head="3" update algorithm=4 t=17.44s
[eval] 
	 Loss@"edu_fineweb1B"=3.094(0.0022) nBranch=1 nToken=6.31M best=3.0965(234) E2T=-0.00231 T=36.7967(0)s x=0
	#3.09433±0.0977 tps=171K(6.30784M) a=[2.91109,3.37162] T=36.7967(sec)
[Section@47200] layer[32-40] tasks=19(nPassBack=0) last_loss=3.09664(0.0344129) N=(772,53536,52976 6230268)
[epoch_0]_47201  loss=3.097834 |g|=0.479	lr=7.95e-05 | 66.7%@S39  T=13.82s(data=4.8ms QKV=2.11s FFN=3.04s) eta=2d 05:06:14 | 40.3K token/s | 
[epoch_0]_47211  loss=3.037659 |g|=0.49	lr=7.94e-05 | 67.5%@S39  T=1.81s(data=8.4ms QKV=2.12s FFN=3.04s) eta=06:57:22 | 40.6K token/s | 
[epoch_0]_47221  loss=3.041466 |g|=0.487	lr=7.93e-05 | 68.4%@S39  T=1.75s(data=3.3ms QKV=2.12s FFN=3.04s) eta=06:43:30 | 40.9K token/s | 
[epoch_0]_47231  loss=3.168926 |g|=0.481	lr=7.92e-05 | 69.2%@S39  T=1.78s(data=3.1ms QKV=2.12s FFN=3.04s) eta=06:49:18 | 41.1K token/s | 
[epoch_0]_47241  loss=3.092287 |g|=0.485	lr=7.91e-05 | 70.0%@S39  T=1.78s(data=3.0ms QKV=2.12s FFN=3.04s) eta=06:49:09 | 41.4K token/s | 
[epoch_0]_47251  loss=3.067165 |g|=0.486	lr=7.90e-05 | 70.8%@S39  T=1.81s(data=3.1ms QKV=2.12s FFN=3.05s) eta=06:56:19 | 41.6K token/s | 
[epoch_0]_47261  loss=3.117612 |g|=0.479	lr=7.89e-05 | 71.6%@S39  T=1.79s(data=2.9ms QKV=2.12s FFN=3.04s) eta=06:51:14 | 41.8K token/s | 
[epoch_0]_47271  loss=3.096631 |g|=0.489	lr=7.88e-05 | 72.5%@S39  T=1.75s(data=2.4ms QKV=2.12s FFN=3.04s) eta=06:41:35 | 42.0K token/s | 
[epoch_0]_47281  loss=3.060539 |g|=0.467	lr=7.87e-05 | 73.3%@S39  T=1.80s(data=2.7ms QKV=2.12s FFN=3.04s) eta=06:52:10 | 42.2K token/s | 
[epoch_0]_47291  loss=2.996781 |g|=0.5	lr=7.86e-05 | 74.1%@S39  T=1.90s(data=2.7ms QKV=2.12s FFN=3.04s) eta=07:14:41 | 42.2K token/s | 
[Fuyou] head="4" update algorithm=4 t=16.21s
[Section@47300] layer[40-48] tasks=19(nPassBack=0) last_loss=3.05409(0.0562794) N=(772,53648,53088 6243468)
[epoch_0]_47301  loss=3.081906 |g|=0.499	lr=7.85e-05 | 74.9%@S39  T=4.84s(data=3.2ms QKV=2.12s FFN=3.04s) eta=18:26:45 | 41.0K token/s | 
[epoch_0]_47311  loss=3.048372 |g|=0.517	lr=7.84e-05 | 75.7%@S39  T=1.77s(data=3.3ms QKV=2.12s FFN=3.04s) eta=06:44:01 | 41.2K token/s | 
[epoch_0]_47321  loss=3.105211 |g|=0.519	lr=7.83e-05 | 76.5%@S39  T=1.77s(data=2.8ms QKV=2.13s FFN=3.04s) eta=06:44:36 | 41.5K token/s | 
[epoch_0]_47331  loss=3.054117 |g|=0.527	lr=7.82e-05 | 77.4%@S39  T=1.77s(data=3.0ms QKV=2.12s FFN=3.04s) eta=06:45:17 | 41.7K token/s | 
[epoch_0]_47341  loss=3.055987 |g|=0.495	lr=7.81e-05 | 78.2%@S39  T=1.78s(data=2.8ms QKV=2.12s FFN=3.04s) eta=06:46:55 | 41.9K token/s | 
[epoch_0]_47351  loss=3.077596 |g|=0.498	lr=7.80e-05 | 79.0%@S39  T=1.77s(data=2.8ms QKV=2.12s FFN=3.04s) eta=06:43:57 | 42.2K token/s | 
[epoch_0]_47361  loss=3.113685 |g|=0.495	lr=7.79e-05 | 79.8%@S39  T=1.79s(data=3.3ms QKV=2.12s FFN=3.04s) eta=06:48:32 | 42.3K token/s | 
[epoch_0]_47371  loss=3.056911 |g|=0.484	lr=7.78e-05 | 80.6%@S39  T=1.77s(data=3.0ms QKV=2.12s FFN=3.04s) eta=06:43:57 | 42.5K token/s | 
[epoch_0]_47381  loss=3.053777 |g|=0.508	lr=7.77e-05 | 81.5%@S39  T=1.77s(data=3.0ms QKV=2.12s FFN=3.04s) eta=06:43:45 | 42.7K token/s | 
[epoch_0]_47391  loss=3.042421 |g|=0.511	lr=7.76e-05 | 82.3%@S39  T=1.81s(data=2.7ms QKV=2.13s FFN=3.04s) eta=06:52:22 | 42.8K token/s | 
[Fuyou] head="5" update algorithm=4 t=16.79s
[eval] 
	 Loss@"edu_fineweb1B"=3.093(0.0014) nBranch=1 nToken=6.31M best=3.0943(235) E2T=0.0332 T=36.758(0)s x=0
	#3.09294±0.0976 tps=172K(6.30784M) a=[2.91173,3.37348] T=36.758(sec)
[Section@47400] layer[0-8] tasks=19(nPassBack=0) last_loss=3.05971(0.023227) N=(772,53760,53200 6256668)
[epoch_0]_47401  loss=3.125428 |g|=0.472	lr=7.75e-05 | 83.1%@S39  T=13.02s(data=3.8ms QKV=2.11s FFN=3.04s) eta=2d 01:18:19 | 41.0K token/s | 
[epoch_0]_47411  loss=3.081774 |g|=0.474	lr=7.74e-05 | 83.9%@S39  T=1.80s(data=3.7ms QKV=2.12s FFN=3.04s) eta=06:48:55 | 41.2K token/s | 
[epoch_0]_47421  loss=3.103955 |g|=0.485	lr=7.73e-05 | 84.7%@S39  T=1.77s(data=2.9ms QKV=2.11s FFN=3.04s) eta=06:42:07 | 41.5K token/s | 
[epoch_0]_47431  loss=3.049377 |g|=0.484	lr=7.72e-05 | 85.6%@S39  T=1.86s(data=2.8ms QKV=2.12s FFN=3.04s) eta=07:02:11 | 41.6K token/s | 
[epoch_0]_47441  loss=3.100181 |g|=0.485	lr=7.71e-05 | 86.4%@S39  T=1.82s(data=2.9ms QKV=2.12s FFN=3.05s) eta=06:51:29 | 41.8K token/s | 
[epoch_0]_47451  loss=3.103377 |g|=0.518	lr=7.70e-05 | 87.2%@S39  T=1.89s(data=4.0ms QKV=2.12s FFN=3.04s) eta=07:07:20 | 41.9K token/s | 
[epoch_0]_47461  loss=3.044920 |g|=0.472	lr=7.69e-05 | 88.0%@S39  T=1.83s(data=3.5ms QKV=2.12s FFN=3.04s) eta=06:54:10 | 42.0K token/s | 
[epoch_0]_47471  loss=3.073977 |g|=0.49	lr=7.68e-05 | 88.8%@S39  T=1.81s(data=3.2ms QKV=2.12s FFN=3.04s) eta=06:50:12 | 42.2K token/s | 
[epoch_0]_47481  loss=3.083586 |g|=0.483	lr=7.67e-05 | 89.7%@S39  T=1.79s(data=3.0ms QKV=2.12s FFN=3.04s) eta=06:45:15 | 42.3K token/s | 
[epoch_0]_47491  loss=3.071245 |g|=0.487	lr=7.66e-05 | 90.5%@S39  T=1.83s(data=2.0ms QKV=2.12s FFN=3.04s) eta=06:53:23 | 42.5K token/s | 
[Fuyou] head="0" update algorithm=4 t=15.55s
[Section@47500] layer[8-16] tasks=19(nPassBack=0) last_loss=3.07649(0.0522482) N=(772,53872,53312 6269868)
[epoch_0]_47501  loss=3.006072 |g|=0.468	lr=7.65e-05 | 91.3%@S39  T=5.70s(data=4.2ms QKV=2.12s FFN=3.04s) eta=21:25:27 | 41.1K token/s | 
[epoch_0]_47511  loss=3.005089 |g|=0.504	lr=7.64e-05 | 92.1%@S39  T=1.80s(data=3.4ms QKV=2.12s FFN=3.04s) eta=06:44:58 | 41.3K token/s | 
[epoch_0]_47521  loss=3.027272 |g|=0.491	lr=7.63e-05 | 92.9%@S39  T=1.81s(data=3.3ms QKV=2.12s FFN=3.04s) eta=06:46:56 | 41.5K token/s | 
[epoch_0]_47531  loss=3.139008 |g|=0.486	lr=7.62e-05 | 93.8%@S39  T=1.83s(data=3.2ms QKV=2.12s FFN=3.04s) eta=06:51:48 | 41.6K token/s | 
[epoch_0]_47541  loss=3.095360 |g|=0.485	lr=7.61e-05 | 94.6%@S39  T=1.81s(data=3.7ms QKV=2.13s FFN=3.04s) eta=06:47:50 | 41.8K token/s | 
[epoch_0]_47551  loss=2.940474 |g|=0.473	lr=7.60e-05 | 95.4%@S39  T=1.87s(data=3.8ms QKV=2.12s FFN=3.04s) eta=07:00:07 | 41.9K token/s | 
[epoch_0]_47561  loss=3.037413 |g|=0.475	lr=7.59e-05 | 96.2%@S39  T=1.80s(data=3.2ms QKV=2.13s FFN=3.04s) eta=06:43:33 | 42.1K token/s | 
[epoch_0]_47571  loss=2.973510 |g|=0.475	lr=7.58e-05 | 97.0%@S39  T=1.84s(data=2.0ms QKV=2.13s FFN=3.04s) eta=06:53:02 | 42.2K token/s | 
[epoch_0]_47581  loss=3.037060 |g|=0.495	lr=7.57e-05 | 97.8%@S39  T=1.81s(data=2.9ms QKV=2.13s FFN=3.04s) eta=06:45:14 | 42.4K token/s | 
[epoch_0]_47591  loss=3.096941 |g|=0.497	lr=7.56e-05 | 98.7%@S39  T=1.79s(data=2.1ms QKV=2.14s FFN=3.04s) eta=06:41:41 | 42.5K token/s | 
[Fuyou] head="1" update algorithm=4 t=15.43s
[eval] 
	 Loss@"edu_fineweb1B"=3.091(0.0015) nBranch=1 nToken=6.31M best=3.0929(236) E2T=0.0573 T=36.7812(0)s x=0
	#3.09141±0.0975 tps=171K(6.30784M) a=[2.90902,3.37178] T=36.7812(sec)
[Section@47600] layer[16-24] tasks=19(nPassBack=0) last_loss=3.03413(0.0829334) N=(772,53984,53424 6283068)
[epoch_0]_47601  loss=3.115050 |g|=0.513	lr=7.55e-05 | 99.5%@S39  T=14.01s(data=4.6ms QKV=2.12s FFN=3.03s) eta=2d 04:16:43 | 40.7K token/s | 
[epoch_0]_47607  loss=3.010487 |g|=0.489	lr=7.55e-05 | 100.0%@S39  T=1.84s(data=3.8ms QKV=2.11s FFN=3.04s) eta=06:50:51 | 40.9K token/s | 
-------- End of shard_39@"./Datasets/edu_fineweb1B/edu_fineweb_train_000797.bin"-------- 
[shard-40]@"./Datasets/edu_fineweb1B/edu_fineweb_train_000798.bin": tokens=100(M) nShardSamples=1220(3906240) 
[epoch_0]_47611  loss=3.118591 |g|=0.498	lr=7.54e-05 | 0.3%@S40  T=1.83s(data=1.8ms QKV=2.12s FFN=3.04s) eta=06:48:31 | 41.1K token/s | 
[epoch_0]_47621  loss=3.105672 |g|=0.503	lr=7.53e-05 | 1.1%@S40  T=1.84s(data=2.2ms QKV=2.12s FFN=3.04s) eta=06:52:23 | 41.3K token/s | 
[epoch_0]_47631  loss=3.137171 |g|=0.496	lr=7.52e-05 | 1.9%@S40  T=1.84s(data=2.2ms QKV=2.12s FFN=3.04s) eta=06:50:34 | 41.4K token/s | 
[epoch_0]_47641  loss=3.103325 |g|=0.497	lr=7.51e-05 | 2.8%@S40  T=1.88s(data=2.1ms QKV=2.12s FFN=3.04s) eta=06:58:42 | 41.5K token/s | 
[epoch_0]_47651  loss=2.996873 |g|=0.489	lr=7.50e-05 | 3.6%@S40  T=1.88s(data=3.1ms QKV=2.12s FFN=3.04s) eta=06:58:37 | 41.7K token/s | 
[epoch_0]_47661  loss=2.982510 |g|=0.488	lr=7.49e-05 | 4.4%@S40  T=1.88s(data=4.4ms QKV=2.12s FFN=3.04s) eta=06:59:31 | 41.7K token/s | 
[epoch_0]_47671  loss=3.085585 |g|=0.502	lr=7.48e-05 | 5.2%@S40  T=1.84s(data=4.2ms QKV=2.12s FFN=3.04s) eta=06:49:17 | 41.9K token/s | 
[epoch_0]_47681  loss=3.040884 |g|=0.508	lr=7.47e-05 | 6.0%@S40  T=1.83s(data=4.1ms QKV=2.12s FFN=3.04s) eta=06:47:43 | 42.0K token/s | 
[epoch_0]_47691  loss=3.063201 |g|=0.479	lr=7.46e-05 | 6.9%@S40  T=1.83s(data=4.1ms QKV=2.12s FFN=3.04s) eta=06:47:25 | 42.2K token/s | 
[Fuyou] head="2" update algorithm=4 t=13.38s
[Section@47700] layer[24-32] tasks=19(nPassBack=0) last_loss=3.06325(-0.0129693) N=(772,54096,53536 6296268)
[epoch_0]_47701  loss=3.062424 |g|=0.492	lr=7.45e-05 | 7.7%@S40  T=5.29s(data=3.3ms QKV=2.11s FFN=3.03s) eta=19:35:14 | 40.8K token/s | 
[epoch_0]_47711  loss=3.063699 |g|=0.485	lr=7.44e-05 | 8.5%@S40  T=1.79s(data=2.4ms QKV=2.13s FFN=3.04s) eta=06:37:34 | 41.1K token/s | 
[epoch_0]_47721  loss=3.083123 |g|=0.515	lr=7.43e-05 | 9.3%@S40  T=1.80s(data=2.2ms QKV=2.12s FFN=3.04s) eta=06:40:23 | 41.3K token/s | 
[epoch_0]_47731  loss=2.979941 |g|=0.473	lr=7.42e-05 | 10.1%@S40  T=1.79s(data=2.0ms QKV=2.12s FFN=3.04s) eta=06:36:33 | 41.5K token/s | 
[epoch_0]_47741  loss=3.072054 |g|=0.479	lr=7.41e-05 | 11.0%@S40  T=1.83s(data=1.9ms QKV=2.12s FFN=3.04s) eta=06:45:25 | 41.7K token/s | 
[epoch_0]_47751  loss=3.085792 |g|=0.491	lr=7.40e-05 | 11.8%@S40  T=1.78s(data=2.9ms QKV=2.12s FFN=3.04s) eta=06:33:55 | 41.9K token/s | 
[epoch_0]_47761  loss=3.096416 |g|=0.501	lr=7.39e-05 | 12.6%@S40  T=1.82s(data=4.4ms QKV=2.12s FFN=3.04s) eta=06:42:49 | 42.1K token/s | 
[epoch_0]_47771  loss=3.064809 |g|=0.473	lr=7.38e-05 | 13.4%@S40  T=1.82s(data=3.4ms QKV=2.12s FFN=3.04s) eta=06:42:33 | 42.2K token/s | 
[epoch_0]_47781  loss=3.113282 |g|=0.488	lr=7.37e-05 | 14.2%@S40  T=1.78s(data=2.5ms QKV=2.12s FFN=3.04s) eta=06:33:42 | 42.4K token/s | 
[epoch_0]_47791  loss=3.033991 |g|=0.48	lr=7.36e-05 | 15.0%@S40  T=1.87s(data=1.9ms QKV=2.12s FFN=3.04s) eta=06:52:27 | 42.5K token/s | 
[Fuyou] head="3" update algorithm=4 t=15.29s
[eval] 
	 Loss@"edu_fineweb1B"=3.092(-0.0004) nBranch=1 nToken=6.31M best=3.0914(237) E2T=0.147 T=36.8173(0)s x=0
	#3.09182±0.0977 tps=171K(6.30784M) a=[2.90561,3.37486] T=36.8173(sec)
[Section@47800] layer[32-40] tasks=19(nPassBack=0) last_loss=2.94513(0.15151) N=(772,54208,53648 6309468)
[epoch_0]_47801  loss=3.061105 |g|=0.486	lr=7.36e-05 | 15.9%@S40  T=13.17s(data=4.9ms QKV=2.12s FFN=3.04s) eta=2d 00:25:32 | 40.6K token/s | 
[epoch_0]_47811  loss=2.992964 |g|=0.483	lr=7.35e-05 | 16.7%@S40  T=1.85s(data=4.5ms QKV=2.11s FFN=3.04s) eta=06:48:45 | 40.8K token/s | 
[epoch_0]_47821  loss=3.062155 |g|=0.526	lr=7.34e-05 | 17.5%@S40  T=1.81s(data=4.9ms QKV=2.11s FFN=3.04s) eta=06:39:22 | 41.0K token/s | 
[epoch_0]_47831  loss=3.011893 |g|=0.493	lr=7.33e-05 | 18.3%@S40  T=1.83s(data=3.8ms QKV=2.11s FFN=3.04s) eta=06:42:37 | 41.2K token/s | 
[epoch_0]_47841  loss=3.114694 |g|=0.486	lr=7.32e-05 | 19.1%@S40  T=1.82s(data=3.6ms QKV=2.12s FFN=3.04s) eta=06:39:43 | 41.4K token/s | 
[epoch_0]_47851  loss=3.028394 |g|=0.484	lr=7.31e-05 | 20.0%@S40  T=1.81s(data=3.4ms QKV=2.11s FFN=3.04s) eta=06:37:06 | 41.6K token/s | 
[epoch_0]_47861  loss=3.030537 |g|=0.49	lr=7.30e-05 | 20.8%@S40  T=1.83s(data=2.6ms QKV=2.11s FFN=3.04s) eta=06:42:30 | 41.8K token/s | 
[epoch_0]_47871  loss=3.084892 |g|=0.499	lr=7.29e-05 | 21.6%@S40  T=1.80s(data=3.2ms QKV=2.11s FFN=3.04s) eta=06:35:29 | 42.0K token/s | 
[epoch_0]_47881  loss=3.039517 |g|=0.476	lr=7.28e-05 | 22.4%@S40  T=1.77s(data=2.0ms QKV=2.12s FFN=3.04s) eta=06:27:24 | 42.2K token/s | 
[epoch_0]_47891  loss=3.082714 |g|=0.475	lr=7.27e-05 | 23.2%@S40  T=1.74s(data=3.0ms QKV=2.11s FFN=3.04s) eta=06:21:59 | 42.4K token/s | 
[Fuyou] head="4" update algorithm=4 t=15.65s
[Section@47900] layer[40-48] tasks=19(nPassBack=0) last_loss=3.03036(0.0237279) N=(772,54320,53760 6322668)
[epoch_0]_47901  loss=3.093650 |g|=0.489	lr=7.26e-05 | 24.1%@S40  T=5.31s(data=5.3ms QKV=2.12s FFN=3.03s) eta=19:21:49 | 41.1K token/s | 
[epoch_0]_47911  loss=3.067724 |g|=0.474	lr=7.25e-05 | 24.9%@S40  T=1.81s(data=3.0ms QKV=2.12s FFN=3.04s) eta=06:35:28 | 41.3K token/s | 
[epoch_0]_47921  loss=3.118802 |g|=0.518	lr=7.24e-05 | 25.7%@S40  T=1.75s(data=2.6ms QKV=2.12s FFN=3.04s) eta=06:23:20 | 41.5K token/s | 
[epoch_0]_47931  loss=3.061114 |g|=0.48	lr=7.23e-05 | 26.5%@S40  T=1.76s(data=3.0ms QKV=2.12s FFN=3.04s) eta=06:24:30 | 41.8K token/s | 
[epoch_0]_47941  loss=3.021586 |g|=0.492	lr=7.22e-05 | 27.3%@S40  T=1.75s(data=2.6ms QKV=2.12s FFN=3.04s) eta=06:21:10 | 42.1K token/s | 
[epoch_0]_47951  loss=2.997525 |g|=0.496	lr=7.21e-05 | 28.2%@S40  T=1.79s(data=2.7ms QKV=2.12s FFN=3.04s) eta=06:29:21 | 42.2K token/s | 
[epoch_0]_47961  loss=3.071291 |g|=0.49	lr=7.20e-05 | 29.0%@S40  T=1.76s(data=1.8ms QKV=2.12s FFN=3.04s) eta=06:23:35 | 42.5K token/s | 
[epoch_0]_47971  loss=3.048834 |g|=0.492	lr=7.19e-05 | 29.8%@S40  T=1.83s(data=3.6ms QKV=2.13s FFN=3.04s) eta=06:37:50 | 42.6K token/s | 
[epoch_0]_47981  loss=3.040755 |g|=0.481	lr=7.18e-05 | 30.6%@S40  T=1.80s(data=2.1ms QKV=2.12s FFN=3.04s) eta=06:30:43 | 42.7K token/s | 
[epoch_0]_47991  loss=3.099339 |g|=0.498	lr=7.17e-05 | 31.4%@S40  T=1.81s(data=1.5ms QKV=2.12s FFN=3.04s) eta=06:32:47 | 42.9K token/s | 
[Fuyou] head="5" update algorithm=4 t=15.71s
[eval] 
	 Loss@"edu_fineweb1B"=3.091(0.00063) nBranch=1 nToken=6.31M best=3.0918(238) E2T=0.0696 T=36.7473(0)s x=0
	#3.09119±0.0973 tps=172K(6.30784M) a=[2.90534,3.37171] T=36.7473(sec)
[Section@48000] layer[0-8] tasks=19(nPassBack=0) last_loss=3.02154(0.0381711) N=(772,54432,53872 6335868)
[epoch_0]_48001  loss=3.104454 |g|=0.498	lr=7.16e-05 | 32.3%@S40  T=12.79s(data=2.5ms QKV=2.11s FFN=3.03s) eta=1d 22:17:44 | 41.0K token/s | 
[epoch_0]_48011  loss=3.101477 |g|=0.475	lr=7.15e-05 | 33.1%@S40  T=1.78s(data=1.8ms QKV=2.12s FFN=3.04s) eta=06:25:42 | 41.3K token/s | 
[epoch_0]_48021  loss=3.032298 |g|=0.507	lr=7.14e-05 | 33.9%@S40  T=1.77s(data=4.1ms QKV=2.12s FFN=3.04s) eta=06:23:56 | 41.5K token/s | 
[epoch_0]_48031  loss=3.061822 |g|=0.503	lr=7.13e-05 | 34.7%@S40  T=1.86s(data=2.2ms QKV=2.12s FFN=3.04s) eta=06:43:33 | 41.7K token/s | 
[epoch_0]_48041  loss=3.007798 |g|=0.485	lr=7.12e-05 | 35.5%@S40  T=1.84s(data=2.1ms QKV=2.12s FFN=3.04s) eta=06:39:01 | 41.8K token/s | 
[epoch_0]_48051  loss=3.067399 |g|=0.496	lr=7.11e-05 | 36.3%@S40  T=1.82s(data=3.0ms QKV=2.12s FFN=3.04s) eta=06:33:53 | 42.0K token/s | 
[epoch_0]_48061  loss=3.035716 |g|=0.505	lr=7.10e-05 | 37.2%@S40  T=1.76s(data=3.2ms QKV=2.12s FFN=3.04s) eta=06:19:34 | 42.2K token/s | 
[epoch_0]_48071  loss=3.030549 |g|=0.479	lr=7.09e-05 | 38.0%@S40  T=1.84s(data=2.0ms QKV=2.12s FFN=3.04s) eta=06:36:42 | 42.3K token/s | 
[epoch_0]_48081  loss=3.003180 |g|=0.485	lr=7.08e-05 | 38.8%@S40  T=1.78s(data=2.0ms QKV=2.12s FFN=3.04s) eta=06:25:06 | 42.5K token/s | 
[epoch_0]_48091  loss=3.133320 |g|=0.491	lr=7.07e-05 | 39.6%@S40  T=1.88s(data=2.6ms QKV=2.12s FFN=3.04s) eta=06:45:14 | 42.6K token/s | 
[Fuyou] head="0" update algorithm=4 t=15.41s
[Section@48100] layer[8-16] tasks=19(nPassBack=0) last_loss=3.03542(0.0410745) N=(772,54544,53984 6349068)
[epoch_0]_48101  loss=3.079632 |g|=0.481	lr=7.06e-05 | 40.4%@S40  T=6.02s(data=4.0ms QKV=2.12s FFN=3.03s) eta=21:38:11 | 41.1K token/s | 
[epoch_0]_48111  loss=3.039293 |g|=0.482	lr=7.05e-05 | 41.3%@S40  T=1.84s(data=2.9ms QKV=2.12s FFN=3.03s) eta=06:36:05 | 41.3K token/s | 
[epoch_0]_48121  loss=3.029246 |g|=0.501	lr=7.04e-05 | 42.1%@S40  T=1.88s(data=2.1ms QKV=2.13s FFN=3.04s) eta=06:43:48 | 41.4K token/s | 
[epoch_0]_48131  loss=3.058945 |g|=0.488	lr=7.04e-05 | 42.9%@S40  T=1.75s(data=3.1ms QKV=2.12s FFN=3.04s) eta=06:15:44 | 41.7K token/s | 
[epoch_0]_48141  loss=3.086914 |g|=0.49	lr=7.03e-05 | 43.7%@S40  T=1.75s(data=2.4ms QKV=2.12s FFN=3.04s) eta=06:16:41 | 41.9K token/s | 
[epoch_0]_48151  loss=3.061618 |g|=0.491	lr=7.02e-05 | 44.5%@S40  T=1.78s(data=2.5ms QKV=2.12s FFN=3.04s) eta=06:21:56 | 42.1K token/s | 
[epoch_0]_48161  loss=3.029216 |g|=0.511	lr=7.01e-05 | 45.4%@S40  T=1.86s(data=2.0ms QKV=2.12s FFN=3.04s) eta=06:39:38 | 42.2K token/s | 
[epoch_0]_48171  loss=3.037492 |g|=0.474	lr=7.00e-05 | 46.2%@S40  T=1.87s(data=2.4ms QKV=2.12s FFN=3.04s) eta=06:41:51 | 42.3K token/s | 
[epoch_0]_48181  loss=3.065560 |g|=0.482	lr=6.99e-05 | 47.0%@S40  T=1.85s(data=2.0ms QKV=2.12s FFN=3.04s) eta=06:36:17 | 42.4K token/s | 
[epoch_0]_48191  loss=3.058622 |g|=0.518	lr=6.98e-05 | 47.8%@S40  T=1.77s(data=2.9ms QKV=2.12s FFN=3.04s) eta=06:19:30 | 42.6K token/s | 
[Fuyou] head="1" update algorithm=4 t=13.43s
[eval] 
	 Loss@"edu_fineweb1B"=3.090(0.0008) nBranch=1 nToken=6.31M best=3.0912(239) E2T=0.00925 T=36.7594(0)s x=0
	#3.09039±0.0975 tps=172K(6.30784M) a=[2.90453,3.36876] T=36.7594(sec)
[Section@48200] layer[16-24] tasks=19(nPassBack=0) last_loss=3.08113(-0.0470047) N=(772,54656,54096 6362268)
[epoch_0]_48201  loss=3.067029 |g|=0.481	lr=6.97e-05 | 48.6%@S40  T=12.99s(data=3.1ms QKV=2.11s FFN=3.03s) eta=1d 22:19:09 | 40.8K token/s | 
[epoch_0]_48211  loss=3.044894 |g|=0.499	lr=6.96e-05 | 49.5%@S40  T=1.77s(data=3.5ms QKV=2.12s FFN=3.04s) eta=06:18:39 | 41.0K token/s | 
[epoch_0]_48221  loss=3.052188 |g|=0.476	lr=6.95e-05 | 50.3%@S40  T=1.78s(data=3.1ms QKV=2.12s FFN=3.04s) eta=06:21:08 | 41.3K token/s | 
[epoch_0]_48231  loss=2.936570 |g|=0.483	lr=6.94e-05 | 51.1%@S40  T=1.75s(data=3.1ms QKV=2.12s FFN=3.04s) eta=06:14:01 | 41.6K token/s | 
[epoch_0]_48241  loss=3.086763 |g|=0.482	lr=6.93e-05 | 51.9%@S40  T=1.82s(data=2.5ms QKV=2.12s FFN=3.04s) eta=06:28:03 | 41.7K token/s | 
[epoch_0]_48251  loss=3.090849 |g|=0.505	lr=6.92e-05 | 52.7%@S40  T=1.87s(data=2.9ms QKV=2.12s FFN=3.04s) eta=06:38:32 | 41.8K token/s | 
[epoch_0]_48261  loss=3.072782 |g|=0.487	lr=6.91e-05 | 53.6%@S40  T=1.86s(data=2.1ms QKV=2.13s FFN=3.04s) eta=06:35:11 | 42.0K token/s | 
[epoch_0]_48271  loss=3.133583 |g|=0.5	lr=6.90e-05 | 54.4%@S40  T=1.78s(data=2.9ms QKV=2.12s FFN=3.04s) eta=06:18:50 | 42.2K token/s | 
[epoch_0]_48281  loss=3.095852 |g|=0.504	lr=6.89e-05 | 55.2%@S40  T=1.76s(data=2.6ms QKV=2.12s FFN=3.04s) eta=06:13:09 | 42.4K token/s | 
[epoch_0]_48291  loss=2.983669 |g|=0.47	lr=6.88e-05 | 56.0%@S40  T=1.75s(data=2.9ms QKV=2.12s FFN=3.04s) eta=06:12:18 | 42.6K token/s | 
[Fuyou] head="2" update algorithm=4 t=12.84s
[Section@48300] layer[24-32] tasks=19(nPassBack=0) last_loss=3.08138(-0.0181265) N=(772,54768,54208 6375468)
[epoch_0]_48301  loss=3.124543 |g|=0.494	lr=6.87e-05 | 56.8%@S40  T=5.13s(data=3.2ms QKV=2.12s FFN=3.03s) eta=18:08:37 | 41.3K token/s | 
[epoch_0]_48311  loss=3.052427 |g|=0.495	lr=6.86e-05 | 57.6%@S40  T=1.83s(data=3.7ms QKV=2.13s FFN=3.04s) eta=06:28:26 | 41.4K token/s | 
[epoch_0]_48321  loss=3.061689 |g|=0.5	lr=6.85e-05 | 58.5%@S40  T=1.96s(data=5.4ms QKV=2.12s FFN=3.04s) eta=06:56:06 | 41.5K token/s | 
[epoch_0]_48331  loss=2.972935 |g|=0.498	lr=6.84e-05 | 59.3%@S40  T=1.84s(data=3.7ms QKV=2.12s FFN=3.04s) eta=06:29:25 | 41.6K token/s | 
[epoch_0]_48341  loss=2.992657 |g|=0.492	lr=6.83e-05 | 60.1%@S40  T=1.80s(data=2.7ms QKV=2.12s FFN=3.04s) eta=06:19:54 | 41.8K token/s | 
[epoch_0]_48351  loss=2.968342 |g|=0.48	lr=6.83e-05 | 60.9%@S40  T=1.87s(data=2.8ms QKV=2.12s FFN=3.04s) eta=06:34:25 | 41.9K token/s | 
[epoch_0]_48361  loss=3.067705 |g|=0.494	lr=6.82e-05 | 61.7%@S40  T=1.77s(data=2.6ms QKV=2.12s FFN=3.04s) eta=06:14:00 | 42.1K token/s | 
[epoch_0]_48371  loss=3.092922 |g|=0.48	lr=6.81e-05 | 62.6%@S40  T=1.79s(data=12.4ms QKV=2.13s FFN=3.04s) eta=06:18:37 | 42.3K token/s | 
[epoch_0]_48381  loss=2.997944 |g|=0.499	lr=6.80e-05 | 63.4%@S40  T=1.85s(data=2.8ms QKV=2.12s FFN=3.04s) eta=06:30:35 | 42.4K token/s | 
[epoch_0]_48391  loss=3.014099 |g|=0.48	lr=6.79e-05 | 64.2%@S40  T=1.78s(data=3.2ms QKV=2.12s FFN=3.04s) eta=06:16:00 | 42.6K token/s | 
[Fuyou] head="3" update algorithm=4 t=14.43s
[eval] 
	 Loss@"edu_fineweb1B"=3.089(0.0015) nBranch=1 nToken=6.31M best=3.0904(240) E2T=0.0355 T=36.7463(0)s x=0
	#3.08886±0.0974 tps=172K(6.30784M) a=[2.90396,3.36831] T=36.7463(sec)
[Section@48400] layer[32-40] tasks=19(nPassBack=0) last_loss=3.05335(-0.108224) N=(772,54880,54320 6388668)
[epoch_0]_48401  loss=3.056099 |g|=0.491	lr=6.78e-05 | 65.0%@S40  T=12.66s(data=3.4ms QKV=2.12s FFN=3.03s) eta=1d 20:25:38 | 40.8K token/s | 
[epoch_0]_48411  loss=2.990176 |g|=0.504	lr=6.77e-05 | 65.8%@S40  T=1.77s(data=2.8ms QKV=2.11s FFN=3.04s) eta=06:12:32 | 41.0K token/s | 
[epoch_0]_48421  loss=3.012772 |g|=0.467	lr=6.76e-05 | 66.7%@S40  T=1.87s(data=2.2ms QKV=2.12s FFN=3.04s) eta=06:32:52 | 41.2K token/s | 
[epoch_0]_48431  loss=3.008615 |g|=0.478	lr=6.75e-05 | 67.5%@S40  T=1.78s(data=3.3ms QKV=2.11s FFN=3.04s) eta=06:14:56 | 41.4K token/s | 
[epoch_0]_48441  loss=3.045049 |g|=0.488	lr=6.74e-05 | 68.3%@S40  T=1.80s(data=3.4ms QKV=2.12s FFN=3.04s) eta=06:17:29 | 41.6K token/s | 
[epoch_0]_48451  loss=2.984432 |g|=0.475	lr=6.73e-05 | 69.1%@S40  T=1.85s(data=3.1ms QKV=2.12s FFN=3.04s) eta=06:27:03 | 41.8K token/s | 
[epoch_0]_48461  loss=3.018904 |g|=0.513	lr=6.72e-05 | 69.9%@S40  T=1.89s(data=2.9ms QKV=2.12s FFN=3.04s) eta=06:35:34 | 41.8K token/s | 
[epoch_0]_48471  loss=3.009940 |g|=0.476	lr=6.71e-05 | 70.8%@S40  T=1.81s(data=2.8ms QKV=2.12s FFN=3.04s) eta=06:18:54 | 42.0K token/s | 
[epoch_0]_48481  loss=3.001379 |g|=0.473	lr=6.70e-05 | 71.6%@S40  T=1.78s(data=3.0ms QKV=2.12s FFN=3.04s) eta=06:12:51 | 42.2K token/s | 
[epoch_0]_48491  loss=3.021471 |g|=0.474	lr=6.69e-05 | 72.4%@S40  T=1.75s(data=2.8ms QKV=2.11s FFN=3.04s) eta=06:06:33 | 42.4K token/s | 
[Fuyou] head="4" update algorithm=4 t=15.43s
[Section@48500] layer[40-48] tasks=19(nPassBack=0) last_loss=3.05092(-0.0205569) N=(772,54992,54432 6401868)
[epoch_0]_48501  loss=3.098430 |g|=0.489	lr=6.68e-05 | 73.2%@S40  T=5.29s(data=5.0ms QKV=2.12s FFN=3.03s) eta=18:25:06 | 41.1K token/s | 
[epoch_0]_48511  loss=3.068279 |g|=0.523	lr=6.67e-05 | 74.0%@S40  T=1.77s(data=3.4ms QKV=2.12s FFN=3.04s) eta=06:09:39 | 41.4K token/s | 
[epoch_0]_48521  loss=3.061720 |g|=0.494	lr=6.67e-05 | 74.9%@S40  T=1.80s(data=3.5ms QKV=2.12s FFN=3.04s) eta=06:15:23 | 41.6K token/s | 
[epoch_0]_48531  loss=2.968585 |g|=0.487	lr=6.66e-05 | 75.7%@S40  T=1.82s(data=3.4ms QKV=2.12s FFN=3.04s) eta=06:19:04 | 41.7K token/s | 
[epoch_0]_48541  loss=2.985394 |g|=0.481	lr=6.65e-05 | 76.5%@S40  T=1.82s(data=3.6ms QKV=2.12s FFN=3.04s) eta=06:19:57 | 41.9K token/s | 
[epoch_0]_48551  loss=3.040564 |g|=0.512	lr=6.64e-05 | 77.3%@S40  T=1.82s(data=3.0ms QKV=2.12s FFN=3.04s) eta=06:18:27 | 42.1K token/s | 
[epoch_0]_48561  loss=3.027116 |g|=0.504	lr=6.63e-05 | 78.1%@S40  T=1.81s(data=3.2ms QKV=2.12s FFN=3.04s) eta=06:17:06 | 42.2K token/s | 
[epoch_0]_48571  loss=3.085931 |g|=0.513	lr=6.62e-05 | 78.9%@S40  T=1.88s(data=3.4ms QKV=2.12s FFN=3.04s) eta=06:30:00 | 42.3K token/s | 
[epoch_0]_48581  loss=2.992816 |g|=0.499	lr=6.61e-05 | 79.8%@S40  T=1.85s(data=3.1ms QKV=2.12s FFN=3.04s) eta=06:23:59 | 42.4K token/s | 
[epoch_0]_48591  loss=3.044886 |g|=0.469	lr=6.60e-05 | 80.6%@S40  T=1.79s(data=2.3ms QKV=2.12s FFN=3.04s) eta=06:11:22 | 42.5K token/s | 
[Fuyou] head="5" update algorithm=4 t=15.70s
[eval] 
	 Loss@"edu_fineweb1B"=3.089(0.00018) nBranch=1 nToken=6.31M best=3.0889(241) E2T=0.0739 T=36.7663(0)s x=0
	#3.08868±0.0976 tps=172K(6.30784M) a=[2.90566,3.36923] T=36.7663(sec)
[Section@48600] layer[0-8] tasks=19(nPassBack=0) last_loss=3.01475(0.00679159) N=(772,55104,54544 6415068)
[epoch_0]_48601  loss=3.084192 |g|=0.482	lr=6.59e-05 | 81.4%@S40  T=12.96s(data=1.8ms QKV=2.11s FFN=3.04s) eta=1d 20:45:42 | 40.7K token/s | 
[epoch_0]_48611  loss=3.066893 |g|=0.481	lr=6.58e-05 | 82.2%@S40  T=1.78s(data=1.6ms QKV=2.11s FFN=3.04s) eta=06:08:02 | 41.0K token/s | 
[epoch_0]_48621  loss=3.063817 |g|=0.505	lr=6.57e-05 | 83.0%@S40  T=1.77s(data=1.7ms QKV=2.12s FFN=3.04s) eta=06:05:42 | 41.3K token/s | 
[epoch_0]_48631  loss=3.049220 |g|=0.493	lr=6.56e-05 | 83.9%@S40  T=1.78s(data=1.6ms QKV=2.11s FFN=3.04s) eta=06:07:16 | 41.5K token/s | 
[epoch_0]_48641  loss=2.996619 |g|=0.479	lr=6.55e-05 | 84.7%@S40  T=1.77s(data=1.8ms QKV=2.12s FFN=3.04s) eta=06:06:14 | 41.7K token/s | 
[epoch_0]_48651  loss=3.011925 |g|=0.473	lr=6.54e-05 | 85.5%@S40  T=1.78s(data=1.6ms QKV=2.11s FFN=3.04s) eta=06:06:37 | 42.0K token/s | 
[epoch_0]_48661  loss=3.039257 |g|=0.496	lr=6.54e-05 | 86.3%@S40  T=1.77s(data=1.6ms QKV=2.12s FFN=3.04s) eta=06:04:59 | 42.2K token/s | 
[epoch_0]_48671  loss=3.061197 |g|=0.476	lr=6.53e-05 | 87.1%@S40  T=1.79s(data=1.6ms QKV=2.12s FFN=3.04s) eta=06:09:32 | 42.4K token/s | 
[epoch_0]_48681  loss=3.038652 |g|=0.49	lr=6.52e-05 | 88.0%@S40  T=1.77s(data=1.7ms QKV=2.12s FFN=3.04s) eta=06:03:45 | 42.6K token/s | 
[epoch_0]_48691  loss=3.025374 |g|=0.508	lr=6.51e-05 | 88.8%@S40  T=1.77s(data=2.7ms QKV=2.13s FFN=3.04s) eta=06:04:17 | 42.7K token/s | 
[Fuyou] head="0" update algorithm=4 t=12.76s
[Section@48700] layer[8-16] tasks=19(nPassBack=0) last_loss=3.01257(0.0228517) N=(772,55216,54656 6428268)
[epoch_0]_48701  loss=3.086806 |g|=0.485	lr=6.50e-05 | 89.6%@S40  T=5.06s(data=3.0ms QKV=2.13s FFN=3.03s) eta=17:19:33 | 41.4K token/s | 
[epoch_0]_48711  loss=3.145687 |g|=0.504	lr=6.49e-05 | 90.4%@S40  T=1.75s(data=1.9ms QKV=2.13s FFN=3.04s) eta=05:58:56 | 41.7K token/s | 
[epoch_0]_48721  loss=3.042852 |g|=0.49	lr=6.48e-05 | 91.2%@S40  T=1.81s(data=1.8ms QKV=2.13s FFN=3.04s) eta=06:11:08 | 41.9K token/s | 
[epoch_0]_48731  loss=3.055705 |g|=0.488	lr=6.47e-05 | 92.1%@S40  T=1.78s(data=1.6ms QKV=2.13s FFN=3.04s) eta=06:04:34 | 42.1K token/s | 
[epoch_0]_48741  loss=3.053328 |g|=0.488	lr=6.46e-05 | 92.9%@S40  T=1.77s(data=1.8ms QKV=2.13s FFN=3.04s) eta=06:01:40 | 42.3K token/s | 
[epoch_0]_48751  loss=3.065854 |g|=0.483	lr=6.45e-05 | 93.7%@S40  T=1.79s(data=1.6ms QKV=2.13s FFN=3.04s) eta=06:06:18 | 42.5K token/s | 
[epoch_0]_48761  loss=3.029235 |g|=0.477	lr=6.44e-05 | 94.5%@S40  T=1.77s(data=1.7ms QKV=2.13s FFN=3.04s) eta=06:01:56 | 42.7K token/s | 
[epoch_0]_48771  loss=2.990054 |g|=0.48	lr=6.43e-05 | 95.3%@S40  T=1.77s(data=1.5ms QKV=2.13s FFN=3.04s) eta=06:01:47 | 42.8K token/s | 
[epoch_0]_48781  loss=3.012994 |g|=0.493	lr=6.42e-05 | 96.2%@S40  T=1.78s(data=1.5ms QKV=2.13s FFN=3.04s) eta=06:04:31 | 43.0K token/s | 
[epoch_0]_48791  loss=2.990639 |g|=0.501	lr=6.42e-05 | 97.0%@S40  T=1.78s(data=1.9ms QKV=2.13s FFN=3.04s) eta=06:02:49 | 43.1K token/s | 
[Fuyou] head="1" update algorithm=4 t=11.18s
[eval] 
	 Loss@"edu_fineweb1B"=3.088(0.00057) nBranch=1 nToken=6.31M best=3.0887(242) E2T=0.00737 T=36.7449(0)s x=0
	#3.08811±0.0974 tps=172K(6.30784M) a=[2.90345,3.36787] T=36.7449(sec)
[Section@48800] layer[16-24] tasks=19(nPassBack=0) last_loss=3.08074(0.000395775) N=(772,55328,54768 6441468)
[epoch_0]_48801  loss=3.025876 |g|=0.508	lr=6.41e-05 | 97.8%@S40  T=12.41s(data=2.2ms QKV=2.12s FFN=3.04s) eta=1d 18:11:08 | 41.3K token/s | 
[epoch_0]_48811  loss=3.053602 |g|=0.487	lr=6.40e-05 | 98.6%@S40  T=1.77s(data=1.8ms QKV=2.12s FFN=3.04s) eta=06:01:18 | 41.6K token/s | 
[epoch_0]_48821  loss=3.074222 |g|=0.499	lr=6.39e-05 | 99.4%@S40  T=1.79s(data=2.0ms QKV=2.12s FFN=3.04s) eta=06:04:30 | 41.8K token/s | 
[epoch_0]_48827  loss=3.027856 |g|=0.485	lr=6.38e-05 | 99.9%@S40  T=1.79s(data=1.7ms QKV=2.12s FFN=3.04s) eta=06:03:47 | 42.0K token/s | 
[epoch_0]_48828  loss=3.006834 |g|=0.493	lr=6.38e-05 | 100.0%@S40  T=1.78s(data=1.9ms QKV=2.12s FFN=3.04s) eta=06:02:50 | 42.2K token/s | 
-------- End of shard_40@"./Datasets/edu_fineweb1B/edu_fineweb_train_000798.bin"-------- 
[shard-41]@"./Datasets/edu_fineweb1B/edu_fineweb_train_000799.bin": tokens=100(M) nShardSamples=1220(4003896) 
[epoch_0]_48831  loss=3.167526 |g|=0.503	lr=6.38e-05 | 0.2%@S41  T=1.84s(data=1.3ms QKV=2.12s FFN=3.04s) eta=06:14:23 | 42.3K token/s | 
[epoch_0]_48841  loss=3.020692 |g|=0.49	lr=6.37e-05 | 1.1%@S41  T=1.80s(data=1.4ms QKV=2.12s FFN=3.04s) eta=06:05:35 | 42.5K token/s | 
[epoch_0]_48851  loss=3.107324 |g|=0.506	lr=6.36e-05 | 1.9%@S41  T=1.92s(data=1.5ms QKV=2.12s FFN=3.04s) eta=06:29:40 | 42.5K token/s | 
[epoch_0]_48861  loss=3.060505 |g|=0.495	lr=6.35e-05 | 2.7%@S41  T=1.83s(data=1.7ms QKV=2.12s FFN=3.04s) eta=06:11:41 | 42.6K token/s | 
[epoch_0]_48871  loss=3.085106 |g|=0.498	lr=6.34e-05 | 3.5%@S41  T=1.76s(data=1.7ms QKV=2.12s FFN=3.04s) eta=05:57:48 | 42.8K token/s | 
[epoch_0]_48881  loss=3.039752 |g|=0.476	lr=6.33e-05 | 4.3%@S41  T=1.79s(data=1.7ms QKV=2.12s FFN=3.04s) eta=06:01:44 | 42.9K token/s | 
[epoch_0]_48891  loss=2.998734 |g|=0.486	lr=6.32e-05 | 5.2%@S41  T=1.77s(data=1.6ms QKV=2.12s FFN=3.04s) eta=05:57:27 | 43.1K token/s | 
[Fuyou] head="2" update algorithm=4 t=11.05s
[Section@48900] layer[24-32] tasks=19(nPassBack=0) last_loss=3.04179(0.0395863) N=(772,55440,54880 6454668)
[epoch_0]_48901  loss=3.040900 |g|=0.489	lr=6.31e-05 | 6.0%@S41  T=4.80s(data=1.6ms QKV=2.12s FFN=3.03s) eta=16:10:25 | 41.8K token/s | 
[epoch_0]_48911  loss=3.051121 |g|=0.489	lr=6.31e-05 | 6.8%@S41  T=1.76s(data=2.8ms QKV=2.12s FFN=3.04s) eta=05:55:00 | 42.0K token/s | 
[epoch_0]_48921  loss=3.031832 |g|=0.475	lr=6.30e-05 | 7.6%@S41  T=1.77s(data=1.6ms QKV=2.12s FFN=3.04s) eta=05:56:55 | 42.3K token/s | 
[epoch_0]_48931  loss=3.076542 |g|=0.496	lr=6.29e-05 | 8.4%@S41  T=1.82s(data=1.4ms QKV=2.13s FFN=3.04s) eta=06:06:24 | 42.4K token/s | 
[epoch_0]_48941  loss=3.063576 |g|=0.491	lr=6.28e-05 | 9.3%@S41  T=1.80s(data=1.3ms QKV=2.13s FFN=3.04s) eta=06:02:41 | 42.6K token/s | 
[epoch_0]_48951  loss=3.059693 |g|=0.495	lr=6.27e-05 | 10.1%@S41  T=1.79s(data=1.4ms QKV=2.13s FFN=3.04s) eta=06:00:08 | 42.7K token/s | 
[epoch_0]_48961  loss=2.960405 |g|=0.506	lr=6.26e-05 | 10.9%@S41  T=1.79s(data=1.4ms QKV=2.13s FFN=3.04s) eta=05:59:20 | 42.9K token/s | 
[epoch_0]_48971  loss=2.983486 |g|=0.491	lr=6.25e-05 | 11.7%@S41  T=1.77s(data=1.6ms QKV=2.13s FFN=3.04s) eta=05:56:10 | 43.0K token/s | 
[epoch_0]_48981  loss=3.000268 |g|=0.504	lr=6.24e-05 | 12.5%@S41  T=1.76s(data=1.7ms QKV=2.13s FFN=3.04s) eta=05:53:34 | 43.2K token/s | 
[epoch_0]_48991  loss=3.028102 |g|=0.485	lr=6.23e-05 | 13.4%@S41  T=1.76s(data=1.6ms QKV=2.13s FFN=3.04s) eta=05:54:07 | 43.4K token/s | 
[Fuyou] head="3" update algorithm=4 t=12.74s
[eval] 
	 Loss@"edu_fineweb1B"=3.084(0.0045) nBranch=1 nToken=6.31M best=3.0881(243) E2T=0.0377 T=36.717(0)s x=0
	#3.08365±0.0975 tps=172K(6.30784M) a=[2.9005,3.36507] T=36.717(sec)
[Section@49000] layer[32-40] tasks=19(nPassBack=0) last_loss=3.04595(0.00740242) N=(772,55552,54992 6467868)
[epoch_0]_49001  loss=3.079293 |g|=0.488	lr=6.22e-05 | 14.2%@S41  T=12.13s(data=1.8ms QKV=2.12s FFN=3.04s) eta=1d 16:32:40 | 41.5K token/s | 
[epoch_0]_49011  loss=3.142500 |g|=0.491	lr=6.22e-05 | 15.0%@S41  T=1.81s(data=1.5ms QKV=2.12s FFN=3.04s) eta=06:02:06 | 41.7K token/s | 
[epoch_0]_49021  loss=2.973513 |g|=0.485	lr=6.21e-05 | 15.8%@S41  T=1.77s(data=1.7ms QKV=2.12s FFN=3.04s) eta=05:54:14 | 42.0K token/s | 
[epoch_0]_49031  loss=3.086543 |g|=0.498	lr=6.20e-05 | 16.6%@S41  T=1.79s(data=1.8ms QKV=2.12s FFN=3.04s) eta=05:57:53 | 42.2K token/s | 
[epoch_0]_49041  loss=3.046089 |g|=0.488	lr=6.19e-05 | 17.5%@S41  T=1.77s(data=1.8ms QKV=2.12s FFN=3.04s) eta=05:53:18 | 42.4K token/s | 
[epoch_0]_49051  loss=3.054879 |g|=0.508	lr=6.18e-05 | 18.3%@S41  T=1.78s(data=2.7ms QKV=2.12s FFN=3.04s) eta=05:54:55 | 42.6K token/s | 
[epoch_0]_49061  loss=3.050950 |g|=0.504	lr=6.17e-05 | 19.1%@S41  T=1.80s(data=1.6ms QKV=2.12s FFN=3.04s) eta=05:58:49 | 42.7K token/s | 
[epoch_0]_49071  loss=3.125915 |g|=0.488	lr=6.16e-05 | 19.9%@S41  T=1.76s(data=2.7ms QKV=2.12s FFN=3.04s) eta=05:51:49 | 42.9K token/s | 
[epoch_0]_49081  loss=3.051853 |g|=0.489	lr=6.15e-05 | 20.7%@S41  T=1.77s(data=1.5ms QKV=2.12s FFN=3.04s) eta=05:51:49 | 43.1K token/s | 
[epoch_0]_49091  loss=3.005043 |g|=0.485	lr=6.14e-05 | 21.5%@S41  T=1.80s(data=1.5ms QKV=2.12s FFN=3.04s) eta=05:57:40 | 43.2K token/s | 
[Fuyou] head="4" update algorithm=4 t=12.60s
[Section@49100] layer[40-48] tasks=19(nPassBack=0) last_loss=3.07318(-0.0222561) N=(772,55664,55104 6481068)
[epoch_0]_49101  loss=3.071744 |g|=0.503	lr=6.13e-05 | 22.4%@S41  T=4.47s(data=2.0ms QKV=2.12s FFN=3.03s) eta=14:48:15 | 41.9K token/s | 
[epoch_0]_49111  loss=3.123205 |g|=0.497	lr=6.13e-05 | 23.2%@S41  T=1.79s(data=2.0ms QKV=2.12s FFN=3.04s) eta=05:55:56 | 42.1K token/s | 
[epoch_0]_49121  loss=3.079720 |g|=0.473	lr=6.12e-05 | 24.0%@S41  T=1.78s(data=1.7ms QKV=2.13s FFN=3.04s) eta=05:54:03 | 42.3K token/s | 
[epoch_0]_49131  loss=3.056183 |g|=0.487	lr=6.11e-05 | 24.8%@S41  T=1.76s(data=1.4ms QKV=2.12s FFN=3.04s) eta=05:50:04 | 42.5K token/s | 
[epoch_0]_49141  loss=3.128324 |g|=0.496	lr=6.10e-05 | 25.6%@S41  T=1.80s(data=1.4ms QKV=2.13s FFN=3.04s) eta=05:56:09 | 42.7K token/s | 
[epoch_0]_49151  loss=3.021242 |g|=0.519	lr=6.09e-05 | 26.5%@S41  T=1.78s(data=1.8ms QKV=2.13s FFN=3.04s) eta=05:52:40 | 42.9K token/s | 
[epoch_0]_49161  loss=2.990037 |g|=0.49	lr=6.08e-05 | 27.3%@S41  T=1.77s(data=1.6ms QKV=2.13s FFN=3.04s) eta=05:50:27 | 43.0K token/s | 
[epoch_0]_49171  loss=3.068077 |g|=0.496	lr=6.07e-05 | 28.1%@S41  T=1.81s(data=1.6ms QKV=2.12s FFN=3.04s) eta=05:58:47 | 43.1K token/s | 
[epoch_0]_49181  loss=3.029112 |g|=0.522	lr=6.06e-05 | 28.9%@S41  T=1.80s(data=1.5ms QKV=2.13s FFN=3.04s) eta=05:55:37 | 43.2K token/s | 
[epoch_0]_49191  loss=3.030975 |g|=0.484	lr=6.05e-05 | 29.7%@S41  T=1.78s(data=2.0ms QKV=2.13s FFN=3.04s) eta=05:51:23 | 43.4K token/s | 
[Fuyou] head="5" update algorithm=4 t=12.31s
[eval] 
	 Loss@"edu_fineweb1B"=3.082(0.0019) nBranch=1 nToken=6.31M best=3.0836(244) E2T=0.118 T=36.7617(0)s x=0
	#3.08173±0.0973 tps=172K(6.30784M) a=[2.89831,3.36127] T=36.7617(sec)
[Section@49200] layer[0-8] tasks=19(nPassBack=0) last_loss=2.96388(0.0508699) N=(772,55776,55216 6494268)
[epoch_0]_49201  loss=3.145720 |g|=0.521	lr=6.04e-05 | 30.6%@S41  T=12.29s(data=2.1ms QKV=2.11s FFN=3.04s) eta=1d 16:24:08 | 41.6K token/s | 
[epoch_0]_49211  loss=3.105929 |g|=0.531	lr=6.04e-05 | 31.4%@S41  T=1.79s(data=1.6ms QKV=2.11s FFN=3.04s) eta=05:52:06 | 41.8K token/s | 
[epoch_0]_49221  loss=3.086487 |g|=0.513	lr=6.03e-05 | 32.2%@S41  T=1.78s(data=1.4ms QKV=2.11s FFN=3.04s) eta=05:51:05 | 42.0K token/s | 
[epoch_0]_49231  loss=2.982092 |g|=0.484	lr=6.02e-05 | 33.0%@S41  T=1.87s(data=1.7ms QKV=2.11s FFN=3.04s) eta=06:07:26 | 42.1K token/s | 
[epoch_0]_49241  loss=3.036959 |g|=0.523	lr=6.01e-05 | 33.8%@S41  T=1.77s(data=1.6ms QKV=2.11s FFN=3.04s) eta=05:48:37 | 42.3K token/s | 
[epoch_0]_49251  loss=2.965826 |g|=0.494	lr=6.00e-05 | 34.7%@S41  T=1.77s(data=1.6ms QKV=2.11s FFN=3.04s) eta=05:48:19 | 42.5K token/s | 
[epoch_0]_49261  loss=3.004551 |g|=0.498	lr=5.99e-05 | 35.5%@S41  T=1.78s(data=1.6ms QKV=2.11s FFN=3.04s) eta=05:48:20 | 42.7K token/s | 
[epoch_0]_49271  loss=3.050253 |g|=0.509	lr=5.98e-05 | 36.3%@S41  T=1.77s(data=1.6ms QKV=2.11s FFN=3.04s) eta=05:46:35 | 42.8K token/s | 
[epoch_0]_49281  loss=2.996535 |g|=0.493	lr=5.97e-05 | 37.1%@S41  T=1.78s(data=1.5ms QKV=2.11s FFN=3.04s) eta=05:48:00 | 43.0K token/s | 
[epoch_0]_49291  loss=3.005959 |g|=0.484	lr=5.96e-05 | 37.9%@S41  T=1.79s(data=1.8ms QKV=2.11s FFN=3.04s) eta=05:50:24 | 43.1K token/s | 
[Fuyou] head="0" update algorithm=4 t=10.75s
[Section@49300] layer[8-16] tasks=19(nPassBack=0) last_loss=2.96686(0.0457103) N=(772,55888,55328 6507468)
[epoch_0]_49301  loss=2.947408 |g|=0.488	lr=5.96e-05 | 38.7%@S41  T=4.65s(data=2.1ms QKV=2.12s FFN=3.03s) eta=15:09:09 | 41.9K token/s | 
[epoch_0]_49311  loss=3.038711 |g|=0.511	lr=5.95e-05 | 39.6%@S41  T=1.77s(data=1.9ms QKV=2.12s FFN=3.04s) eta=05:46:42 | 42.1K token/s | 
[epoch_0]_49321  loss=3.027221 |g|=0.483	lr=5.94e-05 | 40.4%@S41  T=1.80s(data=1.5ms QKV=2.12s FFN=3.04s) eta=05:52:15 | 42.2K token/s | 
[epoch_0]_49331  loss=3.090751 |g|=0.496	lr=5.93e-05 | 41.2%@S41  T=1.79s(data=2.1ms QKV=2.12s FFN=3.04s) eta=05:48:27 | 42.4K token/s | 
[epoch_0]_49341  loss=3.001216 |g|=0.494	lr=5.92e-05 | 42.0%@S41  T=1.78s(data=1.5ms QKV=2.12s FFN=3.04s) eta=05:47:53 | 42.6K token/s | 
[epoch_0]_49351  loss=3.127270 |g|=0.492	lr=5.91e-05 | 42.8%@S41  T=1.78s(data=1.6ms QKV=2.12s FFN=3.04s) eta=05:45:41 | 42.8K token/s | 
[epoch_0]_49361  loss=3.121233 |g|=0.479	lr=5.90e-05 | 43.7%@S41  T=1.77s(data=1.8ms QKV=2.12s FFN=3.04s) eta=05:43:49 | 43.0K token/s | 
[epoch_0]_49371  loss=3.061060 |g|=0.486	lr=5.89e-05 | 44.5%@S41  T=1.78s(data=1.5ms QKV=2.12s FFN=3.04s) eta=05:45:08 | 43.1K token/s | 
[epoch_0]_49381  loss=3.005190 |g|=0.499	lr=5.89e-05 | 45.3%@S41  T=1.78s(data=1.5ms QKV=2.12s FFN=3.04s) eta=05:45:09 | 43.3K token/s | 
[epoch_0]_49391  loss=3.018000 |g|=0.51	lr=5.88e-05 | 46.1%@S41  T=1.77s(data=2.0ms QKV=2.12s FFN=3.04s) eta=05:43:49 | 43.4K token/s | 
[Fuyou] head="1" update algorithm=4 t=11.09s
[eval] 
	 Loss@"edu_fineweb1B"=3.080(0.0016) nBranch=1 nToken=6.31M best=3.0817(245) E2T=0.109 T=36.7495(0)s x=0
	#3.08014±0.0973 tps=172K(6.30784M) a=[2.89638,3.35872] T=36.7495(sec)
[Section@49400] layer[16-24] tasks=19(nPassBack=0) last_loss=2.97149(0.109251) N=(772,56000,55440 6520668)
[epoch_0]_49401  loss=3.101119 |g|=0.498	lr=5.87e-05 | 46.9%@S41  T=12.46s(data=1.7ms QKV=2.11s FFN=3.04s) eta=1d 16:15:31 | 41.6K token/s | 
[epoch_0]_49411  loss=3.103992 |g|=0.5	lr=5.86e-05 | 47.8%@S41  T=1.78s(data=1.6ms QKV=2.11s FFN=3.04s) eta=05:44:38 | 41.8K token/s | 
[epoch_0]_49421  loss=3.050013 |g|=0.484	lr=5.85e-05 | 48.6%@S41  T=1.78s(data=1.6ms QKV=2.11s FFN=3.04s) eta=05:44:11 | 42.0K token/s | 
[epoch_0]_49431  loss=3.099183 |g|=0.486	lr=5.84e-05 | 49.4%@S41  T=1.78s(data=1.8ms QKV=2.12s FFN=3.04s) eta=05:44:29 | 42.2K token/s | 
[epoch_0]_49441  loss=3.051278 |g|=0.501	lr=5.83e-05 | 50.2%@S41  T=1.77s(data=1.8ms QKV=2.12s FFN=3.04s) eta=05:41:35 | 42.4K token/s | 
[epoch_0]_49451  loss=3.026004 |g|=0.503	lr=5.82e-05 | 51.0%@S41  T=1.79s(data=1.6ms QKV=2.12s FFN=3.04s) eta=05:46:00 | 42.6K token/s | 
[epoch_0]_49461  loss=2.991682 |g|=0.498	lr=5.82e-05 | 51.9%@S41  T=1.77s(data=1.6ms QKV=2.11s FFN=3.04s) eta=05:41:45 | 42.8K token/s | 
[epoch_0]_49471  loss=3.065223 |g|=0.501	lr=5.81e-05 | 52.7%@S41  T=1.78s(data=1.5ms QKV=2.12s FFN=3.04s) eta=05:43:46 | 42.9K token/s | 
[epoch_0]_49481  loss=2.999954 |g|=0.486	lr=5.80e-05 | 53.5%@S41  T=1.78s(data=1.6ms QKV=2.11s FFN=3.04s) eta=05:43:30 | 43.1K token/s | 
[epoch_0]_49491  loss=3.095251 |g|=0.492	lr=5.79e-05 | 54.3%@S41  T=1.77s(data=1.6ms QKV=2.11s FFN=3.04s) eta=05:41:14 | 43.2K token/s | 
[Fuyou] head="2" update algorithm=4 t=10.73s
[Section@49500] layer[24-32] tasks=19(nPassBack=0) last_loss=2.95535(0.0864456) N=(772,56112,55552 6533868)
[epoch_0]_49501  loss=3.095287 |g|=0.489	lr=5.78e-05 | 55.1%@S41  T=4.75s(data=1.6ms QKV=2.12s FFN=3.04s) eta=15:12:29 | 41.9K token/s | 
[epoch_0]_49511  loss=2.963420 |g|=0.494	lr=5.77e-05 | 56.0%@S41  T=1.78s(data=1.7ms QKV=2.12s FFN=3.04s) eta=05:41:15 | 42.1K token/s | 
[epoch_0]_49521  loss=3.051604 |g|=0.498	lr=5.76e-05 | 56.8%@S41  T=1.78s(data=1.7ms QKV=2.12s FFN=3.04s) eta=05:40:46 | 42.3K token/s | 
[epoch_0]_49531  loss=2.990522 |g|=0.482	lr=5.75e-05 | 57.6%@S41  T=1.77s(data=2.1ms QKV=2.12s FFN=3.04s) eta=05:39:58 | 42.5K token/s | 
[epoch_0]_49541  loss=2.942484 |g|=0.522	lr=5.75e-05 | 58.4%@S41  T=1.79s(data=1.7ms QKV=2.12s FFN=3.04s) eta=05:43:44 | 42.7K token/s | 
[epoch_0]_49551  loss=3.051626 |g|=0.499	lr=5.74e-05 | 59.2%@S41  T=1.79s(data=1.6ms QKV=2.12s FFN=3.04s) eta=05:43:10 | 42.8K token/s | 
[epoch_0]_49561  loss=3.007207 |g|=0.494	lr=5.73e-05 | 60.0%@S41  T=1.80s(data=1.5ms QKV=2.12s FFN=3.04s) eta=05:44:51 | 43.0K token/s | 
[epoch_0]_49571  loss=3.054055 |g|=0.49	lr=5.72e-05 | 60.9%@S41  T=1.79s(data=1.9ms QKV=2.12s FFN=3.04s) eta=05:42:50 | 43.1K token/s | 
[epoch_0]_49581  loss=2.960154 |g|=0.491	lr=5.71e-05 | 61.7%@S41  T=1.79s(data=1.6ms QKV=2.12s FFN=3.04s) eta=05:42:34 | 43.2K token/s | 
[epoch_0]_49591  loss=3.031507 |g|=0.475	lr=5.70e-05 | 62.5%@S41  T=1.78s(data=2.0ms QKV=2.12s FFN=3.04s) eta=05:39:45 | 43.4K token/s | 
[Fuyou] head="3" update algorithm=4 t=11.44s
[eval] 
	 Loss@"edu_fineweb1B"=3.078(0.0017) nBranch=1 nToken=6.31M best=3.0801(246) E2T=-0.0185 T=36.7471(0)s x=0
	#3.07842±0.0974 tps=172K(6.30784M) a=[2.89356,3.35854] T=36.7471(sec)
[Section@49600] layer[32-40] tasks=19(nPassBack=0) last_loss=3.0969(-0.0509515) N=(772,56224,55664 6547068)
[epoch_0]_49601  loss=3.085149 |g|=0.494	lr=5.69e-05 | 63.3%@S41  T=12.16s(data=2.1ms QKV=2.11s FFN=3.04s) eta=1d 14:36:49 | 41.5K token/s | 
[epoch_0]_49611  loss=3.033971 |g|=0.483	lr=5.68e-05 | 64.1%@S41  T=2.08s(data=1.7ms QKV=2.13s FFN=3.05s) eta=06:35:44 | 41.4K token/s | 
[epoch_0]_49621  loss=2.962274 |g|=0.479	lr=5.68e-05 | 65.0%@S41  T=1.81s(data=1.7ms QKV=2.12s FFN=3.04s) eta=05:44:43 | 41.6K token/s | 
[epoch_0]_49631  loss=3.119558 |g|=0.508	lr=5.67e-05 | 65.8%@S41  T=1.77s(data=1.7ms QKV=2.12s FFN=3.04s) eta=05:36:07 | 41.9K token/s | 
[epoch_0]_49641  loss=3.120955 |g|=0.506	lr=5.66e-05 | 66.6%@S41  T=1.78s(data=1.6ms QKV=2.12s FFN=3.04s) eta=05:38:07 | 42.1K token/s | 
[epoch_0]_49651  loss=2.988443 |g|=0.482	lr=5.65e-05 | 67.4%@S41  T=1.80s(data=1.6ms QKV=2.12s FFN=3.04s) eta=05:42:10 | 42.2K token/s | 
[epoch_0]_49661  loss=3.069735 |g|=0.49	lr=5.64e-05 | 68.2%@S41  T=1.79s(data=1.5ms QKV=2.12s FFN=3.04s) eta=05:38:56 | 42.4K token/s | 
[epoch_0]_49671  loss=2.986333 |g|=0.488	lr=5.63e-05 | 69.1%@S41  T=1.80s(data=1.8ms QKV=2.12s FFN=3.04s) eta=05:41:04 | 42.6K token/s | 
[epoch_0]_49681  loss=3.029365 |g|=0.499	lr=5.62e-05 | 69.9%@S41  T=1.80s(data=1.7ms QKV=2.12s FFN=3.04s) eta=05:40:18 | 42.7K token/s | 
[epoch_0]_49691  loss=3.097985 |g|=0.493	lr=5.62e-05 | 70.7%@S41  T=1.79s(data=1.7ms QKV=2.12s FFN=3.04s) eta=05:39:10 | 42.9K token/s | 
[Fuyou] head="4" update algorithm=4 t=12.51s
[Section@49700] layer[40-48] tasks=19(nPassBack=0) last_loss=3.04237(0.0308075) N=(772,56336,55776 6560268)
[epoch_0]_49701  loss=2.983705 |g|=0.488	lr=5.61e-05 | 71.5%@S41  T=4.23s(data=1.8ms QKV=2.12s FFN=3.04s) eta=13:18:37 | 41.7K token/s | 
[epoch_0]_49711  loss=3.055139 |g|=0.512	lr=5.60e-05 | 72.3%@S41  T=1.77s(data=1.7ms QKV=2.12s FFN=3.04s) eta=05:33:21 | 41.9K token/s | 
[epoch_0]_49721  loss=3.067210 |g|=0.487	lr=5.59e-05 | 73.2%@S41  T=1.79s(data=1.6ms QKV=2.12s FFN=3.04s) eta=05:37:41 | 42.1K token/s | 
[epoch_0]_49731  loss=3.059904 |g|=0.502	lr=5.58e-05 | 74.0%@S41  T=1.80s(data=1.7ms QKV=2.12s FFN=3.04s) eta=05:39:11 | 42.3K token/s | 
[epoch_0]_49741  loss=3.093251 |g|=0.494	lr=5.57e-05 | 74.8%@S41  T=1.80s(data=1.6ms QKV=2.12s FFN=3.04s) eta=05:37:57 | 42.4K token/s | 
[epoch_0]_49751  loss=3.028425 |g|=0.481	lr=5.56e-05 | 75.6%@S41  T=1.78s(data=1.6ms QKV=2.12s FFN=3.04s) eta=05:35:39 | 42.6K token/s | 
[epoch_0]_49761  loss=3.066035 |g|=0.52	lr=5.56e-05 | 76.4%@S41  T=1.77s(data=1.7ms QKV=2.12s FFN=3.04s) eta=05:31:40 | 42.8K token/s | 
[epoch_0]_49771  loss=3.005317 |g|=0.517	lr=5.55e-05 | 77.3%@S41  T=1.78s(data=1.8ms QKV=2.12s FFN=3.04s) eta=05:33:38 | 43.0K token/s | 
[epoch_0]_49781  loss=3.066746 |g|=0.49	lr=5.54e-05 | 78.1%@S41  T=1.78s(data=1.6ms QKV=2.12s FFN=3.04s) eta=05:34:17 | 43.1K token/s | 
[epoch_0]_49791  loss=3.047523 |g|=0.495	lr=5.53e-05 | 78.9%@S41  T=1.79s(data=1.6ms QKV=2.12s FFN=3.04s) eta=05:35:51 | 43.3K token/s | 
[Fuyou] head="5" update algorithm=4 t=11.68s
[eval] 
	 Loss@"edu_fineweb1B"=3.078(0.00083) nBranch=1 nToken=6.31M best=3.0784(247) E2T=0.0391 T=36.7482(0)s x=0
	#3.07759±0.0972 tps=172K(6.30784M) a=[2.89345,3.35409] T=36.7482(sec)
[Section@49800] layer[0-8] tasks=19(nPassBack=0) last_loss=3.03851(-0.0746298) N=(772,56448,55888 6573468)
[epoch_0]_49801  loss=3.003942 |g|=0.493	lr=5.52e-05 | 79.7%@S41  T=12.29s(data=1.8ms QKV=2.12s FFN=3.04s) eta=1d 14:20:49 | 41.4K token/s | 
[epoch_0]_49811  loss=3.053012 |g|=0.483	lr=5.51e-05 | 80.5%@S41  T=1.80s(data=1.8ms QKV=2.12s FFN=3.04s) eta=05:36:19 | 41.6K token/s | 
[epoch_0]_49821  loss=3.028530 |g|=0.502	lr=5.50e-05 | 81.3%@S41  T=1.79s(data=1.7ms QKV=2.12s FFN=3.04s) eta=05:34:35 | 41.8K token/s | 
[epoch_0]_49831  loss=3.007930 |g|=0.49	lr=5.50e-05 | 82.2%@S41  T=1.80s(data=1.6ms QKV=2.11s FFN=3.04s) eta=05:35:45 | 42.0K token/s | 
[epoch_0]_49841  loss=3.027982 |g|=0.471	lr=5.49e-05 | 83.0%@S41  T=1.78s(data=1.7ms QKV=2.11s FFN=3.04s) eta=05:31:22 | 42.2K token/s | 
[epoch_0]_49851  loss=2.980354 |g|=0.493	lr=5.48e-05 | 83.8%@S41  T=1.78s(data=1.5ms QKV=2.12s FFN=3.04s) eta=05:31:22 | 42.4K token/s | 
[epoch_0]_49861  loss=2.978942 |g|=0.509	lr=5.47e-05 | 84.6%@S41  T=1.77s(data=1.6ms QKV=2.12s FFN=3.04s) eta=05:30:14 | 42.6K token/s | 
[epoch_0]_49871  loss=3.054249 |g|=0.486	lr=5.46e-05 | 85.4%@S41  T=1.79s(data=1.7ms QKV=2.12s FFN=3.04s) eta=05:33:14 | 42.8K token/s | 
[epoch_0]_49881  loss=3.086643 |g|=0.487	lr=5.45e-05 | 86.3%@S41  T=1.80s(data=2.0ms QKV=2.12s FFN=3.04s) eta=05:33:51 | 42.9K token/s | 
[epoch_0]_49891  loss=3.022740 |g|=0.484	lr=5.45e-05 | 87.1%@S41  T=1.79s(data=1.6ms QKV=2.12s FFN=3.04s) eta=05:33:18 | 43.0K token/s | 
[Fuyou] head="0" update algorithm=4 t=11.45s
[Section@49900] layer[8-16] tasks=19(nPassBack=0) last_loss=3.12388(-0.157026) N=(772,56560,56000 6586668)
[epoch_0]_49901  loss=2.979656 |g|=0.498	lr=5.44e-05 | 87.9%@S41  T=4.74s(data=1.9ms QKV=2.12s FFN=3.03s) eta=14:39:01 | 41.8K token/s | 
[epoch_0]_49911  loss=2.995572 |g|=0.49	lr=5.43e-05 | 88.7%@S41  T=1.76s(data=1.9ms QKV=2.13s FFN=3.04s) eta=05:25:51 | 42.0K token/s | 
[epoch_0]_49921  loss=3.114946 |g|=0.494	lr=5.42e-05 | 89.5%@S41  T=1.78s(data=2.0ms QKV=2.12s FFN=3.04s) eta=05:29:55 | 42.2K token/s | 
[epoch_0]_49931  loss=2.982796 |g|=0.505	lr=5.41e-05 | 90.4%@S41  T=1.79s(data=1.7ms QKV=2.13s FFN=3.04s) eta=05:30:36 | 42.4K token/s | 
[epoch_0]_49941  loss=2.897357 |g|=0.509	lr=5.40e-05 | 91.2%@S41  T=1.79s(data=1.6ms QKV=2.13s FFN=3.04s) eta=05:31:32 | 42.5K token/s | 
[epoch_0]_49951  loss=3.074322 |g|=0.487	lr=5.40e-05 | 92.0%@S41  T=1.81s(data=2.1ms QKV=2.13s FFN=3.04s) eta=05:34:10 | 42.7K token/s | 
[epoch_0]_49961  loss=3.041470 |g|=0.536	lr=5.39e-05 | 92.8%@S41  T=1.80s(data=1.7ms QKV=2.13s FFN=3.04s) eta=05:31:24 | 42.8K token/s | 
[epoch_0]_49971  loss=2.971769 |g|=0.534	lr=5.38e-05 | 93.6%@S41  T=1.80s(data=1.6ms QKV=2.13s FFN=3.04s) eta=05:31:47 | 43.0K token/s | 
[epoch_0]_49981  loss=2.981529 |g|=0.503	lr=5.37e-05 | 94.5%@S41  T=1.77s(data=1.9ms QKV=2.12s FFN=3.04s) eta=05:25:11 | 43.1K token/s | 
[epoch_0]_49991  loss=3.121533 |g|=0.513	lr=5.36e-05 | 95.3%@S41  T=1.81s(data=1.9ms QKV=2.13s FFN=3.04s) eta=05:34:00 | 43.2K token/s | 
[Fuyou] head="1" update algorithm=4 t=10.76s
[eval] 
	 Loss@"edu_fineweb1B"=3.077(0.0009) nBranch=1 nToken=6.31M best=3.0776(248) E2T=0.0566 T=36.7461(0)s x=0
	#3.07669±0.0978 tps=172K(6.30784M) a=[2.89317,3.35457] T=36.7461(sec)
[Section@50000] layer[16-24] tasks=19(nPassBack=0) last_loss=3.02007(-0.0485842) N=(772,56672,56112 6599868)
[epoch_0]_50001  loss=3.046058 |g|=0.487	lr=5.35e-05 | 96.1%@S41  T=12.50s(data=2.0ms QKV=2.12s FFN=3.04s) eta=1d 14:18:42 | 41.4K token/s | 
[epoch_0]_50011  loss=3.033299 |g|=0.485	lr=5.34e-05 | 96.9%@S41  T=1.85s(data=1.6ms QKV=2.12s FFN=3.04s) eta=05:40:20 | 41.5K token/s | 
[epoch_0]_50021  loss=3.001310 |g|=0.503	lr=5.34e-05 | 97.7%@S41  T=1.77s(data=1.9ms QKV=2.12s FFN=3.04s) eta=05:24:55 | 41.8K token/s | 
[epoch_0]_50031  loss=3.076259 |g|=0.479	lr=5.33e-05 | 98.6%@S41  T=1.81s(data=1.5ms QKV=2.12s FFN=3.04s) eta=05:32:20 | 42.0K token/s | 
[epoch_0]_50041  loss=3.022243 |g|=0.497	lr=5.32e-05 | 99.4%@S41  T=1.82s(data=1.9ms QKV=2.12s FFN=3.04s) eta=05:32:48 | 42.1K token/s | 
[epoch_0]_50048  loss=3.020984 |g|=0.519	lr=5.31e-05 | 99.9%@S41  T=1.79s(data=1.6ms QKV=2.12s FFN=3.04s) eta=05:27:09 | 42.3K token/s | 
-------- End of shard_41@"./Datasets/edu_fineweb1B/edu_fineweb_train_000799.bin"-------- 
[shard-42]@"./Datasets/edu_fineweb1B/edu_fineweb_train_000800.bin": tokens=100(M) nShardSamples=1220(4101552) 
[epoch_0]_50051  loss=3.012751 |g|=0.493	lr=5.31e-05 | 0.2%@S42  T=1.85s(data=1.3ms QKV=2.12s FFN=3.04s) eta=05:37:46 | 42.4K token/s | 
[epoch_0]_50061  loss=3.031918 |g|=0.507	lr=5.30e-05 | 1.0%@S42  T=1.78s(data=1.2ms QKV=2.12s FFN=3.04s) eta=05:26:14 | 42.6K token/s | 
[epoch_0]_50071  loss=3.050795 |g|=0.51	lr=5.29e-05 | 1.8%@S42  T=1.79s(data=1.4ms QKV=2.12s FFN=3.04s) eta=05:26:54 | 42.7K token/s | 
[epoch_0]_50081  loss=3.084023 |g|=0.497	lr=5.29e-05 | 2.6%@S42  T=1.81s(data=1.3ms QKV=2.12s FFN=3.04s) eta=05:29:57 | 42.9K token/s | 
[epoch_0]_50091  loss=3.073024 |g|=0.5	lr=5.28e-05 | 3.5%@S42  T=1.82s(data=1.7ms QKV=2.12s FFN=3.04s) eta=05:32:34 | 43.0K token/s | 
[Fuyou] head="2" update algorithm=4 t=10.48s
[Section@50100] layer[24-32] tasks=19(nPassBack=0) last_loss=2.99107(-0.0357213) N=(772,56784,56224 6613068)
[epoch_0]_50101  loss=2.983198 |g|=0.505	lr=5.27e-05 | 4.3%@S42  T=4.68s(data=1.9ms QKV=2.12s FFN=3.03s) eta=14:12:01 | 41.7K token/s | 
[epoch_0]_50111  loss=3.077706 |g|=0.508	lr=5.26e-05 | 5.1%@S42  T=1.78s(data=1.6ms QKV=2.12s FFN=3.04s) eta=05:24:01 | 41.9K token/s | 
[epoch_0]_50121  loss=2.996529 |g|=0.482	lr=5.25e-05 | 5.9%@S42  T=1.78s(data=1.7ms QKV=2.12s FFN=3.04s) eta=05:22:54 | 42.1K token/s | 
[epoch_0]_50131  loss=3.055593 |g|=0.489	lr=5.24e-05 | 6.7%@S42  T=1.77s(data=2.0ms QKV=2.13s FFN=3.04s) eta=05:21:06 | 42.3K token/s | 
[epoch_0]_50141  loss=3.025789 |g|=0.505	lr=5.24e-05 | 7.6%@S42  T=1.78s(data=1.6ms QKV=2.13s FFN=3.04s) eta=05:22:19 | 42.5K token/s | 
[epoch_0]_50151  loss=2.979990 |g|=0.482	lr=5.23e-05 | 8.4%@S42  T=1.81s(data=1.5ms QKV=2.13s FFN=3.04s) eta=05:28:56 | 42.7K token/s | 
[epoch_0]_50161  loss=3.041881 |g|=0.513	lr=5.22e-05 | 9.2%@S42  T=1.78s(data=1.4ms QKV=2.13s FFN=3.04s) eta=05:23:06 | 42.8K token/s | 
[epoch_0]_50171  loss=3.046421 |g|=0.491	lr=5.21e-05 | 10.0%@S42  T=1.79s(data=1.6ms QKV=2.13s FFN=3.04s) eta=05:24:49 | 43.0K token/s | 
[epoch_0]_50181  loss=2.935988 |g|=0.489	lr=5.20e-05 | 10.8%@S42  T=1.79s(data=1.4ms QKV=2.13s FFN=3.04s) eta=05:23:21 | 43.1K token/s | 
[epoch_0]_50191  loss=3.087739 |g|=0.487	lr=5.20e-05 | 11.7%@S42  T=1.76s(data=1.8ms QKV=2.13s FFN=3.04s) eta=05:18:37 | 43.3K token/s | 
[Fuyou] head="3" update algorithm=4 t=11.39s
[eval] 
	 Loss@"edu_fineweb1B"=3.075(0.0013) nBranch=1 nToken=6.31M best=3.0767(249) E2T=0.0325 T=36.7243(0)s x=0
	#3.07541±0.0974 tps=172K(6.30784M) a=[2.89093,3.35342] T=36.7243(sec)
[Section@50200] layer[32-40] tasks=19(nPassBack=0) last_loss=3.04287(0.0540287) N=(772,56896,56336 6626268)
[epoch_0]_50201  loss=3.080448 |g|=0.505	lr=5.19e-05 | 12.5%@S42  T=12.27s(data=1.9ms QKV=2.12s FFN=3.04s) eta=1d 12:56:04 | 41.4K token/s | 
[epoch_0]_50211  loss=3.002321 |g|=0.49	lr=5.18e-05 | 13.3%@S42  T=1.79s(data=1.7ms QKV=2.13s FFN=3.04s) eta=05:22:14 | 41.7K token/s | 
[epoch_0]_50221  loss=3.053090 |g|=0.492	lr=5.17e-05 | 14.1%@S42  T=1.77s(data=2.1ms QKV=2.12s FFN=3.04s) eta=05:18:54 | 41.9K token/s | 
[epoch_0]_50231  loss=3.125619 |g|=0.517	lr=5.16e-05 | 14.9%@S42  T=1.78s(data=1.4ms QKV=2.12s FFN=3.04s) eta=05:19:50 | 42.1K token/s | 
[epoch_0]_50241  loss=3.035083 |g|=0.503	lr=5.15e-05 | 15.8%@S42  T=1.79s(data=1.6ms QKV=2.12s FFN=3.04s) eta=05:21:33 | 42.3K token/s | 
[epoch_0]_50251  loss=3.015395 |g|=0.49	lr=5.15e-05 | 16.6%@S42  T=1.81s(data=1.5ms QKV=2.12s FFN=3.04s) eta=05:25:11 | 42.4K token/s | 
[epoch_0]_50261  loss=2.980816 |g|=0.505	lr=5.14e-05 | 17.4%@S42  T=1.79s(data=1.6ms QKV=2.12s FFN=3.04s) eta=05:22:02 | 42.6K token/s | 
[epoch_0]_50271  loss=3.061804 |g|=0.502	lr=5.13e-05 | 18.2%@S42  T=1.78s(data=1.7ms QKV=2.12s FFN=3.04s) eta=05:18:37 | 42.8K token/s | 
[epoch_0]_50281  loss=3.022237 |g|=0.469	lr=5.12e-05 | 19.0%@S42  T=1.76s(data=1.6ms QKV=2.12s FFN=3.04s) eta=05:15:59 | 43.0K token/s | 
[epoch_0]_50291  loss=3.059980 |g|=0.488	lr=5.11e-05 | 19.9%@S42  T=1.77s(data=1.6ms QKV=2.12s FFN=3.04s) eta=05:16:21 | 43.1K token/s | 
[Fuyou] head="4" update algorithm=4 t=12.32s
[Section@50300] layer[40-48] tasks=19(nPassBack=0) last_loss=2.99405(0.0483191) N=(772,57008,56448 6639468)
[epoch_0]_50301  loss=3.027963 |g|=0.473	lr=5.10e-05 | 20.7%@S42  T=4.25s(data=1.8ms QKV=2.12s FFN=3.03s) eta=12:41:07 | 41.9K token/s | 
[epoch_0]_50311  loss=2.998667 |g|=0.488	lr=5.10e-05 | 21.5%@S42  T=1.92s(data=1.7ms QKV=2.13s FFN=3.04s) eta=05:43:42 | 42.0K token/s | 
[epoch_0]_50321  loss=3.104601 |g|=0.515	lr=5.09e-05 | 22.3%@S42  T=1.76s(data=2.2ms QKV=2.13s FFN=3.04s) eta=05:14:49 | 42.2K token/s | 
[epoch_0]_50331  loss=3.001822 |g|=0.504	lr=5.08e-05 | 23.1%@S42  T=1.80s(data=1.7ms QKV=2.13s FFN=3.04s) eta=05:20:31 | 42.4K token/s | 
[epoch_0]_50341  loss=3.021427 |g|=0.491	lr=5.07e-05 | 23.9%@S42  T=1.79s(data=1.4ms QKV=2.13s FFN=3.04s) eta=05:18:32 | 42.5K token/s | 
[epoch_0]_50351  loss=3.021973 |g|=0.504	lr=5.06e-05 | 24.8%@S42  T=1.77s(data=1.6ms QKV=2.13s FFN=3.04s) eta=05:15:30 | 42.7K token/s | 
[epoch_0]_50361  loss=3.035290 |g|=0.501	lr=5.06e-05 | 25.6%@S42  T=1.78s(data=1.5ms QKV=2.13s FFN=3.04s) eta=05:15:48 | 42.9K token/s | 
[epoch_0]_50371  loss=2.985504 |g|=0.509	lr=5.05e-05 | 26.4%@S42  T=1.78s(data=1.5ms QKV=2.13s FFN=3.04s) eta=05:15:44 | 43.1K token/s | 
[epoch_0]_50381  loss=3.050380 |g|=0.499	lr=5.04e-05 | 27.2%@S42  T=1.81s(data=1.4ms QKV=2.13s FFN=3.04s) eta=05:21:47 | 43.2K token/s | 
[epoch_0]_50391  loss=3.053047 |g|=0.493	lr=5.03e-05 | 28.0%@S42  T=1.78s(data=1.7ms QKV=2.13s FFN=3.04s) eta=05:15:50 | 43.3K token/s | 
[Fuyou] head="5" update algorithm=4 t=11.57s
[eval] 
	 Loss@"edu_fineweb1B"=3.075(0.00041) nBranch=1 nToken=6.31M best=3.0754(250) E2T=0.0738 T=36.7656(0)s x=0
	#3.07501±0.0974 tps=172K(6.30784M) a=[2.88949,3.35194] T=36.7656(sec)
[Section@50400] layer[0-8] tasks=19(nPassBack=0) last_loss=3.00117(0.037344) N=(772,57120,56560 6652668)
[epoch_0]_50401  loss=3.017406 |g|=0.501	lr=5.02e-05 | 28.9%@S42  T=12.69s(data=1.7ms QKV=2.11s FFN=3.04s) eta=1d 13:28:27 | 41.5K token/s | 
[epoch_0]_50411  loss=2.989167 |g|=0.486	lr=5.02e-05 | 29.7%@S42  T=1.75s(data=1.7ms QKV=2.12s FFN=3.04s) eta=05:10:11 | 41.7K token/s | 
[epoch_0]_50421  loss=2.952447 |g|=0.486	lr=5.01e-05 | 30.5%@S42  T=1.76s(data=1.8ms QKV=2.12s FFN=3.04s) eta=05:11:52 | 42.0K token/s | 
[epoch_0]_50431  loss=3.005604 |g|=0.491	lr=5.00e-05 | 31.3%@S42  T=1.78s(data=2.0ms QKV=2.12s FFN=3.04s) eta=05:14:11 | 42.2K token/s | 
[epoch_0]_50441  loss=2.957994 |g|=0.488	lr=4.99e-05 | 32.1%@S42  T=1.76s(data=1.8ms QKV=2.12s FFN=3.04s) eta=05:10:08 | 42.4K token/s | 
[epoch_0]_50451  loss=3.057885 |g|=0.499	lr=4.98e-05 | 33.0%@S42  T=1.78s(data=1.8ms QKV=2.12s FFN=3.04s) eta=05:13:26 | 42.6K token/s | 
[epoch_0]_50461  loss=3.039456 |g|=0.489	lr=4.97e-05 | 33.8%@S42  T=1.81s(data=1.5ms QKV=2.12s FFN=3.04s) eta=05:18:17 | 42.7K token/s | 
[epoch_0]_50471  loss=3.093379 |g|=0.478	lr=4.97e-05 | 34.6%@S42  T=1.80s(data=1.5ms QKV=2.12s FFN=3.04s) eta=05:17:45 | 42.9K token/s | 
[epoch_0]_50481  loss=2.974635 |g|=0.509	lr=4.96e-05 | 35.4%@S42  T=1.82s(data=2.0ms QKV=2.12s FFN=3.04s) eta=05:19:52 | 43.0K token/s | 
[epoch_0]_50491  loss=2.912103 |g|=0.519	lr=4.95e-05 | 36.2%@S42  T=1.78s(data=1.9ms QKV=2.12s FFN=3.04s) eta=05:12:49 | 43.1K token/s | 
[Fuyou] head="0" update algorithm=4 t=11.71s
[Section@50500] layer[8-16] tasks=19(nPassBack=0) last_loss=2.87791(0.245975) N=(772,57232,56672 6665868)
[epoch_0]_50501  loss=3.014867 |g|=0.496	lr=4.94e-05 | 37.1%@S42  T=4.79s(data=1.8ms QKV=2.12s FFN=3.03s) eta=14:01:23 | 41.8K token/s | 
[epoch_0]_50511  loss=3.074091 |g|=0.491	lr=4.93e-05 | 37.9%@S42  T=1.78s(data=1.9ms QKV=2.12s FFN=3.04s) eta=05:11:33 | 42.0K token/s | 
[epoch_0]_50521  loss=2.963685 |g|=0.487	lr=4.93e-05 | 38.7%@S42  T=1.76s(data=1.7ms QKV=2.12s FFN=3.04s) eta=05:07:33 | 42.3K token/s | 
[epoch_0]_50531  loss=2.960859 |g|=0.487	lr=4.92e-05 | 39.5%@S42  T=1.79s(data=1.8ms QKV=2.13s FFN=3.04s) eta=05:13:01 | 42.4K token/s | 
[epoch_0]_50541  loss=3.026339 |g|=0.508	lr=4.91e-05 | 40.3%@S42  T=1.79s(data=1.8ms QKV=2.12s FFN=3.04s) eta=05:13:00 | 42.6K token/s | 
[epoch_0]_50551  loss=2.999426 |g|=0.479	lr=4.90e-05 | 41.1%@S42  T=1.76s(data=1.8ms QKV=2.12s FFN=3.04s) eta=05:08:16 | 42.8K token/s | 
[epoch_0]_50561  loss=3.082793 |g|=0.49	lr=4.89e-05 | 42.0%@S42  T=1.78s(data=1.5ms QKV=2.12s FFN=3.04s) eta=05:10:43 | 43.0K token/s | 
[epoch_0]_50571  loss=3.000407 |g|=0.494	lr=4.89e-05 | 42.8%@S42  T=1.81s(data=1.7ms QKV=2.12s FFN=3.04s) eta=05:15:30 | 43.1K token/s | 
[epoch_0]_50581  loss=2.969834 |g|=0.499	lr=4.88e-05 | 43.6%@S42  T=1.79s(data=1.8ms QKV=2.12s FFN=3.04s) eta=05:11:32 | 43.2K token/s | 
[epoch_0]_50591  loss=2.999699 |g|=0.515	lr=4.87e-05 | 44.4%@S42  T=1.79s(data=1.6ms QKV=2.12s FFN=3.04s) eta=05:11:48 | 43.3K token/s | 
[Fuyou] head="1" update algorithm=4 t=10.35s
[eval] 
	 Loss@"edu_fineweb1B"=3.074(0.0006) nBranch=1 nToken=6.31M best=3.0750(251) E2T=0.0262 T=36.7523(0)s x=0
	#3.07441±0.0975 tps=172K(6.30784M) a=[2.88838,3.35288] T=36.7523(sec)
[Section@50600] layer[16-24] tasks=19(nPassBack=0) last_loss=3.04821(-0.0281379) N=(772,57344,56784 6679068)
[epoch_0]_50601  loss=3.005529 |g|=0.488	lr=4.86e-05 | 45.2%@S42  T=12.28s(data=1.9ms QKV=2.11s FFN=3.04s) eta=1d 11:35:55 | 41.5K token/s | 
[epoch_0]_50611  loss=3.048266 |g|=0.542	lr=4.85e-05 | 46.1%@S42  T=1.81s(data=1.7ms QKV=2.11s FFN=3.04s) eta=05:14:15 | 41.7K token/s | 
[epoch_0]_50621  loss=2.982297 |g|=0.511	lr=4.85e-05 | 46.9%@S42  T=1.79s(data=1.7ms QKV=2.12s FFN=3.04s) eta=05:11:32 | 41.9K token/s | 
[epoch_0]_50631  loss=3.027345 |g|=0.498	lr=4.84e-05 | 47.7%@S42  T=1.79s(data=1.7ms QKV=2.12s FFN=3.04s) eta=05:10:56 | 42.1K token/s | 
[epoch_0]_50641  loss=3.038234 |g|=0.511	lr=4.83e-05 | 48.5%@S42  T=1.79s(data=1.8ms QKV=2.12s FFN=3.04s) eta=05:10:16 | 42.3K token/s | 
[epoch_0]_50651  loss=3.015949 |g|=0.471	lr=4.82e-05 | 49.3%@S42  T=1.79s(data=1.5ms QKV=2.12s FFN=3.04s) eta=05:10:35 | 42.4K token/s | 
[epoch_0]_50661  loss=2.990252 |g|=0.497	lr=4.81e-05 | 50.2%@S42  T=1.80s(data=1.5ms QKV=2.12s FFN=3.04s) eta=05:10:40 | 42.6K token/s | 
[epoch_0]_50671  loss=2.958850 |g|=0.491	lr=4.81e-05 | 51.0%@S42  T=1.78s(data=1.8ms QKV=2.12s FFN=3.04s) eta=05:07:45 | 42.8K token/s | 
[epoch_0]_50681  loss=2.987650 |g|=0.506	lr=4.80e-05 | 51.8%@S42  T=1.79s(data=1.6ms QKV=2.12s FFN=3.04s) eta=05:09:35 | 42.9K token/s | 
[epoch_0]_50691  loss=2.986362 |g|=0.487	lr=4.79e-05 | 52.6%@S42  T=1.81s(data=1.5ms QKV=2.12s FFN=3.04s) eta=05:12:38 | 43.0K token/s | 
[Fuyou] head="2" update algorithm=4 t=11.33s
[Section@50700] layer[24-32] tasks=19(nPassBack=0) last_loss=2.9789(0.0121675) N=(772,57456,56896 6692268)
[epoch_0]_50701  loss=3.001121 |g|=0.495	lr=4.78e-05 | 53.4%@S42  T=4.87s(data=2.1ms QKV=2.12s FFN=3.03s) eta=13:59:01 | 41.7K token/s | 
[epoch_0]_50711  loss=3.031238 |g|=0.489	lr=4.78e-05 | 54.3%@S42  T=1.77s(data=1.8ms QKV=2.12s FFN=3.04s) eta=05:04:52 | 41.9K token/s | 
[epoch_0]_50721  loss=3.067521 |g|=0.494	lr=4.77e-05 | 55.1%@S42  T=1.77s(data=1.7ms QKV=2.12s FFN=3.04s) eta=05:04:08 | 42.2K token/s | 
[epoch_0]_50731  loss=3.054870 |g|=0.503	lr=4.76e-05 | 55.9%@S42  T=1.77s(data=1.7ms QKV=2.12s FFN=3.04s) eta=05:04:23 | 42.4K token/s | 
[epoch_0]_50741  loss=3.070090 |g|=0.497	lr=4.75e-05 | 56.7%@S42  T=1.76s(data=1.8ms QKV=2.12s FFN=3.04s) eta=05:02:42 | 42.6K token/s | 
[epoch_0]_50751  loss=3.062642 |g|=0.481	lr=4.74e-05 | 57.5%@S42  T=1.80s(data=1.6ms QKV=2.12s FFN=3.04s) eta=05:08:48 | 42.7K token/s | 
[epoch_0]_50761  loss=2.978854 |g|=0.469	lr=4.74e-05 | 58.4%@S42  T=1.76s(data=1.9ms QKV=2.12s FFN=3.04s) eta=05:01:57 | 42.9K token/s | 
[epoch_0]_50771  loss=2.989432 |g|=0.488	lr=4.73e-05 | 59.2%@S42  T=1.79s(data=1.5ms QKV=2.12s FFN=3.04s) eta=05:05:21 | 43.0K token/s | 
[epoch_0]_50781  loss=2.981970 |g|=0.477	lr=4.72e-05 | 60.0%@S42  T=1.77s(data=1.8ms QKV=2.12s FFN=3.04s) eta=05:01:47 | 43.2K token/s | 
[epoch_0]_50791  loss=3.037731 |g|=0.488	lr=4.71e-05 | 60.8%@S42  T=1.77s(data=1.9ms QKV=2.12s FFN=3.04s) eta=05:02:39 | 43.4K token/s | 
[Fuyou] head="3" update algorithm=4 t=10.21s
[eval] 
	 Loss@"edu_fineweb1B"=3.073(0.00095) nBranch=1 nToken=6.31M best=3.0744(252) E2T=0.0191 T=36.7666(0)s x=0
	#3.07346±0.0974 tps=172K(6.30784M) a=[2.8866,3.35011] T=36.7666(sec)
[Section@50800] layer[32-40] tasks=19(nPassBack=0) last_loss=3.05433(-0.0114632) N=(772,57568,57008 6705468)
[epoch_0]_50801  loss=2.977059 |g|=0.494	lr=4.70e-05 | 61.6%@S42  T=11.93s(data=1.8ms QKV=2.11s FFN=3.04s) eta=1d 09:54:17 | 41.5K token/s | 
[epoch_0]_50811  loss=3.007651 |g|=0.484	lr=4.70e-05 | 62.4%@S42  T=1.79s(data=1.6ms QKV=2.11s FFN=3.04s) eta=05:04:24 | 41.8K token/s | 
[epoch_0]_50821  loss=3.061077 |g|=0.507	lr=4.69e-05 | 63.3%@S42  T=1.78s(data=1.6ms QKV=2.11s FFN=3.04s) eta=05:02:46 | 42.0K token/s | 
[epoch_0]_50831  loss=3.017390 |g|=0.509	lr=4.68e-05 | 64.1%@S42  T=1.78s(data=1.6ms QKV=2.11s FFN=3.04s) eta=05:03:02 | 42.2K token/s | 
[epoch_0]_50841  loss=2.971513 |g|=0.475	lr=4.67e-05 | 64.9%@S42  T=1.80s(data=1.6ms QKV=2.12s FFN=3.04s) eta=05:06:17 | 42.3K token/s | 
[epoch_0]_50851  loss=3.088015 |g|=0.488	lr=4.67e-05 | 65.7%@S42  T=1.77s(data=1.7ms QKV=2.12s FFN=3.04s) eta=05:00:57 | 42.5K token/s | 
[epoch_0]_50861  loss=2.988443 |g|=0.466	lr=4.66e-05 | 66.5%@S42  T=1.80s(data=1.6ms QKV=2.11s FFN=3.04s) eta=05:05:31 | 42.7K token/s | 
[epoch_0]_50871  loss=3.011229 |g|=0.507	lr=4.65e-05 | 67.4%@S42  T=1.82s(data=1.6ms QKV=2.11s FFN=3.04s) eta=05:07:46 | 42.8K token/s | 
[epoch_0]_50881  loss=3.048409 |g|=0.49	lr=4.64e-05 | 68.2%@S42  T=1.81s(data=1.6ms QKV=2.11s FFN=3.04s) eta=05:06:48 | 42.9K token/s | 
[epoch_0]_50891  loss=3.077202 |g|=0.495	lr=4.63e-05 | 69.0%@S42  T=1.81s(data=1.6ms QKV=2.12s FFN=3.04s) eta=05:06:32 | 43.0K token/s | 
[Fuyou] head="4" update algorithm=4 t=12.30s
[Section@50900] layer[40-48] tasks=19(nPassBack=0) last_loss=2.9937(0.000346422) N=(772,57680,57120 6718668)
[epoch_0]_50901  loss=3.040156 |g|=0.499	lr=4.63e-05 | 69.8%@S42  T=4.29s(data=2.0ms QKV=2.12s FFN=3.03s) eta=12:04:12 | 41.8K token/s | 
[epoch_0]_50911  loss=2.983416 |g|=0.485	lr=4.62e-05 | 70.6%@S42  T=1.79s(data=1.7ms QKV=2.12s FFN=3.04s) eta=05:02:12 | 42.0K token/s | 
[epoch_0]_50921  loss=3.043893 |g|=0.488	lr=4.61e-05 | 71.5%@S42  T=1.75s(data=1.5ms QKV=2.12s FFN=3.04s) eta=04:54:12 | 42.3K token/s | 
[epoch_0]_50931  loss=3.026343 |g|=0.486	lr=4.60e-05 | 72.3%@S42  T=1.76s(data=1.6ms QKV=2.12s FFN=3.04s) eta=04:56:15 | 42.5K token/s | 
[epoch_0]_50941  loss=2.991628 |g|=0.491	lr=4.60e-05 | 73.1%@S42  T=1.79s(data=1.5ms QKV=2.12s FFN=3.04s) eta=05:00:43 | 42.7K token/s | 
[epoch_0]_50951  loss=2.971339 |g|=0.509	lr=4.59e-05 | 73.9%@S42  T=1.81s(data=2.1ms QKV=2.13s FFN=3.04s) eta=05:03:26 | 42.8K token/s | 
[epoch_0]_50961  loss=3.074865 |g|=0.492	lr=4.58e-05 | 74.7%@S42  T=1.78s(data=1.5ms QKV=2.12s FFN=3.04s) eta=04:58:46 | 43.0K token/s | 
[epoch_0]_50971  loss=3.012155 |g|=0.504	lr=4.57e-05 | 75.6%@S42  T=1.76s(data=1.6ms QKV=2.12s FFN=3.04s) eta=04:54:29 | 43.1K token/s | 
[epoch_0]_50981  loss=3.029011 |g|=0.514	lr=4.56e-05 | 76.4%@S42  T=1.78s(data=1.7ms QKV=2.12s FFN=3.04s) eta=04:58:33 | 43.3K token/s | 
[epoch_0]_50991  loss=2.974440 |g|=0.482	lr=4.56e-05 | 77.2%@S42  T=1.76s(data=1.6ms QKV=2.12s FFN=3.04s) eta=04:54:43 | 43.4K token/s | 
[Fuyou] head="5" update algorithm=4 t=11.06s
[eval] 
	 Loss@"edu_fineweb1B"=3.072(0.001) nBranch=1 nToken=6.31M best=3.0735(253) E2T=0.111 T=36.7643(0)s x=0
	#3.07244±0.0974 tps=172K(6.30784M) a=[2.88538,3.35004] T=36.7643(sec)
[Section@51000] layer[0-8] tasks=19(nPassBack=0) last_loss=2.96143(0.0397408) N=(772,57792,57232 6731868)
[epoch_0]_51001  loss=2.991175 |g|=0.51	lr=4.55e-05 | 78.0%@S42  T=12.19s(data=1.7ms QKV=2.12s FFN=3.04s) eta=1d 09:57:53 | 41.6K token/s | 
[epoch_0]_51011  loss=3.035177 |g|=0.516	lr=4.54e-05 | 78.8%@S42  T=1.80s(data=1.6ms QKV=2.12s FFN=3.04s) eta=04:59:56 | 41.8K token/s | 
[epoch_0]_51021  loss=2.986803 |g|=0.478	lr=4.53e-05 | 79.7%@S42  T=1.77s(data=1.7ms QKV=2.12s FFN=3.04s) eta=04:55:33 | 42.0K token/s | 
[epoch_0]_51031  loss=2.927900 |g|=0.508	lr=4.53e-05 | 80.5%@S42  T=1.77s(data=1.8ms QKV=2.12s FFN=3.04s) eta=04:54:51 | 42.2K token/s | 
[epoch_0]_51041  loss=3.035393 |g|=0.492	lr=4.52e-05 | 81.3%@S42  T=1.78s(data=1.6ms QKV=2.12s FFN=3.04s) eta=04:57:18 | 42.4K token/s | 
[epoch_0]_51051  loss=3.050268 |g|=0.511	lr=4.51e-05 | 82.1%@S42  T=1.77s(data=1.8ms QKV=2.12s FFN=3.04s) eta=04:54:35 | 42.6K token/s | 
[epoch_0]_51061  loss=3.051575 |g|=0.496	lr=4.50e-05 | 82.9%@S42  T=1.76s(data=1.6ms QKV=2.12s FFN=3.04s) eta=04:52:25 | 42.8K token/s | 
[epoch_0]_51071  loss=3.092236 |g|=0.51	lr=4.50e-05 | 83.7%@S42  T=1.76s(data=1.6ms QKV=2.12s FFN=3.04s) eta=04:53:03 | 43.0K token/s | 
[epoch_0]_51081  loss=3.061133 |g|=0.488	lr=4.49e-05 | 84.6%@S42  T=1.77s(data=1.6ms QKV=2.12s FFN=3.04s) eta=04:53:43 | 43.2K token/s | 
[epoch_0]_51091  loss=2.975921 |g|=0.486	lr=4.48e-05 | 85.4%@S42  T=1.75s(data=1.5ms QKV=2.12s FFN=3.04s) eta=04:50:32 | 43.3K token/s | 
[Fuyou] head="0" update algorithm=4 t=10.78s
[Section@51100] layer[8-16] tasks=19(nPassBack=0) last_loss=2.99446(-0.116558) N=(772,57904,57344 6745068)
[epoch_0]_51101  loss=2.978439 |g|=0.484	lr=4.47e-05 | 86.2%@S42  T=4.75s(data=2.0ms QKV=2.12s FFN=3.04s) eta=13:06:00 | 42.0K token/s | 
[epoch_0]_51111  loss=3.077986 |g|=0.507	lr=4.47e-05 | 87.0%@S42  T=1.76s(data=2.1ms QKV=2.12s FFN=3.04s) eta=04:51:38 | 42.3K token/s | 
[epoch_0]_51121  loss=2.924813 |g|=0.485	lr=4.46e-05 | 87.8%@S42  T=1.78s(data=1.9ms QKV=2.13s FFN=3.04s) eta=04:53:41 | 42.4K token/s | 
[epoch_0]_51131  loss=3.026380 |g|=0.509	lr=4.45e-05 | 88.7%@S42  T=1.81s(data=1.6ms QKV=2.13s FFN=3.04s) eta=04:58:26 | 42.6K token/s | 
[epoch_0]_51141  loss=3.042508 |g|=0.489	lr=4.44e-05 | 89.5%@S42  T=1.79s(data=1.6ms QKV=2.12s FFN=3.04s) eta=04:54:32 | 42.8K token/s | 
[epoch_0]_51151  loss=3.042256 |g|=0.498	lr=4.43e-05 | 90.3%@S42  T=1.77s(data=1.8ms QKV=2.13s FFN=3.04s) eta=04:51:05 | 42.9K token/s | 
[epoch_0]_51161  loss=3.028746 |g|=0.478	lr=4.43e-05 | 91.1%@S42  T=1.77s(data=1.6ms QKV=2.13s FFN=3.04s) eta=04:50:42 | 43.1K token/s | 
[epoch_0]_51171  loss=3.054250 |g|=0.492	lr=4.42e-05 | 91.9%@S42  T=1.77s(data=1.5ms QKV=2.12s FFN=3.04s) eta=04:51:07 | 43.3K token/s | 
[epoch_0]_51181  loss=3.027226 |g|=0.493	lr=4.41e-05 | 92.8%@S42  T=1.78s(data=1.9ms QKV=2.13s FFN=3.04s) eta=04:52:11 | 43.4K token/s | 
[epoch_0]_51191  loss=3.024266 |g|=0.484	lr=4.40e-05 | 93.6%@S42  T=1.79s(data=1.8ms QKV=2.13s FFN=3.04s) eta=04:53:08 | 43.5K token/s | 
[Fuyou] head="1" update algorithm=4 t=10.99s
[eval] 
	 Loss@"edu_fineweb1B"=3.071(0.00096) nBranch=1 nToken=6.31M best=3.0724(254) E2T=0.00529 T=36.7477(0)s x=0
	#3.07148±0.0978 tps=172K(6.30784M) a=[2.88503,3.35193] T=36.7477(sec)
[Section@51200] layer[16-24] tasks=19(nPassBack=0) last_loss=3.06619(-0.0179815) N=(772,58016,57456 6758268)
[epoch_0]_51201  loss=3.019971 |g|=0.491	lr=4.40e-05 | 94.4%@S42  T=12.51s(data=2.4ms QKV=2.12s FFN=3.04s) eta=1d 10:10:51 | 41.7K token/s | 
[epoch_0]_51211  loss=3.113667 |g|=0.492	lr=4.39e-05 | 95.2%@S42  T=1.76s(data=1.6ms QKV=2.12s FFN=3.04s) eta=04:48:47 | 41.9K token/s | 
[epoch_0]_51221  loss=3.034402 |g|=0.501	lr=4.38e-05 | 96.0%@S42  T=1.75s(data=1.6ms QKV=2.12s FFN=3.04s) eta=04:46:34 | 42.2K token/s | 
[epoch_0]_51231  loss=3.018453 |g|=0.486	lr=4.37e-05 | 96.9%@S42  T=1.79s(data=2.1ms QKV=2.12s FFN=3.04s) eta=04:52:21 | 42.3K token/s | 
[epoch_0]_51241  loss=3.047886 |g|=0.511	lr=4.37e-05 | 97.7%@S42  T=1.78s(data=1.8ms QKV=2.12s FFN=3.04s) eta=04:50:08 | 42.5K token/s | 
[epoch_0]_51251  loss=3.026937 |g|=0.496	lr=4.36e-05 | 98.5%@S42  T=1.81s(data=1.6ms QKV=2.13s FFN=3.04s) eta=04:55:39 | 42.7K token/s | 
[epoch_0]_51261  loss=3.019994 |g|=0.496	lr=4.35e-05 | 99.3%@S42  T=1.77s(data=1.5ms QKV=2.12s FFN=3.04s) eta=04:48:33 | 42.8K token/s | 
[epoch_0]_51269  loss=3.123846 |g|=0.49	lr=4.35e-05 | 100.0%@S42  T=1.80s(data=1.7ms QKV=2.13s FFN=3.04s) eta=04:52:45 | 43.0K token/s | 
-------- End of shard_42@"./Datasets/edu_fineweb1B/edu_fineweb_train_000800.bin"-------- 
[shard-43]@"./Datasets/edu_fineweb1B/edu_fineweb_train_000801.bin": tokens=100(M) nShardSamples=1220(4199208) 
[epoch_0]_51271  loss=3.085519 |g|=0.531	lr=4.34e-05 | 0.1%@S43  T=2.01s(data=1.4ms QKV=2.12s FFN=3.04s) eta=05:26:21 | 42.9K token/s | 
[epoch_0]_51281  loss=3.057730 |g|=0.497	lr=4.34e-05 | 1.0%@S43  T=1.75s(data=1.6ms QKV=2.12s FFN=3.04s) eta=04:45:05 | 43.1K token/s | 
[epoch_0]_51291  loss=3.057541 |g|=0.502	lr=4.33e-05 | 1.8%@S43  T=1.75s(data=1.2ms QKV=2.12s FFN=3.04s) eta=04:43:51 | 43.2K token/s | 
[Fuyou] head="2" update algorithm=4 t=10.39s
[Section@51300] layer[24-32] tasks=19(nPassBack=0) last_loss=3.12065(-0.141749) N=(772,58128,57568 6771468)
[epoch_0]_51301  loss=3.057760 |g|=0.506	lr=4.32e-05 | 2.6%@S43  T=4.69s(data=1.5ms QKV=2.12s FFN=3.04s) eta=12:40:25 | 42.0K token/s | 
[epoch_0]_51311  loss=2.980982 |g|=0.486	lr=4.31e-05 | 3.4%@S43  T=1.74s(data=1.3ms QKV=2.12s FFN=3.04s) eta=04:42:27 | 42.2K token/s | 
[epoch_0]_51321  loss=3.116014 |g|=0.514	lr=4.31e-05 | 4.2%@S43  T=1.75s(data=1.3ms QKV=2.12s FFN=3.04s) eta=04:43:59 | 42.4K token/s | 
[epoch_0]_51331  loss=3.000405 |g|=0.493	lr=4.30e-05 | 5.0%@S43  T=1.76s(data=1.3ms QKV=2.12s FFN=3.04s) eta=04:45:06 | 42.6K token/s | 
[epoch_0]_51341  loss=3.007639 |g|=0.495	lr=4.29e-05 | 5.9%@S43  T=1.85s(data=1.4ms QKV=2.12s FFN=3.04s) eta=04:58:47 | 42.7K token/s | 
[epoch_0]_51351  loss=3.122516 |g|=0.489	lr=4.28e-05 | 6.7%@S43  T=1.78s(data=1.6ms QKV=2.12s FFN=3.04s) eta=04:47:32 | 42.9K token/s | 
[epoch_0]_51361  loss=3.126981 |g|=0.511	lr=4.28e-05 | 7.5%@S43  T=1.76s(data=1.6ms QKV=2.12s FFN=3.04s) eta=04:44:04 | 43.1K token/s | 
[epoch_0]_51371  loss=3.093769 |g|=0.499	lr=4.27e-05 | 8.3%@S43  T=1.76s(data=1.4ms QKV=2.12s FFN=3.04s) eta=04:43:55 | 43.2K token/s | 
[epoch_0]_51381  loss=3.056606 |g|=0.494	lr=4.26e-05 | 9.1%@S43  T=1.76s(data=1.4ms QKV=2.12s FFN=3.04s) eta=04:43:06 | 43.4K token/s | 
[epoch_0]_51391  loss=2.978450 |g|=0.492	lr=4.25e-05 | 10.0%@S43  T=1.77s(data=1.4ms QKV=2.12s FFN=3.04s) eta=04:44:48 | 43.5K token/s | 
[Fuyou] head="3" update algorithm=4 t=11.79s
[eval] 
	 Loss@"edu_fineweb1B"=3.069(0.0026) nBranch=1 nToken=6.31M best=3.0715(255) E2T=0.029 T=36.7695(0)s x=0
	#3.06887±0.0976 tps=172K(6.30784M) a=[2.88137,3.34916] T=36.7695(sec)
[Section@51400] layer[32-40] tasks=19(nPassBack=0) last_loss=3.0399(0.0144365) N=(772,58240,57680 6784668)
[epoch_0]_51401  loss=3.087517 |g|=0.514	lr=4.25e-05 | 10.8%@S43  T=12.00s(data=1.8ms QKV=2.11s FFN=3.04s) eta=1d 08:06:18 | 41.7K token/s | 
[epoch_0]_51411  loss=3.027831 |g|=0.497	lr=4.24e-05 | 11.6%@S43  T=1.75s(data=1.7ms QKV=2.12s FFN=3.04s) eta=04:40:56 | 42.0K token/s | 
[epoch_0]_51421  loss=3.056085 |g|=0.493	lr=4.23e-05 | 12.4%@S43  T=1.76s(data=3.2ms QKV=2.12s FFN=3.04s) eta=04:42:38 | 42.2K token/s | 
[epoch_0]_51431  loss=2.980625 |g|=0.505	lr=4.23e-05 | 13.2%@S43  T=1.77s(data=1.6ms QKV=2.12s FFN=3.04s) eta=04:42:47 | 42.4K token/s | 
[epoch_0]_51441  loss=3.115537 |g|=0.508	lr=4.22e-05 | 14.1%@S43  T=1.77s(data=1.6ms QKV=2.12s FFN=3.04s) eta=04:42:30 | 42.6K token/s | 
[epoch_0]_51451  loss=3.070156 |g|=0.516	lr=4.21e-05 | 14.9%@S43  T=1.76s(data=1.4ms QKV=2.12s FFN=3.04s) eta=04:40:41 | 42.8K token/s | 
[epoch_0]_51461  loss=3.057197 |g|=0.491	lr=4.20e-05 | 15.7%@S43  T=1.80s(data=1.5ms QKV=2.12s FFN=3.04s) eta=04:46:32 | 42.9K token/s | 
[epoch_0]_51471  loss=3.052543 |g|=0.498	lr=4.20e-05 | 16.5%@S43  T=1.77s(data=1.5ms QKV=2.12s FFN=3.04s) eta=04:42:43 | 43.1K token/s | 
[epoch_0]_51481  loss=3.019585 |g|=0.504	lr=4.19e-05 | 17.3%@S43  T=1.75s(data=1.5ms QKV=2.12s FFN=3.04s) eta=04:39:25 | 43.3K token/s | 
[epoch_0]_51491  loss=2.999247 |g|=1.21	lr=4.18e-05 | 18.2%@S43  T=1.76s(data=1.6ms QKV=2.12s FFN=3.04s) eta=04:39:44 | 43.4K token/s | 
[Fuyou] head="4" update algorithm=4 t=12.03s
[Section@51500] layer[40-48] tasks=19(nPassBack=0) last_loss=3.01845(-0.0247438) N=(772,58352,57792 6797868)
[epoch_0]_51501  loss=3.075866 |g|=0.486	lr=4.17e-05 | 19.0%@S43  T=4.15s(data=1.7ms QKV=2.13s FFN=3.04s) eta=10:59:50 | 42.3K token/s | 
[epoch_0]_51511  loss=3.045623 |g|=0.492	lr=4.17e-05 | 19.8%@S43  T=1.76s(data=1.7ms QKV=2.12s FFN=3.04s) eta=04:39:16 | 42.5K token/s | 
[epoch_0]_51521  loss=3.034358 |g|=0.492	lr=4.16e-05 | 20.6%@S43  T=1.76s(data=1.7ms QKV=2.12s FFN=3.04s) eta=04:39:51 | 42.7K token/s | 
[epoch_0]_51531  loss=2.881719 |g|=0.491	lr=4.15e-05 | 21.4%@S43  T=1.75s(data=1.6ms QKV=2.12s FFN=3.04s) eta=04:36:28 | 42.9K token/s | 
[epoch_0]_51541  loss=3.055867 |g|=0.485	lr=4.14e-05 | 22.3%@S43  T=1.75s(data=1.5ms QKV=2.12s FFN=3.04s) eta=04:37:39 | 43.1K token/s | 
[epoch_0]_51551  loss=3.102842 |g|=0.488	lr=4.14e-05 | 23.1%@S43  T=1.76s(data=1.8ms QKV=2.12s FFN=3.04s) eta=04:38:30 | 43.2K token/s | 
[epoch_0]_51561  loss=3.012437 |g|=0.503	lr=4.13e-05 | 23.9%@S43  T=1.76s(data=1.4ms QKV=2.12s FFN=3.04s) eta=04:38:32 | 43.4K token/s | 
[epoch_0]_51571  loss=2.948969 |g|=0.478	lr=4.12e-05 | 24.7%@S43  T=1.76s(data=1.5ms QKV=2.12s FFN=3.04s) eta=04:37:30 | 43.6K token/s | 
[epoch_0]_51581  loss=3.042207 |g|=0.494	lr=4.11e-05 | 25.5%@S43  T=1.76s(data=1.5ms QKV=2.12s FFN=3.04s) eta=04:37:25 | 43.7K token/s | 
[epoch_0]_51591  loss=3.000372 |g|=0.513	lr=4.11e-05 | 26.3%@S43  T=1.76s(data=1.5ms QKV=2.12s FFN=3.04s) eta=04:37:46 | 43.8K token/s | 
[Fuyou] head="5" update algorithm=4 t=10.08s
[eval] 
	 Loss@"edu_fineweb1B"=3.068(0.0012) nBranch=1 nToken=6.31M best=3.0689(256) E2T=0.0911 T=36.7547(0)s x=0
	#3.0677±0.0977 tps=172K(6.30784M) a=[2.88076,3.34873] T=36.7547(sec)
[Section@51600] layer[0-8] tasks=19(nPassBack=0) last_loss=2.97661(-0.0151861) N=(772,58464,57904 6811068)
[epoch_0]_51601  loss=3.074097 |g|=0.51	lr=4.10e-05 | 27.2%@S43  T=12.28s(data=1.9ms QKV=2.11s FFN=3.04s) eta=1d 08:10:07 | 42.0K token/s | 
[epoch_0]_51611  loss=3.104543 |g|=0.501	lr=4.09e-05 | 28.0%@S43  T=1.76s(data=1.7ms QKV=2.12s FFN=3.04s) eta=04:35:42 | 42.2K token/s | 
[epoch_0]_51621  loss=3.020022 |g|=0.492	lr=4.09e-05 | 28.8%@S43  T=1.74s(data=1.5ms QKV=2.12s FFN=3.04s) eta=04:33:09 | 42.5K token/s | 
[epoch_0]_51631  loss=3.028701 |g|=0.497	lr=4.08e-05 | 29.6%@S43  T=1.75s(data=1.5ms QKV=2.12s FFN=3.04s) eta=04:34:25 | 42.7K token/s | 
[epoch_0]_51641  loss=2.969270 |g|=0.491	lr=4.07e-05 | 30.4%@S43  T=1.75s(data=1.5ms QKV=2.12s FFN=3.04s) eta=04:33:33 | 42.9K token/s | 
[epoch_0]_51651  loss=3.123627 |g|=0.49	lr=4.06e-05 | 31.3%@S43  T=1.76s(data=1.6ms QKV=2.12s FFN=3.04s) eta=04:34:36 | 43.1K token/s | 
[epoch_0]_51661  loss=3.070982 |g|=0.49	lr=4.06e-05 | 32.1%@S43  T=1.75s(data=1.6ms QKV=2.12s FFN=3.04s) eta=04:32:58 | 43.3K token/s | 
[epoch_0]_51671  loss=3.033284 |g|=0.496	lr=4.05e-05 | 32.9%@S43  T=1.74s(data=1.5ms QKV=2.12s FFN=3.04s) eta=04:30:47 | 43.5K token/s | 
[epoch_0]_51681  loss=3.056308 |g|=0.519	lr=4.04e-05 | 33.7%@S43  T=1.73s(data=1.5ms QKV=2.12s FFN=3.04s) eta=04:30:27 | 43.7K token/s | 
[epoch_0]_51691  loss=3.031612 |g|=0.481	lr=4.04e-05 | 34.5%@S43  T=1.75s(data=1.7ms QKV=2.12s FFN=3.04s) eta=04:31:49 | 43.8K token/s | 
[Fuyou] head="0" update algorithm=4 t=12.90s
[Section@51700] layer[8-16] tasks=19(nPassBack=0) last_loss=3.06088(-0.0664134) N=(772,58576,58016 6824268)
[epoch_0]_51701  loss=3.073000 |g|=0.511	lr=4.03e-05 | 35.4%@S43  T=4.76s(data=1.6ms QKV=2.12s FFN=3.03s) eta=12:21:00 | 42.5K token/s | 
[epoch_0]_51711  loss=3.034489 |g|=0.488	lr=4.02e-05 | 36.2%@S43  T=1.74s(data=1.7ms QKV=2.12s FFN=3.04s) eta=04:30:53 | 42.7K token/s | 
[epoch_0]_51721  loss=2.989334 |g|=0.514	lr=4.01e-05 | 37.0%@S43  T=1.78s(data=1.6ms QKV=2.12s FFN=3.04s) eta=04:36:24 | 42.9K token/s | 
[epoch_0]_51731  loss=3.006569 |g|=0.504	lr=4.01e-05 | 37.8%@S43  T=1.73s(data=1.7ms QKV=2.12s FFN=3.04s) eta=04:28:30 | 43.1K token/s | 
[epoch_0]_51741  loss=3.024590 |g|=0.49	lr=4.00e-05 | 38.6%@S43  T=1.74s(data=1.6ms QKV=2.12s FFN=3.04s) eta=04:28:45 | 43.3K token/s | 
[epoch_0]_51751  loss=2.953154 |g|=0.499	lr=3.99e-05 | 39.5%@S43  T=1.76s(data=1.4ms QKV=2.12s FFN=3.04s) eta=04:32:29 | 43.5K token/s | 
[epoch_0]_51761  loss=2.972658 |g|=0.478	lr=3.98e-05 | 40.3%@S43  T=1.76s(data=1.6ms QKV=2.12s FFN=3.04s) eta=04:31:43 | 43.6K token/s | 
[epoch_0]_51771  loss=2.986403 |g|=0.482	lr=3.98e-05 | 41.1%@S43  T=1.74s(data=1.7ms QKV=2.12s FFN=3.04s) eta=04:27:56 | 43.8K token/s | 
[epoch_0]_51781  loss=2.950232 |g|=0.506	lr=3.97e-05 | 41.9%@S43  T=1.76s(data=1.6ms QKV=2.12s FFN=3.04s) eta=04:31:09 | 43.9K token/s | 
[epoch_0]_51791  loss=2.976020 |g|=0.479	lr=3.96e-05 | 42.7%@S43  T=1.75s(data=1.4ms QKV=2.12s FFN=3.04s) eta=04:30:07 | 44.1K token/s | 
[Fuyou] head="1" update algorithm=4 t=11.01s
[eval] 
	 Loss@"edu_fineweb1B"=3.067(0.0011) nBranch=1 nToken=6.31M best=3.0677(257) E2T=-0.0144 T=36.7652(0)s x=0
	#3.06657±0.0978 tps=172K(6.30784M) a=[2.87917,3.34741] T=36.7652(sec)
[Section@51800] layer[16-24] tasks=19(nPassBack=0) last_loss=3.08095(-0.0147591) N=(772,58688,58128 6837468)
[epoch_0]_51801  loss=2.965059 |g|=0.513	lr=3.96e-05 | 43.5%@S43  T=12.33s(data=1.5ms QKV=2.11s FFN=3.04s) eta=1d 07:38:21 | 42.2K token/s | 
[epoch_0]_51811  loss=3.050204 |g|=0.486	lr=3.95e-05 | 44.4%@S43  T=1.74s(data=1.6ms QKV=2.12s FFN=3.04s) eta=04:27:25 | 42.5K token/s | 
[epoch_0]_51821  loss=3.072334 |g|=0.557	lr=3.94e-05 | 45.2%@S43  T=1.79s(data=1.6ms QKV=2.12s FFN=3.04s) eta=04:34:53 | 42.6K token/s | 
[epoch_0]_51831  loss=3.064987 |g|=0.522	lr=3.94e-05 | 46.0%@S43  T=1.74s(data=1.7ms QKV=2.12s FFN=3.04s) eta=04:26:17 | 42.8K token/s | 
[epoch_0]_51841  loss=3.067857 |g|=0.497	lr=3.93e-05 | 46.8%@S43  T=1.75s(data=1.6ms QKV=2.12s FFN=3.04s) eta=04:27:40 | 43.0K token/s | 
[epoch_0]_51851  loss=3.062004 |g|=0.496	lr=3.92e-05 | 47.6%@S43  T=1.75s(data=1.6ms QKV=2.12s FFN=3.04s) eta=04:28:34 | 43.2K token/s | 
[epoch_0]_51861  loss=3.033125 |g|=0.512	lr=3.91e-05 | 48.5%@S43  T=1.78s(data=1.7ms QKV=2.12s FFN=3.04s) eta=04:32:01 | 43.4K token/s | 
[epoch_0]_51871  loss=2.903613 |g|=0.493	lr=3.91e-05 | 49.3%@S43  T=1.74s(data=1.6ms QKV=2.12s FFN=3.04s) eta=04:26:30 | 43.5K token/s | 
[epoch_0]_51881  loss=3.011889 |g|=0.503	lr=3.90e-05 | 50.1%@S43  T=1.76s(data=1.6ms QKV=2.12s FFN=3.04s) eta=04:27:52 | 43.7K token/s | 
[epoch_0]_51891  loss=3.001272 |g|=0.48	lr=3.89e-05 | 50.9%@S43  T=1.76s(data=1.6ms QKV=2.12s FFN=3.04s) eta=04:28:30 | 43.8K token/s | 
[Fuyou] head="2" update algorithm=4 t=9.74s
[Section@51900] layer[24-32] tasks=19(nPassBack=0) last_loss=3.09284(0.027812) N=(772,58800,58240 6850668)
[epoch_0]_51901  loss=2.982969 |g|=0.502	lr=3.89e-05 | 51.7%@S43  T=4.69s(data=1.8ms QKV=2.12s FFN=3.04s) eta=11:54:02 | 42.5K token/s | 
[epoch_0]_51911  loss=3.016477 |g|=0.492	lr=3.88e-05 | 52.6%@S43  T=1.81s(data=1.7ms QKV=2.12s FFN=3.04s) eta=04:35:15 | 42.7K token/s | 
[epoch_0]_51921  loss=3.035019 |g|=0.484	lr=3.87e-05 | 53.4%@S43  T=1.76s(data=2.1ms QKV=2.13s FFN=3.04s) eta=04:27:34 | 42.9K token/s | 
[epoch_0]_51931  loss=3.047607 |g|=0.495	lr=3.86e-05 | 54.2%@S43  T=1.75s(data=1.5ms QKV=2.13s FFN=3.04s) eta=04:25:57 | 43.0K token/s | 
[epoch_0]_51941  loss=3.020865 |g|=0.498	lr=3.86e-05 | 55.0%@S43  T=1.79s(data=1.6ms QKV=2.13s FFN=3.04s) eta=04:31:13 | 43.2K token/s | 
[epoch_0]_51951  loss=3.011360 |g|=0.481	lr=3.85e-05 | 55.8%@S43  T=1.76s(data=1.6ms QKV=2.13s FFN=3.04s) eta=04:27:04 | 43.3K token/s | 
[epoch_0]_51961  loss=3.041550 |g|=0.485	lr=3.84e-05 | 56.7%@S43  T=1.77s(data=2.2ms QKV=2.13s FFN=3.04s) eta=04:28:10 | 43.5K token/s | 
[epoch_0]_51971  loss=3.035585 |g|=0.479	lr=3.84e-05 | 57.5%@S43  T=1.79s(data=2.3ms QKV=2.13s FFN=3.04s) eta=04:30:07 | 43.6K token/s | 
[epoch_0]_51981  loss=2.930424 |g|=0.502	lr=3.83e-05 | 58.3%@S43  T=1.75s(data=1.5ms QKV=2.13s FFN=3.04s) eta=04:23:39 | 43.8K token/s | 
[epoch_0]_51991  loss=3.047724 |g|=0.505	lr=3.82e-05 | 59.1%@S43  T=1.81s(data=1.5ms QKV=2.13s FFN=3.04s) eta=04:32:50 | 43.8K token/s | 
[Fuyou] head="3" update algorithm=4 t=11.33s
[eval] 
	 Loss@"edu_fineweb1B"=3.065(0.0018) nBranch=1 nToken=6.31M best=3.0666(258) E2T=0.0229 T=36.7549(0)s x=0
	#3.06473±0.0974 tps=172K(6.30784M) a=[2.87731,3.34674] T=36.7549(sec)
[Section@52000] layer[32-40] tasks=19(nPassBack=0) last_loss=3.04183(-0.00193572) N=(772,58912,58352 6863868)
[epoch_0]_52001  loss=3.002839 |g|=0.514	lr=3.82e-05 | 59.9%@S43  T=12.62s(data=2.2ms QKV=2.12s FFN=3.04s) eta=1d 07:40:05 | 42.0K token/s | 
[epoch_0]_52011  loss=3.055360 |g|=0.521	lr=3.81e-05 | 60.8%@S43  T=1.77s(data=1.6ms QKV=2.12s FFN=3.04s) eta=04:25:30 | 42.2K token/s | 
[epoch_0]_52021  loss=2.999948 |g|=0.501	lr=3.80e-05 | 61.6%@S43  T=1.74s(data=1.6ms QKV=2.12s FFN=3.04s) eta=04:20:56 | 42.4K token/s | 
[epoch_0]_52031  loss=3.092436 |g|=0.51	lr=3.79e-05 | 62.4%@S43  T=1.75s(data=1.6ms QKV=2.12s FFN=3.04s) eta=04:22:48 | 42.7K token/s | 
[epoch_0]_52041  loss=3.026914 |g|=0.492	lr=3.79e-05 | 63.2%@S43  T=1.76s(data=1.5ms QKV=2.12s FFN=3.04s) eta=04:24:10 | 42.9K token/s | 
[epoch_0]_52051  loss=3.044322 |g|=0.503	lr=3.78e-05 | 64.0%@S43  T=1.78s(data=1.5ms QKV=2.12s FFN=3.04s) eta=04:25:59 | 43.0K token/s | 
[epoch_0]_52061  loss=2.957877 |g|=0.51	lr=3.77e-05 | 64.8%@S43  T=1.74s(data=1.6ms QKV=2.12s FFN=3.04s) eta=04:20:16 | 43.2K token/s | 
[epoch_0]_52071  loss=3.019732 |g|=0.491	lr=3.77e-05 | 65.7%@S43  T=1.74s(data=1.5ms QKV=2.12s FFN=3.04s) eta=04:20:03 | 43.4K token/s | 
[epoch_0]_52081  loss=2.957690 |g|=0.49	lr=3.76e-05 | 66.5%@S43  T=1.79s(data=1.6ms QKV=2.12s FFN=3.04s) eta=04:26:48 | 43.5K token/s | 
[epoch_0]_52091  loss=2.940718 |g|=0.486	lr=3.75e-05 | 67.3%@S43  T=1.76s(data=1.5ms QKV=2.12s FFN=3.04s) eta=04:22:13 | 43.7K token/s | 
[Fuyou] head="4" update algorithm=4 t=10.57s
[Section@52100] layer[40-48] tasks=19(nPassBack=0) last_loss=3.05912(-0.0406749) N=(772,59024,58464 6877068)
[epoch_0]_52101  loss=3.036039 |g|=0.492	lr=3.75e-05 | 68.1%@S43  T=4.30s(data=1.9ms QKV=2.13s FFN=3.04s) eta=10:39:49 | 42.5K token/s | 
[epoch_0]_52111  loss=2.987479 |g|=0.517	lr=3.74e-05 | 68.9%@S43  T=1.76s(data=1.7ms QKV=2.12s FFN=3.04s) eta=04:21:31 | 42.7K token/s | 
[epoch_0]_52121  loss=3.072402 |g|=0.514	lr=3.73e-05 | 69.8%@S43  T=1.76s(data=1.6ms QKV=2.13s FFN=3.04s) eta=04:21:45 | 42.9K token/s | 
[epoch_0]_52131  loss=2.990103 |g|=0.489	lr=3.73e-05 | 70.6%@S43  T=1.75s(data=1.6ms QKV=2.12s FFN=3.04s) eta=04:19:00 | 43.1K token/s | 
[epoch_0]_52141  loss=2.958746 |g|=0.487	lr=3.72e-05 | 71.4%@S43  T=1.73s(data=1.6ms QKV=2.13s FFN=3.05s) eta=04:16:52 | 43.3K token/s | 
[epoch_0]_52151  loss=3.047480 |g|=0.504	lr=3.71e-05 | 72.2%@S43  T=1.76s(data=1.5ms QKV=2.13s FFN=3.04s) eta=04:20:24 | 43.4K token/s | 
[epoch_0]_52161  loss=3.038386 |g|=0.495	lr=3.70e-05 | 73.0%@S43  T=1.77s(data=1.7ms QKV=2.13s FFN=3.04s) eta=04:21:04 | 43.6K token/s | 
[epoch_0]_52171  loss=3.032415 |g|=0.504	lr=3.70e-05 | 73.9%@S43  T=1.77s(data=1.5ms QKV=2.13s FFN=3.04s) eta=04:20:54 | 43.7K token/s | 
[epoch_0]_52181  loss=3.110296 |g|=0.498	lr=3.69e-05 | 74.7%@S43  T=1.76s(data=1.7ms QKV=2.13s FFN=3.05s) eta=04:20:01 | 43.9K token/s | 
[epoch_0]_52191  loss=3.014149 |g|=0.482	lr=3.68e-05 | 75.5%@S43  T=1.75s(data=1.5ms QKV=2.13s FFN=3.04s) eta=04:17:57 | 44.0K token/s | 
[Fuyou] head="5" update algorithm=4 t=12.35s
[eval] 
	 Loss@"edu_fineweb1B"=3.064(0.00078) nBranch=1 nToken=6.31M best=3.0647(259) E2T=0.0192 T=36.7642(0)s x=0
	#3.06394±0.0976 tps=172K(6.30784M) a=[2.87723,3.34671] T=36.7642(sec)
[Section@52200] layer[0-8] tasks=19(nPassBack=0) last_loss=3.04477(-0.0681579) N=(772,59136,58576 6890268)
[epoch_0]_52201  loss=3.102428 |g|=0.509	lr=3.68e-05 | 76.3%@S43  T=12.46s(data=1.7ms QKV=2.12s FFN=3.04s) eta=1d 06:34:13 | 42.1K token/s | 
[epoch_0]_52211  loss=2.991242 |g|=0.474	lr=3.67e-05 | 77.1%@S43  T=1.77s(data=1.6ms QKV=2.12s FFN=3.04s) eta=04:20:06 | 42.3K token/s | 
[epoch_0]_52221  loss=2.988173 |g|=0.486	lr=3.66e-05 | 78.0%@S43  T=1.76s(data=2.0ms QKV=2.12s FFN=3.04s) eta=04:17:56 | 42.6K token/s | 
[epoch_0]_52231  loss=3.037651 |g|=0.494	lr=3.66e-05 | 78.8%@S43  T=1.75s(data=1.6ms QKV=2.12s FFN=3.04s) eta=04:16:34 | 42.8K token/s | 
[epoch_0]_52241  loss=2.975082 |g|=0.488	lr=3.65e-05 | 79.6%@S43  T=1.75s(data=1.6ms QKV=2.12s FFN=3.05s) eta=04:15:51 | 43.0K token/s | 
[epoch_0]_52251  loss=2.980984 |g|=0.49	lr=3.64e-05 | 80.4%@S43  T=1.77s(data=6.3ms QKV=2.13s FFN=3.05s) eta=04:19:34 | 43.1K token/s | 
[epoch_0]_52261  loss=3.029037 |g|=0.511	lr=3.64e-05 | 81.2%@S43  T=1.75s(data=1.5ms QKV=2.12s FFN=3.04s) eta=04:16:06 | 43.3K token/s | 
[epoch_0]_52271  loss=2.998363 |g|=0.486	lr=3.63e-05 | 82.1%@S43  T=1.76s(data=1.6ms QKV=2.12s FFN=3.04s) eta=04:16:24 | 43.5K token/s | 
[epoch_0]_52281  loss=3.065110 |g|=0.501	lr=3.62e-05 | 82.9%@S43  T=1.74s(data=1.6ms QKV=2.12s FFN=3.05s) eta=04:14:18 | 43.7K token/s | 
[epoch_0]_52291  loss=3.038165 |g|=0.484	lr=3.62e-05 | 83.7%@S43  T=1.76s(data=1.5ms QKV=2.12s FFN=3.05s) eta=04:16:51 | 43.8K token/s | 
[Fuyou] head="0" update algorithm=4 t=11.65s
[Section@52300] layer[8-16] tasks=19(nPassBack=0) last_loss=2.94171(0.119164) N=(772,59248,58688 6903468)
[epoch_0]_52301  loss=3.083807 |g|=0.517	lr=3.61e-05 | 84.5%@S43  T=4.76s(data=1.8ms QKV=2.13s FFN=3.04s) eta=11:33:19 | 42.5K token/s | 
[epoch_0]_52311  loss=2.978516 |g|=0.5	lr=3.60e-05 | 85.3%@S43  T=1.75s(data=1.6ms QKV=2.13s FFN=3.04s) eta=04:15:08 | 42.7K token/s | 
[epoch_0]_52321  loss=3.050734 |g|=0.492	lr=3.60e-05 | 86.1%@S43  T=1.76s(data=1.6ms QKV=2.13s FFN=3.05s) eta=04:16:05 | 42.9K token/s | 
[epoch_0]_52331  loss=2.993080 |g|=0.469	lr=3.59e-05 | 87.0%@S43  T=1.84s(data=2.0ms QKV=2.13s FFN=3.05s) eta=04:27:28 | 43.0K token/s | 
[epoch_0]_52341  loss=3.074921 |g|=0.497	lr=3.58e-05 | 87.8%@S43  T=1.81s(data=1.9ms QKV=2.13s FFN=3.05s) eta=04:22:41 | 43.1K token/s | 
[epoch_0]_52351  loss=2.938870 |g|=0.504	lr=3.58e-05 | 88.6%@S43  T=1.77s(data=1.6ms QKV=2.13s FFN=3.05s) eta=04:16:03 | 43.2K token/s | 
[epoch_0]_52361  loss=3.020103 |g|=0.523	lr=3.57e-05 | 89.4%@S43  T=1.75s(data=1.6ms QKV=2.13s FFN=3.05s) eta=04:13:40 | 43.4K token/s | 
[epoch_0]_52371  loss=2.979391 |g|=0.501	lr=3.56e-05 | 90.2%@S43  T=1.76s(data=1.6ms QKV=2.13s FFN=3.05s) eta=04:14:03 | 43.6K token/s | 
[epoch_0]_52381  loss=2.976251 |g|=0.498	lr=3.55e-05 | 91.1%@S43  T=1.75s(data=1.6ms QKV=2.13s FFN=3.05s) eta=04:12:46 | 43.7K token/s | 
[epoch_0]_52391  loss=3.027518 |g|=0.52	lr=3.55e-05 | 91.9%@S43  T=1.76s(data=1.5ms QKV=2.13s FFN=3.05s) eta=04:14:02 | 43.9K token/s | 
[Fuyou] head="1" update algorithm=4 t=9.92s
[eval] 
	 Loss@"edu_fineweb1B"=3.063(0.00093) nBranch=1 nToken=6.31M best=3.0639(260) E2T=0.0841 T=36.7747(0)s x=0
	#3.06301±0.0975 tps=172K(6.30784M) a=[2.87504,3.34493] T=36.7747(sec)
[Section@52400] layer[16-24] tasks=19(nPassBack=0) last_loss=2.9789(0.102048) N=(772,59360,58800 6916668)
[epoch_0]_52401  loss=2.913422 |g|=0.483	lr=3.54e-05 | 92.7%@S43  T=12.42s(data=6.7ms QKV=2.12s FFN=3.04s) eta=1d 05:46:53 | 42.0K token/s | 
[epoch_0]_52411  loss=3.100283 |g|=0.491	lr=3.53e-05 | 93.5%@S43  T=1.77s(data=1.9ms QKV=2.12s FFN=3.04s) eta=04:14:21 | 42.2K token/s | 
[epoch_0]_52421  loss=3.044302 |g|=0.485	lr=3.53e-05 | 94.3%@S43  T=1.77s(data=1.7ms QKV=2.12s FFN=3.04s) eta=04:13:54 | 42.4K token/s | 
[epoch_0]_52431  loss=3.114463 |g|=0.506	lr=3.52e-05 | 95.2%@S43  T=1.77s(data=1.6ms QKV=2.12s FFN=3.04s) eta=04:14:21 | 42.6K token/s | 
[epoch_0]_52441  loss=3.015511 |g|=0.48	lr=3.51e-05 | 96.0%@S43  T=1.76s(data=1.6ms QKV=2.12s FFN=3.04s) eta=04:11:41 | 42.8K token/s | 
[epoch_0]_52451  loss=3.007387 |g|=0.483	lr=3.51e-05 | 96.8%@S43  T=1.76s(data=1.6ms QKV=2.12s FFN=3.04s) eta=04:12:15 | 43.0K token/s | 
[epoch_0]_52461  loss=2.953609 |g|=0.493	lr=3.50e-05 | 97.6%@S43  T=1.76s(data=1.5ms QKV=2.12s FFN=3.04s) eta=04:11:44 | 43.2K token/s | 
[epoch_0]_52471  loss=3.047459 |g|=0.505	lr=3.49e-05 | 98.4%@S43  T=1.76s(data=1.5ms QKV=2.12s FFN=3.04s) eta=04:10:41 | 43.3K token/s | 
[epoch_0]_52481  loss=2.957837 |g|=0.486	lr=3.49e-05 | 99.3%@S43  T=1.75s(data=1.5ms QKV=2.12s FFN=3.04s) eta=04:09:20 | 43.5K token/s | 
[epoch_0]_52490  loss=3.009854 |g|=0.488	lr=3.48e-05 | 100.0%@S43  T=1.75s(data=1.5ms QKV=2.12s FFN=3.04s) eta=04:08:39 | 43.7K token/s | 
-------- End of shard_43@"./Datasets/edu_fineweb1B/edu_fineweb_train_000801.bin"-------- 
[shard-44]@"./Datasets/edu_fineweb1B/edu_fineweb_train_000802.bin": tokens=100(M) nShardSamples=1220(4296864) 
[epoch_0]_52491  loss=2.989480 |g|=0.493	lr=3.48e-05 | 0.1%@S44  T=2.48s(data=1.05s QKV=2.11s FFN=3.04s) eta=05:52:42 | 43.2K token/s | 
[Fuyou] head="2" update algorithm=4 t=11.42s
[Section@52500] layer[24-32] tasks=19(nPassBack=0) last_loss=2.98078(0.11206) N=(772,59472,58912 6929868)
[epoch_0]_52501  loss=2.963904 |g|=0.499	lr=3.47e-05 | 0.9%@S44  T=4.90s(data=1.7ms QKV=2.12s FFN=3.04s) eta=11:37:25 | 41.8K token/s | 
[epoch_0]_52511  loss=3.063208 |g|=0.493	lr=3.47e-05 | 1.7%@S44  T=1.74s(data=1.6ms QKV=2.12s FFN=3.04s) eta=04:07:09 | 42.1K token/s | 
[epoch_0]_52521  loss=3.036859 |g|=0.486	lr=3.46e-05 | 2.5%@S44  T=1.74s(data=1.6ms QKV=2.12s FFN=3.04s) eta=04:07:25 | 42.3K token/s | 
[epoch_0]_52531  loss=3.006222 |g|=0.502	lr=3.46e-05 | 3.4%@S44  T=1.77s(data=1.5ms QKV=2.13s FFN=3.04s) eta=04:11:04 | 42.5K token/s | 
[epoch_0]_52541  loss=3.055574 |g|=0.502	lr=3.45e-05 | 4.2%@S44  T=1.75s(data=1.6ms QKV=2.13s FFN=3.04s) eta=04:07:51 | 42.7K token/s | 
[epoch_0]_52551  loss=2.998279 |g|=0.504	lr=3.44e-05 | 5.0%@S44  T=1.76s(data=1.7ms QKV=2.13s FFN=3.04s) eta=04:08:55 | 42.9K token/s | 
[epoch_0]_52561  loss=3.009221 |g|=0.495	lr=3.44e-05 | 5.8%@S44  T=1.74s(data=1.6ms QKV=2.13s FFN=3.04s) eta=04:06:15 | 43.1K token/s | 
[epoch_0]_52571  loss=2.966767 |g|=0.517	lr=3.43e-05 | 6.6%@S44  T=1.77s(data=1.6ms QKV=2.13s FFN=3.04s) eta=04:09:32 | 43.3K token/s | 
[epoch_0]_52581  loss=2.973735 |g|=0.485	lr=3.42e-05 | 7.4%@S44  T=1.75s(data=1.5ms QKV=2.13s FFN=3.04s) eta=04:06:38 | 43.5K token/s | 
[epoch_0]_52591  loss=3.027801 |g|=0.504	lr=3.42e-05 | 8.3%@S44  T=1.81s(data=1.8ms QKV=2.13s FFN=3.04s) eta=04:14:24 | 43.6K token/s | 
[Fuyou] head="3" update algorithm=4 t=11.78s
[eval] 
	 Loss@"edu_fineweb1B"=3.062(0.001) nBranch=1 nToken=6.31M best=3.0630(261) E2T=0.0658 T=36.7402(0)s x=0
	#3.06199±0.0974 tps=172K(6.30784M) a=[2.87275,3.34195] T=36.7402(sec)
[Section@52600] layer[32-40] tasks=19(nPassBack=0) last_loss=2.99615(0.0456786) N=(772,59584,59024 6943068)
[epoch_0]_52601  loss=3.018284 |g|=0.529	lr=3.41e-05 | 9.1%@S44  T=11.95s(data=1.5ms QKV=2.12s FFN=3.04s) eta=1d 04:00:00 | 41.7K token/s | 
[epoch_0]_52611  loss=3.034093 |g|=0.495	lr=3.40e-05 | 9.9%@S44  T=1.74s(data=1.4ms QKV=2.12s FFN=3.04s) eta=04:03:37 | 42.0K token/s | 
[epoch_0]_52621  loss=3.035166 |g|=0.514	lr=3.40e-05 | 10.7%@S44  T=1.75s(data=1.4ms QKV=2.12s FFN=3.04s) eta=04:05:12 | 42.2K token/s | 
[epoch_0]_52631  loss=3.085614 |g|=0.491	lr=3.39e-05 | 11.5%@S44  T=1.76s(data=1.4ms QKV=2.12s FFN=3.04s) eta=04:07:04 | 42.5K token/s | 
[epoch_0]_52641  loss=2.861904 |g|=0.495	lr=3.38e-05 | 12.4%@S44  T=1.78s(data=1.8ms QKV=2.12s FFN=3.04s) eta=04:09:24 | 42.6K token/s | 
[epoch_0]_52651  loss=2.994512 |g|=0.491	lr=3.38e-05 | 13.2%@S44  T=1.77s(data=1.7ms QKV=2.12s FFN=3.04s) eta=04:07:54 | 42.8K token/s | 
[epoch_0]_52661  loss=3.064708 |g|=0.484	lr=3.37e-05 | 14.0%@S44  T=1.77s(data=1.7ms QKV=2.12s FFN=3.04s) eta=04:06:23 | 43.0K token/s | 
[epoch_0]_52671  loss=2.994131 |g|=0.503	lr=3.36e-05 | 14.8%@S44  T=1.78s(data=1.4ms QKV=2.12s FFN=3.04s) eta=04:07:37 | 43.1K token/s | 
[epoch_0]_52681  loss=2.998135 |g|=0.505	lr=3.36e-05 | 15.6%@S44  T=1.75s(data=1.5ms QKV=2.12s FFN=3.04s) eta=04:03:46 | 43.3K token/s | 
[epoch_0]_52691  loss=3.062021 |g|=0.495	lr=3.35e-05 | 16.5%@S44  T=1.76s(data=1.6ms QKV=2.12s FFN=3.04s) eta=04:04:54 | 43.5K token/s | 
[Fuyou] head="4" update algorithm=4 t=12.64s
[Section@52700] layer[40-48] tasks=19(nPassBack=0) last_loss=3.01533(0.0437965) N=(772,59696,59136 6956268)
[epoch_0]_52701  loss=3.009178 |g|=0.5	lr=3.34e-05 | 17.3%@S44  T=4.40s(data=2.1ms QKV=2.12s FFN=3.04s) eta=10:11:19 | 42.2K token/s | 
[epoch_0]_52711  loss=3.032038 |g|=0.521	lr=3.34e-05 | 18.1%@S44  T=1.77s(data=1.7ms QKV=2.13s FFN=3.04s) eta=04:06:13 | 42.4K token/s | 
[epoch_0]_52721  loss=3.007212 |g|=0.529	lr=3.33e-05 | 18.9%@S44  T=1.83s(data=1.7ms QKV=2.13s FFN=3.04s) eta=04:13:37 | 42.6K token/s | 
[epoch_0]_52731  loss=2.994953 |g|=0.49	lr=3.32e-05 | 19.7%@S44  T=1.77s(data=1.6ms QKV=2.13s FFN=3.04s) eta=04:04:37 | 42.7K token/s | 
[epoch_0]_52741  loss=3.028517 |g|=0.486	lr=3.32e-05 | 20.6%@S44  T=1.79s(data=1.6ms QKV=2.13s FFN=3.04s) eta=04:06:51 | 42.9K token/s | 
[epoch_0]_52751  loss=3.075334 |g|=0.507	lr=3.31e-05 | 21.4%@S44  T=1.87s(data=1.6ms QKV=2.13s FFN=3.04s) eta=04:17:53 | 42.9K token/s | 
[epoch_0]_52761  loss=3.066053 |g|=0.508	lr=3.31e-05 | 22.2%@S44  T=1.76s(data=1.5ms QKV=2.13s FFN=3.04s) eta=04:03:15 | 43.1K token/s | 
[epoch_0]_52771  loss=3.023754 |g|=0.509	lr=3.30e-05 | 23.0%@S44  T=1.75s(data=1.5ms QKV=2.13s FFN=3.04s) eta=04:00:46 | 43.3K token/s | 
[epoch_0]_52781  loss=3.022564 |g|=0.506	lr=3.29e-05 | 23.8%@S44  T=1.76s(data=1.5ms QKV=2.13s FFN=3.04s) eta=04:02:05 | 43.5K token/s | 
[epoch_0]_52791  loss=2.981766 |g|=0.51	lr=3.29e-05 | 24.7%@S44  T=1.76s(data=1.5ms QKV=2.13s FFN=3.04s) eta=04:01:53 | 43.6K token/s | 
[Fuyou] head="5" update algorithm=4 t=10.40s
[eval] 
	 Loss@"edu_fineweb1B"=3.061(0.00063) nBranch=1 nToken=6.31M best=3.0620(262) E2T=0.0132 T=36.7459(0)s x=0
	#3.06136±0.0975 tps=172K(6.30784M) a=[2.87162,3.34293] T=36.7459(sec)
[Section@52800] layer[0-8] tasks=19(nPassBack=0) last_loss=3.04816(-0.0033884) N=(772,59808,59248 6969468)
[epoch_0]_52801  loss=3.040473 |g|=0.512	lr=3.28e-05 | 25.5%@S44  T=12.40s(data=1.5ms QKV=2.12s FFN=3.04s) eta=1d 04:22:01 | 41.8K token/s | 
[epoch_0]_52811  loss=3.080289 |g|=0.497	lr=3.27e-05 | 26.3%@S44  T=1.77s(data=1.6ms QKV=2.12s FFN=3.04s) eta=04:02:41 | 42.0K token/s | 
[epoch_0]_52821  loss=3.033320 |g|=0.502	lr=3.27e-05 | 27.1%@S44  T=1.75s(data=1.7ms QKV=2.12s FFN=3.04s) eta=03:58:53 | 42.2K token/s | 
[epoch_0]_52831  loss=2.982832 |g|=0.5	lr=3.26e-05 | 27.9%@S44  T=1.76s(data=1.6ms QKV=2.12s FFN=3.04s) eta=04:00:43 | 42.5K token/s | 
[epoch_0]_52841  loss=3.043354 |g|=0.5	lr=3.25e-05 | 28.7%@S44  T=1.76s(data=1.4ms QKV=2.12s FFN=3.04s) eta=04:00:55 | 42.7K token/s | 
[epoch_0]_52851  loss=2.979679 |g|=0.514	lr=3.25e-05 | 29.6%@S44  T=1.77s(data=1.6ms QKV=2.12s FFN=3.04s) eta=04:01:04 | 42.8K token/s | 
[epoch_0]_52861  loss=3.101390 |g|=0.508	lr=3.24e-05 | 30.4%@S44  T=1.76s(data=1.4ms QKV=2.12s FFN=3.04s) eta=03:59:39 | 43.0K token/s | 
[epoch_0]_52871  loss=3.010196 |g|=0.503	lr=3.23e-05 | 31.2%@S44  T=1.77s(data=1.6ms QKV=2.12s FFN=3.04s) eta=04:00:51 | 43.2K token/s | 
[epoch_0]_52881  loss=3.004994 |g|=0.506	lr=3.23e-05 | 32.0%@S44  T=1.75s(data=1.4ms QKV=2.12s FFN=3.04s) eta=03:57:54 | 43.4K token/s | 
[epoch_0]_52891  loss=2.993598 |g|=0.492	lr=3.22e-05 | 32.8%@S44  T=1.76s(data=1.6ms QKV=2.12s FFN=3.04s) eta=03:59:30 | 43.5K token/s | 
[Fuyou] head="0" update algorithm=4 t=12.79s
[Section@52900] layer[8-16] tasks=19(nPassBack=0) last_loss=2.99312(-0.0514059) N=(772,59920,59360 6982668)
[epoch_0]_52901  loss=3.022906 |g|=0.502	lr=3.22e-05 | 33.7%@S44  T=4.83s(data=1.5ms QKV=2.12s FFN=3.04s) eta=10:54:28 | 42.2K token/s | 
[epoch_0]_52911  loss=2.965229 |g|=0.482	lr=3.21e-05 | 34.5%@S44  T=1.76s(data=1.7ms QKV=2.12s FFN=3.04s) eta=03:58:29 | 42.4K token/s | 
[epoch_0]_52921  loss=3.035313 |g|=0.493	lr=3.20e-05 | 35.3%@S44  T=1.75s(data=1.6ms QKV=2.12s FFN=3.04s) eta=03:56:15 | 42.6K token/s | 
[epoch_0]_52931  loss=2.889964 |g|=0.496	lr=3.20e-05 | 36.1%@S44  T=1.76s(data=1.6ms QKV=2.12s FFN=3.04s) eta=03:58:23 | 42.8K token/s | 
[epoch_0]_52941  loss=3.023584 |g|=0.485	lr=3.19e-05 | 36.9%@S44  T=1.76s(data=1.6ms QKV=2.12s FFN=3.04s) eta=03:57:21 | 43.0K token/s | 
[epoch_0]_52951  loss=3.007077 |g|=0.504	lr=3.18e-05 | 37.8%@S44  T=1.75s(data=1.5ms QKV=2.12s FFN=3.04s) eta=03:55:25 | 43.2K token/s | 
[epoch_0]_52961  loss=2.960462 |g|=0.49	lr=3.18e-05 | 38.6%@S44  T=1.75s(data=1.6ms QKV=2.13s FFN=3.04s) eta=03:55:36 | 43.4K token/s | 
[epoch_0]_52971  loss=2.988995 |g|=0.488	lr=3.17e-05 | 39.4%@S44  T=1.76s(data=1.5ms QKV=2.13s FFN=3.04s) eta=03:56:50 | 43.5K token/s | 
[epoch_0]_52981  loss=3.004288 |g|=0.485	lr=3.17e-05 | 40.2%@S44  T=1.75s(data=1.5ms QKV=2.13s FFN=3.04s) eta=03:54:24 | 43.7K token/s | 
[epoch_0]_52991  loss=3.056567 |g|=0.511	lr=3.16e-05 | 41.0%@S44  T=1.75s(data=1.6ms QKV=2.13s FFN=3.04s) eta=03:55:09 | 43.9K token/s | 
[Fuyou] head="1" update algorithm=4 t=11.32s
[eval] 
	 Loss@"edu_fineweb1B"=3.061(0.00054) nBranch=1 nToken=6.31M best=3.0614(263) E2T=0.053 T=36.7423(0)s x=0
	#3.06082±0.0975 tps=172K(6.30784M) a=[2.87173,3.34256] T=36.7423(sec)
[Section@53000] layer[16-24] tasks=19(nPassBack=0) last_loss=3.00777(-0.0288687) N=(772,60032,59472 6995868)
[epoch_0]_53001  loss=2.985929 |g|=0.5	lr=3.15e-05 | 41.9%@S44  T=12.47s(data=1.7ms QKV=2.11s FFN=3.04s) eta=1d 03:49:43 | 42.0K token/s | 
[epoch_0]_53011  loss=2.967096 |g|=0.51	lr=3.15e-05 | 42.7%@S44  T=1.78s(data=1.7ms QKV=2.12s FFN=3.04s) eta=03:58:03 | 42.2K token/s | 
[epoch_0]_53021  loss=3.000592 |g|=0.483	lr=3.14e-05 | 43.5%@S44  T=1.76s(data=1.7ms QKV=2.12s FFN=3.04s) eta=03:55:30 | 42.4K token/s | 
[epoch_0]_53031  loss=2.985780 |g|=0.494	lr=3.13e-05 | 44.3%@S44  T=1.77s(data=1.6ms QKV=2.12s FFN=3.04s) eta=03:56:42 | 42.6K token/s | 
[epoch_0]_53041  loss=2.962821 |g|=0.484	lr=3.13e-05 | 45.1%@S44  T=1.76s(data=1.8ms QKV=2.12s FFN=3.04s) eta=03:53:56 | 42.8K token/s | 
[epoch_0]_53051  loss=2.918777 |g|=0.506	lr=3.12e-05 | 46.0%@S44  T=1.76s(data=1.7ms QKV=2.12s FFN=3.04s) eta=03:54:43 | 43.0K token/s | 
[epoch_0]_53061  loss=3.007272 |g|=0.49	lr=3.12e-05 | 46.8%@S44  T=1.75s(data=1.6ms QKV=2.12s FFN=3.04s) eta=03:53:05 | 43.2K token/s | 
[epoch_0]_53071  loss=3.093791 |g|=0.523	lr=3.11e-05 | 47.6%@S44  T=1.75s(data=1.6ms QKV=2.12s FFN=3.04s) eta=03:52:11 | 43.4K token/s | 
[epoch_0]_53081  loss=2.988322 |g|=0.499	lr=3.10e-05 | 48.4%@S44  T=1.75s(data=1.6ms QKV=2.12s FFN=3.04s) eta=03:52:08 | 43.5K token/s | 
[epoch_0]_53091  loss=3.058899 |g|=0.508	lr=3.10e-05 | 49.2%@S44  T=1.80s(data=2.0ms QKV=2.12s FFN=3.04s) eta=03:58:20 | 43.6K token/s | 
[Fuyou] head="2" update algorithm=4 t=9.96s
[Section@53100] layer[24-32] tasks=19(nPassBack=0) last_loss=2.9558(0.0249767) N=(772,60144,59584 7009068)
[epoch_0]_53101  loss=3.045173 |g|=0.494	lr=3.09e-05 | 50.0%@S44  T=4.68s(data=1.5ms QKV=2.12s FFN=3.03s) eta=10:19:13 | 42.3K token/s | 
[epoch_0]_53111  loss=2.974236 |g|=0.495	lr=3.08e-05 | 50.9%@S44  T=1.76s(data=1.6ms QKV=2.12s FFN=3.04s) eta=03:52:40 | 42.5K token/s | 
[epoch_0]_53121  loss=3.015411 |g|=0.493	lr=3.08e-05 | 51.7%@S44  T=1.80s(data=1.6ms QKV=2.13s FFN=3.04s) eta=03:57:32 | 42.7K token/s | 
[epoch_0]_53131  loss=3.006960 |g|=0.487	lr=3.07e-05 | 52.5%@S44  T=1.78s(data=1.5ms QKV=2.13s FFN=3.04s) eta=03:54:55 | 42.8K token/s | 
[epoch_0]_53141  loss=3.008976 |g|=0.484	lr=3.07e-05 | 53.3%@S44  T=1.77s(data=1.7ms QKV=2.12s FFN=3.04s) eta=03:53:31 | 43.0K token/s | 
[epoch_0]_53151  loss=2.913354 |g|=0.516	lr=3.06e-05 | 54.1%@S44  T=1.75s(data=1.5ms QKV=2.13s FFN=3.04s) eta=03:50:00 | 43.2K token/s | 
[epoch_0]_53161  loss=3.043637 |g|=0.505	lr=3.05e-05 | 55.0%@S44  T=1.76s(data=1.6ms QKV=2.12s FFN=3.04s) eta=03:50:37 | 43.4K token/s | 
[epoch_0]_53171  loss=2.907092 |g|=0.503	lr=3.05e-05 | 55.8%@S44  T=1.76s(data=1.6ms QKV=2.13s FFN=3.04s) eta=03:51:11 | 43.5K token/s | 
[epoch_0]_53181  loss=3.104025 |g|=0.523	lr=3.04e-05 | 56.6%@S44  T=1.80s(data=1.7ms QKV=2.12s FFN=3.04s) eta=03:55:45 | 43.6K token/s | 
[epoch_0]_53191  loss=2.999553 |g|=0.499	lr=3.03e-05 | 57.4%@S44  T=1.77s(data=1.6ms QKV=2.13s FFN=3.04s) eta=03:50:48 | 43.8K token/s | 
[Fuyou] head="3" update algorithm=4 t=11.62s
[eval] 
	 Loss@"edu_fineweb1B"=3.060(0.0007) nBranch=1 nToken=6.31M best=3.0608(264) E2T=0.0809 T=36.7322(0)s x=0
	#3.06012±0.0974 tps=172K(6.30784M) a=[2.87334,3.34026] T=36.7322(sec)
[Section@53200] layer[32-40] tasks=19(nPassBack=0) last_loss=2.97925(0.0168996) N=(772,60256,59696 7022268)
[epoch_0]_53201  loss=2.911349 |g|=0.493	lr=3.03e-05 | 58.2%@S44  T=12.36s(data=2.0ms QKV=2.11s FFN=3.03s) eta=1d 02:54:15 | 41.9K token/s | 
[epoch_0]_53211  loss=2.982922 |g|=0.501	lr=3.02e-05 | 59.1%@S44  T=1.83s(data=1.6ms QKV=2.12s FFN=3.04s) eta=03:58:09 | 42.0K token/s | 
[epoch_0]_53221  loss=2.963714 |g|=0.509	lr=3.02e-05 | 59.9%@S44  T=1.80s(data=1.6ms QKV=2.12s FFN=3.04s) eta=03:53:59 | 42.2K token/s | 
[epoch_0]_53231  loss=2.963876 |g|=0.514	lr=3.01e-05 | 60.7%@S44  T=1.76s(data=1.6ms QKV=2.12s FFN=3.04s) eta=03:49:01 | 42.4K token/s | 
[epoch_0]_53241  loss=2.874307 |g|=0.524	lr=3.00e-05 | 61.5%@S44  T=1.75s(data=1.6ms QKV=2.12s FFN=3.04s) eta=03:47:34 | 42.7K token/s | 
[epoch_0]_53251  loss=3.049784 |g|=0.486	lr=3.00e-05 | 62.3%@S44  T=1.80s(data=1.6ms QKV=2.12s FFN=3.04s) eta=03:52:56 | 42.8K token/s | 
[epoch_0]_53261  loss=2.980976 |g|=0.489	lr=2.99e-05 | 63.2%@S44  T=1.77s(data=1.6ms QKV=2.12s FFN=3.04s) eta=03:48:46 | 43.0K token/s | 
[epoch_0]_53271  loss=2.974319 |g|=0.494	lr=2.99e-05 | 64.0%@S44  T=1.79s(data=1.7ms QKV=2.12s FFN=3.04s) eta=03:52:08 | 43.1K token/s | 
[epoch_0]_53281  loss=3.092581 |g|=0.494	lr=2.98e-05 | 64.8%@S44  T=1.76s(data=1.6ms QKV=2.12s FFN=3.04s) eta=03:47:47 | 43.3K token/s | 
[epoch_0]_53291  loss=2.918346 |g|=0.508	lr=2.97e-05 | 65.6%@S44  T=1.77s(data=1.8ms QKV=2.12s FFN=3.04s) eta=03:48:26 | 43.4K token/s | 
[Fuyou] head="4" update algorithm=4 t=11.05s
[Section@53300] layer[40-48] tasks=19(nPassBack=0) last_loss=3.08293(-0.0675995) N=(772,60368,59808 7035468)
[epoch_0]_53301  loss=3.074105 |g|=0.478	lr=2.97e-05 | 66.4%@S44  T=4.15s(data=3.6ms QKV=2.12s FFN=3.03s) eta=08:54:46 | 42.2K token/s | 
[epoch_0]_53311  loss=3.068736 |g|=0.482	lr=2.96e-05 | 67.2%@S44  T=1.76s(data=1.6ms QKV=2.12s FFN=3.04s) eta=03:46:04 | 42.5K token/s | 
[epoch_0]_53321  loss=3.048797 |g|=0.49	lr=2.96e-05 | 68.1%@S44  T=1.77s(data=1.6ms QKV=2.12s FFN=3.04s) eta=03:46:57 | 42.7K token/s | 
[epoch_0]_53331  loss=3.041734 |g|=0.495	lr=2.95e-05 | 68.9%@S44  T=1.78s(data=1.7ms QKV=2.13s FFN=3.04s) eta=03:48:31 | 42.8K token/s | 
[epoch_0]_53341  loss=3.061740 |g|=0.495	lr=2.94e-05 | 69.7%@S44  T=1.79s(data=1.5ms QKV=2.12s FFN=3.04s) eta=03:49:39 | 43.0K token/s | 
[epoch_0]_53351  loss=3.025697 |g|=0.495	lr=2.94e-05 | 70.5%@S44  T=1.83s(data=1.6ms QKV=2.12s FFN=3.04s) eta=03:54:03 | 43.1K token/s | 
[epoch_0]_53361  loss=2.983417 |g|=0.487	lr=2.93e-05 | 71.3%@S44  T=1.81s(data=1.7ms QKV=2.13s FFN=3.04s) eta=03:51:46 | 43.2K token/s | 
[epoch_0]_53371  loss=3.035063 |g|=0.496	lr=2.93e-05 | 72.2%@S44  T=1.77s(data=1.6ms QKV=2.12s FFN=3.04s) eta=03:45:49 | 43.3K token/s | 
[epoch_0]_53381  loss=2.977739 |g|=0.484	lr=2.92e-05 | 73.0%@S44  T=1.76s(data=1.7ms QKV=2.12s FFN=3.04s) eta=03:44:41 | 43.5K token/s | 
[epoch_0]_53391  loss=3.077116 |g|=0.486	lr=2.91e-05 | 73.8%@S44  T=1.76s(data=1.5ms QKV=2.13s FFN=3.04s) eta=03:43:54 | 43.7K token/s | 
[Fuyou] head="5" update algorithm=4 t=12.95s
[eval] 
	 Loss@"edu_fineweb1B"=3.060(0.00029) nBranch=1 nToken=6.31M best=3.0601(265) E2T=0.0348 T=36.7379(0)s x=0
	#3.05983±0.0974 tps=172K(6.30784M) a=[2.87266,3.3401] T=36.7379(sec)
[Section@53400] layer[0-8] tasks=19(nPassBack=0) last_loss=3.02508(0.0230749) N=(772,60480,59920 7048668)
[epoch_0]_53401  loss=2.965515 |g|=0.502	lr=2.91e-05 | 74.6%@S44  T=12.37s(data=1.8ms QKV=2.12s FFN=3.04s) eta=1d 02:13:24 | 41.8K token/s | 
[epoch_0]_53411  loss=2.891398 |g|=0.48	lr=2.90e-05 | 75.4%@S44  T=1.80s(data=1.7ms QKV=2.12s FFN=3.04s) eta=03:48:36 | 42.0K token/s | 
[epoch_0]_53421  loss=3.038460 |g|=0.502	lr=2.90e-05 | 76.3%@S44  T=1.77s(data=1.6ms QKV=2.12s FFN=3.04s) eta=03:44:42 | 42.2K token/s | 
[epoch_0]_53431  loss=2.998394 |g|=0.487	lr=2.89e-05 | 77.1%@S44  T=1.76s(data=1.6ms QKV=2.12s FFN=3.04s) eta=03:42:33 | 42.4K token/s | 
[epoch_0]_53441  loss=3.077175 |g|=0.5	lr=2.88e-05 | 77.9%@S44  T=1.77s(data=1.6ms QKV=2.12s FFN=3.04s) eta=03:44:08 | 42.6K token/s | 
[epoch_0]_53451  loss=2.989817 |g|=0.49	lr=2.88e-05 | 78.7%@S44  T=1.76s(data=1.5ms QKV=2.12s FFN=3.04s) eta=03:42:11 | 42.8K token/s | 
[epoch_0]_53461  loss=3.014760 |g|=0.502	lr=2.87e-05 | 79.5%@S44  T=1.77s(data=1.7ms QKV=2.12s FFN=3.04s) eta=03:43:35 | 43.0K token/s | 
[epoch_0]_53471  loss=2.961129 |g|=0.486	lr=2.87e-05 | 80.4%@S44  T=1.76s(data=1.5ms QKV=2.12s FFN=3.04s) eta=03:42:16 | 43.2K token/s | 
[epoch_0]_53481  loss=2.953475 |g|=0.476	lr=2.86e-05 | 81.2%@S44  T=1.77s(data=1.6ms QKV=2.12s FFN=3.04s) eta=03:42:49 | 43.3K token/s | 
[epoch_0]_53491  loss=2.986947 |g|=0.489	lr=2.85e-05 | 82.0%@S44  T=1.75s(data=1.5ms QKV=2.12s FFN=3.04s) eta=03:40:16 | 43.5K token/s | 
[Fuyou] head="0" update algorithm=4 t=10.36s
[Section@53500] layer[8-16] tasks=19(nPassBack=0) last_loss=2.97981(0.0133111) N=(772,60592,60032 7061868)
[epoch_0]_53501  loss=2.902481 |g|=0.487	lr=2.85e-05 | 82.8%@S44  T=4.84s(data=2.5ms QKV=2.12s FFN=3.03s) eta=10:08:04 | 42.2K token/s | 
[epoch_0]_53511  loss=3.038863 |g|=0.504	lr=2.84e-05 | 83.6%@S44  T=1.78s(data=2.0ms QKV=2.13s FFN=3.04s) eta=03:43:12 | 42.4K token/s | 
[epoch_0]_53521  loss=2.941917 |g|=0.486	lr=2.84e-05 | 84.5%@S44  T=1.75s(data=1.6ms QKV=2.13s FFN=3.04s) eta=03:39:10 | 42.6K token/s | 
[epoch_0]_53531  loss=2.997126 |g|=0.496	lr=2.83e-05 | 85.3%@S44  T=1.76s(data=1.7ms QKV=2.13s FFN=3.04s) eta=03:40:28 | 42.8K token/s | 
[epoch_0]_53541  loss=3.004935 |g|=0.493	lr=2.83e-05 | 86.1%@S44  T=1.77s(data=1.6ms QKV=2.13s FFN=3.04s) eta=03:40:33 | 43.0K token/s | 
[epoch_0]_53551  loss=3.035437 |g|=0.485	lr=2.82e-05 | 86.9%@S44  T=1.77s(data=1.5ms QKV=2.13s FFN=3.04s) eta=03:40:35 | 43.1K token/s | 
[epoch_0]_53561  loss=2.956858 |g|=0.483	lr=2.81e-05 | 87.7%@S44  T=1.84s(data=1.7ms QKV=2.13s FFN=3.04s) eta=03:48:59 | 43.2K token/s | 
[epoch_0]_53571  loss=3.043733 |g|=0.504	lr=2.81e-05 | 88.5%@S44  T=1.77s(data=1.6ms QKV=2.13s FFN=3.04s) eta=03:40:04 | 43.3K token/s | 
[epoch_0]_53581  loss=2.961645 |g|=0.508	lr=2.80e-05 | 89.4%@S44  T=1.77s(data=1.7ms QKV=2.13s FFN=3.04s) eta=03:39:23 | 43.5K token/s | 
[epoch_0]_53591  loss=3.060570 |g|=0.505	lr=2.80e-05 | 90.2%@S44  T=1.76s(data=1.6ms QKV=2.13s FFN=3.04s) eta=03:38:40 | 43.6K token/s | 
[Fuyou] head="1" update algorithm=4 t=9.98s
[eval] 
	 Loss@"edu_fineweb1B"=3.059(0.001) nBranch=1 nToken=6.31M best=3.0598(266) E2T=0.0415 T=36.7411(0)s x=0
	#3.05881±0.0976 tps=172K(6.30784M) a=[2.8714,3.33978] T=36.7411(sec)
[Section@53600] layer[16-24] tasks=19(nPassBack=0) last_loss=3.01733(-0.00956106) N=(772,60704,60144 7075068)
[epoch_0]_53601  loss=2.996799 |g|=0.507	lr=2.79e-05 | 91.0%@S44  T=12.34s(data=2.0ms QKV=2.13s FFN=3.03s) eta=1d 01:28:33 | 41.8K token/s | 
[epoch_0]_53611  loss=3.069824 |g|=0.522	lr=2.78e-05 | 91.8%@S44  T=1.80s(data=1.9ms QKV=2.12s FFN=3.04s) eta=03:42:45 | 42.0K token/s | 
[epoch_0]_53621  loss=2.998338 |g|=0.499	lr=2.78e-05 | 92.6%@S44  T=1.81s(data=1.7ms QKV=2.12s FFN=3.04s) eta=03:43:57 | 42.1K token/s | 
[epoch_0]_53631  loss=2.978225 |g|=0.496	lr=2.77e-05 | 93.5%@S44  T=1.80s(data=1.6ms QKV=2.12s FFN=3.04s) eta=03:42:16 | 42.3K token/s | 
[epoch_0]_53641  loss=2.934461 |g|=0.488	lr=2.77e-05 | 94.3%@S44  T=1.79s(data=1.7ms QKV=2.12s FFN=3.04s) eta=03:40:22 | 42.5K token/s | 
[epoch_0]_53651  loss=3.001370 |g|=0.505	lr=2.76e-05 | 95.1%@S44  T=1.80s(data=1.6ms QKV=2.12s FFN=3.04s) eta=03:40:54 | 42.6K token/s | 
[epoch_0]_53661  loss=3.058035 |g|=0.496	lr=2.76e-05 | 95.9%@S44  T=1.82s(data=1.5ms QKV=2.13s FFN=3.04s) eta=03:44:00 | 42.8K token/s | 
[epoch_0]_53671  loss=2.943568 |g|=0.525	lr=2.75e-05 | 96.7%@S44  T=1.80s(data=1.7ms QKV=2.13s FFN=3.04s) eta=03:41:23 | 42.9K token/s | 
[epoch_0]_53681  loss=2.985995 |g|=0.499	lr=2.74e-05 | 97.6%@S44  T=1.80s(data=1.9ms QKV=2.14s FFN=3.04s) eta=03:40:59 | 43.0K token/s | 
[epoch_0]_53691  loss=3.098109 |g|=0.494	lr=2.74e-05 | 98.4%@S44  T=1.78s(data=1.5ms QKV=2.13s FFN=3.04s) eta=03:37:28 | 43.2K token/s | 
[Fuyou] head="2" update algorithm=4 t=10.53s
[Section@53700] layer[24-32] tasks=19(nPassBack=0) last_loss=3.07071(-0.114908) N=(772,60816,60256 7088268)
[epoch_0]_53701  loss=3.017579 |g|=0.498	lr=2.73e-05 | 99.2%@S44  T=4.79s(data=2.1ms QKV=2.13s FFN=3.03s) eta=09:45:23 | 41.9K token/s | 
[epoch_0]_53710  loss=3.008533 |g|=0.486	lr=2.73e-05 | 99.9%@S44  T=1.78s(data=1.8ms QKV=2.14s FFN=3.04s) eta=03:37:03 | 42.1K token/s | 
-------- End of shard_44@"./Datasets/edu_fineweb1B/edu_fineweb_train_000802.bin"-------- 
[shard-45]@"./Datasets/edu_fineweb1B/edu_fineweb_train_000803.bin": tokens=100(M) nShardSamples=1220(4394520) 
[epoch_0]_53711  loss=3.064536 |g|=0.488	lr=2.73e-05 | 0.0%@S45  T=2.43s(data=945.3ms QKV=2.13s FFN=3.04s) eta=04:56:42 | 41.7K token/s | 
[epoch_0]_53721  loss=3.042232 |g|=0.505	lr=2.72e-05 | 0.8%@S45  T=1.79s(data=1.3ms QKV=2.13s FFN=3.04s) eta=03:37:57 | 41.9K token/s | 
[epoch_0]_53731  loss=2.941926 |g|=0.491	lr=2.72e-05 | 1.7%@S45  T=1.78s(data=1.4ms QKV=2.13s FFN=3.04s) eta=03:37:17 | 42.1K token/s | 
[epoch_0]_53741  loss=2.967122 |g|=0.513	lr=2.71e-05 | 2.5%@S45  T=1.78s(data=1.2ms QKV=2.13s FFN=3.04s) eta=03:36:07 | 42.3K token/s | 
[epoch_0]_53751  loss=3.033169 |g|=0.501	lr=2.70e-05 | 3.3%@S45  T=1.81s(data=6.2ms QKV=2.14s FFN=3.04s) eta=03:39:12 | 42.4K token/s | 
[epoch_0]_53761  loss=3.075782 |g|=0.497	lr=2.70e-05 | 4.1%@S45  T=1.79s(data=1.2ms QKV=2.13s FFN=3.04s) eta=03:36:28 | 42.6K token/s | 
[epoch_0]_53771  loss=3.018779 |g|=0.482	lr=2.69e-05 | 4.9%@S45  T=1.79s(data=1.2ms QKV=2.14s FFN=3.04s) eta=03:37:15 | 42.8K token/s | 
[epoch_0]_53781  loss=3.062219 |g|=0.509	lr=2.69e-05 | 5.8%@S45  T=1.86s(data=1.6ms QKV=2.14s FFN=3.04s) eta=03:44:47 | 42.8K token/s | 
[epoch_0]_53791  loss=3.007373 |g|=0.495	lr=2.68e-05 | 6.6%@S45  T=1.78s(data=1.9ms QKV=2.13s FFN=3.04s) eta=03:34:22 | 43.0K token/s | 
[Fuyou] head="3" update algorithm=4 t=12.20s
[eval] 
	 Loss@"edu_fineweb1B"=3.058(0.00081) nBranch=1 nToken=6.31M best=3.0588(267) E2T=-0.00699 T=36.7579(0)s x=0
	#3.05801±0.0975 tps=172K(6.30784M) a=[2.87048,3.33914] T=36.7579(sec)
[Section@53800] layer[32-40] tasks=19(nPassBack=0) last_loss=3.065(-0.0857425) N=(772,60928,60368 7101468)
[epoch_0]_53801  loss=2.971124 |g|=0.5	lr=2.68e-05 | 7.4%@S45  T=12.23s(data=1.6ms QKV=2.12s FFN=3.04s) eta=1d 00:34:30 | 41.2K token/s | 
[epoch_0]_53811  loss=3.072689 |g|=0.5	lr=2.67e-05 | 8.2%@S45  T=1.81s(data=1.6ms QKV=2.13s FFN=3.04s) eta=03:37:24 | 41.4K token/s | 
[epoch_0]_53821  loss=3.084541 |g|=0.497	lr=2.66e-05 | 9.0%@S45  T=1.78s(data=1.5ms QKV=2.13s FFN=3.04s) eta=03:34:20 | 41.6K token/s | 
[epoch_0]_53831  loss=3.031330 |g|=0.51	lr=2.66e-05 | 9.8%@S45  T=1.76s(data=1.3ms QKV=2.13s FFN=3.04s) eta=03:31:35 | 41.9K token/s | 
[epoch_0]_53841  loss=2.983704 |g|=0.494	lr=2.65e-05 | 10.7%@S45  T=1.82s(data=1.3ms QKV=2.13s FFN=3.04s) eta=03:37:53 | 42.0K token/s | 
[epoch_0]_53851  loss=2.995229 |g|=0.516	lr=2.65e-05 | 11.5%@S45  T=1.81s(data=1.5ms QKV=2.13s FFN=3.04s) eta=03:36:27 | 42.2K token/s | 
[epoch_0]_53861  loss=3.029403 |g|=0.5	lr=2.64e-05 | 12.3%@S45  T=1.79s(data=1.6ms QKV=2.13s FFN=3.04s) eta=03:33:55 | 42.4K token/s | 
[epoch_0]_53871  loss=3.004720 |g|=0.496	lr=2.64e-05 | 13.1%@S45  T=1.81s(data=1.8ms QKV=2.13s FFN=3.04s) eta=03:36:36 | 42.5K token/s | 
[epoch_0]_53881  loss=3.003001 |g|=0.509	lr=2.63e-05 | 13.9%@S45  T=1.80s(data=1.8ms QKV=2.13s FFN=3.04s) eta=03:34:46 | 42.6K token/s | 
[epoch_0]_53891  loss=2.996853 |g|=0.481	lr=2.62e-05 | 14.8%@S45  T=1.80s(data=1.5ms QKV=2.13s FFN=3.04s) eta=03:34:26 | 42.8K token/s | 
[Fuyou] head="4" update algorithm=4 t=11.37s
[Section@53900] layer[40-48] tasks=19(nPassBack=0) last_loss=3.04107(0.0418587) N=(772,61040,60480 7114668)
[epoch_0]_53901  loss=3.026333 |g|=0.509	lr=2.62e-05 | 15.6%@S45  T=4.15s(data=1.9ms QKV=2.13s FFN=3.03s) eta=08:13:49 | 41.6K token/s | 
[epoch_0]_53911  loss=2.997657 |g|=0.523	lr=2.61e-05 | 16.4%@S45  T=1.83s(data=1.7ms QKV=2.14s FFN=3.04s) eta=03:37:20 | 41.8K token/s | 
[epoch_0]_53921  loss=2.995445 |g|=0.517	lr=2.61e-05 | 17.2%@S45  T=1.82s(data=1.7ms QKV=2.13s FFN=3.04s) eta=03:35:19 | 42.0K token/s | 
[epoch_0]_53931  loss=3.030979 |g|=0.483	lr=2.60e-05 | 18.0%@S45  T=1.80s(data=1.8ms QKV=2.13s FFN=3.04s) eta=03:32:54 | 42.1K token/s | 
[epoch_0]_53941  loss=2.966978 |g|=0.519	lr=2.60e-05 | 18.9%@S45  T=1.78s(data=1.5ms QKV=2.13s FFN=3.04s) eta=03:31:01 | 42.3K token/s | 
[epoch_0]_53951  loss=3.075632 |g|=0.497	lr=2.59e-05 | 19.7%@S45  T=1.83s(data=1.8ms QKV=2.14s FFN=3.04s) eta=03:35:31 | 42.5K token/s | 
[epoch_0]_53961  loss=3.017160 |g|=0.494	lr=2.59e-05 | 20.5%@S45  T=1.81s(data=1.5ms QKV=2.14s FFN=3.04s) eta=03:32:56 | 42.6K token/s | 
[epoch_0]_53971  loss=2.971068 |g|=0.489	lr=2.58e-05 | 21.3%@S45  T=1.84s(data=1.7ms QKV=2.14s FFN=3.04s) eta=03:36:56 | 42.7K token/s | 
[epoch_0]_53981  loss=3.077581 |g|=0.507	lr=2.57e-05 | 22.1%@S45  T=1.84s(data=1.4ms QKV=2.14s FFN=3.04s) eta=03:35:55 | 42.8K token/s | 
[epoch_0]_53991  loss=3.024523 |g|=0.477	lr=2.57e-05 | 23.0%@S45  T=1.84s(data=1.6ms QKV=2.14s FFN=3.04s) eta=03:35:39 | 42.9K token/s | 
[Fuyou] head="5" update algorithm=4 t=12.00s
[eval] 
	 Loss@"edu_fineweb1B"=3.057(0.0011) nBranch=1 nToken=6.31M best=3.0580(268) E2T=0.0222 T=36.7737(0)s x=0
	#3.05694±0.0974 tps=172K(6.30784M) a=[2.87039,3.33703] T=36.7737(sec)
[Section@54000] layer[0-8] tasks=19(nPassBack=0) last_loss=3.03471(-0.009624) N=(772,61152,60592 7127868)
[epoch_0]_54001  loss=3.004611 |g|=0.488	lr=2.56e-05 | 23.8%@S45  T=12.65s(data=1.9ms QKV=2.12s FFN=3.03s) eta=1d 00:42:56 | 41.1K token/s | 
[epoch_0]_54011  loss=3.073512 |g|=0.526	lr=2.56e-05 | 24.6%@S45  T=1.83s(data=1.7ms QKV=2.12s FFN=3.04s) eta=03:33:42 | 41.2K token/s | 
[epoch_0]_54021  loss=2.966981 |g|=0.503	lr=2.55e-05 | 25.4%@S45  T=1.79s(data=1.5ms QKV=2.13s FFN=3.04s) eta=03:28:57 | 41.5K token/s | 
[epoch_0]_54031  loss=3.105485 |g|=0.503	lr=2.55e-05 | 26.2%@S45  T=1.80s(data=1.6ms QKV=2.12s FFN=3.04s) eta=03:30:27 | 41.7K token/s | 
[epoch_0]_54041  loss=2.939112 |g|=0.509	lr=2.54e-05 | 27.1%@S45  T=1.80s(data=1.5ms QKV=2.13s FFN=3.04s) eta=03:30:19 | 41.9K token/s | 
[epoch_0]_54051  loss=3.064609 |g|=0.498	lr=2.54e-05 | 27.9%@S45  T=1.80s(data=1.9ms QKV=2.13s FFN=3.04s) eta=03:29:59 | 42.0K token/s | 
[epoch_0]_54061  loss=3.003524 |g|=0.5	lr=2.53e-05 | 28.7%@S45  T=1.81s(data=1.6ms QKV=2.13s FFN=3.04s) eta=03:29:52 | 42.2K token/s | 
[epoch_0]_54071  loss=2.954785 |g|=0.491	lr=2.52e-05 | 29.5%@S45  T=1.83s(data=1.8ms QKV=2.13s FFN=3.04s) eta=03:32:16 | 42.3K token/s | 
[epoch_0]_54081  loss=2.936535 |g|=0.487	lr=2.52e-05 | 30.3%@S45  T=1.80s(data=1.5ms QKV=2.13s FFN=3.04s) eta=03:29:06 | 42.5K token/s | 
[epoch_0]_54091  loss=2.989896 |g|=0.5	lr=2.51e-05 | 31.1%@S45  T=1.81s(data=1.7ms QKV=2.13s FFN=3.04s) eta=03:29:37 | 42.6K token/s | 
[Fuyou] head="0" update algorithm=4 t=12.64s
[Section@54100] layer[8-16] tasks=19(nPassBack=0) last_loss=3.04733(-0.0675266) N=(772,61264,60704 7141068)
[epoch_0]_54101  loss=3.064101 |g|=0.499	lr=2.51e-05 | 32.0%@S45  T=4.87s(data=1.7ms QKV=2.13s FFN=3.03s) eta=09:22:26 | 41.3K token/s | 
[epoch_0]_54111  loss=2.976017 |g|=0.493	lr=2.50e-05 | 32.8%@S45  T=1.79s(data=2.0ms QKV=2.14s FFN=3.04s) eta=03:27:00 | 41.6K token/s | 
[epoch_0]_54121  loss=2.965020 |g|=0.481	lr=2.50e-05 | 33.6%@S45  T=1.82s(data=1.7ms QKV=2.14s FFN=3.04s) eta=03:30:16 | 41.7K token/s | 
[epoch_0]_54131  loss=3.082983 |g|=0.492	lr=2.49e-05 | 34.4%@S45  T=1.84s(data=1.8ms QKV=2.14s FFN=3.04s) eta=03:31:55 | 41.9K token/s | 
[epoch_0]_54141  loss=2.975435 |g|=0.484	lr=2.49e-05 | 35.2%@S45  T=1.79s(data=1.8ms QKV=2.14s FFN=3.04s) eta=03:25:37 | 42.1K token/s | 
[epoch_0]_54151  loss=3.011980 |g|=0.487	lr=2.48e-05 | 36.1%@S45  T=1.81s(data=1.8ms QKV=2.14s FFN=3.04s) eta=03:27:08 | 42.2K token/s | 
[epoch_0]_54161  loss=2.981645 |g|=0.503	lr=2.48e-05 | 36.9%@S45  T=1.87s(data=1.6ms QKV=2.14s FFN=3.04s) eta=03:33:55 | 42.3K token/s | 
[epoch_0]_54171  loss=2.973373 |g|=0.487	lr=2.47e-05 | 37.7%@S45  T=1.80s(data=1.7ms QKV=2.14s FFN=3.04s) eta=03:26:01 | 42.5K token/s | 
[epoch_0]_54181  loss=3.064862 |g|=0.507	lr=2.47e-05 | 38.5%@S45  T=1.81s(data=1.8ms QKV=2.14s FFN=3.04s) eta=03:26:55 | 42.6K token/s | 
[epoch_0]_54191  loss=3.072339 |g|=0.501	lr=2.46e-05 | 39.3%@S45  T=1.78s(data=1.5ms QKV=2.14s FFN=3.04s) eta=03:23:14 | 42.8K token/s | 
[Fuyou] head="1" update algorithm=4 t=11.23s
[eval] 
	 Loss@"edu_fineweb1B"=3.056(0.00065) nBranch=1 nToken=6.31M best=3.0569(269) E2T=0.0695 T=36.7548(0)s x=0
	#3.05629±0.0973 tps=172K(6.30784M) a=[2.87076,3.33553] T=36.7548(sec)
[Section@54200] layer[16-24] tasks=19(nPassBack=0) last_loss=2.98675(0.0305805) N=(772,61376,60816 7154268)
[epoch_0]_54201  loss=2.990564 |g|=0.497	lr=2.45e-05 | 40.2%@S45  T=12.48s(data=1.8ms QKV=2.12s FFN=3.04s) eta=23:41:04 | 41.0K token/s | 
[epoch_0]_54211  loss=3.039907 |g|=0.507	lr=2.45e-05 | 41.0%@S45  T=1.79s(data=1.6ms QKV=2.13s FFN=3.04s) eta=03:23:40 | 41.2K token/s | 
[epoch_0]_54221  loss=3.008305 |g|=0.496	lr=2.44e-05 | 41.8%@S45  T=1.86s(data=1.6ms QKV=2.12s FFN=3.04s) eta=03:31:40 | 41.3K token/s | 
[epoch_0]_54231  loss=2.974254 |g|=0.51	lr=2.44e-05 | 42.6%@S45  T=1.83s(data=1.9ms QKV=2.13s FFN=3.04s) eta=03:27:02 | 41.5K token/s | 
[epoch_0]_54241  loss=2.962567 |g|=0.492	lr=2.43e-05 | 43.4%@S45  T=1.79s(data=1.5ms QKV=2.12s FFN=3.04s) eta=03:22:59 | 41.7K token/s | 
[epoch_0]_54251  loss=3.050077 |g|=0.501	lr=2.43e-05 | 44.3%@S45  T=1.81s(data=1.7ms QKV=2.12s FFN=3.04s) eta=03:24:06 | 41.9K token/s | 
[epoch_0]_54261  loss=3.047390 |g|=0.492	lr=2.42e-05 | 45.1%@S45  T=1.81s(data=1.8ms QKV=2.12s FFN=3.04s) eta=03:24:31 | 42.1K token/s | 
[epoch_0]_54271  loss=3.020530 |g|=0.504	lr=2.42e-05 | 45.9%@S45  T=1.81s(data=1.5ms QKV=2.12s FFN=3.04s) eta=03:23:45 | 42.2K token/s | 
[epoch_0]_54281  loss=3.046243 |g|=0.496	lr=2.41e-05 | 46.7%@S45  T=1.81s(data=1.5ms QKV=2.12s FFN=3.04s) eta=03:24:10 | 42.4K token/s | 
[epoch_0]_54291  loss=3.114581 |g|=0.511	lr=2.41e-05 | 47.5%@S45  T=1.83s(data=1.5ms QKV=2.13s FFN=3.04s) eta=03:25:12 | 42.5K token/s | 
[Fuyou] head="2" update algorithm=4 t=10.03s
[Section@54300] layer[24-32] tasks=19(nPassBack=0) last_loss=3.02287(0.047842) N=(772,61488,60928 7167468)
[epoch_0]_54301  loss=2.996102 |g|=0.526	lr=2.40e-05 | 48.4%@S45  T=4.81s(data=1.8ms QKV=2.13s FFN=3.03s) eta=08:59:51 | 41.2K token/s | 
[epoch_0]_54311  loss=2.919686 |g|=0.491	lr=2.40e-05 | 49.2%@S45  T=1.81s(data=1.7ms QKV=2.13s FFN=3.04s) eta=03:22:24 | 41.4K token/s | 
[epoch_0]_54321  loss=3.002341 |g|=0.484	lr=2.39e-05 | 50.0%@S45  T=1.79s(data=1.8ms QKV=2.13s FFN=3.04s) eta=03:20:48 | 41.6K token/s | 
[epoch_0]_54331  loss=3.052030 |g|=0.489	lr=2.39e-05 | 50.8%@S45  T=1.80s(data=2.0ms QKV=2.13s FFN=3.04s) eta=03:21:34 | 41.8K token/s | 
[epoch_0]_54341  loss=3.025220 |g|=0.504	lr=2.38e-05 | 51.6%@S45  T=1.86s(data=1.8ms QKV=2.13s FFN=3.04s) eta=03:27:12 | 41.9K token/s | 
[epoch_0]_54351  loss=2.952027 |g|=0.509	lr=2.37e-05 | 52.4%@S45  T=1.80s(data=1.7ms QKV=2.13s FFN=3.04s) eta=03:20:55 | 42.1K token/s | 
[epoch_0]_54361  loss=3.010412 |g|=0.502	lr=2.37e-05 | 53.3%@S45  T=1.82s(data=1.7ms QKV=2.13s FFN=3.04s) eta=03:22:39 | 42.3K token/s | 
[epoch_0]_54371  loss=3.020244 |g|=0.496	lr=2.36e-05 | 54.1%@S45  T=1.79s(data=1.4ms QKV=2.13s FFN=3.04s) eta=03:19:00 | 42.4K token/s | 
[epoch_0]_54381  loss=3.125106 |g|=0.512	lr=2.36e-05 | 54.9%@S45  T=1.82s(data=1.5ms QKV=2.13s FFN=3.04s) eta=03:21:23 | 42.6K token/s | 
[epoch_0]_54391  loss=3.026405 |g|=0.504	lr=2.35e-05 | 55.7%@S45  T=1.82s(data=1.9ms QKV=2.13s FFN=3.04s) eta=03:21:09 | 42.7K token/s | 
[Fuyou] head="3" update algorithm=4 t=11.84s
[eval] 
	 Loss@"edu_fineweb1B"=3.056(0.00053) nBranch=1 nToken=6.31M best=3.0563(270) E2T=0.0438 T=36.742(0)s x=0
	#3.05575±0.0973 tps=172K(6.30784M) a=[2.86902,3.3359] T=36.742(sec)
[Section@54400] layer[32-40] tasks=19(nPassBack=0) last_loss=3.01194(0.0530589) N=(772,61600,61040 7180668)
[epoch_0]_54401  loss=2.942986 |g|=0.521	lr=2.35e-05 | 56.5%@S45  T=12.15s(data=1.9ms QKV=2.12s FFN=3.04s) eta=22:23:33 | 40.9K token/s | 
[epoch_0]_54411  loss=3.086806 |g|=0.501	lr=2.34e-05 | 57.4%@S45  T=1.81s(data=1.7ms QKV=2.13s FFN=3.04s) eta=03:20:07 | 41.1K token/s | 
[epoch_0]_54421  loss=2.983825 |g|=0.506	lr=2.34e-05 | 58.2%@S45  T=1.85s(data=2.2ms QKV=2.13s FFN=3.04s) eta=03:24:13 | 41.3K token/s | 
[epoch_0]_54431  loss=3.000480 |g|=0.496	lr=2.33e-05 | 59.0%@S45  T=1.80s(data=1.7ms QKV=2.12s FFN=3.04s) eta=03:18:20 | 41.5K token/s | 
[epoch_0]_54441  loss=3.062052 |g|=0.491	lr=2.33e-05 | 59.8%@S45  T=1.87s(data=1.9ms QKV=2.13s FFN=3.04s) eta=03:25:15 | 41.6K token/s | 
[epoch_0]_54451  loss=2.972950 |g|=0.476	lr=2.32e-05 | 60.6%@S45  T=1.79s(data=1.6ms QKV=2.12s FFN=3.04s) eta=03:16:32 | 41.8K token/s | 
[epoch_0]_54461  loss=3.021120 |g|=0.498	lr=2.32e-05 | 61.5%@S45  T=1.80s(data=1.7ms QKV=2.13s FFN=3.04s) eta=03:17:45 | 42.0K token/s | 
[epoch_0]_54471  loss=3.004805 |g|=0.483	lr=2.31e-05 | 62.3%@S45  T=1.81s(data=1.7ms QKV=2.13s FFN=3.04s) eta=03:18:13 | 42.1K token/s | 
[epoch_0]_54481  loss=3.003021 |g|=0.502	lr=2.31e-05 | 63.1%@S45  T=1.79s(data=1.9ms QKV=2.13s FFN=3.04s) eta=03:15:32 | 42.3K token/s | 
[epoch_0]_54491  loss=3.087029 |g|=0.507	lr=2.30e-05 | 63.9%@S45  T=1.87s(data=1.8ms QKV=2.12s FFN=3.04s) eta=03:23:59 | 42.4K token/s | 
[Fuyou] head="4" update algorithm=4 t=12.51s
[Section@54500] layer[40-48] tasks=19(nPassBack=0) last_loss=3.05159(-0.0105186) N=(772,61712,61152 7193868)
[epoch_0]_54501  loss=2.990111 |g|=0.49	lr=2.30e-05 | 64.7%@S45  T=4.34s(data=2.1ms QKV=2.13s FFN=3.03s) eta=07:52:59 | 41.2K token/s | 
[epoch_0]_54511  loss=3.002596 |g|=0.491	lr=2.29e-05 | 65.6%@S45  T=1.82s(data=1.6ms QKV=2.13s FFN=3.04s) eta=03:17:51 | 41.4K token/s | 
[epoch_0]_54521  loss=2.986758 |g|=0.499	lr=2.29e-05 | 66.4%@S45  T=1.83s(data=1.6ms QKV=2.13s FFN=3.04s) eta=03:19:09 | 41.6K token/s | 
[epoch_0]_54531  loss=3.068213 |g|=0.507	lr=2.28e-05 | 67.2%@S45  T=1.80s(data=2.1ms QKV=2.13s FFN=3.04s) eta=03:15:37 | 41.8K token/s | 
[epoch_0]_54541  loss=3.064093 |g|=0.502	lr=2.28e-05 | 68.0%@S45  T=1.81s(data=1.8ms QKV=2.13s FFN=3.04s) eta=03:15:33 | 41.9K token/s | 
[epoch_0]_54551  loss=3.049948 |g|=0.502	lr=2.27e-05 | 68.8%@S45  T=1.79s(data=1.7ms QKV=2.14s FFN=3.04s) eta=03:13:03 | 42.1K token/s | 
[epoch_0]_54561  loss=3.060580 |g|=0.485	lr=2.27e-05 | 69.6%@S45  T=1.81s(data=1.8ms QKV=2.13s FFN=3.04s) eta=03:15:37 | 42.3K token/s | 
[epoch_0]_54571  loss=3.079507 |g|=0.491	lr=2.26e-05 | 70.5%@S45  T=1.82s(data=1.8ms QKV=2.13s FFN=3.04s) eta=03:15:36 | 42.4K token/s | 
[epoch_0]_54581  loss=3.010494 |g|=0.494	lr=2.26e-05 | 71.3%@S45  T=1.79s(data=1.5ms QKV=2.13s FFN=3.04s) eta=03:12:21 | 42.6K token/s | 
[epoch_0]_54591  loss=3.042732 |g|=0.491	lr=2.25e-05 | 72.1%@S45  T=1.82s(data=1.7ms QKV=2.14s FFN=3.04s) eta=03:15:04 | 42.7K token/s | 
[Fuyou] head="5" update algorithm=4 t=10.91s
[eval] 
	 Loss@"edu_fineweb1B"=3.055(0.00042) nBranch=1 nToken=6.31M best=3.0558(271) E2T=0.0403 T=36.7395(0)s x=0
	#3.05533±0.0974 tps=172K(6.30784M) a=[2.86861,3.33681] T=36.7395(sec)
[Section@54600] layer[0-8] tasks=19(nPassBack=0) last_loss=3.01501(0.0196977) N=(772,61824,61264 7207068)
[epoch_0]_54601  loss=3.064674 |g|=0.509	lr=2.25e-05 | 72.9%@S45  T=12.41s(data=1.8ms QKV=2.12s FFN=3.03s) eta=22:10:39 | 40.9K token/s | 
[epoch_0]_54611  loss=3.024135 |g|=0.498	lr=2.24e-05 | 73.7%@S45  T=1.80s(data=1.8ms QKV=2.12s FFN=3.04s) eta=03:12:51 | 41.1K token/s | 
[epoch_0]_54621  loss=2.960010 |g|=0.507	lr=2.24e-05 | 74.6%@S45  T=1.79s(data=1.6ms QKV=2.13s FFN=3.04s) eta=03:11:34 | 41.4K token/s | 
[epoch_0]_54631  loss=3.014357 |g|=0.49	lr=2.23e-05 | 75.4%@S45  T=1.81s(data=1.6ms QKV=2.12s FFN=3.04s) eta=03:13:11 | 41.6K token/s | 
[epoch_0]_54641  loss=2.974586 |g|=0.487	lr=2.23e-05 | 76.2%@S45  T=1.82s(data=1.8ms QKV=2.13s FFN=3.04s) eta=03:13:52 | 41.7K token/s | 
[epoch_0]_54651  loss=2.959281 |g|=0.487	lr=2.22e-05 | 77.0%@S45  T=1.82s(data=1.6ms QKV=2.12s FFN=3.04s) eta=03:13:18 | 41.9K token/s | 
[epoch_0]_54661  loss=3.084107 |g|=0.5	lr=2.22e-05 | 77.8%@S45  T=1.83s(data=1.7ms QKV=2.13s FFN=3.04s) eta=03:14:00 | 42.1K token/s | 
[epoch_0]_54671  loss=2.945303 |g|=0.488	lr=2.21e-05 | 78.7%@S45  T=1.79s(data=1.7ms QKV=2.13s FFN=3.04s) eta=03:09:52 | 42.2K token/s | 
[epoch_0]_54681  loss=3.042676 |g|=0.497	lr=2.21e-05 | 79.5%@S45  T=1.79s(data=1.6ms QKV=2.12s FFN=3.04s) eta=03:09:54 | 42.4K token/s | 
[epoch_0]_54691  loss=2.999844 |g|=0.483	lr=2.20e-05 | 80.3%@S45  T=1.83s(data=2.0ms QKV=2.13s FFN=3.04s) eta=03:13:44 | 42.5K token/s | 
[Fuyou] head="0" update algorithm=4 t=12.53s
[Section@54700] layer[8-16] tasks=19(nPassBack=0) last_loss=2.98477(0.0625682) N=(772,61936,61376 7220268)
[epoch_0]_54701  loss=3.013794 |g|=0.486	lr=2.20e-05 | 81.1%@S45  T=4.90s(data=2.1ms QKV=2.13s FFN=3.03s) eta=08:37:16 | 41.2K token/s | 
[epoch_0]_54711  loss=2.973294 |g|=0.5	lr=2.19e-05 | 81.9%@S45  T=1.81s(data=1.8ms QKV=2.13s FFN=3.04s) eta=03:10:49 | 41.4K token/s | 
[epoch_0]_54721  loss=3.066993 |g|=0.49	lr=2.19e-05 | 82.8%@S45  T=1.79s(data=2.0ms QKV=2.13s FFN=3.04s) eta=03:08:45 | 41.7K token/s | 
[epoch_0]_54731  loss=3.036986 |g|=0.512	lr=2.18e-05 | 83.6%@S45  T=1.80s(data=1.8ms QKV=2.14s FFN=3.04s) eta=03:09:36 | 41.8K token/s | 
[epoch_0]_54741  loss=2.952060 |g|=0.491	lr=2.18e-05 | 84.4%@S45  T=1.81s(data=1.8ms QKV=2.14s FFN=3.04s) eta=03:10:12 | 42.0K token/s | 
[epoch_0]_54751  loss=3.018308 |g|=0.494	lr=2.17e-05 | 85.2%@S45  T=1.82s(data=1.9ms QKV=2.14s FFN=3.04s) eta=03:10:19 | 42.2K token/s | 
[epoch_0]_54761  loss=2.990699 |g|=0.485	lr=2.17e-05 | 86.0%@S45  T=1.81s(data=1.7ms QKV=2.14s FFN=3.04s) eta=03:09:44 | 42.3K token/s | 
[epoch_0]_54771  loss=2.960775 |g|=0.486	lr=2.16e-05 | 86.9%@S45  T=1.81s(data=1.7ms QKV=2.14s FFN=3.04s) eta=03:09:12 | 42.5K token/s | 
[epoch_0]_54781  loss=2.996746 |g|=0.507	lr=2.16e-05 | 87.7%@S45  T=1.78s(data=1.7ms QKV=2.14s FFN=3.04s) eta=03:05:17 | 42.6K token/s | 
[epoch_0]_54791  loss=2.978014 |g|=0.491	lr=2.15e-05 | 88.5%@S45  T=1.80s(data=1.7ms QKV=2.13s FFN=3.04s) eta=03:07:24 | 42.8K token/s | 
[Fuyou] head="1" update algorithm=4 t=10.94s
[eval] 
	 Loss@"edu_fineweb1B"=3.055(0.0006) nBranch=1 nToken=6.31M best=3.0553(272) E2T=0.0819 T=36.7526(0)s x=0
	#3.05473±0.0974 tps=172K(6.30784M) a=[2.86776,3.33568] T=36.7526(sec)
[Section@54800] layer[16-24] tasks=19(nPassBack=0) last_loss=2.97282(0.0139329) N=(772,62048,61488 7233468)
[epoch_0]_54801  loss=3.033902 |g|=0.5	lr=2.15e-05 | 89.3%@S45  T=12.73s(data=1.9ms QKV=2.13s FFN=3.03s) eta=22:02:15 | 41.0K token/s | 
[epoch_0]_54811  loss=3.066231 |g|=0.504	lr=2.14e-05 | 90.1%@S45  T=1.81s(data=1.9ms QKV=2.13s FFN=3.04s) eta=03:07:41 | 41.2K token/s | 
[epoch_0]_54821  loss=3.032061 |g|=0.493	lr=2.14e-05 | 90.9%@S45  T=1.79s(data=2.0ms QKV=2.14s FFN=3.04s) eta=03:05:02 | 41.4K token/s | 
[epoch_0]_54831  loss=3.022247 |g|=0.495	lr=2.13e-05 | 91.8%@S45  T=1.80s(data=1.6ms QKV=2.13s FFN=3.04s) eta=03:06:24 | 41.6K token/s | 
[epoch_0]_54841  loss=3.082504 |g|=0.487	lr=2.13e-05 | 92.6%@S45  T=1.81s(data=1.6ms QKV=2.12s FFN=3.04s) eta=03:06:26 | 41.8K token/s | 
[epoch_0]_54851  loss=3.027555 |g|=0.493	lr=2.12e-05 | 93.4%@S45  T=1.79s(data=3.7ms QKV=2.13s FFN=3.04s) eta=03:04:24 | 42.0K token/s | 
[epoch_0]_54861  loss=3.058328 |g|=0.505	lr=2.12e-05 | 94.2%@S45  T=1.80s(data=1.5ms QKV=2.13s FFN=3.04s) eta=03:05:08 | 42.2K token/s | 
[epoch_0]_54871  loss=3.020759 |g|=0.491	lr=2.11e-05 | 95.0%@S45  T=1.81s(data=1.8ms QKV=2.13s FFN=3.04s) eta=03:05:50 | 42.3K token/s | 
[epoch_0]_54881  loss=3.001743 |g|=0.488	lr=2.11e-05 | 95.9%@S45  T=1.81s(data=1.5ms QKV=2.13s FFN=3.04s) eta=03:05:30 | 42.5K token/s | 
[epoch_0]_54891  loss=3.002038 |g|=0.48	lr=2.10e-05 | 96.7%@S45  T=1.80s(data=6.2ms QKV=2.13s FFN=3.04s) eta=03:03:59 | 42.6K token/s | 
[Fuyou] head="2" update algorithm=4 t=10.40s
[Section@54900] layer[24-32] tasks=19(nPassBack=0) last_loss=3.01156(0.0113063) N=(772,62160,61600 7246668)
[epoch_0]_54901  loss=3.048506 |g|=0.494	lr=2.10e-05 | 97.5%@S45  T=4.80s(data=1.9ms QKV=2.13s FFN=3.03s) eta=08:11:06 | 41.4K token/s | 
[epoch_0]_54911  loss=3.047433 |g|=0.494	lr=2.09e-05 | 98.3%@S45  T=1.81s(data=1.6ms QKV=2.13s FFN=3.04s) eta=03:04:24 | 41.6K token/s | 
[epoch_0]_54921  loss=3.090109 |g|=0.499	lr=2.09e-05 | 99.1%@S45  T=1.82s(data=2.5ms QKV=2.14s FFN=3.04s) eta=03:05:21 | 41.7K token/s | 
[epoch_0]_54931  loss=3.089927 |g|=0.502	lr=2.08e-05 | 100.0%@S45  T=1.81s(data=1.6ms QKV=2.14s FFN=3.04s) eta=03:03:51 | 41.9K token/s | 
-------- End of shard_45@"./Datasets/edu_fineweb1B/edu_fineweb_train_000803.bin"-------- 
[shard-46]@"./Datasets/edu_fineweb1B/edu_fineweb_train_000804.bin": tokens=100(M) nShardSamples=1220(4492176) 
[epoch_0]_54941  loss=3.029678 |g|=0.5	lr=2.08e-05 | 0.8%@S46  T=1.80s(data=1.4ms QKV=2.14s FFN=3.04s) eta=03:03:05 | 42.1K token/s | 
[epoch_0]_54951  loss=3.070422 |g|=0.523	lr=2.07e-05 | 1.6%@S46  T=1.80s(data=1.3ms QKV=2.13s FFN=3.04s) eta=03:02:04 | 42.3K token/s | 
[epoch_0]_54961  loss=3.014327 |g|=0.487	lr=2.07e-05 | 2.4%@S46  T=1.79s(data=1.3ms QKV=2.14s FFN=3.04s) eta=03:01:16 | 42.4K token/s | 
[epoch_0]_54971  loss=3.069026 |g|=0.51	lr=2.06e-05 | 3.2%@S46  T=1.82s(data=1.8ms QKV=2.14s FFN=3.04s) eta=03:04:01 | 42.6K token/s | 
[epoch_0]_54981  loss=3.030361 |g|=0.487	lr=2.06e-05 | 4.1%@S46  T=1.80s(data=1.6ms QKV=2.14s FFN=3.04s) eta=03:01:09 | 42.7K token/s | 
[epoch_0]_54991  loss=3.091275 |g|=0.497	lr=2.05e-05 | 4.9%@S46  T=1.84s(data=1.9ms QKV=2.14s FFN=3.04s) eta=03:05:26 | 42.8K token/s | 
[Fuyou] head="3" update algorithm=4 t=12.07s
[eval] 
	 Loss@"edu_fineweb1B"=3.053(0.0013) nBranch=1 nToken=6.31M best=3.0547(273) E2T=0.0103 T=36.7301(0)s x=0
	#3.0534±0.0973 tps=172K(6.30784M) a=[2.86578,3.33363] T=36.7301(sec)
[Section@55000] layer[32-40] tasks=19(nPassBack=0) last_loss=3.04314(-0.0312037) N=(772,62272,61712 7259868)
[epoch_0]_55001  loss=3.026108 |g|=0.517	lr=2.05e-05 | 5.7%@S46  T=12.32s(data=1.7ms QKV=2.12s FFN=3.04s) eta=20:38:29 | 41.0K token/s | 
[epoch_0]_55011  loss=3.040160 |g|=0.493	lr=2.04e-05 | 6.5%@S46  T=1.82s(data=1.6ms QKV=2.12s FFN=3.04s) eta=03:02:20 | 41.2K token/s | 
[epoch_0]_55021  loss=3.011652 |g|=0.508	lr=2.04e-05 | 7.3%@S46  T=1.83s(data=1.9ms QKV=2.13s FFN=3.04s) eta=03:03:30 | 41.4K token/s | 
[epoch_0]_55031  loss=3.021143 |g|=0.493	lr=2.03e-05 | 8.2%@S46  T=1.81s(data=1.8ms QKV=2.13s FFN=3.04s) eta=03:01:10 | 41.6K token/s | 
[epoch_0]_55041  loss=3.043389 |g|=0.497	lr=2.03e-05 | 9.0%@S46  T=1.80s(data=1.6ms QKV=2.12s FFN=3.04s) eta=02:59:30 | 41.8K token/s | 
[epoch_0]_55051  loss=2.995576 |g|=0.49	lr=2.03e-05 | 9.8%@S46  T=1.81s(data=1.7ms QKV=2.13s FFN=3.04s) eta=03:00:51 | 41.9K token/s | 
[epoch_0]_55061  loss=2.961936 |g|=0.508	lr=2.02e-05 | 10.6%@S46  T=1.82s(data=1.5ms QKV=2.13s FFN=3.04s) eta=03:00:50 | 42.1K token/s | 
[epoch_0]_55071  loss=3.018961 |g|=0.502	lr=2.02e-05 | 11.4%@S46  T=1.81s(data=1.4ms QKV=2.13s FFN=3.04s) eta=02:59:43 | 42.3K token/s | 
[epoch_0]_55081  loss=2.937873 |g|=0.498	lr=2.01e-05 | 12.2%@S46  T=1.81s(data=1.7ms QKV=2.13s FFN=3.04s) eta=02:59:50 | 42.4K token/s | 
[epoch_0]_55091  loss=2.982882 |g|=0.491	lr=2.01e-05 | 13.1%@S46  T=1.82s(data=1.7ms QKV=2.13s FFN=3.04s) eta=03:00:22 | 42.5K token/s | 
[Fuyou] head="4" update algorithm=4 t=11.55s
[Section@55100] layer[40-48] tasks=19(nPassBack=0) last_loss=2.98528(0.066308) N=(772,62384,61824 7273068)
[epoch_0]_55101  loss=3.005355 |g|=0.501	lr=2.00e-05 | 13.9%@S46  T=4.28s(data=1.5ms QKV=2.13s FFN=3.03s) eta=07:03:43 | 41.4K token/s | 
[epoch_0]_55111  loss=3.031414 |g|=0.492	lr=2.00e-05 | 14.7%@S46  T=1.80s(data=1.4ms QKV=2.13s FFN=3.04s) eta=02:57:16 | 41.6K token/s | 
[epoch_0]_55121  loss=3.059270 |g|=0.484	lr=1.99e-05 | 15.5%@S46  T=1.80s(data=1.6ms QKV=2.13s FFN=3.04s) eta=02:57:34 | 41.8K token/s | 
[epoch_0]_55131  loss=3.021430 |g|=0.479	lr=1.99e-05 | 16.3%@S46  T=1.87s(data=1.6ms QKV=2.13s FFN=3.04s) eta=03:03:50 | 41.9K token/s | 
[epoch_0]_55141  loss=3.018722 |g|=0.51	lr=1.98e-05 | 17.2%@S46  T=1.82s(data=2.1ms QKV=2.13s FFN=3.04s) eta=02:58:30 | 42.0K token/s | 
[epoch_0]_55151  loss=2.975821 |g|=0.496	lr=1.98e-05 | 18.0%@S46  T=1.82s(data=1.6ms QKV=2.13s FFN=3.04s) eta=02:58:33 | 42.2K token/s | 
[epoch_0]_55161  loss=3.027333 |g|=0.52	lr=1.97e-05 | 18.8%@S46  T=1.82s(data=1.4ms QKV=2.13s FFN=3.04s) eta=02:58:13 | 42.3K token/s | 
[epoch_0]_55171  loss=2.979355 |g|=0.513	lr=1.97e-05 | 19.6%@S46  T=1.80s(data=1.7ms QKV=2.13s FFN=3.04s) eta=02:55:42 | 42.5K token/s | 
[epoch_0]_55181  loss=2.950312 |g|=0.498	lr=1.96e-05 | 20.4%@S46  T=1.78s(data=1.5ms QKV=2.13s FFN=3.04s) eta=02:53:13 | 42.7K token/s | 
[epoch_0]_55191  loss=2.973022 |g|=0.494	lr=1.96e-05 | 21.3%@S46  T=1.80s(data=1.5ms QKV=2.13s FFN=3.04s) eta=02:55:28 | 42.8K token/s | 
[Fuyou] head="5" update algorithm=4 t=11.89s
[eval] 
	 Loss@"edu_fineweb1B"=3.052(0.0012) nBranch=1 nToken=6.31M best=3.0534(274) E2T=0.0131 T=36.7305(0)s x=0
	#3.0522±0.0971 tps=172K(6.30784M) a=[2.86409,3.33151] T=36.7305(sec)
[Section@55200] layer[0-8] tasks=19(nPassBack=0) last_loss=3.03905(-0.0240438) N=(772,62496,61936 7286268)
[epoch_0]_55201  loss=3.013795 |g|=0.509	lr=1.96e-05 | 22.1%@S46  T=12.39s(data=1.9ms QKV=2.12s FFN=3.04s) eta=20:04:33 | 41.0K token/s | 
[epoch_0]_55211  loss=3.028719 |g|=0.514	lr=1.95e-05 | 22.9%@S46  T=1.80s(data=1.9ms QKV=2.12s FFN=3.04s) eta=02:54:25 | 41.2K token/s | 
[epoch_0]_55221  loss=3.008016 |g|=0.505	lr=1.95e-05 | 23.7%@S46  T=1.85s(data=1.9ms QKV=2.13s FFN=3.04s) eta=02:59:29 | 41.4K token/s | 
[epoch_0]_55231  loss=3.010170 |g|=0.5	lr=1.94e-05 | 24.5%@S46  T=1.82s(data=1.8ms QKV=2.12s FFN=3.04s) eta=02:55:55 | 41.6K token/s | 
[epoch_0]_55241  loss=3.038182 |g|=0.498	lr=1.94e-05 | 25.4%@S46  T=1.86s(data=1.6ms QKV=2.12s FFN=3.04s) eta=02:59:19 | 41.7K token/s | 
[epoch_0]_55251  loss=3.004341 |g|=0.486	lr=1.93e-05 | 26.2%@S46  T=1.85s(data=1.8ms QKV=2.12s FFN=3.04s) eta=02:58:12 | 41.8K token/s | 
[epoch_0]_55261  loss=3.035052 |g|=0.523	lr=1.93e-05 | 27.0%@S46  T=1.82s(data=1.6ms QKV=2.13s FFN=3.04s) eta=02:55:30 | 42.0K token/s | 
[epoch_0]_55271  loss=2.971774 |g|=0.479	lr=1.92e-05 | 27.8%@S46  T=1.79s(data=1.5ms QKV=2.12s FFN=3.04s) eta=02:52:01 | 42.2K token/s | 
[epoch_0]_55281  loss=3.040373 |g|=0.49	lr=1.92e-05 | 28.6%@S46  T=1.80s(data=1.5ms QKV=2.12s FFN=3.04s) eta=02:52:13 | 42.3K token/s | 
[epoch_0]_55291  loss=3.012393 |g|=0.506	lr=1.91e-05 | 29.5%@S46  T=1.82s(data=1.5ms QKV=2.12s FFN=3.04s) eta=02:54:35 | 42.5K token/s | 
[Fuyou] head="0" update algorithm=4 t=10.64s
[Section@55300] layer[8-16] tasks=19(nPassBack=0) last_loss=3.06648(-0.081717) N=(772,62608,62048 7299468)
[epoch_0]_55301  loss=3.074519 |g|=0.506	lr=1.91e-05 | 30.3%@S46  T=4.88s(data=2.2ms QKV=2.13s FFN=3.03s) eta=07:46:42 | 41.2K token/s | 
[epoch_0]_55311  loss=3.016413 |g|=0.502	lr=1.91e-05 | 31.1%@S46  T=1.81s(data=1.9ms QKV=2.13s FFN=3.04s) eta=02:52:34 | 41.4K token/s | 
[epoch_0]_55321  loss=2.961371 |g|=0.497	lr=1.90e-05 | 31.9%@S46  T=1.78s(data=1.5ms QKV=2.13s FFN=3.04s) eta=02:49:07 | 41.6K token/s | 
[epoch_0]_55331  loss=3.076208 |g|=0.5	lr=1.90e-05 | 32.7%@S46  T=1.82s(data=1.7ms QKV=2.13s FFN=3.04s) eta=02:52:59 | 41.8K token/s | 
[epoch_0]_55341  loss=3.033572 |g|=0.487	lr=1.89e-05 | 33.5%@S46  T=1.84s(data=1.7ms QKV=2.13s FFN=3.04s) eta=02:55:02 | 41.9K token/s | 
[epoch_0]_55351  loss=2.985113 |g|=0.485	lr=1.89e-05 | 34.4%@S46  T=1.81s(data=1.8ms QKV=2.13s FFN=3.04s) eta=02:51:17 | 42.1K token/s | 
[epoch_0]_55361  loss=2.992040 |g|=0.486	lr=1.88e-05 | 35.2%@S46  T=1.82s(data=1.5ms QKV=2.13s FFN=3.04s) eta=02:51:50 | 42.2K token/s | 
[epoch_0]_55371  loss=3.027338 |g|=0.51	lr=1.88e-05 | 36.0%@S46  T=1.82s(data=1.5ms QKV=2.13s FFN=3.04s) eta=02:51:54 | 42.4K token/s | 
[epoch_0]_55381  loss=2.917330 |g|=0.498	lr=1.87e-05 | 36.8%@S46  T=1.82s(data=1.6ms QKV=2.13s FFN=3.04s) eta=02:51:49 | 42.5K token/s | 
[epoch_0]_55391  loss=3.108672 |g|=0.516	lr=1.87e-05 | 37.6%@S46  T=1.83s(data=1.8ms QKV=2.13s FFN=3.04s) eta=02:52:16 | 42.6K token/s | 
[Fuyou] head="1" update algorithm=4 t=10.31s
[eval] 
	 Loss@"edu_fineweb1B"=3.051(0.00076) nBranch=1 nToken=6.31M best=3.0522(275) E2T=0.0331 T=36.7432(0)s x=0
	#3.05144±0.0973 tps=172K(6.30784M) a=[2.86267,3.33125] T=36.7432(sec)
[Section@55400] layer[16-24] tasks=19(nPassBack=0) last_loss=3.01838(-0.045558) N=(772,62720,62160 7312668)
[epoch_0]_55401  loss=3.027206 |g|=0.521	lr=1.86e-05 | 38.5%@S46  T=12.43s(data=1.9ms QKV=2.12s FFN=3.04s) eta=19:27:25 | 40.8K token/s | 
[epoch_0]_55411  loss=2.995138 |g|=0.498	lr=1.86e-05 | 39.3%@S46  T=1.83s(data=1.8ms QKV=2.12s FFN=3.04s) eta=02:51:36 | 41.0K token/s | 
[epoch_0]_55421  loss=2.985807 |g|=0.496	lr=1.86e-05 | 40.1%@S46  T=1.80s(data=1.6ms QKV=2.12s FFN=3.04s) eta=02:48:51 | 41.2K token/s | 
[epoch_0]_55431  loss=3.064245 |g|=0.507	lr=1.85e-05 | 40.9%@S46  T=1.82s(data=2.0ms QKV=2.12s FFN=3.04s) eta=02:50:19 | 41.4K token/s | 
[epoch_0]_55441  loss=3.089157 |g|=0.495	lr=1.85e-05 | 41.7%@S46  T=1.80s(data=1.7ms QKV=2.12s FFN=3.04s) eta=02:47:29 | 41.6K token/s | 
[epoch_0]_55451  loss=2.965974 |g|=0.503	lr=1.84e-05 | 42.6%@S46  T=1.83s(data=1.7ms QKV=2.13s FFN=3.04s) eta=02:50:33 | 41.8K token/s | 
[epoch_0]_55461  loss=2.942996 |g|=0.521	lr=1.84e-05 | 43.4%@S46  T=1.82s(data=1.7ms QKV=2.12s FFN=3.04s) eta=02:49:23 | 41.9K token/s | 
[epoch_0]_55471  loss=3.019539 |g|=0.506	lr=1.83e-05 | 44.2%@S46  T=1.80s(data=1.7ms QKV=2.12s FFN=3.04s) eta=02:47:02 | 42.1K token/s | 
[epoch_0]_55481  loss=3.087336 |g|=0.496	lr=1.83e-05 | 45.0%@S46  T=1.81s(data=2.0ms QKV=2.12s FFN=3.04s) eta=02:47:43 | 42.3K token/s | 
[epoch_0]_55491  loss=3.030955 |g|=0.494	lr=1.82e-05 | 45.8%@S46  T=1.81s(data=1.6ms QKV=2.12s FFN=3.04s) eta=02:47:31 | 42.4K token/s | 
[Fuyou] head="2" update algorithm=4 t=9.72s
[Section@55500] layer[24-32] tasks=19(nPassBack=0) last_loss=2.98108(0.0304837) N=(772,62832,62272 7325868)
[epoch_0]_55501  loss=3.054138 |g|=0.54	lr=1.82e-05 | 46.7%@S46  T=4.37s(data=1.8ms QKV=2.13s FFN=3.03s) eta=06:43:10 | 41.2K token/s | 
[epoch_0]_55511  loss=3.040408 |g|=0.511	lr=1.82e-05 | 47.5%@S46  T=1.80s(data=1.7ms QKV=2.13s FFN=3.04s) eta=02:45:34 | 41.4K token/s | 
[epoch_0]_55521  loss=3.091438 |g|=0.505	lr=1.81e-05 | 48.3%@S46  T=1.78s(data=1.7ms QKV=2.13s FFN=3.04s) eta=02:43:41 | 41.7K token/s | 
[epoch_0]_55531  loss=3.081347 |g|=0.506	lr=1.81e-05 | 49.1%@S46  T=1.79s(data=1.6ms QKV=2.13s FFN=3.04s) eta=02:44:29 | 41.9K token/s | 
[epoch_0]_55541  loss=3.006862 |g|=0.488	lr=1.80e-05 | 49.9%@S46  T=1.81s(data=1.7ms QKV=2.13s FFN=3.04s) eta=02:45:57 | 42.0K token/s | 
[epoch_0]_55551  loss=2.990395 |g|=0.504	lr=1.80e-05 | 50.8%@S46  T=1.82s(data=1.8ms QKV=2.14s FFN=3.04s) eta=02:46:32 | 42.2K token/s | 
[epoch_0]_55561  loss=2.964706 |g|=0.497	lr=1.79e-05 | 51.6%@S46  T=1.82s(data=1.8ms QKV=2.13s FFN=3.04s) eta=02:46:22 | 42.3K token/s | 
[epoch_0]_55571  loss=3.059205 |g|=0.494	lr=1.79e-05 | 52.4%@S46  T=1.80s(data=1.7ms QKV=2.13s FFN=3.04s) eta=02:44:16 | 42.5K token/s | 
[epoch_0]_55581  loss=2.982418 |g|=0.49	lr=1.79e-05 | 53.2%@S46  T=1.81s(data=1.8ms QKV=2.13s FFN=3.04s) eta=02:44:11 | 42.6K token/s | 
[epoch_0]_55591  loss=3.028792 |g|=0.496	lr=1.78e-05 | 54.0%@S46  T=1.79s(data=1.6ms QKV=2.13s FFN=3.04s) eta=02:42:19 | 42.8K token/s | 
[Fuyou] head="3" update algorithm=4 t=11.78s
[eval] 
	 Loss@"edu_fineweb1B"=3.050(0.00096) nBranch=1 nToken=6.31M best=3.0514(276) E2T=-0.0138 T=36.7509(0)s x=0
	#3.05047±0.0973 tps=172K(6.30784M) a=[2.86277,3.33038] T=36.7509(sec)
[Section@55600] layer[32-40] tasks=19(nPassBack=0) last_loss=3.06431(-0.0211699) N=(772,62944,62384 7339068)
[epoch_0]_55601  loss=3.016005 |g|=0.511	lr=1.78e-05 | 54.8%@S46  T=12.07s(data=2.2ms QKV=2.12s FFN=3.04s) eta=18:12:42 | 41.0K token/s | 
[epoch_0]_55611  loss=2.949483 |g|=0.49	lr=1.77e-05 | 55.7%@S46  T=1.82s(data=1.9ms QKV=2.12s FFN=3.04s) eta=02:44:32 | 41.2K token/s | 
[epoch_0]_55621  loss=3.072434 |g|=0.514	lr=1.77e-05 | 56.5%@S46  T=1.82s(data=1.6ms QKV=2.12s FFN=3.04s) eta=02:44:22 | 41.4K token/s | 
[epoch_0]_55631  loss=3.069447 |g|=0.497	lr=1.76e-05 | 57.3%@S46  T=1.79s(data=1.6ms QKV=2.12s FFN=3.04s) eta=02:40:52 | 41.6K token/s | 
[epoch_0]_55641  loss=3.031971 |g|=0.507	lr=1.76e-05 | 58.1%@S46  T=1.81s(data=1.7ms QKV=2.12s FFN=3.05s) eta=02:43:04 | 41.8K token/s | 
[epoch_0]_55651  loss=3.042866 |g|=0.499	lr=1.76e-05 | 58.9%@S46  T=1.83s(data=1.7ms QKV=2.12s FFN=3.04s) eta=02:44:02 | 41.9K token/s | 
[epoch_0]_55661  loss=3.030576 |g|=0.502	lr=1.75e-05 | 59.8%@S46  T=1.81s(data=1.5ms QKV=2.12s FFN=3.04s) eta=02:42:09 | 42.1K token/s | 
[epoch_0]_55671  loss=3.068086 |g|=0.501	lr=1.75e-05 | 60.6%@S46  T=1.87s(data=1.6ms QKV=2.13s FFN=3.04s) eta=02:47:02 | 42.2K token/s | 
[epoch_0]_55681  loss=3.060436 |g|=0.488	lr=1.74e-05 | 61.4%@S46  T=1.90s(data=1.7ms QKV=2.13s FFN=3.04s) eta=02:49:12 | 42.2K token/s | 
[epoch_0]_55691  loss=3.076289 |g|=0.497	lr=1.74e-05 | 62.2%@S46  T=1.83s(data=1.8ms QKV=2.12s FFN=3.04s) eta=02:42:38 | 42.4K token/s | 
[Fuyou] head="4" update algorithm=4 t=11.92s
[Section@55700] layer[40-48] tasks=19(nPassBack=0) last_loss=2.98166(0.00362253) N=(772,63056,62496 7352268)
[epoch_0]_55701  loss=3.008907 |g|=0.494	lr=1.73e-05 | 63.0%@S46  T=4.24s(data=2.0ms QKV=2.13s FFN=3.03s) eta=06:17:14 | 41.2K token/s | 
[epoch_0]_55711  loss=3.011052 |g|=0.499	lr=1.73e-05 | 63.9%@S46  T=1.77s(data=1.6ms QKV=2.13s FFN=3.04s) eta=02:37:28 | 41.5K token/s | 
[epoch_0]_55721  loss=2.999144 |g|=0.506	lr=1.73e-05 | 64.7%@S46  T=1.82s(data=1.7ms QKV=2.13s FFN=3.04s) eta=02:40:52 | 41.6K token/s | 
[epoch_0]_55731  loss=3.053513 |g|=0.495	lr=1.72e-05 | 65.5%@S46  T=1.82s(data=1.6ms QKV=2.13s FFN=3.04s) eta=02:40:58 | 41.8K token/s | 
[epoch_0]_55741  loss=3.082215 |g|=0.501	lr=1.72e-05 | 66.3%@S46  T=1.79s(data=1.5ms QKV=2.13s FFN=3.04s) eta=02:38:12 | 42.0K token/s | 
[epoch_0]_55751  loss=3.026143 |g|=0.485	lr=1.71e-05 | 67.1%@S46  T=1.86s(data=1.5ms QKV=2.13s FFN=3.04s) eta=02:43:54 | 42.1K token/s | 
[epoch_0]_55761  loss=2.937888 |g|=0.506	lr=1.71e-05 | 68.0%@S46  T=1.80s(data=1.8ms QKV=2.13s FFN=3.04s) eta=02:37:47 | 42.3K token/s | 
[epoch_0]_55771  loss=3.060279 |g|=0.495	lr=1.71e-05 | 68.8%@S46  T=1.84s(data=1.7ms QKV=2.13s FFN=3.04s) eta=02:40:59 | 42.4K token/s | 
[epoch_0]_55781  loss=3.074784 |g|=0.503	lr=1.70e-05 | 69.6%@S46  T=1.81s(data=1.7ms QKV=2.13s FFN=3.04s) eta=02:38:04 | 42.5K token/s | 
[epoch_0]_55791  loss=3.055392 |g|=0.495	lr=1.70e-05 | 70.4%@S46  T=1.83s(data=1.8ms QKV=2.13s FFN=3.04s) eta=02:39:50 | 42.7K token/s | 
[Fuyou] head="5" update algorithm=4 t=11.98s
[eval] 
	 Loss@"edu_fineweb1B"=3.050(0.00062) nBranch=1 nToken=6.31M best=3.0505(277) E2T=0.0411 T=36.7463(0)s x=0
	#3.04986±0.0972 tps=172K(6.30784M) a=[2.86218,3.33058] T=36.7463(sec)
[Section@55800] layer[0-8] tasks=19(nPassBack=0) last_loss=3.00871(0.0303459) N=(772,63168,62608 7365468)
[epoch_0]_55801  loss=3.005056 |g|=0.509	lr=1.69e-05 | 71.2%@S46  T=12.42s(data=1.6ms QKV=2.12s FFN=3.04s) eta=18:03:24 | 40.9K token/s | 
[epoch_0]_55811  loss=3.011319 |g|=0.496	lr=1.69e-05 | 72.0%@S46  T=1.79s(data=1.7ms QKV=2.12s FFN=3.04s) eta=02:35:54 | 41.1K token/s | 
[epoch_0]_55821  loss=2.957267 |g|=0.498	lr=1.68e-05 | 72.9%@S46  T=1.81s(data=1.6ms QKV=2.12s FFN=3.04s) eta=02:37:29 | 41.3K token/s | 
[epoch_0]_55831  loss=3.107156 |g|=0.503	lr=1.68e-05 | 73.7%@S46  T=1.84s(data=1.7ms QKV=2.13s FFN=3.04s) eta=02:39:28 | 41.5K token/s | 
[epoch_0]_55841  loss=3.081608 |g|=0.496	lr=1.68e-05 | 74.5%@S46  T=1.81s(data=1.8ms QKV=2.13s FFN=3.04s) eta=02:36:29 | 41.7K token/s | 
[epoch_0]_55851  loss=3.066134 |g|=0.505	lr=1.67e-05 | 75.3%@S46  T=1.81s(data=1.8ms QKV=2.13s FFN=3.04s) eta=02:36:09 | 41.8K token/s | 
[epoch_0]_55861  loss=2.925013 |g|=0.492	lr=1.67e-05 | 76.1%@S46  T=1.79s(data=1.6ms QKV=2.12s FFN=3.04s) eta=02:34:45 | 42.0K token/s | 
[epoch_0]_55871  loss=2.926799 |g|=0.496	lr=1.66e-05 | 77.0%@S46  T=1.80s(data=1.6ms QKV=2.13s FFN=3.04s) eta=02:34:52 | 42.2K token/s | 
[epoch_0]_55881  loss=3.022249 |g|=0.5	lr=1.66e-05 | 77.8%@S46  T=1.83s(data=1.7ms QKV=2.13s FFN=3.04s) eta=02:37:01 | 42.3K token/s | 
[epoch_0]_55891  loss=2.955077 |g|=0.49	lr=1.66e-05 | 78.6%@S46  T=1.78s(data=1.8ms QKV=2.12s FFN=3.04s) eta=02:32:37 | 42.5K token/s | 
[Fuyou] head="0" update algorithm=4 t=11.97s
[Section@55900] layer[8-16] tasks=19(nPassBack=0) last_loss=2.96424(0.102243) N=(772,63280,62720 7378668)
[epoch_0]_55901  loss=2.962598 |g|=0.521	lr=1.65e-05 | 79.4%@S46  T=4.79s(data=2.0ms QKV=2.13s FFN=3.03s) eta=06:49:31 | 41.3K token/s | 
[epoch_0]_55911  loss=3.057964 |g|=0.49	lr=1.65e-05 | 80.2%@S46  T=1.84s(data=1.7ms QKV=2.13s FFN=3.04s) eta=02:37:33 | 41.4K token/s | 
[epoch_0]_55921  loss=2.995382 |g|=0.488	lr=1.64e-05 | 81.1%@S46  T=1.83s(data=1.9ms QKV=2.14s FFN=3.04s) eta=02:36:02 | 41.6K token/s | 
[epoch_0]_55931  loss=2.976318 |g|=0.498	lr=1.64e-05 | 81.9%@S46  T=1.78s(data=1.6ms QKV=2.14s FFN=3.04s) eta=02:31:38 | 41.8K token/s | 
[epoch_0]_55941  loss=3.016825 |g|=0.482	lr=1.64e-05 | 82.7%@S46  T=1.81s(data=1.8ms QKV=2.14s FFN=3.04s) eta=02:33:39 | 42.0K token/s | 
[epoch_0]_55951  loss=3.018728 |g|=0.483	lr=1.63e-05 | 83.5%@S46  T=1.80s(data=1.8ms QKV=2.14s FFN=3.04s) eta=02:32:17 | 42.1K token/s | 
[epoch_0]_55961  loss=3.020561 |g|=0.483	lr=1.63e-05 | 84.3%@S46  T=1.78s(data=1.5ms QKV=2.14s FFN=3.04s) eta=02:30:23 | 42.3K token/s | 
[epoch_0]_55971  loss=3.038202 |g|=0.508	lr=1.62e-05 | 85.2%@S46  T=1.82s(data=1.7ms QKV=2.14s FFN=3.04s) eta=02:33:25 | 42.5K token/s | 
[epoch_0]_55981  loss=3.004311 |g|=0.495	lr=1.62e-05 | 86.0%@S46  T=1.82s(data=2.1ms QKV=2.14s FFN=3.04s) eta=02:33:25 | 42.6K token/s | 
[epoch_0]_55991  loss=3.085839 |g|=0.498	lr=1.62e-05 | 86.8%@S46  T=1.80s(data=2.0ms QKV=2.15s FFN=3.04s) eta=02:31:20 | 42.8K token/s | 
[Fuyou] head="1" update algorithm=4 t=11.08s
[eval] 
	 Loss@"edu_fineweb1B"=3.049(0.00076) nBranch=1 nToken=6.31M best=3.0499(278) E2T=-0.00434 T=36.7413(0)s x=0
	#3.0491±0.0973 tps=172K(6.30784M) a=[2.85917,3.32972] T=36.7413(sec)
[Section@56000] layer[16-24] tasks=19(nPassBack=0) last_loss=3.05343(-0.0350573) N=(772,63392,62832 7391868)
[epoch_0]_56001  loss=3.027218 |g|=0.508	lr=1.61e-05 | 87.6%@S46  T=12.52s(data=1.9ms QKV=2.12s FFN=3.04s) eta=17:30:29 | 40.9K token/s | 
[epoch_0]_56011  loss=3.085968 |g|=0.495	lr=1.61e-05 | 88.4%@S46  T=1.78s(data=1.7ms QKV=2.12s FFN=3.04s) eta=02:28:42 | 41.2K token/s | 
[epoch_0]_56021  loss=3.105916 |g|=0.497	lr=1.60e-05 | 89.3%@S46  T=1.81s(data=1.8ms QKV=2.12s FFN=3.04s) eta=02:31:12 | 41.4K token/s | 
[epoch_0]_56031  loss=2.992621 |g|=0.485	lr=1.60e-05 | 90.1%@S46  T=1.81s(data=1.6ms QKV=2.12s FFN=3.04s) eta=02:31:00 | 41.6K token/s | 
[epoch_0]_56041  loss=3.020555 |g|=0.514	lr=1.60e-05 | 90.9%@S46  T=1.82s(data=1.6ms QKV=2.13s FFN=3.04s) eta=02:31:47 | 41.8K token/s | 
[epoch_0]_56051  loss=3.001281 |g|=0.502	lr=1.59e-05 | 91.7%@S46  T=1.86s(data=1.7ms QKV=2.12s FFN=3.04s) eta=02:34:26 | 41.9K token/s | 
[epoch_0]_56061  loss=3.067132 |g|=0.513	lr=1.59e-05 | 92.5%@S46  T=1.85s(data=1.9ms QKV=2.13s FFN=3.04s) eta=02:33:15 | 42.0K token/s | 
[epoch_0]_56071  loss=2.978817 |g|=0.506	lr=1.58e-05 | 93.3%@S46  T=1.81s(data=1.7ms QKV=2.13s FFN=3.04s) eta=02:29:40 | 42.2K token/s | 
[epoch_0]_56081  loss=2.962603 |g|=0.506	lr=1.58e-05 | 94.2%@S46  T=1.83s(data=1.7ms QKV=2.13s FFN=3.04s) eta=02:31:05 | 42.3K token/s | 
[epoch_0]_56091  loss=3.010146 |g|=0.502	lr=1.58e-05 | 95.0%@S46  T=1.82s(data=1.6ms QKV=2.13s FFN=3.04s) eta=02:29:52 | 42.4K token/s | 
[Fuyou] head="2" update algorithm=4 t=9.60s
[Section@56100] layer[24-32] tasks=19(nPassBack=0) last_loss=2.9968(-0.0157225) N=(772,63504,62944 7405068)
[epoch_0]_56101  loss=3.063800 |g|=0.508	lr=1.57e-05 | 95.8%@S46  T=4.81s(data=2.2ms QKV=2.13s FFN=3.03s) eta=06:35:30 | 41.2K token/s | 
[epoch_0]_56111  loss=3.047522 |g|=0.499	lr=1.57e-05 | 96.6%@S46  T=1.83s(data=2.1ms QKV=2.13s FFN=3.04s) eta=02:29:55 | 41.3K token/s | 
[epoch_0]_56121  loss=3.010905 |g|=0.49	lr=1.56e-05 | 97.4%@S46  T=1.84s(data=1.6ms QKV=2.13s FFN=3.04s) eta=02:30:50 | 41.5K token/s | 
[epoch_0]_56131  loss=3.022617 |g|=0.505	lr=1.56e-05 | 98.3%@S46  T=1.83s(data=1.8ms QKV=2.14s FFN=3.04s) eta=02:29:14 | 41.7K token/s | 
[epoch_0]_56141  loss=2.957572 |g|=0.497	lr=1.56e-05 | 99.1%@S46  T=1.83s(data=1.7ms QKV=2.13s FFN=3.04s) eta=02:29:04 | 41.8K token/s | 
[epoch_0]_56151  loss=3.049696 |g|=0.48	lr=1.55e-05 | 99.9%@S46  T=1.78s(data=1.7ms QKV=2.14s FFN=3.04s) eta=02:25:02 | 42.0K token/s | 
[epoch_0]_56152  loss=3.029493 |g|=0.498	lr=1.55e-05 | 100.0%@S46  T=1.82s(data=1.5ms QKV=2.13s FFN=3.04s) eta=02:28:04 | 42.2K token/s | 
-------- End of shard_46@"./Datasets/edu_fineweb1B/edu_fineweb_train_000804.bin"-------- 
[shard-47]@"./Datasets/edu_fineweb1B/edu_fineweb_train_000805.bin": tokens=100(M) nShardSamples=1220(4589832) 
[epoch_0]_56161  loss=3.050301 |g|=0.496	lr=1.55e-05 | 0.7%@S47  T=1.86s(data=1.6ms QKV=2.14s FFN=3.04s) eta=02:30:58 | 42.3K token/s | 
[epoch_0]_56171  loss=3.098386 |g|=0.492	lr=1.54e-05 | 1.5%@S47  T=1.82s(data=2.0ms QKV=2.13s FFN=3.04s) eta=02:27:52 | 42.4K token/s | 
[epoch_0]_56181  loss=2.963015 |g|=0.491	lr=1.54e-05 | 2.4%@S47  T=1.83s(data=1.9ms QKV=2.14s FFN=3.04s) eta=02:27:53 | 42.5K token/s | 
[epoch_0]_56191  loss=2.974465 |g|=0.494	lr=1.54e-05 | 3.2%@S47  T=1.81s(data=2.0ms QKV=2.14s FFN=3.04s) eta=02:26:03 | 42.7K token/s | 
[Fuyou] head="3" update algorithm=4 t=11.15s
[eval] 
	 Loss@"edu_fineweb1B"=3.049(8.9e-05) nBranch=1 nToken=6.31M best=3.0491(279) E2T=-0.00193 T=36.7298(0)s x=0
	#3.04901±0.0974 tps=172K(6.30784M) a=[2.85956,3.32882] T=36.7298(sec)
[Section@56200] layer[32-40] tasks=19(nPassBack=0) last_loss=3.05094(0.0133724) N=(772,63616,63056 7418268)
[epoch_0]_56201  loss=3.017899 |g|=0.5	lr=1.53e-05 | 4.0%@S47  T=12.36s(data=1.9ms QKV=2.12s FFN=3.04s) eta=16:35:35 | 40.9K token/s | 
[epoch_0]_56211  loss=3.053947 |g|=0.491	lr=1.53e-05 | 4.8%@S47  T=1.89s(data=2.0ms QKV=2.12s FFN=3.04s) eta=02:31:59 | 41.0K token/s | 
[epoch_0]_56221  loss=3.056783 |g|=0.508	lr=1.53e-05 | 5.6%@S47  T=1.84s(data=2.0ms QKV=2.12s FFN=3.04s) eta=02:27:23 | 41.2K token/s | 
[epoch_0]_56231  loss=3.102788 |g|=0.509	lr=1.52e-05 | 6.5%@S47  T=1.84s(data=1.6ms QKV=2.12s FFN=3.04s) eta=02:27:13 | 41.3K token/s | 
[epoch_0]_56241  loss=3.056658 |g|=0.503	lr=1.52e-05 | 7.3%@S47  T=1.86s(data=1.8ms QKV=2.13s FFN=3.04s) eta=02:28:52 | 41.5K token/s | 
[epoch_0]_56251  loss=3.027088 |g|=0.49	lr=1.51e-05 | 8.1%@S47  T=1.83s(data=1.7ms QKV=2.13s FFN=3.04s) eta=02:25:45 | 41.6K token/s | 
[epoch_0]_56261  loss=3.005311 |g|=0.501	lr=1.51e-05 | 8.9%@S47  T=1.85s(data=1.7ms QKV=2.12s FFN=3.04s) eta=02:27:23 | 41.8K token/s | 
[epoch_0]_56271  loss=3.053772 |g|=0.503	lr=1.51e-05 | 9.7%@S47  T=1.84s(data=1.4ms QKV=2.13s FFN=3.04s) eta=02:26:19 | 41.9K token/s | 
[epoch_0]_56281  loss=3.056583 |g|=0.498	lr=1.50e-05 | 10.6%@S47  T=1.82s(data=1.3ms QKV=2.12s FFN=3.04s) eta=02:24:26 | 42.1K token/s | 
[epoch_0]_56291  loss=3.011219 |g|=0.509	lr=1.50e-05 | 11.4%@S47  T=1.82s(data=1.7ms QKV=2.13s FFN=3.04s) eta=02:24:11 | 42.2K token/s | 
[Fuyou] head="4" update algorithm=4 t=11.09s
[Section@56300] layer[40-48] tasks=19(nPassBack=0) last_loss=3.02682(-0.0451679) N=(772,63728,63168 7431468)
[epoch_0]_56301  loss=3.045539 |g|=0.525	lr=1.49e-05 | 12.2%@S47  T=4.23s(data=1.7ms QKV=2.13s FFN=3.03s) eta=05:33:43 | 41.1K token/s | 
[epoch_0]_56311  loss=2.984052 |g|=0.491	lr=1.49e-05 | 13.0%@S47  T=1.79s(data=1.7ms QKV=2.13s FFN=3.04s) eta=02:20:41 | 41.3K token/s | 
[epoch_0]_56321  loss=3.027988 |g|=0.49	lr=1.49e-05 | 13.8%@S47  T=1.86s(data=1.6ms QKV=2.13s FFN=3.04s) eta=02:26:18 | 41.4K token/s | 
[epoch_0]_56331  loss=3.017181 |g|=0.495	lr=1.48e-05 | 14.6%@S47  T=1.81s(data=1.7ms QKV=2.14s FFN=3.04s) eta=02:21:38 | 41.6K token/s | 
[epoch_0]_56341  loss=2.978904 |g|=0.497	lr=1.48e-05 | 15.5%@S47  T=1.80s(data=1.8ms QKV=2.13s FFN=3.04s) eta=02:20:55 | 41.8K token/s | 
[epoch_0]_56351  loss=3.019591 |g|=0.509	lr=1.48e-05 | 16.3%@S47  T=1.85s(data=1.5ms QKV=2.13s FFN=3.04s) eta=02:24:24 | 41.9K token/s | 
[epoch_0]_56361  loss=3.031628 |g|=0.509	lr=1.47e-05 | 17.1%@S47  T=1.87s(data=1.9ms QKV=2.13s FFN=3.04s) eta=02:25:25 | 42.0K token/s | 
[epoch_0]_56371  loss=3.036309 |g|=0.492	lr=1.47e-05 | 17.9%@S47  T=1.86s(data=1.6ms QKV=2.14s FFN=3.04s) eta=02:24:20 | 42.1K token/s | 
[epoch_0]_56381  loss=3.059475 |g|=0.503	lr=1.46e-05 | 18.7%@S47  T=1.83s(data=1.6ms QKV=2.14s FFN=3.04s) eta=02:22:09 | 42.3K token/s | 
[epoch_0]_56391  loss=3.091740 |g|=0.493	lr=1.46e-05 | 19.6%@S47  T=1.82s(data=1.7ms QKV=2.14s FFN=3.04s) eta=02:21:08 | 42.4K token/s | 
[Fuyou] head="5" update algorithm=4 t=12.21s
[eval] 
	 Loss@"edu_fineweb1B"=3.049(0.00018) nBranch=1 nToken=6.31M best=3.0490(280) E2T=0.0195 T=36.7424(0)s x=0
	#3.04882±0.0973 tps=172K(6.30784M) a=[2.85981,3.32865] T=36.7424(sec)
[Section@56400] layer[0-8] tasks=19(nPassBack=0) last_loss=3.02937(-0.0206656) N=(772,63840,63280 7444668)
[epoch_0]_56401  loss=3.091228 |g|=0.509	lr=1.46e-05 | 20.4%@S47  T=12.34s(data=1.6ms QKV=2.12s FFN=3.04s) eta=15:53:18 | 40.6K token/s | 
[epoch_0]_56411  loss=3.036014 |g|=0.499	lr=1.45e-05 | 21.2%@S47  T=1.81s(data=1.6ms QKV=2.13s FFN=3.04s) eta=02:19:47 | 40.8K token/s | 
[epoch_0]_56421  loss=2.993792 |g|=0.503	lr=1.45e-05 | 22.0%@S47  T=1.82s(data=1.7ms QKV=2.13s FFN=3.04s) eta=02:20:03 | 41.0K token/s | 
[epoch_0]_56431  loss=2.984423 |g|=0.503	lr=1.45e-05 | 22.8%@S47  T=1.79s(data=1.7ms QKV=2.12s FFN=3.04s) eta=02:17:22 | 41.3K token/s | 
[epoch_0]_56441  loss=3.081324 |g|=0.506	lr=1.44e-05 | 23.7%@S47  T=1.81s(data=1.7ms QKV=2.12s FFN=3.04s) eta=02:18:14 | 41.5K token/s | 
[epoch_0]_56451  loss=3.026588 |g|=0.504	lr=1.44e-05 | 24.5%@S47  T=1.79s(data=1.7ms QKV=2.12s FFN=3.04s) eta=02:16:47 | 41.7K token/s | 
[epoch_0]_56461  loss=2.974458 |g|=0.507	lr=1.44e-05 | 25.3%@S47  T=1.79s(data=1.5ms QKV=2.13s FFN=3.04s) eta=02:16:31 | 41.9K token/s | 
[epoch_0]_56471  loss=2.983099 |g|=0.507	lr=1.43e-05 | 26.1%@S47  T=1.79s(data=1.6ms QKV=2.12s FFN=3.04s) eta=02:16:02 | 42.1K token/s | 
[epoch_0]_56481  loss=3.054502 |g|=0.49	lr=1.43e-05 | 26.9%@S47  T=1.78s(data=1.4ms QKV=2.12s FFN=3.04s) eta=02:14:55 | 42.3K token/s | 
[epoch_0]_56491  loss=3.014617 |g|=0.481	lr=1.42e-05 | 27.8%@S47  T=1.81s(data=1.5ms QKV=2.13s FFN=3.04s) eta=02:17:14 | 42.4K token/s | 
[Fuyou] head="0" update algorithm=4 t=10.41s
[Section@56500] layer[8-16] tasks=19(nPassBack=0) last_loss=3.0143(-0.0500555) N=(772,63952,63392 7457868)
[epoch_0]_56501  loss=3.031452 |g|=0.492	lr=1.42e-05 | 28.6%@S47  T=4.87s(data=2.2ms QKV=2.13s FFN=3.03s) eta=06:07:40 | 41.2K token/s | 
[epoch_0]_56511  loss=2.970628 |g|=0.489	lr=1.42e-05 | 29.4%@S47  T=1.77s(data=1.7ms QKV=2.13s FFN=3.04s) eta=02:13:17 | 41.4K token/s | 
[epoch_0]_56521  loss=3.003192 |g|=0.489	lr=1.41e-05 | 30.2%@S47  T=1.79s(data=2.9ms QKV=2.13s FFN=3.04s) eta=02:14:47 | 41.6K token/s | 
[epoch_0]_56531  loss=3.034272 |g|=0.499	lr=1.41e-05 | 31.0%@S47  T=1.83s(data=1.6ms QKV=2.13s FFN=3.04s) eta=02:17:37 | 41.8K token/s | 
[epoch_0]_56541  loss=3.028454 |g|=0.501	lr=1.41e-05 | 31.9%@S47  T=1.91s(data=2.0ms QKV=2.13s FFN=3.04s) eta=02:23:21 | 41.8K token/s | 
[epoch_0]_56551  loss=2.933495 |g|=0.482	lr=1.40e-05 | 32.7%@S47  T=1.79s(data=1.5ms QKV=2.13s FFN=3.04s) eta=02:14:07 | 42.0K token/s | 
[epoch_0]_56561  loss=3.036803 |g|=0.501	lr=1.40e-05 | 33.5%@S47  T=1.83s(data=1.7ms QKV=2.14s FFN=3.04s) eta=02:16:46 | 42.2K token/s | 
[epoch_0]_56571  loss=2.998872 |g|=0.491	lr=1.40e-05 | 34.3%@S47  T=1.79s(data=1.7ms QKV=2.13s FFN=3.04s) eta=02:13:23 | 42.3K token/s | 
[epoch_0]_56581  loss=3.060880 |g|=0.506	lr=1.39e-05 | 35.1%@S47  T=1.83s(data=1.8ms QKV=2.13s FFN=3.04s) eta=02:15:33 | 42.5K token/s | 
[epoch_0]_56591  loss=3.100982 |g|=0.507	lr=1.39e-05 | 35.9%@S47  T=1.80s(data=2.0ms QKV=2.14s FFN=3.04s) eta=02:12:57 | 42.6K token/s | 
[Fuyou] head="1" update algorithm=4 t=9.73s
[eval] 
	 Loss@"edu_fineweb1B"=3.048(0.00057) nBranch=1 nToken=6.31M best=3.0488(281) E2T=0.0254 T=36.7441(0)s x=0
	#3.04825±0.0975 tps=172K(6.30784M) a=[2.85882,3.32878] T=36.7441(sec)
[Section@56600] layer[16-24] tasks=19(nPassBack=0) last_loss=3.02288(0.0305576) N=(772,64064,63504 7471068)
[epoch_0]_56601  loss=3.072992 |g|=0.493	lr=1.39e-05 | 36.8%@S47  T=12.38s(data=2.0ms QKV=2.12s FFN=3.04s) eta=15:15:14 | 40.8K token/s | 
[epoch_0]_56611  loss=3.003628 |g|=0.511	lr=1.38e-05 | 37.6%@S47  T=1.81s(data=1.8ms QKV=2.12s FFN=3.04s) eta=02:13:42 | 41.0K token/s | 
[epoch_0]_56621  loss=2.967406 |g|=0.5	lr=1.38e-05 | 38.4%@S47  T=1.81s(data=1.6ms QKV=2.12s FFN=3.04s) eta=02:12:56 | 41.3K token/s | 
[epoch_0]_56631  loss=3.057891 |g|=0.498	lr=1.37e-05 | 39.2%@S47  T=1.82s(data=3.1ms QKV=2.13s FFN=3.04s) eta=02:13:33 | 41.4K token/s | 
[epoch_0]_56641  loss=3.014465 |g|=0.516	lr=1.37e-05 | 40.0%@S47  T=1.81s(data=1.7ms QKV=2.12s FFN=3.04s) eta=02:12:33 | 41.6K token/s | 
[epoch_0]_56651  loss=3.055941 |g|=0.503	lr=1.37e-05 | 40.9%@S47  T=1.81s(data=1.6ms QKV=2.12s FFN=3.04s) eta=02:12:00 | 41.8K token/s | 
[epoch_0]_56661  loss=3.057235 |g|=0.488	lr=1.36e-05 | 41.7%@S47  T=1.85s(data=1.6ms QKV=2.12s FFN=3.04s) eta=02:14:56 | 41.9K token/s | 
[epoch_0]_56671  loss=3.089573 |g|=0.499	lr=1.36e-05 | 42.5%@S47  T=1.80s(data=1.5ms QKV=2.12s FFN=3.04s) eta=02:10:49 | 42.1K token/s | 
[epoch_0]_56681  loss=3.032925 |g|=0.495	lr=1.36e-05 | 43.3%@S47  T=1.82s(data=1.5ms QKV=2.12s FFN=3.04s) eta=02:11:53 | 42.3K token/s | 
[epoch_0]_56691  loss=2.991083 |g|=0.49	lr=1.35e-05 | 44.1%@S47  T=1.80s(data=1.6ms QKV=2.12s FFN=3.04s) eta=02:10:20 | 42.4K token/s | 
[Fuyou] head="2" update algorithm=4 t=11.35s
[Section@56700] layer[24-32] tasks=19(nPassBack=0) last_loss=3.02722(-0.0304232) N=(772,64176,63616 7484268)
[epoch_0]_56701  loss=2.986322 |g|=0.498	lr=1.35e-05 | 45.0%@S47  T=4.79s(data=1.9ms QKV=2.12s FFN=3.03s) eta=05:46:17 | 41.2K token/s | 
[epoch_0]_56711  loss=2.979003 |g|=0.489	lr=1.35e-05 | 45.8%@S47  T=1.81s(data=1.7ms QKV=2.12s FFN=3.04s) eta=02:10:18 | 41.4K token/s | 
[epoch_0]_56721  loss=3.052527 |g|=0.502	lr=1.34e-05 | 46.6%@S47  T=1.80s(data=1.6ms QKV=2.13s FFN=3.04s) eta=02:09:16 | 41.6K token/s | 
[epoch_0]_56731  loss=3.079150 |g|=0.533	lr=1.34e-05 | 47.4%@S47  T=1.80s(data=1.8ms QKV=2.13s FFN=3.04s) eta=02:09:08 | 41.8K token/s | 
[epoch_0]_56741  loss=3.007906 |g|=0.494	lr=1.34e-05 | 48.2%@S47  T=1.80s(data=1.8ms QKV=2.13s FFN=3.04s) eta=02:08:57 | 42.0K token/s | 
[epoch_0]_56751  loss=3.175359 |g|=0.509	lr=1.33e-05 | 49.1%@S47  T=1.80s(data=1.5ms QKV=2.13s FFN=3.04s) eta=02:08:35 | 42.1K token/s | 
[epoch_0]_56761  loss=2.994203 |g|=0.476	lr=1.33e-05 | 49.9%@S47  T=1.79s(data=1.8ms QKV=2.13s FFN=3.04s) eta=02:07:09 | 42.3K token/s | 
[epoch_0]_56771  loss=3.040003 |g|=0.49	lr=1.33e-05 | 50.7%@S47  T=1.79s(data=1.9ms QKV=2.13s FFN=3.04s) eta=02:07:17 | 42.5K token/s | 
[epoch_0]_56781  loss=3.019505 |g|=0.493	lr=1.32e-05 | 51.5%@S47  T=1.79s(data=1.5ms QKV=2.13s FFN=3.04s) eta=02:06:51 | 42.7K token/s | 
[epoch_0]_56791  loss=2.983063 |g|=0.504	lr=1.32e-05 | 52.3%@S47  T=1.80s(data=1.5ms QKV=2.13s FFN=3.04s) eta=02:07:18 | 42.8K token/s | 
[Fuyou] head="3" update algorithm=4 t=11.06s
[eval] 
	 Loss@"edu_fineweb1B"=3.048(0.0001) nBranch=1 nToken=6.31M best=3.0483(282) E2T=0.0388 T=36.7449(0)s x=0
	#3.04815±0.0974 tps=172K(6.30784M) a=[2.85963,3.32825] T=36.7449(sec)
[Section@56800] layer[32-40] tasks=19(nPassBack=0) last_loss=3.00937(0.0415697) N=(772,64288,63728 7497468)
[epoch_0]_56801  loss=3.051892 |g|=0.494	lr=1.32e-05 | 53.2%@S47  T=12.18s(data=2.2ms QKV=2.12s FFN=3.04s) eta=14:19:45 | 41.0K token/s | 
[epoch_0]_56811  loss=2.979369 |g|=0.49	lr=1.31e-05 | 54.0%@S47  T=1.79s(data=1.6ms QKV=2.12s FFN=3.04s) eta=02:05:42 | 41.2K token/s | 
[epoch_0]_56821  loss=3.001789 |g|=0.487	lr=1.31e-05 | 54.8%@S47  T=1.82s(data=1.7ms QKV=2.12s FFN=3.04s) eta=02:07:54 | 41.4K token/s | 
[epoch_0]_56831  loss=3.018133 |g|=0.481	lr=1.31e-05 | 55.6%@S47  T=1.82s(data=3.2ms QKV=2.13s FFN=3.04s) eta=02:07:30 | 41.6K token/s | 
[epoch_0]_56841  loss=3.005402 |g|=0.483	lr=1.30e-05 | 56.4%@S47  T=1.80s(data=1.7ms QKV=2.12s FFN=3.04s) eta=02:05:51 | 41.8K token/s | 
[epoch_0]_56851  loss=2.974505 |g|=0.483	lr=1.30e-05 | 57.2%@S47  T=1.82s(data=1.6ms QKV=2.12s FFN=3.04s) eta=02:06:34 | 42.0K token/s | 
[epoch_0]_56861  loss=3.020082 |g|=0.505	lr=1.30e-05 | 58.1%@S47  T=1.86s(data=1.7ms QKV=2.12s FFN=3.04s) eta=02:09:30 | 42.1K token/s | 
[epoch_0]_56871  loss=3.024458 |g|=0.503	lr=1.29e-05 | 58.9%@S47  T=1.81s(data=1.6ms QKV=2.12s FFN=3.04s) eta=02:05:16 | 42.2K token/s | 
[epoch_0]_56881  loss=3.076588 |g|=0.504	lr=1.29e-05 | 59.7%@S47  T=1.79s(data=1.7ms QKV=2.12s FFN=3.04s) eta=02:04:09 | 42.4K token/s | 
[epoch_0]_56891  loss=3.049691 |g|=0.497	lr=1.29e-05 | 60.5%@S47  T=1.83s(data=1.6ms QKV=2.12s FFN=3.04s) eta=02:06:22 | 42.5K token/s | 
[Fuyou] head="4" update algorithm=4 t=11.87s
[Section@56900] layer[40-48] tasks=19(nPassBack=0) last_loss=3.05704(-0.0302207) N=(772,64400,63840 7510668)
[epoch_0]_56901  loss=3.060186 |g|=0.512	lr=1.28e-05 | 61.3%@S47  T=4.18s(data=3.7ms QKV=2.15s FFN=3.04s) eta=04:47:56 | 41.4K token/s | 
[epoch_0]_56911  loss=3.077841 |g|=0.486	lr=1.28e-05 | 62.2%@S47  T=1.78s(data=1.7ms QKV=2.13s FFN=3.04s) eta=02:02:22 | 41.6K token/s | 
[epoch_0]_56921  loss=3.045714 |g|=0.489	lr=1.28e-05 | 63.0%@S47  T=1.80s(data=1.7ms QKV=2.14s FFN=3.04s) eta=02:03:08 | 41.8K token/s | 
[epoch_0]_56931  loss=3.013819 |g|=0.498	lr=1.27e-05 | 63.8%@S47  T=1.78s(data=1.6ms QKV=2.14s FFN=3.04s) eta=02:01:30 | 42.0K token/s | 
[epoch_0]_56941  loss=2.983497 |g|=0.5	lr=1.27e-05 | 64.6%@S47  T=1.89s(data=1.8ms QKV=2.14s FFN=3.04s) eta=02:08:56 | 42.1K token/s | 
[epoch_0]_56951  loss=2.989151 |g|=0.484	lr=1.27e-05 | 65.4%@S47  T=1.84s(data=1.8ms QKV=2.13s FFN=3.04s) eta=02:05:09 | 42.2K token/s | 
[epoch_0]_56961  loss=2.981286 |g|=0.496	lr=1.26e-05 | 66.3%@S47  T=1.81s(data=1.8ms QKV=2.14s FFN=3.04s) eta=02:02:56 | 42.4K token/s | 
[epoch_0]_56971  loss=3.025930 |g|=0.495	lr=1.26e-05 | 67.1%@S47  T=1.82s(data=1.7ms QKV=2.14s FFN=3.04s) eta=02:03:10 | 42.5K token/s | 
[epoch_0]_56981  loss=3.088932 |g|=0.488	lr=1.26e-05 | 67.9%@S47  T=1.83s(data=1.8ms QKV=2.14s FFN=3.04s) eta=02:03:25 | 42.6K token/s | 
[epoch_0]_56991  loss=2.988231 |g|=0.497	lr=1.25e-05 | 68.7%@S47  T=1.80s(data=1.6ms QKV=2.14s FFN=3.04s) eta=02:01:28 | 42.8K token/s | 
[Fuyou] head="5" update algorithm=4 t=10.67s
[eval] 
	 Loss@"edu_fineweb1B"=3.048(0.00047) nBranch=1 nToken=6.31M best=3.0481(283) E2T=0.0364 T=36.754(0)s x=0
	#3.04768±0.0974 tps=172K(6.30784M) a=[2.85966,3.32771] T=36.754(sec)
[Section@57000] layer[0-8] tasks=19(nPassBack=0) last_loss=3.01132(0.018048) N=(772,64512,63952 7523868)
[epoch_0]_57001  loss=2.984161 |g|=0.506	lr=1.25e-05 | 69.5%@S47  T=12.32s(data=1.8ms QKV=2.13s FFN=3.04s) eta=13:48:26 | 41.0K token/s | 
[epoch_0]_57011  loss=3.004509 |g|=0.498	lr=1.25e-05 | 70.4%@S47  T=1.81s(data=1.8ms QKV=2.13s FFN=3.04s) eta=02:01:25 | 41.2K token/s | 
[epoch_0]_57021  loss=3.029061 |g|=0.487	lr=1.24e-05 | 71.2%@S47  T=1.80s(data=1.8ms QKV=2.13s FFN=3.04s) eta=02:00:06 | 41.4K token/s | 
[epoch_0]_57031  loss=3.089489 |g|=0.498	lr=1.24e-05 | 72.0%@S47  T=1.82s(data=1.8ms QKV=2.13s FFN=3.04s) eta=02:01:22 | 41.6K token/s | 
[epoch_0]_57041  loss=3.082247 |g|=0.512	lr=1.24e-05 | 72.8%@S47  T=1.83s(data=1.9ms QKV=2.13s FFN=3.04s) eta=02:01:53 | 41.7K token/s | 
[epoch_0]_57051  loss=3.020849 |g|=0.491	lr=1.23e-05 | 73.6%@S47  T=1.81s(data=1.5ms QKV=2.13s FFN=3.04s) eta=01:59:56 | 41.9K token/s | 
[epoch_0]_57061  loss=2.984491 |g|=0.496	lr=1.23e-05 | 74.5%@S47  T=1.82s(data=1.7ms QKV=2.13s FFN=3.04s) eta=02:00:22 | 42.1K token/s | 
[epoch_0]_57071  loss=3.106306 |g|=0.491	lr=1.23e-05 | 75.3%@S47  T=1.80s(data=1.6ms QKV=2.13s FFN=3.04s) eta=01:59:06 | 42.2K token/s | 
[epoch_0]_57081  loss=3.058692 |g|=0.495	lr=1.23e-05 | 76.1%@S47  T=1.81s(data=1.7ms QKV=2.13s FFN=3.04s) eta=01:59:29 | 42.4K token/s | 
[epoch_0]_57091  loss=3.032814 |g|=0.501	lr=1.22e-05 | 76.9%@S47  T=1.79s(data=1.9ms QKV=2.13s FFN=3.04s) eta=01:57:41 | 42.6K token/s | 
[Fuyou] head="0" update algorithm=4 t=12.42s
[Section@57100] layer[8-16] tasks=19(nPassBack=0) last_loss=2.98177(0.0325274) N=(772,64624,64064 7537068)
[epoch_0]_57101  loss=3.038164 |g|=0.5	lr=1.22e-05 | 77.7%@S47  T=4.74s(data=1.7ms QKV=2.13s FFN=3.03s) eta=05:10:45 | 41.3K token/s | 
[epoch_0]_57111  loss=3.092692 |g|=0.498	lr=1.22e-05 | 78.5%@S47  T=1.82s(data=1.6ms QKV=2.14s FFN=3.04s) eta=01:58:55 | 41.5K token/s | 
[epoch_0]_57121  loss=3.012639 |g|=0.503	lr=1.21e-05 | 79.4%@S47  T=1.82s(data=1.6ms QKV=2.14s FFN=3.04s) eta=01:58:50 | 41.7K token/s | 
[epoch_0]_57131  loss=3.041377 |g|=0.495	lr=1.21e-05 | 80.2%@S47  T=1.80s(data=2.0ms QKV=2.15s FFN=3.04s) eta=01:57:01 | 41.8K token/s | 
[epoch_0]_57141  loss=3.014239 |g|=0.502	lr=1.21e-05 | 81.0%@S47  T=1.86s(data=1.6ms QKV=2.14s FFN=3.04s) eta=02:01:01 | 42.0K token/s | 
[epoch_0]_57151  loss=3.031654 |g|=0.491	lr=1.20e-05 | 81.8%@S47  T=1.84s(data=1.9ms QKV=2.15s FFN=3.04s) eta=01:59:09 | 42.1K token/s | 
[epoch_0]_57161  loss=3.011734 |g|=0.483	lr=1.20e-05 | 82.6%@S47  T=1.81s(data=1.7ms QKV=2.15s FFN=3.04s) eta=01:56:57 | 42.2K token/s | 
[epoch_0]_57171  loss=2.995019 |g|=0.503	lr=1.20e-05 | 83.5%@S47  T=1.84s(data=1.8ms QKV=2.15s FFN=3.04s) eta=01:58:12 | 42.4K token/s | 
[epoch_0]_57181  loss=2.970718 |g|=0.475	lr=1.19e-05 | 84.3%@S47  T=1.83s(data=1.6ms QKV=2.14s FFN=3.04s) eta=01:57:49 | 42.5K token/s | 
[epoch_0]_57191  loss=3.043880 |g|=0.479	lr=1.19e-05 | 85.1%@S47  T=1.82s(data=1.6ms QKV=2.14s FFN=3.04s) eta=01:56:45 | 42.6K token/s | 
[Fuyou] head="1" update algorithm=4 t=11.29s
[eval] 
	 Loss@"edu_fineweb1B"=3.048(7.2e-05) nBranch=1 nToken=6.31M best=3.0477(284) E2T=-0.0351 T=36.7609(0)s x=0
	#3.04761±0.0975 tps=172K(6.30784M) a=[2.85917,3.32798] T=36.7609(sec)
[Section@57200] layer[16-24] tasks=19(nPassBack=0) last_loss=3.08266(-0.0597866) N=(772,64736,64176 7550268)
[epoch_0]_57201  loss=3.029966 |g|=0.509	lr=1.19e-05 | 85.9%@S47  T=12.57s(data=2.6ms QKV=2.14s FFN=3.04s) eta=13:22:55 | 40.8K token/s | 
[epoch_0]_57211  loss=3.077024 |g|=0.505	lr=1.18e-05 | 86.7%@S47  T=1.80s(data=1.6ms QKV=2.14s FFN=3.04s) eta=01:55:02 | 41.0K token/s | 
[epoch_0]_57221  loss=3.067731 |g|=0.514	lr=1.18e-05 | 87.6%@S47  T=1.82s(data=1.7ms QKV=2.13s FFN=3.04s) eta=01:55:53 | 41.2K token/s | 
[epoch_0]_57231  loss=3.048848 |g|=0.518	lr=1.18e-05 | 88.4%@S47  T=1.82s(data=1.8ms QKV=2.14s FFN=3.04s) eta=01:55:15 | 41.4K token/s | 
[epoch_0]_57241  loss=2.992936 |g|=0.49	lr=1.18e-05 | 89.2%@S47  T=1.81s(data=1.6ms QKV=2.13s FFN=3.04s) eta=01:54:41 | 41.6K token/s | 
[epoch_0]_57251  loss=3.048336 |g|=0.503	lr=1.17e-05 | 90.0%@S47  T=1.82s(data=1.9ms QKV=2.15s FFN=3.04s) eta=01:54:56 | 41.8K token/s | 
[epoch_0]_57261  loss=3.104153 |g|=0.512	lr=1.17e-05 | 90.8%@S47  T=1.81s(data=1.7ms QKV=2.14s FFN=3.04s) eta=01:53:43 | 41.9K token/s | 
[epoch_0]_57271  loss=2.997269 |g|=0.482	lr=1.17e-05 | 91.7%@S47  T=1.80s(data=1.8ms QKV=2.15s FFN=3.04s) eta=01:53:07 | 42.1K token/s | 
[epoch_0]_57281  loss=3.037187 |g|=0.492	lr=1.16e-05 | 92.5%@S47  T=1.82s(data=1.5ms QKV=2.13s FFN=3.04s) eta=01:53:50 | 42.3K token/s | 
[epoch_0]_57291  loss=3.046631 |g|=0.502	lr=1.16e-05 | 93.3%@S47  T=1.83s(data=1.8ms QKV=2.14s FFN=3.04s) eta=01:53:54 | 42.4K token/s | 
[Fuyou] head="2" update algorithm=4 t=10.27s
[Section@57300] layer[24-32] tasks=19(nPassBack=0) last_loss=3.04638(-0.0191538) N=(772,64848,64288 7563468)
[epoch_0]_57301  loss=3.071776 |g|=0.508	lr=1.16e-05 | 94.1%@S47  T=5.01s(data=1.8ms QKV=2.14s FFN=3.03s) eta=05:11:38 | 41.1K token/s | 
[epoch_0]_57311  loss=3.038664 |g|=0.504	lr=1.15e-05 | 94.9%@S47  T=1.77s(data=2.0ms QKV=2.14s FFN=3.04s) eta=01:49:59 | 41.3K token/s | 
[epoch_0]_57321  loss=2.953043 |g|=0.498	lr=1.15e-05 | 95.7%@S47  T=1.78s(data=1.7ms QKV=2.15s FFN=3.04s) eta=01:50:13 | 41.6K token/s | 
[epoch_0]_57331  loss=3.062364 |g|=0.485	lr=1.15e-05 | 96.6%@S47  T=1.83s(data=1.8ms QKV=2.15s FFN=3.04s) eta=01:52:48 | 41.7K token/s | 
[epoch_0]_57341  loss=3.058427 |g|=0.495	lr=1.15e-05 | 97.4%@S47  T=1.81s(data=1.7ms QKV=2.15s FFN=3.04s) eta=01:51:09 | 41.9K token/s | 
[epoch_0]_57351  loss=3.033004 |g|=0.492	lr=1.14e-05 | 98.2%@S47  T=1.81s(data=1.7ms QKV=2.14s FFN=3.04s) eta=01:51:03 | 42.1K token/s | 
[epoch_0]_57361  loss=3.047890 |g|=0.499	lr=1.14e-05 | 99.0%@S47  T=1.79s(data=1.8ms QKV=2.15s FFN=3.04s) eta=01:49:45 | 42.3K token/s | 
[epoch_0]_57371  loss=3.038975 |g|=0.49	lr=1.14e-05 | 99.8%@S47  T=1.82s(data=1.6ms QKV=2.15s FFN=3.04s) eta=01:50:54 | 42.4K token/s | 
[epoch_0]_57372  loss=3.045183 |g|=0.502	lr=1.14e-05 | 99.9%@S47  T=1.79s(data=1.9ms QKV=2.16s FFN=3.04s) eta=01:49:08 | 42.6K token/s | 
-------- End of shard_47@"./Datasets/edu_fineweb1B/edu_fineweb_train_000805.bin"-------- 
[shard-48]@"./Datasets/edu_fineweb1B/edu_fineweb_train_000806.bin": tokens=100(M) nShardSamples=1220(4687488) 
[epoch_0]_57381  loss=2.978368 |g|=0.509	lr=1.13e-05 | 0.7%@S48  T=1.78s(data=1.3ms QKV=2.14s FFN=3.04s) eta=01:48:34 | 42.8K token/s | 
[epoch_0]_57391  loss=3.001170 |g|=0.506	lr=1.13e-05 | 1.5%@S48  T=1.87s(data=1.3ms QKV=2.14s FFN=3.04s) eta=01:53:36 | 42.8K token/s | 
[Fuyou] head="3" update algorithm=4 t=12.01s
[eval] 
	 Loss@"edu_fineweb1B"=3.047(0.001) nBranch=1 nToken=6.31M best=3.0476(285) E2T=0.0639 T=36.7343(0)s x=0
	#3.04659±0.0974 tps=172K(6.30784M) a=[2.85803,3.32736] T=36.7343(sec)
[Section@57400] layer[32-40] tasks=19(nPassBack=0) last_loss=2.98266(0.0267062) N=(772,64960,64400 7576668)
[epoch_0]_57401  loss=3.026923 |g|=0.505	lr=1.13e-05 | 2.3%@S48  T=12.34s(data=1.6ms QKV=2.13s FFN=3.03s) eta=12:27:23 | 41.0K token/s | 
[epoch_0]_57411  loss=3.003014 |g|=0.497	lr=1.13e-05 | 3.1%@S48  T=1.79s(data=1.7ms QKV=2.13s FFN=3.04s) eta=01:48:03 | 41.2K token/s | 
[epoch_0]_57421  loss=2.982902 |g|=0.495	lr=1.12e-05 | 3.9%@S48  T=1.83s(data=1.8ms QKV=2.13s FFN=3.04s) eta=01:50:28 | 41.4K token/s | 
[epoch_0]_57431  loss=3.030133 |g|=0.492	lr=1.12e-05 | 4.8%@S48  T=1.81s(data=1.6ms QKV=2.13s FFN=3.04s) eta=01:48:37 | 41.6K token/s | 
[epoch_0]_57441  loss=2.955762 |g|=0.5	lr=1.12e-05 | 5.6%@S48  T=1.85s(data=1.7ms QKV=2.13s FFN=3.04s) eta=01:50:54 | 41.7K token/s | 
[epoch_0]_57451  loss=2.937366 |g|=0.481	lr=1.11e-05 | 6.4%@S48  T=1.83s(data=1.6ms QKV=2.13s FFN=3.04s) eta=01:49:28 | 41.9K token/s | 
[epoch_0]_57461  loss=3.009971 |g|=0.497	lr=1.11e-05 | 7.2%@S48  T=1.78s(data=1.7ms QKV=2.13s FFN=3.04s) eta=01:46:04 | 42.1K token/s | 
[epoch_0]_57471  loss=2.927242 |g|=0.502	lr=1.11e-05 | 8.0%@S48  T=1.81s(data=2.9ms QKV=2.13s FFN=3.04s) eta=01:47:32 | 42.2K token/s | 
[epoch_0]_57481  loss=2.992189 |g|=0.509	lr=1.11e-05 | 8.9%@S48  T=1.80s(data=1.8ms QKV=2.13s FFN=3.04s) eta=01:46:39 | 42.4K token/s | 
[epoch_0]_57491  loss=3.007428 |g|=0.501	lr=1.10e-05 | 9.7%@S48  T=1.80s(data=1.5ms QKV=2.13s FFN=3.04s) eta=01:46:34 | 42.6K token/s | 
[Fuyou] head="4" update algorithm=4 t=11.49s
[Section@57500] layer[40-48] tasks=19(nPassBack=0) last_loss=2.89481(0.162237) N=(772,65072,64512 7589868)
[epoch_0]_57501  loss=3.082984 |g|=0.521	lr=1.10e-05 | 10.5%@S48  T=4.18s(data=1.8ms QKV=2.13s FFN=3.04s) eta=04:06:26 | 41.4K token/s | 
[epoch_0]_57511  loss=3.018719 |g|=0.506	lr=1.10e-05 | 11.3%@S48  T=1.80s(data=1.3ms QKV=2.13s FFN=3.04s) eta=01:45:29 | 41.6K token/s | 
[epoch_0]_57521  loss=3.003923 |g|=0.495	lr=1.09e-05 | 12.1%@S48  T=1.82s(data=1.7ms QKV=2.13s FFN=3.04s) eta=01:46:35 | 41.8K token/s | 
[epoch_0]_57531  loss=3.023898 |g|=0.51	lr=1.09e-05 | 13.0%@S48  T=1.83s(data=1.7ms QKV=2.14s FFN=3.04s) eta=01:46:56 | 41.9K token/s | 
[epoch_0]_57541  loss=3.018100 |g|=0.476	lr=1.09e-05 | 13.8%@S48  T=1.83s(data=1.9ms QKV=2.14s FFN=3.04s) eta=01:46:22 | 42.1K token/s | 
[epoch_0]_57551  loss=3.093065 |g|=0.504	lr=1.09e-05 | 14.6%@S48  T=1.79s(data=1.7ms QKV=2.14s FFN=3.04s) eta=01:43:59 | 42.3K token/s | 
[epoch_0]_57561  loss=3.062806 |g|=0.496	lr=1.08e-05 | 15.4%@S48  T=1.81s(data=1.6ms QKV=2.14s FFN=3.04s) eta=01:44:49 | 42.4K token/s | 
[epoch_0]_57571  loss=2.980201 |g|=0.505	lr=1.08e-05 | 16.2%@S48  T=1.82s(data=1.7ms QKV=2.14s FFN=3.04s) eta=01:44:48 | 42.5K token/s | 
[epoch_0]_57581  loss=2.951379 |g|=0.504	lr=1.08e-05 | 17.0%@S48  T=1.83s(data=1.6ms QKV=2.14s FFN=3.04s) eta=01:45:13 | 42.7K token/s | 
[epoch_0]_57591  loss=3.086365 |g|=0.494	lr=1.07e-05 | 17.9%@S48  T=1.82s(data=1.4ms QKV=2.14s FFN=3.04s) eta=01:44:18 | 42.8K token/s | 
[Fuyou] head="5" update algorithm=4 t=12.26s
[eval] 
	 Loss@"edu_fineweb1B"=3.046(0.0011) nBranch=1 nToken=6.31M best=3.0466(286) E2T=0.0132 T=36.762(0)s x=0
	#3.04554±0.0974 tps=172K(6.30784M) a=[2.85744,3.32603] T=36.762(sec)
[Section@57600] layer[0-8] tasks=19(nPassBack=0) last_loss=3.03232(-0.0209997) N=(772,65184,64624 7603068)
[epoch_0]_57601  loss=3.001687 |g|=0.498	lr=1.07e-05 | 18.7%@S48  T=12.50s(data=1.5ms QKV=2.13s FFN=3.04s) eta=11:55:23 | 41.0K token/s | 
[epoch_0]_57611  loss=2.945020 |g|=0.506	lr=1.07e-05 | 19.5%@S48  T=1.85s(data=1.8ms QKV=2.13s FFN=3.04s) eta=01:45:26 | 41.1K token/s | 
[epoch_0]_57621  loss=3.013718 |g|=0.502	lr=1.07e-05 | 20.3%@S48  T=1.81s(data=1.5ms QKV=2.13s FFN=3.04s) eta=01:42:47 | 41.4K token/s | 
[epoch_0]_57631  loss=3.007145 |g|=0.49	lr=1.06e-05 | 21.1%@S48  T=1.79s(data=1.7ms QKV=2.13s FFN=3.04s) eta=01:41:32 | 41.6K token/s | 
[epoch_0]_57641  loss=3.025854 |g|=0.497	lr=1.06e-05 | 22.0%@S48  T=1.80s(data=1.6ms QKV=2.13s FFN=3.04s) eta=01:41:44 | 41.8K token/s | 
[epoch_0]_57651  loss=2.847400 |g|=0.499	lr=1.06e-05 | 22.8%@S48  T=1.82s(data=3.3ms QKV=2.13s FFN=3.04s) eta=01:42:42 | 41.9K token/s | 
[epoch_0]_57661  loss=3.084754 |g|=0.527	lr=1.06e-05 | 23.6%@S48  T=1.85s(data=8.2ms QKV=2.14s FFN=3.05s) eta=01:43:58 | 42.0K token/s | 
[epoch_0]_57671  loss=3.002602 |g|=0.506	lr=1.05e-05 | 24.4%@S48  T=1.83s(data=1.6ms QKV=2.13s FFN=3.04s) eta=01:42:24 | 42.2K token/s | 
[epoch_0]_57681  loss=2.913843 |g|=0.502	lr=1.05e-05 | 25.2%@S48  T=1.84s(data=1.7ms QKV=2.14s FFN=3.04s) eta=01:42:49 | 42.3K token/s | 
[epoch_0]_57691  loss=3.036386 |g|=0.502	lr=1.05e-05 | 26.1%@S48  T=1.82s(data=1.5ms QKV=2.13s FFN=3.04s) eta=01:41:17 | 42.4K token/s | 
[Fuyou] head="0" update algorithm=4 t=11.32s
[Section@57700] layer[8-16] tasks=19(nPassBack=0) last_loss=3.03348(-0.0517139) N=(772,65296,64736 7616268)
[epoch_0]_57701  loss=2.990525 |g|=0.503	lr=1.04e-05 | 26.9%@S48  T=4.80s(data=2.2ms QKV=2.14s FFN=3.04s) eta=04:26:56 | 41.2K token/s | 
[epoch_0]_57711  loss=3.008616 |g|=0.504	lr=1.04e-05 | 27.7%@S48  T=1.86s(data=1.6ms QKV=2.15s FFN=3.04s) eta=01:42:50 | 41.3K token/s | 
[epoch_0]_57721  loss=2.973803 |g|=0.526	lr=1.04e-05 | 28.5%@S48  T=1.82s(data=1.6ms QKV=2.15s FFN=3.04s) eta=01:40:35 | 41.5K token/s | 
[epoch_0]_57731  loss=2.949701 |g|=0.482	lr=1.04e-05 | 29.3%@S48  T=1.81s(data=1.4ms QKV=2.15s FFN=3.04s) eta=01:39:31 | 41.7K token/s | 
[epoch_0]_57741  loss=3.027569 |g|=0.508	lr=1.03e-05 | 30.2%@S48  T=1.82s(data=1.6ms QKV=2.15s FFN=3.04s) eta=01:39:44 | 41.9K token/s | 
[epoch_0]_57751  loss=3.000254 |g|=0.491	lr=1.03e-05 | 31.0%@S48  T=1.82s(data=1.7ms QKV=2.15s FFN=3.04s) eta=01:39:48 | 42.0K token/s | 
[epoch_0]_57761  loss=3.010796 |g|=0.497	lr=1.03e-05 | 31.8%@S48  T=1.80s(data=1.7ms QKV=2.15s FFN=3.04s) eta=01:38:26 | 42.2K token/s | 
[epoch_0]_57771  loss=2.950161 |g|=0.485	lr=1.03e-05 | 32.6%@S48  T=1.81s(data=1.4ms QKV=2.15s FFN=3.04s) eta=01:38:28 | 42.3K token/s | 
[epoch_0]_57781  loss=3.012299 |g|=0.502	lr=1.02e-05 | 33.4%@S48  T=1.87s(data=1.6ms QKV=2.15s FFN=3.04s) eta=01:41:27 | 42.4K token/s | 
[epoch_0]_57791  loss=2.932418 |g|=0.498	lr=1.02e-05 | 34.3%@S48  T=1.83s(data=1.7ms QKV=2.15s FFN=3.04s) eta=01:39:10 | 42.5K token/s | 
[Fuyou] head="1" update algorithm=4 t=10.57s
[eval] 
	 Loss@"edu_fineweb1B"=3.045(0.00046) nBranch=1 nToken=6.31M best=3.0455(287) E2T=0.101 T=36.7539(0)s x=0
	#3.04508±0.0974 tps=172K(6.30784M) a=[2.85769,3.3259] T=36.7539(sec)
[Section@57800] layer[16-24] tasks=19(nPassBack=0) last_loss=2.94371(0.138954) N=(772,65408,64848 7629468)
[epoch_0]_57801  loss=2.893672 |g|=0.51	lr=1.02e-05 | 35.1%@S48  T=12.53s(data=2.1ms QKV=2.13s FFN=3.04s) eta=11:15:14 | 40.7K token/s | 
[epoch_0]_57811  loss=3.025423 |g|=0.511	lr=1.02e-05 | 35.9%@S48  T=1.79s(data=1.7ms QKV=2.13s FFN=3.04s) eta=01:36:19 | 41.0K token/s | 
[epoch_0]_57821  loss=3.002863 |g|=0.492	lr=1.01e-05 | 36.7%@S48  T=1.84s(data=1.6ms QKV=2.14s FFN=3.04s) eta=01:38:37 | 41.2K token/s | 
[epoch_0]_57831  loss=3.055029 |g|=0.505	lr=1.01e-05 | 37.5%@S48  T=1.82s(data=2.1ms QKV=2.15s FFN=3.04s) eta=01:37:15 | 41.3K token/s | 
[epoch_0]_57841  loss=3.008916 |g|=0.513	lr=1.01e-05 | 38.3%@S48  T=1.83s(data=1.7ms QKV=2.14s FFN=3.04s) eta=01:37:26 | 41.5K token/s | 
[epoch_0]_57851  loss=2.988677 |g|=0.499	lr=1.01e-05 | 39.2%@S48  T=1.82s(data=1.5ms QKV=2.14s FFN=3.04s) eta=01:36:39 | 41.7K token/s | 
[epoch_0]_57861  loss=2.975708 |g|=0.502	lr=1.00e-05 | 40.0%@S48  T=1.81s(data=1.9ms QKV=2.14s FFN=3.04s) eta=01:35:36 | 41.9K token/s | 
[epoch_0]_57871  loss=3.017786 |g|=0.495	lr=1.00e-05 | 40.8%@S48  T=1.85s(data=1.7ms QKV=2.14s FFN=3.04s) eta=01:37:48 | 42.0K token/s | 
[epoch_0]_57881  loss=2.981187 |g|=0.494	lr=9.98e-06 | 41.6%@S48  T=1.87s(data=1.7ms QKV=2.14s FFN=3.04s) eta=01:38:19 | 42.1K token/s | 
[epoch_0]_57891  loss=2.971146 |g|=0.518	lr=9.96e-06 | 42.4%@S48  T=1.83s(data=1.6ms QKV=2.14s FFN=3.04s) eta=01:35:41 | 42.2K token/s | 
[Fuyou] head="2" update algorithm=4 t=10.29s
[Section@57900] layer[24-32] tasks=19(nPassBack=0) last_loss=2.94261(0.103761) N=(772,65520,64960 7642668)
[epoch_0]_57901  loss=3.001555 |g|=0.502	lr=9.93e-06 | 43.3%@S48  T=4.79s(data=1.9ms QKV=2.14s FFN=3.03s) eta=04:10:16 | 41.0K token/s | 
[epoch_0]_57911  loss=2.948806 |g|=0.493	lr=9.91e-06 | 44.1%@S48  T=1.82s(data=1.6ms QKV=2.15s FFN=3.04s) eta=01:34:38 | 41.2K token/s | 
[epoch_0]_57921  loss=2.946157 |g|=0.5	lr=9.88e-06 | 44.9%@S48  T=1.80s(data=1.8ms QKV=2.15s FFN=3.04s) eta=01:33:37 | 41.4K token/s | 
[epoch_0]_57931  loss=2.999996 |g|=0.495	lr=9.86e-06 | 45.7%@S48  T=1.81s(data=1.6ms QKV=2.15s FFN=3.04s) eta=01:33:44 | 41.6K token/s | 
[epoch_0]_57941  loss=3.004590 |g|=0.508	lr=9.83e-06 | 46.5%@S48  T=1.81s(data=1.6ms QKV=2.15s FFN=3.04s) eta=01:33:16 | 41.8K token/s | 
[epoch_0]_57951  loss=3.017432 |g|=0.507	lr=9.81e-06 | 47.4%@S48  T=1.79s(data=1.8ms QKV=2.15s FFN=3.04s) eta=01:31:46 | 42.0K token/s | 
[epoch_0]_57961  loss=3.059224 |g|=0.502	lr=9.78e-06 | 48.2%@S48  T=1.80s(data=1.7ms QKV=2.15s FFN=3.04s) eta=01:32:06 | 42.1K token/s | 
[epoch_0]_57971  loss=2.958357 |g|=0.498	lr=9.76e-06 | 49.0%@S48  T=1.82s(data=1.6ms QKV=2.14s FFN=3.04s) eta=01:32:43 | 42.3K token/s | 
[epoch_0]_57981  loss=2.978623 |g|=0.504	lr=9.73e-06 | 49.8%@S48  T=1.82s(data=1.6ms QKV=2.15s FFN=3.04s) eta=01:32:47 | 42.4K token/s | 
[epoch_0]_57991  loss=3.001364 |g|=0.504	lr=9.71e-06 | 50.6%@S48  T=1.84s(data=1.7ms QKV=2.15s FFN=3.04s) eta=01:33:31 | 42.5K token/s | 
[Fuyou] head="3" update algorithm=4 t=11.46s
[eval] 
	 Loss@"edu_fineweb1B"=3.045(0.00046) nBranch=1 nToken=6.31M best=3.0451(288) E2T=0.0234 T=36.7622(0)s x=0
	#3.04462±0.0975 tps=172K(6.30784M) a=[2.85588,3.32511] T=36.7622(sec)
[Section@58000] layer[32-40] tasks=19(nPassBack=0) last_loss=3.02121(-0.0385501) N=(772,65632,65072 7655868)
[epoch_0]_58001  loss=2.888737 |g|=0.512	lr=9.69e-06 | 51.5%@S48  T=12.09s(data=1.7ms QKV=2.13s FFN=3.04s) eta=10:11:21 | 40.7K token/s | 
[epoch_0]_58011  loss=3.080164 |g|=0.525	lr=9.66e-06 | 52.3%@S48  T=1.82s(data=1.5ms QKV=2.13s FFN=3.05s) eta=01:31:50 | 40.9K token/s | 
[epoch_0]_58021  loss=2.967839 |g|=0.485	lr=9.64e-06 | 53.1%@S48  T=1.81s(data=1.8ms QKV=2.13s FFN=3.05s) eta=01:31:02 | 41.2K token/s | 
[epoch_0]_58031  loss=2.971904 |g|=0.489	lr=9.61e-06 | 53.9%@S48  T=1.83s(data=1.8ms QKV=2.14s FFN=3.05s) eta=01:31:37 | 41.3K token/s | 
[epoch_0]_58041  loss=2.978571 |g|=0.509	lr=9.59e-06 | 54.7%@S48  T=1.83s(data=1.6ms QKV=2.14s FFN=3.05s) eta=01:31:24 | 41.5K token/s | 
[epoch_0]_58051  loss=3.017509 |g|=0.498	lr=9.57e-06 | 55.6%@S48  T=1.81s(data=1.6ms QKV=2.13s FFN=3.05s) eta=01:30:10 | 41.7K token/s | 
[epoch_0]_58061  loss=2.990064 |g|=0.501	lr=9.54e-06 | 56.4%@S48  T=1.84s(data=1.6ms QKV=2.13s FFN=3.05s) eta=01:31:20 | 41.8K token/s | 
[epoch_0]_58071  loss=2.976902 |g|=0.494	lr=9.52e-06 | 57.2%@S48  T=1.83s(data=1.6ms QKV=2.13s FFN=3.05s) eta=01:30:33 | 42.0K token/s | 
[epoch_0]_58081  loss=3.066733 |g|=0.509	lr=9.49e-06 | 58.0%@S48  T=1.82s(data=1.6ms QKV=2.13s FFN=3.05s) eta=01:29:47 | 42.1K token/s | 
[epoch_0]_58091  loss=2.960475 |g|=0.501	lr=9.47e-06 | 58.8%@S48  T=1.79s(data=1.6ms QKV=2.13s FFN=3.05s) eta=01:27:53 | 42.3K token/s | 
[Fuyou] head="4" update algorithm=4 t=12.24s
[Section@58100] layer[40-48] tasks=19(nPassBack=0) last_loss=2.99519(-0.100384) N=(772,65744,65184 7669068)
[epoch_0]_58101  loss=2.958131 |g|=0.497	lr=9.45e-06 | 59.6%@S48  T=4.41s(data=3.9ms QKV=2.14s FFN=3.04s) eta=03:35:30 | 41.1K token/s | 
[epoch_0]_58111  loss=2.966615 |g|=0.496	lr=9.42e-06 | 60.5%@S48  T=1.82s(data=1.7ms QKV=2.14s FFN=3.04s) eta=01:28:55 | 41.3K token/s | 
[epoch_0]_58121  loss=2.990055 |g|=0.505	lr=9.40e-06 | 61.3%@S48  T=1.81s(data=1.6ms QKV=2.15s FFN=3.05s) eta=01:27:54 | 41.5K token/s | 
[epoch_0]_58131  loss=2.932354 |g|=0.5	lr=9.38e-06 | 62.1%@S48  T=1.82s(data=1.7ms QKV=2.15s FFN=3.05s) eta=01:27:51 | 41.7K token/s | 
[epoch_0]_58141  loss=3.002748 |g|=0.509	lr=9.35e-06 | 62.9%@S48  T=1.81s(data=1.6ms QKV=2.15s FFN=3.05s) eta=01:27:20 | 41.9K token/s | 
[epoch_0]_58151  loss=2.999003 |g|=0.499	lr=9.33e-06 | 63.7%@S48  T=1.82s(data=1.8ms QKV=2.15s FFN=3.05s) eta=01:27:38 | 42.0K token/s | 
[epoch_0]_58161  loss=2.927141 |g|=0.503	lr=9.31e-06 | 64.6%@S48  T=1.81s(data=1.7ms QKV=2.15s FFN=3.05s) eta=01:26:53 | 42.2K token/s | 
[epoch_0]_58171  loss=2.896911 |g|=0.492	lr=9.29e-06 | 65.4%@S48  T=1.85s(data=1.5ms QKV=2.15s FFN=3.05s) eta=01:28:21 | 42.3K token/s | 
[epoch_0]_58181  loss=2.961558 |g|=0.529	lr=9.26e-06 | 66.2%@S48  T=1.82s(data=1.6ms QKV=2.15s FFN=3.05s) eta=01:26:37 | 42.4K token/s | 
[epoch_0]_58191  loss=2.982162 |g|=0.503	lr=9.24e-06 | 67.0%@S48  T=1.86s(data=1.6ms QKV=2.15s FFN=3.05s) eta=01:28:05 | 42.5K token/s | 
[Fuyou] head="5" update algorithm=4 t=10.53s
[eval] 
	 Loss@"edu_fineweb1B"=3.044(0.00042) nBranch=1 nToken=6.31M best=3.0446(289) E2T=0.0777 T=36.7627(0)s x=0
	#3.0442±0.0975 tps=172K(6.30784M) a=[2.85538,3.32468] T=36.7627(sec)
[Section@58200] layer[0-8] tasks=19(nPassBack=0) last_loss=2.96651(0.0658104) N=(772,65856,65296 7682268)
[epoch_0]_58201  loss=2.935928 |g|=0.507	lr=9.22e-06 | 67.8%@S48  T=12.28s(data=1.7ms QKV=2.13s FFN=3.04s) eta=09:40:15 | 40.7K token/s | 
[epoch_0]_58211  loss=2.876986 |g|=0.49	lr=9.19e-06 | 68.7%@S48  T=1.82s(data=1.6ms QKV=2.13s FFN=3.05s) eta=01:25:35 | 40.9K token/s | 
[epoch_0]_58221  loss=3.106743 |g|=0.488	lr=9.17e-06 | 69.5%@S48  T=1.79s(data=1.6ms QKV=2.13s FFN=3.05s) eta=01:23:56 | 41.2K token/s | 
[epoch_0]_58231  loss=2.944860 |g|=0.502	lr=9.15e-06 | 70.3%@S48  T=1.84s(data=1.6ms QKV=2.13s FFN=3.05s) eta=01:25:56 | 41.3K token/s | 
[epoch_0]_58241  loss=3.022481 |g|=0.478	lr=9.13e-06 | 71.1%@S48  T=1.81s(data=2.0ms QKV=2.13s FFN=3.05s) eta=01:24:16 | 41.5K token/s | 
[epoch_0]_58251  loss=3.088494 |g|=0.5	lr=9.10e-06 | 71.9%@S48  T=1.95s(data=2.1ms QKV=2.15s FFN=3.05s) eta=01:30:24 | 41.6K token/s | 
[epoch_0]_58261  loss=3.030095 |g|=0.499	lr=9.08e-06 | 72.8%@S48  T=1.88s(data=1.9ms QKV=2.13s FFN=3.05s) eta=01:26:56 | 41.7K token/s | 
[epoch_0]_58271  loss=3.030888 |g|=0.503	lr=9.06e-06 | 73.6%@S48  T=1.83s(data=1.6ms QKV=2.13s FFN=3.05s) eta=01:24:18 | 41.8K token/s | 
[epoch_0]_58281  loss=3.021718 |g|=0.51	lr=9.04e-06 | 74.4%@S48  T=1.84s(data=2.0ms QKV=2.14s FFN=3.05s) eta=01:24:34 | 41.9K token/s | 
[epoch_0]_58291  loss=2.894115 |g|=0.495	lr=9.02e-06 | 75.2%@S48  T=1.85s(data=1.7ms QKV=2.13s FFN=3.05s) eta=01:24:29 | 42.1K token/s | 
[Fuyou] head="0" update algorithm=4 t=13.01s
[Section@58300] layer[8-16] tasks=19(nPassBack=0) last_loss=2.93436(0.0991273) N=(772,65968,65408 7695468)
[epoch_0]_58301  loss=3.045788 |g|=0.511	lr=8.99e-06 | 76.0%@S48  T=5.03s(data=2.1ms QKV=2.15s FFN=3.04s) eta=03:49:08 | 40.8K token/s | 
[epoch_0]_58311  loss=2.972671 |g|=0.499	lr=8.97e-06 | 76.9%@S48  T=1.81s(data=1.8ms QKV=2.15s FFN=3.04s) eta=01:22:01 | 41.0K token/s | 
[epoch_0]_58321  loss=2.972691 |g|=0.513	lr=8.95e-06 | 77.7%@S48  T=1.84s(data=1.6ms QKV=2.15s FFN=3.05s) eta=01:23:07 | 41.2K token/s | 
[epoch_0]_58331  loss=3.009365 |g|=0.502	lr=8.93e-06 | 78.5%@S48  T=1.87s(data=1.7ms QKV=2.15s FFN=3.05s) eta=01:24:11 | 41.3K token/s | 
[epoch_0]_58341  loss=2.977671 |g|=0.493	lr=8.91e-06 | 79.3%@S48  T=1.80s(data=1.8ms QKV=2.16s FFN=3.05s) eta=01:20:54 | 41.5K token/s | 
[epoch_0]_58351  loss=2.907388 |g|=0.488	lr=8.89e-06 | 80.1%@S48  T=1.82s(data=2.0ms QKV=2.15s FFN=3.05s) eta=01:21:13 | 41.7K token/s | 
[epoch_0]_58361  loss=2.996035 |g|=0.498	lr=8.86e-06 | 80.9%@S48  T=1.83s(data=1.7ms QKV=2.15s FFN=3.05s) eta=01:21:36 | 41.9K token/s | 
[epoch_0]_58371  loss=2.966284 |g|=0.501	lr=8.84e-06 | 81.8%@S48  T=1.86s(data=1.5ms QKV=2.15s FFN=3.05s) eta=01:22:37 | 42.0K token/s | 
[epoch_0]_58381  loss=2.903922 |g|=0.488	lr=8.82e-06 | 82.6%@S48  T=1.82s(data=1.9ms QKV=2.15s FFN=3.05s) eta=01:20:43 | 42.1K token/s | 
[epoch_0]_58391  loss=2.999075 |g|=0.497	lr=8.80e-06 | 83.4%@S48  T=1.79s(data=1.8ms QKV=2.15s FFN=3.05s) eta=01:18:51 | 42.3K token/s | 
[Fuyou] head="1" update algorithm=4 t=12.31s
[eval] 
	 Loss@"edu_fineweb1B"=3.044(0.00048) nBranch=1 nToken=6.31M best=3.0442(290) E2T=0.0496 T=36.7562(0)s x=0
	#3.04372±0.0976 tps=172K(6.30784M) a=[2.85597,3.3238] T=36.7562(sec)
[Section@58400] layer[16-24] tasks=19(nPassBack=0) last_loss=2.99414(-0.0504286) N=(772,66080,65520 7708668)
[epoch_0]_58401  loss=3.047302 |g|=0.516	lr=8.78e-06 | 84.2%@S48  T=12.59s(data=2.2ms QKV=2.14s FFN=3.04s) eta=09:12:43 | 40.5K token/s | 
[epoch_0]_58411  loss=3.051095 |g|=0.501	lr=8.76e-06 | 85.0%@S48  T=1.82s(data=2.0ms QKV=2.14s FFN=3.05s) eta=01:19:30 | 40.7K token/s | 
[epoch_0]_58421  loss=3.028277 |g|=0.506	lr=8.74e-06 | 85.9%@S48  T=1.84s(data=1.9ms QKV=2.14s FFN=3.05s) eta=01:20:13 | 40.9K token/s | 
[epoch_0]_58431  loss=2.942663 |g|=0.501	lr=8.72e-06 | 86.7%@S48  T=1.83s(data=1.6ms QKV=2.14s FFN=3.05s) eta=01:19:19 | 41.1K token/s | 
[epoch_0]_58441  loss=2.990108 |g|=0.492	lr=8.70e-06 | 87.5%@S48  T=1.84s(data=1.6ms QKV=2.14s FFN=3.05s) eta=01:19:20 | 41.3K token/s | 
[epoch_0]_58451  loss=2.949445 |g|=0.506	lr=8.68e-06 | 88.3%@S48  T=1.84s(data=1.8ms QKV=2.15s FFN=3.05s) eta=01:19:24 | 41.4K token/s | 
[epoch_0]_58461  loss=3.009041 |g|=0.481	lr=8.65e-06 | 89.1%@S48  T=1.82s(data=1.7ms QKV=2.14s FFN=3.05s) eta=01:18:05 | 41.6K token/s | 
[epoch_0]_58471  loss=3.004714 |g|=0.501	lr=8.63e-06 | 90.0%@S48  T=1.87s(data=1.6ms QKV=2.15s FFN=3.05s) eta=01:19:54 | 41.7K token/s | 
[epoch_0]_58481  loss=2.958619 |g|=0.514	lr=8.61e-06 | 90.8%@S48  T=1.80s(data=1.6ms QKV=2.14s FFN=3.05s) eta=01:16:27 | 41.9K token/s | 
[epoch_0]_58491  loss=2.974620 |g|=0.502	lr=8.59e-06 | 91.6%@S48  T=1.85s(data=1.7ms QKV=2.15s FFN=3.05s) eta=01:18:21 | 42.0K token/s | 
[Fuyou] head="2" update algorithm=4 t=12.16s
[Section@58500] layer[24-32] tasks=19(nPassBack=0) last_loss=3.03883(-0.0962124) N=(772,66192,65632 7721868)
[epoch_0]_58501  loss=2.986820 |g|=0.512	lr=8.57e-06 | 92.4%@S48  T=4.95s(data=1.9ms QKV=2.15s FFN=3.04s) eta=03:28:52 | 40.8K token/s | 
[epoch_0]_58511  loss=2.943105 |g|=0.497	lr=8.55e-06 | 93.2%@S48  T=1.80s(data=1.8ms QKV=2.15s FFN=3.04s) eta=01:15:32 | 41.0K token/s | 
[epoch_0]_58521  loss=3.042676 |g|=0.5	lr=8.53e-06 | 94.1%@S48  T=1.81s(data=1.6ms QKV=2.16s FFN=3.04s) eta=01:15:47 | 41.2K token/s | 
[epoch_0]_58531  loss=3.035364 |g|=0.504	lr=8.51e-06 | 94.9%@S48  T=1.84s(data=1.7ms QKV=2.16s FFN=3.04s) eta=01:16:46 | 41.4K token/s | 
[epoch_0]_58541  loss=3.022775 |g|=0.507	lr=8.49e-06 | 95.7%@S48  T=1.83s(data=1.6ms QKV=2.16s FFN=3.04s) eta=01:16:00 | 41.6K token/s | 
[epoch_0]_58551  loss=3.012314 |g|=0.498	lr=8.47e-06 | 96.5%@S48  T=1.86s(data=6.5ms QKV=2.16s FFN=3.04s) eta=01:16:53 | 41.7K token/s | 
[epoch_0]_58561  loss=2.919958 |g|=0.505	lr=8.45e-06 | 97.3%@S48  T=1.87s(data=1.9ms QKV=2.16s FFN=3.04s) eta=01:16:59 | 41.8K token/s | 
[epoch_0]_58571  loss=2.951729 |g|=0.5	lr=8.43e-06 | 98.1%@S48  T=1.81s(data=1.6ms QKV=2.16s FFN=3.04s) eta=01:14:11 | 42.0K token/s | 
[epoch_0]_58581  loss=3.086628 |g|=0.505	lr=8.41e-06 | 99.0%@S48  T=1.80s(data=1.7ms QKV=2.16s FFN=3.04s) eta=01:13:36 | 42.2K token/s | 
[epoch_0]_58591  loss=3.013574 |g|=0.502	lr=8.39e-06 | 99.8%@S48  T=1.86s(data=1.7ms QKV=2.16s FFN=3.04s) eta=01:15:48 | 42.2K token/s | 
[epoch_0]_58593  loss=2.987867 |g|=0.498	lr=8.39e-06 | 100.0%@S48  T=1.86s(data=2.2ms QKV=2.16s FFN=3.04s) eta=01:15:39 | 42.3K token/s | 
-------- End of shard_48@"./Datasets/edu_fineweb1B/edu_fineweb_train_000806.bin"-------- 
[shard-49]@"./Datasets/edu_fineweb1B/edu_fineweb_train_000807.bin": tokens=100(M) nShardSamples=1220(4785144) 
[Fuyou] head="3" update algorithm=4 t=12.05s
[eval] 
	 Loss@"edu_fineweb1B"=3.044(0.00016) nBranch=1 nToken=6.31M best=3.0437(291) E2T=0.0924 T=36.7638(0)s x=0
	#3.04356±0.0975 tps=172K(6.30784M) a=[2.85536,3.32359] T=36.7638(sec)
[Section@58600] layer[32-40] tasks=19(nPassBack=0) last_loss=2.95111(0.0700994) N=(772,66304,65744 7735068)
[epoch_0]_58601  loss=2.955029 |g|=0.49	lr=8.37e-06 | 0.6%@S49  T=12.66s(data=1.9ms QKV=2.14s FFN=3.04s) eta=08:33:24 | 40.5K token/s | 
[epoch_0]_58611  loss=2.986433 |g|=0.498	lr=8.35e-06 | 1.4%@S49  T=1.80s(data=2.2ms QKV=2.14s FFN=3.04s) eta=01:12:52 | 40.8K token/s | 
[epoch_0]_58621  loss=2.990649 |g|=0.503	lr=8.34e-06 | 2.2%@S49  T=1.79s(data=1.7ms QKV=2.14s FFN=3.04s) eta=01:11:57 | 41.0K token/s | 
[epoch_0]_58631  loss=3.056587 |g|=0.491	lr=8.32e-06 | 3.1%@S49  T=1.82s(data=1.9ms QKV=2.14s FFN=3.04s) eta=01:12:52 | 41.2K token/s | 
[epoch_0]_58641  loss=2.978715 |g|=0.497	lr=8.30e-06 | 3.9%@S49  T=1.80s(data=1.8ms QKV=2.14s FFN=3.04s) eta=01:11:42 | 41.5K token/s | 
[epoch_0]_58651  loss=3.013483 |g|=0.502	lr=8.28e-06 | 4.7%@S49  T=1.80s(data=1.7ms QKV=2.14s FFN=3.04s) eta=01:11:41 | 41.7K token/s | 
[epoch_0]_58661  loss=2.996493 |g|=0.486	lr=8.26e-06 | 5.5%@S49  T=1.79s(data=1.6ms QKV=2.14s FFN=3.04s) eta=01:10:57 | 41.9K token/s | 
[epoch_0]_58671  loss=3.005164 |g|=0.492	lr=8.24e-06 | 6.3%@S49  T=1.82s(data=1.6ms QKV=2.14s FFN=3.04s) eta=01:11:31 | 42.0K token/s | 
[epoch_0]_58681  loss=3.110491 |g|=0.504	lr=8.22e-06 | 7.2%@S49  T=1.81s(data=1.6ms QKV=2.14s FFN=3.04s) eta=01:10:51 | 42.2K token/s | 
[epoch_0]_58691  loss=3.020792 |g|=0.493	lr=8.20e-06 | 8.0%@S49  T=1.84s(data=1.6ms QKV=2.14s FFN=3.04s) eta=01:11:43 | 42.3K token/s | 
[Fuyou] head="4" update algorithm=4 t=11.96s
[Section@58700] layer[40-48] tasks=19(nPassBack=0) last_loss=3.03948(-0.0442877) N=(772,66416,65856 7748268)
[epoch_0]_58701  loss=3.025371 |g|=0.492	lr=8.18e-06 | 8.8%@S49  T=4.80s(data=2.1ms QKV=2.14s FFN=3.04s) eta=03:06:36 | 41.0K token/s | 
[epoch_0]_58711  loss=2.963054 |g|=0.491	lr=8.16e-06 | 9.6%@S49  T=1.81s(data=1.8ms QKV=2.15s FFN=3.04s) eta=01:10:17 | 41.3K token/s | 
[epoch_0]_58721  loss=2.993507 |g|=0.499	lr=8.15e-06 | 10.4%@S49  T=1.80s(data=1.6ms QKV=2.15s FFN=3.04s) eta=01:09:19 | 41.5K token/s | 
[epoch_0]_58731  loss=3.044043 |g|=0.499	lr=8.13e-06 | 11.3%@S49  T=1.82s(data=1.5ms QKV=2.15s FFN=3.04s) eta=01:09:44 | 41.6K token/s | 
[epoch_0]_58741  loss=2.983356 |g|=0.504	lr=8.11e-06 | 12.1%@S49  T=1.82s(data=1.7ms QKV=2.15s FFN=3.04s) eta=01:09:34 | 41.8K token/s | 
[epoch_0]_58751  loss=2.987851 |g|=0.494	lr=8.09e-06 | 12.9%@S49  T=1.82s(data=1.7ms QKV=2.15s FFN=3.04s) eta=01:09:17 | 42.0K token/s | 
[epoch_0]_58761  loss=3.063996 |g|=0.491	lr=8.07e-06 | 13.7%@S49  T=1.82s(data=1.9ms QKV=2.15s FFN=3.04s) eta=01:08:52 | 42.1K token/s | 
[epoch_0]_58771  loss=3.043021 |g|=0.483	lr=8.05e-06 | 14.5%@S49  T=1.82s(data=1.7ms QKV=2.15s FFN=3.04s) eta=01:08:32 | 42.3K token/s | 
[epoch_0]_58781  loss=3.004157 |g|=0.495	lr=8.04e-06 | 15.4%@S49  T=1.83s(data=1.8ms QKV=2.15s FFN=3.04s) eta=01:08:51 | 42.4K token/s | 
[epoch_0]_58791  loss=3.034041 |g|=0.494	lr=8.02e-06 | 16.2%@S49  T=1.81s(data=1.7ms QKV=2.15s FFN=3.04s) eta=01:07:50 | 42.5K token/s | 
[Fuyou] head="5" update algorithm=4 t=12.50s
[eval] 
	 Loss@"edu_fineweb1B"=3.044(-0.00025) nBranch=1 nToken=6.31M best=3.0437(291) E2T=0.0146 T=36.7703(0)s x=0
	#3.04381±0.0975 tps=172K(6.30784M) a=[2.85591,3.32451] T=36.7703(sec)
[Section@58800] layer[0-8] tasks=19(nPassBack=0) last_loss=3.02917(-0.0626543) N=(772,66528,65968 7761468)
[epoch_0]_58801  loss=3.061064 |g|=0.502	lr=8.00e-06 | 17.0%@S49  T=12.19s(data=1.9ms QKV=2.12s FFN=3.04s) eta=07:33:59 | 40.7K token/s | 
[epoch_0]_58811  loss=3.058760 |g|=0.491	lr=7.98e-06 | 17.8%@S49  T=1.80s(data=2.0ms QKV=2.13s FFN=3.04s) eta=01:06:33 | 41.0K token/s | 
[epoch_0]_58821  loss=3.017726 |g|=0.481	lr=7.96e-06 | 18.6%@S49  T=1.85s(data=1.7ms QKV=2.13s FFN=3.04s) eta=01:08:08 | 41.2K token/s | 
[epoch_0]_58831  loss=3.035141 |g|=0.485	lr=7.95e-06 | 19.4%@S49  T=1.82s(data=1.8ms QKV=2.13s FFN=3.04s) eta=01:06:57 | 41.3K token/s | 
[epoch_0]_58841  loss=3.120662 |g|=0.49	lr=7.93e-06 | 20.3%@S49  T=1.81s(data=1.6ms QKV=2.12s FFN=3.04s) eta=01:06:04 | 41.5K token/s | 
[epoch_0]_58851  loss=3.025286 |g|=0.492	lr=7.91e-06 | 21.1%@S49  T=1.80s(data=1.7ms QKV=2.13s FFN=3.04s) eta=01:05:23 | 41.8K token/s | 
[epoch_0]_58861  loss=3.010327 |g|=0.486	lr=7.89e-06 | 21.9%@S49  T=1.79s(data=1.5ms QKV=2.13s FFN=3.04s) eta=01:04:50 | 42.0K token/s | 
[epoch_0]_58871  loss=3.006881 |g|=0.502	lr=7.88e-06 | 22.7%@S49  T=1.79s(data=1.7ms QKV=2.13s FFN=3.04s) eta=01:04:35 | 42.1K token/s | 
[epoch_0]_58881  loss=3.039887 |g|=0.497	lr=7.86e-06 | 23.5%@S49  T=1.80s(data=1.5ms QKV=2.13s FFN=3.04s) eta=01:04:46 | 42.3K token/s | 
[epoch_0]_58891  loss=2.973478 |g|=0.485	lr=7.84e-06 | 24.4%@S49  T=1.80s(data=1.9ms QKV=2.14s FFN=3.04s) eta=01:04:12 | 42.5K token/s | 
[Fuyou] head="0" update algorithm=4 t=10.65s
[Section@58900] layer[8-16] tasks=19(nPassBack=0) last_loss=3.03433(-0.0999749) N=(772,66640,66080 7774668)
[epoch_0]_58901  loss=3.030713 |g|=0.503	lr=7.83e-06 | 25.2%@S49  T=4.77s(data=2.1ms QKV=2.13s FFN=3.04s) eta=02:49:34 | 41.2K token/s | 
[epoch_0]_58911  loss=3.014146 |g|=0.501	lr=7.81e-06 | 26.0%@S49  T=1.79s(data=1.7ms QKV=2.13s FFN=3.04s) eta=01:03:19 | 41.4K token/s | 
[epoch_0]_58921  loss=2.889732 |g|=0.508	lr=7.79e-06 | 26.8%@S49  T=1.80s(data=1.5ms QKV=2.13s FFN=3.04s) eta=01:03:17 | 41.6K token/s | 
[epoch_0]_58931  loss=2.965878 |g|=0.482	lr=7.77e-06 | 27.6%@S49  T=1.80s(data=1.5ms QKV=2.14s FFN=3.04s) eta=01:03:07 | 41.8K token/s | 
[epoch_0]_58941  loss=3.041151 |g|=0.495	lr=7.76e-06 | 28.5%@S49  T=1.79s(data=1.7ms QKV=2.13s FFN=3.04s) eta=01:02:36 | 42.0K token/s | 
[epoch_0]_58951  loss=2.947942 |g|=0.49	lr=7.74e-06 | 29.3%@S49  T=1.80s(data=1.4ms QKV=2.13s FFN=3.04s) eta=01:02:34 | 42.2K token/s | 
[epoch_0]_58961  loss=2.969035 |g|=0.473	lr=7.72e-06 | 30.1%@S49  T=1.79s(data=1.5ms QKV=2.14s FFN=3.04s) eta=01:01:54 | 42.4K token/s | 
[epoch_0]_58971  loss=2.963963 |g|=0.494	lr=7.71e-06 | 30.9%@S49  T=1.79s(data=1.6ms QKV=2.13s FFN=3.04s) eta=01:01:32 | 42.5K token/s | 
[epoch_0]_58981  loss=3.030201 |g|=0.49	lr=7.69e-06 | 31.7%@S49  T=1.83s(data=1.7ms QKV=2.14s FFN=3.04s) eta=01:02:31 | 42.7K token/s | 
[epoch_0]_58991  loss=2.968566 |g|=0.495	lr=7.67e-06 | 32.6%@S49  T=1.81s(data=1.9ms QKV=2.14s FFN=3.04s) eta=01:01:48 | 42.8K token/s | 
[Fuyou] head="1" update algorithm=4 t=11.00s
[eval] 
	 Loss@"edu_fineweb1B"=3.044(-1.1e-05) nBranch=1 nToken=6.31M best=3.0437(291) E2T=0.0926 T=36.7355(0)s x=0
	#3.04383±0.0976 tps=172K(6.30784M) a=[2.85557,3.32487] T=36.7355(sec)
[Section@59000] layer[16-24] tasks=19(nPassBack=0) last_loss=2.95123(0.042907) N=(772,66752,66192 7787868)
[epoch_0]_59001  loss=3.075948 |g|=0.507	lr=7.66e-06 | 33.4%@S49  T=12.36s(data=1.6ms QKV=2.12s FFN=3.04s) eta=06:58:57 | 41.0K token/s | 
[epoch_0]_59011  loss=3.011947 |g|=0.489	lr=7.64e-06 | 34.2%@S49  T=1.79s(data=1.8ms QKV=2.13s FFN=3.04s) eta=01:00:22 | 41.2K token/s | 
[epoch_0]_59021  loss=2.959690 |g|=0.495	lr=7.63e-06 | 35.0%@S49  T=1.79s(data=1.7ms QKV=2.13s FFN=3.04s) eta=01:00:13 | 41.4K token/s | 
[epoch_0]_59031  loss=3.010212 |g|=0.499	lr=7.61e-06 | 35.8%@S49  T=1.78s(data=1.6ms QKV=2.12s FFN=3.04s) eta=00:59:36 | 41.7K token/s | 
[epoch_0]_59041  loss=2.984413 |g|=0.501	lr=7.59e-06 | 36.7%@S49  T=1.83s(data=1.7ms QKV=2.12s FFN=3.04s) eta=01:00:42 | 41.8K token/s | 
[epoch_0]_59051  loss=3.029844 |g|=0.495	lr=7.58e-06 | 37.5%@S49  T=1.80s(data=1.6ms QKV=2.12s FFN=3.04s) eta=00:59:28 | 42.0K token/s | 
[epoch_0]_59061  loss=3.041078 |g|=0.489	lr=7.56e-06 | 38.3%@S49  T=1.82s(data=1.8ms QKV=2.13s FFN=3.04s) eta=00:59:54 | 42.2K token/s | 
[epoch_0]_59071  loss=3.006639 |g|=0.506	lr=7.55e-06 | 39.1%@S49  T=1.80s(data=1.9ms QKV=2.12s FFN=3.04s) eta=00:58:57 | 42.3K token/s | 
[epoch_0]_59081  loss=2.992392 |g|=0.497	lr=7.53e-06 | 39.9%@S49  T=1.80s(data=1.8ms QKV=2.13s FFN=3.04s) eta=00:58:45 | 42.5K token/s | 
[epoch_0]_59091  loss=3.028288 |g|=0.512	lr=7.52e-06 | 40.7%@S49  T=1.78s(data=1.6ms QKV=2.13s FFN=3.04s) eta=00:57:47 | 42.7K token/s | 
[Fuyou] head="2" update algorithm=4 t=10.16s
[Section@59100] layer[24-32] tasks=19(nPassBack=0) last_loss=3.02138(0.0174506) N=(772,66864,66304 7801068)
[epoch_0]_59101  loss=3.012134 |g|=0.503	lr=7.50e-06 | 41.6%@S49  T=4.68s(data=1.6ms QKV=2.13s FFN=3.03s) eta=02:30:53 | 41.4K token/s | 
[epoch_0]_59111  loss=3.012346 |g|=0.493	lr=7.48e-06 | 42.4%@S49  T=1.79s(data=1.5ms QKV=2.13s FFN=3.04s) eta=00:57:19 | 41.6K token/s | 
[epoch_0]_59121  loss=3.004500 |g|=0.483	lr=7.47e-06 | 43.2%@S49  T=1.82s(data=1.5ms QKV=2.13s FFN=3.04s) eta=00:58:01 | 41.8K token/s | 
[epoch_0]_59131  loss=2.979112 |g|=0.501	lr=7.45e-06 | 44.0%@S49  T=1.81s(data=1.8ms QKV=2.13s FFN=3.04s) eta=00:57:25 | 42.0K token/s | 
[epoch_0]_59141  loss=3.037319 |g|=0.489	lr=7.44e-06 | 44.8%@S49  T=1.84s(data=1.7ms QKV=2.13s FFN=3.04s) eta=00:58:12 | 42.1K token/s | 
[epoch_0]_59151  loss=3.000295 |g|=0.5	lr=7.42e-06 | 45.7%@S49  T=1.80s(data=1.8ms QKV=2.13s FFN=3.04s) eta=00:56:34 | 42.3K token/s | 
[epoch_0]_59161  loss=3.054688 |g|=0.505	lr=7.41e-06 | 46.5%@S49  T=1.81s(data=1.7ms QKV=2.13s FFN=3.04s) eta=00:56:23 | 42.4K token/s | 
[epoch_0]_59171  loss=3.108350 |g|=0.511	lr=7.39e-06 | 47.3%@S49  T=1.79s(data=1.6ms QKV=2.13s FFN=3.04s) eta=00:55:39 | 42.6K token/s | 
[epoch_0]_59181  loss=3.002701 |g|=0.499	lr=7.38e-06 | 48.1%@S49  T=1.81s(data=1.5ms QKV=2.13s FFN=3.04s) eta=00:56:04 | 42.7K token/s | 
[epoch_0]_59191  loss=3.015592 |g|=0.497	lr=7.36e-06 | 48.9%@S49  T=1.80s(data=1.5ms QKV=2.13s FFN=3.04s) eta=00:55:26 | 42.8K token/s | 
[Fuyou] head="3" update algorithm=4 t=11.93s
[eval] 
	 Loss@"edu_fineweb1B"=3.044(0.00023) nBranch=1 nToken=6.31M best=3.0438(294) E2T=0.0436 T=36.7638(0)s x=0
	#3.0436±0.0976 tps=172K(6.30784M) a=[2.85589,3.32549] T=36.7638(sec)
[Section@59200] layer[32-40] tasks=19(nPassBack=0) last_loss=3.00002(-0.0489028) N=(772,66976,66416 7814268)
[epoch_0]_59201  loss=3.092997 |g|=0.509	lr=7.35e-06 | 49.8%@S49  T=12.29s(data=2.0ms QKV=2.12s FFN=3.04s) eta=06:15:35 | 41.0K token/s | 
[epoch_0]_59211  loss=2.964846 |g|=0.496	lr=7.33e-06 | 50.6%@S49  T=1.79s(data=1.9ms QKV=2.12s FFN=3.04s) eta=00:54:17 | 41.3K token/s | 
[epoch_0]_59221  loss=2.981633 |g|=0.49	lr=7.32e-06 | 51.4%@S49  T=1.83s(data=1.9ms QKV=2.12s FFN=3.04s) eta=00:55:15 | 41.4K token/s | 
[epoch_0]_59231  loss=3.001633 |g|=0.504	lr=7.30e-06 | 52.2%@S49  T=1.80s(data=2.0ms QKV=2.13s FFN=3.04s) eta=00:54:04 | 41.7K token/s | 
[epoch_0]_59241  loss=3.087679 |g|=0.546	lr=7.29e-06 | 53.0%@S49  T=1.79s(data=1.7ms QKV=2.13s FFN=3.04s) eta=00:53:40 | 41.9K token/s | 
[epoch_0]_59251  loss=2.969037 |g|=0.488	lr=7.28e-06 | 53.9%@S49  T=1.78s(data=1.5ms QKV=2.12s FFN=3.04s) eta=00:52:54 | 42.1K token/s | 
[epoch_0]_59261  loss=2.992560 |g|=0.496	lr=7.26e-06 | 54.7%@S49  T=1.80s(data=1.6ms QKV=2.13s FFN=3.04s) eta=00:53:18 | 42.2K token/s | 
[epoch_0]_59271  loss=3.005389 |g|=0.492	lr=7.25e-06 | 55.5%@S49  T=1.79s(data=1.8ms QKV=2.13s FFN=3.04s) eta=00:52:31 | 42.4K token/s | 
[epoch_0]_59281  loss=3.040668 |g|=0.507	lr=7.23e-06 | 56.3%@S49  T=1.79s(data=1.5ms QKV=2.13s FFN=3.04s) eta=00:52:19 | 42.6K token/s | 
[epoch_0]_59291  loss=3.030043 |g|=0.495	lr=7.22e-06 | 57.1%@S49  T=1.81s(data=1.6ms QKV=2.13s FFN=3.04s) eta=00:52:41 | 42.7K token/s | 
[Fuyou] head="4" update algorithm=4 t=11.41s
[Section@59300] layer[40-48] tasks=19(nPassBack=0) last_loss=2.99614(0.0433407) N=(772,67088,66528 7827468)
[epoch_0]_59301  loss=2.999234 |g|=0.502	lr=7.21e-06 | 58.0%@S49  T=4.33s(data=2.4ms QKV=2.13s FFN=3.03s) eta=02:05:15 | 41.5K token/s | 
[epoch_0]_59311  loss=3.051092 |g|=0.489	lr=7.19e-06 | 58.8%@S49  T=1.80s(data=1.7ms QKV=2.14s FFN=3.04s) eta=00:51:39 | 41.7K token/s | 
[epoch_0]_59321  loss=2.993301 |g|=0.494	lr=7.18e-06 | 59.6%@S49  T=1.79s(data=1.6ms QKV=2.14s FFN=3.04s) eta=00:51:00 | 41.9K token/s | 
[epoch_0]_59331  loss=3.064661 |g|=0.503	lr=7.16e-06 | 60.4%@S49  T=1.80s(data=1.6ms QKV=2.14s FFN=3.04s) eta=00:51:12 | 42.1K token/s | 
[epoch_0]_59341  loss=2.987599 |g|=0.501	lr=7.15e-06 | 61.2%@S49  T=1.83s(data=3.0ms QKV=2.14s FFN=3.04s) eta=00:51:37 | 42.2K token/s | 
[epoch_0]_59351  loss=2.947543 |g|=0.497	lr=7.14e-06 | 62.0%@S49  T=1.80s(data=1.5ms QKV=2.14s FFN=3.04s) eta=00:50:26 | 42.4K token/s | 
[epoch_0]_59361  loss=3.019615 |g|=0.491	lr=7.12e-06 | 62.9%@S49  T=1.80s(data=1.6ms QKV=2.14s FFN=3.04s) eta=00:50:19 | 42.6K token/s | 
[epoch_0]_59371  loss=3.064508 |g|=0.486	lr=7.11e-06 | 63.7%@S49  T=1.79s(data=1.6ms QKV=2.14s FFN=3.04s) eta=00:49:45 | 42.7K token/s | 
[epoch_0]_59381  loss=3.052104 |g|=0.501	lr=7.10e-06 | 64.5%@S49  T=1.83s(data=1.6ms QKV=2.14s FFN=3.04s) eta=00:50:25 | 42.8K token/s | 
[epoch_0]_59391  loss=3.008948 |g|=0.485	lr=7.08e-06 | 65.3%@S49  T=1.80s(data=1.7ms QKV=2.14s FFN=3.04s) eta=00:49:23 | 42.9K token/s | 
[Fuyou] head="5" update algorithm=4 t=10.68s
[eval] 
	 Loss@"edu_fineweb1B"=3.044(8.1e-06) nBranch=1 nToken=6.31M best=3.0436(295) E2T=0.0332 T=36.7324(0)s x=0
	#3.04359±0.0976 tps=172K(6.30784M) a=[2.85524,3.32467] T=36.7324(sec)
[Section@59400] layer[0-8] tasks=19(nPassBack=0) last_loss=3.0104(0.0187666) N=(772,67200,66640 7840668)
[epoch_0]_59401  loss=3.016605 |g|=0.487	lr=7.07e-06 | 66.1%@S49  T=12.40s(data=1.7ms QKV=2.13s FFN=3.03s) eta=05:37:40 | 41.1K token/s | 
[epoch_0]_59411  loss=3.042539 |g|=0.509	lr=7.06e-06 | 67.0%@S49  T=1.80s(data=1.6ms QKV=2.13s FFN=3.04s) eta=00:48:38 | 41.4K token/s | 
[epoch_0]_59421  loss=2.997226 |g|=0.494	lr=7.04e-06 | 67.8%@S49  T=1.81s(data=1.6ms QKV=2.13s FFN=3.04s) eta=00:48:41 | 41.5K token/s | 
[epoch_0]_59431  loss=3.020219 |g|=0.497	lr=7.03e-06 | 68.6%@S49  T=1.81s(data=1.7ms QKV=2.13s FFN=3.04s) eta=00:48:23 | 41.7K token/s | 
[epoch_0]_59441  loss=3.073662 |g|=0.499	lr=7.02e-06 | 69.4%@S49  T=1.85s(data=1.9ms QKV=2.13s FFN=3.04s) eta=00:49:02 | 41.9K token/s | 
[epoch_0]_59451  loss=3.056897 |g|=0.49	lr=7.01e-06 | 70.2%@S49  T=1.82s(data=1.6ms QKV=2.13s FFN=3.04s) eta=00:47:58 | 42.0K token/s | 
[epoch_0]_59461  loss=2.972386 |g|=0.517	lr=6.99e-06 | 71.1%@S49  T=1.82s(data=1.6ms QKV=2.13s FFN=3.04s) eta=00:47:46 | 42.2K token/s | 
[epoch_0]_59471  loss=2.964718 |g|=0.513	lr=6.98e-06 | 71.9%@S49  T=1.81s(data=1.5ms QKV=2.13s FFN=3.04s) eta=00:47:05 | 42.3K token/s | 
[epoch_0]_59481  loss=3.032712 |g|=0.494	lr=6.97e-06 | 72.7%@S49  T=1.80s(data=2.1ms QKV=2.13s FFN=3.04s) eta=00:46:37 | 42.5K token/s | 
[epoch_0]_59491  loss=2.970081 |g|=0.497	lr=6.96e-06 | 73.5%@S49  T=1.83s(data=1.6ms QKV=2.13s FFN=3.04s) eta=00:46:59 | 42.6K token/s | 
[Fuyou] head="0" update algorithm=4 t=10.89s
[Section@59500] layer[8-16] tasks=19(nPassBack=0) last_loss=2.95147(0.0828562) N=(772,67312,66752 7853868)
[epoch_0]_59501  loss=2.977321 |g|=0.496	lr=6.94e-06 | 74.3%@S49  T=4.79s(data=2.1ms QKV=2.14s FFN=3.03s) eta=02:02:33 | 41.3K token/s | 
[epoch_0]_59511  loss=3.008288 |g|=0.496	lr=6.93e-06 | 75.2%@S49  T=1.78s(data=1.7ms QKV=2.14s FFN=3.04s) eta=00:45:20 | 41.6K token/s | 
[epoch_0]_59521  loss=3.012361 |g|=0.503	lr=6.92e-06 | 76.0%@S49  T=1.78s(data=1.6ms QKV=2.13s FFN=3.04s) eta=00:44:53 | 41.8K token/s | 
[epoch_0]_59531  loss=2.929794 |g|=0.498	lr=6.91e-06 | 76.8%@S49  T=1.80s(data=1.6ms QKV=2.14s FFN=3.04s) eta=00:45:10 | 42.0K token/s | 
[epoch_0]_59541  loss=3.012067 |g|=0.483	lr=6.90e-06 | 77.6%@S49  T=1.81s(data=1.8ms QKV=2.14s FFN=3.04s) eta=00:44:59 | 42.1K token/s | 
[epoch_0]_59551  loss=2.985615 |g|=0.492	lr=6.88e-06 | 78.4%@S49  T=1.81s(data=1.6ms QKV=2.14s FFN=3.04s) eta=00:44:42 | 42.3K token/s | 
[epoch_0]_59561  loss=2.977359 |g|=0.49	lr=6.87e-06 | 79.3%@S49  T=1.80s(data=1.7ms QKV=2.14s FFN=3.04s) eta=00:44:19 | 42.5K token/s | 
[epoch_0]_59571  loss=3.014309 |g|=0.493	lr=6.86e-06 | 80.1%@S49  T=1.80s(data=1.6ms QKV=2.13s FFN=3.04s) eta=00:43:57 | 42.6K token/s | 
[epoch_0]_59581  loss=3.017760 |g|=0.497	lr=6.85e-06 | 80.9%@S49  T=1.85s(data=1.6ms QKV=2.14s FFN=3.04s) eta=00:44:54 | 42.7K token/s | 
[epoch_0]_59591  loss=3.066395 |g|=0.507	lr=6.84e-06 | 81.7%@S49  T=1.83s(data=1.6ms QKV=2.14s FFN=3.04s) eta=00:43:55 | 42.8K token/s | 
[Fuyou] head="1" update algorithm=4 t=10.28s
[eval] 
	 Loss@"edu_fineweb1B"=3.044(7.8e-05) nBranch=1 nToken=6.31M best=3.0436(296) E2T=0.0447 T=36.766(0)s x=0
	#3.04351±0.0976 tps=172K(6.30784M) a=[2.85562,3.32497] T=36.766(sec)
[Section@59600] layer[16-24] tasks=19(nPassBack=0) last_loss=2.99876(-0.0475328) N=(772,67424,66864 7867068)
[epoch_0]_59601  loss=3.051567 |g|=0.525	lr=6.82e-06 | 82.5%@S49  T=12.29s(data=1.7ms QKV=2.12s FFN=3.03s) eta=04:53:40 | 41.0K token/s | 
[epoch_0]_59611  loss=3.008653 |g|=0.51	lr=6.81e-06 | 83.3%@S49  T=1.81s(data=1.9ms QKV=2.13s FFN=3.04s) eta=00:42:59 | 41.2K token/s | 
[epoch_0]_59621  loss=3.001241 |g|=0.49	lr=6.80e-06 | 84.2%@S49  T=1.80s(data=1.6ms QKV=2.13s FFN=3.04s) eta=00:42:20 | 41.4K token/s | 
[epoch_0]_59631  loss=2.979252 |g|=0.492	lr=6.79e-06 | 85.0%@S49  T=1.82s(data=1.9ms QKV=2.13s FFN=3.04s) eta=00:42:30 | 41.6K token/s | 
[epoch_0]_59641  loss=2.986412 |g|=0.493	lr=6.78e-06 | 85.8%@S49  T=1.81s(data=1.8ms QKV=2.13s FFN=3.04s) eta=00:42:05 | 41.8K token/s | 
[epoch_0]_59651  loss=3.068310 |g|=0.498	lr=6.77e-06 | 86.6%@S49  T=1.81s(data=1.6ms QKV=2.13s FFN=3.04s) eta=00:41:40 | 42.0K token/s | 
[epoch_0]_59661  loss=3.023910 |g|=0.488	lr=6.76e-06 | 87.4%@S49  T=1.80s(data=1.6ms QKV=2.13s FFN=3.04s) eta=00:41:09 | 42.1K token/s | 
[epoch_0]_59671  loss=3.040467 |g|=0.489	lr=6.75e-06 | 88.3%@S49  T=1.80s(data=1.7ms QKV=2.13s FFN=3.04s) eta=00:40:59 | 42.3K token/s | 
[epoch_0]_59681  loss=2.962200 |g|=0.496	lr=6.74e-06 | 89.1%@S49  T=1.80s(data=1.7ms QKV=2.13s FFN=3.04s) eta=00:40:42 | 42.5K token/s | 
[epoch_0]_59691  loss=3.064472 |g|=0.522	lr=6.72e-06 | 89.9%@S49  T=1.81s(data=1.5ms QKV=2.13s FFN=3.04s) eta=00:40:29 | 42.6K token/s | 
[Fuyou] head="2" update algorithm=4 t=10.84s
[Section@59700] layer[24-32] tasks=19(nPassBack=0) last_loss=2.98427(0.037107) N=(772,67536,66976 7880268)
[epoch_0]_59701  loss=2.923909 |g|=0.489	lr=6.71e-06 | 90.7%@S49  T=4.82s(data=1.8ms QKV=2.14s FFN=3.03s) eta=01:47:11 | 41.3K token/s | 
[epoch_0]_59711  loss=3.053363 |g|=0.497	lr=6.70e-06 | 91.5%@S49  T=1.78s(data=1.6ms QKV=2.14s FFN=3.04s) eta=00:39:21 | 41.6K token/s | 
[epoch_0]_59721  loss=3.016251 |g|=0.495	lr=6.69e-06 | 92.4%@S49  T=1.79s(data=1.8ms QKV=2.14s FFN=3.04s) eta=00:39:18 | 41.8K token/s | 
[epoch_0]_59731  loss=3.083164 |g|=0.528	lr=6.68e-06 | 93.2%@S49  T=1.80s(data=1.6ms QKV=2.14s FFN=3.04s) eta=00:39:09 | 41.9K token/s | 
[epoch_0]_59741  loss=3.032104 |g|=0.509	lr=6.67e-06 | 94.0%@S49  T=1.78s(data=1.8ms QKV=2.14s FFN=3.04s) eta=00:38:25 | 42.1K token/s | 
[epoch_0]_59751  loss=3.059956 |g|=0.512	lr=6.66e-06 | 94.8%@S49  T=1.80s(data=2.0ms QKV=2.14s FFN=3.04s) eta=00:38:34 | 42.3K token/s | 
[epoch_0]_59761  loss=3.077698 |g|=0.508	lr=6.65e-06 | 95.6%@S49  T=1.79s(data=1.6ms QKV=2.14s FFN=3.04s) eta=00:37:54 | 42.5K token/s | 
[epoch_0]_59771  loss=2.982215 |g|=0.504	lr=6.64e-06 | 96.5%@S49  T=1.80s(data=1.5ms QKV=2.14s FFN=3.04s) eta=00:37:58 | 42.6K token/s | 
[epoch_0]_59781  loss=3.009298 |g|=0.51	lr=6.63e-06 | 97.3%@S49  T=1.81s(data=1.6ms QKV=2.14s FFN=3.04s) eta=00:37:53 | 42.8K token/s | 
[epoch_0]_59791  loss=3.020210 |g|=0.506	lr=6.62e-06 | 98.1%@S49  T=1.84s(data=1.5ms QKV=2.14s FFN=3.04s) eta=00:38:04 | 42.9K token/s | 
[Fuyou] head="3" update algorithm=4 t=11.87s
[eval] 
	 Loss@"edu_fineweb1B"=3.043(0.00012) nBranch=1 nToken=6.31M best=3.0435(297) E2T=0.084 T=36.7557(0)s x=0
	#3.0434±0.0976 tps=172K(6.30784M) a=[2.85486,3.32482] T=36.7557(sec)
[Section@59800] layer[32-40] tasks=19(nPassBack=0) last_loss=2.95943(0.040585) N=(772,67648,67088 7893468)
[epoch_0]_59801  loss=3.006213 |g|=0.511	lr=6.61e-06 | 98.9%@S49  T=11.99s(data=1.6ms QKV=2.12s FFN=3.04s) eta=04:06:31 | 41.1K token/s | 
[epoch_0]_59811  loss=3.100121 |g|=0.497	lr=6.60e-06 | 99.7%@S49  T=1.80s(data=1.7ms QKV=2.13s FFN=3.04s) eta=00:36:39 | 41.3K token/s | 
[epoch_0]_59814  loss=3.026114 |g|=0.496	lr=6.60e-06 | 100.0%@S49  T=1.79s(data=1.7ms QKV=2.13s FFN=3.04s) eta=00:36:26 | 41.5K token/s | 
-------- End of shard_49@"./Datasets/edu_fineweb1B/edu_fineweb_train_000807.bin"-------- 
[shard-50]@"./Datasets/edu_fineweb1B/edu_fineweb_train_000808.bin": tokens=100(M) nShardSamples=1220(4882800) 
[epoch_0]_59821  loss=3.079996 |g|=0.508	lr=6.59e-06 | 0.5%@S50  T=1.83s(data=1.5ms QKV=2.13s FFN=3.04s) eta=00:36:58 | 41.7K token/s | 
[epoch_0]_59831  loss=2.960858 |g|=0.514	lr=6.58e-06 | 1.4%@S50  T=1.78s(data=1.9ms QKV=2.13s FFN=3.04s) eta=00:35:46 | 41.9K token/s | 
[epoch_0]_59841  loss=3.031716 |g|=0.508	lr=6.57e-06 | 2.2%@S50  T=1.80s(data=1.6ms QKV=2.12s FFN=3.04s) eta=00:35:53 | 42.1K token/s | 
[epoch_0]_59851  loss=3.016815 |g|=0.502	lr=6.56e-06 | 3.0%@S50  T=1.79s(data=1.6ms QKV=2.13s FFN=3.04s) eta=00:35:17 | 42.2K token/s | 
[epoch_0]_59861  loss=3.025642 |g|=0.506	lr=6.55e-06 | 3.8%@S50  T=1.79s(data=1.6ms QKV=2.13s FFN=3.04s) eta=00:35:06 | 42.4K token/s | 
[epoch_0]_59871  loss=3.071731 |g|=0.502	lr=6.54e-06 | 4.6%@S50  T=1.80s(data=1.6ms QKV=2.13s FFN=3.04s) eta=00:34:50 | 42.6K token/s | 
[epoch_0]_59881  loss=2.981957 |g|=0.505	lr=6.53e-06 | 5.5%@S50  T=1.78s(data=1.5ms QKV=2.12s FFN=3.04s) eta=00:34:13 | 42.8K token/s | 
[epoch_0]_59891  loss=3.020854 |g|=0.486	lr=6.53e-06 | 6.3%@S50  T=1.79s(data=1.4ms QKV=2.13s FFN=3.04s) eta=00:34:04 | 42.9K token/s | 
[Fuyou] head="4" update algorithm=4 t=12.25s
[Section@59900] layer[40-48] tasks=19(nPassBack=0) last_loss=3.05905(-0.0629115) N=(772,67760,67200 7906668)
[epoch_0]_59901  loss=2.922974 |g|=0.493	lr=6.52e-06 | 7.1%@S50  T=4.21s(data=1.6ms QKV=2.13s FFN=3.04s) eta=01:19:30 | 41.7K token/s | 
[epoch_0]_59911  loss=3.024599 |g|=0.52	lr=6.51e-06 | 7.9%@S50  T=1.79s(data=1.7ms QKV=2.13s FFN=3.04s) eta=00:33:28 | 41.9K token/s | 
[epoch_0]_59921  loss=2.950501 |g|=0.502	lr=6.50e-06 | 8.7%@S50  T=1.82s(data=3.7ms QKV=2.13s FFN=3.04s) eta=00:33:50 | 42.1K token/s | 
[epoch_0]_59931  loss=2.964600 |g|=0.498	lr=6.49e-06 | 9.6%@S50  T=1.82s(data=1.5ms QKV=2.13s FFN=3.04s) eta=00:33:33 | 42.2K token/s | 
[epoch_0]_59941  loss=3.036040 |g|=0.504	lr=6.48e-06 | 10.4%@S50  T=1.81s(data=1.6ms QKV=2.13s FFN=3.04s) eta=00:32:59 | 42.4K token/s | 
[epoch_0]_59951  loss=3.044104 |g|=0.536	lr=6.47e-06 | 11.2%@S50  T=1.80s(data=1.4ms QKV=2.14s FFN=3.04s) eta=00:32:36 | 42.5K token/s | 
[epoch_0]_59961  loss=2.981801 |g|=0.499	lr=6.46e-06 | 12.0%@S50  T=1.80s(data=3.0ms QKV=2.14s FFN=3.04s) eta=00:32:18 | 42.7K token/s | 
[epoch_0]_59971  loss=3.034847 |g|=0.486	lr=6.45e-06 | 12.8%@S50  T=1.80s(data=2.8ms QKV=2.13s FFN=3.04s) eta=00:31:58 | 42.8K token/s | 
[epoch_0]_59981  loss=2.982510 |g|=0.492	lr=6.45e-06 | 13.7%@S50  T=1.79s(data=1.8ms QKV=2.14s FFN=3.04s) eta=00:31:31 | 43.0K token/s | 
[epoch_0]_59991  loss=2.936656 |g|=0.497	lr=6.44e-06 | 14.5%@S50  T=1.79s(data=1.4ms QKV=2.14s FFN=3.04s) eta=00:31:12 | 43.1K token/s | 
[Fuyou] head="5" update algorithm=4 t=10.60s
[eval] 
	 Loss@"edu_fineweb1B"=3.042(0.0013) nBranch=1 nToken=6.31M best=3.0434(298) E2T=0.102 T=36.7634(0)s x=0
	#3.04214±0.0974 tps=172K(6.30784M) a=[2.85299,3.32254] T=36.7634(sec)
[Section@60000] layer[0-8] tasks=19(nPassBack=0) last_loss=2.93971(0.0706878) N=(772,67872,67312 7919868)
[epoch_0]_60001  loss=3.052840 |g|=0.504	lr=6.43e-06 | 15.3%@S50  T=12.14s(data=1.9ms QKV=2.12s FFN=3.04s) eta=03:29:17 | 41.3K token/s | 
[epoch_0]_60011  loss=3.041324 |g|=0.506	lr=6.42e-06 | 16.1%@S50  T=1.83s(data=1.8ms QKV=2.13s FFN=3.04s) eta=00:31:09 | 41.5K token/s | 
[epoch_0]_60021  loss=2.949235 |g|=0.495	lr=6.41e-06 | 16.9%@S50  T=1.80s(data=1.8ms QKV=2.13s FFN=3.04s) eta=00:30:27 | 41.7K token/s | 
[epoch_0]_60031  loss=3.032441 |g|=0.499	lr=6.40e-06 | 17.8%@S50  T=1.81s(data=1.6ms QKV=2.13s FFN=3.04s) eta=00:30:17 | 41.8K token/s | 
[epoch_0]_60041  loss=2.987742 |g|=0.505	lr=6.40e-06 | 18.6%@S50  T=1.79s(data=1.4ms QKV=2.13s FFN=3.04s) eta=00:29:40 | 42.0K token/s | 
[epoch_0]_60051  loss=2.986345 |g|=0.497	lr=6.39e-06 | 19.4%@S50  T=1.81s(data=1.6ms QKV=2.13s FFN=3.04s) eta=00:29:43 | 42.2K token/s | 
[epoch_0]_60061  loss=3.024996 |g|=0.497	lr=6.38e-06 | 20.2%@S50  T=1.81s(data=1.7ms QKV=2.13s FFN=3.04s) eta=00:29:22 | 42.3K token/s | 
[epoch_0]_60071  loss=3.028654 |g|=0.523	lr=6.37e-06 | 21.0%@S50  T=1.80s(data=1.7ms QKV=2.13s FFN=3.04s) eta=00:28:59 | 42.5K token/s | 
[epoch_0]_60081  loss=2.965488 |g|=0.501	lr=6.37e-06 | 21.8%@S50  T=1.81s(data=1.6ms QKV=2.13s FFN=3.04s) eta=00:28:45 | 42.6K token/s | 
[epoch_0]_60091  loss=3.003951 |g|=0.487	lr=6.36e-06 | 22.7%@S50  T=1.80s(data=1.6ms QKV=2.13s FFN=3.04s) eta=00:28:23 | 42.8K token/s | 
[Fuyou] head="0" update algorithm=4 t=12.30s
[Section@60100] layer[8-16] tasks=19(nPassBack=0) last_loss=3.00918(-0.0577013) N=(772,67984,67424 7933068)
[epoch_0]_60101  loss=2.928847 |g|=0.524	lr=6.35e-06 | 23.5%@S50  T=4.94s(data=2.2ms QKV=2.13s FFN=3.03s) eta=01:16:57 | 41.5K token/s | 
[epoch_0]_60111  loss=3.015034 |g|=0.495	lr=6.34e-06 | 24.3%@S50  T=1.80s(data=1.6ms QKV=2.14s FFN=3.04s) eta=00:27:44 | 41.7K token/s | 
[epoch_0]_60121  loss=2.937679 |g|=0.509	lr=6.34e-06 | 25.1%@S50  T=1.79s(data=1.9ms QKV=2.14s FFN=3.04s) eta=00:27:13 | 41.9K token/s | 
[epoch_0]_60131  loss=2.967386 |g|=0.508	lr=6.33e-06 | 25.9%@S50  T=1.80s(data=1.4ms QKV=2.14s FFN=3.04s) eta=00:27:04 | 42.1K token/s | 
[epoch_0]_60141  loss=2.984123 |g|=0.507	lr=6.32e-06 | 26.8%@S50  T=1.80s(data=1.4ms QKV=2.14s FFN=3.04s) eta=00:26:52 | 42.2K token/s | 
[epoch_0]_60151  loss=2.974581 |g|=0.503	lr=6.31e-06 | 27.6%@S50  T=1.81s(data=1.4ms QKV=2.14s FFN=3.04s) eta=00:26:35 | 42.4K token/s | 
[epoch_0]_60161  loss=2.866229 |g|=0.53	lr=6.31e-06 | 28.4%@S50  T=1.81s(data=1.6ms QKV=2.14s FFN=3.04s) eta=00:26:25 | 42.5K token/s | 
[epoch_0]_60171  loss=2.954728 |g|=0.501	lr=6.30e-06 | 29.2%@S50  T=1.81s(data=1.7ms QKV=2.14s FFN=3.04s) eta=00:26:06 | 42.7K token/s | 
[epoch_0]_60181  loss=2.992108 |g|=0.501	lr=6.29e-06 | 30.0%@S50  T=1.78s(data=1.6ms QKV=2.14s FFN=3.04s) eta=00:25:21 | 42.8K token/s | 
[epoch_0]_60191  loss=2.973833 |g|=0.491	lr=6.29e-06 | 30.9%@S50  T=1.81s(data=1.4ms QKV=2.14s FFN=3.04s) eta=00:25:30 | 42.9K token/s | 
[Fuyou] head="1" update algorithm=4 t=11.05s
[eval] 
	 Loss@"edu_fineweb1B"=3.042(0.00033) nBranch=1 nToken=6.31M best=3.0421(299) E2T=0.0721 T=36.7594(0)s x=0
	#3.04182±0.0975 tps=172K(6.30784M) a=[2.85304,3.32262] T=36.7594(sec)
[Section@60200] layer[16-24] tasks=19(nPassBack=0) last_loss=2.96971(0.0290558) N=(772,68096,67536 7946268)
[epoch_0]_60201  loss=2.970078 |g|=0.515	lr=6.28e-06 | 31.7%@S50  T=12.54s(data=2.0ms QKV=2.12s FFN=3.04s) eta=02:54:15 | 41.1K token/s | 
[epoch_0]_60211  loss=3.042356 |g|=0.496	lr=6.27e-06 | 32.5%@S50  T=1.80s(data=1.6ms QKV=2.13s FFN=3.04s) eta=00:24:47 | 41.3K token/s | 
[epoch_0]_60221  loss=2.963088 |g|=0.515	lr=6.27e-06 | 33.3%@S50  T=1.80s(data=1.5ms QKV=2.13s FFN=3.04s) eta=00:24:21 | 41.5K token/s | 
[epoch_0]_60231  loss=2.974119 |g|=0.505	lr=6.26e-06 | 34.1%@S50  T=1.79s(data=2.6ms QKV=2.13s FFN=3.04s) eta=00:24:00 | 41.8K token/s | 
[epoch_0]_60241  loss=3.006263 |g|=0.516	lr=6.25e-06 | 35.0%@S50  T=1.81s(data=1.6ms QKV=2.13s FFN=3.04s) eta=00:23:56 | 41.9K token/s | 
[epoch_0]_60251  loss=2.953794 |g|=0.501	lr=6.25e-06 | 35.8%@S50  T=1.80s(data=1.7ms QKV=2.13s FFN=3.04s) eta=00:23:31 | 42.1K token/s | 
[epoch_0]_60261  loss=3.077072 |g|=0.526	lr=6.24e-06 | 36.6%@S50  T=1.80s(data=2.3ms QKV=2.13s FFN=3.04s) eta=00:23:10 | 42.3K token/s | 
[epoch_0]_60271  loss=3.044680 |g|=0.512	lr=6.23e-06 | 37.4%@S50  T=1.79s(data=1.6ms QKV=2.13s FFN=3.04s) eta=00:22:48 | 42.5K token/s | 
[epoch_0]_60281  loss=2.992288 |g|=0.501	lr=6.23e-06 | 38.2%@S50  T=1.81s(data=1.5ms QKV=2.13s FFN=3.04s) eta=00:22:41 | 42.6K token/s | 
[epoch_0]_60291  loss=2.909842 |g|=0.494	lr=6.22e-06 | 39.1%@S50  T=1.81s(data=1.6ms QKV=2.13s FFN=3.04s) eta=00:22:25 | 42.7K token/s | 
[Fuyou] head="2" update algorithm=4 t=10.22s
[Section@60300] layer[24-32] tasks=19(nPassBack=0) last_loss=2.9956(-0.0113339) N=(772,68208,67648 7959468)
[epoch_0]_60301  loss=3.024377 |g|=0.515	lr=6.22e-06 | 39.9%@S50  T=4.80s(data=2.1ms QKV=2.13s FFN=3.03s) eta=00:58:44 | 41.5K token/s | 
[epoch_0]_60311  loss=3.008926 |g|=0.506	lr=6.21e-06 | 40.7%@S50  T=1.80s(data=1.7ms QKV=2.13s FFN=3.04s) eta=00:21:39 | 41.7K token/s | 
[epoch_0]_60321  loss=2.873647 |g|=0.497	lr=6.20e-06 | 41.5%@S50  T=1.80s(data=1.7ms QKV=2.13s FFN=3.04s) eta=00:21:25 | 41.9K token/s | 
[epoch_0]_60331  loss=2.990787 |g|=0.521	lr=6.20e-06 | 42.3%@S50  T=1.79s(data=1.6ms QKV=2.14s FFN=3.04s) eta=00:20:59 | 42.1K token/s | 
[epoch_0]_60341  loss=3.039982 |g|=0.484	lr=6.19e-06 | 43.1%@S50  T=1.83s(data=1.6ms QKV=2.14s FFN=3.04s) eta=00:21:07 | 42.2K token/s | 
[epoch_0]_60351  loss=2.982334 |g|=0.489	lr=6.19e-06 | 44.0%@S50  T=1.79s(data=2.6ms QKV=2.14s FFN=3.04s) eta=00:20:25 | 42.4K token/s | 
[epoch_0]_60361  loss=2.986708 |g|=0.531	lr=6.18e-06 | 44.8%@S50  T=1.92s(data=1.6ms QKV=2.14s FFN=3.04s) eta=00:21:32 | 42.4K token/s | 
[epoch_0]_60371  loss=3.065648 |g|=0.504	lr=6.18e-06 | 45.6%@S50  T=1.79s(data=1.6ms QKV=2.14s FFN=3.04s) eta=00:19:47 | 42.6K token/s | 
[epoch_0]_60381  loss=3.094332 |g|=0.501	lr=6.17e-06 | 46.4%@S50  T=1.82s(data=1.8ms QKV=2.14s FFN=3.04s) eta=00:19:48 | 42.7K token/s | 
[epoch_0]_60391  loss=2.939943 |g|=0.52	lr=6.17e-06 | 47.2%@S50  T=1.80s(data=1.6ms QKV=2.14s FFN=3.04s) eta=00:19:20 | 42.8K token/s | 
[Fuyou] head="3" update algorithm=4 t=9.28s
[eval] 
	 Loss@"edu_fineweb1B"=3.042(0.00022) nBranch=1 nToken=6.31M best=3.0418(300) E2T=0.0528 T=36.7896(0)s x=0
	#3.04159±0.0975 tps=171K(6.30784M) a=[2.85366,3.32228] T=36.7896(sec)
[Section@60400] layer[32-40] tasks=19(nPassBack=0) last_loss=2.98878(-0.0293453) N=(772,68320,67760 7972668)
[epoch_0]_60401  loss=2.966279 |g|=0.51	lr=6.16e-06 | 48.1%@S50  T=11.90s(data=2.7ms QKV=2.12s FFN=3.04s) eta=02:05:42 | 41.0K token/s | 
[epoch_0]_60411  loss=3.045674 |g|=0.517	lr=6.16e-06 | 48.9%@S50  T=1.79s(data=1.8ms QKV=2.13s FFN=3.04s) eta=00:18:37 | 41.3K token/s | 
[epoch_0]_60421  loss=3.080717 |g|=0.532	lr=6.15e-06 | 49.7%@S50  T=1.81s(data=1.6ms QKV=2.13s FFN=3.04s) eta=00:18:30 | 41.5K token/s | 
[epoch_0]_60431  loss=3.035517 |g|=0.509	lr=6.15e-06 | 50.5%@S50  T=1.80s(data=1.8ms QKV=2.13s FFN=3.04s) eta=00:18:06 | 41.7K token/s | 
[epoch_0]_60441  loss=3.023236 |g|=0.516	lr=6.14e-06 | 51.3%@S50  T=1.82s(data=1.6ms QKV=2.13s FFN=3.04s) eta=00:18:01 | 41.8K token/s | 
[epoch_0]_60451  loss=2.998915 |g|=0.515	lr=6.14e-06 | 52.2%@S50  T=1.80s(data=1.8ms QKV=2.13s FFN=3.04s) eta=00:17:30 | 42.0K token/s | 
[epoch_0]_60461  loss=2.901489 |g|=0.507	lr=6.13e-06 | 53.0%@S50  T=1.82s(data=1.8ms QKV=2.13s FFN=3.04s) eta=00:17:22 | 42.2K token/s | 
[epoch_0]_60471  loss=3.067533 |g|=0.505	lr=6.13e-06 | 53.8%@S50  T=1.82s(data=1.5ms QKV=2.13s FFN=3.04s) eta=00:17:04 | 42.3K token/s | 
[epoch_0]_60481  loss=2.993513 |g|=0.498	lr=6.12e-06 | 54.6%@S50  T=1.81s(data=1.5ms QKV=2.13s FFN=3.04s) eta=00:16:43 | 42.5K token/s | 
[epoch_0]_60491  loss=3.053043 |g|=0.5	lr=6.12e-06 | 55.4%@S50  T=1.83s(data=1.7ms QKV=2.13s FFN=3.04s) eta=00:16:37 | 42.6K token/s | 
[Fuyou] head="4" update algorithm=4 t=11.67s
[Section@60500] layer[40-48] tasks=19(nPassBack=0) last_loss=2.97533(0.0837197) N=(772,68432,67872 7985868)
[epoch_0]_60501  loss=3.000216 |g|=0.508	lr=6.11e-06 | 56.3%@S50  T=4.32s(data=1.6ms QKV=2.13s FFN=3.03s) eta=00:38:27 | 41.4K token/s | 
[epoch_0]_60511  loss=2.983845 |g|=0.516	lr=6.11e-06 | 57.1%@S50  T=1.81s(data=1.8ms QKV=2.13s FFN=3.04s) eta=00:15:48 | 41.6K token/s | 
[epoch_0]_60521  loss=3.073426 |g|=0.514	lr=6.11e-06 | 57.9%@S50  T=1.81s(data=1.6ms QKV=2.13s FFN=3.04s) eta=00:15:29 | 41.8K token/s | 
[epoch_0]_60531  loss=3.103787 |g|=0.512	lr=6.10e-06 | 58.7%@S50  T=1.81s(data=1.8ms QKV=2.13s FFN=3.04s) eta=00:15:11 | 41.9K token/s | 
[epoch_0]_60541  loss=3.078275 |g|=0.503	lr=6.10e-06 | 59.5%@S50  T=1.82s(data=1.6ms QKV=2.15s FFN=3.04s) eta=00:14:59 | 42.1K token/s | 
[epoch_0]_60551  loss=2.974956 |g|=0.504	lr=6.09e-06 | 60.4%@S50  T=1.81s(data=1.5ms QKV=2.14s FFN=3.04s) eta=00:14:37 | 42.3K token/s | 
[epoch_0]_60561  loss=3.096164 |g|=0.508	lr=6.09e-06 | 61.2%@S50  T=1.80s(data=1.5ms QKV=2.13s FFN=3.04s) eta=00:14:11 | 42.4K token/s | 
[epoch_0]_60571  loss=2.906896 |g|=0.488	lr=6.09e-06 | 62.0%@S50  T=1.81s(data=2.3ms QKV=2.14s FFN=3.04s) eta=00:13:59 | 42.6K token/s | 
[epoch_0]_60581  loss=3.005090 |g|=0.503	lr=6.08e-06 | 62.8%@S50  T=1.81s(data=1.6ms QKV=2.13s FFN=3.04s) eta=00:13:43 | 42.7K token/s | 
[epoch_0]_60591  loss=3.002348 |g|=0.506	lr=6.08e-06 | 63.6%@S50  T=1.80s(data=2.2ms QKV=2.14s FFN=3.04s) eta=00:13:18 | 42.8K token/s | 
[Fuyou] head="5" update algorithm=4 t=11.45s
[eval] 
	 Loss@"edu_fineweb1B"=3.041(0.00017) nBranch=1 nToken=6.31M best=3.0416(301) E2T=-0.00521 T=36.7541(0)s x=0
	#3.04142±0.0975 tps=172K(6.30784M) a=[2.85291,3.32245] T=36.7541(sec)
[Section@60600] layer[0-8] tasks=19(nPassBack=0) last_loss=3.04663(-0.106921) N=(772,68544,67984 7999068)
[epoch_0]_60601  loss=2.856926 |g|=0.492	lr=6.08e-06 | 64.4%@S50  T=12.16s(data=1.7ms QKV=2.13s FFN=3.04s) eta=01:27:58 | 41.0K token/s | 
[epoch_0]_60611  loss=2.967727 |g|=0.504	lr=6.07e-06 | 65.3%@S50  T=1.82s(data=1.7ms QKV=2.13s FFN=3.04s) eta=00:12:50 | 41.2K token/s | 
[epoch_0]_60621  loss=3.011036 |g|=0.485	lr=6.07e-06 | 66.1%@S50  T=1.80s(data=1.6ms QKV=2.13s FFN=3.04s) eta=00:12:25 | 41.4K token/s | 
[epoch_0]_60631  loss=3.031217 |g|=0.502	lr=6.07e-06 | 66.9%@S50  T=1.81s(data=1.6ms QKV=2.13s FFN=3.04s) eta=00:12:13 | 41.6K token/s | 
[epoch_0]_60641  loss=2.993013 |g|=0.496	lr=6.06e-06 | 67.7%@S50  T=1.78s(data=1.5ms QKV=2.13s FFN=3.04s) eta=00:11:43 | 41.8K token/s | 
[epoch_0]_60651  loss=3.034927 |g|=0.499	lr=6.06e-06 | 68.5%@S50  T=1.80s(data=1.9ms QKV=2.13s FFN=3.04s) eta=00:11:30 | 42.0K token/s | 
[epoch_0]_60661  loss=2.991394 |g|=0.497	lr=6.06e-06 | 69.4%@S50  T=1.81s(data=1.6ms QKV=2.13s FFN=3.04s) eta=00:11:15 | 42.2K token/s | 
[epoch_0]_60671  loss=2.994300 |g|=0.496	lr=6.05e-06 | 70.2%@S50  T=1.81s(data=1.5ms QKV=2.13s FFN=3.04s) eta=00:10:57 | 42.4K token/s | 
[epoch_0]_60681  loss=2.928594 |g|=0.497	lr=6.05e-06 | 71.0%@S50  T=1.82s(data=1.6ms QKV=2.13s FFN=3.04s) eta=00:10:45 | 42.5K token/s | 
[epoch_0]_60691  loss=2.981792 |g|=0.51	lr=6.05e-06 | 71.8%@S50  T=1.81s(data=1.8ms QKV=2.13s FFN=3.04s) eta=00:10:23 | 42.6K token/s | 
[Fuyou] head="0" update algorithm=4 t=10.57s
[Section@60700] layer[8-16] tasks=19(nPassBack=0) last_loss=2.9983(0.010874) N=(772,68656,68096 8012268)
[epoch_0]_60701  loss=3.062618 |g|=0.508	lr=6.04e-06 | 72.6%@S50  T=4.68s(data=2.2ms QKV=2.14s FFN=3.03s) eta=00:26:03 | 41.4K token/s | 
[epoch_0]_60711  loss=2.945971 |g|=0.488	lr=6.04e-06 | 73.5%@S50  T=1.81s(data=1.5ms QKV=2.14s FFN=3.04s) eta=00:09:47 | 41.6K token/s | 
[epoch_0]_60721  loss=2.976902 |g|=0.491	lr=6.04e-06 | 74.3%@S50  T=1.83s(data=1.6ms QKV=2.14s FFN=3.04s) eta=00:09:33 | 41.7K token/s | 
[epoch_0]_60731  loss=2.921458 |g|=0.487	lr=6.04e-06 | 75.1%@S50  T=1.80s(data=1.7ms QKV=2.14s FFN=3.04s) eta=00:09:08 | 41.9K token/s | 
[epoch_0]_60741  loss=2.989771 |g|=0.503	lr=6.03e-06 | 75.9%@S50  T=1.80s(data=1.8ms QKV=2.14s FFN=3.04s) eta=00:08:47 | 42.1K token/s | 
[epoch_0]_60751  loss=3.035337 |g|=0.493	lr=6.03e-06 | 76.7%@S50  T=1.80s(data=1.7ms QKV=2.14s FFN=3.04s) eta=00:08:31 | 42.3K token/s | 
[epoch_0]_60761  loss=2.986347 |g|=0.504	lr=6.03e-06 | 77.6%@S50  T=1.81s(data=1.7ms QKV=2.14s FFN=3.05s) eta=00:08:16 | 42.4K token/s | 
[epoch_0]_60771  loss=2.953466 |g|=0.508	lr=6.03e-06 | 78.4%@S50  T=1.82s(data=1.6ms QKV=2.14s FFN=3.04s) eta=00:07:59 | 42.5K token/s | 
[epoch_0]_60781  loss=3.072390 |g|=0.502	lr=6.03e-06 | 79.2%@S50  T=1.81s(data=1.5ms QKV=2.14s FFN=3.04s) eta=00:07:39 | 42.7K token/s | 
[epoch_0]_60791  loss=3.018085 |g|=0.493	lr=6.02e-06 | 80.0%@S50  T=1.82s(data=1.5ms QKV=2.14s FFN=3.04s) eta=00:07:22 | 42.8K token/s | 
[Fuyou] head="1" update algorithm=4 t=10.41s
[eval] 
	 Loss@"edu_fineweb1B"=3.041(0.00027) nBranch=1 nToken=6.31M best=3.0414(302) E2T=0.085 T=36.7727(0)s x=0
	#3.04116±0.0975 tps=172K(6.30784M) a=[2.85317,3.3224] T=36.7727(sec)
[Section@60800] layer[16-24] tasks=19(nPassBack=0) last_loss=2.95614(0.0135651) N=(772,68768,68208 8025468)
[epoch_0]_60801  loss=3.012473 |g|=0.529	lr=6.02e-06 | 80.8%@S50  T=12.47s(data=1.8ms QKV=2.13s FFN=3.04s) eta=00:48:37 | 41.0K token/s | 
[epoch_0]_60811  loss=2.985571 |g|=0.496	lr=6.02e-06 | 81.7%@S50  T=1.81s(data=1.7ms QKV=2.13s FFN=3.04s) eta=00:06:45 | 41.2K token/s | 
[epoch_0]_60821  loss=3.035781 |g|=0.49	lr=6.02e-06 | 82.5%@S50  T=1.82s(data=1.8ms QKV=2.13s FFN=3.04s) eta=00:06:29 | 41.4K token/s | 
[epoch_0]_60831  loss=3.009313 |g|=0.497	lr=6.02e-06 | 83.3%@S50  T=1.82s(data=1.8ms QKV=2.13s FFN=3.04s) eta=00:06:11 | 41.6K token/s | 
[epoch_0]_60841  loss=2.940830 |g|=0.512	lr=6.02e-06 | 84.1%@S50  T=1.81s(data=1.9ms QKV=2.13s FFN=3.04s) eta=00:05:50 | 41.8K token/s | 
[epoch_0]_60851  loss=3.033881 |g|=0.502	lr=6.01e-06 | 84.9%@S50  T=1.81s(data=1.7ms QKV=2.13s FFN=3.04s) eta=00:05:32 | 41.9K token/s | 
[epoch_0]_60861  loss=2.931044 |g|=0.491	lr=6.01e-06 | 85.7%@S50  T=1.81s(data=1.5ms QKV=2.13s FFN=3.04s) eta=00:05:14 | 42.1K token/s | 
[epoch_0]_60871  loss=2.996406 |g|=0.504	lr=6.01e-06 | 86.6%@S50  T=1.81s(data=1.7ms QKV=2.13s FFN=3.04s) eta=00:04:56 | 42.3K token/s | 
[epoch_0]_60881  loss=2.960392 |g|=0.504	lr=6.01e-06 | 87.4%@S50  T=1.82s(data=1.7ms QKV=2.14s FFN=3.04s) eta=00:04:39 | 42.4K token/s | 
[epoch_0]_60891  loss=2.942958 |g|=0.489	lr=6.01e-06 | 88.2%@S50  T=1.80s(data=1.6ms QKV=2.13s FFN=3.04s) eta=00:04:18 | 42.6K token/s | 
[Fuyou] head="2" update algorithm=4 t=10.25s
[Section@60900] layer[24-32] tasks=19(nPassBack=0) last_loss=2.99966(-0.00406051) N=(772,68880,68320 8038668)
[epoch_0]_60901  loss=3.036907 |g|=0.508	lr=6.01e-06 | 89.0%@S50  T=4.88s(data=2.0ms QKV=2.14s FFN=3.03s) eta=00:10:53 | 41.3K token/s | 
[epoch_0]_60911  loss=3.013173 |g|=0.513	lr=6.01e-06 | 89.8%@S50  T=1.80s(data=2.0ms QKV=2.14s FFN=3.04s) eta=00:03:43 | 41.5K token/s | 
[epoch_0]_60921  loss=2.946823 |g|=0.495	lr=6.01e-06 | 90.7%@S50  T=1.82s(data=1.7ms QKV=2.14s FFN=3.04s) eta=00:03:26 | 41.7K token/s | 
[epoch_0]_60931  loss=3.030299 |g|=0.507	lr=6.00e-06 | 91.5%@S50  T=1.78s(data=1.6ms QKV=2.14s FFN=3.04s) eta=00:03:05 | 41.9K token/s | 
[epoch_0]_60941  loss=2.900924 |g|=0.503	lr=6.00e-06 | 92.3%@S50  T=1.82s(data=1.7ms QKV=2.14s FFN=3.04s) eta=00:02:51 | 42.0K token/s | 
[epoch_0]_60951  loss=3.071927 |g|=0.505	lr=6.00e-06 | 93.1%@S50  T=1.82s(data=1.6ms QKV=2.14s FFN=3.04s) eta=00:02:32 | 42.2K token/s | 
[epoch_0]_60961  loss=2.949450 |g|=0.495	lr=6.00e-06 | 93.9%@S50  T=1.82s(data=1.5ms QKV=2.15s FFN=3.04s) eta=00:02:15 | 42.3K token/s | 
[epoch_0]_60971  loss=3.029501 |g|=0.497	lr=6.00e-06 | 94.8%@S50  T=1.80s(data=1.5ms QKV=2.14s FFN=3.04s) eta=00:01:55 | 42.5K token/s | 
[epoch_0]_60981  loss=3.007583 |g|=0.507	lr=6.00e-06 | 95.6%@S50  T=1.83s(data=1.5ms QKV=2.14s FFN=3.04s) eta=00:01:38 | 42.6K token/s | 
[epoch_0]_60991  loss=2.903232 |g|=0.498	lr=6.00e-06 | 96.4%@S50  T=1.81s(data=1.7ms QKV=2.14s FFN=3.04s) eta=00:01:19 | 42.7K token/s | 
[Fuyou] head="3" update algorithm=4 t=11.84s
[eval] 
	 Loss@"edu_fineweb1B"=3.041(0.0002) nBranch=1 nToken=6.31M best=3.0412(303) E2T=0.0174 T=36.7425(0)s x=0
	#3.04096±0.0973 tps=172K(6.30784M) a=[2.85257,3.322] T=36.7425(sec)
[Section@61000] layer[32-40] tasks=19(nPassBack=0) last_loss=3.02355(-0.0347748) N=(772,68992,68432 8051868)
[epoch_0]_61001  loss=2.998146 |g|=0.503	lr=6.00e-06 | 97.2%@S50  T=11.86s(data=1.7ms QKV=2.13s FFN=3.04s) eta=00:06:43 | 40.9K token/s | 
[epoch_0]_61011  loss=2.917229 |g|=0.505	lr=6.00e-06 | 98.0%@S50  T=1.84s(data=1.7ms QKV=2.14s FFN=3.04s) eta=44.17s | 41.1K token/s | 
[epoch_0]_61021  loss=2.931533 |g|=0.509	lr=6.00e-06 | 98.9%@S50  T=1.79s(data=1.7ms QKV=2.13s FFN=3.04s) eta=25.02s | 41.4K token/s | 
[epoch_0]_61031  loss=3.037645 |g|=0.518	lr=6.00e-06 | 99.7%@S50  T=1.80s(data=1.6ms QKV=2.13s FFN=3.04s) eta=7.20s | 41.6K token/s | 
[epoch_0]_61034  loss=3.096055 |g|=0.493	lr=6.00e-06 | 99.9%@S50  T=1.83s(data=1.6ms QKV=2.13s FFN=3.04s) eta=1.83s | 41.7K token/s | 
[epoch_0]_61035  loss=2.873706 |g|=0.513	lr=6.00e-06 | 100.0%@S50  T=1.82s(data=1.8ms QKV=2.14s FFN=3.04s) eta=0.0ms | 41.9K token/s | 
[train]: End of all epochs. nEpoch=1 nIter=61035(0) nToken=5000(M)

[train]: Total time=1d 12:24:16

free(): invalid pointer
Aborted (core dumped)
