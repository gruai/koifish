{        
    "version":"0.1.0",
    
    "model":{      
        "arch":"GPT2",
        "datatype":{
            "weight":"BF16",
            "embed":"BF16",
            "gradient":"BF16",
            "# ternary":["ffn_down.weight", "ffn_up.weight"]
        },
        "parameter":{
            "Layer": 12,  
            "transformer":{
                "Ctx":1024,  "Embed":    768,    "Head": 12,   "Ffn":3072,
                "on":[""]
            }
        },  
        "inp_embd": {"Embedding+":[]},    
        "layer":  {      
            "attn":{"QKV":[]},               
            "ffn":{"FFN":[]},       
            "# gattn":{"GAU":[]}
                                  
        },
        "last_normal":{"Normal":[]},
        "out": {"CLASIFY":[]}
    },

    "datasets":{
        "train":{
            "glob":"./Datasets/edu_fineweb1B/*train*.bin","most":10, "name":"edu_fineweb1B"
        },
        "#eval_1": {"glob":"./Datasets/edu_fineweb1B/*val*.bin","name":"edu_fineweb1B","eval-every":100        },
        "#eval_2":{"glob":"./Datasets/hellaswag_val.bin", "type":"hellaswag","eval-every":500 }        
    },
    
    "train": {
        "save-every":500,
        "dump-every":10,
        "gpt-every":-10,
        "epoch":1,
        "batch":40,
        "learning-rate":0.0006,  

        "optimizatioin":{
            "#method":"adamw sgdv hsgd lion",
            "method":"adamw",
            "sign":0,
            "grad_accumulation":1,
            "lars_ratio":0,      "ZMUV_ratio":0.00    
        }              
    },    
    
    

    "# checkpoint-in":"./hy-tmp/checkpoint/chk-GPT2_9001.gguf",
    "# checkpoint-out":"./hy-tmp/checkpoint/chk-GPT2_",
    "# model-out":"gpt2_cys.gguf",
    

    "threads":20,            
    "seed":42,
    "use-checkpointing":true,   
    "n-gpu-layers":100
}