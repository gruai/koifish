{
    "version": "0.1.0",
    "model": {
        "arch": "GPT2",
        "datatype": {
            "weight": "BF16",
            "embed": "BF16",
            "#gradient": "BF16",
            "#ternary": [
                "attn.wq.weight",
                "attn.wk.weight",
                "attn.wv.weight",
                "attn.wo.weight"
            ],
            "#tile": [
                "ffn_down.weight",
                "ffn_up.weight"
            ]
        },
        "parameter": {
            "Layer": 48,
            "transformer": {
                "Ctx": 1024,
                "Embed": 1600,
                "Head": 25,
                "Ffn": 6400
            }
        },
        "inp_embd": {
            "Embedding+": []
        },
        "Layer": {
            "attn": {
                "QKV": []
            },
            "ffn": {
                "FFN": []
            },
            "# gattn": {
                "GAU": []
            }
        },
        "output_norm": {
            "Normal": []
        },
        "out": {
            "CLASIFY": []
        }
    },
    "datasets": {
        "train": {
            "glob": "./Datasets/edu_fineweb1B/*train*.bin",
            "most": 20,
            "name": "edu_fineweb1B"
        },
        "eval_1": {
            "glob": "./Datasets/edu_fineweb1B/*val*.bin",
            "name": "edu_fineweb1B",
            "most": 10,
            "eval-every": 100
        },
        "#eval_2": {
            "glob": "./Datasets/hellaswag_val.bin",
            "type": "hellaswag",
            "eval-every": 1000
        }
    },
    "train": {
        "save-every": 500,
        "dump-every": 10,
        "gpt-every": -10,
        "branch": 6,
        "epoch": 2,
        "batch": 40,
        "learning-rate": 0.0006,
        "decay": 0.1,
        "optimizatioin": {
            "#method": "adamw sgdv hsgd lion adams",
            "method": "adams",
            "sign": 0,
            "grad_accumulation": 1,
            "lars_ratio": 0,
            "ZMUV_ratio": 0.0
        }
    },
    "# checkpoint-in": "./hy-tmp/checkpoint/chk-GPT2_9001.gguf",
    "checkpoint-out": "./hy-tmp/checkpoint/GPT2_1558M_",
    "# model-out": "gpt2_cys.gguf",
    "threads": 20,
    "seed": 42
}